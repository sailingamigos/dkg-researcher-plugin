[
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6ed7d96188fc9c56d93db7eb05f868a8e3469642",
            "@type": "ScholarlyArticle",
            "paperId": "6ed7d96188fc9c56d93db7eb05f868a8e3469642",
            "corpusId": 60721833,
            "url": "https://www.semanticscholar.org/paper/6ed7d96188fc9c56d93db7eb05f868a8e3469642",
            "title": "Review of Speech and language processing: an introduction to natural language processing, computational linguistics, and speech recognition by Daniel Jurafsky and James H. Martin. Prentice Hall 2000.",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2000,
            "externalIds": {
                "MAG": "1572130671",
                "CorpusId": 60721833
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 775,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2000-12-01",
            "journal": {
                "name": "Computational Linguistics",
                "volume": "26"
            },
            "citationStyles": {
                "bibtex": "@Article{Reviewer-Teller2000ReviewOS,\n author = {Virginia Reviewer-Teller},\n journal = {Computational Linguistics},\n pages = {638-641},\n title = {Review of Speech and language processing: an introduction to natural language processing, computational linguistics, and speech recognition by Daniel Jurafsky and James H. Martin. Prentice Hall 2000.},\n volume = {26},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e45775d6917288dc8cfe30b74df19ecd3135b15b",
            "@type": "ScholarlyArticle",
            "paperId": "e45775d6917288dc8cfe30b74df19ecd3135b15b",
            "corpusId": 56915389,
            "url": "https://www.semanticscholar.org/paper/e45775d6917288dc8cfe30b74df19ecd3135b15b",
            "title": "Natural Language Processing and Information Retrieval",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2008,
            "externalIds": {
                "MAG": "1234692112",
                "CorpusId": 56915389
            },
            "abstract": "Natural Language Processing and Information Retrieval is a textbook designed to meet the requirements of engineering students pursuing undergraduate and postgraduate programs in computer science and information technology. The book attempts to bridge the gap between theory and practice and would also serve as a useful reference for professionals and researchers working on language-related projects. Integrating two rapidly developing and popular research fields of language processing and information retrieval, the book provides an extensive coverage of various concepts and widely used techniques in these areas. The text includes topics such as language modeling, lexical analysis, computational modeling, grammar and parsing, and semantic as well as knowledge-based analysis. The statistical and semantic approaches are explained with examples from Hindi, English, and Urdu. Besides presenting traditional applications of machine translation and natural language generation, the book discusses recent trends and practices of information retrieval, text summarization, and information extraction in sufficient detail. Written in easy-to-understand and student-friendly style, the textbook also provides ample practical applications based on hands-on research experience wherever appropriate.",
            "referenceCount": 0,
            "citationCount": 34,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2008-08-15",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Tiwary2008NaturalLP,\n author = {U. Tiwary and Tanveer J. Siddiqui},\n title = {Natural Language Processing and Information Retrieval},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:63758d897c3451a108d49b2420a29c715ecd7b85",
            "@type": "ScholarlyArticle",
            "paperId": "63758d897c3451a108d49b2420a29c715ecd7b85",
            "corpusId": 18681074,
            "url": "https://www.semanticscholar.org/paper/63758d897c3451a108d49b2420a29c715ecd7b85",
            "title": "Using natural language processing in order to create SQL queries",
            "venue": "International Conference on Computer and Communication Engineering",
            "publicationVenue": {
                "id": "urn:research:97df697a-0a5d-457e-93a1-4e40852ffabf",
                "name": "International Conference on Computer and Communication Engineering",
                "alternate_names": [
                    "ICCCE",
                    "Int Conf Comput Commun Eng"
                ],
                "issn": null,
                "url": null
            },
            "year": 2008,
            "externalIds": {
                "MAG": "2159231020",
                "DOI": "10.1109/ICCCE.2008.4580674",
                "CorpusId": 18681074
            },
            "abstract": "Using query language for dealing with databases is always a professional and complex problem. This complexity causes the userpsilas usage of data existing in database limits to use definite reports there are in some pre implemented softwares. However, you can create this opportunity that each none professional user transfers his questions and requirements to computer in natural language and derives his desired data by natural language processing. In this paper we represent a method for building a ldquonatural languages interfaces to data basesrdquo (NLIDB) system. This system prepares an ldquoexpert systemrdquo implemented in prolog which it can identify synonymous words in any language. It first parses the input sentences, and then the natural language expressions are transformed to SQL language.",
            "referenceCount": 11,
            "citationCount": 45,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Conference"
            ],
            "publicationDate": "2008-05-13",
            "journal": {
                "name": "2008 International Conference on Computer and Communication Engineering",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Conference{djahantighi2008UsingNL,\n author = {F. Siasar djahantighi and M. Norouzifard and S. H. Davarpanah and M. H. Shenassa},\n booktitle = {International Conference on Computer and Communication Engineering},\n journal = {2008 International Conference on Computer and Communication Engineering},\n pages = {600-604},\n title = {Using natural language processing in order to create SQL queries},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f6c73a7cca40a218d9385812cd743a3331822d68",
            "@type": "ScholarlyArticle",
            "paperId": "f6c73a7cca40a218d9385812cd743a3331822d68",
            "corpusId": 22425932,
            "url": "https://www.semanticscholar.org/paper/f6c73a7cca40a218d9385812cd743a3331822d68",
            "title": "Second i2b2 workshop on natural language processing challenges for clinical records.",
            "venue": "AMIA ... Annual Symposium proceedings. AMIA Symposium",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2008,
            "externalIds": {
                "MAG": "27189800",
                "CorpusId": 22425932,
                "PubMed": "18998924"
            },
            "abstract": "The second i2b2 workshop on Natural Language Processing (NLP) for clinical records presents a shared-task and challenge on the automated extraction of obesity information from narrative patient records. The goal of the obesity challenge is to continue i2b2's effort to open patient records to studies by the NLP and Medical Informatics communities for the advancement of the state of the art in medical language processing. For this, i2b2 made available a set of de-identified patient records that are hand-annotated by medical professionals for obesity-related information, and invited the development of systems that can automatically mark the presence of obesity and co-morbidities in each patient from information in their records. In this workshop, we will discuss the obesity challenge, review some approaches to automatically identifying obese patients and obesity co-morbidities from medical records, and present the challenge results. The findings of the i2b2 challenge on obesity will shed light onto the state of the art in natural language processing for multi-label multi-class classification of narrative records for clinical applications.",
            "referenceCount": 4,
            "citationCount": 72,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2008-11-06",
            "journal": {
                "name": "AMIA ... Annual Symposium proceedings. AMIA Symposium",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Uzuner2008SecondIW,\n author = {Ozlem Uzuner},\n booktitle = {AMIA ... Annual Symposium proceedings. AMIA Symposium},\n journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},\n pages = {\n          1252-3\n        },\n title = {Second i2b2 workshop on natural language processing challenges for clinical records.},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:20ab42c9b93b6e41f6e1d7b546f87c5a871db020",
            "@type": "ScholarlyArticle",
            "paperId": "20ab42c9b93b6e41f6e1d7b546f87c5a871db020",
            "corpusId": 7899387,
            "url": "https://www.semanticscholar.org/paper/20ab42c9b93b6e41f6e1d7b546f87c5a871db020",
            "title": "Integrating Language and Vision to Generate Natural Language Descriptions of Videos in the Wild",
            "venue": "International Conference on Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:f51ff783-cdff-4e22-94fb-28e6336d17b3",
                "name": "International Conference on Computational Linguistics",
                "alternate_names": [
                    "Int Conf Comput Linguistics",
                    "COLING"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/coling/"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2251353663",
                "ACL": "C14-1115",
                "DBLP": "conf/coling/ThomasonVGSM14",
                "CorpusId": 7899387
            },
            "abstract": "This paper integrates techniques in natural language processing and computer vision to improve recognition and description of entities and activities in real-world videos. We propose a strategy for generating textual descriptions of videos by using a factor graph to combine visual detections with language statistics. We use state-of-the-art visual recognition systems to obtain confidences on entities, activities, and scenes present in the video. Our factor graph model combines these detection confidences with probabilistic knowledge mined from text corpora to estimate the most likely subject, verb, object, and place. Results on YouTube videos show that our approach improves both the joint detection of these latent, diverse sentence components and the detection of some individual components when compared to using the vision system alone, as well as over a previous n-gram language-modeling approach. The joint detection allows us to automatically generate more accurate, richer sentential descriptions of videos with a wide array of possible content.",
            "referenceCount": 32,
            "citationCount": 198,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-08-23",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Thomason2014IntegratingLA,\n author = {Jesse Thomason and Subhashini Venugopalan and S. Guadarrama and Kate Saenko and R. Mooney},\n booktitle = {International Conference on Computational Linguistics},\n pages = {1218-1227},\n title = {Integrating Language and Vision to Generate Natural Language Descriptions of Videos in the Wild},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0beb7b527bb6d53ad5250654008eaffc44686cd5",
            "@type": "ScholarlyArticle",
            "paperId": "0beb7b527bb6d53ad5250654008eaffc44686cd5",
            "corpusId": 61804551,
            "url": "https://www.semanticscholar.org/paper/0beb7b527bb6d53ad5250654008eaffc44686cd5",
            "title": "Arabic Natural Language Processing",
            "venue": "Conference on Empirical Methods in Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:41bf9ed3-85b3-4c90-b015-150e31690253",
                "name": "Conference on Empirical Methods in Natural Language Processing",
                "alternate_names": [
                    "Empir Method Nat Lang Process",
                    "Empirical Methods in Natural Language Processing",
                    "Conf Empir Method Nat Lang Process",
                    "EMNLP"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/emnlp"
            },
            "year": 2008,
            "externalIds": {
                "ACL": "2022.emnlp-tutorials.2",
                "MAG": "2294764339",
                "DOI": "10.18653/v1/2022.emnlp-tutorials.2",
                "CorpusId": 61804551
            },
            "abstract": "The Arabic language continues to be the focus of an increasing number of projects in natural language processing (NLP) and computational linguistics (CL). This tutorial provides NLP/CL system developers and researchers (computer scientists and linguists alike) with the necessary background information for working with Arabic in its various forms: Classical, Modern Standard and Dialectal. We discuss various Arabic linguistic phenomena and review the state-of-the-art in Arabic processing from enabling technologies and resources, to common tasks and applications. The tutorial will explain important concepts, common wisdom, and common pitfalls in Arabic processing. Given the wide range of possible issues, we invite tutorial attendees to bring up interesting challenges and problems they are working on to discuss during the tutorial.",
            "referenceCount": 6,
            "citationCount": 22,
            "influentialCitationCount": 0,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://aclanthology.org/2022.emnlp-tutorials.2.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Conference",
                "Review"
            ],
            "publicationDate": "2008-11-30",
            "journal": {
                "name": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Conference{Habash2008ArabicNL,\n author = {Nizar Habash},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts},\n title = {Arabic Natural Language Processing},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ecbd467eacde24de43f43bc703c891df447ff389",
            "@type": "ScholarlyArticle",
            "paperId": "ecbd467eacde24de43f43bc703c891df447ff389",
            "corpusId": 606325,
            "url": "https://www.semanticscholar.org/paper/ecbd467eacde24de43f43bc703c891df447ff389",
            "title": "Domain adaptation of natural language processing systems",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2008,
            "externalIds": {
                "MAG": "113837456",
                "CorpusId": 606325
            },
            "abstract": "Statistical language processing models are being applied to an ever wider and more varied range of linguistic domains. Collecting and curating training sets for each different domain is prohibitively expensive, and at the same time differences in vocabulary and writing style across domains can cause state-of-the-art supervised models to dramatically increase in error. \nThe first part of this thesis describes structural correspondence learning (SCL), a method for adapting linear discriminative models from resource-rich source domains to resource-poor target domains. The key idea is the use of pivot features which occur frequently and behave similarly in both the source and target domains. SCL builds a shared representation by searching for a low-dimensional feature subspace that allows us to accurately predict the presence or absence of pivot features on unlabeled data. We demonstrate SCL on two text processing problems: sentiment classification of product reviews and part of speech tagging. For both tasks, SCL significantly improves over state of the art supervised models using only unlabeled target data. \nIn the second part of the thesis, we develop a formal framework for analyzing domain adaptation tasks. We first describe a measure of divergence, the HDH -divergence, that depends on the hypothesis class H from which we estimate our supervised model. We then use this measure to state an upper bound on the true target error of a model trained to minimize a convex combination of empirical source and target errors. The bound characterizes the tradeoff inherent in training on both the large quantity of biased source data and the small quantity of unbiased target data, and we can compute it from finite labeled and unlabeled samples of the source and target distributions under relatively weak assumptions. Finally, we confirm experimentally that the bound corresponds well to empirical target error for the task of sentiment classification.",
            "referenceCount": 77,
            "citationCount": 64,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Pereira2008DomainAO,\n author = {Fernando C Pereira and John Blitzer},\n title = {Domain adaptation of natural language processing systems},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1e43c7084bdcb6b3102afaf301cce10faead2702",
            "@type": "ScholarlyArticle",
            "paperId": "1e43c7084bdcb6b3102afaf301cce10faead2702",
            "corpusId": 59291975,
            "url": "https://www.semanticscholar.org/paper/1e43c7084bdcb6b3102afaf301cce10faead2702",
            "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining",
            "venue": "Bioinform.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2911489562",
                "ArXiv": "1901.08746",
                "PubMedCentral": "7703786",
                "DBLP": "journals/corr/abs-1901-08746",
                "DOI": "10.1093/bioinformatics/btz682",
                "CorpusId": 59291975,
                "PubMed": "31501885"
            },
            "abstract": "Abstract Motivation Biomedical text mining is becoming increasingly important as the number of biomedical documents rapidly grows. With the progress in natural language processing (NLP), extracting valuable information from biomedical literature has gained popularity among researchers, and deep learning has boosted the development of effective biomedical text mining models. However, directly applying the advancements in NLP to biomedical text mining often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora. In this article, we investigate how the recently introduced pre-trained language model BERT can be adapted for biomedical corpora. Results We introduce BioBERT (Bidirectional Encoder Representations from Transformers for Biomedical Text Mining), which is a domain-specific language representation model pre-trained on large-scale biomedical corpora. With almost the same architecture across tasks, BioBERT largely outperforms BERT and previous state-of-the-art models in a variety of biomedical text mining tasks when pre-trained on biomedical corpora. While BERT obtains performance comparable to that of previous state-of-the-art models, BioBERT significantly outperforms them on the following three representative biomedical text mining tasks: biomedical named entity recognition (0.62% F1 score improvement), biomedical relation extraction (2.80% F1 score improvement) and biomedical question answering (12.24% MRR improvement). Our analysis results show that pre-training BERT on biomedical corpora helps it to understand complex biomedical texts. Availability and implementation We make the pre-trained weights of BioBERT freely available at https://github.com/naver/biobert-pretrained, and the source code for fine-tuning BioBERT available at https://github.com/dmis-lab/biobert.",
            "referenceCount": 45,
            "citationCount": 3658,
            "influentialCitationCount": 644,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-01-25",
            "journal": {
                "name": "Bioinformatics",
                "volume": "36"
            },
            "citationStyles": {
                "bibtex": "@Article{Lee2019BioBERTAP,\n author = {Jinhyuk Lee and Wonjin Yoon and Sungdong Kim and Donghyeon Kim and Sunkyu Kim and Chan Ho So and Jaewoo Kang},\n booktitle = {Bioinform.},\n journal = {Bioinformatics},\n pages = {1234 - 1240},\n title = {BioBERT: a pre-trained biomedical language representation model for biomedical text mining},\n volume = {36},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ee3e2a5608033acda22bcc7abc9f767e3e8fc912",
            "@type": "ScholarlyArticle",
            "paperId": "ee3e2a5608033acda22bcc7abc9f767e3e8fc912",
            "corpusId": 1554697,
            "url": "https://www.semanticscholar.org/paper/ee3e2a5608033acda22bcc7abc9f767e3e8fc912",
            "title": "GENIES: a natural-language processing system for the extraction of molecular pathways from journal articles",
            "venue": "Intelligent Systems in Molecular Biology",
            "publicationVenue": {
                "id": "urn:research:9d3979be-d38e-4ba6-8e93-ce5332aa70ce",
                "name": "Intelligent Systems in Molecular Biology",
                "alternate_names": [
                    "ISMB",
                    "Intell Syst Mol Biology"
                ],
                "issn": null,
                "url": "http://www.iscb.org/"
            },
            "year": 2001,
            "externalIds": {
                "MAG": "2158505321",
                "DBLP": "conf/ismb/FriedmanKYKR01",
                "DOI": "10.1093/BIOINFORMATICS/17.SUPPL_1.S74",
                "CorpusId": 1554697,
                "PubMed": "11472995"
            },
            "abstract": "Systems that extract structured information from natural language passages have been highly successful in specialized domains. The time is opportune for developing analogous applications for molecular biology and genomics. We present a system, GENIES, that extracts and structures information about cellular pathways from the biological literature in accordance with a knowledge model that we developed earlier. We implemented GENIES by modifying an existing medical natural language processing system, MedLEE, and performed a preliminary evaluation study. Our results demonstrate the value of the underlying techniques for the purpose of acquiring valuable knowledge from biological journals.",
            "referenceCount": 38,
            "citationCount": 575,
            "influentialCitationCount": 24,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Study",
                "Conference"
            ],
            "publicationDate": "2001-06-01",
            "journal": {
                "name": "Bioinformatics",
                "volume": "17 Suppl 1"
            },
            "citationStyles": {
                "bibtex": "@Article{Friedman2001GENIESAN,\n author = {C. Friedman and Pauline Kra and Hong Yu and M. Krauthammer and A. Rzhetsky},\n booktitle = {Intelligent Systems in Molecular Biology},\n journal = {Bioinformatics},\n pages = {\n          S74-82\n        },\n title = {GENIES: a natural-language processing system for the extraction of molecular pathways from journal articles},\n volume = {17 Suppl 1},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:96ea07447d2f9adefe03852a878517a2a6d45b96",
            "@type": "ScholarlyArticle",
            "paperId": "96ea07447d2f9adefe03852a878517a2a6d45b96",
            "corpusId": 237386023,
            "url": "https://www.semanticscholar.org/paper/96ea07447d2f9adefe03852a878517a2a6d45b96",
            "title": "Learning to Prompt for Vision-Language Models",
            "venue": "International Journal of Computer Vision",
            "publicationVenue": {
                "id": "urn:research:939ee07c-6009-43f8-b884-69238b40659e",
                "name": "International Journal of Computer Vision",
                "alternate_names": [
                    "Int J Comput Vis"
                ],
                "issn": "0920-5691",
                "url": "https://www.springer.com/computer/image+processing/journal/11263"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "journals/corr/abs-2109-01134",
                "ArXiv": "2109.01134",
                "DOI": "10.1007/s11263-022-01653-1",
                "CorpusId": 237386023
            },
            "abstract": null,
            "referenceCount": 59,
            "citationCount": 787,
            "influentialCitationCount": 162,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2109.01134",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-09-02",
            "journal": {
                "name": "International Journal of Computer Vision",
                "volume": "130"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhou2021LearningTP,\n author = {Kaiyang Zhou and Jingkang Yang and Chen Change Loy and Ziwei Liu},\n booktitle = {International Journal of Computer Vision},\n journal = {International Journal of Computer Vision},\n pages = {2337 - 2348},\n title = {Learning to Prompt for Vision-Language Models},\n volume = {130},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c64b9ed6a42b93a24316c7d1d6b3fddbd96dbaf5",
            "@type": "ScholarlyArticle",
            "paperId": "c64b9ed6a42b93a24316c7d1d6b3fddbd96dbaf5",
            "corpusId": 264719695,
            "url": "https://www.semanticscholar.org/paper/c64b9ed6a42b93a24316c7d1d6b3fddbd96dbaf5",
            "title": "Chinese Whispers - an Efficient Graph Clustering Algorithm and its Application to Natural Language Processing Problems",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2006,
            "externalIds": {
                "MAG": "1987302197",
                "ACL": "W06-3812",
                "DOI": "10.3115/1654758.1654774",
                "CorpusId": 264719695
            },
            "abstract": "We introduce Chinese Whispers, a randomized graph-clustering algorithm, which is time-linear in the number of edges. After a detailed definition of the algorithm and a discussion of its strengths and weaknesses, the performance of Chinese Whispers is measured on Natural Language Processing (NLP) problems as diverse as language separation, acquisition of syntactic word classes and word sense disambiguation. At this, the fact is employed that the small-world property holds for many graphs in NLP.",
            "referenceCount": 18,
            "citationCount": 346,
            "influentialCitationCount": 38,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.5555/1654758.1654774",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2006-06-09",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Biemann2006ChineseW,\n author = {Chris Biemann},\n pages = {73-80},\n title = {Chinese Whispers - an Efficient Graph Clustering Algorithm and its Application to Natural Language Processing Problems},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:16f58a56302a485fe3473fa267cb67902b5b02dd",
            "@type": "ScholarlyArticle",
            "paperId": "16f58a56302a485fe3473fa267cb67902b5b02dd",
            "corpusId": 20290601,
            "url": "https://www.semanticscholar.org/paper/16f58a56302a485fe3473fa267cb67902b5b02dd",
            "title": "Automated encoding of clinical documents based on natural language processing.",
            "venue": "JAMIA Journal of the American Medical Informatics Association",
            "publicationVenue": {
                "id": "urn:research:5eb9af16-8aea-4524-be6c-bd3418bf7570",
                "name": "JAMIA Journal of the American Medical Informatics Association",
                "alternate_names": [
                    "AMIA Annual Symposium Proceedings",
                    "AMIA Annu Symp Proc",
                    "Journal of the American Medical Informatics Association",
                    "J Am Med Informatics Assoc",
                    "JAMIA J Am Med Informatics Assoc"
                ],
                "issn": "1067-5027",
                "url": "http://jamia.bmj.com/"
            },
            "year": 2004,
            "externalIds": {
                "MAG": "1871067837",
                "DOI": "10.1197/JAMIA.M1552",
                "CorpusId": 20290601,
                "PubMed": "15187068"
            },
            "abstract": "OBJECTIVE\nThe aim of this study was to develop a method based on natural language processing (NLP) that automatically maps an entire clinical document to codes with modifiers and to quantitatively evaluate the method.\n\n\nMETHODS\nAn existing NLP system, MedLEE, was adapted to automatically generate codes. The method involves matching of structured output generated by MedLEE consisting of findings and modifiers to obtain the most specific code. Recall and precision applied to Unified Medical Language System (UMLS) coding were evaluated in two separate studies. Recall was measured using a test set of 150 randomly selected sentences, which were processed using MedLEE. Results were compared with a reference standard determined manually by seven experts. Precision was measured using a second test set of 150 randomly selected sentences from which UMLS codes were automatically generated by the method and then validated by experts.\n\n\nRESULTS\nRecall of the system for UMLS coding of all terms was .77 (95% CI.72-.81), and for coding terms that had corresponding UMLS codes recall was .83 (.79-.87). Recall of the system for extracting all terms was .84 (.81-.88). Recall of the experts ranged from .69 to .91 for extracting terms. The precision of the system was .89 (.87-.91), and precision of the experts ranged from .61 to .91.\n\n\nCONCLUSION\nExtraction of relevant clinical information and UMLS coding were accomplished using a method based on NLP. The method appeared to be comparable to or better than six experts. The advantage of the method is that it maps text to codes along with other related information, rendering the coded output suitable for effective retrieval.",
            "referenceCount": 38,
            "citationCount": 515,
            "influentialCitationCount": 19,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://academic.oup.com/jamia/article-pdf/11/5/392/2448181/11-5-392.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Study"
            ],
            "publicationDate": "2004-09-01",
            "journal": {
                "name": "Journal of the American Medical Informatics Association : JAMIA",
                "volume": "11 5"
            },
            "citationStyles": {
                "bibtex": "@Article{Friedman2004AutomatedEO,\n author = {C. Friedman and L. Shagina and Y. Lussier and G. Hripcsak},\n booktitle = {JAMIA Journal of the American Medical Informatics Association},\n journal = {Journal of the American Medical Informatics Association : JAMIA},\n pages = {\n          392-402\n        },\n title = {Automated encoding of clinical documents based on natural language processing.},\n volume = {11 5},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:aab6f3b98cda74cfa252c710cf9b652afc024947",
            "@type": "ScholarlyArticle",
            "paperId": "aab6f3b98cda74cfa252c710cf9b652afc024947",
            "corpusId": 51622098,
            "url": "https://www.semanticscholar.org/paper/aab6f3b98cda74cfa252c710cf9b652afc024947",
            "title": "Handbook of Natural Language Processing",
            "venue": "Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:ee37a78c-f3d8-407a-bd24-bb97fe6dbab9",
                "name": "Computational Linguistics",
                "alternate_names": [
                    "Comput Linguistics"
                ],
                "issn": "0891-2017",
                "url": "http://aclanthology.info/venues/cl"
            },
            "year": 2001,
            "externalIds": {
                "MAG": "2111989294",
                "DOI": "10.1162/coli.2000.27.4.602",
                "CorpusId": 51622098
            },
            "abstract": "Symbolic approaches to natural language processing tokenisation and sentence segmentation lexical analysis parsing techniques semantic analysis discourse structure and intention recognition natural language generation intelligent writing assistance database interfaces information extraction the generation of reports from databases the generation of multimedia presentations machine translation dialogue systems - from theory to practice in TRAINS-96 empirical approaches to natural language processing corpus creation for data-intensive linguistics part-of-speech tagging alignment contextual word similarity computing similarity collocations statistical parsing authorship identificaiton and computational stylometry lexical knowledge acquisition example-based machine translation word-sense disambiguation NLP based on artificial neural-networks - introduction.",
            "referenceCount": 0,
            "citationCount": 541,
            "influentialCitationCount": 22,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.mitpressjournals.org/doi/pdf/10.1162/coli.2000.27.4.602",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "Computational Linguistics",
                "volume": "27"
            },
            "citationStyles": {
                "bibtex": "@Article{Dale2001HandbookON,\n author = {R. Dale and H. Moisl and H. Somers},\n booktitle = {Computational Linguistics},\n journal = {Computational Linguistics},\n pages = {602-603},\n title = {Handbook of Natural Language Processing},\n volume = {27},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:29dfba100b567a6d9aaa3a66b83994f9925c49e1",
            "@type": "ScholarlyArticle",
            "paperId": "29dfba100b567a6d9aaa3a66b83994f9925c49e1",
            "corpusId": 28841837,
            "url": "https://www.semanticscholar.org/paper/29dfba100b567a6d9aaa3a66b83994f9925c49e1",
            "title": "Prediction and Substantiation: A New Approach to Natural Language Processing",
            "venue": "Cognitive Sciences",
            "publicationVenue": {
                "id": "urn:research:c33b01b0-31b4-470e-a9f9-8432e02c3cb9",
                "name": "Cognitive Sciences",
                "alternate_names": [
                    "Cognitive Science",
                    "Cogn Sci"
                ],
                "issn": "1935-8059",
                "url": "http://www.informaworld.com/openurl?genre=journal&issn=1551-6709"
            },
            "year": 1979,
            "externalIds": {
                "DBLP": "journals/cogsci/DeJong79",
                "MAG": "2083017379",
                "DOI": "10.1207/s15516709cog0303_4",
                "CorpusId": 28841837
            },
            "abstract": "This paper describes a new approach to natural language processing which results in a very robust and efficient system. The approach taken is to integrate the parser with the rest of the system. This enables the parser to benefit from predictions that the rest of the system makes in the course of its processing. These predictions can be invaluable as guides to the parser in such difficult problem areas as resolving referents and selecting meanings of ambiguous words. A program, called FRUMP for Fast Reading Understanding and Memory Program, employs this approach to parsing. FRUMP skims articles rather than reading them for detail. The program works on the relatively unconstrained domain of news articles. It routinely understands stories it has never before seen. The program's success is largely due to its radically different approach to parsing.",
            "referenceCount": 14,
            "citationCount": 126,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1207/s15516709cog0303_4",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1979-07-01",
            "journal": {
                "name": "Cogn. Sci.",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{DeJong1979PredictionAS,\n author = {G. DeJong},\n booktitle = {Cognitive Sciences},\n journal = {Cogn. Sci.},\n pages = {251-273},\n title = {Prediction and Substantiation: A New Approach to Natural Language Processing},\n volume = {3},\n year = {1979}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:edefd81d41e7aa901b880e125ab8c86d7a48b75f",
            "@type": "ScholarlyArticle",
            "paperId": "edefd81d41e7aa901b880e125ab8c86d7a48b75f",
            "corpusId": 60545533,
            "url": "https://www.semanticscholar.org/paper/edefd81d41e7aa901b880e125ab8c86d7a48b75f",
            "title": "Strategies for Natural Language Processing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1982,
            "externalIds": {
                "MAG": "1563635790",
                "DOI": "10.4324/9781315802671",
                "CorpusId": 60545533
            },
            "abstract": "Introducing a new hobby for other people may inspire them to join with you. Reading, as one of mutual hobby, is considered as the very easy hobby to do. But, many people are not interested in this hobby. Why? Boring is the reason of why. However, this feel actually can deal with the book and time of you reading. Yeah, one that we will refer to break the boredom in reading is choosing strategies for natural language processing as the reading material.",
            "referenceCount": 0,
            "citationCount": 279,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Lehnert1982StrategiesFN,\n author = {W. Lehnert and Martin H. Ringle},\n title = {Strategies for Natural Language Processing},\n year = {1982}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1c0058b12db2e8001cf0f7a5a0046e910fe289f4",
            "@type": "ScholarlyArticle",
            "paperId": "1c0058b12db2e8001cf0f7a5a0046e910fe289f4",
            "corpusId": 12173422,
            "url": "https://www.semanticscholar.org/paper/1c0058b12db2e8001cf0f7a5a0046e910fe289f4",
            "title": "Using Natural Language Processing to Classify Suicide Notes",
            "venue": "Workshop on Biomedical Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:3afb600a-49ad-40aa-858c-081def027584",
                "name": "Workshop on Biomedical Natural Language Processing",
                "alternate_names": [
                    "BioNLP",
                    "Workshop Biomed Nat Lang Process"
                ],
                "issn": null,
                "url": null
            },
            "year": 2008,
            "externalIds": {
                "DBLP": "conf/bionlp/PestianMGLCK08",
                "MAG": "1989385699",
                "ACL": "W08-0616",
                "DOI": "10.3115/1572306.1572327",
                "CorpusId": 12173422,
                "PubMed": "19006447"
            },
            "abstract": "We hypothesize that machine-learning algorithms (MLA) could classify completer and ideator suicide notes as well a mental health professionals (MHP). Five MHPs classified 66 notes as either ideator or completer; machine learning algorithms (MLA) were used for the same task. Results: MHPs were accurate 71% of the time; the SMO algorithm was accurate 79% of the time. This is an important first step in developing an evidence based suicide predictor for emergency department use. Language: en",
            "referenceCount": 5,
            "citationCount": 71,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://dl.acm.org/ft_gateway.cfm?id=1572327&type=pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2008-06-19",
            "journal": {
                "name": "AMIA ... Annual Symposium proceedings. AMIA Symposium",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Pestian2008UsingNL,\n author = {J. Pestian and P. Matykiewicz and J. Grupp\u2010Phelan and S. Lavanier and Jennifer Combs and R. Kowatch},\n booktitle = {Workshop on Biomedical Natural Language Processing},\n journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},\n pages = {\n          1091\n        },\n title = {Using Natural Language Processing to Classify Suicide Notes},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8324a33c405c5f29ef7eec8bd91e63623141e033",
            "@type": "ScholarlyArticle",
            "paperId": "8324a33c405c5f29ef7eec8bd91e63623141e033",
            "corpusId": 15887915,
            "url": "https://www.semanticscholar.org/paper/8324a33c405c5f29ef7eec8bd91e63623141e033",
            "title": "Incremental natural language processing for HRI",
            "venue": "IEEE/ACM International Conference on Human-Robot Interaction",
            "publicationVenue": {
                "id": "urn:research:b49868ed-865c-4154-b70a-8d34e341cf68",
                "name": "IEEE/ACM International Conference on Human-Robot Interaction",
                "alternate_names": [
                    "Human-Robot Interaction",
                    "HRI",
                    "Human-robot Interact",
                    "IEEE/ACM Int Conf Human-robot Interact"
                ],
                "issn": null,
                "url": "http://www.wikicfp.com/cfp/program?id=1232"
            },
            "year": 2007,
            "externalIds": {
                "MAG": "2132963441",
                "DBLP": "conf/hri/BrickS07",
                "DOI": "10.1145/1228716.1228752",
                "CorpusId": 15887915
            },
            "abstract": "Robots that interact with humans face-to-face using natural language need to be responsive to the way humans use language in those situations. We propose a psychologically-inspired natural language processing system for robots which performs incremental semantic interpretation of spoken utterances, integrating tightly with the robot's perceptual and motor systems.",
            "referenceCount": 44,
            "citationCount": 107,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2007-03-10",
            "journal": {
                "name": "2007 2nd ACM/IEEE International Conference on Human-Robot Interaction (HRI)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Brick2007IncrementalNL,\n author = {Timothy Brick and Matthias Scheutz},\n booktitle = {IEEE/ACM International Conference on Human-Robot Interaction},\n journal = {2007 2nd ACM/IEEE International Conference on Human-Robot Interaction (HRI)},\n pages = {263-270},\n title = {Incremental natural language processing for HRI},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f61d7f85d95f222229ccae7bd9a13f97c50d172a",
            "@type": "ScholarlyArticle",
            "paperId": "f61d7f85d95f222229ccae7bd9a13f97c50d172a",
            "corpusId": 14169778,
            "url": "https://www.semanticscholar.org/paper/f61d7f85d95f222229ccae7bd9a13f97c50d172a",
            "title": "On Natural Language Processing and Plan Recognition",
            "venue": "International Joint Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:67f7f831-711a-43c8-8785-1e09005359b5",
                "name": "International Joint Conference on Artificial Intelligence",
                "alternate_names": [
                    "Int Jt Conf Artif Intell",
                    "IJCAI"
                ],
                "issn": null,
                "url": "http://www.ijcai.org/"
            },
            "year": 2007,
            "externalIds": {
                "MAG": "2882640",
                "DBLP": "conf/ijcai/GeibS07",
                "CorpusId": 14169778
            },
            "abstract": "The research areas of plan recognition and natural language parsing share many common features and even algorithms. However, the dialog between these two disciplines has not been effective. Specifically, significant recent results in parsing mildly context sensitive grammars have not been leveraged in the state of the art plan recognition systems. This paper will outline the relations between natural language processing(NLP) and plan recognition(PR), argue that each of them can effectively inform the other, and then focus on key recent research results in NLP and argue for their applicability to PR.",
            "referenceCount": 32,
            "citationCount": 74,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2007-01-06",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Geib2007OnNL,\n author = {C. Geib and Mark Steedman},\n booktitle = {International Joint Conference on Artificial Intelligence},\n pages = {1612-1617},\n title = {On Natural Language Processing and Plan Recognition},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7990e819c87bbdffd1bb96b69b263bc2def5993e",
            "@type": "ScholarlyArticle",
            "paperId": "7990e819c87bbdffd1bb96b69b263bc2def5993e",
            "corpusId": 9936918,
            "url": "https://www.semanticscholar.org/paper/7990e819c87bbdffd1bb96b69b263bc2def5993e",
            "title": "Natural language processing for information retrieval: the time is ripe (again)",
            "venue": "Ph.D. Workshop on Information and Knowledge Management",
            "publicationVenue": {
                "id": "urn:research:d114235e-cb74-412a-9551-2d2c67ab6e29",
                "name": "Ph.D. Workshop on Information and Knowledge Management",
                "alternate_names": [
                    "PIKM",
                    "Ph.d Workshop Inf Knowl Manag"
                ],
                "issn": null,
                "url": null
            },
            "year": 2007,
            "externalIds": {
                "DBLP": "conf/cikm/Lease07",
                "MAG": "2103905129",
                "DOI": "10.1145/1316874.1316876",
                "CorpusId": 9936918
            },
            "abstract": "Paraphrasing van Rijsbergen [37], the time is ripe for another attempt at using natural language processing (NLP) for information retrieval (IR). This paper introduces my dissertation study, which will explore methods for integrating modern NLP with state-of-the-art IR techniques. In addition to text, I will also apply retrieval to conversational speech data, which poses a unique set of considerations in comparison to text. Greater use of NLP has potential to improve both text and speech retrieval.",
            "referenceCount": 37,
            "citationCount": 177,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2007-11-09",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Brants2007NaturalLP,\n author = {T. Brants},\n booktitle = {Ph.D. Workshop on Information and Knowledge Management},\n pages = {1-8},\n title = {Natural language processing for information retrieval: the time is ripe (again)},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d1fadcb994e67399b10d9721c2cb86fae8a0f15f",
            "@type": "ScholarlyArticle",
            "paperId": "d1fadcb994e67399b10d9721c2cb86fae8a0f15f",
            "corpusId": 8080967,
            "url": "https://www.semanticscholar.org/paper/d1fadcb994e67399b10d9721c2cb86fae8a0f15f",
            "title": "Natural Language Processing and Text Mining",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2006,
            "externalIds": {
                "MAG": "9328536",
                "DOI": "10.1007/978-1-84628-754-1",
                "CorpusId": 8080967
            },
            "abstract": null,
            "referenceCount": 76,
            "citationCount": 307,
            "influentialCitationCount": 8,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2006-11-14",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Kao2006NaturalLP,\n author = {Anne Kao and Steve Poteet},\n title = {Natural Language Processing and Text Mining},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f093f146aba7ec70564e10a32d28513c09a1e049",
            "@type": "ScholarlyArticle",
            "paperId": "f093f146aba7ec70564e10a32d28513c09a1e049",
            "corpusId": 9157090,
            "url": "https://www.semanticscholar.org/paper/f093f146aba7ec70564e10a32d28513c09a1e049",
            "title": "Optical character recognition errors and their effects on natural language processing",
            "venue": "Workshop on Analytics for Noisy Unstructured Text Data",
            "publicationVenue": {
                "id": "urn:research:3b528130-09f6-45a0-8560-3e97da7e6e55",
                "name": "Workshop on Analytics for Noisy Unstructured Text Data",
                "alternate_names": [
                    "AND",
                    "Workshop Anal Noisy Unstructured Text Data",
                    "Anal Noisy Unstructured Text Data",
                    "Analytics for Noisy Unstructured Text Data"
                ],
                "issn": null,
                "url": "http://www.wikicfp.com/cfp/program?id=172"
            },
            "year": 2008,
            "externalIds": {
                "MAG": "2133058591",
                "DBLP": "journals/ijdar/Lopresti09",
                "DOI": "10.1007/s10032-009-0094-8",
                "CorpusId": 9157090
            },
            "abstract": null,
            "referenceCount": 25,
            "citationCount": 109,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2008-07-24",
            "journal": {
                "name": "International Journal on Document Analysis and Recognition (IJDAR)",
                "volume": "12"
            },
            "citationStyles": {
                "bibtex": "@Article{Lopresti2008OpticalCR,\n author = {D. Lopresti},\n booktitle = {Workshop on Analytics for Noisy Unstructured Text Data},\n journal = {International Journal on Document Analysis and Recognition (IJDAR)},\n pages = {141-151},\n title = {Optical character recognition errors and their effects on natural language processing},\n volume = {12},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b89e7578fc907456a899b896f0b7cd252fc17fcc",
            "@type": "ScholarlyArticle",
            "paperId": "b89e7578fc907456a899b896f0b7cd252fc17fcc",
            "corpusId": 17443949,
            "url": "https://www.semanticscholar.org/paper/b89e7578fc907456a899b896f0b7cd252fc17fcc",
            "title": "Principles of Evaluation in Natural Language Processing",
            "venue": "ICON",
            "publicationVenue": {
                "id": "urn:research:8a6e871b-6c73-419c-98a8-27e437270a12",
                "name": "ICON",
                "alternate_names": [
                    "ICNLP",
                    "Int conf nat lang process",
                    "International conference natural language processing",
                    "Int Conf Nat Lang Process",
                    "TAL",
                    "IEEE International Conference on Networks",
                    "IEEE Int Conf Netw",
                    "International Conference on Natural Language Processing"
                ],
                "issn": "1361-8113",
                "url": "http://www.icohtec.org/publications-icon.html"
            },
            "year": 2007,
            "externalIds": {
                "ACL": "2007.tal-1.1",
                "MAG": "1664649366",
                "CorpusId": 17443949
            },
            "abstract": "In this special issue of TAL, we look at the fundamental principles underlying evaluation in natural language processing. We adopt a global point of view that goes beyond the horizon of a single evaluation campaign or a particular protocol. After a brief review of history and terminology, we will address the topic of a gold standard for natural language processing, of annotation quality, of the amount of data, of the difference between technology evaluation and usage evaluation, of dialog systems, and of standards, before concluding with a short discussion of the articles in this special issue and some prospective remarks",
            "referenceCount": 83,
            "citationCount": 32,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Art"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Art",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2007-05-15",
            "journal": {
                "name": "",
                "volume": "48"
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Paroubek2007PrinciplesOE,\n author = {P. Paroubek and St\u00e9phane Chaudiron and L. Hirschman},\n booktitle = {ICON},\n pages = {7-31},\n title = {Principles of Evaluation in Natural Language Processing},\n volume = {48},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9a4182e790e4536221bbd6932e11557b83a94d34",
            "@type": "ScholarlyArticle",
            "paperId": "9a4182e790e4536221bbd6932e11557b83a94d34",
            "corpusId": 12827495,
            "url": "https://www.semanticscholar.org/paper/9a4182e790e4536221bbd6932e11557b83a94d34",
            "title": "A Large Subcategorization Lexicon for Natural Language Processing Applications",
            "venue": "International Conference on Language Resources and Evaluation",
            "publicationVenue": {
                "id": "urn:research:7474c4a0-75d9-4105-9809-8e7d5201c5e1",
                "name": "International Conference on Language Resources and Evaluation",
                "alternate_names": [
                    "LREC",
                    "Int Conf Lang Resour Evaluation"
                ],
                "issn": null,
                "url": "http://www.lrec-conf.org/"
            },
            "year": 2006,
            "externalIds": {
                "ACL": "L06-1337",
                "DBLP": "conf/lrec/KorhonenKB06",
                "MAG": "2759962768",
                "CorpusId": 12827495
            },
            "abstract": "We introduce a large computational subcategorization lexicon which includes subcategorization frame (SCF) and frequency information for 6,397 English verbs. This extensive lexicon was acquired automatically from five corpora and the Web using the current version of the comprehensive subcategorization acquisition system of Briscoe and Carroll (1997). The lexicon is provided freely for research use, along with a script which can be used to filter and build sub-lexicons suited for different natural language processing (NLP) purposes. Documentation is also provided which explains each sub-lexicon option and evaluates its accuracy.",
            "referenceCount": 33,
            "citationCount": 114,
            "influentialCitationCount": 15,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Korhonen2006ALS,\n author = {A. Korhonen and Yuval Krymolowski and Ted Briscoe},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {1015-1020},\n title = {A Large Subcategorization Lexicon for Natural Language Processing Applications},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e1d77997b84c56a4d1865f4386a04c820fd1491a",
            "@type": "ScholarlyArticle",
            "paperId": "e1d77997b84c56a4d1865f4386a04c820fd1491a",
            "corpusId": 6067840,
            "url": "https://www.semanticscholar.org/paper/e1d77997b84c56a4d1865f4386a04c820fd1491a",
            "title": "Practical structured learning techniques for natural language processing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2006,
            "externalIds": {
                "MAG": "2112648537",
                "CorpusId": 6067840
            },
            "abstract": "Natural language processing is replete with problems whose outputs are highly complex and structured. The current state-of-the-art in machine learning is not yet sufficiently general to be applied to general problems in NLP. In this thesis, I present Searn (for \u201csearch-learn\u201d), an approach to learning for structured outputs that is applicable to the wide variety of problems encountered in natural language (and, hopefully, to problems in other domains, such as vision and biology). To demonstrate Searn\u2019s general applicability, I present applications in such diverse areas as automatic document summarization and entity detection and tracking. In these applications, Searn is empirically shown to achieve state-of-the-art performance. \nSearn is based on an integration of learning and search. This contrasts with standard approaches that define a model, learn parameters for that model, and then use the model and the learned parameters to produce new outputs. In most NLP problems, the \u201cproduce new outputs\u201d step includes an intractable computation. One must therefore employ a heuristic search function for the production step. Instead of shying away from search, Searn attacks it head on and considers structured prediction to be defined by a search problem. The corresponding learning problem is then made natural: learn parameters so that search succeeds. \nThe two application domains I study most closely in this thesis are entity detection and tracking (EDT) and automatic document summarization. EDT is the problem of finding all references to people, places and organizations in a document and identifying their relationships. Summarization is the task of producing a short summary for either a single document or for a collection of documents. These problems exhibit complex structure that cannot be captured and exploited using previously proposed structured prediction algorithms. By applying Searn to these problems, I am able to learn models that benefit from complex, non-local features of both the input and the output. Such features would not be available to structured prediction algorithm that require model tractability. These improvements lead to state-of-the-art performance on standardized data sets with low computational overhead. \nSearn operates by transforming structured prediction problems into a collection of classification problems, to which any standard binary classifier may be applied (for instance, a support vector machine or decision tree). In fact, Searn represents a family of structured prediction algorithms depending on the classifier and search space used. From a theoretical perspective, Searn satisfies a strong fundamental performance guarantee: given a good classification algorithm, Searn yields a good structured prediction algorithm. Such theoretical results are possible for other structured prediction only when the underlying model is tractable. For Searn, I am able to state strong results that are independent of the size or tractability of the search space. This provides theoretical justification for integrating search with learning.",
            "referenceCount": 215,
            "citationCount": 114,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Marcu2006PracticalSL,\n author = {D. Marcu and Hal Daum\u00e9},\n title = {Practical structured learning techniques for natural language processing},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b1a6ec04c658e0069def94f04c3f2454b9a0f2f9",
            "@type": "ScholarlyArticle",
            "paperId": "b1a6ec04c658e0069def94f04c3f2454b9a0f2f9",
            "corpusId": 14790149,
            "url": "https://www.semanticscholar.org/paper/b1a6ec04c658e0069def94f04c3f2454b9a0f2f9",
            "title": "NLP (Natural Language Processing) for NLP (Natural Language Programming)",
            "venue": "Conference on Intelligent Text Processing and Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:a1c1b2d2-5629-4b8f-b764-20ea10fa588c",
                "name": "Conference on Intelligent Text Processing and Computational Linguistics",
                "alternate_names": [
                    "Conf Intell Text Process Comput Linguistics",
                    "CICLing"
                ],
                "issn": null,
                "url": "http://www.cicling.org/"
            },
            "year": 2006,
            "externalIds": {
                "MAG": "2755107783",
                "DBLP": "conf/cicling/MihalceaLL06",
                "DOI": "10.1007/11671299_34",
                "CorpusId": 14790149
            },
            "abstract": null,
            "referenceCount": 10,
            "citationCount": 84,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://digital.library.unt.edu/ark:/67531/metadc30984/m2/1/high_res_d/Mihalcea-2006-NLP_Natural_Language_Processing.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2006-02-19",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Mihalcea2006NLPL,\n author = {Rada Mihalcea and Hugo Liu and H. Lieberman},\n booktitle = {Conference on Intelligent Text Processing and Computational Linguistics},\n pages = {319-330},\n title = {NLP (Natural Language Processing) for NLP (Natural Language Programming)},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9c6e1979d02831910c9276eb7e1bdb1e76e3bc15",
            "@type": "ScholarlyArticle",
            "paperId": "9c6e1979d02831910c9276eb7e1bdb1e76e3bc15",
            "corpusId": 6343375,
            "url": "https://www.semanticscholar.org/paper/9c6e1979d02831910c9276eb7e1bdb1e76e3bc15",
            "title": "Integrating Natural Language Processing with Flybase Curation",
            "venue": "Pacific Symposium on Biocomputing",
            "publicationVenue": {
                "id": "urn:research:bf8c915b-282b-4817-987d-62e47e42d5e1",
                "name": "Pacific Symposium on Biocomputing",
                "alternate_names": [
                    "PSB",
                    "Pac Symp Biocomput"
                ],
                "issn": null,
                "url": "http://psb.stanford.edu/"
            },
            "year": 2006,
            "externalIds": {
                "MAG": "2009433284",
                "DBLP": "conf/psb/KaramanisLSDB07",
                "DOI": "10.1142/9789812772435_0024",
                "CorpusId": 6343375,
                "PubMed": "17990496"
            },
            "abstract": "Applying Natural Language Processing techniques to biomedical text as a potential aid to curation has become the focus of intensive research. However, developing integrated systems which address the curators' real-world needs has been studied less rigorously. This paper addresses this question and presents generic tools developed to assist FlyBase curators. We discuss how they have been integrated into the curation workflow and present initial evidence about their effectiveness.",
            "referenceCount": 17,
            "citationCount": 53,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2006-12-01",
            "journal": {
                "name": "Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Karamanis2006IntegratingNL,\n author = {Nikiforos Karamanis and Ian Lewin and Ruth L. Seal and R. Drysdale and Ted Briscoe},\n booktitle = {Pacific Symposium on Biocomputing},\n journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},\n pages = {\n          245-56\n        },\n title = {Integrating Natural Language Processing with Flybase Curation},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c70f7b2f88709755fa9c84443979cca6ea08a15b",
            "@type": "ScholarlyArticle",
            "paperId": "c70f7b2f88709755fa9c84443979cca6ea08a15b",
            "corpusId": 107818182,
            "url": "https://www.semanticscholar.org/paper/c70f7b2f88709755fa9c84443979cca6ea08a15b",
            "title": "State of the Art of Natural Language Processing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1987,
            "externalIds": {
                "MAG": "226086854",
                "DOI": "10.21236/ada188112",
                "CorpusId": 107818182
            },
            "abstract": "Abstract : A study was carried out to determine the state of the art of the natural language processing requirements of a battle management system. The study was based on a method developed by this contractor. Study results indicate the field is in an early stage of development and further progress will be required to achieve the tools for a natural language interface to a battle management system. Keywords: Artificial intelligence; Information processing.",
            "referenceCount": 0,
            "citationCount": 93,
            "influentialCitationCount": 5,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.dtic.mil/dtic/tr/fulltext/u2/a188112.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1987-11-15",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Anderson1987StateOT,\n author = {T. Anderson},\n title = {State of the Art of Natural Language Processing},\n year = {1987}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:998dbb7344086edaf050ec9dcfc886d359f18458",
            "@type": "ScholarlyArticle",
            "paperId": "998dbb7344086edaf050ec9dcfc886d359f18458",
            "corpusId": 17793739,
            "url": "https://www.semanticscholar.org/paper/998dbb7344086edaf050ec9dcfc886d359f18458",
            "title": "Large Lexicons for Natural Language Processing: Utilising the Grammar Coding System of LDOCE",
            "venue": "Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:ee37a78c-f3d8-407a-bd24-bb97fe6dbab9",
                "name": "Computational Linguistics",
                "alternate_names": [
                    "Comput Linguistics"
                ],
                "issn": "0891-2017",
                "url": "http://aclanthology.info/venues/cl"
            },
            "year": 1987,
            "externalIds": {
                "DBLP": "journals/coling/Boguraev87",
                "ACL": "J87-3002",
                "MAG": "1516154677",
                "CorpusId": 17793739
            },
            "abstract": "This article focusses on the derivation of large lexicons for natural language processing. We describe the development of a dictionary support environment linking a restructured version of the Longman Dictionary of Contemporary English to natural language processing systems. The process of restructuring the information in the machine readable version of the dictionary is discussed. The Longman grammar code system is used to construct 'theory neutral' lexical entries. We demonstrate how such lexical entries can be put to practical use by linking up the system described here with the experimental PATR-II grammar development environment. Finally, we offer an evaluation of the utility of the grammar coding system for use by automatic natural language parsing systems.",
            "referenceCount": 48,
            "citationCount": 86,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1987-07-01",
            "journal": {
                "name": "Comput. Linguistics",
                "volume": "13"
            },
            "citationStyles": {
                "bibtex": "@Article{Boguraev1987LargeLF,\n author = {B. Boguraev},\n booktitle = {Computational Linguistics},\n journal = {Comput. Linguistics},\n pages = {203-218},\n title = {Large Lexicons for Natural Language Processing: Utilising the Grammar Coding System of LDOCE},\n volume = {13},\n year = {1987}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7135d4a1615638b723ce085b58c2e4709056f1aa",
            "@type": "ScholarlyArticle",
            "paperId": "7135d4a1615638b723ce085b58c2e4709056f1aa",
            "corpusId": 5436772,
            "url": "https://www.semanticscholar.org/paper/7135d4a1615638b723ce085b58c2e4709056f1aa",
            "title": "Human Engineering for Applied Natural Language Processing",
            "venue": "International Joint Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:67f7f831-711a-43c8-8785-1e09005359b5",
                "name": "International Joint Conference on Artificial Intelligence",
                "alternate_names": [
                    "Int Jt Conf Artif Intell",
                    "IJCAI"
                ],
                "issn": null,
                "url": "http://www.ijcai.org/"
            },
            "year": 1977,
            "externalIds": {
                "MAG": "177919227",
                "DBLP": "conf/ijcai/Hendrix77",
                "CorpusId": 5436772
            },
            "abstract": "Human engineering features for enhancing the usabil ity of practical natural language systems a l re described. Such features include spelling correction, processing of incomplete (ell ipt ic-~I) input?, jntfrrog-t ior of th p underlying language definition through English oueries, and ?r rbil.it y for casual users to extrnd the language accepted by the system through the-use of synonyms ana peraphrases. All of 1 h* features described are incorporated in LJFER,-\"n r ppl ieat ions-orj e nlf d system for 1 creating natural language j nterfaees between computer programs and casual USERS LJFER's methods for r<\"v] izir? the mroe complex human enginering features ? re presented. 1 INTRODUCTION This pape r depcribes aspect r of a n applieations-oriented system for creating natural langruage interfaces between computer software and Casual users. Like the underlying researen itself, the paper is focused on the human engineering involved in designing practical rnd comfortable interfaces. This focus has lead to the investigation of some generally neglected facets of language processing, including the processing of Ireomplfte inputs, the ability to resume parsing after recovering from spelling errors and the ability for naive users to input English stat.emert s at run time that, extend and person-lize the language accepted by the system. The implementation of these features in a convenient package and their integration with other human engineering features are discussed. There has been mounting evidence that the current state of the art in natural language processing, although still relatively primitive, is sufficient for dealing with some very real problems. For example, Brown and Burton (1975) have developed a usable system for computer assisted instruction, and a number of language systems have been developed for interfacing to data bases, including the REL system developed by Thompson and Thompson (1975), the LUNAR system of Woods et al. (1972), and the PLANES system ol Walt7 (1975). The SIGART newsletter for February, 1977, contains a collection cf 5? short overviews of research efforts in the general area of natural language interfaces. Tnere has rise been a growing demand for application systems. At SRi's Artificial Irtellugene Center alone, many programs are ripe for the addition of language capabilities, Including systems for data base accessing, industrial automation, automatic programming, deduct ior, and judgmental reasoning. The appeal cf these systems to builders ana users .-'like is greatly enhanced when they are able to accept natural language inputs. B. The LIFER SYSTEM To add \u2026",
            "referenceCount": 15,
            "citationCount": 67,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hendrix1977HumanEF,\n author = {G. Hendrix},\n booktitle = {International Joint Conference on Artificial Intelligence},\n pages = {183-191},\n title = {Human Engineering for Applied Natural Language Processing},\n year = {1977}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f7dd148541ea070b028dda68b8b8fe5321717790",
            "@type": "ScholarlyArticle",
            "paperId": "f7dd148541ea070b028dda68b8b8fe5321717790",
            "corpusId": 59814145,
            "url": "https://www.semanticscholar.org/paper/f7dd148541ea070b028dda68b8b8fe5321717790",
            "title": "Human engineering fcr applied natural language processing",
            "venue": "International Joint Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:67f7f831-711a-43c8-8785-1e09005359b5",
                "name": "International Joint Conference on Artificial Intelligence",
                "alternate_names": [
                    "Int Jt Conf Artif Intell",
                    "IJCAI"
                ],
                "issn": null,
                "url": "http://www.ijcai.org/"
            },
            "year": 1977,
            "externalIds": {
                "MAG": "53998823",
                "CorpusId": 59814145
            },
            "abstract": "Human engineering features for enhancing the usability of practical natural language systems are described. Such features include spelling correction, processing of incomplete (elliptical) input?, of the underlying language definition through English queries, and their ability for casual users to extend the language accepted by the system through the use of synonyms and peraphrases. All of the features described are incorporated in LJFER, -\"applications-oriented system for creating natural language interfaces between computer programs and casual USERS LJFER's methods for the mroe complex human engineering features presented.",
            "referenceCount": 8,
            "citationCount": 82,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1977-08-22",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Herdrix1977HumanEF,\n author = {Gary G. Herdrix},\n booktitle = {International Joint Conference on Artificial Intelligence},\n pages = {183-191},\n title = {Human engineering fcr applied natural language processing},\n year = {1977}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a42397893746da6488f70bfc0d48e66763860f0f",
            "@type": "ScholarlyArticle",
            "paperId": "a42397893746da6488f70bfc0d48e66763860f0f",
            "corpusId": 63812413,
            "url": "https://www.semanticscholar.org/paper/a42397893746da6488f70bfc0d48e66763860f0f",
            "title": "On memory limitations in natural language processing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1982,
            "externalIds": {
                "MAG": "2438775341",
                "CorpusId": 63812413
            },
            "abstract": "This paper proposes a welcome hypothesis: a computationally simple device is sufficient for processing natural language. Traditionally it has been argued that processing natural language syntax requires very powerful machinery. Many engineers have come to this rather grim conclusion; almost all working parsers are actually Turing Machines (TM). For example, Woods specifically designed his Augmented Transition Networks (ATN''s) to be Turing Equivalent. If the problem is really as hard as it appears, then the only solution is to grin and bear it. Our own position is that parsing acceptable sentences is simpler because there are constraints on human performance that drastically reduce the computational requirements (time and space bounds). Although ideal linguistic competence is very complex, this observation may not apply directly to a real processing problem such as parsing. By including performance factors, it is possible to simplify the computation. We will propose two performance limitations, bounded memory and deterministic control, which have been incorporated in a new parser YAP.",
            "referenceCount": 0,
            "citationCount": 41,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Church1982OnML,\n author = {Kenneth Ward Church},\n title = {On memory limitations in natural language processing},\n year = {1982}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:30bafa2d2f9dbe9e89c0efae1e4571809d383328",
            "@type": "ScholarlyArticle",
            "paperId": "30bafa2d2f9dbe9e89c0efae1e4571809d383328",
            "corpusId": 18939887,
            "url": "https://www.semanticscholar.org/paper/30bafa2d2f9dbe9e89c0efae1e4571809d383328",
            "title": "The interaction of domain knowledge and linguistic structure in natural language processing: interpreting hypernymic propositions in biomedical text",
            "venue": "Journal of Biomedical Informatics",
            "publicationVenue": {
                "id": "urn:research:f9827422-a381-440c-a8a4-e5e50415934e",
                "name": "Journal of Biomedical Informatics",
                "alternate_names": [
                    "J Biomed Informatics"
                ],
                "issn": "1532-0464",
                "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/622857/description#description"
            },
            "year": 2003,
            "externalIds": {
                "MAG": "2098201295",
                "DBLP": "journals/jbi/RindfleschF03",
                "DOI": "10.1016/J.JBI.2003.11.003",
                "CorpusId": 18939887,
                "PubMed": "14759819"
            },
            "abstract": null,
            "referenceCount": 71,
            "citationCount": 543,
            "influentialCitationCount": 54,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Study"
            ],
            "publicationDate": "2003-12-01",
            "journal": {
                "name": "Journal of biomedical informatics",
                "volume": "36 6"
            },
            "citationStyles": {
                "bibtex": "@Article{Rindflesch2003TheIO,\n author = {T. Rindflesch and M. Fiszman},\n booktitle = {Journal of Biomedical Informatics},\n journal = {Journal of biomedical informatics},\n pages = {\n          462-77\n        },\n title = {The interaction of domain knowledge and linguistic structure in natural language processing: interpreting hypernymic propositions in biomedical text},\n volume = {36 6},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c6474406664a1fadc2964ea453eca07cabbd9d67",
            "@type": "ScholarlyArticle",
            "paperId": "c6474406664a1fadc2964ea453eca07cabbd9d67",
            "corpusId": 17940440,
            "url": "https://www.semanticscholar.org/paper/c6474406664a1fadc2964ea453eca07cabbd9d67",
            "title": "Arabic natural language processing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2008,
            "externalIds": {
                "MAG": "34098155",
                "CorpusId": 17940440
            },
            "abstract": "A surface detection system for airport facilities is described wherein a plurality of infrared (IR) scanners as well as presence/absence detectors are located with respect to taxiways and runways of an airport complex. These devices are arranged to perform in conjunction with local processors to generate data from aircraft and ground based vehicles available from a bar coding identification of both forms of vehicles. These data are utilized to compute alert conditions as well as to develop a real time map of the airport which may be provided at a tower installation for air traffic control utilization as well as at an aircraft flight deck during the course of ground maneuvering. Through the Utilization of aircraft tail numbers as an index, a master host memory may be developed which includes flight numbers, aircraft characteristics and the like which may be employed for evolving alert conditions and the like.",
            "referenceCount": 16,
            "citationCount": 47,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Belaid2008ArabicNL,\n author = {A. Belaid},\n title = {Arabic natural language processing},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:77a582fc45b1b8e6e6430202ff806720f438d5c9",
            "@type": "ScholarlyArticle",
            "paperId": "77a582fc45b1b8e6e6430202ff806720f438d5c9",
            "corpusId": 207157738,
            "url": "https://www.semanticscholar.org/paper/77a582fc45b1b8e6e6430202ff806720f438d5c9",
            "title": "Using text mining and natural language processing for health care claims processing",
            "venue": "SKDD",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "DBLP": "journals/sigkdd/Popowich05",
                "MAG": "2036543108",
                "DOI": "10.1145/1089815.1089824",
                "CorpusId": 207157738
            },
            "abstract": "A health care claims processing application is introduced which processes both structured and unstructured information associated with medical insurance claims. The application makes use of a natural language processing (NLP) engine, together with application-specific knowledge, written in a concept specification language. Using NLP techniques, the entities and relationships that act as indicators of recoverable claims are mined from management notes, call centre logs and patient records to identify medical claims that require further investigation. Text mining techniques can then be applied to find dependencies between different entities, and to combine indicators to provide scores to individual claims. Claims are scored to determine whether they involve potential fraud or abuse, or to determine whether claims should be paid by or in conjunction with other insurers or organizations. Dependencies between claims and other records can then be combined to create cases. Issues related to the design of the application are discussed, specifically the use of rule-based techniques which provide a capability for deeper analysis than traditionally found in statistical techniques.",
            "referenceCount": 17,
            "citationCount": 68,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2005-06-01",
            "journal": {
                "name": "SIGKDD Explor.",
                "volume": "7"
            },
            "citationStyles": {
                "bibtex": "@Article{Popowich2005UsingTM,\n author = {F. Popowich},\n booktitle = {SKDD},\n journal = {SIGKDD Explor.},\n pages = {59-66},\n title = {Using text mining and natural language processing for health care claims processing},\n volume = {7},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7b2db05be1c33636007c655b1fe7e3a2bd028e71",
            "@type": "ScholarlyArticle",
            "paperId": "7b2db05be1c33636007c655b1fe7e3a2bd028e71",
            "corpusId": 7893158,
            "url": "https://www.semanticscholar.org/paper/7b2db05be1c33636007c655b1fe7e3a2bd028e71",
            "title": "An Overview of Probabilistic Tree Transducers for Natural Language Processing",
            "venue": "Conference on Intelligent Text Processing and Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:a1c1b2d2-5629-4b8f-b764-20ea10fa588c",
                "name": "Conference on Intelligent Text Processing and Computational Linguistics",
                "alternate_names": [
                    "Conf Intell Text Process Comput Linguistics",
                    "CICLing"
                ],
                "issn": null,
                "url": "http://www.cicling.org/"
            },
            "year": 2005,
            "externalIds": {
                "MAG": "1493576607",
                "DBLP": "conf/cicling/KnightG05",
                "DOI": "10.1007/978-3-540-30586-6_1",
                "CorpusId": 7893158
            },
            "abstract": null,
            "referenceCount": 65,
            "citationCount": 156,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.isi.edu/natural-language/people/p5.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": "2005-02-13",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Knight2005AnOO,\n author = {Kevin Knight and Jonathan Graehl},\n booktitle = {Conference on Intelligent Text Processing and Computational Linguistics},\n pages = {1-24},\n title = {An Overview of Probabilistic Tree Transducers for Natural Language Processing},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ca409f9e368b1896aaa82e76e6446774ac001042",
            "@type": "ScholarlyArticle",
            "paperId": "ca409f9e368b1896aaa82e76e6446774ac001042",
            "corpusId": 2202507,
            "url": "https://www.semanticscholar.org/paper/ca409f9e368b1896aaa82e76e6446774ac001042",
            "title": "Extracting Information on Pneumonia in Infants Using Natural Language Processing of Radiology Reports",
            "venue": "Journal of Biomedical Informatics",
            "publicationVenue": {
                "id": "urn:research:f9827422-a381-440c-a8a4-e5e50415934e",
                "name": "Journal of Biomedical Informatics",
                "alternate_names": [
                    "J Biomed Informatics"
                ],
                "issn": "1532-0464",
                "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/622857/description#description"
            },
            "year": 2005,
            "externalIds": {
                "MAG": "2012688710",
                "DBLP": "journals/jbi/MendoncaHSLF05",
                "ACL": "W03-1311",
                "DOI": "10.3115/1118958.1118969",
                "CorpusId": 2202507,
                "PubMed": "16084473"
            },
            "abstract": "Natural language processing (NLP) is critical for improvement of the healthcare process because it can encode clinical data in patient documents. Many clinical applications such as decision support require coded data to function appropriately. However, in order to be applicable for healthcare, performance must be adequate. A valuable automated application is the detection of infectious diseases, such as surveillance of pneumonia in newborns (e.g., neonates) because the disease produces significant rates of morbidity and mortality, and manual surveillance is challenging. Studies have demonstrated that automated surveillance using NLP is a useful adjunct to manual surveillance and an effective tool for infection control practitioners. This paper presents a study evaluating the feasibility of an NLP-based monitoring system to screen for healthcare-associated pneumonia in neonates. We estimated sensitivity, specificity, and positive predictive value by comparing results with clinicians' judgments. Sensitivity was 71% and specificity was 99%. Our results demonstrated that the automated method was feasible.",
            "referenceCount": 38,
            "citationCount": 115,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "ClinicalTrial"
            ],
            "publicationDate": "2005-08-01",
            "journal": {
                "name": "Journal of biomedical informatics",
                "volume": "38 4"
            },
            "citationStyles": {
                "bibtex": "@Article{Mendon\u00e7a2005ExtractingIO,\n author = {Eneida A. Mendon\u00e7a and J. Haas and L. Shagina and E. Larson and C. Friedman},\n booktitle = {Journal of Biomedical Informatics},\n journal = {Journal of biomedical informatics},\n pages = {\n          314-21\n        },\n title = {Extracting Information on Pneumonia in Infants Using Natural Language Processing of Radiology Reports},\n volume = {38 4},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c147f5eaf647dfd22a011784f16c37d9002b1af9",
            "@type": "ScholarlyArticle",
            "paperId": "c147f5eaf647dfd22a011784f16c37d9002b1af9",
            "corpusId": 14698774,
            "url": "https://www.semanticscholar.org/paper/c147f5eaf647dfd22a011784f16c37d9002b1af9",
            "title": "PhenoGO: Assigning Phenotypic Context to Gene Ontology Annotations with Natural Language Processing",
            "venue": "Pacific Symposium on Biocomputing",
            "publicationVenue": {
                "id": "urn:research:bf8c915b-282b-4817-987d-62e47e42d5e1",
                "name": "Pacific Symposium on Biocomputing",
                "alternate_names": [
                    "PSB",
                    "Pac Symp Biocomput"
                ],
                "issn": null,
                "url": "http://psb.stanford.edu/"
            },
            "year": 2005,
            "externalIds": {
                "DBLP": "conf/psb/LussierBRLF06",
                "MAG": "2080007652",
                "DOI": "10.1142/9789812701626_0007",
                "CorpusId": 14698774,
                "PubMed": "17094228"
            },
            "abstract": "Natural language processing (NLP) is a high throughput technology because it can process vast quantities of text within a reasonable time period. It has the potential to substantially facilitate biomedical research by extracting, linking, and organizing massive amounts of information that occur in biomedical journal articles as well as in textual fields of biological databases. Until recently, much of the work in biological NLP and text mining has revolved around recognizing the occurrence of biomolecular entities in articles, and in extracting particular relationships among the entities. Now, researchers have recognized a need to link the extracted information to ontologies or knowledge bases, which is a more difficult task. One such knowledge base is Gene Ontology annotations (GOA), which significantly increases semantic computations over the function, cellular components and processes of genes. For multicellular organisms, these annotations can be refined with phenotypic context, such as the cell type, tissue, and organ because establishing phenotypic contexts in which a gene is expressed is a crucial step for understanding the development and the molecular underpinning of the pathophysiology of diseases. In this paper, we propose a system, PhenoGO, which automatically augments annotations in GOA with additional context. PhenoGO utilizes an existing NLP system, called BioMedLEE, an existing knowledge-based phenotype organizer system (PhenOS) in conjunction with MeSH indexing and established biomedical ontologies. More specifically, PhenoGO adds phenotypic contextual information to existing associations between gene products and GO terms as specified in GOA. The system also maps the context to identifiers that are associated with different biomedical ontologies, including the UMLS, Cell Ontology, Mouse Anatomy, NCBI taxonomy, GO, and Mammalian Phenotype Ontology. In addition, PhenoGO was evaluated for coding of anatomical and cellular information and assigning the coded phenotypes to the correct GOA; results obtained show that PhenoGO has a precision of 91% and recall of 92%, demonstrating that the PhenoGO NLP system can accurately encode a large number of anatomical and cellular ontologies to GO annotations. The PhenoGO Database may be accessed at the following URL: http://www.phenoGO.org",
            "referenceCount": 0,
            "citationCount": 92,
            "influentialCitationCount": 1,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://europepmc.org/articles/pmc2906243?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Study"
            ],
            "publicationDate": "2005-12-01",
            "journal": {
                "name": "Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Lussier2005PhenoGOAP,\n author = {Y. Lussier and T. Borlawsky and Daniel Rappaport and Yang Liu and C. Friedman},\n booktitle = {Pacific Symposium on Biocomputing},\n journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},\n pages = {\n          64-75\n        },\n title = {PhenoGO: Assigning Phenotypic Context to Gene Ontology Annotations with Natural Language Processing},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1bdc66bf35f7443cea550eb82a691966761f1111",
            "@type": "ScholarlyArticle",
            "paperId": "1bdc66bf35f7443cea550eb82a691966761f1111",
            "corpusId": 765849,
            "url": "https://www.semanticscholar.org/paper/1bdc66bf35f7443cea550eb82a691966761f1111",
            "title": "Web-based models for natural language processing",
            "venue": "TSLP",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "MAG": "2000577984",
                "DBLP": "journals/tslp/LapataK05",
                "DOI": "10.1145/1075389.1075392",
                "CorpusId": 765849
            },
            "abstract": "Previous work demonstrated that Web counts can be used to approximate bigram counts, suggesting that Web-based frequencies should be useful for a wide variety of Natural Language Processing (NLP) tasks. However, only a limited number of tasks have so far been tested using Web-scale data sets. The present article overcomes this limitation by systematically investigating the performance of Web-based models for several NLP tasks, covering both syntax and semantics, both generation and analysis, and a wider range of n-grams and parts of speech than have been previously explored. For the majority of our tasks, we find that simple, unsupervised models perform better when n-gram counts are obtained from the Web rather than from a large corpus. In some cases, performance can be improved further by using backoff or interpolation techniques that combine Web counts and corpus counts. However, unsupervised Web-based models generally fail to outperform supervised state-of-the-art models trained on smaller corpora. We argue that Web-based models should therefore be used as a baseline for, rather than an alternative to, standard supervised models.",
            "referenceCount": 59,
            "citationCount": 201,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2005-02-01",
            "journal": {
                "name": "ACM Trans. Speech Lang. Process.",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Lapata2005WebbasedMF,\n author = {Mirella Lapata and Frank Keller},\n booktitle = {TSLP},\n journal = {ACM Trans. Speech Lang. Process.},\n pages = {1-31},\n title = {Web-based models for natural language processing},\n volume = {2},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0bd43e269cf4fe30ea929da2628318ca7bc1e4d3",
            "@type": "ScholarlyArticle",
            "paperId": "0bd43e269cf4fe30ea929da2628318ca7bc1e4d3",
            "corpusId": 16204005,
            "url": "https://www.semanticscholar.org/paper/0bd43e269cf4fe30ea929da2628318ca7bc1e4d3",
            "title": "Natural language processing of lyrics",
            "venue": "ACM Multimedia",
            "publicationVenue": {
                "id": "urn:research:f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                "name": "ACM Multimedia",
                "alternate_names": [
                    "MM"
                ],
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "MAG": "2059363583",
                "DBLP": "conf/mm/MahederoMCKG05",
                "DOI": "10.1145/1101149.1101255",
                "CorpusId": 16204005
            },
            "abstract": "We report experiments on the use of standard natural language processing (NLP) tools for the analysis of music lyrics. A significant amount of music audio has lyrics. Lyrics encode an important part of the semantics of a song, therefore their analysis complements that of acoustic and cultural metadata and is fundamental for the development of complete music information retrieval systems. Moreover, a textual analysis of a song can generate ground truth data that can be used to validate results from purely acoustic methods. Preliminary results on language identification, structure extraction, categorization and similarity searches suggests that a lot of profit can be gained from the analysis of lyrics.",
            "referenceCount": 12,
            "citationCount": 107,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle"
            ],
            "publicationDate": "2005-11-06",
            "journal": {
                "name": "Proceedings of the 13th annual ACM international conference on Multimedia",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Mahedero2005NaturalLP,\n author = {Jose P. G. Mahedero and A. Martinez and P. Cano and Markus Koppenberger and F. Gouyon},\n booktitle = {ACM Multimedia},\n journal = {Proceedings of the 13th annual ACM international conference on Multimedia},\n title = {Natural language processing of lyrics},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:00c7b37ad903430676bd6afb825f7ce1a8d4cecf",
            "@type": "ScholarlyArticle",
            "paperId": "00c7b37ad903430676bd6afb825f7ce1a8d4cecf",
            "corpusId": 1308868,
            "url": "https://www.semanticscholar.org/paper/00c7b37ad903430676bd6afb825f7ce1a8d4cecf",
            "title": "Dynamically Combining Syntax and Semantics in Natural Language Processing",
            "venue": "AAAI Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:bdc2e585-4e48-4e36-8af1-6d859763d405",
                "name": "AAAI Conference on Artificial Intelligence",
                "alternate_names": [
                    "National Conference on Artificial Intelligence",
                    "National Conf Artif Intell",
                    "AAAI Conf Artif Intell",
                    "AAAI"
                ],
                "issn": null,
                "url": "http://www.aaai.org/"
            },
            "year": 1986,
            "externalIds": {
                "MAG": "2184689099",
                "DBLP": "conf/aaai/Lytinen86",
                "CorpusId": 1308868
            },
            "abstract": "A controversy has existed over the interaction of syntax and semantics in natural language understanding systems. According to theories of integrated parsing, syntactic and semantic processing should take place simultaneously, with the parsing process driven by a single rule base which contains both syntactic and semantic knowledge. This is in sharp contrast to traditional linguistic approaches to language analysis, in which syntactic and semantic processing are performed separately from one another, driven by completely separate sets of syntactic and semantic rules. \n \nThis paper presents an approach to natural language understanding which is a compromise between these two views. It is an integrated approach, in the sense that syntactic and semantic processing take place at the same time. However, unlike previous integrated systems, the approach described here uses largely separate bodies of syntactic and semantic knowledge, which are combined only at the time of processing.",
            "referenceCount": 14,
            "citationCount": 51,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1986-08-11",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Lytinen1986DynamicallyCS,\n author = {S. Lytinen},\n booktitle = {AAAI Conference on Artificial Intelligence},\n pages = {574-587},\n title = {Dynamically Combining Syntax and Semantics in Natural Language Processing},\n year = {1986}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:daf2ea806f7082d5a2bd1c6fd87ae2d7686b4dfa",
            "@type": "ScholarlyArticle",
            "paperId": "daf2ea806f7082d5a2bd1c6fd87ae2d7686b4dfa",
            "corpusId": 17545683,
            "url": "https://www.semanticscholar.org/paper/daf2ea806f7082d5a2bd1c6fd87ae2d7686b4dfa",
            "title": "Maurice Gross' grammar lexicon and Natural Language Processing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "MAG": "2627656340",
                "CorpusId": 17545683
            },
            "abstract": "Maurice Gross' grammar lexicon contains an extremly rich and exhaustive information about the morphosyntactic and semantic properties of French syntactic functors (verbs, adjectives, nouns). Yet its use within natural language processing systems is still restricted. In this paper, we first argue that the information contained in the grammar lexicon is potentially useful for Natural Language Processing (NLP). We then sketch a way to translate this information into a format which is arguably more amenable for use by NLP systems.",
            "referenceCount": 20,
            "citationCount": 35,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2005-04-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Gardent2005MauriceGG,\n author = {Claire Gardent and Bruno Guillaume and Guy Perrier and Ingrid Falk},\n title = {Maurice Gross' grammar lexicon and Natural Language Processing},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d6cffe777943222869c019dd6ebd66784e64be06",
            "@type": "ScholarlyArticle",
            "paperId": "d6cffe777943222869c019dd6ebd66784e64be06",
            "corpusId": 63733836,
            "url": "https://www.semanticscholar.org/paper/d6cffe777943222869c019dd6ebd66784e64be06",
            "title": "Natural Language Processing in Computer-Assisted Language Learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "MAG": "2391138172",
                "DOI": "10.1093/OXFORDHB/9780199276349.013.0037",
                "CorpusId": 63733836
            },
            "abstract": "This chapter examines the application of natural language processing to computerassisted language learning including the history of work in this field over the last thirtyfive years but with a focus on current developments and opportunities.",
            "referenceCount": 91,
            "citationCount": 31,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2005-01-13",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Nerbonne2005NaturalLP,\n author = {J. Nerbonne},\n title = {Natural Language Processing in Computer-Assisted Language Learning},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e75220a87e08464b01c433ed6adc68138f1eb38b",
            "@type": "ScholarlyArticle",
            "paperId": "e75220a87e08464b01c433ed6adc68138f1eb38b",
            "corpusId": 34205817,
            "url": "https://www.semanticscholar.org/paper/e75220a87e08464b01c433ed6adc68138f1eb38b",
            "title": "Facilitating Cancer Research using Natural Language Processing of Pathology Reports",
            "venue": "Medinfo",
            "publicationVenue": {
                "id": "urn:research:74ac5df9-f803-4de9-91f3-ec5f69bc0c8c",
                "name": "Medinfo",
                "alternate_names": [
                    "Medinfo"
                ],
                "issn": "1314-0345",
                "url": "https://www.medinfo.bg/"
            },
            "year": 2004,
            "externalIds": {
                "MAG": "2418239156",
                "DBLP": "conf/medinfo/XuAGF04",
                "DOI": "10.3233/978-1-60750-949-3-565",
                "CorpusId": 34205817,
                "PubMed": "15360876"
            },
            "abstract": "Many ongoing clinical research projects, such as projects involving studies associated with cancer, involve manual capture of information in surgical pathology reports so that the information can be used to determine the eligibility of recruited patients for the study and to provide other information, such as cancer prognosis. Natural language processing (NLP) systems offer an alternative to automated coding, but pathology reports have certain features that are difficult for NLP systems. This paper describes how a preprocessor was integrated with an existing NLP system (MedLEE) in order to reduce modification to the NLP system and to improve performance. The work was done in conjunction with an ongoing clinical research project that assesses disparities and risks of developing breast cancer for minority women. An evaluation of the system was performed using manually coded data from the research project's database as a gold standard. The evaluation outcome showed that the extended NLP system had a sensitivity of 90.6% and a precision of 91.6%. Results indicated that this system performed satisfactorily for capturing information for the cancer research project.",
            "referenceCount": 5,
            "citationCount": 75,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Study"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Studies in health technology and informatics",
                "volume": "107 Pt 1"
            },
            "citationStyles": {
                "bibtex": "@Article{Xu2004FacilitatingCR,\n author = {Huan Xu and K. Anderson and V. Grann and C. Friedman},\n booktitle = {Medinfo},\n journal = {Studies in health technology and informatics},\n pages = {\n          565-72\n        },\n title = {Facilitating Cancer Research using Natural Language Processing of Pathology Reports},\n volume = {107 Pt 1},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b6fb385b5cc68e8f67a9d5f8cfad0e8da476e560",
            "@type": "ScholarlyArticle",
            "paperId": "b6fb385b5cc68e8f67a9d5f8cfad0e8da476e560",
            "corpusId": 15902243,
            "url": "https://www.semanticscholar.org/paper/b6fb385b5cc68e8f67a9d5f8cfad0e8da476e560",
            "title": "Natural Language Processing and Systems Biology",
            "venue": "Artificial Intelligence Methods And Tools For Systems Biology",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2004,
            "externalIds": {
                "DBLP": "series/cb/CohenH04",
                "MAG": "108101778",
                "DOI": "10.1007/978-1-4020-5811-0_9",
                "CorpusId": 15902243
            },
            "abstract": null,
            "referenceCount": 103,
            "citationCount": 101,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Cohen2004NaturalLP,\n author = {K. Cohen and L. Hunter},\n booktitle = {Artificial Intelligence Methods And Tools For Systems Biology},\n pages = {147-173},\n title = {Natural Language Processing and Systems Biology},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:642fa1495d3e146e8eca38613651a467198fa87b",
            "@type": "ScholarlyArticle",
            "paperId": "642fa1495d3e146e8eca38613651a467198fa87b",
            "corpusId": 5193658,
            "url": "https://www.semanticscholar.org/paper/642fa1495d3e146e8eca38613651a467198fa87b",
            "title": "Natural Language Processing of Patents and Technical Documentation",
            "venue": "International Workshop on Document Analysis Systems",
            "publicationVenue": {
                "id": "urn:research:02d53b80-30d7-493c-9453-ed7406056b31",
                "name": "International Workshop on Document Analysis Systems",
                "alternate_names": [
                    "DAS",
                    "Document Analysis Systems",
                    "Int Workshop Doc Anal Syst",
                    "Doc Anal Syst"
                ],
                "issn": null,
                "url": "http://www.wikicfp.com/cfp/program?id=647"
            },
            "year": 2004,
            "externalIds": {
                "DBLP": "conf/das/CasciniFS04",
                "MAG": "74235943",
                "DOI": "10.1007/978-3-540-28640-0_48",
                "CorpusId": 5193658
            },
            "abstract": null,
            "referenceCount": 23,
            "citationCount": 93,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/978-3-540-28640-0_48.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2004-09-08",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Cascini2004NaturalLP,\n author = {G. Cascini and A. Fantechi and Emilio Spinicci},\n booktitle = {International Workshop on Document Analysis Systems},\n pages = {508-520},\n title = {Natural Language Processing of Patents and Technical Documentation},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7beeaf688e99db93d83ecba8211b9eafba7022d3",
            "@type": "ScholarlyArticle",
            "paperId": "7beeaf688e99db93d83ecba8211b9eafba7022d3",
            "corpusId": 40622465,
            "url": "https://www.semanticscholar.org/paper/7beeaf688e99db93d83ecba8211b9eafba7022d3",
            "title": "Processing Natural Language without Natural Language Processing",
            "venue": "Conference on Intelligent Text Processing and Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:a1c1b2d2-5629-4b8f-b764-20ea10fa588c",
                "name": "Conference on Intelligent Text Processing and Computational Linguistics",
                "alternate_names": [
                    "Conf Intell Text Process Comput Linguistics",
                    "CICLing"
                ],
                "issn": null,
                "url": "http://www.cicling.org/"
            },
            "year": 2003,
            "externalIds": {
                "MAG": "1519936037",
                "DBLP": "conf/cicling/Brill03",
                "DOI": "10.1007/3-540-36456-0_37",
                "CorpusId": 40622465
            },
            "abstract": null,
            "referenceCount": 13,
            "citationCount": 67,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2003-02-16",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Brill2003ProcessingNL,\n author = {Eric Brill},\n booktitle = {Conference on Intelligent Text Processing and Computational Linguistics},\n pages = {360-369},\n title = {Processing Natural Language without Natural Language Processing},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6c92ac4eb449b53ce9a7b0dd94316da17a394446",
            "@type": "ScholarlyArticle",
            "paperId": "6c92ac4eb449b53ce9a7b0dd94316da17a394446",
            "corpusId": 15386387,
            "url": "https://www.semanticscholar.org/paper/6c92ac4eb449b53ce9a7b0dd94316da17a394446",
            "title": "Integrating Plot, Character and Natural Language Processing in the Interactive Drama Fa\u00e7ade",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2003,
            "externalIds": {
                "MAG": "2185451601",
                "CorpusId": 15386387
            },
            "abstract": "Facade is an artificial intelligence-based art/research experiment in electronic narrative - an attempt to move beyond traditional branching or hy- per-linked narrative to create a fully-realized, one-act interactive drama. We are completing a three year collaboration to engineer a novel architecture that inte- grates emotional, interactive character behavior, drama-managed plot and shal- low natural language processing. In this architecture, authors can organize hierarchies of reactive behaviors and natural-language discourse contexts into entities called story beats, achieving rich, robust local interaction; a drama manager globally sequences beats chosen from a large pool in order to make story tension rise and fall to match an Aristotelian arc. Within this architecture we are building a dramatically interesting, real-time 3D virtual world inhabited by computer-controlled characters, in which the user experiences a theatrical drama from a first-person perspective. Facade will be publicly released as a free download in 2003.",
            "referenceCount": 17,
            "citationCount": 213,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Art",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Mateas2003IntegratingPC,\n author = {Michael Mateas and A. Stern},\n title = {Integrating Plot, Character and Natural Language Processing in the Interactive Drama Fa\u00e7ade},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6c192552d23da5b4a0d6eceb2cb24b5c8c4a349f",
            "@type": "ScholarlyArticle",
            "paperId": "6c192552d23da5b4a0d6eceb2cb24b5c8c4a349f",
            "corpusId": 58820395,
            "url": "https://www.semanticscholar.org/paper/6c192552d23da5b4a0d6eceb2cb24b5c8c4a349f",
            "title": "Recycling Translations : Extraction of Lexical Data from Parallel Corpora and their Application in Natural Language Processing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2003,
            "externalIds": {
                "MAG": "188422765",
                "CorpusId": 58820395
            },
            "abstract": "The focus of this thesis is on re-using translations in natural language processing. It involves the collection of documents and their translations in an appropriate format, the automatic extractio ...",
            "referenceCount": 0,
            "citationCount": 103,
            "influentialCitationCount": 10,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Tiedemann2003RecyclingT,\n author = {J. Tiedemann},\n title = {Recycling Translations : Extraction of Lexical Data from Parallel Corpora and their Application in Natural Language Processing},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c43d3fbca6086a5c096ea69675928d8dbcff5a4b",
            "@type": "ScholarlyArticle",
            "paperId": "c43d3fbca6086a5c096ea69675928d8dbcff5a4b",
            "corpusId": 15366907,
            "url": "https://www.semanticscholar.org/paper/c43d3fbca6086a5c096ea69675928d8dbcff5a4b",
            "title": "A Simple Introduction to Maximum Entropy Models for Natural Language Processing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1997,
            "externalIds": {
                "MAG": "1550597138",
                "CorpusId": 15366907
            },
            "abstract": "Many problems in natural language processing can be viewed as lin guistic classi cation problems in which linguistic contexts are used to pre dict linguistic classes Maximum entropy models o er a clean way to com bine diverse pieces of contextual evidence in order to estimate the proba bility of a certain linguistic class occurring with a certain linguistic con text This report demonstrates the use of a particular maximum entropy model on an example problem and then proves some relevant mathemat ical facts about the model in a simple and accessible manner This report also describes an existing procedure called Generalized Iterative Scaling which estimates the parameters of this particular model The goal of this report is to provide enough detail to re implement the maximum entropy models described in Ratnaparkhi Reynar and Ratnaparkhi Ratnaparkhi and also to provide a simple explanation of the max imum entropy formalism Introduction Many problems in natural language processing NLP can be re formulated as statistical classi cation problems in which the task is to estimate the probability of class a occurring with context b or p a b Contexts in NLP tasks usually include words and the exact context depends on the nature of the task for some tasks the context b may consist of just a single word while for others b may consist of several words and their associated syntactic labels Large text corpora usually contain some information about the cooccurrence of a s and b s but never enough to completely specify p a b for all possible a b pairs since the words in b are typically sparse The problem is then to nd a method for using the sparse evidence about the a s and b s to reliably estimate a probability model p a b Consider the Principle of Maximum Entropy Jaynes Good which states that the correct distribution p a b is that which maximizes en tropy or uncertainty subject to the constraints which represent evidence i e the facts known to the experimenter Jaynes discusses its advan tages in making inferences on the basis of partial information we must use that probability distribution which has maximum entropy sub ject to whatever is known This is the only unbiased assignment we can make to use any other would amount to arbitrary assumption of information which by hypothesis we do not have More explicitly if A denotes the set of possible classes and B denotes the set of possible contexts p should maximize the entropy H p X",
            "referenceCount": 10,
            "citationCount": 246,
            "influentialCitationCount": 22,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Ratnaparkhi1997ASI,\n author = {A. Ratnaparkhi},\n title = {A Simple Introduction to Maximum Entropy Models for Natural Language Processing},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d64dc949b8ceae642e8fcad7ccd29ee523116371",
            "@type": "ScholarlyArticle",
            "paperId": "d64dc949b8ceae642e8fcad7ccd29ee523116371",
            "corpusId": 8786762,
            "url": "https://www.semanticscholar.org/paper/d64dc949b8ceae642e8fcad7ccd29ee523116371",
            "title": "Natural language processing for information assurance and security: an overview and implementations",
            "venue": "New Security Paradigms Workshop",
            "publicationVenue": {
                "id": "urn:research:c143becc-2c64-418b-bc48-dacb39a3c93b",
                "name": "New Security Paradigms Workshop",
                "alternate_names": [
                    "NSPW",
                    "New Secur Paradig Workshop"
                ],
                "issn": null,
                "url": null
            },
            "year": 2001,
            "externalIds": {
                "MAG": "1969457446",
                "DBLP": "conf/nspw/AtallahMRN00",
                "DOI": "10.1145/366173.366190",
                "CorpusId": 8786762
            },
            "abstract": "This research paper explores a promising interface between natural language processing (NLP) and information assurance and security (IAS). More specificall~ it is devoted to possible applications to, and further dedicated development of, the accumulated considerable resources in NLP for, IAS. The expected and partially accomplished result is in harnessing the weird, illogical ways natural languages encode meaning, the very ways that defy all the usual combinatorial approaches to mathematical--and computational--complexity and make NLP so hard, to enhance information security. The paper is of a mixed theoretical and empirical nature. Of the four possible venues of applications, (i) memorizing randomly generated passwords with the help of automatically generated funny jingles, (ii) natural language watermarking, (iii) using the available machine translation (MT) systems for (additional) encryption of text messages, and (iv) downgrading, or sanitizing classified information in networks, two venues, (i) and (iv), have been at least partially implemented and the remaining two (ii) and (iii) are being implemented to the proof-of-concept level. We must make it very clear, however, that we have done very little experimentation or evaluation at this point, though we are moving quickly in that direction. The merits of the paper, if any, are in its venture to make considerable progress achieved recently in NLE especially in knowledge representation and meaning analysis, useful for IAS needs. The NLP approach adopted here, ontological semantics, has been developed by two of the coauthors; watermarking is based on the pioneering research by another coauthor and his associates; most of the implementation of the password memorization software has been done by the fourth coauthor. All the four of us have agonized whether we should report this research now or wait till we have fully implemented all or at least some of the systems we are developing. At the end of the day, we have reached a consensus that it is important, even at this early stage, to review for the information security community what NLP can do for it and to invite feedback and further efforts and ideas on what seems likely to become a new paradigm in information security. To the body of the paper, we Mikhail J. Atallah, Craig J. McDonough, Victor Raskin Center for Education and Research in Information Assurance and Security (CERIAS, www.cerias.purdue.edu) Purdue University W. Lafayette, IN 47907 mja, raskin, mcdonoug@cerias.purdue.edu Sergei Nirenburg Computing Research Laboratory, New Mexico State University Las Cruces, NM 88003 sergei@crl.nmsu.edu have added two self-contained deliberately reference-free appendices on NLP and ontological semantics, respectively, primarily for the benefit of those IAS readers, who are interested in expanding their understanding of those fields and further exploring their possible fruitful interactions with IAS.",
            "referenceCount": 26,
            "citationCount": 140,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2001-02-20",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Atallah2001NaturalLP,\n author = {M. Atallah and C. McDonough and V. Raskin and S. Nirenburg},\n booktitle = {New Security Paradigms Workshop},\n pages = {51-65},\n title = {Natural language processing for information assurance and security: an overview and implementations},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b3e5c7c906c9745efe2c3e5d8912f718343efc2b",
            "@type": "ScholarlyArticle",
            "paperId": "b3e5c7c906c9745efe2c3e5d8912f718343efc2b",
            "corpusId": 8235303,
            "url": "https://www.semanticscholar.org/paper/b3e5c7c906c9745efe2c3e5d8912f718343efc2b",
            "title": "Segmentation Standard for Chinese Natural Language Processing",
            "venue": "International Conference on Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:f51ff783-cdff-4e22-94fb-28e6336d17b3",
                "name": "International Conference on Computational Linguistics",
                "alternate_names": [
                    "Int Conf Comput Linguistics",
                    "COLING"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/coling/"
            },
            "year": 1996,
            "externalIds": {
                "ACL": "C96-2184",
                "DBLP": "conf/coling/HuangCC96",
                "MAG": "2007439110",
                "DOI": "10.3115/993268.993362",
                "CorpusId": 8235303
            },
            "abstract": "This paper proposes a segmentation standard for Chinese natural language processing. The standard is proposed to achieve linguistic felicity, computational feasibility, and data uniformity. Linguistic felicity is maintained by defining a segmentation unit to be equivalent to the theoretical definition of word, and by providing a set of segmentation principles that are equivalent to a functional definition of a word. Computational feasibility is ensured by the fact that the above functional definitions are procedural in nature and can be converted to segmentation algorithms, as well as by the implementable heuristic guidelines which deal with specific linguistic categories. Data uniformity is achieved by stratification of the standard itself and by defining a standard lexicon as part of the segmentation standard.",
            "referenceCount": 16,
            "citationCount": 73,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.3115/993268.993362",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1996-08-05",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Huang1996SegmentationSF,\n author = {Chu-Ren Huang and Keh-Jiann Chen and Fengyi Chen and Li-Li Chang},\n booktitle = {International Conference on Computational Linguistics},\n pages = {1045-1048},\n title = {Segmentation Standard for Chinese Natural Language Processing},\n year = {1996}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:59b77e7ee98adae815f254ddb1a7d35d680daf25",
            "@type": "ScholarlyArticle",
            "paperId": "59b77e7ee98adae815f254ddb1a7d35d680daf25",
            "corpusId": 16131947,
            "url": "https://www.semanticscholar.org/paper/59b77e7ee98adae815f254ddb1a7d35d680daf25",
            "title": "A broad-coverage natural language processing system",
            "venue": "American Medical Informatics Association Annual Symposium",
            "publicationVenue": {
                "id": "urn:research:c9e16b3c-2fdf-4b4c-82bf-5cdf3d3435b7",
                "name": "American Medical Informatics Association Annual Symposium",
                "alternate_names": [
                    "Conference of American Medical Informatics Association",
                    "Am Med Informatics Assoc Annu Symp",
                    "Conf Am Med Informatics Assoc",
                    "AMIA"
                ],
                "issn": null,
                "url": "https://knowledge.amia.org/"
            },
            "year": 2000,
            "externalIds": {
                "MAG": "1637593105",
                "DBLP": "conf/amia/Friedman00",
                "CorpusId": 16131947,
                "PubMed": "11079887"
            },
            "abstract": "Natural language processing systems (NLP) that extract clinical information from textual reports were shown to be effective for limited domains and for particular applications. Because an NLP system typically requires substantial resources to develop, it is beneficial if it is designed to be easily extendible to multiple domains and applications. This paper describes multiple extensions of an NLP system called MedLEE, which was originally developed for the domain of radiological reports of the chest, but has subsequently been extended to mammography, discharge summaries, all of radiology, electrocardiography, echocardiography, and pathology.",
            "referenceCount": 13,
            "citationCount": 248,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Proceedings. AMIA Symposium",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Friedman2000ABN,\n author = {C. Friedman},\n booktitle = {American Medical Informatics Association Annual Symposium},\n journal = {Proceedings. AMIA Symposium},\n pages = {\n          270-4\n        },\n title = {A broad-coverage natural language processing system},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fe32895baaea4b3759dd161fa4d879d64c60baa5",
            "@type": "ScholarlyArticle",
            "paperId": "fe32895baaea4b3759dd161fa4d879d64c60baa5",
            "corpusId": 5454734,
            "url": "https://www.semanticscholar.org/paper/fe32895baaea4b3759dd161fa4d879d64c60baa5",
            "title": "Natural Language Processing in PROLOG",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1989,
            "externalIds": {
                "DBLP": "books/aw/GazdarM89",
                "MAG": "152453476",
                "CorpusId": 5454734
            },
            "abstract": "Chapter Objectives Natural language processing representations were presented Semantic relationships Conceptual graphs Verb-based case frames Prolog was used to build a series of parsers Context free parsers Deterministic Probabilistic Parsers Probabilistic measures for sentence structures and words Lexicalized probabilistic parsers capture word combination plausibility Context sensitive parsers Deterministic Recursive descent semantic net parsers Enforce word-based case frame constraints Because of its declarative semantics, built-in search, and pattern matching, Prolog provides an important tool for programs that process natural language. Indeed, natural language understanding was one of Prolog's earliest applications. As we will see with many examples in this chapter, we can write natural language grammars directly in Prolog, for example, context-free, context-sensitive, recursive descent semantic network, as well as stochastic parsers. Semantic representations are also easy to create in Prolog, as we see for conceptual graphs and case frames in Section 8.2. Semantic relationships may be captured either using the first-order predicate calculus or by a meta-interpreter for another representation, as suggested by semantic networks (Section 2.4.1) or frames (Sections 2.4.2 and 8.1). This not only simplifies programming, but also keeps a close connection between theories and their implementation. In Section 8.3 we present a context-free parser and later add context sensitivity to the parse Section 8.5. We accomplish many of the same justifications for context sensitivity in parsing, e.g., noun-verb agreement, with the various probabilistic parsers of Section 8.4. Finally, semantic",
            "referenceCount": 0,
            "citationCount": 201,
            "influentialCitationCount": 7,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Gazdar1989NaturalLP,\n author = {G. Gazdar and C. Mellish},\n title = {Natural Language Processing in PROLOG},\n year = {1989}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8f1b5c6bbd47cebff3f2c08e0773b0b878642e39",
            "@type": "ScholarlyArticle",
            "paperId": "8f1b5c6bbd47cebff3f2c08e0773b0b878642e39",
            "corpusId": 5689069,
            "url": "https://www.semanticscholar.org/paper/8f1b5c6bbd47cebff3f2c08e0773b0b878642e39",
            "title": "Evaluating natural language processing systems",
            "venue": "CACM",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1996,
            "externalIds": {
                "DBLP": "journals/cacm/King96",
                "MAG": "1967972613",
                "DOI": "10.1145/234173.234208",
                "CorpusId": 5689069
            },
            "abstract": "A variety of factions may be interested in evaluating natural language processing (NLP) systems, ranging from funding authorities who must choose between competing research projects and justify their choices through the results subsequently obtained, to the end user who needs to choose between competing products. If the product is expensive, or if it implies a major reorganization of workflow, the user may also need to provide post hoc justification. Surprisingly, the literature on evaluation is relatively sparse for several reasons. First, evaluations are often carried out under consultancy arrangements for a particular customer. Not only is the evaluation then tailor-made to suit that customer and therefore not considered to be of general interest, but the customer may be reluctant to have the results of the evaluation made public, either because of an agreement with the manufacturer whose product has been evaluated, or an unwillingness to reveal the results to competitors. Secondly, evaluation of research proposals and of projects in the academic area has traditionally been by peer review. This has changed somewhat in particular areas, under the influence of the DARPA/ARPA series of evaluations, but is still the most common pattern. The only result of a peer review evaluation is a report which is often confidential. Thirdly, evaluation acquired a bad name as a result of the Automatic Language Processing Advisory Committee\u2019s (ALPAC) Evaluating Natural Language Processing Systems Designing customized methods for testing various NLP systems may be costly and",
            "referenceCount": 23,
            "citationCount": 172,
            "influentialCitationCount": 10,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Commun. ACM",
                "volume": "39"
            },
            "citationStyles": {
                "bibtex": "@Article{King1996EvaluatingNL,\n author = {M. King},\n booktitle = {CACM},\n journal = {Commun. ACM},\n pages = {73-79},\n title = {Evaluating natural language processing systems},\n volume = {39},\n year = {1996}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:080e4404c0b6f4154d29341613b97d1b8dee0708",
            "@type": "ScholarlyArticle",
            "paperId": "080e4404c0b6f4154d29341613b97d1b8dee0708",
            "corpusId": 8178023,
            "url": "https://www.semanticscholar.org/paper/080e4404c0b6f4154d29341613b97d1b8dee0708",
            "title": "NL-OOPS: from natural language to object oriented requirements using the natural language processing system LOLITA",
            "venue": "Natural Language Engineering",
            "publicationVenue": {
                "id": "urn:research:b0dc264e-1ef6-4c58-be54-d2e6137ac35f",
                "name": "Natural Language Engineering",
                "alternate_names": [
                    "Nat Lang Eng"
                ],
                "issn": "1351-3249",
                "url": "https://www.cambridge.org/core/journals/natural-language-engineering"
            },
            "year": 1996,
            "externalIds": {
                "MAG": "2115076780",
                "DBLP": "journals/nle/Mich96",
                "DOI": "10.1017/S1351324996001337",
                "CorpusId": 8178023
            },
            "abstract": "This paper describes NL-OOPS, a CASE tool that supports requirements analysis by generating object oriented models from natural language requirements documents. The full natural language analysis is obtained using as a core system the Natural Language Processing System LOLITA. The object oriented analysis module implements an algorithm for the extraction of the objects and their associations for use in creating object models.",
            "referenceCount": 43,
            "citationCount": 165,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1996-06-01",
            "journal": {
                "name": "Natural Language Engineering",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Mich1996NLOOPSFN,\n author = {Luisa Mich},\n booktitle = {Natural Language Engineering},\n journal = {Natural Language Engineering},\n pages = {161 - 187},\n title = {NL-OOPS: from natural language to object oriented requirements using the natural language processing system LOLITA},\n volume = {2},\n year = {1996}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:319a3a51457b5fcaa179576de11305a045177eaa",
            "@type": "ScholarlyArticle",
            "paperId": "319a3a51457b5fcaa179576de11305a045177eaa",
            "corpusId": 21173842,
            "url": "https://www.semanticscholar.org/paper/319a3a51457b5fcaa179576de11305a045177eaa",
            "title": "Connectionist, Statistical and Symbolic Approaches to Learning for Natural Language Processing",
            "venue": "Lecture Notes in Computer Science",
            "publicationVenue": {
                "id": "urn:research:2f5d0e8a-faad-4f10-b323-2b2e3c439a78",
                "name": "Lecture Notes in Computer Science",
                "alternate_names": [
                    "LNCS",
                    "Transactions on Computational Systems Biology",
                    "Trans Comput Syst Biology",
                    "Lect Note Comput Sci"
                ],
                "issn": "0302-9743",
                "url": "http://www.springer.com/lncs"
            },
            "year": 1996,
            "externalIds": {
                "DBLP": "conf/ijcai/1995lp",
                "MAG": "1591234214",
                "DOI": "10.1007/3-540-60925-3",
                "CorpusId": 21173842
            },
            "abstract": null,
            "referenceCount": 72,
            "citationCount": 159,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1996-03-15",
            "journal": {
                "name": null,
                "volume": "1040"
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Wermter1996ConnectionistSA,\n author = {S. Wermter and E. Riloff and G. Scheler},\n booktitle = {Lecture Notes in Computer Science},\n title = {Connectionist, Statistical and Symbolic Approaches to Learning for Natural Language Processing},\n volume = {1040},\n year = {1996}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:81e089d1adab2125d505672dbabfac2178c41f5c",
            "@type": "ScholarlyArticle",
            "paperId": "81e089d1adab2125d505672dbabfac2178c41f5c",
            "corpusId": 40510502,
            "url": "https://www.semanticscholar.org/paper/81e089d1adab2125d505672dbabfac2178c41f5c",
            "title": "Inheritance in Natural Language Processing",
            "venue": "Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:ee37a78c-f3d8-407a-bd24-bb97fe6dbab9",
                "name": "Computational Linguistics",
                "alternate_names": [
                    "Comput Linguistics"
                ],
                "issn": "0891-2017",
                "url": "http://aclanthology.info/venues/cl"
            },
            "year": 1992,
            "externalIds": {
                "DBLP": "journals/coling/DaelemansSG92",
                "ACL": "J92-2004",
                "MAG": "1513310202",
                "CorpusId": 40510502
            },
            "abstract": "In this introduction to the special issues, we begin by outlining a concrete example that indicates some of the motivations leading to the widespread use of inheritance networks in computational linguistics. This example allows us to illustrate some of the formal choices that have to be made by those who seek network solutions to natural language processing (NLP) problems. We provide some pointers into the extensive body of AI knowledge representation publications that have been concerned with the theory of inheritance over the last dozen years or so. We go on to identify the three rather separate traditions that have led to the current work in NLP. We then provide a fairly comprehensive literature survey of the use that computational linguists have made of inheritance networks over the last two decades, organized by reference to levels of linguistic description. In the course of this survey, we draw the reader's attention to each of the papers in these issues of Computational Linguistics and set them in the context of related work.",
            "referenceCount": 93,
            "citationCount": 87,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "1992-06-01",
            "journal": {
                "name": "Comput. Linguistics",
                "volume": "18"
            },
            "citationStyles": {
                "bibtex": "@Article{Daelemans1992InheritanceIN,\n author = {Walter Daelemans and Koenraad J M J De Smedt and G. Gazdar},\n booktitle = {Computational Linguistics},\n journal = {Comput. Linguistics},\n pages = {205-218},\n title = {Inheritance in Natural Language Processing},\n volume = {18},\n year = {1992}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2612f8294454aab719376b411185d8a90b3510b9",
            "@type": "ScholarlyArticle",
            "paperId": "2612f8294454aab719376b411185d8a90b3510b9",
            "corpusId": 3264770,
            "url": "https://www.semanticscholar.org/paper/2612f8294454aab719376b411185d8a90b3510b9",
            "title": "The Theoretical Status of Ontologies in Natural Language Processing",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 1997,
            "externalIds": {
                "MAG": "1602515394",
                "DBLP": "journals/corr/cmp-lg-9704010",
                "ArXiv": "cmp-lg/9704010",
                "CorpusId": 3264770
            },
            "abstract": "This paper discusses the use of `ontologies' in Natural Language Processing. It classifies various kinds of ontologies that have been employed in NLP and discusses various benefits and problems with those designs. Particular focus is then placed on experiences gained in the use of the Upper Model, a linguistically-motivated `ontology' originally designed for use with the Penman text generation system. Some proposals for further NLP ontology design criteria are then made.",
            "referenceCount": 134,
            "citationCount": 56,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1997-04-25",
            "journal": {
                "name": "ArXiv",
                "volume": "cmp-lg/9704010"
            },
            "citationStyles": {
                "bibtex": "@Article{Bateman1997TheTS,\n author = {J. Bateman},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {The Theoretical Status of Ontologies in Natural Language Processing},\n volume = {cmp-lg/9704010},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:919d68f52df7dc307688b8b00231c11a69a396d5",
            "@type": "ScholarlyArticle",
            "paperId": "919d68f52df7dc307688b8b00231c11a69a396d5",
            "corpusId": 60467631,
            "url": "https://www.semanticscholar.org/paper/919d68f52df7dc307688b8b00231c11a69a396d5",
            "title": "Natural Language Processing in PROLOG: An Introduction to Computational Linguistics",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1989,
            "externalIds": {
                "MAG": "1976130806",
                "CorpusId": 60467631
            },
            "abstract": "Any books that you read, no matter how you got the sentences that have been read from the books, surely they will give you goodness. But, we will show you one of recommendation of the book that you need to read. This natural language processing in prolog an introduction to computational linguistics is what we surely mean. We will show you the reasonable reasons why you need to read this book. This book is a kind of precious book written by an experienced author.",
            "referenceCount": 0,
            "citationCount": 128,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1989-04-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Gazdar1989NaturalLP,\n author = {G. Gazdar and C. Mellish},\n title = {Natural Language Processing in PROLOG: An Introduction to Computational Linguistics},\n year = {1989}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b664336723a06fc844ba751d974236898f0470f6",
            "@type": "ScholarlyArticle",
            "paperId": "b664336723a06fc844ba751d974236898f0470f6",
            "corpusId": 17989776,
            "url": "https://www.semanticscholar.org/paper/b664336723a06fc844ba751d974236898f0470f6",
            "title": "Use of natural language processing to translate clinical information from a database of 889,921 chest radiographic reports.",
            "venue": "Radiology",
            "publicationVenue": {
                "id": "urn:research:357207a3-a4af-4091-822c-75ef52d02fb5",
                "name": "Radiology",
                "alternate_names": null,
                "issn": "0033-8419",
                "url": "http://radiology.rsna.org/"
            },
            "year": 2002,
            "externalIds": {
                "MAG": "2156518033",
                "DOI": "10.1148/RADIOL.2241011118",
                "CorpusId": 17989776,
                "PubMed": "12091676"
            },
            "abstract": "PURPOSE\nTo evaluate translation of chest radiographic reports by using natural language processing and to compare the findings with those in the literature.\n\n\nMATERIALS AND METHODS\nA natural language processor coded 10 years of narrative chest radiographic reports from an urban academic medical center. Coding for 150 reports was compared with manual coding. Frequencies and co-occurrences of 24 clinical conditions (diseases, abnormalities, and clinical states) were estimated. The ratio of right to left lung mass, association of pleural effusion with other conditions, and frequency of bullet and stab wounds were compared with independent observations. The sensitivity and specificity of the system's pneumothorax coding were compared with those of manual financial coding.\n\n\nRESULTS\nThe system coded 889,921 reports on 251,186 patients. On the basis of manual coding of 150 reports, the processor's sensitivity (0.81) and specificity (0.99) were comparable to those previously reported for natural language processing and for expert coders. The frequencies of the selected conditions ranged from 0.22 for pleural effusion to 0.0004 for tension pneumothorax. The database confirmed earlier observations that lung cancer occurs in a 3:2 right-to-left ratio. The association of pleural effusion with other conditions mirrored that in the literature. Bullet and stab wounds decreased during 10 years at a rate consistent with crime statistics. A review of pneumothorax cases showed that the database (sensitivity, 1.00; specificity, 0.996) was more accurate than financial discharge coding (sensitivity, 0.17; P =.002; specificity, 0.996; not significant).\n\n\nCONCLUSION\nInternal and external validation in this study confirmed the accuracy of natural language processing for translating chest radiographic narrative reports into a large database of information.",
            "referenceCount": 34,
            "citationCount": 202,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Study",
                "Review"
            ],
            "publicationDate": "2002-07-01",
            "journal": {
                "name": "Radiology",
                "volume": "224 1"
            },
            "citationStyles": {
                "bibtex": "@Article{Hripcsak2002UseON,\n author = {G. Hripcsak and J. Austin and P. Alderson and C. Friedman},\n booktitle = {Radiology},\n journal = {Radiology},\n pages = {\n          157-63\n        },\n title = {Use of natural language processing to translate clinical information from a database of 889,921 chest radiographic reports.},\n volume = {224 1},\n year = {2002}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bb1b1fadceb96dc45391da449c5e40ded87f5b03",
            "@type": "ScholarlyArticle",
            "paperId": "bb1b1fadceb96dc45391da449c5e40ded87f5b03",
            "corpusId": 2576858,
            "url": "https://www.semanticscholar.org/paper/bb1b1fadceb96dc45391da449c5e40ded87f5b03",
            "title": "Natural Language Processing and User Modeling: Synergies and Limitations",
            "venue": "User modeling and user-adapted interaction",
            "publicationVenue": {
                "id": "urn:research:cf7b0aac-26b9-4d6a-ba15-e72f6755e11c",
                "name": "User modeling and user-adapted interaction",
                "alternate_names": [
                    "User model user-adapted interact",
                    "User Modeling and User-adapted Interaction",
                    "User Model User-adapted Interact"
                ],
                "issn": "0924-1868",
                "url": "https://link.springer.com/journal/11257"
            },
            "year": 2001,
            "externalIds": {
                "DBLP": "journals/umuai/ZukermanL01",
                "MAG": "73056518",
                "DOI": "10.1023/A:1011174108613",
                "CorpusId": 2576858
            },
            "abstract": null,
            "referenceCount": 122,
            "citationCount": 101,
            "influentialCitationCount": 5,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1023/A:1011174108613.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2001-03-27",
            "journal": {
                "name": "User Modeling and User-Adapted Interaction",
                "volume": "11"
            },
            "citationStyles": {
                "bibtex": "@Article{Zukerman2001NaturalLP,\n author = {Ingrid Zukerman and D. Litman},\n booktitle = {User modeling and user-adapted interaction},\n journal = {User Modeling and User-Adapted Interaction},\n pages = {129-158},\n title = {Natural Language Processing and User Modeling: Synergies and Limitations},\n volume = {11},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d6d7c78be84929a83930ee62acfec57ae6ab1691",
            "@type": "ScholarlyArticle",
            "paperId": "d6d7c78be84929a83930ee62acfec57ae6ab1691",
            "corpusId": 36925364,
            "url": "https://www.semanticscholar.org/paper/d6d7c78be84929a83930ee62acfec57ae6ab1691",
            "title": "The r\u00f4le of natural language processing in alternative and augmentative communication",
            "venue": "Natural Language Engineering",
            "publicationVenue": {
                "id": "urn:research:b0dc264e-1ef6-4c58-be54-d2e6137ac35f",
                "name": "Natural Language Engineering",
                "alternate_names": [
                    "Nat Lang Eng"
                ],
                "issn": "1351-3249",
                "url": "https://www.cambridge.org/core/journals/natural-language-engineering"
            },
            "year": 1998,
            "externalIds": {
                "MAG": "2155983010",
                "DBLP": "journals/nle/NewellLH98",
                "DOI": "10.1017/S135132499800182X",
                "CorpusId": 36925364
            },
            "abstract": "Alternative and Augmentative Communication (AAC) for people with speech and language disorders is an interesting and challenging application field for research in Natural Language Processing. Further advances in the development of AAC systems require robust language processing techniques and versatile linguistic knowledge bases. Also NLP research can benefit from studying the techniques used in this field and from the user-centred methodologies used to develop and evaluate AAC systems. Until recently, however, apart from some exceptions, there was little scientific exchange between the two research areas. This paper aims to make a contribution to closing this gap. We will argue that current interest in language use, which can be shown by the large amount of research on comprehensive dictionaries and on corpora processing, makes the results of NLP research more relevant to AAC. We will also show that the increasing interest of AAC researchers in NLP is having positive results. To situate research on communication aids, the first half of this paper gives an overview of the AAC research field. The second half is dedicated to an overview of research prototype systems and commercially available communication aids that specifically involve more advanced language processing techniques.",
            "referenceCount": 51,
            "citationCount": 69,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "1998-03-01",
            "journal": {
                "name": "Natural Language Engineering",
                "volume": "4"
            },
            "citationStyles": {
                "bibtex": "@Article{Newell1998TheRO,\n author = {A. Newell and Stefan Langer and M. Hickey},\n booktitle = {Natural Language Engineering},\n journal = {Natural Language Engineering},\n pages = {1 - 16},\n title = {The r\u00f4le of natural language processing in alternative and augmentative communication},\n volume = {4},\n year = {1998}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:46ee016d0fa067f65494e4721589eb8b59e11c1d",
            "@type": "ScholarlyArticle",
            "paperId": "46ee016d0fa067f65494e4721589eb8b59e11c1d",
            "corpusId": 10423588,
            "url": "https://www.semanticscholar.org/paper/46ee016d0fa067f65494e4721589eb8b59e11c1d",
            "title": "Genomics and natural language processing",
            "venue": "Nature reviews genetics",
            "publicationVenue": {
                "id": "urn:research:f44976b5-2cb9-402a-bc59-6a174239987b",
                "name": "Nature reviews genetics",
                "alternate_names": [
                    "Nature Reviews Genetics",
                    "Nat rev genet",
                    "Nat Rev Genet"
                ],
                "issn": "1471-0056",
                "url": "https://www.nature.com/nrg/"
            },
            "year": 2002,
            "externalIds": {
                "MAG": "1541931954",
                "DOI": "10.1038/nrg861",
                "CorpusId": 10423588,
                "PubMed": "12154383"
            },
            "abstract": null,
            "referenceCount": 57,
            "citationCount": 168,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Biology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2002-08-01",
            "journal": {
                "name": "Nature Reviews Genetics",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{Yandell2002GenomicsAN,\n author = {M. Yandell and W. Majoros},\n booktitle = {Nature reviews genetics},\n journal = {Nature Reviews Genetics},\n pages = {601-610},\n title = {Genomics and natural language processing},\n volume = {3},\n year = {2002}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ac97b011f4f1e773f36af352bb5425d52f2dfafc",
            "@type": "ScholarlyArticle",
            "paperId": "ac97b011f4f1e773f36af352bb5425d52f2dfafc",
            "corpusId": 12846589,
            "url": "https://www.semanticscholar.org/paper/ac97b011f4f1e773f36af352bb5425d52f2dfafc",
            "title": "An Overview of Empirical Natural Language Processing",
            "venue": "The AI Magazine",
            "publicationVenue": {
                "id": "urn:research:6fedff74-7525-4b7f-bbb4-4df4e23948e4",
                "name": "The AI Magazine",
                "alternate_names": [
                    "AI Mag",
                    "Ai Mag",
                    "Ai Magazine"
                ],
                "issn": "0738-4602",
                "url": "https://www.aaai.org/Library/Magazine/magazine-library.php"
            },
            "year": 1997,
            "externalIds": {
                "DBLP": "journals/aim/BrillM97",
                "MAG": "2154773184",
                "DOI": "10.1609/aimag.v18i4.1318",
                "CorpusId": 12846589
            },
            "abstract": "In recent years, there has been a resurgence in research on empirical methods in natural language processing. These methods employ learning techniques to automatically extract linguistic knowledge from natural language corpora rather than require the system developer to manually encode the requisite knowledge. The current special issue reviews recent research in empirical methods in speech recognition, syntactic parsing, semantic processing, information extraction, and machine translation. This article presents an introduction to the series of specialized articles on these topics and attempts to describe and explain the growing interest in using learning methods to aid the development of natural language processing systems.",
            "referenceCount": 59,
            "citationCount": 110,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "1997-12-15",
            "journal": {
                "name": "AI Mag.",
                "volume": "18"
            },
            "citationStyles": {
                "bibtex": "@Article{Brill1997AnOO,\n author = {Eric Brill and R. Mooney},\n booktitle = {The AI Magazine},\n journal = {AI Mag.},\n pages = {13-24},\n title = {An Overview of Empirical Natural Language Processing},\n volume = {18},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1e98c87e8cbf55da15860739cd40c73797f7d3bc",
            "@type": "ScholarlyArticle",
            "paperId": "1e98c87e8cbf55da15860739cd40c73797f7d3bc",
            "corpusId": 35756700,
            "url": "https://www.semanticscholar.org/paper/1e98c87e8cbf55da15860739cd40c73797f7d3bc",
            "title": "Natural Language Processing and Semantical Representation of Medical Texts",
            "venue": "Methods of Information in Medicine",
            "publicationVenue": {
                "id": "urn:research:95f5bdab-1f05-4090-899f-3869a15b5707",
                "name": "Methods of Information in Medicine",
                "alternate_names": [
                    "Method Inf Med"
                ],
                "issn": "0026-1270",
                "url": "https://methods.schattauer.de/en/contents/methods-open.html"
            },
            "year": 1992,
            "externalIds": {
                "MAG": "173092572",
                "DOI": "10.1055/s-0038-1634865",
                "CorpusId": 35756700,
                "PubMed": "1635463"
            },
            "abstract": "Abstract: For medical records, the challenge for the present decade is Natural Language Processing (NLP) of texts, and the construction of an adequate Knowledge Representation. This article describes the components of an NLP system, which is currently being developed in the Geneva Hospital, and within the European Community\u2019s AIM programme. They are: a Natural Language Analyser, a Conceptual Graphs Builder, a Data Base Storage component, a Query Processor, a Natural Language Generator and, in addition, a Translator, a Diagnosis Encoding System and a Literature Indexing System. Taking advantage of a closed domain of knowledge, defined around a medical specialty, a method called proximity processing has been developed. In this situation no parser of the initial text is needed, and the system is based on semantical information of near words in sentences. The benefits are: easy implementation, portability between languages, robustness towards badly-formed sentences, and a sound representation using conceptual graphs.",
            "referenceCount": 17,
            "citationCount": 126,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1992-06-01",
            "journal": {
                "name": "Methods of Information in Medicine",
                "volume": "31"
            },
            "citationStyles": {
                "bibtex": "@Article{Baud1992NaturalLP,\n author = {R. Baud and A. Rassinoux and J. Scherrer},\n booktitle = {Methods of Information in Medicine},\n journal = {Methods of Information in Medicine},\n pages = {117 - 125},\n title = {Natural Language Processing and Semantical Representation of Medical Texts},\n volume = {31},\n year = {1992}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3e706cc15637a01a622f6f0bbaf7d200f3bdba3e",
            "@type": "ScholarlyArticle",
            "paperId": "3e706cc15637a01a622f6f0bbaf7d200f3bdba3e",
            "corpusId": 2893534,
            "url": "https://www.semanticscholar.org/paper/3e706cc15637a01a622f6f0bbaf7d200f3bdba3e",
            "title": "Progress in the Application of Natural Language Processing to Information Retrieval Tasks",
            "venue": "Computer/law journal",
            "publicationVenue": {
                "id": "urn:research:aa746a02-d187-42c2-bdf9-df6a5d4e648c",
                "name": "Computer/law journal",
                "alternate_names": [
                    "Computer journal",
                    "The Computer Journal",
                    "Comput j",
                    "Comput J"
                ],
                "issn": "0164-8756",
                "url": "https://repository.jmls.edu/jitpl/all_issues.html"
            },
            "year": 1992,
            "externalIds": {
                "MAG": "2136987143",
                "DBLP": "journals/cj/Smeaton92",
                "DOI": "10.1093/comjnl/35.3.268",
                "CorpusId": 2893534
            },
            "abstract": "Techniques of automatic natural language processing have been under development since the earliest computing machines, and in recent years these techniques have proven to be robust, reliable and efficient enough to lead to commercial products in many areas. The applications include machine translation, natural language interfaces and the stylistic analysis of texts but NLP techniques have also been applied to other computing tasks besides these. In this paper we will examine and review recent progress in using the lexical, syntactic, semantic and discourse levels of the language analysis for tasks like automatic and semi-automatic indexing of text, text retrieval, text abstracting and summarisation, thesaurus generation from text corpus and conceptual information retrieval. Our own work on the application of syntactic analysis to the matching and ranking of phrases using structured representations of texts, will be included in the overview. Finally, the prospects for gains in terms of overall retrieval effectiveness or quality will be discussed.",
            "referenceCount": 40,
            "citationCount": 146,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "1992-06-01",
            "journal": {
                "name": "Comput. J.",
                "volume": "35"
            },
            "citationStyles": {
                "bibtex": "@Article{Smeaton1992ProgressIT,\n author = {A. Smeaton},\n booktitle = {Computer/law journal},\n journal = {Comput. J.},\n pages = {268-278},\n title = {Progress in the Application of Natural Language Processing to Information Retrieval Tasks},\n volume = {35},\n year = {1992}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:744569e1ff6377ba0b7e3a8e2bcd88ac94d9a02d",
            "@type": "ScholarlyArticle",
            "paperId": "744569e1ff6377ba0b7e3a8e2bcd88ac94d9a02d",
            "corpusId": 30564756,
            "url": "https://www.semanticscholar.org/paper/744569e1ff6377ba0b7e3a8e2bcd88ac94d9a02d",
            "title": "Natural Language Processing: A Historical Review",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1994,
            "externalIds": {
                "MAG": "2145946200",
                "DOI": "10.1007/978-0-585-35958-8_1",
                "CorpusId": 30564756
            },
            "abstract": null,
            "referenceCount": 35,
            "citationCount": 103,
            "influentialCitationCount": 8,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.mt-archive.info/Zampolli-1994-Sparck-Jones.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "History",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Jones1994NaturalLP,\n author = {Karen Sparck Jones},\n pages = {3-16},\n title = {Natural Language Processing: A Historical Review},\n year = {1994}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b3c81b523b1f03c87192aa2abbf9ffb81a143e54",
            "@type": "ScholarlyArticle",
            "paperId": "b3c81b523b1f03c87192aa2abbf9ffb81a143e54",
            "corpusId": 14006552,
            "url": "https://www.semanticscholar.org/paper/b3c81b523b1f03c87192aa2abbf9ffb81a143e54",
            "title": "Self-Organizing Maps In Natural Language Processing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1997,
            "externalIds": {
                "MAG": "30915769",
                "CorpusId": 14006552
            },
            "abstract": "Kohonen's Self-Organizing Map (SOM) is one of the most popular arti cial neural network algorithms. Word category maps are SOMs that have been organized according to word similarities, measured by the similarity of the short contexts of the words. Conceptually interrelated words tend to fall into the same or neighboring map nodes. Nodes may thus be viewed as word categories. Although no a priori information about classes is given, during the self-organizing process a model of the word classes emerges. The central topic of the thesis is the use of the SOM in natural language processing. The approach based on the word category maps is compared with the methods that are widely used in arti cial intelligence research. Modeling gradience, conceptual change, and subjectivity of natural language interpretation are considered. The main application area is information retrieval and textual data mining for which a speci c SOM-based method called the WEBSOM has been developed. The WEBSOM method organizes a document collection on a map display that provides an overview of the collection and facilitates interactive browsing. 1",
            "referenceCount": 120,
            "citationCount": 101,
            "influentialCitationCount": 7,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Honkela1997SelfOrganizingMI,\n author = {T. Honkela},\n title = {Self-Organizing Maps In Natural Language Processing},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3970c8e88cda4e56995c290bd9da586fbd15448a",
            "@type": "ScholarlyArticle",
            "paperId": "3970c8e88cda4e56995c290bd9da586fbd15448a",
            "corpusId": 3035418,
            "url": "https://www.semanticscholar.org/paper/3970c8e88cda4e56995c290bd9da586fbd15448a",
            "title": "Information Retrieval Using Robust Natural Language Processing",
            "venue": "Human Language Technology - The Baltic Perspectiv",
            "publicationVenue": {
                "id": "urn:research:f8e3f8d0-0f40-48c0-b3c0-0c540237b859",
                "name": "Human Language Technology - The Baltic Perspectiv",
                "alternate_names": [
                    "Human Language Technology",
                    "HLT",
                    "Hum Lang Technol",
                    "Hum Lang Technol  Balt Perspect"
                ],
                "issn": null,
                "url": null
            },
            "year": 1992,
            "externalIds": {
                "DBLP": "conf/naacl/Strzalkowski92",
                "MAG": "2129640063",
                "ACL": "H92-1040",
                "DOI": "10.3115/981967.981981",
                "CorpusId": 3035418
            },
            "abstract": "We developed a fully automated Information Retrieval System which uses advanced natural language processing techniques to enhance the effectiveness of traditional key-word based document retrieval. In early experiments with the standard CACM-3204 collection of abstracts, the augmented system has displayed capabilities that made it clearly superior to the purely statistical base system.",
            "referenceCount": 24,
            "citationCount": 66,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.3115/981967.981981",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1992-02-23",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Strzalkowski1992InformationRU,\n author = {T. Strzalkowski and Barbara Vauthey},\n booktitle = {Human Language Technology - The Baltic Perspectiv},\n pages = {104-111},\n title = {Information Retrieval Using Robust Natural Language Processing},\n year = {1992}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ed521609ebfc7494410d1b367b3ba73c0d7da6f4",
            "@type": "ScholarlyArticle",
            "paperId": "ed521609ebfc7494410d1b367b3ba73c0d7da6f4",
            "corpusId": 18363281,
            "url": "https://www.semanticscholar.org/paper/ed521609ebfc7494410d1b367b3ba73c0d7da6f4",
            "title": "Upper Modeling: organizing knowledge for natural language processing",
            "venue": "International Conference on Natural Language Generation",
            "publicationVenue": {
                "id": "urn:research:8648a277-d0ec-4691-9eed-399b31ff9860",
                "name": "International Conference on Natural Language Generation",
                "alternate_names": [
                    "Int Conf Nat Lang Gener",
                    "INLG"
                ],
                "issn": null,
                "url": "http://www.wikicfp.com/cfp/program?id=1613"
            },
            "year": 1990,
            "externalIds": {
                "DBLP": "conf/inlg/Bateman90",
                "MAG": "1495594963",
                "ACL": "W90-0108",
                "CorpusId": 18363281
            },
            "abstract": "Abstract : A general, reusable computational resource has been developed within the Penman text generation project for organizing domain knowledge appropriately for linguistic realization. This resource, called the upper model, provides a domain- and task-independent classification system' that supports sophisticated natural language processing while significantly simplifying the interface between domain-specific knowledge and general linguistic resources. This paper presents the results of our experiences in designing and using the upper model in a variety of applications over the past 5 years. In particular, we present our conclusions concerning the appropriate organization of an upper model, its domain- independence, and the types of interrelationships that need to be supported between upper model and grammar and semantics.",
            "referenceCount": 44,
            "citationCount": 93,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Bateman1990UpperMO,\n author = {J. Bateman},\n booktitle = {International Conference on Natural Language Generation},\n title = {Upper Modeling: organizing knowledge for natural language processing},\n year = {1990}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:573ccec35276bad75f73bb608760444a87416533",
            "@type": "ScholarlyArticle",
            "paperId": "573ccec35276bad75f73bb608760444a87416533",
            "corpusId": 14697906,
            "url": "https://www.semanticscholar.org/paper/573ccec35276bad75f73bb608760444a87416533",
            "title": "Evaluating UMLS strings for natural language processing",
            "venue": "American Medical Informatics Association Annual Symposium",
            "publicationVenue": {
                "id": "urn:research:c9e16b3c-2fdf-4b4c-82bf-5cdf3d3435b7",
                "name": "American Medical Informatics Association Annual Symposium",
                "alternate_names": [
                    "Conference of American Medical Informatics Association",
                    "Am Med Informatics Assoc Annu Symp",
                    "Conf Am Med Informatics Assoc",
                    "AMIA"
                ],
                "issn": null,
                "url": "https://knowledge.amia.org/"
            },
            "year": 2001,
            "externalIds": {
                "DBLP": "conf/amia/McCrayBMB01",
                "MAG": "2133629218",
                "CorpusId": 14697906,
                "PubMed": "11825228"
            },
            "abstract": "The National Library of Medicine's Unified Medical Language System (UMLS) is a rich source of knowledge in the biomedical domain. The UMLS is used for research and development in a range of different applications, including natural language processing (NLP). In this paper we investigate the nature of the strings found in the UMLS Metathesaurus and evaluate them for their usefulness in NLP. We begin by identifying a number of properties that might allow us to predict the likelihood of a given string being found or not found in a corpus. We use a statistical model to test these predictors against our corpus, which is derived from the MEDLINE database. For one set of properties the model correctly predicted 77% of the strings that do not belong to the corpus, and 85% of the strings that do belong to the corpus. For another set of properties the model correctly predicted 96% of the strings that do not belong to the corpus and 29% of the strings that do belong to the corpus.",
            "referenceCount": 14,
            "citationCount": 52,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Proceedings. AMIA Symposium",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{McCray2001EvaluatingUS,\n author = {A. McCray and O. Bodenreider and J. Malley and Allen C. Browne},\n booktitle = {American Medical Informatics Association Annual Symposium},\n journal = {Proceedings. AMIA Symposium},\n pages = {\n          448-52\n        },\n title = {Evaluating UMLS strings for natural language processing},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:01d88ddd3e7a9c5af2acc91a05734b7f066908dc",
            "@type": "ScholarlyArticle",
            "paperId": "01d88ddd3e7a9c5af2acc91a05734b7f066908dc",
            "corpusId": 2488776,
            "url": "https://www.semanticscholar.org/paper/01d88ddd3e7a9c5af2acc91a05734b7f066908dc",
            "title": "Probabilistic Tree-Adjoining Grammar as a Framework for Statistical Natural Language Processing",
            "venue": "International Conference on Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:f51ff783-cdff-4e22-94fb-28e6336d17b3",
                "name": "International Conference on Computational Linguistics",
                "alternate_names": [
                    "Int Conf Comput Linguistics",
                    "COLING"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/coling/"
            },
            "year": 1992,
            "externalIds": {
                "DBLP": "conf/coling/Resnik92a",
                "MAG": "2138389163",
                "ACL": "C92-2065",
                "DOI": "10.3115/992133.992135",
                "CorpusId": 2488776
            },
            "abstract": "In this paper, I argue for the use of a probabilistic form of tree-adjoining grammar (TAG) in statistical natural language processing. I first discuss two previous statistical approaches --- one that concentrates on the probabilities of structural operations, and another that emphasizes co-occurrence relationships between words. I argue that a purely structural apprach, exemplified by probabilistic context-free grammar, lacks sufficient sensitivity to lexical context, and, conversely, that lexical co-occurence analyses require a richer notion of locality that is best provided by importing some notion of structure.I then propose probabilistic TAG as a framework for statistical language modelling, arguing that it provides an advantageous combination of structure, locality, and lexical sensitivity. Issues in the acquisition of probabilistic TAG and parameter estimation are briefly considered.",
            "referenceCount": 22,
            "citationCount": 142,
            "influentialCitationCount": 17,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://dl.acm.org/ft_gateway.cfm?id=992135&type=pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1992-08-23",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Resnik1992ProbabilisticTG,\n author = {P. Resnik},\n booktitle = {International Conference on Computational Linguistics},\n pages = {418-424},\n title = {Probabilistic Tree-Adjoining Grammar as a Framework for Statistical Natural Language Processing},\n year = {1992}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7fe72de6d9c926edf5bdac1c0568eff449fc4acd",
            "@type": "ScholarlyArticle",
            "paperId": "7fe72de6d9c926edf5bdac1c0568eff449fc4acd",
            "corpusId": 16049736,
            "url": "https://www.semanticscholar.org/paper/7fe72de6d9c926edf5bdac1c0568eff449fc4acd",
            "title": "Applications of Finite-State Transducers in Natural Language Processing",
            "venue": "International Conference on Implementation and Application of Automata",
            "publicationVenue": {
                "id": "urn:research:cd0e0376-59f3-406d-b1b7-46ae4f8db467",
                "name": "International Conference on Implementation and Application of Automata",
                "alternate_names": [
                    "CIAA",
                    "Conf Implement Appl Autom",
                    "Int Conf Implement Appl Autom",
                    "Conference on Implementation and Application of Automata",
                    "CIAAI",
                    "Int Conf Implement appl autom",
                    "International Conference on Implementation and application of automata"
                ],
                "issn": null,
                "url": "http://www.wikicfp.com/cfp/program?id=441"
            },
            "year": 2000,
            "externalIds": {
                "DBLP": "conf/wia/Karttunen00",
                "MAG": "2123265813",
                "DOI": "10.1007/3-540-44674-5_2",
                "CorpusId": 16049736
            },
            "abstract": null,
            "referenceCount": 19,
            "citationCount": 74,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.cs.mun.ca/~harold/Courses/Old/Ling6800.W06/Diary/n9g3bt35leexrhtc.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": "2000-07-24",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Karttunen2000ApplicationsOF,\n author = {L. Karttunen},\n booktitle = {International Conference on Implementation and Application of Automata},\n pages = {34-46},\n title = {Applications of Finite-State Transducers in Natural Language Processing},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c4d70f6c2a87f66a78491533a0d0d6d40299d834",
            "@type": "ScholarlyArticle",
            "paperId": "c4d70f6c2a87f66a78491533a0d0d6d40299d834",
            "corpusId": 2319072,
            "url": "https://www.semanticscholar.org/paper/c4d70f6c2a87f66a78491533a0d0d6d40299d834",
            "title": "Natural language processing and its future in medicine.",
            "venue": "Academic medicine : journal of the Association of American Medical Colleges",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1999,
            "externalIds": {
                "MAG": "2062458775",
                "DOI": "10.1097/00001888-199908000-00012",
                "CorpusId": 2319072,
                "PubMed": "10495728"
            },
            "abstract": "If accurate clinical information were available electronically, automated applications could be developed to use this information to improve patient care and lower costs. However, to be fully retrievable, clinical information must be structured or coded. Many online patient reports are not coded, but are recorded in natural-language text that cannot be reliably accessed. Natural language processing (NLP) can solve this problem by extracting and structuring text-based clinical information, making clinical data available for use. NLP systems are quite difficult to develop, as they require substantial amounts of knowledge, but progress has definitely been made. Some NLP systems have been developed and tested and have demonstrated promising performance in practical clinical applications; some of these systems have already been deployed. The authors provide background information about NLP, briefly describe some of the systems that have been recently developed, and discuss the future of NLP in medicine.",
            "referenceCount": 0,
            "citationCount": 166,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1999-08-01",
            "journal": {
                "name": "Academic medicine : journal of the Association of American Medical Colleges",
                "volume": "74 8"
            },
            "citationStyles": {
                "bibtex": "@Article{Friedman1999NaturalLP,\n author = {Carol Friedman and G. Hripcsak},\n booktitle = {Academic medicine : journal of the Association of American Medical Colleges},\n journal = {Academic medicine : journal of the Association of American Medical Colleges},\n pages = {\n          890-5\n        },\n title = {Natural language processing and its future in medicine.},\n volume = {74 8},\n year = {1999}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:afa13fa294b63c00ce03771b81416bdd4bd49837",
            "@type": "ScholarlyArticle",
            "paperId": "afa13fa294b63c00ce03771b81416bdd4bd49837",
            "corpusId": 215979972,
            "url": "https://www.semanticscholar.org/paper/afa13fa294b63c00ce03771b81416bdd4bd49837",
            "title": "Transformation-based error-driven learning and natural language processing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1995,
            "externalIds": {
                "MAG": "2998314454",
                "CorpusId": 215979972
            },
            "abstract": "Recently, there has been a rebirth of empiricism in the field of natural language processing. Manual encoding of linguistic information is being challenged by automated corpus-based learning as a m...",
            "referenceCount": 0,
            "citationCount": 73,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1995-12-01",
            "journal": {
                "name": "Computational Linguistics",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{BrillEric1995TransformationbasedEL,\n author = {BrillEric},\n journal = {Computational Linguistics},\n title = {Transformation-based error-driven learning and natural language processing},\n year = {1995}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c2d95e890ee904f70701fa27326d31980424d5dd",
            "@type": "ScholarlyArticle",
            "paperId": "c2d95e890ee904f70701fa27326d31980424d5dd",
            "corpusId": 385288,
            "url": "https://www.semanticscholar.org/paper/c2d95e890ee904f70701fa27326d31980424d5dd",
            "title": "Lexical Semantic Relatedness and Its Application in Natural Language Processing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1999,
            "externalIds": {
                "MAG": "149305727",
                "CorpusId": 385288
            },
            "abstract": "Lexical Semantic Relatedness and Its Application in Natural Language Processing Alexander Budanitsky Department of Computer Science University of Toronto August 1999 A great variety of Natural Language Processing tasks, from word sense disambiguation to text summarization to speech recognition, rely heavily on the ability to measure semantic relatedness or distance between words of a natural language. This report is a comprehensive study of recent computational methods of measuring lexical semantic relatedness. A survey of methods, as well as their applications, is presented, and the question of evaluation is addressed both theoretically and experimentally. Application to the speci c task of intelligent spelling checking is discussed in detail: the design of a prototype system for the detection and correction of malapropisms (words that are similar in spelling or sound to, but quite di erent in meaning from, intended words) is described, and results of experiments on using various measures as plug-ins are considered. Suggestions for research directions in the areas of measuring semantic relatedness and intelligent spelling checking are o ered.",
            "referenceCount": 84,
            "citationCount": 131,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Budanitsky1999LexicalSR,\n author = {Alexander Budanitsky},\n title = {Lexical Semantic Relatedness and Its Application in Natural Language Processing},\n year = {1999}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8f8686e0bd7db0fc2f9eddda2f24aea71f85d863",
            "@type": "ScholarlyArticle",
            "paperId": "8f8686e0bd7db0fc2f9eddda2f24aea71f85d863",
            "corpusId": 7075193,
            "url": "https://www.semanticscholar.org/paper/8f8686e0bd7db0fc2f9eddda2f24aea71f85d863",
            "title": "On some applications of finite-state automata theory to natural language processing",
            "venue": "Natural Language Engineering",
            "publicationVenue": {
                "id": "urn:research:b0dc264e-1ef6-4c58-be54-d2e6137ac35f",
                "name": "Natural Language Engineering",
                "alternate_names": [
                    "Nat Lang Eng"
                ],
                "issn": "1351-3249",
                "url": "https://www.cambridge.org/core/journals/natural-language-engineering"
            },
            "year": 1996,
            "externalIds": {
                "DBLP": "journals/nle/Mohri96",
                "MAG": "2007624857",
                "DOI": "10.1017/S135132499600126X",
                "CorpusId": 7075193
            },
            "abstract": "We describe new applications of the theory of automata to natural language processing: the representation of very large scale dictionaries and the indexation of natural language texts. They are based on new algorithms that we introduce and describe in detail. In particular, we give pseudocodes for the determinisation of string to string transducers, the deterministic union of p-subsequential string to string transducers, and the indexation by automata. We report on several experiments illustrating the applications.",
            "referenceCount": 35,
            "citationCount": 164,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1996-03-01",
            "journal": {
                "name": "Natural Language Engineering",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Mohri1996OnSA,\n author = {Mehryar Mohri},\n booktitle = {Natural Language Engineering},\n journal = {Natural Language Engineering},\n pages = {61 - 80},\n title = {On some applications of finite-state automata theory to natural language processing},\n volume = {2},\n year = {1996}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fe83c1ddbfddf8ccb0d46fead0ad751a8ecc6d46",
            "@type": "ScholarlyArticle",
            "paperId": "fe83c1ddbfddf8ccb0d46fead0ad751a8ecc6d46",
            "corpusId": 8611016,
            "url": "https://www.semanticscholar.org/paper/fe83c1ddbfddf8ccb0d46fead0ad751a8ecc6d46",
            "title": "Subsymbolic natural language processing - an integrated model of scripts, lexicon, and memory",
            "venue": "Neural network modeling and connectionism",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1993,
            "externalIds": {
                "MAG": "1531988931",
                "DBLP": "books/daglib/0070930",
                "DOI": "10.2307/416074",
                "CorpusId": 8611016
            },
            "abstract": "Risto Miikkulainen draws on recent connectionist work in language comprehension to create a model that can understand natural language. Using the DISCERN system as an example, he describes a general approach to building high-level cognitive models from distributed neural networks and shows how the special properties of such networks are useful in modeling human performance. In this approach connectionist networks are not only plausible models of isolated cognitive phenomena, but also sufficient constituents for complete artificial intelligence systems.Distributed neural networks have been very successful in modeling isolated cognitive phenomena, but complex high-level behavior has been tractable only with symbolic artificial intelligence techniques. Aiming to bridge this gap, Miikkulainen describes DISCERN, a complete natural language processing system implemented entirely at the subsymbolic level. In DISCERN, distributed neural network models of parsing, generating, reasoning, lexical processing, and episodic memory are integrated into a single system that learns to read, paraphrase, and answer questions about stereotypical narratives.Miikkulainen's work, which includes a comprehensive survey of the connectionist literature related to natural language processing, will prove especially valuable to researchers interested in practical techniques for high-level representation, inferencing, memory modeling, and modular connectionist architectures. Risto Miikkulainen is an Assistant Professor in the Department of Computer Sciences at The University of Texas at Austin.",
            "referenceCount": 3,
            "citationCount": 292,
            "influentialCitationCount": 21,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Miikkulainen1993SubsymbolicNL,\n author = {R. Miikkulainen},\n booktitle = {Neural network modeling and connectionism},\n pages = {I-XII, 1-391},\n title = {Subsymbolic natural language processing - an integrated model of scripts, lexicon, and memory},\n year = {1993}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2f00d047edd943d56389678c55175bbbf257cde0",
            "@type": "ScholarlyArticle",
            "paperId": "2f00d047edd943d56389678c55175bbbf257cde0",
            "corpusId": 24656810,
            "url": "https://www.semanticscholar.org/paper/2f00d047edd943d56389678c55175bbbf257cde0",
            "title": "Natural Language Processing in Medicine: An Overview",
            "venue": "Methods of Information in Medicine",
            "publicationVenue": {
                "id": "urn:research:95f5bdab-1f05-4090-899f-3869a15b5707",
                "name": "Methods of Information in Medicine",
                "alternate_names": [
                    "Method Inf Med"
                ],
                "issn": "0026-1270",
                "url": "https://methods.schattauer.de/en/contents/methods-open.html"
            },
            "year": 1996,
            "externalIds": {
                "MAG": "139989439",
                "DOI": "10.1055/s-0038-1634681",
                "CorpusId": 24656810,
                "PubMed": "9019092"
            },
            "abstract": "Abstract: An overview is given of natural language processing applications in medicine. An attempt has been made to enumerate the most important and known international projects and to summarize their goals, principles, methods and results. A section is devoted to projects involving the Dutch language. A more general discussion about the two fundamental approaches concerning medical language understanding is provided. An extensive bibliography may be useful for those wishing to explore this research domain.",
            "referenceCount": 170,
            "citationCount": 155,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "1996-09-01",
            "journal": {
                "name": "Methods of Information in Medicine",
                "volume": "35"
            },
            "citationStyles": {
                "bibtex": "@Article{Spyns1996NaturalLP,\n author = {Peter Spyns},\n booktitle = {Methods of Information in Medicine},\n journal = {Methods of Information in Medicine},\n pages = {285 - 301},\n title = {Natural Language Processing in Medicine: An Overview},\n volume = {35},\n year = {1996}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:93121c6d06b9f26ed89768c9f585f94d1c490465",
            "@type": "ScholarlyArticle",
            "paperId": "93121c6d06b9f26ed89768c9f585f94d1c490465",
            "corpusId": 28294794,
            "url": "https://www.semanticscholar.org/paper/93121c6d06b9f26ed89768c9f585f94d1c490465",
            "title": "Spotting and Discovering Terms through Natural Language Processing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1997,
            "externalIds": {
                "MAG": "1606527432",
                "CorpusId": 28294794
            },
            "abstract": "In this book Christian Jacquemin shows how the power of natural language processing (NLP) can be used to advance text indexing and information retrieval (IR). Jacquemin's novel tool is FASTR, a parser that normalizes terms and recognizes term variants. Since there are more meanings in a language than there are words, FASTR uses a metagrammar composed of shallow linguistic transformations that describe the morphological, syntactic, semantic, and pragmatic variations of words and terms. The acquired parsed terms can then be applied for precise retrieval and assembly of information.The use of a corpus-based unification grammar to define, recognize, and combine term variants from their base forms allows for intelligent information access to, or \"linguistic data tuning\" of, heterogeneous texts. FASTR can be used to do automatic controlled indexing, to carry out content-based Web searches through conceptually related alternative query formulations, to abstract scientific and technical extracts, and even to translate and collect terms from multilingual material. Jacquemin provides a comprehensive account of the method and implementation of this innovative retrieval technique for text processing.",
            "referenceCount": 13,
            "citationCount": 61,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1997-05-19",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Jacquemin1997SpottingAD,\n author = {C. Jacquemin},\n title = {Spotting and Discovering Terms through Natural Language Processing},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:33995b0f996229742b9ca28916c73d51f55766d2",
            "@type": "ScholarlyArticle",
            "paperId": "33995b0f996229742b9ca28916c73d51f55766d2",
            "corpusId": 5982270,
            "url": "https://www.semanticscholar.org/paper/33995b0f996229742b9ca28916c73d51f55766d2",
            "title": "Natural Language Processing With Modular PDP Networks and Distributed Lexicon",
            "venue": "Cognitive Sciences",
            "publicationVenue": {
                "id": "urn:research:c33b01b0-31b4-470e-a9f9-8432e02c3cb9",
                "name": "Cognitive Sciences",
                "alternate_names": [
                    "Cognitive Science",
                    "Cogn Sci"
                ],
                "issn": "1935-8059",
                "url": "http://www.informaworld.com/openurl?genre=journal&issn=1551-6709"
            },
            "year": 1991,
            "externalIds": {
                "DBLP": "journals/cogsci/MikkulainenD91",
                "MAG": "2097009961",
                "DOI": "10.1207/s15516709cog1503_2",
                "CorpusId": 5982270
            },
            "abstract": "An approach to connectionist natural language processing is proposed, which is based on hierarchically organized modular parallel distributed processing (PDP) networks and a central lexicon of distributed input/output representations. The modules communicate using these representations, which are global and publicly available in the system. The representations are developed automatically by all networks while they are learning their processing tasks. The resulting representations reflect the regularities in the subtasks, which facilitates robust processing in the face of noise and damage, supports improved generalization, and provides expectations about possible contexts. The lexicon can be extended by cloning new instances of the items, that is, by generating a number of items with known processing properties and distinct identities. This technique combinatorially increases the processing power of the system. The recurrent FGREP module, together with a central lexicon, is used as a basic building block in modeling higher level natural language tasks. A single module is used to form case-role representations of sentences from word-by-word sequential natural language input. A hierarchical organization of four recurrent FGREP modules (the DISPAR system) is trained to produce fully expanded paraphrases of script-based stories, where unmentioned events and role fillers are inferred.",
            "referenceCount": 68,
            "citationCount": 196,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1207/s15516709cog1503_2",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1991-07-01",
            "journal": {
                "name": "Cogn. Sci.",
                "volume": "15"
            },
            "citationStyles": {
                "bibtex": "@Article{Miikkulainen1991NaturalLP,\n author = {R. Miikkulainen and M. Dyer},\n booktitle = {Cognitive Sciences},\n journal = {Cogn. Sci.},\n pages = {343-399},\n title = {Natural Language Processing With Modular PDP Networks and Distributed Lexicon},\n volume = {15},\n year = {1991}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d0ab0c49bd5f62ca3ebcd5d922d5d6d8faa9339e",
            "@type": "ScholarlyArticle",
            "paperId": "d0ab0c49bd5f62ca3ebcd5d922d5d6d8faa9339e",
            "corpusId": 6554789,
            "url": "https://www.semanticscholar.org/paper/d0ab0c49bd5f62ca3ebcd5d922d5d6d8faa9339e",
            "title": "Research Paper: Representing Information in Patient Reports Using Natural Language Processing and the Extensible Markup Language",
            "venue": "J. Am. Medical Informatics Assoc.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1999,
            "externalIds": {
                "DBLP": "journals/jamia/FriedmanHSL99",
                "MAG": "1534442584",
                "DOI": "10.1136/jamia.1999.0060076",
                "CorpusId": 6554789,
                "PubMed": "9925230"
            },
            "abstract": "OBJECTIVE\nTo design a document model that provides reliable and efficient access to clinical information in patient reports for a broad range of clinical applications, and to implement an automated method using natural language processing that maps textual reports to a form consistent with the model.\n\n\nMETHODS\nA document model that encodes structured clinical information in patient reports while retaining the original contents was designed using the extensible markup language (XML), and a document type definition (DTD) was created. An existing natural language processor (NLP) was modified to generate output consistent with the model. Two hundred reports were processed using the modified NLP system, and the XML output that was generated was validated using an XML validating parser.\n\n\nRESULTS\nThe modified NLP system successfully processed all 200 reports. The output of one report was invalid, and 199 reports were valid XML forms consistent with the DTD.\n\n\nCONCLUSIONS\nNatural language processing can be used to automatically create an enriched document that contains a structured component whose elements are linked to portions of the original textual report. This integrated document model provides a representation where documents containing specific information can be accurately and efficiently retrieved by querying the structured components. If manual review of the documents is desired, the salient information in the original reports can also be identified and highlighted. Using an XML model of tagging provides an additional benefit in that software tools that manipulate XML documents are readily available.",
            "referenceCount": 41,
            "citationCount": 131,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://academic.oup.com/jamia/article-pdf/6/1/76/2206355/6-1-76.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Journal of the American Medical Informatics Association : JAMIA",
                "volume": "6 1"
            },
            "citationStyles": {
                "bibtex": "@Article{Friedman1999ResearchPR,\n author = {C. Friedman and G. Hripcsak and L. Shagina and Hongfang Liu},\n booktitle = {J. Am. Medical Informatics Assoc.},\n journal = {Journal of the American Medical Informatics Association : JAMIA},\n pages = {\n          76-87\n        },\n title = {Research Paper: Representing Information in Patient Reports Using Natural Language Processing and the Extensible Markup Language},\n volume = {6 1},\n year = {1999}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9546e5d6876e843679102bb6b91ebdbb6a45c8ef",
            "@type": "ScholarlyArticle",
            "paperId": "9546e5d6876e843679102bb6b91ebdbb6a45c8ef",
            "corpusId": 13991701,
            "url": "https://www.semanticscholar.org/paper/9546e5d6876e843679102bb6b91ebdbb6a45c8ef",
            "title": "Natural Language Processing and Information Retrieval",
            "venue": "International Summer School on Information Extraction",
            "publicationVenue": {
                "id": "urn:research:bcb642b9-c4dc-439e-b1fa-1ab3ce89d351",
                "name": "International Summer School on Information Extraction",
                "alternate_names": [
                    "SCIE",
                    "Int Summer Sch Inf Extr"
                ],
                "issn": null,
                "url": null
            },
            "year": 1999,
            "externalIds": {
                "MAG": "1658342862",
                "DBLP": "conf/scie/Voorhees99",
                "DOI": "10.1007/3-540-48089-7_3",
                "CorpusId": 13991701
            },
            "abstract": null,
            "referenceCount": 35,
            "citationCount": 70,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Voorhees1999NaturalLP,\n author = {E. Voorhees},\n booktitle = {International Summer School on Information Extraction},\n pages = {32-48},\n title = {Natural Language Processing and Information Retrieval},\n year = {1999}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2e6e282c1c05103d13f17dd9cf4640660256409d",
            "@type": "ScholarlyArticle",
            "paperId": "2e6e282c1c05103d13f17dd9cf4640660256409d",
            "corpusId": 13045218,
            "url": "https://www.semanticscholar.org/paper/2e6e282c1c05103d13f17dd9cf4640660256409d",
            "title": "Language Determination: Natural Language Processing from Scanned Document Images",
            "venue": "Applied Natural Language Processing Conference",
            "publicationVenue": {
                "id": "urn:research:a8d0722b-8d14-4675-ae77-47b7d0e3fd64",
                "name": "Applied Natural Language Processing Conference",
                "alternate_names": [
                    "Conf Appl Nat Lang Process",
                    "Appl Nat Lang Process Conf",
                    "Conference on Applied Natural Language Processing",
                    "ANLP"
                ],
                "issn": null,
                "url": "https://aclweb.org/anthology/venues/anlp/"
            },
            "year": 1994,
            "externalIds": {
                "ACL": "A94-1003",
                "DBLP": "conf/anlp/SibunS94",
                "MAG": "2033814354",
                "DOI": "10.3115/974358.974363",
                "CorpusId": 13045218
            },
            "abstract": "Many documents are available to a computer only as images from paper. However, most natural language processing systems expect their input as character-coded text, which may be difficult or expensive to extract accurately from the page. We describe a method for converting a document image into character shape codes and word shape tokens. We believe that this representation, which is both cheap and robust, is sufficient for many NLP tasks. In this paper, we show that the representation is sufficient for determining which of 23 languages the document is written in, using only a small number of features, with greater than 90% accuracy overall.",
            "referenceCount": 19,
            "citationCount": 66,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1994-10-13",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Sibun1994LanguageDN,\n author = {Penelope Sibun and A. Spitz},\n booktitle = {Applied Natural Language Processing Conference},\n pages = {15-21},\n title = {Language Determination: Natural Language Processing from Scanned Document Images},\n year = {1994}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:02c275d06cf3009a95418aa5d01e506636995a70",
            "@type": "ScholarlyArticle",
            "paperId": "02c275d06cf3009a95418aa5d01e506636995a70",
            "corpusId": 67735781,
            "url": "https://www.semanticscholar.org/paper/02c275d06cf3009a95418aa5d01e506636995a70",
            "title": "Machine Learning and Natural Language Processing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2000,
            "externalIds": {
                "MAG": "23090566",
                "CorpusId": 67735781
            },
            "abstract": "In this report, some collaborative work between the fields of Machine Learning (ML) and Natural Language Processing (NLP) \nis presented. The document is structured in two parts. The first part includes a superficial but comprehensive survey covering \nthe state-of-the-art of machine learning techniques applied to natural language learning tasks. In the second part, a particular \nproblem, namely Word Sense Disambiguation (WSD), is studied in more detail. In doing so, four algorithms for supervised \nlearning, which belong to different families, are compared in a benchmark corpus for the WSD task. Both qualitative and \nquantitative conclusions are drawn.",
            "referenceCount": 218,
            "citationCount": 62,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2000-07-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{M\u00e0rquez2000MachineLA,\n author = {L. M\u00e0rquez},\n title = {Machine Learning and Natural Language Processing},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9779b821f818ce72daf27d5d73d3b4eea9f3036e",
            "@type": "ScholarlyArticle",
            "paperId": "9779b821f818ce72daf27d5d73d3b4eea9f3036e",
            "corpusId": 1964757,
            "url": "https://www.semanticscholar.org/paper/9779b821f818ce72daf27d5d73d3b4eea9f3036e",
            "title": "Decomposable Modeling in Natural Language Processing",
            "venue": "International Conference on Computational Logic",
            "publicationVenue": {
                "id": "urn:research:30a8645d-22d4-42e2-b3f6-304bf4ce3a02",
                "name": "International Conference on Computational Logic",
                "alternate_names": [
                    "CL",
                    "Int Conf Comput Log"
                ],
                "issn": null,
                "url": null
            },
            "year": 1999,
            "externalIds": {
                "MAG": "1495836335",
                "ACL": "J99-2002",
                "DBLP": "journals/coling/BruceW99",
                "CorpusId": 1964757
            },
            "abstract": "In this paper, we describe a framework for developing probabilistic classifiers in natural language processing. Our focus is on formulating models that capture the most important interdependencies among features, to avoid overfitting the data while also characterizing the data well. The class of probability models and the associated inference techniques described here were developed in mathematical statistics, and are widely used in artificial intelligence and applied statistics. Our goal is to make this model selection framework accessible to researchers in NLP, and provide pointers to available software and important references. In addition, we describe how the quality of the three determinants of classifier performance (the features, the form of the model, and the parameter estimates) can be separately evaluated. We also demonstrate the classification performance of these models in a large-scale experiment involving the disambiguation of 34 words taken from the HECTOR word sense corpus (Hanks 1996). In 10-fold cross-validations, the model search procedure performs significantly better than naive Bayes on 6 of the words without being significantly worse on any of them.",
            "referenceCount": 29,
            "citationCount": 55,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1999-06-01",
            "journal": {
                "name": "Comput. Linguistics",
                "volume": "25"
            },
            "citationStyles": {
                "bibtex": "@Article{Bruce1999DecomposableMI,\n author = {Rebecca F. Bruce and J. Wiebe},\n booktitle = {International Conference on Computational Logic},\n journal = {Comput. Linguistics},\n pages = {195-207},\n title = {Decomposable Modeling in Natural Language Processing},\n volume = {25},\n year = {1999}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7857f4d4638f07552459fe23f245aa5ddf8d2927",
            "@type": "ScholarlyArticle",
            "paperId": "7857f4d4638f07552459fe23f245aa5ddf8d2927",
            "corpusId": 21234557,
            "url": "https://www.semanticscholar.org/paper/7857f4d4638f07552459fe23f245aa5ddf8d2927",
            "title": "Identification of findings suspicious for breast cancer based on natural language processing of mammogram reports",
            "venue": "American Medical Informatics Association Annual Symposium",
            "publicationVenue": {
                "id": "urn:research:c9e16b3c-2fdf-4b4c-82bf-5cdf3d3435b7",
                "name": "American Medical Informatics Association Annual Symposium",
                "alternate_names": [
                    "Conference of American Medical Informatics Association",
                    "Am Med Informatics Assoc Annu Symp",
                    "Conf Am Med Informatics Assoc",
                    "AMIA"
                ],
                "issn": null,
                "url": "https://knowledge.amia.org/"
            },
            "year": 1997,
            "externalIds": {
                "MAG": "1523813553",
                "DBLP": "conf/amia/JainF97",
                "CorpusId": 21234557,
                "PubMed": "9357741"
            },
            "abstract": "There is need for encoded data for computerized clinical decision support, but most such data are unavailable as they are in free-text reports. Natural language processing offers one alternative for encoding such data. MedLEE is a natural language processing system which is in routine use for encoding chest radiograph and mammogram reports. In this paper, we study MedLEE's ability to identify mammogram findings suspicious for breast cancer by comparing MedLEE's encoding with a logbook of all suspicious findings maintained by the mammography center. While MedLEE was able to identify all the suspicious findings, it varied in the level of granularity, particularly about the location of the suspicious finding. Thus, natural language processing is a useful technique for encoding mammogram reports in order to detect suspicious findings.",
            "referenceCount": 24,
            "citationCount": 113,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Proceedings : a conference of the American Medical Informatics Association. AMIA Fall Symposium",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Jain1997IdentificationOF,\n author = {N. L. Jain and C. Friedman},\n booktitle = {American Medical Informatics Association Annual Symposium},\n journal = {Proceedings : a conference of the American Medical Informatics Association. AMIA Fall Symposium},\n pages = {\n          829-33\n        },\n title = {Identification of findings suspicious for breast cancer based on natural language processing of mammogram reports},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ac11493e05275258f09e6406a2635752899f074d",
            "@type": "ScholarlyArticle",
            "paperId": "ac11493e05275258f09e6406a2635752899f074d",
            "corpusId": 14390515,
            "url": "https://www.semanticscholar.org/paper/ac11493e05275258f09e6406a2635752899f074d",
            "title": "Inductive Logic Programming for Natural Language Processing",
            "venue": "Inductive Logic Programming Workshop",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1996,
            "externalIds": {
                "MAG": "1843649836",
                "DBLP": "conf/ilp/Mooney96",
                "DOI": "10.1007/3-540-63494-0_45",
                "CorpusId": 14390515
            },
            "abstract": null,
            "referenceCount": 71,
            "citationCount": 74,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "1996-08-26",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Mooney1996InductiveLP,\n author = {R. Mooney},\n booktitle = {Inductive Logic Programming Workshop},\n pages = {3-22},\n title = {Inductive Logic Programming for Natural Language Processing},\n year = {1996}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d51ef575fe2317411b1395dc823a7d1625626864",
            "@type": "ScholarlyArticle",
            "paperId": "d51ef575fe2317411b1395dc823a7d1625626864",
            "corpusId": 13774241,
            "url": "https://www.semanticscholar.org/paper/d51ef575fe2317411b1395dc823a7d1625626864",
            "title": "Natural language processing for information retrieval",
            "venue": "CACM",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1996,
            "externalIds": {
                "MAG": "1970161214",
                "DBLP": "journals/cacm/LewisJ96",
                "DOI": "10.1145/234173.234210",
                "CorpusId": 13774241
            },
            "abstract": "The paper summarizes the essential properties of document retrieval and reviews both conventional practice and research findings, the latter suggesting that simple statistical techniques can be effective. It then considers the new opportunities and challenges presented by the user\u2019s ability to search full text directly (rather than e.g. titles and abstracts), and suggests appropriate approaches to doing this, with a focus on the potential role of natural language processing. The paper also comments on possible connections with data and knowledge retrieval, and concludes by emphasizing the importance of rigorous performance testing.",
            "referenceCount": 41,
            "citationCount": 233,
            "influentialCitationCount": 5,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/234173.234210",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Commun. ACM",
                "volume": "39"
            },
            "citationStyles": {
                "bibtex": "@Article{Lewis1996NaturalLP,\n author = {D. Lewis and Karen Sp\u00e4rck Jones},\n booktitle = {CACM},\n journal = {Commun. ACM},\n pages = {92-101},\n title = {Natural language processing for information retrieval},\n volume = {39},\n year = {1996}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:81b32c389001b301d7043b12a79d30a63bfac980",
            "@type": "ScholarlyArticle",
            "paperId": "81b32c389001b301d7043b12a79d30a63bfac980",
            "corpusId": 7754395,
            "url": "https://www.semanticscholar.org/paper/81b32c389001b301d7043b12a79d30a63bfac980",
            "title": "New trends in natural language processing: statistical natural language processing.",
            "venue": "Proceedings of the National Academy of Sciences of the United States of America",
            "publicationVenue": {
                "id": "urn:research:bb95bf2e-8383-4748-bf9d-d6906d091085",
                "name": "Proceedings of the National Academy of Sciences of the United States of America",
                "alternate_names": [
                    "PNAS",
                    "PNAS online",
                    "Proceedings of the National Academy of Sciences of the United States of America.",
                    "Proc National Acad Sci",
                    "Proceedings of the National Academy of Sciences",
                    "Proc National Acad Sci u s Am"
                ],
                "issn": "0027-8424",
                "url": "https://www.jstor.org/journal/procnatiacadscie"
            },
            "year": 1994,
            "externalIds": {
                "MAG": "2612416190",
                "DOI": "10.1073/PNAS.92.22.10052",
                "CorpusId": 7754395,
                "PubMed": "7479725"
            },
            "abstract": "The field of natural language processing (NLP) has seen a dramatic shift in both research direction and methodology in the past several years. In the past, most work in computational linguistics tended to focus on purely symbolic methods. Recently, more and more work is shifting toward hybrid methods that combine new empirical corpus-based methods, including the use of probabilistic and information-theoretic techniques, with traditional symbolic methods. This work is made possible by the recent availability of linguistic databases that add rich linguistic annotation to corpora of natural language text. Already, these methods have led to a dramatic improvement in the performance of a variety of NLP systems with similar improvement likely in the coming years. This paper focuses on these trends, surveying in particular three areas of recent progress: part-of-speech tagging, stochastic parsing, and lexical semantics.",
            "referenceCount": 9,
            "citationCount": 32,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc40734?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "1994-11-01",
            "journal": {
                "name": "Proceedings of the National Academy of Sciences of the United States of America",
                "volume": "92 22"
            },
            "citationStyles": {
                "bibtex": "@Article{Marcus1994NewTI,\n author = {Mitchell P. Marcus},\n booktitle = {Proceedings of the National Academy of Sciences of the United States of America},\n journal = {Proceedings of the National Academy of Sciences of the United States of America},\n pages = {\n          10052-9\n        },\n title = {New trends in natural language processing: statistical natural language processing.},\n volume = {92 22},\n year = {1994}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e456401ea4e75a30087e1f15b5ef429568c4a28b",
            "@type": "ScholarlyArticle",
            "paperId": "e456401ea4e75a30087e1f15b5ef429568c4a28b",
            "corpusId": 6338334,
            "url": "https://www.semanticscholar.org/paper/e456401ea4e75a30087e1f15b5ef429568c4a28b",
            "title": "Knowledge and natural language processing",
            "venue": "CACM",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1990,
            "externalIds": {
                "DBLP": "journals/cacm/BarnettKMR90",
                "MAG": "2066393862",
                "DOI": "10.1145/79173.79177",
                "CorpusId": 6338334
            },
            "abstract": "KBNL is a knowledge-based natural language processing system that is novel in several ways, including the clean separation it enforces between linguistic knowledge and world knowledge, and its use of knowledge to aid in lexical acquisition. Applications of KBNL include intelligent interfaces, text retrieval, and machine translation.",
            "referenceCount": 54,
            "citationCount": 62,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/79173.79177",
                "status": "CLOSED"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1990-08-01",
            "journal": {
                "name": "Commun. ACM",
                "volume": "33"
            },
            "citationStyles": {
                "bibtex": "@Article{Barnett1990KnowledgeAN,\n author = {Jim Barnett and Kevin Knight and I. Mani and E. Rich},\n booktitle = {CACM},\n journal = {Commun. ACM},\n pages = {50-71},\n title = {Knowledge and natural language processing},\n volume = {33},\n year = {1990}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e05b86cf8be027d689b32da6a29b0410db43e0ba",
            "@type": "ScholarlyArticle",
            "paperId": "e05b86cf8be027d689b32da6a29b0410db43e0ba",
            "corpusId": 63161151,
            "url": "https://www.semanticscholar.org/paper/e05b86cf8be027d689b32da6a29b0410db43e0ba",
            "title": "Connectionist Natural Language Processing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1992,
            "externalIds": {
                "MAG": "2476701415",
                "DOI": "10.1007/978-94-011-2624-3",
                "CorpusId": 63161151
            },
            "abstract": null,
            "referenceCount": 52,
            "citationCount": 51,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Philosophy",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1992-05-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Sharkey1992ConnectionistNL,\n author = {N. Sharkey},\n title = {Connectionist Natural Language Processing},\n year = {1992}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a84e6ad289428e03579995ad1ee459b6e0119383",
            "@type": "ScholarlyArticle",
            "paperId": "a84e6ad289428e03579995ad1ee459b6e0119383",
            "corpusId": 2597422,
            "url": "https://www.semanticscholar.org/paper/a84e6ad289428e03579995ad1ee459b6e0119383",
            "title": "Commercial applications of natural language processing",
            "venue": "CACM",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1995,
            "externalIds": {
                "DBLP": "journals/cacm/ChurchR95",
                "MAG": "2030458294",
                "DOI": "10.1145/219717.219778",
                "CorpusId": 2597422
            },
            "abstract": "Vast quantities of text are becoming available in electronic form, ranging from published documents (e.g., electronic dictionaries, encyclopedias, libraries and archives for information retrieval services), to private databases (e.g., marketing information, legal records, medical histories), to personal email and faxes. Online information services are reaching mainstream computer users. There were over 15 million Internet users in 1993, and projections are for 30 million in 1997. With media attention reaching all-time highs, hardly a day goes by without a new article on the National Information Infrastructure, digital libraries, networked services, digital convergence or intelligent agents. This attention is moving natural language processing along the critical path for all kinds of novel applications.",
            "referenceCount": 23,
            "citationCount": 52,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/219717.219778",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Business",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1995-11-01",
            "journal": {
                "name": "Commun. ACM",
                "volume": "38"
            },
            "citationStyles": {
                "bibtex": "@Article{Church1995CommercialAO,\n author = {Kenneth Ward Church and L. Rau},\n booktitle = {CACM},\n journal = {Commun. ACM},\n pages = {71-79},\n title = {Commercial applications of natural language processing},\n volume = {38},\n year = {1995}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9ec721aa29260617eb9e3dd287aa72e83f0b8069",
            "@type": "ScholarlyArticle",
            "paperId": "9ec721aa29260617eb9e3dd287aa72e83f0b8069",
            "corpusId": 60849773,
            "url": "https://www.semanticscholar.org/paper/9ec721aa29260617eb9e3dd287aa72e83f0b8069",
            "title": "Paradigm merger in natural language processing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1996,
            "externalIds": {
                "MAG": "1586946436",
                "DOI": "10.1017/CBO9780511605611.007",
                "CorpusId": 60849773
            },
            "abstract": "This chapter considers the revolution that has taken place in natural language processing research over the last ve years. It begins by providing a brief guide to the structure of the eld and then presents a caricature of two competing paradigms of 1980s NLP research and indicates the reasons why many of those involved have now seen t to abandon them in their pure forms. Attention is then directed to the lexicon, a component of NLP systems which started out as Cinderella but which has nally arrived at the ball. This brings us to an account of what has been going on in the eld most recently, namely a merging of the two 1980s paradigms in a way that is generating a host of interesting new research questions. The chapter concludes by trying to identify some of the key conceptual, empirical and formal issues that now stand in need of resolution.",
            "referenceCount": 31,
            "citationCount": 46,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1996-12-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Gazdar1996ParadigmMI,\n author = {G. Gazdar},\n pages = {88-109},\n title = {Paradigm merger in natural language processing},\n year = {1996}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:72b0fd47c175b940290501a58780d98cfa5d5a09",
            "@type": "ScholarlyArticle",
            "paperId": "72b0fd47c175b940290501a58780d98cfa5d5a09",
            "corpusId": 14122119,
            "url": "https://www.semanticscholar.org/paper/72b0fd47c175b940290501a58780d98cfa5d5a09",
            "title": "Workshop on the Evaluation of Natural Language Processing Systems",
            "venue": "International Conference on Computational Logic",
            "publicationVenue": {
                "id": "urn:research:30a8645d-22d4-42e2-b3f6-304bf4ce3a02",
                "name": "International Conference on Computational Logic",
                "alternate_names": [
                    "CL",
                    "Int Conf Comput Log"
                ],
                "issn": null,
                "url": null
            },
            "year": 1990,
            "externalIds": {
                "MAG": "2144845931",
                "ACL": "J90-3005",
                "DBLP": "journals/coling/PalmerF90",
                "CorpusId": 14122119
            },
            "abstract": "In the past few years, the computational linguistics research community has begun to wrestle with the problem of how to evaluate its progress in developing natural language processing systems. With the exception of natural language interfaces, there are few working systems in existence, and they tend to focus on very different tasks using equally different techniques. There has been little agreement in the field about training sets and test sets, or about clearly defined subsets of problems that constitute standards for different levels of performance. Even those groups that have attempted a measure of self-evaluation have often been reduced to discussing a system's performance in isolation---comparing its current performance to its previous performance rather than to another system. As this technology begins to move slowly into the marketplace, the lack of useful evaluation techniques is becoming more and more painfully obvious. In order to make progress in the difficult area of natural language evaluation, a Workshop on the Evaluation of Natural Language Processing Systems was held on December 7-9, 1988 at the Wayne Hotel in Wayne, Pennsylvania. The workshop was organized by Martha Palmer (Unisys), assisted by a program committee consisting of Beth Sundheim (NOSC), Ed Hovy (ISI), Tim Finin (Unisys), Lynn Bates (BBN), and Mitch Marcus (Pennsylvania). Approximately 50 people participated, drawn from universities, industry, and government. The workshop received the generous support of the Rome Air Defense Center, the Association of Computational Linguistics, the American Association of Artificial Intelligence, and Unisys Defense Systems. The workshop was organized along two basic premises. First, it should be possible to discuss system evaluation in general without having to state whether the purpose of the system is \"question-answering\" or \"text processing.\" Evaluating a system requires the definition of an application task in terms of input/output pairs that are equally applicable to question-answering, text processing, or generation. Second, there are two basic types of evaluation, black-box evaluation, which measures system performance on a given task in terms of well-defined input/output pairs, and glassbox evaluation, which examines the internal workings of the system. For example, glass-box performance evaluation for a system that is supposed to perform semantic and pragmatic analysis should include the examination of predicate-argument relations, referents, and temporal and causal relations. Since there are many different stages of development that a natural language system passes through before it is in a state where black-box evaluation is even possible (see Figure 1), glass-box evaluation plays an especially important role in guiding the development at early stages. With these premises in mind, the workshop was structured around the following three sessions: (i) defining the notions of \"black-box evaluat ion\" and \"glass-box evaluation\" and exploring their utility; (ii) defining criteria for \"black-box evaluation\"; and (iii) defining criteria for \"glass-box evaluation.\" It was hoped that the workshop would shed light on the following questions.",
            "referenceCount": 7,
            "citationCount": 49,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1990-09-01",
            "journal": {
                "name": "Comput. Linguistics",
                "volume": "16"
            },
            "citationStyles": {
                "bibtex": "@Article{Palmer1990WorkshopOT,\n author = {Martha Palmer and Timothy W. Finin},\n booktitle = {International Conference on Computational Logic},\n journal = {Comput. Linguistics},\n pages = {175-181},\n title = {Workshop on the Evaluation of Natural Language Processing Systems},\n volume = {16},\n year = {1990}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:77ce9f4b1caae416cde3ebfc3059508c8c5b04fd",
            "@type": "ScholarlyArticle",
            "paperId": "77ce9f4b1caae416cde3ebfc3059508c8c5b04fd",
            "corpusId": 14803914,
            "url": "https://www.semanticscholar.org/paper/77ce9f4b1caae416cde3ebfc3059508c8c5b04fd",
            "title": "Review of Natural Language Processing in",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2001,
            "externalIds": {
                "CorpusId": 14803914
            },
            "abstract": "The MIT Encyclopedia of the Cognitive Sciences (MITECS) is the first encyclopedia in cognitive sciences\u2014a web-navigable resource with invaluable information and several hundred links to related resources. The material provided therein is thorough and very clearly presented by the leading scientists in each area. This is one of the most comprehensive resources in cognitive science to date. It will serve as a teaching and research guide that users may frequently refer to for important definitions, background information, and citations to relevant literature. This review covers areas relevant to Natural Language Processing (NLP), in particular, the entries entitled \u201cNatural Language Processing\u201d (James Allen), \u201cComputational Linguistics\u201d (Aravind Joshi), \u201cGeneration\u201d and \u201cMachine Translation\u201d (both by Eduard Hovy), \u201cComputational Lexicons\u201d (James Pustejovsky), and \u201cStatistical Techniques\u201d (Eugene Charniak). I will also address issues concerning the use of MITECS as an online, web-navigable document.",
            "referenceCount": 7,
            "citationCount": 34,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Wilson2001ReviewON,\n author = {R. A. Wilson and F. Keil and B. Dorr},\n title = {Review of Natural Language Processing in},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f5d2fcac3dd05bf483a53bbaedbaf9d1682f6621",
            "@type": "ScholarlyArticle",
            "paperId": "f5d2fcac3dd05bf483a53bbaedbaf9d1682f6621",
            "corpusId": 60985550,
            "url": "https://www.semanticscholar.org/paper/f5d2fcac3dd05bf483a53bbaedbaf9d1682f6621",
            "title": "Lexical Issues in Natural Language Processing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1991,
            "externalIds": {
                "MAG": "1482735081",
                "DOI": "10.1007/978-3-642-77189-7_4",
                "CorpusId": 60985550
            },
            "abstract": null,
            "referenceCount": 47,
            "citationCount": 55,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Briscoe1991LexicalII,\n author = {Ted Briscoe},\n pages = {39-68},\n title = {Lexical Issues in Natural Language Processing},\n year = {1991}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7dc5abed84cfbaa4638f0aa3e9bd05b3582900ba",
            "@type": "ScholarlyArticle",
            "paperId": "7dc5abed84cfbaa4638f0aa3e9bd05b3582900ba",
            "corpusId": 62618150,
            "url": "https://www.semanticscholar.org/paper/7dc5abed84cfbaa4638f0aa3e9bd05b3582900ba",
            "title": "Foundational issues in natural language processing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1991,
            "externalIds": {
                "MAG": "2078853228",
                "DOI": "10.2307/416008",
                "CorpusId": 62618150
            },
            "abstract": "In four separate essays the authors address the complex and difficult connections among grammatical theory, mathematical linguistics, and the operation of real natural-language-processing systems, both human and electronic. The editors' introduction details the progress and problems involved in attempts to relate these four areas of research. William Rounds discusses the relevance of complexity results to linguistics and computational linguistics, providing useful caveats about how results might be misinterpreted and pointing out promising avenues of future research. Avarind Joshi (with K. Vijay-Shanker and David Weir) surveys results showing the equivalence of several different grammatical formalisms, all of which are mildly context-sensitive, with special attention to variants of tree adjoining grammar. Janet Fodor discusses how psycholinguistics results can bear on the choice among competing grammatical theories, surveying a number of recent experiments and their relevance to issues in grammatical theory. Robert Berwick considers the relationships between issues in linguistic theory and the construction of computational parsing issues, in particular the question of what it means to implement a theory of grammar in a computational system. He argues for the advantages of a principle-based approach over a rule-based one, and surveys several recent parsing systems based on the theory of government and binding.",
            "referenceCount": 0,
            "citationCount": 60,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "1991-09-01",
            "journal": {
                "name": "Language",
                "volume": "71"
            },
            "citationStyles": {
                "bibtex": "@Article{Sells1991FoundationalII,\n author = {P. Sells and S. Shieber and T. Wasow},\n journal = {Language},\n pages = {210},\n title = {Foundational issues in natural language processing},\n volume = {71},\n year = {1991}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ac36a57d66f34ddf8b021498528610e0e87a9a3c",
            "@type": "ScholarlyArticle",
            "paperId": "ac36a57d66f34ddf8b021498528610e0e87a9a3c",
            "corpusId": 974288,
            "url": "https://www.semanticscholar.org/paper/ac36a57d66f34ddf8b021498528610e0e87a9a3c",
            "title": "Analogical natural language processing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1996,
            "externalIds": {
                "MAG": "1566719589",
                "CorpusId": 974288
            },
            "abstract": "The use of examples as the basis for machine translation systems has been a major feature of the last decade's research. Developments in this fertile area are described in \"analogical natural language processing\" with a thorough discussion of their theoretical and practical implications. The book outlines the fundamental concepts which distinguish example-based (or analogical) processing from the traditional rule-based approach. New concepts such as \"cloning\" and \"recombination\" are introduced as processes unique to the new paradigm. Some of the new ideas are demonstrated in a series of practical computational experiments which further elucidate the book's central concepts and framework. This book is intended for postgraduate and research level in machine translation and computational linguistics.",
            "referenceCount": 8,
            "citationCount": 44,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Jones1996AnalogicalNL,\n author = {Daniel B. Jones},\n title = {Analogical natural language processing},\n year = {1996}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d9148eab56e4a4168e08b6e5680a9cbe836b2843",
            "@type": "ScholarlyArticle",
            "paperId": "d9148eab56e4a4168e08b6e5680a9cbe836b2843",
            "corpusId": 17585795,
            "url": "https://www.semanticscholar.org/paper/d9148eab56e4a4168e08b6e5680a9cbe836b2843",
            "title": "Test Suites for Natural Language Processing",
            "venue": "TC",
            "publicationVenue": {
                "id": "urn:research:9eda6087-dbf9-47d3-b8c0-046d2a1138c8",
                "name": "TC",
                "alternate_names": [
                    "TC"
                ],
                "issn": "1089-7747",
                "url": "http://rosetta.reltech.org/TC/index.html#page=home"
            },
            "year": 1995,
            "externalIds": {
                "MAG": "65963940",
                "ACL": "1994.tc-1.5",
                "DOI": "10.1108/EB051385",
                "CorpusId": 17585795
            },
            "abstract": "This paper introduces the topic of evaluation of natural language processing systems, and discusses the role of test suites in the linguistic evaluation of a system. The work on test suites that is being carried out within the framework of the TSNLP project is described in detail and the relevance of the project to the evaluation of machine translation systems considered.",
            "referenceCount": 7,
            "citationCount": 39,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1995-04-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Balkan1995TestSF,\n author = {Lorna Balkan and D. Arnold and Siety Meije},\n booktitle = {TC},\n title = {Test Suites for Natural Language Processing},\n year = {1995}\n}\n"
            }
        }
    }
]