[
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:75a5cc26846399493355a3c6b82e5d38f9e3bfaf",
            "@type": "ScholarlyArticle",
            "paperId": "75a5cc26846399493355a3c6b82e5d38f9e3bfaf",
            "corpusId": 60683767,
            "url": "https://www.semanticscholar.org/paper/75a5cc26846399493355a3c6b82e5d38f9e3bfaf",
            "title": "Essentials of language documentation",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2006,
            "externalIds": {
                "MAG": "1486697269",
                "DOI": "10.1515/9783110197730",
                "CorpusId": 60683767
            },
            "abstract": "Language documentation is a rapidly emerging new field in linguistics which is concerned with the methods, tools and theoretical underpinnings for compiling a representative and lasting multipurpose record of a natural language. This volume presents in-depth introductions to major aspects of language documentation, including overviews on fieldwork ethics and data processing, guidelines for the basic annotation of digitally-stored multimedia corpora and a discussion on how to build and maintain a language archive. It combines theoretical and practical considerations and makes specific suggestions for the most common problems encountered in language documentation. Key features textbook introduction to Language Documentation considers all common problems",
            "referenceCount": 0,
            "citationCount": 249,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2006-01-15",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Gippert2006EssentialsOL,\n author = {Jost Gippert and N. Himmelmann and U. Mosel},\n title = {Essentials of language documentation},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:73c624fe634ac0ecfc85bffdca6f6c4c8815aaba",
            "@type": "ScholarlyArticle",
            "paperId": "73c624fe634ac0ecfc85bffdca6f6c4c8815aaba",
            "corpusId": 90386209,
            "url": "https://www.semanticscholar.org/paper/73c624fe634ac0ecfc85bffdca6f6c4c8815aaba",
            "title": "User's guide to the Delta system: a general system for processing taxonomic descriptions",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1993,
            "externalIds": {
                "MAG": "2615910529",
                "CorpusId": 90386209
            },
            "abstract": "The DELTA system is a flexible data-coding format for taxonomic descriptions, and an associated set of programs for producing and typesetting natural-language descriptions and keys, for interactive identification and information retrieval, and for conversion of the data to formats required for phylogenetic and phenetic analysis. This manual is a comprehensive guide to the data format and the program directives.",
            "referenceCount": 64,
            "citationCount": 344,
            "influentialCitationCount": 19,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Biology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Dallwitz1993UsersGT,\n author = {M. Dallwitz and T. A. Paine and E. Zurcher},\n title = {User's guide to the Delta system: a general system for processing taxonomic descriptions},\n year = {1993}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:77797389d163e1633cb86616b724a35f8b31a293",
            "@type": "ScholarlyArticle",
            "paperId": "77797389d163e1633cb86616b724a35f8b31a293",
            "corpusId": 58952135,
            "url": "https://www.semanticscholar.org/paper/77797389d163e1633cb86616b724a35f8b31a293",
            "title": "Law and Word Order: NLP in Legal Tech",
            "venue": "Natural Language Engineering",
            "publicationVenue": {
                "id": "urn:research:b0dc264e-1ef6-4c58-be54-d2e6137ac35f",
                "name": "Natural Language Engineering",
                "alternate_names": [
                    "Nat Lang Eng"
                ],
                "issn": "1351-3249",
                "url": "https://www.cambridge.org/core/journals/natural-language-engineering"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2904226672",
                "DBLP": "journals/nle/Dale19",
                "DOI": "10.1017/S1351324918000475",
                "CorpusId": 58952135
            },
            "abstract": "Abstract The law has language at its heart, so it\u2019s not surprising that software that operates on natural language has played a role in some areas of the legal profession for a long time. But the last few years have seen an increased interest in applying modern techniques to a wider range of problems, so I look here at how natural language processing is being used in the legal sector today.",
            "referenceCount": 3,
            "citationCount": 61,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/E8CC6743F2FCCFD29FBC16A82F7F9B2A/S1351324918000475a.pdf/div-class-title-law-and-word-order-nlp-in-legal-tech-div.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Law",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-12-19",
            "journal": {
                "name": "Natural Language Engineering",
                "volume": "25"
            },
            "citationStyles": {
                "bibtex": "@Article{Dale2018LawAW,\n author = {R. Dale},\n booktitle = {Natural Language Engineering},\n journal = {Natural Language Engineering},\n pages = {211 - 217},\n title = {Law and Word Order: NLP in Legal Tech},\n volume = {25},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9dcf566fa1515896ac7df2c6ff4b158536cc584f",
            "@type": "ScholarlyArticle",
            "paperId": "9dcf566fa1515896ac7df2c6ff4b158536cc584f",
            "corpusId": 1105,
            "url": "https://www.semanticscholar.org/paper/9dcf566fa1515896ac7df2c6ff4b158536cc584f",
            "title": "More accurate tests for the statistical significance of result differences",
            "venue": "International Conference on Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:f51ff783-cdff-4e22-94fb-28e6336d17b3",
                "name": "International Conference on Computational Linguistics",
                "alternate_names": [
                    "Int Conf Comput Linguistics",
                    "COLING"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/coling/"
            },
            "year": 2000,
            "externalIds": {
                "DBLP": "journals/corr/cs-CL-0008005",
                "ACL": "C00-2137",
                "MAG": "2057399676",
                "ArXiv": "cs/0008005",
                "DOI": "10.3115/992730.992783",
                "CorpusId": 1105
            },
            "abstract": "Statistical significance testing of differences in values of metrics like recall, precision and balanced F-score is a necessary part of empirical natural language processing. Unfortunately, we find in a set of experiments that many commonly used tests often underestimate the significance and so are less likely to detect differences that exist between different techniques. This underestimation comes from an independence assumption that is often violated. We point out some useful tests that do not make this assumption, including computationally-intensive randomization tests.",
            "referenceCount": 9,
            "citationCount": 452,
            "influentialCitationCount": 41,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://dl.acm.org/ft_gateway.cfm?id=992783&type=pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2000-07-31",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yeh2000MoreAT,\n author = {A. Yeh},\n booktitle = {International Conference on Computational Linguistics},\n pages = {947-953},\n title = {More accurate tests for the statistical significance of result differences},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:daa9afe2865446b553c95c14ebc241288e7a87cb",
            "@type": "ScholarlyArticle",
            "paperId": "daa9afe2865446b553c95c14ebc241288e7a87cb",
            "corpusId": 7187022,
            "url": "https://www.semanticscholar.org/paper/daa9afe2865446b553c95c14ebc241288e7a87cb",
            "title": "Directional distributional similarity for lexical inference",
            "venue": "Natural Language Engineering",
            "publicationVenue": {
                "id": "urn:research:b0dc264e-1ef6-4c58-be54-d2e6137ac35f",
                "name": "Natural Language Engineering",
                "alternate_names": [
                    "Nat Lang Eng"
                ],
                "issn": "1351-3249",
                "url": "https://www.cambridge.org/core/journals/natural-language-engineering"
            },
            "year": 2010,
            "externalIds": {
                "DBLP": "journals/nle/KotlermanDSZ10",
                "MAG": "2131253837",
                "DOI": "10.1017/S1351324910000124",
                "CorpusId": 7187022
            },
            "abstract": "Abstract Distributional word similarity is most commonly perceived as a symmetric relation. Yet, directional relations are abundant in lexical semantics and in many Natural Language Processing (NLP) settings that require lexical inference, making symmetric similarity measures less suitable for their identification. This paper investigates the nature of directional (asymmetric) similarity measures that aim to quantify distributional feature inclusion. We identify desired properties of such measures for lexical inference, specify a particular measure based on Average Precision that addresses these properties, and demonstrate the empirical benefit of directional measures for two different NLP datasets.",
            "referenceCount": 77,
            "citationCount": 234,
            "influentialCitationCount": 36,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2010-10-01",
            "journal": {
                "name": "Natural Language Engineering",
                "volume": "16"
            },
            "citationStyles": {
                "bibtex": "@Article{Kotlerman2010DirectionalDS,\n author = {Lili Kotlerman and Ido Dagan and Idan Szpektor and M. Zhitomirsky-Geffet},\n booktitle = {Natural Language Engineering},\n journal = {Natural Language Engineering},\n pages = {359 - 389},\n title = {Directional distributional similarity for lexical inference},\n volume = {16},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:842be243e20b5338a3709d56284bee378b30d8bc",
            "@type": "ScholarlyArticle",
            "paperId": "842be243e20b5338a3709d56284bee378b30d8bc",
            "corpusId": 1889,
            "url": "https://www.semanticscholar.org/paper/842be243e20b5338a3709d56284bee378b30d8bc",
            "title": "Weighted Automata in Text and Speech Processing",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2005,
            "externalIds": {
                "MAG": "2949108156",
                "ArXiv": "cs/0503077",
                "DBLP": "journals/corr/abs-cs-0503077",
                "CorpusId": 1889
            },
            "abstract": "Finite-state automata are a very effective tool in natural language processing. However, in a variety of applications and especially in speech precessing, it is necessary to consider more general machines in which arcs are assigned weights or costs. We briefly describe some of the main theoretical and algorithmic aspects of these machines. In particular, we describe an efficient composition algorithm for weighted transducers, and give examples illustrating the value of determinization and minimization algorithms for weighted automata.",
            "referenceCount": 16,
            "citationCount": 158,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2005-03-28",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/cs/0503077"
            },
            "citationStyles": {
                "bibtex": "@Article{Mohri2005WeightedAI,\n author = {Mehryar Mohri and Fernando C Pereira and M. Riley},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Weighted Automata in Text and Speech Processing},\n volume = {abs/cs/0503077},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8dfdedcbeb3b67ecaa4d85ca4b9d1aff368b8e2a",
            "@type": "ScholarlyArticle",
            "paperId": "8dfdedcbeb3b67ecaa4d85ca4b9d1aff368b8e2a",
            "corpusId": 3598758,
            "url": "https://www.semanticscholar.org/paper/8dfdedcbeb3b67ecaa4d85ca4b9d1aff368b8e2a",
            "title": "Better k-best Parsing",
            "venue": "International Workshop/Conference on Parsing Technologies",
            "publicationVenue": {
                "id": "urn:research:da061299-efba-4911-bbd8-90372f62ffed",
                "name": "International Workshop/Conference on Parsing Technologies",
                "alternate_names": [
                    "Int Work Parsing Technol",
                    "IWPT"
                ],
                "issn": null,
                "url": "http://parlevink.cs.utwente.nl/sigparse/"
            },
            "year": 2005,
            "externalIds": {
                "DBLP": "conf/iwpt/HuangC05",
                "ACL": "W05-1506",
                "MAG": "2037894654",
                "DOI": "10.3115/1654494.1654500",
                "CorpusId": 3598758
            },
            "abstract": "We discuss the relevance of k-best parsing to recent applications in natural language processing, and develop efficient algorithms for k-best trees in the framework of hypergraph parsing. To demonstrate the efficiency, scalability and accuracy of these algorithms, we present experiments on Bikel's implementation of Collins' lexicalized PCFG model, and on Chiang's CFG-based decoder for hierarchical phrase-based translation. We show in particular how the improved output of our algorithms has the potential to improve results from parse reranking systems and other applications.",
            "referenceCount": 41,
            "citationCount": 375,
            "influentialCitationCount": 41,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.5555/1654494.1654500",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2005-10-09",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Huang2005BetterKP,\n author = {Liang Huang and David Chiang},\n booktitle = {International Workshop/Conference on Parsing Technologies},\n pages = {53-64},\n title = {Better k-best Parsing},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5ab34e1e0d79aa09ebfd85c9f70236093b3a978d",
            "@type": "ScholarlyArticle",
            "paperId": "5ab34e1e0d79aa09ebfd85c9f70236093b3a978d",
            "corpusId": 14289503,
            "url": "https://www.semanticscholar.org/paper/5ab34e1e0d79aa09ebfd85c9f70236093b3a978d",
            "title": "EDGAR: extraction of drugs, genes and relations from the biomedical literature.",
            "venue": "Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing",
            "publicationVenue": {
                "id": "urn:research:36c06bc2-aa20-4634-bce8-9ca08e27fded",
                "name": "Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing",
                "alternate_names": [
                    "Pac Symp Biocomput Pac Symp Biocomput"
                ],
                "issn": "2335-6928",
                "url": null
            },
            "year": 1999,
            "externalIds": {
                "MAG": "2023736097",
                "DOI": "10.1142/9789814447331_0049",
                "CorpusId": 14289503,
                "PubMed": "10902199"
            },
            "abstract": "EDGAR (Extraction of Drugs, Genes and Relations) is a natural language processing system that extracts information about drugs and genes relevant to cancer from the biomedical literature. This automatically extracted information has remarkable potential to facilitate computational analysis in the molecular biology of cancer, and the technology is straightforwardly generalizable to many areas of biomedicine. This paper reports on the mechanisms for automatically generating such assertions and on a simple application, conceptual clustering of documents. The system uses a stochastic part of speech tagger, generates an underspecified syntactic parse and then uses semantic and pragmatic information to construct its assertions. The system builds on two important existing resources: the MEDLINE database of biomedical citations and abstracts and the Unified Medical Language System, which provides syntactic and semantic information about the terms found in biomedical abstracts.",
            "referenceCount": 33,
            "citationCount": 488,
            "influentialCitationCount": 16,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc2709525?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1999-12-01",
            "journal": {
                "name": "Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Rindflesch1999EDGAREO,\n author = {T. Rindflesch and L. Tanabe and J. Weinstein and L. Hunter},\n booktitle = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},\n journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},\n pages = {\n          517-28\n        },\n title = {EDGAR: extraction of drugs, genes and relations from the biomedical literature.},\n year = {1999}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:431bed4efc485e17f7c7854c2c6ac1b9fdaf6966",
            "@type": "ScholarlyArticle",
            "paperId": "431bed4efc485e17f7c7854c2c6ac1b9fdaf6966",
            "corpusId": 11930550,
            "url": "https://www.semanticscholar.org/paper/431bed4efc485e17f7c7854c2c6ac1b9fdaf6966",
            "title": "Statistical language learning",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1995,
            "externalIds": {
                "MAG": "1994851566",
                "DBLP": "books/daglib/0080794",
                "ArXiv": "cmp-lg/9506019",
                "DOI": "10.2307/2291039",
                "CorpusId": 11930550
            },
            "abstract": "From the Publisher: \nEugene Charniak breaks new ground in artificial intelligence research by presenting statistical language processing from an artificial intelligence point of view in a text for researchers and scientists with a traditional computer science background. \nNew, exacting empirical methods are needed to break the deadlock in such areas of artificial intelligence as robotics, knowledge representation, machine learning, machine translation, and natural language processing (NLP). It is time, Charniak observes, to switch paradigms. This text introduces statistical language processing techniques -- word tagging, parsing with probabilistic context free grammars, grammar induction, syntactic disambiguation, semantic word classes, word-sense disambiguation -- along with the underlying mathematics and chapter exercises. \nCharniak points out that as a method of attacking NLP problems, the statistical approach has several advantages. It is grounded in real text and therefore promises to produce usable results, and it offers an obvious way to approach learning: \"one simply gathers statistics.\" \nLanguage, Speech, and Communication",
            "referenceCount": 28,
            "citationCount": 275,
            "influentialCitationCount": 19,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1995-06-21",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Charniak1995StatisticalLL,\n author = {Eugene Charniak},\n pages = {I-XX, 1-170},\n title = {Statistical language learning},\n year = {1995}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:be73d7737cb7c8a8ce1b7f65f65c6f71d74d1bc0",
            "@type": "ScholarlyArticle",
            "paperId": "be73d7737cb7c8a8ce1b7f65f65c6f71d74d1bc0",
            "corpusId": 19846599,
            "url": "https://www.semanticscholar.org/paper/be73d7737cb7c8a8ce1b7f65f65c6f71d74d1bc0",
            "title": "On building a more effcient grammar by exploiting types",
            "venue": "Natural Language Engineering",
            "publicationVenue": {
                "id": "urn:research:b0dc264e-1ef6-4c58-be54-d2e6137ac35f",
                "name": "Natural Language Engineering",
                "alternate_names": [
                    "Nat Lang Eng"
                ],
                "issn": "1351-3249",
                "url": "https://www.cambridge.org/core/journals/natural-language-engineering"
            },
            "year": 2000,
            "externalIds": {
                "DBLP": "journals/nle/Flickinger00",
                "MAG": "2096871981",
                "DOI": "10.1017/S1351324900002370",
                "CorpusId": 19846599
            },
            "abstract": "Modern grammar development platforms often support multiple devices for representing properties of a natural language, giving the grammar writer some freedom in implementing analyses of linguistic phenomena. These design alternatives can have dramatic consequences for efficiency both in processing and in grammar building. In this paper I report on three experiments in making systematic modifications to a broad-coverage grammar of English in order to gain efficiency without loss of linguistic elegance. While the experiments are to some degree both platform-dependant and theory-bound, the kinds of modifications reported should be applicable to any unification-based grammar which makes use of types. The results make a strong case for a more visible role for the linguist in the collaborative effort to achieve greater processing efficiency.",
            "referenceCount": 36,
            "citationCount": 437,
            "influentialCitationCount": 77,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2000-03-01",
            "journal": {
                "name": "Natural Language Engineering",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Flickinger2000OnBA,\n author = {D. Flickinger},\n booktitle = {Natural Language Engineering},\n journal = {Natural Language Engineering},\n pages = {15 - 28},\n title = {On building a more effcient grammar by exploiting types},\n volume = {6},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a55046619a037e03b13d12c025fdbbc4cc782f91",
            "@type": "ScholarlyArticle",
            "paperId": "a55046619a037e03b13d12c025fdbbc4cc782f91",
            "corpusId": 62764453,
            "url": "https://www.semanticscholar.org/paper/a55046619a037e03b13d12c025fdbbc4cc782f91",
            "title": "Audiovisual speech processing",
            "venue": "IEEE Signal Processing Magazine",
            "publicationVenue": {
                "id": "urn:research:f62e5eab-173a-4e0a-a963-ed8de9835d22",
                "name": "IEEE Signal Processing Magazine",
                "alternate_names": [
                    "IEEE Signal Process Mag"
                ],
                "issn": "1053-5888",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=79"
            },
            "year": 2001,
            "externalIds": {
                "MAG": "2083792893",
                "DBLP": "journals/spm/Chen01",
                "DOI": "10.1109/79.911195",
                "CorpusId": 62764453
            },
            "abstract": "We have reported activities in audiovisual speech processing, with emphasis on lip reading and lip synchronization. These research results have shown that, with lip reading, it is possible to enhance the reliability of audio speech recognition, which may result in a computer that can truly understand the user via hand-free natural spoken language even in a very noisy environments. Similarly, with lip synchronization, it is possible to render realistic talking heads with lip movements synchronized with the voice, which is very useful for human-computer interactions. We envision that in the near future, advancement in audiovisual speech processing will greatly increase the usability of computers. Once that happens, the cameras and the microphone may replace the keyboard and the mouse as better mechanisms for human-computer interaction.",
            "referenceCount": 50,
            "citationCount": 247,
            "influentialCitationCount": 15,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "IEEE Signal Process. Mag.",
                "volume": "18"
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2001AudiovisualSP,\n author = {Tsuhan Chen},\n booktitle = {IEEE Signal Processing Magazine},\n journal = {IEEE Signal Process. Mag.},\n pages = {9-21},\n title = {Audiovisual speech processing},\n volume = {18},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a0968b29aa9d4d5aae6456d7c1dbbe62fbfa9b0d",
            "@type": "ScholarlyArticle",
            "paperId": "a0968b29aa9d4d5aae6456d7c1dbbe62fbfa9b0d",
            "corpusId": 3643309,
            "url": "https://www.semanticscholar.org/paper/a0968b29aa9d4d5aae6456d7c1dbbe62fbfa9b0d",
            "title": "A Closer Look at Skip-gram Modelling",
            "venue": "International Conference on Language Resources and Evaluation",
            "publicationVenue": {
                "id": "urn:research:7474c4a0-75d9-4105-9809-8e7d5201c5e1",
                "name": "International Conference on Language Resources and Evaluation",
                "alternate_names": [
                    "LREC",
                    "Int Conf Lang Resour Evaluation"
                ],
                "issn": null,
                "url": "http://www.lrec-conf.org/"
            },
            "year": 2006,
            "externalIds": {
                "MAG": "2759336060",
                "ACL": "L06-1210",
                "DBLP": "conf/lrec/GuthrieA0GW06",
                "CorpusId": 3643309
            },
            "abstract": "Data sparsity is a large problem in natural language processing that refers to the fact that language is a system of rare events, so varied and complex, that even using an extremely large corpus, we can never accurately model all possible strings of words. This paper examines the use of skip-grams (a technique where by n-grams are still stored to model language, but they allow for tokens to be skipped) to overcome the data sparsity problem. We analyze this by computing all possible skip-grams in a training corpus and measure how many adjacent (standard) n-grams these cover in test documents. We examine skip-gram modelling using one to four skips with various amount of training data and test against similar documents as well as documents generated from a machine translation system. In this paper we also determine the amount of extra training data required to achieve skip-gram coverage using standard adjacent tri-grams.",
            "referenceCount": 8,
            "citationCount": 338,
            "influentialCitationCount": 16,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2006-05-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Guthrie2006ACL,\n author = {David Guthrie and B. Allison and Wei Liu and Louise Guthrie and Y. Wilks},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {1222-1225},\n title = {A Closer Look at Skip-gram Modelling},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:df8568c6e19d427aae989887a47c3a88f8124dda",
            "@type": "ScholarlyArticle",
            "paperId": "df8568c6e19d427aae989887a47c3a88f8124dda",
            "corpusId": 18605528,
            "url": "https://www.semanticscholar.org/paper/df8568c6e19d427aae989887a47c3a88f8124dda",
            "title": "From Sentence Processing to Information Access on the World Wide Web",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1997,
            "externalIds": {
                "MAG": "2157321653",
                "CorpusId": 18605528
            },
            "abstract": "This paper describes the START Information Server built at the MIT Artificial Intelligence Laboratory. Available on the World Wide Web since December 1993, the START Server provides users with access to multi-media information in response to questions formulated in English. Over the last 3 years, the START Server answered hundreds of thousands of questions from users all over the world. The START Server is built on two foundations: the sentence-level Natural Language processing capability provided by the START Natural Language system (Katz [1990])and the idea of natural language annotations for multi-media information segments. This paper starts with an overview of sentence-level processing in the START system and then explains how annotating information segments with collections of English sentences makes it possible to use the power of sentence-level natural language processing in the service of multi-media information access. The paper ends with a proposal to annotate the World Wide Web.",
            "referenceCount": 21,
            "citationCount": 133,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Katz1997FromSP,\n author = {Boris Katz},\n title = {From Sentence Processing to Information Access on the World Wide Web},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:168faeb22d9199ef0a389fdc89e4be26a990f9d3",
            "@type": "ScholarlyArticle",
            "paperId": "168faeb22d9199ef0a389fdc89e4be26a990f9d3",
            "corpusId": 9693272,
            "url": "https://www.semanticscholar.org/paper/168faeb22d9199ef0a389fdc89e4be26a990f9d3",
            "title": "NLP-driven citation analysis for scientometrics",
            "venue": "Natural Language Engineering",
            "publicationVenue": {
                "id": "urn:research:b0dc264e-1ef6-4c58-be54-d2e6137ac35f",
                "name": "Natural Language Engineering",
                "alternate_names": [
                    "Nat Lang Eng"
                ],
                "issn": "1351-3249",
                "url": "https://www.cambridge.org/core/journals/natural-language-engineering"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2565026778",
                "DBLP": "journals/nle/JhaAQR17",
                "DOI": "10.1017/S1351324915000443",
                "CorpusId": 9693272
            },
            "abstract": "Abstract This paper summarizes ongoing research in Natural-Language-Processing-driven citation analysis and describes experiments and motivating examples of how this work can be used to enhance traditional scientometrics analysis that is based on simply treating citations as a \u2018vote\u2019 from the citing paper to cited paper. In particular, we describe our dataset for citation polarity and citation purpose, present experimental results on the automatic detection of these indicators, and demonstrate the use of such annotations for studying research dynamics and scientific summarization. We also look at two complementary problems that show up in Natural-Language-Processing-driven citation analysis for a specific target paper. The first problem is extracting citation context, the implicit citation sentences that do not contain explicit anchors to the target paper. The second problem is extracting reference scope, the target relevant segment of a complicated citing sentence that cites multiple papers. We show how these tasks can be helpful in improving sentiment analysis and citation-based summarization.",
            "referenceCount": 117,
            "citationCount": 80,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-01-25",
            "journal": {
                "name": "Natural Language Engineering",
                "volume": "23"
            },
            "citationStyles": {
                "bibtex": "@Article{Jha2016NLPdrivenCA,\n author = {Rahul Jha and Amjad Abu-Jbara and Vahed Qazvinian and Dragomir R. Radev},\n booktitle = {Natural Language Engineering},\n journal = {Natural Language Engineering},\n pages = {93 - 130},\n title = {NLP-driven citation analysis for scientometrics},\n volume = {23},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:111b870e874ded07f4af222b4754e36202c70d8e",
            "@type": "ScholarlyArticle",
            "paperId": "111b870e874ded07f4af222b4754e36202c70d8e",
            "corpusId": 11455311,
            "url": "https://www.semanticscholar.org/paper/111b870e874ded07f4af222b4754e36202c70d8e",
            "title": "Forgetting Exceptions is Harmful in Language Learning",
            "venue": "Machine-mediated learning",
            "publicationVenue": {
                "id": "urn:research:22c9862f-a25e-40cd-9d31-d09e68a293e6",
                "name": "Machine-mediated learning",
                "alternate_names": [
                    "Mach learn",
                    "Machine Learning",
                    "Mach Learn"
                ],
                "issn": "0732-6718",
                "url": "http://www.springer.com/computer/artificial/journal/10994"
            },
            "year": 1998,
            "externalIds": {
                "MAG": "2952967960",
                "ArXiv": "cs/9812021",
                "DBLP": "journals/ml/DaelemansBZ99",
                "DOI": "10.1023/A:1007585615670",
                "CorpusId": 11455311
            },
            "abstract": null,
            "referenceCount": 75,
            "citationCount": 245,
            "influentialCitationCount": 13,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1023/A:1007585615670.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1998-12-22",
            "journal": {
                "name": "Machine Learning",
                "volume": "34"
            },
            "citationStyles": {
                "bibtex": "@Article{Daelemans1998ForgettingEI,\n author = {Walter Daelemans and Antal van den Bosch and Jakub Zavrel},\n booktitle = {Machine-mediated learning},\n journal = {Machine Learning},\n pages = {11-41},\n title = {Forgetting Exceptions is Harmful in Language Learning},\n volume = {34},\n year = {1998}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7551754581e7e823d0633f3af604e5ed76ecc665",
            "@type": "ScholarlyArticle",
            "paperId": "7551754581e7e823d0633f3af604e5ed76ecc665",
            "corpusId": 6679711,
            "url": "https://www.semanticscholar.org/paper/7551754581e7e823d0633f3af604e5ed76ecc665",
            "title": "Conditional Random Fields: An Introduction",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2004,
            "externalIds": {
                "MAG": "189514790",
                "CorpusId": 6679711
            },
            "abstract": "The task of assigning label sequences to a set of observation sequences arises in many fields, including bioinformatics, computational linguistics and speech recognition [6, 9, 12]. For example, consider the natural language processing task of labeling the words in a sentence with their corresponding part-of-speech (POS) tags. In this task, each word is labeled with a tag indicating its appropriate part of speech, resulting in annotated text, such as:",
            "referenceCount": 15,
            "citationCount": 388,
            "influentialCitationCount": 23,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Wallach2004ConditionalRF,\n author = {Hanna M. Wallach},\n title = {Conditional Random Fields: An Introduction},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ac23e62a18186c9a51dfea16d3602f52ff8c3b3a",
            "@type": "ScholarlyArticle",
            "paperId": "ac23e62a18186c9a51dfea16d3602f52ff8c3b3a",
            "corpusId": 13876865,
            "url": "https://www.semanticscholar.org/paper/ac23e62a18186c9a51dfea16d3602f52ff8c3b3a",
            "title": "Spontaneous Speech Corpus of Japanese",
            "venue": "International Conference on Language Resources and Evaluation",
            "publicationVenue": {
                "id": "urn:research:7474c4a0-75d9-4105-9809-8e7d5201c5e1",
                "name": "International Conference on Language Resources and Evaluation",
                "alternate_names": [
                    "LREC",
                    "Int Conf Lang Resour Evaluation"
                ],
                "issn": null,
                "url": "http://www.lrec-conf.org/"
            },
            "year": 2000,
            "externalIds": {
                "ACL": "L00-1200",
                "DBLP": "conf/lrec/MaekawaKFI00",
                "MAG": "37526647",
                "CorpusId": 13876865
            },
            "abstract": "Design issues of a spontaneous speech corpus is described. The corpus under compilation will contain 800-1000 hour spontaneously uttered Common Japanese speech and the morphologically annotated transcriptions. Also, segmental and intonation labeling will be provided for a subset of the corpus. The primary application domain of the corpus is speech recognition of spontaneous speech, but we plan to make it useful for natural language processing and phonetic/linguistic studies also.",
            "referenceCount": 12,
            "citationCount": 403,
            "influentialCitationCount": 96,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2000-05-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Maekawa2000SpontaneousSC,\n author = {K. Maekawa and H. Koiso and S. Furui and H. Isahara},\n booktitle = {International Conference on Language Resources and Evaluation},\n title = {Spontaneous Speech Corpus of Japanese},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9d3cc5947c4b334941b1919f9aef2d5762b1ccde",
            "@type": "ScholarlyArticle",
            "paperId": "9d3cc5947c4b334941b1919f9aef2d5762b1ccde",
            "corpusId": 60178350,
            "url": "https://www.semanticscholar.org/paper/9d3cc5947c4b334941b1919f9aef2d5762b1ccde",
            "title": "Understanding and enhancing translation by parallel text processing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1999,
            "externalIds": {
                "MAG": "345392283",
                "CorpusId": 60178350
            },
            "abstract": "In recent years the fields of translation studies, natural language processing and corpus linguistics have come to share one object of study, namely parallel text corpora, and more specifically tra ...",
            "referenceCount": 0,
            "citationCount": 114,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Merkel1999UnderstandingAE,\n author = {Magnus Merkel},\n title = {Understanding and enhancing translation by parallel text processing},\n year = {1999}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:303ce3f236ea352b1fcf59f4590474008ad52056",
            "@type": "ScholarlyArticle",
            "paperId": "303ce3f236ea352b1fcf59f4590474008ad52056",
            "corpusId": 10929935,
            "url": "https://www.semanticscholar.org/paper/303ce3f236ea352b1fcf59f4590474008ad52056",
            "title": "Machine Translation Approaches and Survey for Indian Languages",
            "venue": "International Journal of Computational Linguistics and Chinese Language Processing",
            "publicationVenue": {
                "id": "urn:research:948bdbaa-17b4-4e60-8885-abc07efabc3b",
                "name": "International Journal of Computational Linguistics and Chinese Language Processing",
                "alternate_names": [
                    "Int J Comput Linguistics Chin Lang Process"
                ],
                "issn": "1027-376X",
                "url": null
            },
            "year": 2013,
            "externalIds": {
                "DBLP": "journals/ijclclp/Antony13",
                "MAG": "585740886",
                "CorpusId": 10929935
            },
            "abstract": "The term Machine Translation is a standard name for computerized systems responsible for the production of translations from one natural language into another with or without human assistance. It is a sub-field of computational linguistics that investigates the use of computer software to translate text or speech from one natural language to another. Many attempts are being made all over the world to develop machine translation systems for various languages using rule-based as well as statistically based approaches. Development of a full-fledged bilingual machine translation (MT) system for any two natural languages with limited electronic resources and tools is a challenging and demanding task. In order to achieve reasonable translation quality in open source tasks, corpus based machine translation approaches require large amounts of parallel corpora that are not always available, especially for less resourced language pairs. On the other hand, the rule-based machine translation process is extremely time consuming, difficult, and fails to analyze accurately a large corpus of unrestricted text. Even though there has been effort towards building English to Indian language and Indian language to Indian language translation system, unfortunately, we do not have an efficient translation system as of today. The literature shows that there have been many attempts in MT for English to Indian languages and Indian languages to Indian languages. At present, a number of government and private sector projects are working towards developing a full-fledged MT for Indian languages. This paper gives a brief description of the various approaches and major machine translation developments in India.",
            "referenceCount": 44,
            "citationCount": 104,
            "influentialCitationCount": 10,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2013-03-01",
            "journal": {
                "name": "Int. J. Comput. Linguistics Chin. Lang. Process.",
                "volume": "18"
            },
            "citationStyles": {
                "bibtex": "@Article{J2013MachineTA,\n author = {Antony P J},\n booktitle = {International Journal of Computational Linguistics and Chinese Language Processing},\n journal = {Int. J. Comput. Linguistics Chin. Lang. Process.},\n title = {Machine Translation Approaches and Survey for Indian Languages},\n volume = {18},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:84f6eeeac62804de0502a54c444bacfad0f64730",
            "@type": "ScholarlyArticle",
            "paperId": "84f6eeeac62804de0502a54c444bacfad0f64730",
            "corpusId": 2930183,
            "url": "https://www.semanticscholar.org/paper/84f6eeeac62804de0502a54c444bacfad0f64730",
            "title": "Ontology Learning and Its Application to Automated Terminology Translation",
            "venue": "IEEE Intelligent Systems",
            "publicationVenue": {
                "id": "urn:research:7404efea-88b2-4c7c-8cb1-b3a8ced6363f",
                "name": "IEEE Intelligent Systems",
                "alternate_names": [
                    "IEEE Intell Syst"
                ],
                "issn": "1541-1672",
                "url": "https://ieeexplore.ieee.org/servlet/opac?punumber=9670"
            },
            "year": 2003,
            "externalIds": {
                "DBLP": "journals/expert/NavigliVG03",
                "MAG": "2135172365",
                "DOI": "10.1109/MIS.2003.1179190",
                "CorpusId": 2930183
            },
            "abstract": "Our OntoLearn system is an infrastructure for automated ontology learning from domain text. It is the only system, as far as we know, that uses natural language processing and machine learning techniques, and is part of a more general ontology engineering architecture. We describe the system and an experiment in which we used a machine-learned tourism ontology to automatically translate multiword terms from English to Italian. The method can apply to other domains without manual adaptation.",
            "referenceCount": 24,
            "citationCount": 399,
            "influentialCitationCount": 19,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "IEEE Intell. Syst.",
                "volume": "18"
            },
            "citationStyles": {
                "bibtex": "@Article{Navigli2003OntologyLA,\n author = {Roberto Navigli and P. Velardi and Aldo Gangemi},\n booktitle = {IEEE Intelligent Systems},\n journal = {IEEE Intell. Syst.},\n pages = {22-31},\n title = {Ontology Learning and Its Application to Automated Terminology Translation},\n volume = {18},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5e87ee33cf7c0b6da6e501360a5b9eeafb9dccf0",
            "@type": "ScholarlyArticle",
            "paperId": "5e87ee33cf7c0b6da6e501360a5b9eeafb9dccf0",
            "corpusId": 196000998,
            "url": "https://www.semanticscholar.org/paper/5e87ee33cf7c0b6da6e501360a5b9eeafb9dccf0",
            "title": "The Natural Approach",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1983,
            "externalIds": {
                "MAG": "2798987408",
                "CorpusId": 196000998
            },
            "abstract": "Accessed 10 January 2010 The Natural Approach Stephen Krashen and Tracy Terrell developed the Natural Approach in the early eighties (Krashen and Terrell, 1983), based on Krashen's theories about second language acquisition. The approach shared a lot in common with Asher's Total Physical Response method in terms of advocating the need for a silent phase, waiting for spoken production to \"emerge\" of its own accord, and emphasizing the need to make learners as relaxed as possible during the learning process. Some important underlying principles are that there should be a lot of language \"acquisition\" as opposed to language \"processing\", and there needs to be a considerable amount of comprehensible input from the teacher. Meaning is considered as the essence of language and vocabulary (not grammar) is the heart of language.",
            "referenceCount": 0,
            "citationCount": 424,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Krashen1983TheNA,\n author = {S. Krashen and T. D. Terrell},\n title = {The Natural Approach},\n year = {1983}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9a8ebbfc26eb959e111c5c4ad8159aad142cccbc",
            "@type": "ScholarlyArticle",
            "paperId": "9a8ebbfc26eb959e111c5c4ad8159aad142cccbc",
            "corpusId": 18357549,
            "url": "https://www.semanticscholar.org/paper/9a8ebbfc26eb959e111c5c4ad8159aad142cccbc",
            "title": "Helping Our Own: The HOO 2011 Pilot Shared Task",
            "venue": "European Workshop on Natural Language Generation",
            "publicationVenue": {
                "id": "urn:research:e27aff88-fdde-4f04-a3cc-80fc3abdc8db",
                "name": "European Workshop on Natural Language Generation",
                "alternate_names": [
                    "ENLG",
                    "Eur Workshop Nat Lang Gener",
                    "EWNLG"
                ],
                "issn": null,
                "url": null
            },
            "year": 2011,
            "externalIds": {
                "ACL": "W11-2838",
                "DBLP": "conf/enlg/DaleK11",
                "MAG": "1640336798",
                "CorpusId": 18357549
            },
            "abstract": "The aim of the Helping Our Own (HOO) Shared Task is to promote the development of automated tools and techniques that can assist authors in the writing task, with a specific focus on writing within the natural language processing community. This paper reports on the results of a pilot run of the shared task, in which six teams participated. We describe the nature of the task and the data used, report on the results achieved, and discuss some of the things we learned that will guide future versions of the task.",
            "referenceCount": 3,
            "citationCount": 186,
            "influentialCitationCount": 18,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2011-09-28",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Dale2011HelpingOO,\n author = {R. Dale and A. Kilgarriff},\n booktitle = {European Workshop on Natural Language Generation},\n pages = {242-249},\n title = {Helping Our Own: The HOO 2011 Pilot Shared Task},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:042b49ddd96847a17d72fdfec7e9189c7af0d06b",
            "@type": "ScholarlyArticle",
            "paperId": "042b49ddd96847a17d72fdfec7e9189c7af0d06b",
            "corpusId": 2104869,
            "url": "https://www.semanticscholar.org/paper/042b49ddd96847a17d72fdfec7e9189c7af0d06b",
            "title": "An Information Extraction Core System for Real World German Text Processing",
            "venue": "Applied Natural Language Processing Conference",
            "publicationVenue": {
                "id": "urn:research:a8d0722b-8d14-4675-ae77-47b7d0e3fd64",
                "name": "Applied Natural Language Processing Conference",
                "alternate_names": [
                    "Conf Appl Nat Lang Process",
                    "Appl Nat Lang Process Conf",
                    "Conference on Applied Natural Language Processing",
                    "ANLP"
                ],
                "issn": null,
                "url": "https://aclweb.org/anthology/venues/anlp/"
            },
            "year": 1997,
            "externalIds": {
                "ArXiv": "cmp-lg/9706023",
                "ACL": "A97-1031",
                "MAG": "2116184909",
                "DBLP": "conf/anlp/NeumannBBBB97",
                "DOI": "10.3115/974557.974588",
                "CorpusId": 2104869
            },
            "abstract": "This paper describes SMES, an information extraction core system for real world German text processing. The basic design criterion of the system is of providing a set of basic powerful, robust, and efficient natural language components and generic linguistic knowledge sources which can easily be customized for processing different tasks in a flexible manner.",
            "referenceCount": 24,
            "citationCount": 130,
            "influentialCitationCount": 5,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1997-03-31",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Neumann1997AnIE,\n author = {G. Neumann and R. Backofen and Judith Baur and Markus Becker and Christian Braun},\n booktitle = {Applied Natural Language Processing Conference},\n pages = {209-216},\n title = {An Information Extraction Core System for Real World German Text Processing},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0b5a5eea0b99d4afaa4cb24408f3a2bb37ec9c11",
            "@type": "ScholarlyArticle",
            "paperId": "0b5a5eea0b99d4afaa4cb24408f3a2bb37ec9c11",
            "corpusId": 17788645,
            "url": "https://www.semanticscholar.org/paper/0b5a5eea0b99d4afaa4cb24408f3a2bb37ec9c11",
            "title": "Light Stemming for Arabic Information Retrieval",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2007,
            "externalIds": {
                "MAG": "30790492",
                "DOI": "10.1007/978-1-4020-6046-5_12",
                "CorpusId": 17788645
            },
            "abstract": null,
            "referenceCount": 62,
            "citationCount": 281,
            "influentialCitationCount": 31,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Larkey2007LightSF,\n author = {L. Larkey and Lisa Ballesteros and Margaret E. Connell},\n pages = {221-243},\n title = {Light Stemming for Arabic Information Retrieval},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:90d5044b5e7b7b056d6afc0d1f66a537a28fb61f",
            "@type": "ScholarlyArticle",
            "paperId": "90d5044b5e7b7b056d6afc0d1f66a537a28fb61f",
            "corpusId": 9516898,
            "url": "https://www.semanticscholar.org/paper/90d5044b5e7b7b056d6afc0d1f66a537a28fb61f",
            "title": "On automated message processing in electronic commerce and work support systems: speech act theory and expressive felicity",
            "venue": "TOIS",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1997,
            "externalIds": {
                "MAG": "1977281680",
                "DBLP": "journals/tois/KimbroughM97",
                "DOI": "10.1145/263479.263480",
                "CorpusId": 9516898
            },
            "abstract": "Electronic messaging, whether in an office environment or for electronic commerce, is normally carried out in natural language, even when supported by information systems. For a variety of reasons, it would be useful if electronic messaging systems could have semantic access to, that is, access to the meanings and contents of, the messages they process. Given that natural language understanding is not a practicable alternative, there remain three approaches to delivering systems with semantic access: electronic data interchange (EDI), tagged messages, and the development of a formal language for business communication (FLBC). We favor the latter approach. In this article we compare and contrast these three approaches, present a theoretical basis for an FLBC (using speech act theory), and describe a prototype implementation.",
            "referenceCount": 89,
            "citationCount": 130,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1997-10-01",
            "journal": {
                "name": "ACM Trans. Inf. Syst.",
                "volume": "15"
            },
            "citationStyles": {
                "bibtex": "@Article{Kimbrough1997OnAM,\n author = {S. Kimbrough and S. Moore},\n booktitle = {TOIS},\n journal = {ACM Trans. Inf. Syst.},\n pages = {321-367},\n title = {On automated message processing in electronic commerce and work support systems: speech act theory and expressive felicity},\n volume = {15},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:640e47f499c8c083e57def34ca757e72106c25a0",
            "@type": "ScholarlyArticle",
            "paperId": "640e47f499c8c083e57def34ca757e72106c25a0",
            "corpusId": 5129900,
            "url": "https://www.semanticscholar.org/paper/640e47f499c8c083e57def34ca757e72106c25a0",
            "title": "A multimodal learning interface for grounding spoken language in sensory perceptions",
            "venue": "International Conference on Multimodal Interaction",
            "publicationVenue": {
                "id": "urn:research:d11025b6-9660-45df-b13a-555e3ff4ceca",
                "name": "International Conference on Multimodal Interaction",
                "alternate_names": [
                    "Int Conf Multimodal Interact",
                    "International Conference on Multimodal Interfaces",
                    "Int Conf Multimodal Interface",
                    "ICMI"
                ],
                "issn": null,
                "url": "https://en.wikipedia.org/wiki/ACM/IEEE_Virtual_Reality_International_Conference"
            },
            "year": 2003,
            "externalIds": {
                "DBLP": "conf/icmi/YuB03",
                "MAG": "2123815913",
                "DOI": "10.1145/958432.958465",
                "CorpusId": 5129900
            },
            "abstract": "Most speech interfaces are based on natural language processing techniques that use pre-defined symbolic representations of word meanings and process only linguistic information. To understand and use language like their human counterparts in multimodal human-computer interaction, computers need to acquire spoken language and map it to other sensory perceptions. This paper presents a multimodal interface that learns to associate spoken language with perceptual features by being situated in users' everyday environments and sharing user-centric multisensory information. The learning interface is trained in unsupervised mode in which users perform everyday tasks while providing natural language descriptions of their behaviors. We collect acoustic signals in concert with multisensory information from non-speech modalities, such as user's perspective video, gaze positions, head directions and hand movements. The system firstly estimates users' focus of attention from eye and head cues. Attention, as represented by gaze fixation, is used for spotting the target object of user interest. Attention switches are calculated and used to segment an action sequence into action units which are then categorized by mixture hidden Markov models. A multimodal learning algorithm is developed to spot words from continuous speech and then associate them with perceptually grounded meanings extracted from visual perception and action. Successful learning has been demonstrated in the experiments of three natural tasks: \"unscrewing a jar\", \"stapling a letter\" and \"pouring water\".",
            "referenceCount": 56,
            "citationCount": 154,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2003-11-05",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yu2003AML,\n author = {Chen Yu and D. Ballard},\n booktitle = {International Conference on Multimodal Interaction},\n pages = {164-171},\n title = {A multimodal learning interface for grounding spoken language in sensory perceptions},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:af9e0efaaab6927fd256bda15c7fb33fc6df8b62",
            "@type": "ScholarlyArticle",
            "paperId": "af9e0efaaab6927fd256bda15c7fb33fc6df8b62",
            "corpusId": 18206987,
            "url": "https://www.semanticscholar.org/paper/af9e0efaaab6927fd256bda15c7fb33fc6df8b62",
            "title": "Regular expressions for language engineering",
            "venue": "Natural Language Engineering",
            "publicationVenue": {
                "id": "urn:research:b0dc264e-1ef6-4c58-be54-d2e6137ac35f",
                "name": "Natural Language Engineering",
                "alternate_names": [
                    "Nat Lang Eng"
                ],
                "issn": "1351-3249",
                "url": "https://www.cambridge.org/core/journals/natural-language-engineering"
            },
            "year": 1996,
            "externalIds": {
                "DBLP": "journals/nle/KarttunenCGS96",
                "MAG": "2108455276",
                "DOI": "10.1017/S1351324997001563",
                "CorpusId": 18206987
            },
            "abstract": "Many of the processing steps in natural language engineering can be performed using finite state transducers. An optimal way to create such transducers is to compile them from regular expressions. This paper is an introduction to the regular expression calculus, extended with certain operators that have proved very useful in natural language applications ranging from tokenization to light parsing. The examples in the paper illustrate in concrete detail some of these applications.",
            "referenceCount": 29,
            "citationCount": 212,
            "influentialCitationCount": 17,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1996-12-01",
            "journal": {
                "name": "Natural Language Engineering",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Karttunen1996RegularEF,\n author = {L. Karttunen and J. Chanod and G. Grefenstette and A. Schille},\n booktitle = {Natural Language Engineering},\n journal = {Natural Language Engineering},\n pages = {305 - 328},\n title = {Regular expressions for language engineering},\n volume = {2},\n year = {1996}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:72e64476aef57ab92364a0ca058714d2ad337586",
            "@type": "ScholarlyArticle",
            "paperId": "72e64476aef57ab92364a0ca058714d2ad337586",
            "corpusId": 5640626,
            "url": "https://www.semanticscholar.org/paper/72e64476aef57ab92364a0ca058714d2ad337586",
            "title": "ARTIMIS: Natural Dialogue Meets Rational Agency",
            "venue": "International Joint Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:67f7f831-711a-43c8-8785-1e09005359b5",
                "name": "International Joint Conference on Artificial Intelligence",
                "alternate_names": [
                    "Int Jt Conf Artif Intell",
                    "IJCAI"
                ],
                "issn": null,
                "url": "http://www.ijcai.org/"
            },
            "year": 1997,
            "externalIds": {
                "MAG": "1586276265",
                "DBLP": "conf/ijcai/SadekBP97",
                "CorpusId": 5640626
            },
            "abstract": "We present an effective generic communicating rational agent, ARTIMIS, and its application to cooperative spoken dialogue. ARTIMIS ' kernel is the implementation of a formal theory of interaction. This theory involves a set of generic axioms which models, in a homogeneous logical framework, principles of rational behaviour, communication, and cooperation. The theory is interpreted by a specifically designed reasoning engine. When applied to the context of natural dialogue, ARTIMIS includes specialised components for speech and natural language processing.",
            "referenceCount": 25,
            "citationCount": 163,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1997-08-23",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Sadek1997ARTIMISND,\n author = {M. Sadek and P. Bretier and F. Panaget},\n booktitle = {International Joint Conference on Artificial Intelligence},\n pages = {1030-1035},\n title = {ARTIMIS: Natural Dialogue Meets Rational Agency},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a3a81a69f5be7031bb57e4190226b42b3ac4f202",
            "@type": "ScholarlyArticle",
            "paperId": "a3a81a69f5be7031bb57e4190226b42b3ac4f202",
            "corpusId": 15229896,
            "url": "https://www.semanticscholar.org/paper/a3a81a69f5be7031bb57e4190226b42b3ac4f202",
            "title": "Meta-Rules as a Basis for Processing III-Formed Input",
            "venue": "Am. J. Comput. Linguistics",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1983,
            "externalIds": {
                "MAG": "1833210519",
                "DBLP": "journals/coling/WeischedelS83",
                "ACL": "J83-3003",
                "CorpusId": 15229896
            },
            "abstract": "If natural language processing systems are ever to achieve natural, cooperative behavior, they must be able to process input that is ill-formed lexically, syntactically, semantically, or pragmatically. Systems must be able to partially understand, or at least give specific, appropriate error messages, when input does not correspond to their model of language and of context.We propose meta-rules and a control structure under which they are invoked as a framework for processing ill-formed input. The left-hand side of a meta-rule diagnoses a problem as a violated rule of normal processing. The right-hand side relaxes the violated rule and states how processing may be resumed, if at all.Examples discussed in the paper include violated grammatical tests, omitted articles, homonyms, spelling/typographical errors, unknown words, violated selection restrictions, personification, and metonymy. An implementation of a meta-rule processor within the framework of an augmented transition network parser is also described.",
            "referenceCount": 60,
            "citationCount": 134,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1983-07-01",
            "journal": {
                "name": "Am. J. Comput. Linguistics",
                "volume": "9"
            },
            "citationStyles": {
                "bibtex": "@Article{Weischedel1983MetaRulesAA,\n author = {R. Weischedel and N. Sondheimer},\n booktitle = {Am. J. Comput. Linguistics},\n journal = {Am. J. Comput. Linguistics},\n pages = {161-177},\n title = {Meta-Rules as a Basis for Processing III-Formed Input},\n volume = {9},\n year = {1983}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0f9e183f256e7275ca879ca825ecd1cd6f4c5049",
            "@type": "ScholarlyArticle",
            "paperId": "0f9e183f256e7275ca879ca825ecd1cd6f4c5049",
            "corpusId": 11405242,
            "url": "https://www.semanticscholar.org/paper/0f9e183f256e7275ca879ca825ecd1cd6f4c5049",
            "title": "The Edinburgh Twitter Corpus",
            "venue": "HLT-NAACL 2010",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2010,
            "externalIds": {
                "ACL": "W10-0513",
                "MAG": "1800296434",
                "CorpusId": 11405242
            },
            "abstract": "We describe the first release of our corpus of 97 million Twitter posts. We believe that this data will prove valuable to researchers working in social media, natural language processing, large-scale data processing, and similar areas.",
            "referenceCount": 0,
            "citationCount": 182,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2010-06-06",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Petrovic2010TheET,\n author = {S. Petrovic and M. Osborne and V. Lavrenko},\n booktitle = {HLT-NAACL 2010},\n pages = {25-26},\n title = {The Edinburgh Twitter Corpus},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:13c526d88a63be5b34f391725f069a867f202011",
            "@type": "ScholarlyArticle",
            "paperId": "13c526d88a63be5b34f391725f069a867f202011",
            "corpusId": 3082215,
            "url": "https://www.semanticscholar.org/paper/13c526d88a63be5b34f391725f069a867f202011",
            "title": "The challenge of spoken language systems: research directions for the nineties",
            "venue": "IEEE Transactions on Speech and Audio Processing",
            "publicationVenue": {
                "id": "urn:research:cd5799dd-1165-414f-87b0-ea5e184781c0",
                "name": "IEEE Transactions on Speech and Audio Processing",
                "alternate_names": [
                    "IEEE Trans Speech Audio Process"
                ],
                "issn": "1063-6676",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=89"
            },
            "year": 1995,
            "externalIds": {
                "DBLP": "journals/taslp/ColeHABBBCCGHHLMMNOOPSSWWZZ95",
                "MAG": "2170418652",
                "DOI": "10.1109/89.365385",
                "CorpusId": 3082215
            },
            "abstract": "A spoken language system combines speech recognition, natural language processing and human interface technology. It functions by recognizing the person's words, interpreting the sequence of words to obtain a meaning in terms of the application, and providing an appropriate response back to the user. Potential applications of spoken language systems range from simple tasks, such as retrieving information from an existing database (traffic reports, airline schedules), to interactive problem solving tasks involving complex planning and reasoning (travel planning, traffic routing), to support for multilingual interactions. We examine eight key areas in which basic research is needed to produce spoken language systems: (1) robust speech recognition; (2) automatic training and adaptation; (3) spontaneous speech; (4) dialogue models; (5) natural language response generation; (6) speech synthesis and speech generation; (7) multilingual systems; and (8) interactive multimodal systems. In each area, we identify key research challenges, the infrastructure needed to support research, and the expected benefits. We conclude by reviewing the need for multidisciplinary research, for development of shared corpora and related resources, for computational support and far rapid communication among researchers. The successful development of this technology will increase accessibility of computers to a wide range of users, will facilitate multinational communication and trade, and will create new research specialties and jobs in this rapidly expanding area. >",
            "referenceCount": 193,
            "citationCount": 156,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://academiccommons.columbia.edu/doi/10.7916/D82J6NR5/download",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "IEEE Trans. Speech Audio Process.",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{Cole1995TheCO,\n author = {R. Cole and L. Hirschman and L. Atlas and M. Beckman and A. Biermann and M. Bush and M. Clements and Jordan Cohen and Oscar Garcia and B. Hanson and H. Hermansky and S. Levinson and K. McKeown and N. Morgan and D. Novick and Mari Ostendorf and S. Oviatt and P. Price and H. Silverman and J. Spitz and A. Waibel and C. Weinstein and S. Zahorian and V. Zue},\n booktitle = {IEEE Transactions on Speech and Audio Processing},\n journal = {IEEE Trans. Speech Audio Process.},\n pages = {1-21},\n title = {The challenge of spoken language systems: research directions for the nineties},\n volume = {3},\n year = {1995}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7e71862a3652a1a1283bdae6d6268d01af1b2a45",
            "@type": "ScholarlyArticle",
            "paperId": "7e71862a3652a1a1283bdae6d6268d01af1b2a45",
            "corpusId": 140275481,
            "url": "https://www.semanticscholar.org/paper/7e71862a3652a1a1283bdae6d6268d01af1b2a45",
            "title": "The Cognitive Representation and Processing of Discourse: Function and Dysfunction",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1990,
            "externalIds": {
                "MAG": "145293172",
                "DOI": "10.1007/978-1-4612-3262-9_4",
                "CorpusId": 140275481
            },
            "abstract": null,
            "referenceCount": 47,
            "citationCount": 76,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Frederiksen1990TheCR,\n author = {C. Frederiksen and R. Bracewell and Alain Breuleux and Andre Renaud},\n pages = {69-110},\n title = {The Cognitive Representation and Processing of Discourse: Function and Dysfunction},\n year = {1990}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:90c58cbd903ab65da10b620d00b5a9ab8d7ca0f7",
            "@type": "ScholarlyArticle",
            "paperId": "90c58cbd903ab65da10b620d00b5a9ab8d7ca0f7",
            "corpusId": 145180550,
            "url": "https://www.semanticscholar.org/paper/90c58cbd903ab65da10b620d00b5a9ab8d7ca0f7",
            "title": "Psychological Constraints on the Teachability of Languages",
            "venue": "Studies in Second Language Acquisition",
            "publicationVenue": {
                "id": "urn:research:67facdb8-b4af-406e-80a2-e1c892256564",
                "name": "Studies in Second Language Acquisition",
                "alternate_names": [
                    "Stud Second Lang Acquis"
                ],
                "issn": "0272-2631",
                "url": "https://www.cambridge.org/core/journals/studies-in-second-language-acquisition"
            },
            "year": 1984,
            "externalIds": {
                "MAG": "2130119124",
                "DOI": "10.1017/S0272263100005015",
                "CorpusId": 145180550
            },
            "abstract": "This paper reports on the influence of formal instruction on L2 acquisition in an instructional experiment with child learners. The main tendency of the findings is that a structure can only be learned under instruction if the learner's interlanguage has already reached a stage one step prior to the acquisition of the structure to be taught. My hypothesis for an explanation suggests that the teachability of L2 structures is constrained by the same processing restrictions that determine the developmental sequences of natural L2 acquisition: since the processing procedures of each stage build upon the procedures of the preceding stage there is no way to leave out a stage of the developmental sequence by the means of formal teaching. Following such a processing capacity approach I reject the assumption that the constraints on teachability can be explained on the basis of linguistic input.",
            "referenceCount": 45,
            "citationCount": 534,
            "influentialCitationCount": 30,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1984-03-01",
            "journal": {
                "name": "Studies in Second Language Acquisition",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Pienemann1984PsychologicalCO,\n author = {Manfred Pienemann},\n booktitle = {Studies in Second Language Acquisition},\n journal = {Studies in Second Language Acquisition},\n pages = {186 - 214},\n title = {Psychological Constraints on the Teachability of Languages},\n volume = {6},\n year = {1984}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3709d6c71d1003f47fce2989134173bf477802ac",
            "@type": "ScholarlyArticle",
            "paperId": "3709d6c71d1003f47fce2989134173bf477802ac",
            "corpusId": 473213,
            "url": "https://www.semanticscholar.org/paper/3709d6c71d1003f47fce2989134173bf477802ac",
            "title": "An Efficient Context-Free Parsing Algorithm for Natural Languages",
            "venue": "International Joint Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:67f7f831-711a-43c8-8785-1e09005359b5",
                "name": "International Joint Conference on Artificial Intelligence",
                "alternate_names": [
                    "Int Jt Conf Artif Intell",
                    "IJCAI"
                ],
                "issn": null,
                "url": "http://www.ijcai.org/"
            },
            "year": 1985,
            "externalIds": {
                "MAG": "1549379126",
                "DBLP": "conf/ijcai/Tomita85",
                "CorpusId": 473213
            },
            "abstract": "This thesis introduces an efficient context-free parsing algorithm and emphasizes its practical value in natural language processing. In the theoretical worst case analysis, the parsing algorithm occasionally takes more than O(n('3)) time with kinds of context-free grammars which are very unlikely to appear in natural languages. As far as practical natural language processing is concerned, on the other hand, the parsing algorithm seems more efficient than any existing algorithms including Earley's algorithm. Experiments with several English grammars and sample sentences show that our algorithm is 5 to 10 times faster than Earley's standard algorithm. \nThe parsing algorithm can be viewed as an extended LR parsing algorithm which embodies the concept of a \"graph-structured stack.\" Unlike the standard LR, the algorithm is capable of handling arbitrary non-cyclic context-free grammars including ambiguous grammars, with little loss of LR efficiency. In particular, if its grammar is \"close\" to LR, most of the LR parsing efficiency can be preserved. Natural language grammars are, fortunately, considerably \"close\" to LR, compared with other general context-free grammars. \nThe algorithm is an all-path parsing algorithm; it produces all possible parse trees (a parse forest) in an efficient representation called a \"shared-packed forest.\" This thesis also shows that Earley's forest representation has a defect and his representation cannot be used in natural language processing. \nThe last chapters of the thesis suggest practical applications of the algorithm. A concept of left-to-right on-line parsing is introduced, taking advantage of the fact that our algorithm parses a sentence strictly from left to right. Several benefits of on-line parsing are described, and its application to user-friendly natural language interface is discussed. This thesis also proposes a technique to disambiguate a sentence out of the shared-packed forest representation by asking the user questions interactively. Finally, a personal/interactive machine translation system is suggested.",
            "referenceCount": 24,
            "citationCount": 122,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1985-08-18",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Tomita1985AnEC,\n author = {M. Tomita},\n booktitle = {International Joint Conference on Artificial Intelligence},\n pages = {756-764},\n title = {An Efficient Context-Free Parsing Algorithm for Natural Languages},\n year = {1985}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e50bc38b1d3468747a74d5e38bff46ba630ac612",
            "@type": "ScholarlyArticle",
            "paperId": "e50bc38b1d3468747a74d5e38bff46ba630ac612",
            "corpusId": 776192,
            "url": "https://www.semanticscholar.org/paper/e50bc38b1d3468747a74d5e38bff46ba630ac612",
            "title": "Document Ranking and the Vector-Space Model",
            "venue": "IEEE Software",
            "publicationVenue": {
                "id": "urn:research:119227a6-1b94-433e-a52d-8445a387dbbe",
                "name": "IEEE Software",
                "alternate_names": [
                    "IEEE Softw"
                ],
                "issn": "0740-7459",
                "url": "http://www.computer.org/software"
            },
            "year": 1997,
            "externalIds": {
                "MAG": "2119572012",
                "DBLP": "journals/software/LeeCS97",
                "DOI": "10.1109/52.582976",
                "CorpusId": 776192
            },
            "abstract": "Efficient and effective text retrieval techniques are critical in managing the increasing amount of textual information available in electronic form. Yet text retrieval is a daunting task because it is difficult to extract the semantics of natural language texts. Many problems must be resolved before natural language processing techniques can be effectively applied to a large collection of texts. Most existing text retrieval techniques rely on indexing keywords. Unfortunately, keywords or index terms alone cannot adequately capture the document contents, resulting in poor retrieval performance. Yet keyword indexing is widely used in commercial systems because it is still the most viable way by far to process large amounts of text. Using several simplifications of the vector-space model for text retrieval queries, the authors seek the optimal balance between processing efficiency and retrieval effectiveness as expressed in relevant document rankings.",
            "referenceCount": 10,
            "citationCount": 414,
            "influentialCitationCount": 25,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1997-03-01",
            "journal": {
                "name": "IEEE Softw.",
                "volume": "14"
            },
            "citationStyles": {
                "bibtex": "@Article{Lee1997DocumentRA,\n author = {Lee and Huei Chuang and K. Seamons},\n booktitle = {IEEE Software},\n journal = {IEEE Softw.},\n pages = {67-75},\n title = {Document Ranking and the Vector-Space Model},\n volume = {14},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9d0776666d8c7da0f6c40950563687f8ba5b6f7f",
            "@type": "ScholarlyArticle",
            "paperId": "9d0776666d8c7da0f6c40950563687f8ba5b6f7f",
            "corpusId": 62173535,
            "url": "https://www.semanticscholar.org/paper/9d0776666d8c7da0f6c40950563687f8ba5b6f7f",
            "title": "Performance Issues and Error Analysis in an Open-Domain Question Answering System",
            "venue": "Annual Meeting of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                "name": "Annual Meeting of the Association for Computational Linguistics",
                "alternate_names": [
                    "Annu Meet Assoc Comput Linguistics",
                    "Meeting of the Association for Computational Linguistics",
                    "ACL",
                    "Meet Assoc Comput Linguistics"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/acl/"
            },
            "year": 2002,
            "externalIds": {
                "DBLP": "conf/acl/MoldovanPHS02",
                "ACL": "P02-1005",
                "MAG": "2029118765",
                "DOI": "10.1145/763693.763694",
                "CorpusId": 62173535
            },
            "abstract": "This paper presents an in-depth analysis of a state-of-the-art Question Answering system. Several scenarios are examined: (1) the performance of each module in a serial baseline system, (2) the impact of feedbacks and the insertion of a logic prover, and (3) the impact of various retrieval strategies and lexical resources. The main conclusion is that the overall performance depends on the depth of natural language processing resources and the tools used for answer finding.",
            "referenceCount": 26,
            "citationCount": 349,
            "influentialCitationCount": 25,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.3115/1073083.1073091",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2002-07-06",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Moldovan2002PerformanceIA,\n author = {D. Moldovan and Marius Pasca and S. Harabagiu and M. Surdeanu},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {33-40},\n title = {Performance Issues and Error Analysis in an Open-Domain Question Answering System},\n year = {2002}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fe7f1509d6501c09c4f0e8ce53bca494a60d71ef",
            "@type": "ScholarlyArticle",
            "paperId": "fe7f1509d6501c09c4f0e8ce53bca494a60d71ef",
            "corpusId": 52867179,
            "url": "https://www.semanticscholar.org/paper/fe7f1509d6501c09c4f0e8ce53bca494a60d71ef",
            "title": "Book Review: Linguistic Structure Prediction by Noah A. Smith",
            "venue": "International Conference on Computational Logic",
            "publicationVenue": {
                "id": "urn:research:30a8645d-22d4-42e2-b3f6-304bf4ce3a02",
                "name": "International Conference on Computational Logic",
                "alternate_names": [
                    "CL",
                    "Int Conf Comput Log"
                ],
                "issn": null,
                "url": null
            },
            "year": 2011,
            "externalIds": {
                "DBLP": "series/synthesis/2011Smith",
                "MAG": "2596735154",
                "ACL": "J12-2012",
                "DOI": "10.1162/COLI_r_00105",
                "CorpusId": 52867179
            },
            "abstract": "A major part of natural language processing now depends on the use of text data to build linguistic analyzers. We consider statistical, computational approaches to modeling linguistic structure. We seek to unify across many approaches and many kinds of linguistic structures. Assuming a basic understanding of natural language processing and/or machine learning, we seek to bridge the gap between the two fields. Approaches to decoding (i.e., carrying out linguistic structure prediction) and supervised and unsupervised learning of models that predict discrete structures as outputs are the focus. We also survey natural language processing problems to which these methods are being applied, and we address related topics in probabilistic inference, optimization, and experimental methodology. Table of Contents: Representations and Linguistic Data / Decoding: Making Predictions / Learning Structure from Annotated Data / Learning Structure from Incomplete Data / Beyond Decoding: Inference",
            "referenceCount": 275,
            "citationCount": 129,
            "influentialCitationCount": 15,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/bfm:978-3-031-02143-5/1?pdf=chapter%20toc",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Philosophy",
                "Art"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Philosophy",
                    "source": "external"
                },
                {
                    "category": "Art",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2011-06-01",
            "journal": {
                "name": "Computational Linguistics",
                "volume": "38"
            },
            "citationStyles": {
                "bibtex": "@Article{Smith2011BookRL,\n author = {Noah A. Smith},\n booktitle = {International Conference on Computational Logic},\n journal = {Computational Linguistics},\n pages = {455-457},\n title = {Book Review: Linguistic Structure Prediction by Noah A. Smith},\n volume = {38},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b5eaa77d57b14669ed4b0143efe605f7c7392b9a",
            "@type": "ScholarlyArticle",
            "paperId": "b5eaa77d57b14669ed4b0143efe605f7c7392b9a",
            "corpusId": 6724742,
            "url": "https://www.semanticscholar.org/paper/b5eaa77d57b14669ed4b0143efe605f7c7392b9a",
            "title": "Toward Conversational Human-Computer Interaction",
            "venue": "The AI Magazine",
            "publicationVenue": {
                "id": "urn:research:6fedff74-7525-4b7f-bbb4-4df4e23948e4",
                "name": "The AI Magazine",
                "alternate_names": [
                    "AI Mag",
                    "Ai Mag",
                    "Ai Magazine"
                ],
                "issn": "0738-4602",
                "url": "https://www.aaai.org/Library/Magazine/magazine-library.php"
            },
            "year": 2001,
            "externalIds": {
                "MAG": "2098217544",
                "DBLP": "journals/aim/AllenBDFGS01",
                "DOI": "10.1609/aimag.v22i4.1590",
                "CorpusId": 6724742
            },
            "abstract": "The belief that humans will be able to interact with computers in conversational speech has long been a favorite subject in science fiction, reflecting the persistent belief that spoken dialogue would be the most natural and powerful user interface to computers. With recent improvements in computer technology and in speech and language processing, such systems are starting to appear feasible. There are significant technical problems that still need to be solved before speech-driven interfaces become truly conversational. This article describes the results of a 10-year effort building robust spoken dialogue systems at the University of Rochester.",
            "referenceCount": 22,
            "citationCount": 378,
            "influentialCitationCount": 18,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2001-12-15",
            "journal": {
                "name": "AI Mag.",
                "volume": "22"
            },
            "citationStyles": {
                "bibtex": "@Article{Allen2001TowardCH,\n author = {James F. Allen and D. Byron and M. Dzikovska and G. Ferguson and Lucian Galescu and Amanda Stent},\n booktitle = {The AI Magazine},\n journal = {AI Mag.},\n pages = {27-38},\n title = {Toward Conversational Human-Computer Interaction},\n volume = {22},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c50104bd642473b3b628bd75b9898a4d287d2c5b",
            "@type": "ScholarlyArticle",
            "paperId": "c50104bd642473b3b628bd75b9898a4d287d2c5b",
            "corpusId": 14200823,
            "url": "https://www.semanticscholar.org/paper/c50104bd642473b3b628bd75b9898a4d287d2c5b",
            "title": "Robust Text Processing in Automated Information Retrieval",
            "venue": "Applied Natural Language Processing Conference",
            "publicationVenue": {
                "id": "urn:research:a8d0722b-8d14-4675-ae77-47b7d0e3fd64",
                "name": "Applied Natural Language Processing Conference",
                "alternate_names": [
                    "Conf Appl Nat Lang Process",
                    "Appl Nat Lang Process Conf",
                    "Conference on Applied Natural Language Processing",
                    "ANLP"
                ],
                "issn": null,
                "url": "https://aclweb.org/anthology/venues/anlp/"
            },
            "year": 1994,
            "externalIds": {
                "MAG": "2787085287",
                "DBLP": "conf/acl-vlc/Strzalkowski93",
                "ACL": "W93-0302",
                "DOI": "10.3115/974358.974396",
                "CorpusId": 14200823
            },
            "abstract": "We report on the results of a series of experiments with a prototype text retrieval system which uses relatively advanced natural language processing techniques in order to enhance the effectiveness of statistical document retrieval. In this paper we show that large-scale natural language processing (hundreds of millions of words and more) is not only required for a better retrieval, but it is also doable, given appropriate resources. In particular, we demonstrate that the use of syntactic compounds in the representation of database documents as well as in the user queries, coupled with an appropriate term weighting strategy, can considerably improve the effectiveness of retrospective search. The experiments reported here were conducted on TIPSTER database in connection with the Text REtrieval Conference series (TREC).",
            "referenceCount": 24,
            "citationCount": 49,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.3115/974358.974396",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1994-10-13",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Strzalkowski1994RobustTP,\n author = {T. Strzalkowski},\n booktitle = {Applied Natural Language Processing Conference},\n pages = {168-173},\n title = {Robust Text Processing in Automated Information Retrieval},\n year = {1994}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2dc2b0794a871ebbc9f52bb2d6826b11ced31e1e",
            "@type": "ScholarlyArticle",
            "paperId": "2dc2b0794a871ebbc9f52bb2d6826b11ced31e1e",
            "corpusId": 14612056,
            "url": "https://www.semanticscholar.org/paper/2dc2b0794a871ebbc9f52bb2d6826b11ced31e1e",
            "title": "Corpus-based stemming using cooccurrence of word variants",
            "venue": "TOIS",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1998,
            "externalIds": {
                "MAG": "2008495066",
                "DBLP": "journals/tois/XuC98",
                "DOI": "10.1145/267954.267957",
                "CorpusId": 14612056
            },
            "abstract": "Stemming is used in many information retrieval (IR) systems to reduce variant word forms to common roots. It is one of the simplest applications of natural-language processing to IR and is one of the most effective in terms of user acceptance and consistency, though small retrieval improvements. Current stemming techniques do not, however, reflect the language use in specific corpora, and this can lead to occasional serious retrieval failures. We propose a technique for using corpus-based word variant cooccurrence statistics to modify or create a stemmer. The experimental results generated using English newspaper and legal text and Spanish text demonstrate the viability of this technique and its advantages relative to conventional approaches that only employ morphological rules.",
            "referenceCount": 21,
            "citationCount": 374,
            "influentialCitationCount": 15,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/267954.267957",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "ACM Trans. Inf. Syst.",
                "volume": "16"
            },
            "citationStyles": {
                "bibtex": "@Article{Xu1998CorpusbasedSU,\n author = {Jinxi Xu and W. Bruce Croft},\n booktitle = {TOIS},\n journal = {ACM Trans. Inf. Syst.},\n pages = {61-81},\n title = {Corpus-based stemming using cooccurrence of word variants},\n volume = {16},\n year = {1998}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3dc7ced7f0c7321a50a56a4d6b939220beab107e",
            "@type": "ScholarlyArticle",
            "paperId": "3dc7ced7f0c7321a50a56a4d6b939220beab107e",
            "corpusId": 18086946,
            "url": "https://www.semanticscholar.org/paper/3dc7ced7f0c7321a50a56a4d6b939220beab107e",
            "title": "Market research for requirements analysis using linguistic tools",
            "venue": "Requirements Engineering",
            "publicationVenue": {
                "id": "urn:research:fe9174dc-ba90-4d03-929c-4edaf60d2a64",
                "name": "Requirements Engineering",
                "alternate_names": [
                    "Requir Eng"
                ],
                "issn": "0947-3602",
                "url": "http://www.springer.com/computer/programming/journal/766"
            },
            "year": 2004,
            "externalIds": {
                "MAG": "2162497509",
                "DBLP": "journals/re/MichFI04",
                "DOI": "10.1007/s00766-004-0195-3",
                "CorpusId": 18086946
            },
            "abstract": null,
            "referenceCount": 37,
            "citationCount": 294,
            "influentialCitationCount": 15,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://iris.unitn.it/bitstream/11572/74038/3/2002%2bNLP-CASEMarketResearch%2bPre-print.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2004-05-01",
            "journal": {
                "name": "Requirements Engineering",
                "volume": "9"
            },
            "citationStyles": {
                "bibtex": "@Article{Mich2004MarketRF,\n author = {Luisa Mich and M. Franch and P. N. Inverardi},\n booktitle = {Requirements Engineering},\n journal = {Requirements Engineering},\n pages = {151},\n title = {Market research for requirements analysis using linguistic tools},\n volume = {9},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3904de65eca0e3a31ad3ea10e94fdd90599a5033",
            "@type": "ScholarlyArticle",
            "paperId": "3904de65eca0e3a31ad3ea10e94fdd90599a5033",
            "corpusId": 10540932,
            "url": "https://www.semanticscholar.org/paper/3904de65eca0e3a31ad3ea10e94fdd90599a5033",
            "title": "The Grammar Matrix: An Open-Source Starter-Kit for the Rapid Development of Cross-linguistically Consistent Broad-Coverage Precision Grammars",
            "venue": "International Conference on Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:f51ff783-cdff-4e22-94fb-28e6336d17b3",
                "name": "International Conference on Computational Linguistics",
                "alternate_names": [
                    "Int Conf Comput Linguistics",
                    "COLING"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/coling/"
            },
            "year": 2002,
            "externalIds": {
                "ACL": "W02-1502",
                "MAG": "2091312385",
                "DOI": "10.3115/1118783.1118785",
                "CorpusId": 10540932
            },
            "abstract": "The grammar matrix is an open-source starter-kit for the development of broad-coverage HPSGs. By using a type hierarchy to represent cross-linguistic generalizations and providing compatibility with other open-source tools for grammar engineering, evaluation, parsing and generation, it facilitates not only quick start-up but also rapid growth towards the wide coverage necessary for robust natural language processing and the precision parses and semantic representations necessary for natural language understanding.",
            "referenceCount": 26,
            "citationCount": 275,
            "influentialCitationCount": 27,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://dl.acm.org/ft_gateway.cfm?id=1118785&type=pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2002-09-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Bender2002TheGM,\n author = {Emily M. Bender and D. Flickinger and S. Oepen},\n booktitle = {International Conference on Computational Linguistics},\n pages = {1-7},\n title = {The Grammar Matrix: An Open-Source Starter-Kit for the Rapid Development of Cross-linguistically Consistent Broad-Coverage Precision Grammars},\n year = {2002}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:368116149063f1e7ce57040c441c711ea389912a",
            "@type": "ScholarlyArticle",
            "paperId": "368116149063f1e7ce57040c441c711ea389912a",
            "corpusId": 35286865,
            "url": "https://www.semanticscholar.org/paper/368116149063f1e7ce57040c441c711ea389912a",
            "title": "A definition and short history of Language Engineering",
            "venue": "Natural Language Engineering",
            "publicationVenue": {
                "id": "urn:research:b0dc264e-1ef6-4c58-be54-d2e6137ac35f",
                "name": "Natural Language Engineering",
                "alternate_names": [
                    "Nat Lang Eng"
                ],
                "issn": "1351-3249",
                "url": "https://www.cambridge.org/core/journals/natural-language-engineering"
            },
            "year": 1999,
            "externalIds": {
                "MAG": "2141829400",
                "DBLP": "journals/nle/Cunningham99",
                "DOI": "10.1017/S1351324999002144",
                "CorpusId": 35286865
            },
            "abstract": "This paper discusses the nature, history and current characteristics of Language Engineering, which is contrasted with Natural Language Processing and Computational Linguistics, and which is shown to have attained its own distinct identity in recent years. Major trends in the field are examined, including its focus on large-scale practical tasks and on quantitative evaluation of progress, and its willingness to embrace a diverse range of techniques. The importance of software engineering in this context is noted, as are some sociological aspects of the practitioner group.",
            "referenceCount": 75,
            "citationCount": 65,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Sociology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1999-03-01",
            "journal": {
                "name": "Natural Language Engineering",
                "volume": "5"
            },
            "citationStyles": {
                "bibtex": "@Article{Cunningham1999ADA,\n author = {H. Cunningham},\n booktitle = {Natural Language Engineering},\n journal = {Natural Language Engineering},\n pages = {1 - 16},\n title = {A definition and short history of Language Engineering},\n volume = {5},\n year = {1999}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3b06dcfd6e93a4d23d63e078e52296058dfe64fa",
            "@type": "ScholarlyArticle",
            "paperId": "3b06dcfd6e93a4d23d63e078e52296058dfe64fa",
            "corpusId": 9614339,
            "url": "https://www.semanticscholar.org/paper/3b06dcfd6e93a4d23d63e078e52296058dfe64fa",
            "title": "Using concepts in literature-based discovery: Simulating Swanson's Raynaud-fish oil and migraine-magnesium discoveries",
            "venue": "J. Assoc. Inf. Sci. Technol.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2001,
            "externalIds": {
                "DBLP": "journals/jasis/WeeberKBV01",
                "MAG": "2105562985",
                "DOI": "10.1002/asi.1104",
                "CorpusId": 9614339
            },
            "abstract": "Literature-based discovery has resulted in new knowledge. In the biomedical context, Don R. Swanson has generated several literature-based hypotheses that have been corroborated experimentally and clinically. In this paper, we propose a two-step model of the discovery process in which hypotheses are generated and subsequently tested. We have implemented this model in a Natural Language Processing system that uses biomedical Unified Medical Language System (UMLS) concepts as its unit of analysis. We use the semantic information that is provided with these concepts as a powerful filter to successfully simulate Swanson's discoveries of connecting Raynaud's disease with fish oil and migraine with a magnesium deficiency.",
            "referenceCount": 27,
            "citationCount": 282,
            "influentialCitationCount": 28,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2001-05-01",
            "journal": {
                "name": "J. Assoc. Inf. Sci. Technol.",
                "volume": "52"
            },
            "citationStyles": {
                "bibtex": "@Article{Weeber2001UsingCI,\n author = {M. Weeber and H. Klein and L. T. Berg and R. Vos},\n booktitle = {J. Assoc. Inf. Sci. Technol.},\n journal = {J. Assoc. Inf. Sci. Technol.},\n pages = {548-557},\n title = {Using concepts in literature-based discovery: Simulating Swanson's Raynaud-fish oil and migraine-magnesium discoveries},\n volume = {52},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:db0188e7bc557c4928ef6768c3ddea9df90680ae",
            "@type": "ScholarlyArticle",
            "paperId": "db0188e7bc557c4928ef6768c3ddea9df90680ae",
            "corpusId": 15666840,
            "url": "https://www.semanticscholar.org/paper/db0188e7bc557c4928ef6768c3ddea9df90680ae",
            "title": "Robustness beyond shallowness: incremental deep parsing",
            "venue": "Natural Language Engineering",
            "publicationVenue": {
                "id": "urn:research:b0dc264e-1ef6-4c58-be54-d2e6137ac35f",
                "name": "Natural Language Engineering",
                "alternate_names": [
                    "Nat Lang Eng"
                ],
                "issn": "1351-3249",
                "url": "https://www.cambridge.org/core/journals/natural-language-engineering"
            },
            "year": 2002,
            "externalIds": {
                "DBLP": "journals/nle/Ait-MokhtarCR02",
                "MAG": "2069263150",
                "DOI": "10.1017/S1351324902002887",
                "CorpusId": 15666840
            },
            "abstract": "Robustness is a key issue for natural language processing in general and parsing in particular, and many approaches have been explored in the last decade for the design of robust parsing systems. Among those approaches is shallow or partial parsing, which produces minimal and incomplete syntactic structures, often in an incremental way. We argue that with a systematic incremental methodology one can go beyond shallow parsing to deeper language analysis, while preserving robustness. We describe a generic system based on such a methodology and designed for building robust analyzers that tackle deeper linguistic phenomena than those traditionally handled by the now widespread shallow parsers. The rule formalism allows the recognition of n-ary linguistic relations between words or constituents on the basis of global or local structural, topological and/or lexical conditions. It offers the advantage of accepting various types of inputs, ranging from raw to chunked or constituent-marked texts, so for instance it can be used to process existing annotated corpora, or to perform a deeper analysis on the output of an existing shallow parser. It has been successfully used to build a deep functional dependency parser, as well as for the task of co-reference resolution, in a modular way.",
            "referenceCount": 92,
            "citationCount": 288,
            "influentialCitationCount": 18,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://pageperso.lif.univ-mrs.fr/~edouard.thiel/RESP/Semi/2006/ROUX/idp.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2002-06-01",
            "journal": {
                "name": "Natural Language Engineering",
                "volume": "8"
            },
            "citationStyles": {
                "bibtex": "@Article{Ait-Mokhtar2002RobustnessBS,\n author = {Salah Ait-Mokhtar and J. Chanod and Claude Roux},\n booktitle = {Natural Language Engineering},\n journal = {Natural Language Engineering},\n pages = {121 - 144},\n title = {Robustness beyond shallowness: incremental deep parsing},\n volume = {8},\n year = {2002}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2f6de1dc2c0570f484e026e6089de86c07776ac8",
            "@type": "ScholarlyArticle",
            "paperId": "2f6de1dc2c0570f484e026e6089de86c07776ac8",
            "corpusId": 7609686,
            "url": "https://www.semanticscholar.org/paper/2f6de1dc2c0570f484e026e6089de86c07776ac8",
            "title": "Lexical Markup Framework (LMF)",
            "venue": "International Conference on Language Resources and Evaluation",
            "publicationVenue": {
                "id": "urn:research:7474c4a0-75d9-4105-9809-8e7d5201c5e1",
                "name": "International Conference on Language Resources and Evaluation",
                "alternate_names": [
                    "LREC",
                    "Int Conf Lang Resour Evaluation"
                ],
                "issn": null,
                "url": "http://www.lrec-conf.org/"
            },
            "year": 2006,
            "externalIds": {
                "ACL": "L06-1348",
                "MAG": "2733118110",
                "DBLP": "conf/lrec/FrancopouloGCMB06",
                "CorpusId": 7609686
            },
            "abstract": "Optimizing the production, maintenance and extension of lexical resources is one the crucial aspects impacting Natural Language Processing (NLP). A second aspect involves optimizing the process leading to their integration in applications. With this respect, we believe that the production of a consensual specification on lexicons can be a useful aid for the various NLP actors. Within ISO, the purpose of LMF is to define a standard for lexicons. LMF is a model that provides a common standardized framework for the construction of NLP lexicons. The goals of LMF are to provide a common model for the creation and use of lexical resources, to manage the exchange of data between and among these resources, and to enable the merging of large number of individual electronic resources to form extensive global electronic resources. In this paper, we describe the work in progress within the sub-group ISO-TC37/SC4/WG4. Various experts from a lot of countries have been consulted in order to take into account best practices in a lot of languages for (we hope) all kinds of NLP lexicons.",
            "referenceCount": 3,
            "citationCount": 222,
            "influentialCitationCount": 28,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2006-05-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Francopoulo2006LexicalMF,\n author = {Gil Francopoulo and M. George and N. Calzolari and M. Monachini and N\u00faria Bel and Mandy Pet and C. Soria},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {233-236},\n title = {Lexical Markup Framework (LMF)},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d68469ef055bf0db233dc2214bfc94f0fc81c34d",
            "@type": "ScholarlyArticle",
            "paperId": "d68469ef055bf0db233dc2214bfc94f0fc81c34d",
            "corpusId": 6243328,
            "url": "https://www.semanticscholar.org/paper/d68469ef055bf0db233dc2214bfc94f0fc81c34d",
            "title": "A computer-aided environment for generating multiple-choice test items",
            "venue": "Natural Language Engineering",
            "publicationVenue": {
                "id": "urn:research:b0dc264e-1ef6-4c58-be54-d2e6137ac35f",
                "name": "Natural Language Engineering",
                "alternate_names": [
                    "Nat Lang Eng"
                ],
                "issn": "1351-3249",
                "url": "https://www.cambridge.org/core/journals/natural-language-engineering"
            },
            "year": 2006,
            "externalIds": {
                "MAG": "2069032672",
                "DBLP": "journals/nle/MitkovHK06",
                "DOI": "10.1017/S1351324906004177",
                "CorpusId": 6243328
            },
            "abstract": "This paper describes a novel computer-aided procedure for generating multiple-choice test items from electronic documents. In addition to employing various Natural Language Processing techniques, including shallow parsing, automatic term extraction, sentence transformation and computing of semantic distance, the system makes use of language resources such as corpora and ontologies. It identifies important concepts in the text and generates questions about these concepts as well as multiple-choice distractors, offering the user the option to post-edit the test items by means of a user-friendly interface. In assisting test developers to produce items in a fast and expedient manner without compromising quality, the tool saves both time and production costs.",
            "referenceCount": 19,
            "citationCount": 230,
            "influentialCitationCount": 19,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2006-05-22",
            "journal": {
                "name": "Natural Language Engineering",
                "volume": "12"
            },
            "citationStyles": {
                "bibtex": "@Article{Mitkov2006ACE,\n author = {R. Mitkov and L. Ha and Nikiforos Karamanis},\n booktitle = {Natural Language Engineering},\n journal = {Natural Language Engineering},\n pages = {177 - 194},\n title = {A computer-aided environment for generating multiple-choice test items},\n volume = {12},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c52f80f056a2de8f503bf912e8025413ec2111ec",
            "@type": "ScholarlyArticle",
            "paperId": "c52f80f056a2de8f503bf912e8025413ec2111ec",
            "corpusId": 6665511,
            "url": "https://www.semanticscholar.org/paper/c52f80f056a2de8f503bf912e8025413ec2111ec",
            "title": "Transformation Based Learning in the Fast Lane",
            "venue": "North American Chapter of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:01103732-3808-4930-b8e4-7e9e68d5c68d",
                "name": "North American Chapter of the Association for Computational Linguistics",
                "alternate_names": [
                    "North Am Chapter Assoc Comput Linguistics",
                    "NAACL"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/naacl"
            },
            "year": 2001,
            "externalIds": {
                "MAG": "2085606725",
                "ACL": "N01-1006",
                "DBLP": "conf/naacl/NgaiF01",
                "ArXiv": "cs/0107020",
                "DOI": "10.3115/1073336.1073342",
                "CorpusId": 6665511
            },
            "abstract": "Transformation-based learning has been successfully employed to solve many natural language processing problems. It achieves state-of-the-art performance on many natural language processing tasks and does not overtrain easily. However, it does have a serious drawback: the training time is often intorelably long, especially on the large corpora which are often used in NLP. In this paper, we present a novel and realistic method for speeding up the training time of a transformation-based learner without sacrificing performance. The paper compares and contrasts the training time needed and performance achieved by our modified learner with two other systems: a standard transformation-based learner, and the ICA system (Hepple, 2000). The results of these experiments show that our system is able to achieve a significant improvement in training time while still achieving the same performance as a standard transformation-based learner. This is a valuable contribution to systems and algorithms which utilize transformation-based learning at any part of the execution.",
            "referenceCount": 18,
            "citationCount": 255,
            "influentialCitationCount": 28,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://acl.ldc.upenn.edu/N/N01/N01-1006.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2001-06-02",
            "journal": {
                "name": "ArXiv",
                "volume": "cs.CL/0107020"
            },
            "citationStyles": {
                "bibtex": "@Article{Ngai2001TransformationBL,\n author = {G. Ngai and Radu Florian},\n booktitle = {North American Chapter of the Association for Computational Linguistics},\n journal = {ArXiv},\n title = {Transformation Based Learning in the Fast Lane},\n volume = {cs.CL/0107020},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:46728f07dc312f812e0cc94b2c6455aea2eaccdb",
            "@type": "ScholarlyArticle",
            "paperId": "46728f07dc312f812e0cc94b2c6455aea2eaccdb",
            "corpusId": 17700848,
            "url": "https://www.semanticscholar.org/paper/46728f07dc312f812e0cc94b2c6455aea2eaccdb",
            "title": "Sentic Computing for patient centered applications",
            "venue": "IEEE 10th INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2010,
            "externalIds": {
                "MAG": "2019109450",
                "DOI": "10.1109/ICOSP.2010.5657072",
                "CorpusId": 17700848
            },
            "abstract": "Next-generation patients are far from being peripheral to health-care. They are central to understanding the effectiveness and efficiency of services and how they can be improved. Today a lot of patients are used to reviewing local health services on-line but this social information is just stored in natural language text and it is not machine-accessible and machine-processable. To distil knowledge from this extremely unstructured information we use Sentie Computing, a new opinion mining and sentiment analysis paradigm which exploits AI and Semantic Web techniques to better recognize, interpret and process opinions and sentiments in natural language text. In particular, we use a language visualization and analysis system, a novel emotion categorization model, a resource for opinion mining based on a web ontology and novel techniques for finding and defining topic dependent concepts, namely spectral association and CF-IOF weighting respectively.",
            "referenceCount": 14,
            "citationCount": 116,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Conference",
                "Review"
            ],
            "publicationDate": "2010-12-03",
            "journal": {
                "name": "IEEE 10th INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Conference{Cambria2010SenticCF,\n author = {E. Cambria and A. Hussain and T. Durrani and Catherine Havasi and Chris Eckl and James Munro},\n booktitle = {IEEE 10th INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS},\n journal = {IEEE 10th INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS},\n pages = {1279-1282},\n title = {Sentic Computing for patient centered applications},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5d24afe3a62331ebfad400c3fec77c836d2b99db",
            "@type": "ScholarlyArticle",
            "paperId": "5d24afe3a62331ebfad400c3fec77c836d2b99db",
            "corpusId": 3211177,
            "url": "https://www.semanticscholar.org/paper/5d24afe3a62331ebfad400c3fec77c836d2b99db",
            "title": "Word Space",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 1992,
            "externalIds": {
                "DBLP": "conf/nips/Schutze92",
                "MAG": "2295097532",
                "DOI": "10.1007/1-4020-0613-6_21189",
                "CorpusId": 3211177
            },
            "abstract": null,
            "referenceCount": 16,
            "citationCount": 310,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1992-11-30",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Sch\u00fctze1992WordS,\n author = {Hinrich Sch\u00fctze},\n booktitle = {Neural Information Processing Systems},\n pages = {895-902},\n title = {Word Space},\n year = {1992}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:24b20f7b118588055346f4ac5cdb1fe22e886dda",
            "@type": "ScholarlyArticle",
            "paperId": "24b20f7b118588055346f4ac5cdb1fe22e886dda",
            "corpusId": 5881111,
            "url": "https://www.semanticscholar.org/paper/24b20f7b118588055346f4ac5cdb1fe22e886dda",
            "title": "Interpolating between types and tokens by estimating power-law generators",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2005,
            "externalIds": {
                "DBLP": "conf/nips/GoldwaterGJ05",
                "MAG": "2159399018",
                "CorpusId": 5881111
            },
            "abstract": "Standard statistical models of language fail to capture one of the most striking properties of natural languages: the power-law distribution in the frequencies of word tokens. We present a framework for developing statistical models that generically produce power-laws, augmenting standard generative models with an adaptor that produces the appropriate pattern of token frequencies. We show that taking a particular stochastic process - the Pitman-Yor process - as an adaptor justifies the appearance of type frequencies in formal analyses of natural language, and improves the performance of a model for unsupervised learning of morphology.",
            "referenceCount": 17,
            "citationCount": 228,
            "influentialCitationCount": 23,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2005-12-05",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Goldwater2005InterpolatingBT,\n author = {S. Goldwater and T. Griffiths and Mark Johnson},\n booktitle = {Neural Information Processing Systems},\n pages = {459-466},\n title = {Interpolating between types and tokens by estimating power-law generators},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5d254a2486e90d0f4af1e8d1d182202ca2b25ba6",
            "@type": "ScholarlyArticle",
            "paperId": "5d254a2486e90d0f4af1e8d1d182202ca2b25ba6",
            "corpusId": 59962715,
            "url": "https://www.semanticscholar.org/paper/5d254a2486e90d0f4af1e8d1d182202ca2b25ba6",
            "title": "Comparing English worldwide : the International Corpus of English",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1996,
            "externalIds": {
                "MAG": "628960435",
                "CorpusId": 59962715
            },
            "abstract": "The International Corpus of English is a unique linguistic and sociolinguistic project. When complete it will consist of fifteen or more parallel corpora of spoken English drawn from countries where English is either a majority first language or an official second language. Part I introduces the ICE project and a sub-project that investigates writing by advanced learners of English. Part II describes in detail the design of the corpora, the markup systems for speech and writing, the ICE tagset and parsing scheme, and the software packages that have been developed for automatic tagging and parsing, and for retrieving lexical, grammatical, and sociolinguistic information. Part III discusses problems in compiling the corpora, exemplified by the experience of teams in New Zealand, East Africa, and Hong Kong. Finally, Part IV considers some of the applications envisaged for the corpora: research in linguistics, sociolinguistics and natural language processing; teaching, language planning, and the establishment of norms for teaching and examining in second-language countries.",
            "referenceCount": 0,
            "citationCount": 253,
            "influentialCitationCount": 25,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Greenbaum1996ComparingEW,\n author = {Sidney Greenbaum},\n title = {Comparing English worldwide : the International Corpus of English},\n year = {1996}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4e7560f48806d56612349c2ab0086ad0cff986f4",
            "@type": "ScholarlyArticle",
            "paperId": "4e7560f48806d56612349c2ab0086ad0cff986f4",
            "corpusId": 11533588,
            "url": "https://www.semanticscholar.org/paper/4e7560f48806d56612349c2ab0086ad0cff986f4",
            "title": "An Efficient Method for Determining Bilingual Word Classes",
            "venue": "Conference of the European Chapter of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:8de18c35-6785-4e54-99f2-21ee961302c6",
                "name": "Conference of the European Chapter of the Association for Computational Linguistics",
                "alternate_names": [
                    "Conf Eur Chapter Assoc Comput Linguistics",
                    "EACL"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/eacl/"
            },
            "year": 1999,
            "externalIds": {
                "MAG": "2083460949",
                "ACL": "E99-1010",
                "DBLP": "conf/eacl/Och99",
                "DOI": "10.3115/977035.977046",
                "CorpusId": 11533588
            },
            "abstract": "In statistical natural language processing we always face the problem of sparse data. One way to reduce this problem is to group words into equivalence classes which is a standard method in statistical language modeling. In this paper we describe a method to determine bilingual word classes suitable for statistical machine translation. We develop an optimization criterion based on a maximum-likelihood approach and describe a clustering algorithm. We will show that the usage of the bilingual word classes we get can improve statistical machine translation.",
            "referenceCount": 12,
            "citationCount": 255,
            "influentialCitationCount": 16,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.3115/977035.977046",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1999-06-08",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Och1999AnEM,\n author = {F. Och},\n booktitle = {Conference of the European Chapter of the Association for Computational Linguistics},\n pages = {71-76},\n title = {An Efficient Method for Determining Bilingual Word Classes},\n year = {1999}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1e5c33ab632310d827155002311e0adceebb6ec0",
            "@type": "ScholarlyArticle",
            "paperId": "1e5c33ab632310d827155002311e0adceebb6ec0",
            "corpusId": 11515711,
            "url": "https://www.semanticscholar.org/paper/1e5c33ab632310d827155002311e0adceebb6ec0",
            "title": "SCISOR: extracting information from on-line news",
            "venue": "CACM",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1990,
            "externalIds": {
                "DBLP": "journals/cacm/JacobsR90",
                "MAG": "2079690930",
                "DOI": "10.1145/92755.92769",
                "CorpusId": 11515711
            },
            "abstract": "The future of natural language text processing is examined in the SCISOR prototype. Drawing on artificial intelligence techniques, and applying them to financial news items, this powerful tool illustrates some of the future benefits of natural language analysis through a combination of bottom-up and top-down processing.",
            "referenceCount": 25,
            "citationCount": 314,
            "influentialCitationCount": 9,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/92755.92769",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Business",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1990-11-01",
            "journal": {
                "name": "Commun. ACM",
                "volume": "33"
            },
            "citationStyles": {
                "bibtex": "@Article{Jacobs1990SCISOREI,\n author = {P. Jacobs and L. Rau},\n booktitle = {CACM},\n journal = {Commun. ACM},\n pages = {88-97},\n title = {SCISOR: extracting information from on-line news},\n volume = {33},\n year = {1990}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9903c08de6d0ff58a2e45b49cd11046e4333c5c5",
            "@type": "ScholarlyArticle",
            "paperId": "9903c08de6d0ff58a2e45b49cd11046e4333c5c5",
            "corpusId": 4367214,
            "url": "https://www.semanticscholar.org/paper/9903c08de6d0ff58a2e45b49cd11046e4333c5c5",
            "title": "Border crossings",
            "venue": "Nature",
            "publicationVenue": {
                "id": "urn:research:6c24a0a0-b07d-4d7b-a19b-fd09a3ed453a",
                "name": "Nature",
                "alternate_names": null,
                "issn": "0028-0836",
                "url": "https://www.nature.com/"
            },
            "year": 2004,
            "externalIds": {
                "MAG": "2002076713",
                "DOI": "10.1038/443397a",
                "CorpusId": 4367214
            },
            "abstract": null,
            "referenceCount": 1,
            "citationCount": 231,
            "influentialCitationCount": 20,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/443397a.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Philosophy",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Philosophy",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2004-01-01",
            "journal": {
                "name": "Nature",
                "volume": "443"
            },
            "citationStyles": {
                "bibtex": "@Article{Eijck2004BorderC,\n author = {J. Eijck},\n booktitle = {Nature},\n journal = {Nature},\n pages = {397-397},\n title = {Border crossings},\n volume = {443},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5b24ec5dc67169c3ddbd671d09fc62b6d15f9bd0",
            "@type": "ScholarlyArticle",
            "paperId": "5b24ec5dc67169c3ddbd671d09fc62b6d15f9bd0",
            "corpusId": 5689600,
            "url": "https://www.semanticscholar.org/paper/5b24ec5dc67169c3ddbd671d09fc62b6d15f9bd0",
            "title": "Research Paper: Automatic Detection of Acute Bacterial Pneumonia from Chest X-ray Reports",
            "venue": "J. Am. Medical Informatics Assoc.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2000,
            "externalIds": {
                "MAG": "2125726375",
                "DBLP": "journals/jamia/FiszmanCAEH00",
                "DOI": "10.1136/jamia.2000.0070593",
                "CorpusId": 5689600,
                "PubMed": "11062233"
            },
            "abstract": "OBJECTIVE\nTo evaluate the performance of a natural language processing system in extracting pneumonia-related concepts from chest x-ray reports.\n\n\nMETHODS\n\n\n\nDESIGN\nFour physicians, three lay persons, a natural language processing system, and two keyword searches (designated AAKS and KS) detected the presence or absence of three pneumonia-related concepts and inferred the presence or absence of acute bacterial pneumonia from 292 chest x-ray reports. Gold standard: Majority vote of three independent physicians. Reliability of the gold standard was measured.\n\n\nOUTCOME MEASURES\nRecall, precision, specificity, and agreement (using Finn's R: statistic) with respect to the gold standard. Differences between the physicians and the other subjects were tested using the McNemar test for each pneumonia concept and for the disease inference of acute bacterial pneumonia.\n\n\nRESULTS\nReliability of the reference standard ranged from 0.86 to 0.96. Recall, precision, specificity, and agreement (Finn R:) for the inference on acute bacterial pneumonia were, respectively, 0.94, 0.87, 0.91, and 0.84 for physicians; 0.95, 0.78, 0.85, and 0.75 for natural language processing system; 0.46, 0.89, 0.95, and 0.54 for lay persons; 0.79, 0.63, 0.71, and 0.49 for AAKS; and 0.87, 0.70, 0.77, and 0.62 for KS. The McNemar pairwise comparisons showed differences between one physician and the natural language processing system for the infiltrate concept and between another physician and the natural language processing system for the inference on acute bacterial pneumonia. The comparisons also showed that most physicians were significantly different from the other subjects in all pneumonia concepts and the disease inference.\n\n\nCONCLUSION\nIn extracting pneumonia related concepts from chest x-ray reports, the performance of the natural language processing system was similar to that of physicians and better than that of lay persons and keyword searches. The encoded pneumonia information has the potential to support several pneumonia-related applications used in our institution. The applications include a decision support system called the antibiotic assistant, a computerized clinical protocol for pneumonia, and a quality assurance application in the radiology department.",
            "referenceCount": 33,
            "citationCount": 251,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://academic.oup.com/jamia/article-pdf/7/6/593/2208089/7-6-593.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Study"
            ],
            "publicationDate": "2000-11-01",
            "journal": {
                "name": "Journal of the American Medical Informatics Association : JAMIA",
                "volume": "7 6"
            },
            "citationStyles": {
                "bibtex": "@Article{Fiszman2000ResearchPA,\n author = {M. Fiszman and W. Chapman and D. Aronsky and R. Evans and P. Haug},\n booktitle = {J. Am. Medical Informatics Assoc.},\n journal = {Journal of the American Medical Informatics Association : JAMIA},\n pages = {\n          593-604\n        },\n title = {Research Paper: Automatic Detection of Acute Bacterial Pneumonia from Chest X-ray Reports},\n volume = {7 6},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7c8b067649f09b9260569d6e398c5c1b16fa2712",
            "@type": "ScholarlyArticle",
            "paperId": "7c8b067649f09b9260569d6e398c5c1b16fa2712",
            "corpusId": 12308112,
            "url": "https://www.semanticscholar.org/paper/7c8b067649f09b9260569d6e398c5c1b16fa2712",
            "title": "Automatic paraphrase acquisition from news articles",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2002,
            "externalIds": {
                "MAG": "2793847531",
                "DOI": "10.3115/1289189.1289218",
                "CorpusId": 12308112
            },
            "abstract": "Paraphrases play an important role in the variety and complexity of natural language documents. However, they add to the difficulty of natural language processing. Here we describe a procedure for obtaining paraphrases from news articles. Articles derived from different newspapers can contain paraphrases if they report the same event on the same day. We exploit this feature by using Named Entity recognition. Our approach is based on the assumption that Named Entities are preserved across paraphrases. We applied our method to articles of two domains and obtained notable examples. Although this is our initial attempt at automatically extracting paraphrases from a corpus, the results are promising.",
            "referenceCount": 9,
            "citationCount": 230,
            "influentialCitationCount": 16,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2002-03-24",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Shinyama2002AutomaticPA,\n author = {Yusuke Shinyama and S. Sekine and Kiyoshi Sudo},\n pages = {313-318},\n title = {Automatic paraphrase acquisition from news articles},\n year = {2002}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7eb4731df814c5e7dc40dbeec2a549e3737dcd7c",
            "@type": "ScholarlyArticle",
            "paperId": "7eb4731df814c5e7dc40dbeec2a549e3737dcd7c",
            "corpusId": 5242820,
            "url": "https://www.semanticscholar.org/paper/7eb4731df814c5e7dc40dbeec2a549e3737dcd7c",
            "title": "A Linguistically Motivated Probabilistic Model of Information Retrieval",
            "venue": "European Conference on Research and Advanced Technology for Digital Libraries",
            "publicationVenue": {
                "id": "urn:research:cfe80abc-44ba-414f-8c9b-3f1cb68c8fa6",
                "name": "European Conference on Research and Advanced Technology for Digital Libraries",
                "alternate_names": [
                    "ECDL",
                    "Eur Conf Res Adv Technol Digit Libr"
                ],
                "issn": null,
                "url": null
            },
            "year": 1998,
            "externalIds": {
                "DBLP": "conf/ercimdl/Hiemstra98",
                "MAG": "1513915383",
                "DOI": "10.1007/3-540-49653-X_34",
                "CorpusId": 5242820
            },
            "abstract": null,
            "referenceCount": 18,
            "citationCount": 233,
            "influentialCitationCount": 21,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ris.utwente.nl/ws/files/174701563/Hiemstra1998_Chapter_ALinguisticallyMotivatedProbab.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1998-09-21",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hiemstra1998ALM,\n author = {D. Hiemstra},\n booktitle = {European Conference on Research and Advanced Technology for Digital Libraries},\n pages = {569-584},\n title = {A Linguistically Motivated Probabilistic Model of Information Retrieval},\n year = {1998}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:910fdc1d740fd010ef56b07029c24c6eb2ac53f9",
            "@type": "ScholarlyArticle",
            "paperId": "910fdc1d740fd010ef56b07029c24c6eb2ac53f9",
            "corpusId": 5744228,
            "url": "https://www.semanticscholar.org/paper/910fdc1d740fd010ef56b07029c24c6eb2ac53f9",
            "title": "Optimizing SVMs for complex call classification",
            "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
            "publicationVenue": {
                "id": "urn:research:0d6f7fba-7092-46b3-8039-93458dba736b",
                "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                "alternate_names": [
                    "Int Conf Acoust Speech Signal Process",
                    "IEEE Int Conf Acoust Speech Signal Process",
                    "ICASSP",
                    "International Conference on Acoustics, Speech, and Signal Processing"
                ],
                "issn": null,
                "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002"
            },
            "year": 2003,
            "externalIds": {
                "MAG": "1550863320",
                "DBLP": "conf/icassp/HaffnerTW03",
                "DOI": "10.1109/ICASSP.2003.1198860",
                "CorpusId": 5744228
            },
            "abstract": "Large margin classifiers such as support vector machines (SVM) or Adaboost are obvious choices for natural language document or call routing. However, how to combine several binary classifiers to optimize the whole routing process and how this process scales when it involves many different decisions (or classes) is a complex problem that has only received partial answers. We propose a global optimization process based on an optimal channel communication model that allows a combination of possibly heterogeneous binary classifiers. As in Markov modeling, computational feasibility is achieved through simplifications and independence assumptions that are easy to interpret. Using this approach, we have managed to decrease the call-type classification error rate for AT&T's How May I Help You (HMIHY/sup (sm)/) natural dialog system by 50 %.",
            "referenceCount": 19,
            "citationCount": 225,
            "influentialCitationCount": 18,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2003-04-06",
            "journal": {
                "name": "2003 IEEE International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings. (ICASSP '03).",
                "volume": "1"
            },
            "citationStyles": {
                "bibtex": "@Article{Haffner2003OptimizingSF,\n author = {P. Haffner and G\u00f6khan T\u00fcr and Jeremy H. Wright},\n booktitle = {IEEE International Conference on Acoustics, Speech, and Signal Processing},\n journal = {2003 IEEE International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings. (ICASSP '03).},\n pages = {I-I},\n title = {Optimizing SVMs for complex call classification},\n volume = {1},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a8f79b9f8027b1ecc8ab6f8f873f8d3252de69be",
            "@type": "ScholarlyArticle",
            "paperId": "a8f79b9f8027b1ecc8ab6f8f873f8d3252de69be",
            "corpusId": 5230471,
            "url": "https://www.semanticscholar.org/paper/a8f79b9f8027b1ecc8ab6f8f873f8d3252de69be",
            "title": "A probabilistic justification for using tf\u00d7idf term weighting in information retrieval\n",
            "venue": "International Journal on Digital Libraries",
            "publicationVenue": {
                "id": "urn:research:c79aa48a-5be0-4cc6-851b-549f1cf3df25",
                "name": "International Journal on Digital Libraries",
                "alternate_names": [
                    "Int J Digit Libr"
                ],
                "issn": "1432-1300",
                "url": "https://link.springer.com/journal/799"
            },
            "year": 2000,
            "externalIds": {
                "DBLP": "journals/jodl/Hiemstra00",
                "MAG": "2096468639",
                "DOI": "10.1007/s007999900025",
                "CorpusId": 5230471
            },
            "abstract": null,
            "referenceCount": 20,
            "citationCount": 214,
            "influentialCitationCount": 15,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ris.utwente.nl/ws/files/6549341/ijodl.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2000-08-01",
            "journal": {
                "name": "International Journal on Digital Libraries",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{Hiemstra2000APJ,\n author = {D. Hiemstra},\n booktitle = {International Journal on Digital Libraries},\n journal = {International Journal on Digital Libraries},\n pages = {131-139},\n title = {A probabilistic justification for using tf\u00d7idf term weighting in information retrieval\n},\n volume = {3},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8e4ca575fc5759aff9b6e7450c2f17681c75f8d5",
            "@type": "ScholarlyArticle",
            "paperId": "8e4ca575fc5759aff9b6e7450c2f17681c75f8d5",
            "corpusId": 60451180,
            "url": "https://www.semanticscholar.org/paper/8e4ca575fc5759aff9b6e7450c2f17681c75f8d5",
            "title": "The N-best algorithms: an efficient and exact procedure for finding the N most likely sentence hypotheses",
            "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
            "publicationVenue": {
                "id": "urn:research:0d6f7fba-7092-46b3-8039-93458dba736b",
                "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                "alternate_names": [
                    "Int Conf Acoust Speech Signal Process",
                    "IEEE Int Conf Acoust Speech Signal Process",
                    "ICASSP",
                    "International Conference on Acoustics, Speech, and Signal Processing"
                ],
                "issn": null,
                "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002"
            },
            "year": 1990,
            "externalIds": {
                "DBLP": "conf/icassp/SchwartzC90",
                "MAG": "1524975733",
                "DOI": "10.1109/ICASSP.1990.115542",
                "CorpusId": 60451180
            },
            "abstract": "A search algorithm that provides a simple, clean, and efficient interface between the speech and natural language components of a spoken language system is introduced. The N-best algorithm is a time-synchronous Viterbi-style beam search procedure that is guaranteed to find the N most likely whole sentence alternatives that are within a given beam of the most likely sentence. The computation is linear with the length of the utterance, and faster than linear in N. When used together with a first-order statistical grammar, the correct sentence is usually within the first few sentence choices. The output of the algorithm, which is an ordered set of sentence hypotheses with acoustic and language model scores can easily be processed by natural language knowledge sources without the huge expansion of the search space that would be needed to include all possible knowledge sources in a top-down search. In experiments using a first-order statistical language model, the average rank of the correct answer was 1.8 and was within the first 24 choices 99% of the time.<<ETX>>",
            "referenceCount": 6,
            "citationCount": 253,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1990-04-03",
            "journal": {
                "name": "International Conference on Acoustics, Speech, and Signal Processing",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Schwartz1990TheNA,\n author = {R. Schwartz and Y. Chow},\n booktitle = {IEEE International Conference on Acoustics, Speech, and Signal Processing},\n journal = {International Conference on Acoustics, Speech, and Signal Processing},\n pages = {81-84 vol.1},\n title = {The N-best algorithms: an efficient and exact procedure for finding the N most likely sentence hypotheses},\n year = {1990}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:218386bff0869d283b6c869b873db91a8867d4ca",
            "@type": "ScholarlyArticle",
            "paperId": "218386bff0869d283b6c869b873db91a8867d4ca",
            "corpusId": 13006918,
            "url": "https://www.semanticscholar.org/paper/218386bff0869d283b6c869b873db91a8867d4ca",
            "title": "WordNet then and now",
            "venue": "Language Resources and Evaluation",
            "publicationVenue": {
                "id": "urn:research:7dda5bd1-752f-45e5-bc7b-09633096916e",
                "name": "Language Resources and Evaluation",
                "alternate_names": [
                    "Lang Resour Evaluation"
                ],
                "issn": "1574-020X",
                "url": "https://link.springer.com/journal/10579"
            },
            "year": 2007,
            "externalIds": {
                "DBLP": "journals/lre/MillerF07",
                "MAG": "2085529678",
                "DOI": "10.1007/s10579-007-9044-6",
                "CorpusId": 13006918
            },
            "abstract": null,
            "referenceCount": 21,
            "citationCount": 106,
            "influentialCitationCount": 14,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2007-10-20",
            "journal": {
                "name": "Language Resources and Evaluation",
                "volume": "41"
            },
            "citationStyles": {
                "bibtex": "@Article{Miller2007WordNetTA,\n author = {G. Miller and C. Fellbaum},\n booktitle = {Language Resources and Evaluation},\n journal = {Language Resources and Evaluation},\n pages = {209-214},\n title = {WordNet then and now},\n volume = {41},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e7316c33d627b94d2fb9674e4af6408d70dbb52f",
            "@type": "ScholarlyArticle",
            "paperId": "e7316c33d627b94d2fb9674e4af6408d70dbb52f",
            "corpusId": 17089924,
            "url": "https://www.semanticscholar.org/paper/e7316c33d627b94d2fb9674e4af6408d70dbb52f",
            "title": "The birth of Prolog",
            "venue": "HOPL-II",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1993,
            "externalIds": {
                "MAG": "1969456304",
                "DBLP": "conf/hopl/ColmerauerR93",
                "DOI": "10.1145/154766.155362",
                "CorpusId": 17089924
            },
            "abstract": "The programming language, Prolog, was born of a project aimed not at producing a programming language but at processing natural languages; in this case, French. The project gave rise to a preliminary version of Prolog at the end of 1971 and a more definitive version at the end of 1972. This article gives the history of this project and describes in detail the preliminary and then the final versions of Prolog. The authors also felt it appropriate to describe the Q-systems since it was a language which played a prominent part in Prolog's genesis.",
            "referenceCount": 38,
            "citationCount": 287,
            "influentialCitationCount": 14,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/154766.155362",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1993-03-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Colmerauer1993TheBO,\n author = {A. Colmerauer and P. Roussel},\n booktitle = {HOPL-II},\n pages = {37-52},\n title = {The birth of Prolog},\n year = {1993}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:92f6c63a25c92877b2681ba1b5247c824678b408",
            "@type": "ScholarlyArticle",
            "paperId": "92f6c63a25c92877b2681ba1b5247c824678b408",
            "corpusId": 8009818,
            "url": "https://www.semanticscholar.org/paper/92f6c63a25c92877b2681ba1b5247c824678b408",
            "title": "Bidirectional Incremental Parsing for Automatic Pathway Identification with Combinatory Categorial Grammar",
            "venue": "Pacific Symposium on Biocomputing",
            "publicationVenue": {
                "id": "urn:research:bf8c915b-282b-4817-987d-62e47e42d5e1",
                "name": "Pacific Symposium on Biocomputing",
                "alternate_names": [
                    "PSB",
                    "Pac Symp Biocomput"
                ],
                "issn": null,
                "url": "http://psb.stanford.edu/"
            },
            "year": 2000,
            "externalIds": {
                "MAG": "2093618552",
                "DBLP": "conf/psb/ParkKK01",
                "DOI": "10.1142/9789814447362_0039",
                "CorpusId": 8009818,
                "PubMed": "11262958"
            },
            "abstract": "As the importance of automatically extracting and analyzing various natural language assertions about protein-protein interactions in biomedical publications is recognized, many uses of natural language processing techniques are proposed in the literature. However, most proposals to date make rather simplifying assumptions about the syntactic aspects of natural language due to various reasons including efficiency. In this paper, we describe an implemented system that utilizes combinatory categorical grammar known to be competent in modeling natural language, with a controlled mechanism for the parser to operate bidirectionally and incrementally. We discuss the performance of the system on a large set of abstracts in Medline with quite encouraging results.",
            "referenceCount": 8,
            "citationCount": 180,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2000-12-01",
            "journal": {
                "name": "Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Park2000BidirectionalIP,\n author = {Jong C. Park and Hyun Sook Kim and Jung-jae Kim},\n booktitle = {Pacific Symposium on Biocomputing},\n journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},\n pages = {\n          396-407\n        },\n title = {Bidirectional Incremental Parsing for Automatic Pathway Identification with Combinatory Categorial Grammar},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f5d2470662d9007afef0dfc7e45f2547476ab332",
            "@type": "ScholarlyArticle",
            "paperId": "f5d2470662d9007afef0dfc7e45f2547476ab332",
            "corpusId": 16718187,
            "url": "https://www.semanticscholar.org/paper/f5d2470662d9007afef0dfc7e45f2547476ab332",
            "title": "Two Families of Languages Related to ALGOL",
            "venue": "JACM",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1962,
            "externalIds": {
                "DBLP": "journals/jacm/GinsburgR62",
                "MAG": "2000118875",
                "DOI": "10.1145/321127.321132",
                "CorpusId": 16718187
            },
            "abstract": "A serious drawback in the application of modern data processing systems is the cost and time consumed in programming these complexes. The user's problems and their solutions are described in a natural language such as English. To utilize the services of a data processor, it is necessary to convert this language description into machine language, to wit, program steps. Recently, attempts have arisen to bridge the gap between these two languages. The method has been to construct languages (called problem oriented languages, or POL) that are (i) rich enough to allow a description of a set of problems and their solutions; (ii) reasonably close to the user's ordinary language of description and solution; and (iii) formal enough to permit a mechanical translation into machine language. COBOL and ALGOL are two examples of POL. The purpose of this investigation is to gain some insight into the syntax of POL, in particular ALGOL [1]. Specifically, the method of defining constituent parts of ALGOL 60 is abstracted, this giving rise to a family of sets of strings; and mathematical facts about the resulting family deduced. Now an ALGoL-like definable language (we hesitate to use the inclusive term \"POL\") may be viewed either as one of these sets (the set of sentences) ; or else, as a finite collection of these sets, one of which is the set of sentences, and the remaining, the constituent parts of the language used to construct the sentences. This is in line with one current view of natural languages [4, 5, 6]. The defining scheme for ALOOL turns out to be equivalent to one of the several schemes described by Chomsky [6] in his attempt to analyze the syntax of natural languages. Of course, POL, as special kinds of languages, should fit into a general theory of language. However, it is reasonable to expect that POL, as artificial languages contrived so as to be capable of being mechanically translated into machine language, should have a syntax simpler than that of the natural languages. The technical results achieved in this paper are as follows. Two families of sets (of strings), the family of definable sets and the family of sequentially definable sets, are described. Definable sets are obtained from a system of simultaneous equations, all the equations being of a certain form. This system, essentially parallel in nature, is an abstraction of the ALGOL method of description. Definable sets turn out to be identical to the type 2 languages (with identity) introduced by Chomsky [6]. Sequentially definable sets are obtained from a system",
            "referenceCount": 11,
            "citationCount": 282,
            "influentialCitationCount": 18,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/321127.321132",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1962-07-01",
            "journal": {
                "name": "J. ACM",
                "volume": "9"
            },
            "citationStyles": {
                "bibtex": "@Article{Ginsburg1962TwoFO,\n author = {Seymour Ginsburg and H. G. Rice},\n booktitle = {JACM},\n journal = {J. ACM},\n pages = {350-371},\n title = {Two Families of Languages Related to ALGOL},\n volume = {9},\n year = {1962}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:80d8a20897a577f8acb9020aa9189fef437e8f5d",
            "@type": "ScholarlyArticle",
            "paperId": "80d8a20897a577f8acb9020aa9189fef437e8f5d",
            "corpusId": 8849284,
            "url": "https://www.semanticscholar.org/paper/80d8a20897a577f8acb9020aa9189fef437e8f5d",
            "title": "XCES: An XML-based Encoding Standard for Linguistic Corpora",
            "venue": "International Conference on Language Resources and Evaluation",
            "publicationVenue": {
                "id": "urn:research:7474c4a0-75d9-4105-9809-8e7d5201c5e1",
                "name": "International Conference on Language Resources and Evaluation",
                "alternate_names": [
                    "LREC",
                    "Int Conf Lang Resour Evaluation"
                ],
                "issn": null,
                "url": "http://www.lrec-conf.org/"
            },
            "year": 2000,
            "externalIds": {
                "MAG": "2277722610",
                "ACL": "L00-1127",
                "DBLP": "conf/lrec/IdeBR00",
                "CorpusId": 8849284
            },
            "abstract": "The Corpus Encoding Standard (CES) is a part of the EAGLES Guidelines developed by the Expert Advisory Group on Language Engineering Standards (EAGLES) that provides a set of encoding standards for corpus-based work in natural language processing applications. We have instantiated the CES as an XML application called XCES, based on the same data architecture comprised of a primary encoded text and \"standoff\" annotation in separate documents. Conversion to XML enables use of some of the more powerful mechanisms provided in the XML framework, including the XSLT Transformation Language, XML Schemas, and support for interrescue reference together with an extensive path syntax for pointers. In this paper, we describe the differences between the CES and XCES DTDs and demonstrate how XML mechanisms can be used to select from and manipulate annotated corpora encoded according to XCES specifications. We also provide a general overview of XML and the XML mechanisms that are most relevant to language engineering research and applications.",
            "referenceCount": 22,
            "citationCount": 173,
            "influentialCitationCount": 18,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Ide2000XCESAX,\n author = {Nancy Ide and P. Bonhomme and Laurent Romary},\n booktitle = {International Conference on Language Resources and Evaluation},\n title = {XCES: An XML-based Encoding Standard for Linguistic Corpora},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e3c15067ab7ce4adda6e2d9d534b501b9ffccf32",
            "@type": "ScholarlyArticle",
            "paperId": "e3c15067ab7ce4adda6e2d9d534b501b9ffccf32",
            "corpusId": 1397113,
            "url": "https://www.semanticscholar.org/paper/e3c15067ab7ce4adda6e2d9d534b501b9ffccf32",
            "title": "Mathematical Linguistics",
            "venue": "Advanced Information and Knowledge Processing",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2007,
            "externalIds": {
                "DBLP": "series/aikp/Kornai08",
                "MAG": "2611127994",
                "DOI": "10.1007/978-1-84628-986-6",
                "CorpusId": 1397113
            },
            "abstract": null,
            "referenceCount": 278,
            "citationCount": 94,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://eprints.sztaki.hu/7892/1/Kornai_1762374_ny.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book"
            ],
            "publicationDate": "2007-11-13",
            "journal": {
                "name": "Mathematical Linguistics",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Kornai2007MathematicalL,\n author = {Andr\u00e1s Kornai},\n booktitle = {Advanced Information and Knowledge Processing},\n journal = {Mathematical Linguistics},\n title = {Mathematical Linguistics},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:666ca7242ced9a8e89aa0624395704cfc647ad73",
            "@type": "ScholarlyArticle",
            "paperId": "666ca7242ced9a8e89aa0624395704cfc647ad73",
            "corpusId": 1580100,
            "url": "https://www.semanticscholar.org/paper/666ca7242ced9a8e89aa0624395704cfc647ad73",
            "title": "Text-based intelligent systems: current research and practice in information extraction and retrieval",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1992,
            "externalIds": {
                "MAG": "1848260039",
                "DOI": "10.4324/9781315806952",
                "CorpusId": 1580100
            },
            "abstract": "Contents: P.S. Jacobs, Introduction: Text Power and Intelligent Systems. Part I:Broad-Scale NLP. J.R. Hobbs, D.E. Appelt, J. Bear, M. Tyson, D. Magerman, Robust Processing of Real-World Natural-Language Texts. Y. Wilks, L. Guthrie, J. Guthrie, J. Cowie, Combining Weak Methods in Large-Scale Text Processing. G. Hirst, M. Ryan, Mixed-Depth Representations for Natural Language Text. D.D. McDonald, Robust Partial-Parsing Through Incremental, Multi-Algorithm Processing. Corpus-Based Thematic Analysis. Part II:\"Traditional\" Information Retrieval. W.B. Croft, H.R. Turtle, Text Retrieval and Inference. K.S. Jones, Assumptions and Issues in Text-Based Retrieval. D.D. Lewis, Text Representation for Intelligent Text Retrieval: A Classification-Oriented View. G. Salton, C. Buckley, Automatic Text Structuring Experiments. Part III:Emerging Applications. C. Stanfill, D.L. Waltz, Statistical Methods, Artificial Intelligence, and Information Retrieval. P.J. Hayes, Intelligent High-Volume Text Processing Using Shallow, Domain-Specific Techniques. Y.S. Maarek, Automatically Constructing Simple Help Systems from Natural Language Documentation. M.A. Hearst, Direction-Based Text Interpretation as an Information Access Refinement.",
            "referenceCount": 3,
            "citationCount": 164,
            "influentialCitationCount": 7,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1992-07-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Jacobs1992TextbasedIS,\n author = {P. Jacobs},\n title = {Text-based intelligent systems: current research and practice in information extraction and retrieval},\n year = {1992}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2445814a33848e9c6a1058f7d3dda4f2f1c0a022",
            "@type": "ScholarlyArticle",
            "paperId": "2445814a33848e9c6a1058f7d3dda4f2f1c0a022",
            "corpusId": 17675343,
            "url": "https://www.semanticscholar.org/paper/2445814a33848e9c6a1058f7d3dda4f2f1c0a022",
            "title": "Data-Oriented Parsing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2003,
            "externalIds": {
                "MAG": "1938853666",
                "CorpusId": 17675343
            },
            "abstract": "Data-oriented parsing (DOP) is one of the leading paradigms in statistical natural language processing. In this volume, a collection of computational linguists offer a state-of-the-art overview of DOP, suitable for students and researchers in natural language processing and speech recognition as well as for computational linguistics. This handbook begins with the theoretical background of DOP and introduces the algorithms used in DOP as well as in other probabilistic grammar models. After surveying extensions to the basic DOP model, the volume concludes with a close study of the applications that use DOP as a backbone: speech understanding, machine translation, and language learning.",
            "referenceCount": 5,
            "citationCount": 150,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2003-02-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Bod2003DataOrientedP,\n author = {R. Bod and K. Sima'an and R. Scha},\n title = {Data-Oriented Parsing},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1d7c366ff41bc3917a0144cd3aac3647066792ab",
            "@type": "ScholarlyArticle",
            "paperId": "1d7c366ff41bc3917a0144cd3aac3647066792ab",
            "corpusId": 448730,
            "url": "https://www.semanticscholar.org/paper/1d7c366ff41bc3917a0144cd3aac3647066792ab",
            "title": "A Performance Evaluation of Text-Analysis Technologies",
            "venue": "The AI Magazine",
            "publicationVenue": {
                "id": "urn:research:6fedff74-7525-4b7f-bbb4-4df4e23948e4",
                "name": "The AI Magazine",
                "alternate_names": [
                    "AI Mag",
                    "Ai Mag",
                    "Ai Magazine"
                ],
                "issn": "0738-4602",
                "url": "https://www.aaai.org/Library/Magazine/magazine-library.php"
            },
            "year": 1991,
            "externalIds": {
                "DBLP": "journals/aim/LehnertS91",
                "MAG": "2150381178",
                "DOI": "10.1609/aimag.v12i3.905",
                "CorpusId": 448730
            },
            "abstract": "A performance evaluation of 15 text-analysis systems was recently conducted to realistically assess the state of the art for detailed information extraction from unconstrained continuous text. Reports associated with terrorism were chosen as the target domain, and all systems were tested on a collection of previously unseen texts released by a government agency. Based on multiple strategies for computing each metric, the competing systems were evaluated for recall, precision, and overgeneration. The results support the claim that systems incorporating natural language\u2010processing techniques are more effective than systems based on stochastic techniques alone. A wide range of language-processing strategies was employed by the top-scoring systems, indicating that many natural language\u2010processing techniques provide a viable foundation for sophisticated text analysis. Further evaluation is needed to produce a more detailed assessment of the relative merits of specific technologies and establish true performance limits for automated information extraction.",
            "referenceCount": 4,
            "citationCount": 159,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1991-09-01",
            "journal": {
                "name": "AI Mag.",
                "volume": "12"
            },
            "citationStyles": {
                "bibtex": "@Article{Lehnert1991APE,\n author = {W. Lehnert and B. Sundheim},\n booktitle = {The AI Magazine},\n journal = {AI Mag.},\n pages = {81-94},\n title = {A Performance Evaluation of Text-Analysis Technologies},\n volume = {12},\n year = {1991}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c6f29bd2e2de2b059d4d2349b414a7b050530bf9",
            "@type": "ScholarlyArticle",
            "paperId": "c6f29bd2e2de2b059d4d2349b414a7b050530bf9",
            "corpusId": 7240725,
            "url": "https://www.semanticscholar.org/paper/c6f29bd2e2de2b059d4d2349b414a7b050530bf9",
            "title": "Exploiting a Large Thesaurus for Information Retrieval",
            "venue": "RIAO Conference",
            "publicationVenue": {
                "id": "urn:research:ea003d98-cb1c-4330-8b54-126ed1761a30",
                "name": "RIAO Conference",
                "alternate_names": [
                    "RIAO",
                    "RIAO Conf"
                ],
                "issn": null,
                "url": null
            },
            "year": 1994,
            "externalIds": {
                "MAG": "198852883",
                "DBLP": "conf/riao/Aronson94",
                "DOI": "10.5555/2856823.2856842",
                "CorpusId": 7240725
            },
            "abstract": "Accuracy in information retrieval, that is, achieving both high recall and precision, is challenging because the relationship between natural language and semantic conceptual structure is not straightforward. However, effective retrieval requires that the semantic conceptual structure (or content) of both queries and documents be known. Natural language processing is one way to determine the content of a text. But, due to the complexity involved in natural language processing, various methods have been used which simulate (or approximate) representation of the content of both queries and documents.",
            "referenceCount": 36,
            "citationCount": 131,
            "influentialCitationCount": 7,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1994-10-11",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Aronson1994ExploitingAL,\n author = {A. Aronson},\n booktitle = {RIAO Conference},\n pages = {197-216},\n title = {Exploiting a Large Thesaurus for Information Retrieval},\n year = {1994}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:151411a7b32e40dca8a51503135c6e9e3cdbc70c",
            "@type": "ScholarlyArticle",
            "paperId": "151411a7b32e40dca8a51503135c6e9e3cdbc70c",
            "corpusId": 2036954,
            "url": "https://www.semanticscholar.org/paper/151411a7b32e40dca8a51503135c6e9e3cdbc70c",
            "title": "Automated Construction of Database Interfaces: Intergrating Statistical and Relational Learning for Semantic Parsing",
            "venue": "Conference on Empirical Methods in Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:41bf9ed3-85b3-4c90-b015-150e31690253",
                "name": "Conference on Empirical Methods in Natural Language Processing",
                "alternate_names": [
                    "Empir Method Nat Lang Process",
                    "Empirical Methods in Natural Language Processing",
                    "Conf Empir Method Nat Lang Process",
                    "EMNLP"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/emnlp"
            },
            "year": 2000,
            "externalIds": {
                "MAG": "2153710242",
                "ACL": "W00-1317",
                "DBLP": "conf/emnlp/TangM00",
                "DOI": "10.3115/1117794.1117811",
                "CorpusId": 2036954
            },
            "abstract": "The development of natural language interfaces (NLI's) for databases has been a challenging problem in natural language processing (NLP) since the 1970's. The need for NLI's has become more pronounced due to the widespread access to complex databases now available through the Internet. A challenging problem for empirical NLP is the automated acquisition of NLI's from training examples. We present a method for integrating statistical and relational learning techniques for this task which exploits the strength of both approaches. Experimental results from three different domains suggest that such an approach is more robust than a previous purely logic-based approach.",
            "referenceCount": 15,
            "citationCount": 106,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2000-10-07",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Tang2000AutomatedCO,\n author = {Lappoon R. Tang and R. Mooney},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {133-141},\n title = {Automated Construction of Database Interfaces: Intergrating Statistical and Relational Learning for Semantic Parsing},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e13d6ed5dbe36f398445058a6fa3e623ff4196be",
            "@type": "ScholarlyArticle",
            "paperId": "e13d6ed5dbe36f398445058a6fa3e623ff4196be",
            "corpusId": 10489422,
            "url": "https://www.semanticscholar.org/paper/e13d6ed5dbe36f398445058a6fa3e623ff4196be",
            "title": "The EDR electronic dictionary",
            "venue": "CACM",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1995,
            "externalIds": {
                "DBLP": "journals/cacm/Yokoi95",
                "MAG": "2089188520",
                "DOI": "10.1145/219717.219752",
                "CorpusId": 10489422
            },
            "abstract": "Natural language processing will grow into a vital industrial technology in the next five to 10 years. But this growth depends on the development of large linguistic databases that capture natural language phenomena [1, 2]. Another important theme for future work is development of large knowledge bases that are shared widely by different groups. One promising approach to such knowledge bases draws on natural language processing and linguistic knowledge. This article describes the EDR Electronic Dictionary [3], which seeks to provide a foundation for linguistic databases, and explains the relation of electronic dictionaries to very large knowledge bases.",
            "referenceCount": 5,
            "citationCount": 117,
            "influentialCitationCount": 11,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/219717.219752",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1995-11-01",
            "journal": {
                "name": "Commun. ACM",
                "volume": "38"
            },
            "citationStyles": {
                "bibtex": "@Article{Yokoi1995TheEE,\n author = {T. Yokoi},\n booktitle = {CACM},\n journal = {Commun. ACM},\n pages = {42-44},\n title = {The EDR electronic dictionary},\n volume = {38},\n year = {1995}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bc68ec44a97b0ffb7dfc11fac3dd203b3d15c67a",
            "@type": "ScholarlyArticle",
            "paperId": "bc68ec44a97b0ffb7dfc11fac3dd203b3d15c67a",
            "corpusId": 208995335,
            "url": "https://www.semanticscholar.org/paper/bc68ec44a97b0ffb7dfc11fac3dd203b3d15c67a",
            "title": "Parsing",
            "venue": "Annual Meeting of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                "name": "Annual Meeting of the Association for Computational Linguistics",
                "alternate_names": [
                    "Annu Meet Assoc Comput Linguistics",
                    "Meeting of the Association for Computational Linguistics",
                    "ACL",
                    "Meet Assoc Comput Linguistics"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/acl/"
            },
            "year": 1981,
            "externalIds": {
                "ACL": "P81-1022",
                "MAG": "2883337250",
                "DBLP": "conf/acl/Grishman81",
                "DOI": "10.3115/981923.981950",
                "CorpusId": 208995335
            },
            "abstract": "One reason for the wide variety of views on many subjects in computational linguistics (such as parsing) is the diversity of objectives which lead people to do research in this area. Some researchers are motivated primarily by potential applications the development of natural language interfaces for computer systems. Others are primarily concerned with the psychological processes which underlie human language, and view the computer as a tool for modeling and thus improving our understanding of these processes. Since, as is often observed, man is our best example of a natural language processor, these two groups do have a strong commonality of research interest. Nonetheless, their divergence of objective must lead to differences in the way they regard the component processes of natural language understanding. (If when human processing is better understood it is recognized that the simulation of human processes is not the most effective way of constructing a natural language interface, there may even be a deliberate divergence in the processes themselves.) My work, and this position paper, reflect an applications orientation; those with different research objectives will come to quite different conclusions.",
            "referenceCount": 0,
            "citationCount": 185,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1981-06-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Grishman1981Parsing,\n author = {R. Grishman},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {101},\n title = {Parsing},\n year = {1981}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:43865ad56b3364b39ae3badf1fc212547292b335",
            "@type": "ScholarlyArticle",
            "paperId": "43865ad56b3364b39ae3badf1fc212547292b335",
            "corpusId": 11894359,
            "url": "https://www.semanticscholar.org/paper/43865ad56b3364b39ae3badf1fc212547292b335",
            "title": "Disambiguating Prepositional Phrase Attachments by Using On-Line Dictionary Definitions",
            "venue": "Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:ee37a78c-f3d8-407a-bd24-bb97fe6dbab9",
                "name": "Computational Linguistics",
                "alternate_names": [
                    "Comput Linguistics"
                ],
                "issn": "0891-2017",
                "url": "http://aclanthology.info/venues/cl"
            },
            "year": 1987,
            "externalIds": {
                "MAG": "1794966349",
                "ACL": "J87-3005",
                "DBLP": "journals/coling/JensenB87",
                "CorpusId": 11894359
            },
            "abstract": "Standard on-line dictionaries offer a wealth of knowledge expressed in natural language form. We claim that such knowledge can and should be accessed by natural language processing systems to solve difficult ambiguity problems. This paper sustains that claim by describing a set of computational tools and techniques used to disambiguate prepositional phrase attachments in English sentences, by accessing on-line dictionary definitions. Such techniques offer hope for eliminating the time-consuming, and often incomplete, hand coding of semantic information that has been conventional in natural language understanding systems.",
            "referenceCount": 23,
            "citationCount": 119,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1987-07-01",
            "journal": {
                "name": "Comput. Linguistics",
                "volume": "13"
            },
            "citationStyles": {
                "bibtex": "@Article{Jensen1987DisambiguatingPP,\n author = {Karen Jensen and J. Binot},\n booktitle = {Computational Linguistics},\n journal = {Comput. Linguistics},\n pages = {251-260},\n title = {Disambiguating Prepositional Phrase Attachments by Using On-Line Dictionary Definitions},\n volume = {13},\n year = {1987}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a12f03b45fc6899151d143efd9fe14f9dd69fb7b",
            "@type": "ScholarlyArticle",
            "paperId": "a12f03b45fc6899151d143efd9fe14f9dd69fb7b",
            "corpusId": 826222,
            "url": "https://www.semanticscholar.org/paper/a12f03b45fc6899151d143efd9fe14f9dd69fb7b",
            "title": "A Computational Approach to Grammatical Coding of English Words",
            "venue": "JACM",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1963,
            "externalIds": {
                "DBLP": "journals/jacm/KleinS63",
                "MAG": "2015773474",
                "DOI": "10.1145/321172.321180",
                "CorpusId": 826222
            },
            "abstract": "As a firs l~ step in many computer language processing systems, each word in a natural language sentence must be coded as to its form-class or part of speech. This paper describes a computational grammar coder which has been completely programmed and is oper~tional on Lhe IBM 7090. It is part of a complete syntactic annlysis system for which it accomplishes word-class coding, using a computational approach rather than the usual method of dictionary lookup. The resulting system is completely contained in less than 1~,000 computer words. It processes running English text on the IBM 7090 at a rate of more than 1250 words per minute. Since the system is not dependent on large dictionaries, it operates on any ordinary English text. In preliminary experiments with scientific text, the system correctly and unambiguously coded over 90 percent of the words in two samples of scientific writing. A fair proportion of the remaining ambiguity can be removed at higher levels of synvactic analysis, but the problem of structural ambiguity in natural languages is seen to be a critical one in the development of practical language processing systems.",
            "referenceCount": 10,
            "citationCount": 160,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/321172.321180",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1963-07-01",
            "journal": {
                "name": "J. ACM",
                "volume": "10"
            },
            "citationStyles": {
                "bibtex": "@Article{Klein1963ACA,\n author = {Sheldon Klein and R. F. Simmons},\n booktitle = {JACM},\n journal = {J. ACM},\n pages = {334-347},\n title = {A Computational Approach to Grammatical Coding of English Words},\n volume = {10},\n year = {1963}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ac3947d7f4b33a773d1cd2e88c8937eab3205af5",
            "@type": "ScholarlyArticle",
            "paperId": "ac3947d7f4b33a773d1cd2e88c8937eab3205af5",
            "corpusId": 1219107,
            "url": "https://www.semanticscholar.org/paper/ac3947d7f4b33a773d1cd2e88c8937eab3205af5",
            "title": "Statistical Parsing of Messages",
            "venue": "Human Language Technology - The Baltic Perspectiv",
            "publicationVenue": {
                "id": "urn:research:f8e3f8d0-0f40-48c0-b3c0-0c540237b859",
                "name": "Human Language Technology - The Baltic Perspectiv",
                "alternate_names": [
                    "Human Language Technology",
                    "HLT",
                    "Hum Lang Technol",
                    "Hum Lang Technol  Balt Perspect"
                ],
                "issn": null,
                "url": null
            },
            "year": 1990,
            "externalIds": {
                "MAG": "2035801902",
                "DBLP": "conf/naacl/ChitraoG90",
                "ACL": "H90-1053",
                "DOI": "10.3115/116580.116665",
                "CorpusId": 1219107
            },
            "abstract": "The recent trend in natural language processing research has been to develop systems that deal with text concerning small, well defined domains. One practical application for such systems is to process messages pertaining to some very specific task or activity [5]. The advantage of dealing with such domains is twofold - firstly, due to the narrowness of the domain, it is possible to encode most of the knowledge related to the domain and to make this knowledge accessible to the natural language processing system, which in turn can use this knowledge to disambiguate the meanings of the messages. Secondly, in such a domain, there is not a great diversity of language constructs and therefore it becomes easier to construct a grammar which will capture all the constructs which exist in this sub-language.",
            "referenceCount": 12,
            "citationCount": 62,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://wing.comp.nus.edu.sg/~antho/H/H90/H90-1053.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1990-06-24",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Chitrao1990StatisticalPO,\n author = {M. Chitrao and R. Grishman},\n booktitle = {Human Language Technology - The Baltic Perspectiv},\n pages = {263-266},\n title = {Statistical Parsing of Messages},\n year = {1990}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e1cf95d6bc3c9ad6f90a563bd8457d512debe410",
            "@type": "ScholarlyArticle",
            "paperId": "e1cf95d6bc3c9ad6f90a563bd8457d512debe410",
            "corpusId": 1414104,
            "url": "https://www.semanticscholar.org/paper/e1cf95d6bc3c9ad6f90a563bd8457d512debe410",
            "title": "Linguistic Knowledge can Improve Information Retrieval",
            "venue": "Applied Natural Language Processing Conference",
            "publicationVenue": {
                "id": "urn:research:a8d0722b-8d14-4675-ae77-47b7d0e3fd64",
                "name": "Applied Natural Language Processing Conference",
                "alternate_names": [
                    "Conf Appl Nat Lang Process",
                    "Appl Nat Lang Process Conf",
                    "Conference on Applied Natural Language Processing",
                    "ANLP"
                ],
                "issn": null,
                "url": "https://aclweb.org/anthology/venues/anlp/"
            },
            "year": 2000,
            "externalIds": {
                "DBLP": "conf/anlp/WoodsBHKMG00",
                "ACL": "A00-1036",
                "MAG": "2007352190",
                "DOI": "10.3115/974147.974183",
                "CorpusId": 1414104
            },
            "abstract": "This paper describes the results of some experiments using a new approach to information access that combines techniques from natural language processing and knowledge representation with a penalty-based technique for relevance estimation and passage retrieval. Unlike many attempts to combine natural language processing with information retrieval, these results show substantial benefit from using linguistic knowledge.",
            "referenceCount": 18,
            "citationCount": 54,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.3115/974147.974183",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2000-04-29",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Woods2000LinguisticKC,\n author = {W. Woods and Lawrence A. Bookman and A. Houston and Robert J. Kuhns and P. Martin and Stephen Joseph Green},\n booktitle = {Applied Natural Language Processing Conference},\n pages = {262-267},\n title = {Linguistic Knowledge can Improve Information Retrieval},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:671bfcba9c715d94634ca7d1985f3d6e797e646e",
            "@type": "ScholarlyArticle",
            "paperId": "671bfcba9c715d94634ca7d1985f3d6e797e646e",
            "corpusId": 33774504,
            "url": "https://www.semanticscholar.org/paper/671bfcba9c715d94634ca7d1985f3d6e797e646e",
            "title": "Linguistics and information science",
            "venue": "Journal of the American Society for Information Science",
            "publicationVenue": {
                "id": "urn:research:e0706bac-2807-4453-89b8-cc7094693384",
                "name": "Journal of the American Society for Information Science",
                "alternate_names": [
                    "J Am Soc Inf Sci"
                ],
                "issn": "0002-8231",
                "url": "http://www3.interscience.wiley.com/cgi-bin/jtoc?ID=27981"
            },
            "year": 1972,
            "externalIds": {
                "DBLP": "journals/jasis/Montgomery72",
                "MAG": "2045605119",
                "DOI": "10.1002/asi.4630230309",
                "CorpusId": 33774504
            },
            "abstract": "This paper defines the relationship between linguistics and information science in terms of a common interest in natural language. The notion of automated processing of natural language\u2013i.e., machine simulation of the language processing activities of a human\u2013provides novel possibilities for interaction between linguists, who have a theoretical interest in such activities, and information scientists, who have more practical goals, e.g. simulating the language processing activities of an indexer with a machine. \n \n \n \nThe concept of a natural language information system is introduced as a framework for reviewing automated language processing efforts by computational linguists and information scientists. In terms of this framework, the former have concentrated on automating the operations of the component for content analysis and representation, while the latter have emphasized the data management component. The complementary nature of these developments allows the postulation of an integrated approach to automated language processing. This approach, which is outlined in the final sections of the paper, incorporates current notions in linguistic theory and information science, as well as design features of recent computational linguistic models.",
            "referenceCount": 39,
            "citationCount": 71,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "1972-05-01",
            "journal": {
                "name": "J. Am. Soc. Inf. Sci.",
                "volume": "23"
            },
            "citationStyles": {
                "bibtex": "@Article{Montgomery1972LinguisticsAI,\n author = {C. Montgomery},\n booktitle = {Journal of the American Society for Information Science},\n journal = {J. Am. Soc. Inf. Sci.},\n pages = {195-219},\n title = {Linguistics and information science},\n volume = {23},\n year = {1972}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3092325d55f6aa9ba28b0841bdcfd61991a38d48",
            "@type": "ScholarlyArticle",
            "paperId": "3092325d55f6aa9ba28b0841bdcfd61991a38d48",
            "corpusId": 59606259,
            "url": "https://www.semanticscholar.org/paper/3092325d55f6aa9ba28b0841bdcfd61991a38d48",
            "title": "A Neural Model for Generating Natural Language Summaries of Program Subroutines",
            "venue": "International Conference on Software Engineering",
            "publicationVenue": {
                "id": "urn:research:a36dc29e-4ea1-4567-b0fe-1c06daf8bee8",
                "name": "International Conference on Software Engineering",
                "alternate_names": [
                    "Int Conf Softw Eng",
                    "ICSE"
                ],
                "issn": null,
                "url": "http://www.icse-conferences.org/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2964194820",
                "DBLP": "journals/corr/abs-1902-01954",
                "ArXiv": "1902.01954",
                "DOI": "10.1109/ICSE.2019.00087",
                "CorpusId": 59606259
            },
            "abstract": "Source code summarization -- creating natural language descriptions of source code behavior -- is a rapidly-growing research topic with applications to automatic documentation generation, program comprehension, and software maintenance. Traditional techniques relied on heuristics and templates built manually by human experts. Recently, data-driven approaches based on neural machine translation have largely overtaken template-based systems. But nearly all of these techniques rely almost entirely on programs having good internal documentation; without clear identifier names, the models fail to create good summaries. In this paper, we present a neural model that combines words from code with code structure from an AST. Unlike previous approaches, our model processes each data source as a separate input, which allows the model to learn code structure independent of the text in code. This process helps our approach provide coherent summaries in many cases even when zero internal documentation is provided. We evaluate our technique with a dataset we created from 2.1m Java methods. We find improvement over two baseline techniques from SE literature and one from NLP literature.",
            "referenceCount": 61,
            "citationCount": 227,
            "influentialCitationCount": 48,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1902.01954",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book",
                "Conference"
            ],
            "publicationDate": "2019-02-05",
            "journal": {
                "name": "2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{LeClair2019ANM,\n author = {Alexander LeClair and Siyuan Jiang and Collin McMillan},\n booktitle = {International Conference on Software Engineering},\n journal = {2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)},\n pages = {795-806},\n title = {A Neural Model for Generating Natural Language Summaries of Program Subroutines},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ba6797b59c38702725ea0f3e6c141d471164662e",
            "@type": "ScholarlyArticle",
            "paperId": "ba6797b59c38702725ea0f3e6c141d471164662e",
            "corpusId": 46208633,
            "url": "https://www.semanticscholar.org/paper/ba6797b59c38702725ea0f3e6c141d471164662e",
            "title": "Natural Language Understanding",
            "venue": "Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:96018464-22dc-4b5c-a172-c2f4a30ce131",
                "name": "Artificial Intelligence",
                "alternate_names": [
                    "Artif Intell"
                ],
                "issn": "0004-3702",
                "url": "http://www.elsevier.com/locate/artint"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2344501955",
                "DOI": "10.1007/springerreference_19513",
                "CorpusId": 46208633
            },
            "abstract": null,
            "referenceCount": 22,
            "citationCount": 547,
            "influentialCitationCount": 18,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "Artificial Intelligence",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Allen2016NaturalLU,\n author = {James F. Allen},\n booktitle = {Artificial Intelligence},\n journal = {Artificial Intelligence},\n title = {Natural Language Understanding},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b133e361e2f8af22b823d25060b2e7c47f690985",
            "@type": "ScholarlyArticle",
            "paperId": "b133e361e2f8af22b823d25060b2e7c47f690985",
            "corpusId": 1931511,
            "url": "https://www.semanticscholar.org/paper/b133e361e2f8af22b823d25060b2e7c47f690985",
            "title": "Segmentation from Natural Language Expressions",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/eccv/HuRD16",
                "MAG": "2302548814",
                "ArXiv": "1603.06180",
                "DOI": "10.1007/978-3-319-46448-0_7",
                "CorpusId": 1931511
            },
            "abstract": null,
            "referenceCount": 35,
            "citationCount": 296,
            "influentialCitationCount": 59,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/978-3-319-46448-0_7.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-03-20",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1603.06180"
            },
            "citationStyles": {
                "bibtex": "@Article{Hu2016SegmentationFN,\n author = {Ronghang Hu and Marcus Rohrbach and Trevor Darrell},\n booktitle = {European Conference on Computer Vision},\n journal = {ArXiv},\n title = {Segmentation from Natural Language Expressions},\n volume = {abs/1603.06180},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f93a0a3e8a3e6001b4482430254595cf737697fa",
            "@type": "ScholarlyArticle",
            "paperId": "f93a0a3e8a3e6001b4482430254595cf737697fa",
            "corpusId": 12305768,
            "url": "https://www.semanticscholar.org/paper/f93a0a3e8a3e6001b4482430254595cf737697fa",
            "title": "Learning Natural Language Inference using Bidirectional LSTM model and Inner-Attention",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/LiuSLW16",
                "ArXiv": "1605.09090",
                "MAG": "2415204069",
                "CorpusId": 12305768
            },
            "abstract": "In this paper, we proposed a sentence encoding-based model for recognizing text entailment. In our approach, the encoding of sentence is a two-stage process. Firstly, average pooling was used over word-level bidirectional LSTM (biLSTM) to generate a first-stage sentence representation. Secondly, attention mechanism was employed to replace average pooling on the same sentence for better representations. Instead of using target sentence to attend words in source sentence, we utilized the sentence's first-stage representation to attend words appeared in itself, which is called \"Inner-Attention\" in our paper . Experiments conducted on Stanford Natural Language Inference (SNLI) Corpus has proved the effectiveness of \"Inner-Attention\" mechanism. With less number of parameters, our model outperformed the existing best sentence encoding-based approach by a large margin.",
            "referenceCount": 20,
            "citationCount": 262,
            "influentialCitationCount": 35,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-05-30",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1605.09090"
            },
            "citationStyles": {
                "bibtex": "@Article{Liu2016LearningNL,\n author = {Yang Liu and Chengjie Sun and Lei Lin and Xiaolong Wang},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Learning Natural Language Inference using Bidirectional LSTM model and Inner-Attention},\n volume = {abs/1605.09090},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d50b4bd45c6425dacbbf53416b7eb111df36d503",
            "@type": "ScholarlyArticle",
            "paperId": "d50b4bd45c6425dacbbf53416b7eb111df36d503",
            "corpusId": 18275223,
            "url": "https://www.semanticscholar.org/paper/d50b4bd45c6425dacbbf53416b7eb111df36d503",
            "title": "Crowd-Based Personalized Natural Language Explanations for Recommendations",
            "venue": "ACM Conference on Recommender Systems",
            "publicationVenue": {
                "id": "urn:research:61275a16-1e0d-479f-ac4e-f295310761f0",
                "name": "ACM Conference on Recommender Systems",
                "alternate_names": [
                    "Conf Recomm Syst",
                    "RecSys",
                    "ACM Conf Recomm Syst",
                    "Conference on Recommender Systems"
                ],
                "issn": null,
                "url": "http://recsys.acm.org/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2511352244",
                "DBLP": "conf/recsys/ChangHT16",
                "DOI": "10.1145/2959100.2959153",
                "CorpusId": 18275223
            },
            "abstract": "Explanations are important for users to make decisions on whether to take recommendations. However, algorithm generated explanations can be overly simplistic and unconvincing. We believe that humans can overcome these limitations. Inspired by how people explain word-of-mouth recommendations, we designed a process, combining crowdsourcing and computation, that generates personalized natural language explanations. We modeled key topical aspects of movies, asked crowdworkers to write explanations based on quotes from online movie reviews, and personalized the explanations presented to users based on their rating history. We evaluated the explanations by surveying 220 MovieLens users, finding that compared to personalized tag-based explanations, natural language explanations: 1) contain a more appropriate amount of information, 2) earn more trust from users, and 3) make users more satisfied. This paper contributes to the research literature by describing a scalable process for generating high quality and personalized natural language explanations, improving on state-of-the-art content-based explanations, and showing the feasibility and advantages of approaches that combine human wisdom with algorithmic processes.",
            "referenceCount": 27,
            "citationCount": 97,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book",
                "Review"
            ],
            "publicationDate": "2016-09-07",
            "journal": {
                "name": "Proceedings of the 10th ACM Conference on Recommender Systems",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Chang2016CrowdBasedPN,\n author = {Shuo Chang and F. M. Harper and L. Terveen},\n booktitle = {ACM Conference on Recommender Systems},\n journal = {Proceedings of the 10th ACM Conference on Recommender Systems},\n title = {Crowd-Based Personalized Natural Language Explanations for Recommendations},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d696a1923288e6c15422660de9553f6fdb6a4fae",
            "@type": "ScholarlyArticle",
            "paperId": "d696a1923288e6c15422660de9553f6fdb6a4fae",
            "corpusId": 9944232,
            "url": "https://www.semanticscholar.org/paper/d696a1923288e6c15422660de9553f6fdb6a4fae",
            "title": "Natural Language Object Retrieval",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2952544144",
                "ArXiv": "1511.04164",
                "DBLP": "conf/cvpr/HuXRFSD16",
                "DOI": "10.1109/CVPR.2016.493",
                "CorpusId": 9944232
            },
            "abstract": "In this paper, we address the task of natural language object retrieval, to localize a target object within a given image based on a natural language query of the object. Natural language object retrieval differs from text-based image retrieval task as it involves spatial information about objects within the scene and global scene context. To address this issue, we propose a novel Spatial Context Recurrent ConvNet (SCRC) model as scoring function on candidate boxes for object retrieval, integrating spatial configurations and global scene-level contextual information into the network. Our model processes query text, local image descriptors, spatial configurations and global context features through a recurrent network, outputs the probability of the query text conditioned on each candidate box as a score for the box, and can transfer visual-linguistic knowledge from image captioning domain to our task. Experimental results demonstrate that our method effectively utilizes both local and global information, outperforming previous baseline methods significantly on different datasets and scenarios, and can exploit large scale vision and language datasets for knowledge transfer.",
            "referenceCount": 34,
            "citationCount": 512,
            "influentialCitationCount": 64,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1511.04164",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-11-13",
            "journal": {
                "name": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hu2015NaturalLO,\n author = {Ronghang Hu and Huazhe Xu and Marcus Rohrbach and Jiashi Feng and Kate Saenko and Trevor Darrell},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {4555-4564},\n title = {Natural Language Object Retrieval},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2dee9e6c2e8d0e7b64c95caf687566a7466aa633",
            "@type": "ScholarlyArticle",
            "paperId": "2dee9e6c2e8d0e7b64c95caf687566a7466aa633",
            "corpusId": 17143678,
            "url": "https://www.semanticscholar.org/paper/2dee9e6c2e8d0e7b64c95caf687566a7466aa633",
            "title": "Prediction During Natural Language Comprehension.",
            "venue": "Cerebral Cortex",
            "publicationVenue": {
                "id": "urn:research:388efbe2-cd51-4399-93f6-ba85b8300840",
                "name": "Cerebral Cortex",
                "alternate_names": [
                    "Cereb Cortex"
                ],
                "issn": "1047-3211",
                "url": "https://academic.oup.com/cercor"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "1969221307",
                "DOI": "10.1093/cercor/bhv075",
                "CorpusId": 17143678,
                "PubMed": "25903464"
            },
            "abstract": "The notion of prediction is studied in cognitive neuroscience with increasing intensity. We investigated the neural basis of 2 distinct aspects of word prediction, derived from information theory, during story comprehension. We assessed the effect of entropy of next-word probability distributions as well as surprisal A computational model determined entropy and surprisal for each word in 3 literary stories. Twenty-four healthy participants listened to the same 3 stories while their brain activation was measured using fMRI. Reversed speech fragments were presented as a control condition. Brain areas sensitive to entropy were left ventral premotor cortex, left middle frontal gyrus, right inferior frontal gyrus, left inferior parietal lobule, and left supplementary motor area. Areas sensitive to surprisal were left inferior temporal sulcus (\"visual word form area\"), bilateral superior temporal gyrus, right amygdala, bilateral anterior temporal poles, and right inferior frontal sulcus. We conclude that prediction during language comprehension can occur at several levels of processing, including at the level of word form. Our study exemplifies the power of combining computational linguistics with cognitive neuroscience, and additionally underlines the feasibility of studying continuous spoken language materials with fMRI.",
            "referenceCount": 97,
            "citationCount": 196,
            "influentialCitationCount": 8,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://academic.oup.com/cercor/article-pdf/26/6/2506/17309746/bhv075.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-06-01",
            "journal": {
                "name": "Cerebral cortex",
                "volume": "26 6"
            },
            "citationStyles": {
                "bibtex": "@Article{Willems2016PredictionDN,\n author = {Roel M. Willems and S. Frank and Annabel D. Nijhof and P. Hagoort and Antal van den Bosch},\n booktitle = {Cerebral Cortex},\n journal = {Cerebral cortex},\n pages = {\n          2506-2516\n        },\n title = {Prediction During Natural Language Comprehension.},\n volume = {26 6},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1fc1145ef6dbcac74b67cb5c8a742c67b43c4199",
            "@type": "ScholarlyArticle",
            "paperId": "1fc1145ef6dbcac74b67cb5c8a742c67b43c4199",
            "corpusId": 247439606,
            "url": "https://www.semanticscholar.org/paper/1fc1145ef6dbcac74b67cb5c8a742c67b43c4199",
            "title": "ProtGPT2 is a deep unsupervised language model for protein design",
            "venue": "Nature Communications",
            "publicationVenue": {
                "id": "urn:research:43b3f0f9-489a-4566-8164-02fafde3cd98",
                "name": "Nature Communications",
                "alternate_names": [
                    "Nat Commun"
                ],
                "issn": "2041-1723",
                "url": "https://www.nature.com/ncomms/"
            },
            "year": 2022,
            "externalIds": {
                "PubMedCentral": "9329459",
                "DOI": "10.1038/s41467-022-32007-7",
                "CorpusId": 247439606,
                "PubMed": "35896542"
            },
            "abstract": null,
            "referenceCount": 80,
            "citationCount": 150,
            "influentialCitationCount": 5,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s41467-022-32007-7.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Biology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2022-03-11",
            "journal": {
                "name": "Nature Communications",
                "volume": "13"
            },
            "citationStyles": {
                "bibtex": "@Article{Ferruz2022ProtGPT2IA,\n author = {Noelia Ferruz and Steffen Schmidt and B. H\u00f6cker},\n booktitle = {Nature Communications},\n journal = {Nature Communications},\n title = {ProtGPT2 is a deep unsupervised language model for protein design},\n volume = {13},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:36a607d93637475a3675ee55ee7a1c2eb6d4376a",
            "@type": "ScholarlyArticle",
            "paperId": "36a607d93637475a3675ee55ee7a1c2eb6d4376a",
            "corpusId": 2110110,
            "url": "https://www.semanticscholar.org/paper/36a607d93637475a3675ee55ee7a1c2eb6d4376a",
            "title": "DataTone: Managing Ambiguity in Natural Language Interfaces for Data Visualization",
            "venue": "ACM Symposium on User Interface Software and Technology",
            "publicationVenue": {
                "id": "urn:research:c62b1316-0733-4b4c-8017-c07e18afa954",
                "name": "ACM Symposium on User Interface Software and Technology",
                "alternate_names": [
                    "User Interface Software and Technology",
                    "ACM Symp User Interface Softw Technol",
                    "User Interface Softw Technol",
                    "UIST"
                ],
                "issn": null,
                "url": "http://www.acm.org/uist/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2274505579",
                "DBLP": "conf/uist/GaoDALK15",
                "DOI": "10.1145/2807442.2807478",
                "CorpusId": 2110110
            },
            "abstract": "Answering questions with data is a difficult and time-consuming process. Visual dashboards and templates make it easy to get started, but asking more sophisticated questions often requires learning a tool designed for expert analysts. Natural language interaction allows users to ask questions directly in complex programs without having to learn how to use an interface. However, natural language is often ambiguous. In this work we propose a mixed-initiative approach to managing ambiguity in natural language interfaces for data visualization. We model ambiguity throughout the process of turning a natural language query into a visualization and use algorithmic disambiguation coupled with interactive ambiguity widgets. These widgets allow the user to resolve ambiguities by surfacing system decisions at the point where the ambiguity matters. Corrections are stored as constraints and influence subsequent queries. We have implemented these ideas in a system, DataTone. In a comparative study, we find that DataTone is easy to learn and lets users ask questions without worrying about syntax and proper question form.",
            "referenceCount": 41,
            "citationCount": 204,
            "influentialCitationCount": 22,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book",
                "Conference"
            ],
            "publicationDate": "2015-11-05",
            "journal": {
                "name": "Proceedings of the 28th Annual ACM Symposium on User Interface Software & Technology",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gao2015DataToneMA,\n author = {Tong Gao and Mira Dontcheva and Eytan Adar and Zhicheng Liu and Karrie Karahalios},\n booktitle = {ACM Symposium on User Interface Software and Technology},\n journal = {Proceedings of the 28th Annual ACM Symposium on User Interface Software & Technology},\n title = {DataTone: Managing Ambiguity in Natural Language Interfaces for Data Visualization},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1427921e7011412b77dd7d0b911bc66f1ad1cff8",
            "@type": "ScholarlyArticle",
            "paperId": "1427921e7011412b77dd7d0b911bc66f1ad1cff8",
            "corpusId": 9535909,
            "url": "https://www.semanticscholar.org/paper/1427921e7011412b77dd7d0b911bc66f1ad1cff8",
            "title": "Automatic Construction and Natural-Language Description of Nonparametric Regression Models",
            "venue": "AAAI Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:bdc2e585-4e48-4e36-8af1-6d859763d405",
                "name": "AAAI Conference on Artificial Intelligence",
                "alternate_names": [
                    "National Conference on Artificial Intelligence",
                    "National Conf Artif Intell",
                    "AAAI Conf Artif Intell",
                    "AAAI"
                ],
                "issn": null,
                "url": "http://www.aaai.org/"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "conf/aaai/LloydDGTG14",
                "MAG": "1950803081",
                "ArXiv": "1402.4304",
                "DOI": "10.1609/aaai.v28i1.8904",
                "CorpusId": 9535909
            },
            "abstract": "\n \n This paper presents the beginnings of an automatic statistician, focusing on regression problems. Our system explores an open-ended space of statistical models to discover a good explanation of a data set, and then produces a detailed report with figures and natural-language text. Our approach treats unknown regression functions nonparametrically using Gaussian processes, which has two important consequences. First, Gaussian processes can model functions in terms of high-level properties (e.g. smoothness, trends, periodicity, changepoints). Taken together with the compositional structure of our language of models this allows us to automatically describe functions in simple terms. Second, the use of flexible nonparametric models and a rich language for composing them in an open-ended manner also results in state-of-the-art extrapolation performance evaluated over 13 real time series data sets from various domains.\n \n",
            "referenceCount": 32,
            "citationCount": 226,
            "influentialCitationCount": 35,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ojs.aaai.org/index.php/AAAI/article/download/8904/8763",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-02-18",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Lloyd2014AutomaticCA,\n author = {J. Lloyd and D. Duvenaud and R. Grosse and J. Tenenbaum and Zoubin Ghahramani},\n booktitle = {AAAI Conference on Artificial Intelligence},\n pages = {1242-1250},\n title = {Automatic Construction and Natural-Language Description of Nonparametric Regression Models},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2e9fd22b64ba73262cc537d7b7f265c8d59f4acf",
            "@type": "ScholarlyArticle",
            "paperId": "2e9fd22b64ba73262cc537d7b7f265c8d59f4acf",
            "corpusId": 17428739,
            "url": "https://www.semanticscholar.org/paper/2e9fd22b64ba73262cc537d7b7f265c8d59f4acf",
            "title": "Semantic Similarity from Natural Language and Ontology Analysis",
            "venue": "Synthesis Lectures on Human Language Technologies",
            "publicationVenue": {
                "id": "urn:research:400d73aa-0d51-4582-9144-2069958881cd",
                "name": "Synthesis Lectures on Human Language Technologies",
                "alternate_names": [
                    "Synth Lect Hum Lang Technol"
                ],
                "issn": "1947-4040",
                "url": "https://www.morganclaypool.com/toc/hlt/1/1"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "1926956132",
                "DBLP": "series/synthesis/2015Harispe",
                "ArXiv": "1704.05295",
                "DOI": "10.2200/S00639ED1V01Y201504HLT027",
                "CorpusId": 17428739
            },
            "abstract": "Artificial Intelligence federates numerous scientific fields in the aim of developing machines able to assist human operators performing complex treatments; most of which demand high cognitive skills (e.g. learning or decision processes). Central to this quest is to give machines the ability to estimate the likeness or similarity between things in the way human beings estimate the similarity between stimuli. In this context, this book focuses on semantic measures: approaches designed for comparing semantic entities such as units of language, e.g. words, sentences, or concepts and instances defined into knowledge bases. The aim of these measures is to assess the similarity or relatedness of such semantic entities by taking into account their semantics, i.e. their meaning; intuitively, the words tea and coffee, which both refer to stimulating beverage, will be estimated to be more semantically similar than the words toffee (confection) and coffee, despite that the last pair has a higher syntactic similarity. The two state-of-the-art approaches for estimating and quantifying semantic similarities/relatedness of semantic entities are presented in detail: the first one relies on corpora analysis and is based on Natural Language Processing techniques and semantic models while the second is based on more or less formal, computer-readable and workable forms of knowledge such as semantic networks, thesauri or ontologies. Semantic measures are widely used today to compare units of language, concepts, instances or even resources indexed by them (e.g., documents, genes). They are central elements of a large variety of Natural Language Processing applications and knowledge-based treatments, and have therefore naturally been subject to intensive and interdisciplinary research efforts during last decades. Beyond a simple inventory and categorization of existing measures, the aim of this monograph is to convey novices as well as researchers of these domains toward a better understanding of semantic similarity estimation and more generally semantic measures. To this end, we propose an in-depth characterization of existing proposals by discussing their features, the assumptions on which they are based and empirical results regarding their performance in particular applications. By answering these questions and by providing a detailed discussion on the foundations of semantic measures, our aim is to give the reader key knowledge required to: (i) select the more relevant methods according to a particular usage context, (ii) understand the challenges offered to this field of study, (iii) distinguish room of improvements for state-of-the-art approaches and (iv) stimulate creativity toward the development of new approaches. In this aim, several definitions, theoretical and practical details, as well as concrete applications are presented.",
            "referenceCount": 691,
            "citationCount": 181,
            "influentialCitationCount": 11,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/bfm:978-3-031-02156-5/1?pdf=chapter%20toc",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-05-08",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1704.05295"
            },
            "citationStyles": {
                "bibtex": "@Article{Xiong2015SemanticSF,\n author = {Deyi Xiong},\n booktitle = {Synthesis Lectures on Human Language Technologies},\n journal = {ArXiv},\n title = {Semantic Similarity from Natural Language and Ontology Analysis},\n volume = {abs/1704.05295},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e7e19d6456447be8eac771e01572f0846002e051",
            "@type": "ScholarlyArticle",
            "paperId": "e7e19d6456447be8eac771e01572f0846002e051",
            "corpusId": 4863017,
            "url": "https://www.semanticscholar.org/paper/e7e19d6456447be8eac771e01572f0846002e051",
            "title": "Supporting Process Model Validation through Natural Language Generation",
            "venue": "IEEE Transactions on Software Engineering",
            "publicationVenue": {
                "id": "urn:research:c99cfe66-b71c-4ca4-bedd-26267b9cb068",
                "name": "IEEE Transactions on Software Engineering",
                "alternate_names": [
                    "IEEE Trans Softw Eng"
                ],
                "issn": "0098-5589",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=32"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "1823159485",
                "DBLP": "journals/tse/LeopoldMP14",
                "DOI": "10.1109/TSE.2014.2327044",
                "CorpusId": 4863017
            },
            "abstract": "The design and development of process-aware information systems is often supported by specifying requirements as business process models. Although this approach is generally accepted as an effective strategy, it remains a fundamental challenge to adequately validate these models given the diverging skill set of domain experts and system analysts. As domain experts often do not feel confident in judging the correctness and completeness of process models that system analysts create, the validation often has to regress to a discourse using natural language. In order to support such a discourse appropriately, so-called verbalization techniques have been defined for different types of conceptual models. However, there is currently no sophisticated technique available that is capable of generating natural-looking text from process models. In this paper, we address this research gap and propose a technique for generating natural language texts from business process models. A comparison with manually created process descriptions demonstrates that the generated texts are superior in terms of completeness, structure, and linguistic complexity. An evaluation with users further demonstrates that the texts are very understandable and effectively allow the reader to infer the process model semantics. Hence, the generated texts represent a useful input for process model validation.",
            "referenceCount": 114,
            "citationCount": 93,
            "influentialCitationCount": 8,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://research.wu.ac.at/files/27131572/2014_IEEE_TSE_Natural-Language-Generation.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-05-29",
            "journal": {
                "name": "IEEE Transactions on Software Engineering",
                "volume": "40"
            },
            "citationStyles": {
                "bibtex": "@Article{Leopold2014SupportingPM,\n author = {H. Leopold and J. Mendling and Artem Polyvyanyy},\n booktitle = {IEEE Transactions on Software Engineering},\n journal = {IEEE Transactions on Software Engineering},\n pages = {818-840},\n title = {Supporting Process Model Validation through Natural Language Generation},\n volume = {40},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:88e8801e4daf404d3d40f1648ef29faeb8e6d58a",
            "@type": "ScholarlyArticle",
            "paperId": "88e8801e4daf404d3d40f1648ef29faeb8e6d58a",
            "corpusId": 244714366,
            "url": "https://www.semanticscholar.org/paper/88e8801e4daf404d3d40f1648ef29faeb8e6d58a",
            "title": "Blended Diffusion for Text-driven Editing of Natural Images",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2021,
            "externalIds": {
                "ArXiv": "2111.14818",
                "DBLP": "conf/cvpr/AvrahamiLF22",
                "DOI": "10.1109/CVPR52688.2022.01767",
                "CorpusId": 244714366
            },
            "abstract": "Natural language offers a highly intuitive interface for image editing. In this paper, we introduce the first solution for performing local (region-based) edits in generic natural images, based on a natural language description along with an ROI mask. We achieve our goal by leveraging and combining a pretrained language-image model (CLIP), to steer the edit towards a user-provided text prompt, with a denoising diffusion probabilistic model (DDPM) to generate natural-looking results. To seamlessly fuse the edited region with the unchanged parts of the image, we spatially blend noised versions of the input image with the local text-guided diffusion latent at a progression of noise levels. In addition, we show that adding augmentations to the diffusion process mitigates adversarial results. We compare against several baselines and related methods, both qualitatively and quantitatively, and show that our method outperforms these solutions in terms of overall realism, ability to preserve the background and matching the text. Finally, we show several text-driven editing applications, including adding a new object to an image, removing/replacing/altering existing objects, background replacement, and image extrapolation.",
            "referenceCount": 62,
            "citationCount": 338,
            "influentialCitationCount": 43,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2111.14818",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2021-11-29",
            "journal": {
                "name": "2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Avrahami2021BlendedDF,\n author = {Omri Avrahami and D. Lischinski and Ohad Fried},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {18187-18197},\n title = {Blended Diffusion for Text-driven Editing of Natural Images},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:dbe79abbbc1fc7df6ce90d263a363d99fabd3489",
            "@type": "ScholarlyArticle",
            "paperId": "dbe79abbbc1fc7df6ce90d263a363d99fabd3489",
            "corpusId": 6167614,
            "url": "https://www.semanticscholar.org/paper/dbe79abbbc1fc7df6ce90d263a363d99fabd3489",
            "title": "Natural language and natural selection",
            "venue": "Behavioral and Brain Sciences",
            "publicationVenue": {
                "id": "urn:research:f51399af-b5cb-4819-9d81-57ec1d17ebf0",
                "name": "Behavioral and Brain Sciences",
                "alternate_names": [
                    "Behav Brain Sci"
                ],
                "issn": "0140-525X",
                "url": "http://www.bbsonline.org/"
            },
            "year": 1990,
            "externalIds": {
                "MAG": "2162471372",
                "DOI": "10.1017/S0140525X00081061",
                "CorpusId": 6167614
            },
            "abstract": "Abstract Many people have argued that the evolution of the human language faculty cannot be explained by Darwinian natural selection. Chomsky and Gould have suggested that language may have evolved as the by-product of selection for other abilities or as a consequence of as-yet unknown laws of growth and form. Others have argued that a biological specialization for grammar is incompatible with every tenet of Darwinian theory \u2013 that it shows no genetic variation, could not exist in any intermediate forms, confers no selective advantage, and would require more evolutionary time and genomic space than is available. We examine these arguments and show that they depend on inaccurate assumptions about biology or language or both. Evolutionary theory offers clear criteria for when a trait should be attributed to natural selection: complex design for some function, and the absence of alternative processes capable of explaining such complexity. Human language meets these criteria: Grammar is a complex mechanism tailored to the transmission of propositional structures through a serial interface. Autonomous and arbitrary grammatical phenomena have been offered as counterexamples to the position that language is an adaptation, but this reasoning is unsound: Communication protocols depend on arbitrary conventions that are adaptive as long as they are shared. Consequently, language acquisition in the child should systematically differ from language evolution in the species, and attempts to analogize them are misleading. Reviewing other arguments and data, we conclude that there is every reason to believe that a specialization for grammar evolved by a conventional neo-Darwinian process.",
            "referenceCount": 296,
            "citationCount": 2081,
            "influentialCitationCount": 75,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "1990-12-01",
            "journal": {
                "name": "Behavioral and Brain Sciences",
                "volume": "13"
            },
            "citationStyles": {
                "bibtex": "@Article{Pinker1990NaturalLA,\n author = {S. Pinker and P. Bloom},\n booktitle = {Behavioral and Brain Sciences},\n journal = {Behavioral and Brain Sciences},\n pages = {707 - 727},\n title = {Natural language and natural selection},\n volume = {13},\n year = {1990}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:09550accec47459a61fe1710a0a32c2ec22449bd",
            "@type": "ScholarlyArticle",
            "paperId": "09550accec47459a61fe1710a0a32c2ec22449bd",
            "corpusId": 18366823,
            "url": "https://www.semanticscholar.org/paper/09550accec47459a61fe1710a0a32c2ec22449bd",
            "title": "Computational Linguistics Transition Network Grammars for Natural Language Analysis",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": null,
            "externalIds": {
                "CorpusId": 18366823
            },
            "abstract": "The use of augmented transition network grammars for the analysis of natural language sentences is described. Structure building actions associated with the arcs of the grammar network allow for the reordering, restructuring, and copying of constituents necessary to produce deep-structure representations of the type normally obtained from a transforma-tional analysis, and conditions on the arcs allow for a powerful selectivity which can rule out meaningless analyses and take advantage of semantic information to guide the parsing. The advantages of this model for natural language analysis are discussed in detail and illustrated by examples. An implementation of an experimental parsing system for transition network grammars is briefly described. One of the early models for natural language grammars was the finite state transition graph. This model consists of a network of nodes and directed arcs connecting them, where the nodes correspond to states in a finite state machine and the arcs represent transitions from state to state. Each arc is labeled with a symbol whose input can cause a transition from the state at the tail of the arc to the state at its head. This model has the attractive feature that the sequences of words which make up a sentence can be read off directly by following the paths through the grammar from the initial state to some final state. Unfortunately , the model is grossly inadequate for the representation of natural language grammars due to its failure to capture many of their regularities. A most notable inadequacy is the absence of a pushdown mechanism that permits one to suspend the processing of a constituent at a given level while using the same grammar to process an embedded constituent. Suppose, however, that one added the mechanism of re-cursion directly to the transition graph model by fiat. That is, suppose one took a collection of transition graphs each with a name, and permitted as labels on the arcs not only terminal symbols but also nonterminal symbols naming complex constructions which must be present in order for the transition to be followed. The determination of whether such a construction was in fact present in a sentence would be done by a \"subroutine call\" to another transition graph (or the same one). The resulting model of grammar, which we will call a recursive transition network, is equivalent in generative power to that of a context-free grammar or pushdown store automaton, but as we will \u2026",
            "referenceCount": 30,
            "citationCount": 1461,
            "influentialCitationCount": 68,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Misc{None,\n author = {D. Bobrow and W. A. Woods},\n title = {Computational Linguistics Transition Network Grammars for Natural Language Analysis}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:00e26133551f152f4c8913c5442238d30a63ef79",
            "@type": "ScholarlyArticle",
            "paperId": "00e26133551f152f4c8913c5442238d30a63ef79",
            "corpusId": 18731245,
            "url": "https://www.semanticscholar.org/paper/00e26133551f152f4c8913c5442238d30a63ef79",
            "title": "Natural language Interface for Database: A Brief review",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2011,
            "externalIds": {
                "MAG": "2554350299",
                "CorpusId": 18731245
            },
            "abstract": "Information is playing an important role in our lives. One of the major sources of information is databases. Databases and database technology are having major impact on the growing use of computers. Almost all IT applications are storing and retrieving information from databases. Retrieving information database requires knowledge of database languages like SQL. The Structured Query Language (SQL) norms are been pursued in almost all languages for relational database systems. However, not everybody is able to write SQL queries as they may not be aware of the structure of the database. So this has led to the development of Intelligent Database System ( IDBS) . There is an overwhelming need for non-expert users to query relational databases in their natural language instead of working with the values of the attributes. As a result many intelligent natural language interfaces to databases have been developed, which provides flexible options for manipulating queries. The idea of using Natural Language instead of SQL has prompted the development of new type of processing called Natural language Interface to Database. NLIDB is a step towards the development of intelligent database systems (IDBS) to enhance the users in performing flexible querying in databases. This paper is an introduction to Intelligent Database System and Natural Language Interface to Databases. Then a brief overview of NLIDB subcomponents is given and then discussion then moves on to NLIDB architectures and various approaches for the development of NLIDB systems.",
            "referenceCount": 37,
            "citationCount": 87,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Nihalani2011NaturalLI,\n author = {Neelu Nihalani and S. Silakari and Mahesh Motwani},\n title = {Natural language Interface for Database: A Brief review},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2a4e915fda85287f6165c04769dcc9ce92cdac98",
            "@type": "ScholarlyArticle",
            "paperId": "2a4e915fda85287f6165c04769dcc9ce92cdac98",
            "corpusId": 62580020,
            "url": "https://www.semanticscholar.org/paper/2a4e915fda85287f6165c04769dcc9ce92cdac98",
            "title": "Mental Spaces: Aspects of Meaning Construction in Natural Language",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1985,
            "externalIds": {
                "MAG": "2091349213",
                "DOI": "10.1163/9789004360716_002",
                "CorpusId": 62580020
            },
            "abstract": "This book offers a highly original, integrated treatment of issues that play a central role in linguistic semantics, philosophy of language, and cognitive approaches to meaning.It is based on the idea that expressions of language are not interpreted directly via truth conditions; rather, at a certain cognitive level they help to build up mental spaces, internally structured and linked to one another. Because the construction of spaces is typically underdetermined by the expressions, simple principles yield multiple possibilities and apparently complex ambiguities.Focusing on the mental constructions that can be associated with expressions rather than merely on the expressions themselves, Fauconnier reveals a general, uniform, and elegant organization that is responsible for superficially diverse and complex phenomena. A finding that challenges several traditional and widespread views on meaning and natural language, with far-reaching implications: adequate theories of truth and reference cannot bypass the cognitive space-construction process, and standard linguistic arguments for hidden structural levels are invalidated.Gilles Fauconnier is director of studies at the Ecole des Hautes Etudes en Sciences Sociales and Professor of Linguistics at the University of Paris VIII.A Bradford Book.",
            "referenceCount": 6,
            "citationCount": 1426,
            "influentialCitationCount": 101,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Philosophy",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Fauconnier1985MentalSA,\n author = {G. Fauconnier},\n title = {Mental Spaces: Aspects of Meaning Construction in Natural Language},\n year = {1985}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6bd9642470ff8c2089427f7a6392cd17d213a334",
            "@type": "ScholarlyArticle",
            "paperId": "6bd9642470ff8c2089427f7a6392cd17d213a334",
            "corpusId": 4673790,
            "url": "https://www.semanticscholar.org/paper/6bd9642470ff8c2089427f7a6392cd17d213a334",
            "title": "Vision-and-Language Navigation: Interpreting Visually-Grounded Navigation Instructions in Real Environments",
            "venue": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2952157315",
                "DBLP": "conf/cvpr/AndersonWTB0S0G18",
                "ArXiv": "1711.07280",
                "DOI": "10.1109/CVPR.2018.00387",
                "CorpusId": 4673790
            },
            "abstract": "A robot that can carry out a natural-language instruction has been a dream since before the Jetsons cartoon series imagined a life of leisure mediated by a fleet of attentive robot helpers. It is a dream that remains stubbornly distant. However, recent advances in vision and language methods have made incredible progress in closely related areas. This is significant because a robot interpreting a natural-language navigation instruction on the basis of what it sees is carrying out a vision and language process that is similar to Visual Question Answering. Both tasks can be interpreted as visually grounded sequence-to-sequence translation problems, and many of the same methods are applicable. To enable and encourage the application of vision and language methods to the problem of interpreting visually-grounded navigation instructions, we present the Matter-port3D Simulator - a large-scale reinforcement learning environment based on real imagery [11]. Using this simulator, which can in future support a range of embodied vision and language tasks, we provide the first benchmark dataset for visually-grounded natural language navigation in real buildings - the Room-to-Room (R2R) dataset1.",
            "referenceCount": 65,
            "citationCount": 959,
            "influentialCitationCount": 233,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1711.07280",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-11-20",
            "journal": {
                "name": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Anderson2017VisionandLanguageNI,\n author = {Peter Anderson and Qi Wu and Damien Teney and Jake Bruce and Mark Johnson and Niko S\u00fcnderhauf and I. Reid and Stephen Gould and A. Hengel},\n booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n journal = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n pages = {3674-3683},\n title = {Vision-and-Language Navigation: Interpreting Visually-Grounded Navigation Instructions in Real Environments},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:745b14e17bd4e065e14a951452523f0b2dcee008",
            "@type": "ScholarlyArticle",
            "paperId": "745b14e17bd4e065e14a951452523f0b2dcee008",
            "corpusId": 16347965,
            "url": "https://www.semanticscholar.org/paper/745b14e17bd4e065e14a951452523f0b2dcee008",
            "title": "Bilateral brain processes for comprehending natural language",
            "venue": "Trends in Cognitive Sciences",
            "publicationVenue": {
                "id": "urn:research:20cb626a-518d-4016-826a-0157cf2f8fd6",
                "name": "Trends in Cognitive Sciences",
                "alternate_names": [
                    "Trends Cogn Sci"
                ],
                "issn": "1364-6613",
                "url": "https://www.cell.com/trends/cognitive-sciences/home"
            },
            "year": 2005,
            "externalIds": {
                "MAG": "1989092323",
                "DOI": "10.1016/j.tics.2005.09.009",
                "CorpusId": 16347965,
                "PubMed": "16214387"
            },
            "abstract": null,
            "referenceCount": 71,
            "citationCount": 792,
            "influentialCitationCount": 78,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2005-11-01",
            "journal": {
                "name": "Trends in Cognitive Sciences",
                "volume": "9"
            },
            "citationStyles": {
                "bibtex": "@Article{Jung-Beeman2005BilateralBP,\n author = {M. Jung-Beeman},\n booktitle = {Trends in Cognitive Sciences},\n journal = {Trends in Cognitive Sciences},\n pages = {512-518},\n title = {Bilateral brain processes for comprehending natural language},\n volume = {9},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:36371b9b05e964fb56835f8d25bc5c5d3247fb73",
            "@type": "ScholarlyArticle",
            "paperId": "36371b9b05e964fb56835f8d25bc5c5d3247fb73",
            "corpusId": 69361999,
            "url": "https://www.semanticscholar.org/paper/36371b9b05e964fb56835f8d25bc5c5d3247fb73",
            "title": "The revolution will not be controlled: natural stimuli in speech neuroscience",
            "venue": "Language, Cognition and Neuroscience",
            "publicationVenue": {
                "id": "urn:research:c83d29d4-3d88-4065-8da9-3d670a947fb4",
                "name": "Language, Cognition and Neuroscience",
                "alternate_names": [
                    "Lang Cogn Neurosci",
                    "Language, cognition and neuroscience",
                    "Lang cogn neurosci"
                ],
                "issn": "2327-3798",
                "url": "http://www.tandfonline.com/plcp"
            },
            "year": 2018,
            "externalIds": {
                "PubMedCentral": "7324135",
                "MAG": "2883992483",
                "DOI": "10.1080/23273798.2018.1499946",
                "CorpusId": 69361999,
                "PubMed": "32656294"
            },
            "abstract": "ABSTRACT Humans have a unique ability to produce and consume rich, complex, and varied language in order to communicate ideas to one another. Still, outside of natural reading, the most common methods for studying how our brains process speech or understand language use only isolated words or simple sentences. Recent studies have upset this status quo by employing complex natural stimuli and measuring how the brain responds to language as it is used. In this article we argue that natural stimuli offer many advantages over simplified, controlled stimuli for studying how language is processed by the brain. Furthermore, the downsides of using natural language stimuli can be mitigated using modern statistical and computational techniques.",
            "referenceCount": 79,
            "citationCount": 179,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.tandfonline.com/doi/pdf/10.1080/23273798.2018.1499946?needAccess=true",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-07-22",
            "journal": {
                "name": "Language, Cognition and Neuroscience",
                "volume": "35"
            },
            "citationStyles": {
                "bibtex": "@Article{Hamilton2018TheRW,\n author = {Liberty S. Hamilton and Alexander G. Huth},\n booktitle = {Language, Cognition and Neuroscience},\n journal = {Language, Cognition and Neuroscience},\n pages = {573 - 582},\n title = {The revolution will not be controlled: natural stimuli in speech neuroscience},\n volume = {35},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ff46572167b30f1035de7f12f795245ea39868e1",
            "@type": "ScholarlyArticle",
            "paperId": "ff46572167b30f1035de7f12f795245ea39868e1",
            "corpusId": 2317283,
            "url": "https://www.semanticscholar.org/paper/ff46572167b30f1035de7f12f795245ea39868e1",
            "title": "On the Systematic Analysis of Natural Language Requirements with CIRCE",
            "venue": "International Conference on Automated Software Engineering",
            "publicationVenue": {
                "id": "urn:research:1c2ab05c-7d69-465e-929d-0920857aedce",
                "name": "International Conference on Automated Software Engineering",
                "alternate_names": [
                    "Autom Softw Eng",
                    "ASE",
                    "Automated Software Engineering",
                    "Int Conf Autom Softw Eng"
                ],
                "issn": null,
                "url": "http://ase.informatik.uni-essen.de/"
            },
            "year": 2006,
            "externalIds": {
                "MAG": "2048074122",
                "DBLP": "journals/ase/AmbriolaG06",
                "DOI": "10.1007/s10515-006-5468-2",
                "CorpusId": 2317283
            },
            "abstract": null,
            "referenceCount": 75,
            "citationCount": 141,
            "influentialCitationCount": 17,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Automated Software Engineering",
                "volume": "13"
            },
            "citationStyles": {
                "bibtex": "@Article{Ambriola2006OnTS,\n author = {V. Ambriola and V. Gervasi},\n booktitle = {International Conference on Automated Software Engineering},\n journal = {Automated Software Engineering},\n pages = {107-167},\n title = {On the Systematic Analysis of Natural Language Requirements with CIRCE},\n volume = {13},\n year = {2006}\n}\n"
            }
        }
    }
]