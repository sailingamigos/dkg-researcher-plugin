[
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:eb606d9ce65139754232cee62f6ab77f3e0c665f",
            "@type": "ScholarlyArticle",
            "paperId": "eb606d9ce65139754232cee62f6ab77f3e0c665f",
            "corpusId": 198967997,
            "url": "https://www.semanticscholar.org/paper/eb606d9ce65139754232cee62f6ab77f3e0c665f",
            "title": "Leveraging Pre-trained Checkpoints for Sequence Generation Tasks",
            "venue": "Transactions of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:e0dbf116-86aa-418d-859f-a49952d7e44a",
                "name": "Transactions of the Association for Computational Linguistics",
                "alternate_names": [
                    "Trans Assoc Comput Linguistics",
                    "TACL"
                ],
                "issn": "2307-387X",
                "url": "https://www.mitpressjournals.org/loi/tacl"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2964910501",
                "DBLP": "journals/tacl/RotheNS20",
                "ArXiv": "1907.12461",
                "DOI": "10.1162/tacl_a_00313",
                "CorpusId": 198967997
            },
            "abstract": "Abstract Unsupervised pre-training of large neural models has recently revolutionized Natural Language Processing. By warm-starting from the publicly released checkpoints, NLP practitioners have pushed the state-of-the-art on multiple benchmarks while saving significant amounts of compute time. So far the focus has been mainly on the Natural Language Understanding tasks. In this paper, we demonstrate the efficacy of pre-trained checkpoints for Sequence Generation. We developed a Transformer-based sequence-to-sequence model that is compatible with publicly available pre-trained BERT, GPT-2, and RoBERTa checkpoints and conducted an extensive empirical study on the utility of initializing our model, both encoder and decoder, with these checkpoints. Our models result in new state-of-the-art results on Machine Translation, Text Summarization, Sentence Splitting, and Sentence Fusion.",
            "referenceCount": 67,
            "citationCount": 345,
            "influentialCitationCount": 43,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl_a_00313/1923422/tacl_a_00313.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-07-29",
            "journal": {
                "name": "Transactions of the Association for Computational Linguistics",
                "volume": "8"
            },
            "citationStyles": {
                "bibtex": "@Article{Rothe2019LeveragingPC,\n author = {S. Rothe and Shashi Narayan and Aliaksei Severyn},\n booktitle = {Transactions of the Association for Computational Linguistics},\n journal = {Transactions of the Association for Computational Linguistics},\n pages = {264-280},\n title = {Leveraging Pre-trained Checkpoints for Sequence Generation Tasks},\n volume = {8},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b20ddcbd239f3fa9acc603736ac2e4416302d074",
            "@type": "ScholarlyArticle",
            "paperId": "b20ddcbd239f3fa9acc603736ac2e4416302d074",
            "corpusId": 222290851,
            "url": "https://www.semanticscholar.org/paper/b20ddcbd239f3fa9acc603736ac2e4416302d074",
            "title": "COGS: A Compositional Generalization Challenge Based on Semantic Interpretation",
            "venue": "Conference on Empirical Methods in Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:41bf9ed3-85b3-4c90-b015-150e31690253",
                "name": "Conference on Empirical Methods in Natural Language Processing",
                "alternate_names": [
                    "Empir Method Nat Lang Process",
                    "Empirical Methods in Natural Language Processing",
                    "Conf Empir Method Nat Lang Process",
                    "EMNLP"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/emnlp"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3092866762",
                "DBLP": "journals/corr/abs-2010-05465",
                "ArXiv": "2010.05465",
                "ACL": "2020.emnlp-main.731",
                "DOI": "10.18653/v1/2020.emnlp-main.731",
                "CorpusId": 222290851
            },
            "abstract": "Natural language is characterized by compositionality: the meaning of a complex expression is constructed from the meanings of its constituent parts. To facilitate the evaluation of the compositional abilities of language processing architectures, we introduce COGS, a semantic parsing dataset based on a fragment of English. The evaluation portion of COGS contains multiple systematic gaps that can only be addressed by compositional generalization; these include new combinations of familiar syntactic structures, or new combinations of familiar words and familiar structures. In experiments with Transformers and LSTMs, we found that in-distribution accuracy on the COGS test set was near-perfect (96--99%), but generalization accuracy was substantially lower (16--35%) and showed high sensitivity to random seed ($\\pm$6--8%). These findings indicate that contemporary standard NLP models are limited in their compositional generalization capacity, and position COGS as a good way to measure progress.",
            "referenceCount": 59,
            "citationCount": 182,
            "influentialCitationCount": 38,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aclweb.org/anthology/2020.emnlp-main.731.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2020-10-12",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2010.05465"
            },
            "citationStyles": {
                "bibtex": "@Article{Kim2020COGSAC,\n author = {Najoung Kim and Tal Linzen},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {COGS: A Compositional Generalization Challenge Based on Semantic Interpretation},\n volume = {abs/2010.05465},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:afd110eace912c2b273e64851c6b4df2658622eb",
            "@type": "ScholarlyArticle",
            "paperId": "afd110eace912c2b273e64851c6b4df2658622eb",
            "corpusId": 174802633,
            "url": "https://www.semanticscholar.org/paper/afd110eace912c2b273e64851c6b4df2658622eb",
            "title": "Visualizing and Measuring the Geometry of BERT",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2970727289",
                "DBLP": "conf/nips/ReifYWVCPK19",
                "ArXiv": "1906.02715",
                "CorpusId": 174802633
            },
            "abstract": "Transformer architectures show significant promise for natural language processing. Given that a single pretrained model can be fine-tuned to perform well on many different tasks, these networks appear to extract generally useful linguistic features. A natural question is how such networks represent this information internally. This paper describes qualitative and quantitative investigations of one particularly effective model, BERT. At a high level, linguistic features seem to be represented in separate semantic and syntactic subspaces. We find evidence of a fine-grained geometric representation of word senses. We also present empirical descriptions of syntactic representations in both attention matrices and individual word embeddings, as well as a mathematical argument to explain the geometry of these representations.",
            "referenceCount": 29,
            "citationCount": 331,
            "influentialCitationCount": 36,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-06-06",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1906.02715"
            },
            "citationStyles": {
                "bibtex": "@Article{Coenen2019VisualizingAM,\n author = {Andy Coenen and Emily Reif and Ann Yuan and Been Kim and Adam Pearce and F. Vi\u00e9gas and M. Wattenberg},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Visualizing and Measuring the Geometry of BERT},\n volume = {abs/1906.02715},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0f2835a64b865992dc19d090e3ed61e53b16509d",
            "@type": "ScholarlyArticle",
            "paperId": "0f2835a64b865992dc19d090e3ed61e53b16509d",
            "corpusId": 10925786,
            "url": "https://www.semanticscholar.org/paper/0f2835a64b865992dc19d090e3ed61e53b16509d",
            "title": "Using Social Media to Enhance Emergency Situation Awareness",
            "venue": "IEEE Intelligent Systems",
            "publicationVenue": {
                "id": "urn:research:7404efea-88b2-4c7c-8cb1-b3a8ced6363f",
                "name": "IEEE Intelligent Systems",
                "alternate_names": [
                    "IEEE Intell Syst"
                ],
                "issn": "1541-1672",
                "url": "https://ieeexplore.ieee.org/servlet/opac?punumber=9670"
            },
            "year": 2012,
            "externalIds": {
                "MAG": "2133046612",
                "DBLP": "journals/expert/YinLCRP12",
                "DOI": "10.1109/MIS.2012.6",
                "CorpusId": 10925786
            },
            "abstract": "The described system uses natural language processing and data mining techniques to extract situation awareness information from Twitter messages generated during various disasters and crises.",
            "referenceCount": 28,
            "citationCount": 682,
            "influentialCitationCount": 29,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Political Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2012-11-01",
            "journal": {
                "name": "IEEE Intelligent Systems",
                "volume": "27"
            },
            "citationStyles": {
                "bibtex": "@Article{Yin2012UsingSM,\n author = {Jie Yin and Andrew Lampert and M. Cameron and B. Robinson and R. Power},\n booktitle = {IEEE Intelligent Systems},\n journal = {IEEE Intelligent Systems},\n pages = {52-59},\n title = {Using Social Media to Enhance Emergency Situation Awareness},\n volume = {27},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:df9fcf32b0320057e90624b6e16778a3787be648",
            "@type": "ScholarlyArticle",
            "paperId": "df9fcf32b0320057e90624b6e16778a3787be648",
            "corpusId": 410844,
            "url": "https://www.semanticscholar.org/paper/df9fcf32b0320057e90624b6e16778a3787be648",
            "title": "Investigating Semantic Similarity Measures Across the Gene Ontology: The Relationship Between Sequence and Annotation",
            "venue": "Bioinform.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2003,
            "externalIds": {
                "MAG": "2127563440",
                "DBLP": "journals/bioinformatics/LordSBG03",
                "DOI": "10.1093/bioinformatics/btg153",
                "CorpusId": 410844,
                "PubMed": "12835272"
            },
            "abstract": "MOTIVATION\nMany bioinformatics data resources not only hold data in the form of sequences, but also as annotation. In the majority of cases, annotation is written as scientific natural language: this is suitable for humans, but not particularly useful for machine processing. Ontologies offer a mechanism by which knowledge can be represented in a form capable of such processing. In this paper we investigate the use of ontological annotation to measure the similarities in knowledge content or 'semantic similarity' between entries in a data resource. These allow a bioinformatician to perform a similarity measure over annotation in an analogous manner to those performed over sequences. A measure of semantic similarity for the knowledge component of bioinformatics resources should afford a biologist a new tool in their repertoire of analyses.\n\n\nRESULTS\nWe present the results from experiments that investigate the validity of using semantic similarity by comparison with sequence similarity. We show a simple extension that enables a semantic search of the knowledge held within sequence databases.\n\n\nAVAILABILITY\nSoftware available from http://www.russet.org.uk.",
            "referenceCount": 23,
            "citationCount": 933,
            "influentialCitationCount": 78,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://academic.oup.com/bioinformatics/article-pdf/19/10/1275/48903852/bioinformatics_19_10_1275.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Study",
                "JournalArticle"
            ],
            "publicationDate": "2003-07-01",
            "journal": {
                "name": "Bioinformatics",
                "volume": "19 10"
            },
            "citationStyles": {
                "bibtex": "@Article{Lord2003InvestigatingSS,\n author = {P. Lord and R. Stevens and A. Brass and C. Goble},\n booktitle = {Bioinform.},\n journal = {Bioinformatics},\n pages = {\n          1275-83\n        },\n title = {Investigating Semantic Similarity Measures Across the Gene Ontology: The Relationship Between Sequence and Annotation},\n volume = {19 10},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9ea8f5ff2cbd3a65cf0db91b95430bae7d514359",
            "@type": "ScholarlyArticle",
            "paperId": "9ea8f5ff2cbd3a65cf0db91b95430bae7d514359",
            "corpusId": 11777996,
            "url": "https://www.semanticscholar.org/paper/9ea8f5ff2cbd3a65cf0db91b95430bae7d514359",
            "title": "Automatic Keyphrase Extraction: A Survey of the State of the Art",
            "venue": "Annual Meeting of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                "name": "Annual Meeting of the Association for Computational Linguistics",
                "alternate_names": [
                    "Annu Meet Assoc Comput Linguistics",
                    "Meeting of the Association for Computational Linguistics",
                    "ACL",
                    "Meet Assoc Comput Linguistics"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/acl/"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "conf/acl/HasanN14",
                "ACL": "P14-1119",
                "MAG": "2167329753",
                "DOI": "10.3115/v1/P14-1119",
                "CorpusId": 11777996
            },
            "abstract": "While automatic keyphrase extraction has been examined extensively, state-of-theart performance on this task is still much lower than that on many core natural language processing tasks. We present a survey of the state of the art in automatic keyphrase extraction, examining the major sources of errors made by existing systems and discussing the challenges ahead.",
            "referenceCount": 68,
            "citationCount": 478,
            "influentialCitationCount": 56,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hasan2014AutomaticKE,\n author = {K. Hasan and Vincent Ng},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {1262-1273},\n title = {Automatic Keyphrase Extraction: A Survey of the State of the Art},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0dd6795ae207ae4bc455c9ac938c3eebd84897c8",
            "@type": "ScholarlyArticle",
            "paperId": "0dd6795ae207ae4bc455c9ac938c3eebd84897c8",
            "corpusId": 5371566,
            "url": "https://www.semanticscholar.org/paper/0dd6795ae207ae4bc455c9ac938c3eebd84897c8",
            "title": "Book Reviews: Statistical Language Learning",
            "venue": "International Conference on Computational Logic",
            "publicationVenue": {
                "id": "urn:research:30a8645d-22d4-42e2-b3f6-304bf4ce3a02",
                "name": "International Conference on Computational Logic",
                "alternate_names": [
                    "CL",
                    "Int Conf Comput Log"
                ],
                "issn": null,
                "url": null
            },
            "year": 1995,
            "externalIds": {
                "ACL": "J95-1006",
                "MAG": "3088363526",
                "CorpusId": 5371566
            },
            "abstract": "The $64,000 question in computational linguistics these days is: \"What should I read to learn about statistical natural language processing?\" I have been asked this question over and over, and each time I have given basically the same reply: there is no text that addresses this topic directly; the best one can do is find a good probability-theory textbook and a good information-theory textbook and supplement those texts with an assortment of conference papers and journal articles. Understanding the disappointment this answer provoked, I was delighted to hear that someone had finally written a book directly addressing this topic. However, after reading Eugene Charniak's Statistical Language Learning, I have very mixed feelings about the impact this book might have on the ever-growing field of statistical NLP. The book begins with a very brief description of the classic artificial intelligence approach to NLP (Chapter 1), including morphology, syntax, semantics, and pragmatics. It presents a few definitions from probability theory and information theory (Chapter 2), then proceeds to introduce hidden Markov models (Chapters 3 and 4) and probabilistic context-free grammars (Chapters 5 and 6). The book concludes with a few chapters discussing advanced topics in statistical language learning, such as grammar induction (Chapter 7), syntactic disambiguation (Chapter 8), word clustering (Chapter 9), and word sense disambiguation (Chapter 10). To its credit, the book serves as an interesting popular discussion of statistical modeling in NLP. It is well written and entertaining and very accessible to the reader with a limited mathematical background. It presents a good selection of statistical NLP topics to introduce the reader to the field. And the descriptions of the forwardbackward algorithm for hidden Markov models and the inside-outside algorithm for probabilistic context-free grammars are intuitive and easy to follow. However, as a resource for someone interested in entering this area of research, this book falls far short of its author's goals. These goals are clearly stated in the preface:",
            "referenceCount": 30,
            "citationCount": 908,
            "influentialCitationCount": 46,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Magerman1995BookRS,\n author = {David M. Magerman},\n booktitle = {International Conference on Computational Logic},\n title = {Book Reviews: Statistical Language Learning},\n year = {1995}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:04221cd779dc8a9a2cc5d921a3449dbead8d7890",
            "@type": "ScholarlyArticle",
            "paperId": "04221cd779dc8a9a2cc5d921a3449dbead8d7890",
            "corpusId": 436023,
            "url": "https://www.semanticscholar.org/paper/04221cd779dc8a9a2cc5d921a3449dbead8d7890",
            "title": "SemEval-2010 Task 8: Multi-Way Classification of Semantic Relations Between Pairs of Nominals",
            "venue": "SEW@NAACL-HLT",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2009,
            "externalIds": {
                "DBLP": "conf/naacl/HendrickxKKNSPP09",
                "ACL": "W09-2415",
                "MAG": "2099779943",
                "DOI": "10.3115/1621969.1621986",
                "CorpusId": 436023
            },
            "abstract": "We present a brief overview of the main challenges in the extraction of semantic relations from English text, and discuss the shortcomings of previous data sets and shared tasks. This leads us to introduce a new task, which will be part of SemEval-2010: multi-way classification of mutually exclusive semantic relations between pairs of common nominals. The task is designed to compare different approaches to the problem and to provide a standard testbed for future research, which can benefit many applications in Natural Language Processing.",
            "referenceCount": 30,
            "citationCount": 710,
            "influentialCitationCount": 96,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://dl.acm.org/ft_gateway.cfm?id=1621986&type=pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2009-06-04",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hendrickx2009SemEval2010T8,\n author = {Iris Hendrickx and Su Nam Kim and Zornitsa Kozareva and Preslav Nakov and Diarmuid \u00d3 S\u00e9aghdha and Sebastian Pad\u00f3 and M. Pennacchiotti and Lorenza Romano and Stan Szpakowicz},\n booktitle = {SEW@NAACL-HLT},\n pages = {94-99},\n title = {SemEval-2010 Task 8: Multi-Way Classification of Semantic Relations Between Pairs of Nominals},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:21143b8026cefc440ed1ad10e68ef52931b6ff63",
            "@type": "ScholarlyArticle",
            "paperId": "21143b8026cefc440ed1ad10e68ef52931b6ff63",
            "corpusId": 23185326,
            "url": "https://www.semanticscholar.org/paper/21143b8026cefc440ed1ad10e68ef52931b6ff63",
            "title": "Eye movements as a window into real-time spoken language comprehension in natural contexts",
            "venue": "Journal of Psycholinguistic Research",
            "publicationVenue": {
                "id": "urn:research:3cb17eb4-8725-4116-ad0f-c22bf21d9d62",
                "name": "Journal of Psycholinguistic Research",
                "alternate_names": [
                    "J Psycholinguist Res"
                ],
                "issn": "0090-6905",
                "url": "http://www.kluweronline.com/issn/0090-6905/contents"
            },
            "year": 1995,
            "externalIds": {
                "MAG": "2025665527",
                "DOI": "10.1007/BF02143160",
                "CorpusId": 23185326,
                "PubMed": "8531168"
            },
            "abstract": null,
            "referenceCount": 28,
            "citationCount": 353,
            "influentialCitationCount": 15,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "1995-11-01",
            "journal": {
                "name": "Journal of Psycholinguistic Research",
                "volume": "24"
            },
            "citationStyles": {
                "bibtex": "@Article{Eberhard1995EyeMA,\n author = {K. M. Eberhard and M. Spivey-Knowlton and Julie C. Sedivy and M. Tanenhaus},\n booktitle = {Journal of Psycholinguistic Research},\n journal = {Journal of Psycholinguistic Research},\n pages = {409-436},\n title = {Eye movements as a window into real-time spoken language comprehension in natural contexts},\n volume = {24},\n year = {1995}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a08293b2c9c5bcddb023cc7eb3354d4d86bfae89",
            "@type": "ScholarlyArticle",
            "paperId": "a08293b2c9c5bcddb023cc7eb3354d4d86bfae89",
            "corpusId": 85543565,
            "url": "https://www.semanticscholar.org/paper/a08293b2c9c5bcddb023cc7eb3354d4d86bfae89",
            "title": "Distilling Task-Specific Knowledge from BERT into Simple Neural Networks",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1903.12136",
                "DBLP": "journals/corr/abs-1903-12136",
                "MAG": "2924902521",
                "CorpusId": 85543565
            },
            "abstract": "In the natural language processing literature, neural networks are becoming increasingly deeper and complex. The recent poster child of this trend is the deep language representation model, which includes BERT, ELMo, and GPT. These developments have led to the conviction that previous-generation, shallower neural networks for language understanding are obsolete. In this paper, however, we demonstrate that rudimentary, lightweight neural networks can still be made competitive without architecture changes, external training data, or additional input features. We propose to distill knowledge from BERT, a state-of-the-art language representation model, into a single-layer BiLSTM, as well as its siamese counterpart for sentence-pair tasks. Across multiple datasets in paraphrasing, natural language inference, and sentiment classification, we achieve comparable results with ELMo, while using roughly 100 times fewer parameters and 15 times less inference time.",
            "referenceCount": 42,
            "citationCount": 329,
            "influentialCitationCount": 27,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-03-28",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1903.12136"
            },
            "citationStyles": {
                "bibtex": "@Article{Tang2019DistillingTK,\n author = {Raphael Tang and Yao Lu and Linqing Liu and Lili Mou and Olga Vechtomova and Jimmy J. Lin},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Distilling Task-Specific Knowledge from BERT into Simple Neural Networks},\n volume = {abs/1903.12136},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a8912e439ac787c91892ea3d5223e7dd0fea4052",
            "@type": "ScholarlyArticle",
            "paperId": "a8912e439ac787c91892ea3d5223e7dd0fea4052",
            "corpusId": 60709701,
            "url": "https://www.semanticscholar.org/paper/a8912e439ac787c91892ea3d5223e7dd0fea4052",
            "title": "RHETORICAL STRUCTURE THEORY: A THEORY OF TEXT ORGANIZATION",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1987,
            "externalIds": {
                "MAG": "1486798440",
                "CorpusId": 60709701
            },
            "abstract": "Abstract : Rhetorical Structure Theory is a descriptive theory of a major aspect of the organization of natural text. It is a linguistically useful method for describing natural texts, characterizing their structure primarily in terms of relations that hold between parts of the text. This paper establishes a new definitional foundation for RST. Definitions are made more systematic and explicit, they introduce a new functional element, and incidentally reflect more experience in text analysis. Along with the definitions, the paper examines three claims and findings of RST: the predominance of nucleus/satellite structural patterns, the functional basis of hierarchy, and the communicative role of text structure. (Author) Keywords: Artificial intelligence; Coherence; Computational linguistics; Discourse; Grammar; Knowledge delivery; Natural language processing; Pragmatics.",
            "referenceCount": 0,
            "citationCount": 1205,
            "influentialCitationCount": 133,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1987-06-01",
            "journal": {
                "name": "",
                "volume": "87"
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Mann1987RHETORICALST,\n author = {W. Mann},\n pages = {2-82},\n title = {RHETORICAL STRUCTURE THEORY: A THEORY OF TEXT ORGANIZATION},\n volume = {87},\n year = {1987}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:babbf74939612ee2f0203c30a190b4b95881415b",
            "@type": "ScholarlyArticle",
            "paperId": "babbf74939612ee2f0203c30a190b4b95881415b",
            "corpusId": 52161864,
            "url": "https://www.semanticscholar.org/paper/babbf74939612ee2f0203c30a190b4b95881415b",
            "title": "Learning Gender-Neutral Word Embeddings",
            "venue": "Conference on Empirical Methods in Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:41bf9ed3-85b3-4c90-b015-150e31690253",
                "name": "Conference on Empirical Methods in Natural Language Processing",
                "alternate_names": [
                    "Empir Method Nat Lang Process",
                    "Empirical Methods in Natural Language Processing",
                    "Conf Empir Method Nat Lang Process",
                    "EMNLP"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/emnlp"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "conf/emnlp/ZhaoZLWC18",
                "ACL": "D18-1521",
                "ArXiv": "1809.01496",
                "MAG": "2889624842",
                "DOI": "10.18653/v1/D18-1521",
                "CorpusId": 52161864
            },
            "abstract": "Word embedding models have become a fundamental component in a wide range of Natural Language Processing (NLP) applications. However, embeddings trained on human-generated corpora have been demonstrated to inherit strong gender stereotypes that reflect social constructs. To address this concern, in this paper, we propose a novel training procedure for learning gender-neutral word embeddings. Our approach aims to preserve gender information in certain dimensions of word vectors while compelling other dimensions to be free of gender influence. Based on the proposed method, we generate a Gender-Neutral variant of GloVe (GN-GloVe). Quantitative and qualitative experiments demonstrate that GN-GloVe successfully isolates gender information without sacrificing the functionality of the embedding model.",
            "referenceCount": 37,
            "citationCount": 324,
            "influentialCitationCount": 59,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aclweb.org/anthology/D18-1521.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-08-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhao2018LearningGW,\n author = {Jieyu Zhao and Yichao Zhou and Zeyu Li and Wei Wang and Kai-Wei Chang},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {4847-4853},\n title = {Learning Gender-Neutral Word Embeddings},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:46c112747fb44f82d3096c07c6d8a8faeee8b3d4",
            "@type": "ScholarlyArticle",
            "paperId": "46c112747fb44f82d3096c07c6d8a8faeee8b3d4",
            "corpusId": 26127787,
            "url": "https://www.semanticscholar.org/paper/46c112747fb44f82d3096c07c6d8a8faeee8b3d4",
            "title": "A Survey of Cross-lingual Word Embedding Models",
            "venue": "Journal of Artificial Intelligence Research",
            "publicationVenue": {
                "id": "urn:research:aef12dca-60a0-4ca3-819b-cad26d309d4e",
                "name": "Journal of Artificial Intelligence Research",
                "alternate_names": [
                    "JAIR",
                    "J Artif Intell Res",
                    "The Journal of Artificial Intelligence Research"
                ],
                "issn": "1076-9757",
                "url": "http://www.jair.org/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/jair/RuderVS19",
                "MAG": "2769280657",
                "ArXiv": "1706.04902",
                "DOI": "10.1613/jair.1.11640",
                "CorpusId": 26127787
            },
            "abstract": "Cross-lingual representations of words enable us to reason about word meaning in multilingual contexts and are a key facilitator of cross-lingual transfer when developing natural language processing models for low-resource languages. In this survey, we provide a comprehensive typology of cross-lingual word embedding models. We compare their data requirements and objective functions. The recurring theme of the survey is that many of the models presented in the literature optimize for the same objectives, and that seemingly different models are often equivalent, modulo optimization strategies, hyper-parameters, and such. We also discuss the different ways cross-lingual word embeddings are evaluated, as well as future challenges and research horizons.",
            "referenceCount": 221,
            "citationCount": 453,
            "influentialCitationCount": 36,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://jair.org/index.php/jair/article/download/11640/26511",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-06-15",
            "journal": {
                "name": "J. Artif. Intell. Res.",
                "volume": "65"
            },
            "citationStyles": {
                "bibtex": "@Article{Ruder2017ASO,\n author = {Sebastian Ruder and Ivan Vulic and Anders S\u00f8gaard},\n booktitle = {Journal of Artificial Intelligence Research},\n journal = {J. Artif. Intell. Res.},\n pages = {569-631},\n title = {A Survey of Cross-lingual Word Embedding Models},\n volume = {65},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:11342d45911ee8a7c9e3a94117ce774ad7036172",
            "@type": "ScholarlyArticle",
            "paperId": "11342d45911ee8a7c9e3a94117ce774ad7036172",
            "corpusId": 219176513,
            "url": "https://www.semanticscholar.org/paper/11342d45911ee8a7c9e3a94117ce774ad7036172",
            "title": "Neural Unsupervised Domain Adaptation in NLP\u2014A Survey",
            "venue": "International Conference on Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:f51ff783-cdff-4e22-94fb-28e6336d17b3",
                "name": "International Conference on Computational Linguistics",
                "alternate_names": [
                    "Int Conf Comput Linguistics",
                    "COLING"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/coling/"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3114610051",
                "ArXiv": "2006.00632",
                "DBLP": "journals/corr/abs-2006-00632",
                "ACL": "2020.coling-main.603",
                "DOI": "10.18653/V1/2020.COLING-MAIN.603",
                "CorpusId": 219176513
            },
            "abstract": "Deep neural networks excel at learning from labeled data and achieve state-of-the-art results on a wide array of Natural Language Processing tasks. In contrast, learning from unlabeled data, especially under domain shift, remains a challenge. Motivated by the latest advances, in this survey we review neural unsupervised domain adaptation techniques which do not require labeled target domain data. This is a more challenging yet a more widely applicable setup. We outline methods, from early traditional non-neural methods to pre-trained model transfer. We also revisit the notion of domain, and we uncover a bias in the type of Natural Language Processing tasks which received most attention. Lastly, we outline future directions, particularly the broader need for out-of-distribution generalization of future NLP.",
            "referenceCount": 134,
            "citationCount": 193,
            "influentialCitationCount": 17,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aclweb.org/anthology/2020.coling-main.603.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": "2020-05-31",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2006.00632"
            },
            "citationStyles": {
                "bibtex": "@Article{Ramponi2020NeuralUD,\n author = {Alan Ramponi and Barbara Plank},\n booktitle = {International Conference on Computational Linguistics},\n journal = {ArXiv},\n title = {Neural Unsupervised Domain Adaptation in NLP\u2014A Survey},\n volume = {abs/2006.00632},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:52f47e781852a77abedada48cfa971b24c919dde",
            "@type": "ScholarlyArticle",
            "paperId": "52f47e781852a77abedada48cfa971b24c919dde",
            "corpusId": 212747810,
            "url": "https://www.semanticscholar.org/paper/52f47e781852a77abedada48cfa971b24c919dde",
            "title": "Calibration of Pre-trained Transformers",
            "venue": "Conference on Empirical Methods in Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:41bf9ed3-85b3-4c90-b015-150e31690253",
                "name": "Conference on Empirical Methods in Natural Language Processing",
                "alternate_names": [
                    "Empir Method Nat Lang Process",
                    "Empirical Methods in Natural Language Processing",
                    "Conf Empir Method Nat Lang Process",
                    "EMNLP"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/emnlp"
            },
            "year": 2020,
            "externalIds": {
                "ACL": "2020.emnlp-main.21",
                "DBLP": "journals/corr/abs-2003-07892",
                "ArXiv": "2003.07892",
                "MAG": "3104939451",
                "DOI": "10.18653/v1/2020.emnlp-main.21",
                "CorpusId": 212747810
            },
            "abstract": "Pre-trained Transformers are now ubiquitous in natural language processing, but despite their high end-task performance, little is known empirically about whether they are calibrated. Specifically, do these models' posterior probabilities provide an accurate empirical measure of how likely the model is to be correct on a given example? We focus on BERT and RoBERTa in this work, and analyze their calibration across three tasks: natural language inference, paraphrase detection, and commonsense reasoning. For each task, we consider in-domain as well as challenging out-of-domain settings, where models face more examples they should be uncertain about. We show that: (1) when used out-of-the-box, pre-trained models are calibrated in-domain, and compared to baselines, their calibration error out-of-domain can be as much as 3.5x lower; (2) temperature scaling is effective at further reducing calibration error in-domain, and using label smoothing to deliberately increase empirical uncertainty helps calibrate posteriors out-of-domain.",
            "referenceCount": 49,
            "citationCount": 177,
            "influentialCitationCount": 11,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aclweb.org/anthology/2020.emnlp-main.21.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2020-03-17",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2003.07892"
            },
            "citationStyles": {
                "bibtex": "@Article{Desai2020CalibrationOP,\n author = {Shrey Desai and Greg Durrett},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {Calibration of Pre-trained Transformers},\n volume = {abs/2003.07892},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5311f332aa2cb20b8c9c32f5c4c7d59be69aba7c",
            "@type": "ScholarlyArticle",
            "paperId": "5311f332aa2cb20b8c9c32f5c4c7d59be69aba7c",
            "corpusId": 12628845,
            "url": "https://www.semanticscholar.org/paper/5311f332aa2cb20b8c9c32f5c4c7d59be69aba7c",
            "title": "Automatic recognition and understanding of spoken language - a first step toward natural human-machine communication",
            "venue": "Proceedings of the IEEE",
            "publicationVenue": {
                "id": "urn:research:6faaccca-1cc4-45a9-aeb6-96a4901d2606",
                "name": "Proceedings of the IEEE",
                "alternate_names": [
                    "Proc IEEE"
                ],
                "issn": "0018-9219",
                "url": "http://www.ieee.org/portal/pages/pubs/proceedings/"
            },
            "year": 2000,
            "externalIds": {
                "DBLP": "journals/pieee/JuangF00a",
                "MAG": "2119820672",
                "DOI": "10.1109/5.880077",
                "CorpusId": 12628845
            },
            "abstract": "The promise of a powerful computing device to help people in productivity as well as in recreation can only be realized with proper human-machine communication. Automatic recognition and understanding of spoken language is the first step toward natural human-machine interaction. Research in this field has produced remarkable results, leading to many exciting expectations and new challenges. We summarize the development of the spoken language technology from both a vertical (chronology) and a horizontal (spectrum of technical approaches) perspective. We highlight the introduction of statistical methods in dealing with language-related problems, as this represents a paradigm shift in the research field of spoken language processing. Statistical methods are designed to allow the machine to learn structural regularities in the speech signal, directly from data, for the purpose of automatic speech recognition and understanding. Research results in spoken language processing have led to a number of successful applications, ranging from dictation software for personal computers and telephone-call processing systems for automatic call routing, to automatic sub-captioning for television broadcasts. We analyze the technical successes that support these applications. Along with an assessment of the state of the art in this broad technical field, we also discuss the limitations of the current technology, and point out the challenges that are ahead. This paper presents an accurate overview of spoken language technology as a basis to inspire future advances.",
            "referenceCount": 46,
            "citationCount": 147,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://t2r2.star.titech.ac.jp/rrws/file/CTT100443518/ATD100000413/",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2000-08-01",
            "journal": {
                "name": "Proceedings of the IEEE",
                "volume": "88"
            },
            "citationStyles": {
                "bibtex": "@Article{Juang2000AutomaticRA,\n author = {B. Juang and S. Furui},\n booktitle = {Proceedings of the IEEE},\n journal = {Proceedings of the IEEE},\n pages = {1142-1165},\n title = {Automatic recognition and understanding of spoken language - a first step toward natural human-machine communication},\n volume = {88},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d26439e3c2f1d0c1e46f15e8ccb1f5f3cdd0cd3c",
            "@type": "ScholarlyArticle",
            "paperId": "d26439e3c2f1d0c1e46f15e8ccb1f5f3cdd0cd3c",
            "corpusId": 2071984,
            "url": "https://www.semanticscholar.org/paper/d26439e3c2f1d0c1e46f15e8ccb1f5f3cdd0cd3c",
            "title": "Text Mining",
            "venue": "Advanced Analytics with Transact-SQL",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "DOI": "10.1007/springerreference_63533",
                "CorpusId": 2071984
            },
            "abstract": null,
            "referenceCount": 49,
            "citationCount": 475,
            "influentialCitationCount": 20,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2017-06-01",
            "journal": {
                "name": "Advanced Analytics with Transact-SQL",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Sarka2017TextM,\n author = {Dejan Sarka},\n booktitle = {Advanced Analytics with Transact-SQL},\n journal = {Advanced Analytics with Transact-SQL},\n title = {Text Mining},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5290d7921f0266c8b50b79fc8a0b7d22868f4f60",
            "@type": "ScholarlyArticle",
            "paperId": "5290d7921f0266c8b50b79fc8a0b7d22868f4f60",
            "corpusId": 215828359,
            "url": "https://www.semanticscholar.org/paper/5290d7921f0266c8b50b79fc8a0b7d22868f4f60",
            "title": "The Cost of Training NLP Models: A Concise Overview",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2004-08900",
                "MAG": "3016339201",
                "ArXiv": "2004.08900",
                "CorpusId": 215828359
            },
            "abstract": "We review the cost of training large-scale language models, and the drivers of these costs. The intended audience includes engineers and scientists budgeting their model-training experiments, as well as non-practitioners trying to make sense of the economics of modern-day Natural Language Processing (NLP).",
            "referenceCount": 23,
            "citationCount": 151,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Economics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-04-19",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2004.08900"
            },
            "citationStyles": {
                "bibtex": "@Article{Sharir2020TheCO,\n author = {Or Sharir and Barak Peleg and Y. Shoham},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {The Cost of Training NLP Models: A Concise Overview},\n volume = {abs/2004.08900},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3fb416be9e59b35c7cc91cd11b5b3f3f5491f13a",
            "@type": "ScholarlyArticle",
            "paperId": "3fb416be9e59b35c7cc91cd11b5b3f3f5491f13a",
            "corpusId": 16177318,
            "url": "https://www.semanticscholar.org/paper/3fb416be9e59b35c7cc91cd11b5b3f3f5491f13a",
            "title": "Bug report, feature request, or simply praise? On automatically classifying app reviews",
            "venue": "IEEE International Requirements Engineering Conference",
            "publicationVenue": {
                "id": "urn:research:647e2b25-1bff-4e4f-b507-e21dcb081788",
                "name": "IEEE International Requirements Engineering Conference",
                "alternate_names": [
                    "IEEE International Conference on Requirements Engineering",
                    "RE",
                    "IEEE Int Requir Eng Conf",
                    "IEEE Int Conf Requir Eng"
                ],
                "issn": null,
                "url": "http://requirements-engineering.org/"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "1916584426",
                "DBLP": "conf/re/MaalejN15",
                "DOI": "10.1109/RE.2015.7320414",
                "CorpusId": 16177318
            },
            "abstract": "App stores like Google Play and Apple AppStore have over 3 Million apps covering nearly every kind of software and service. Billions of users regularly download, use, and review these apps. Recent studies have shown that reviews written by the users represent a rich source of information for the app vendors and the developers, as they include information about bugs, ideas for new features, or documentation of released features. This paper introduces several probabilistic techniques to classify app reviews into four types: bug reports, feature requests, user experiences, and ratings. For this we use review metadata such as the star rating and the tense, as well as, text classification, natural language processing, and sentiment analysis techniques. We conducted a series of experiments to compare the accuracy of the techniques and compared them with simple string matching. We found that metadata alone results in a poor classification accuracy. When combined with natural language processing, the classification precision got between 70-95% while the recall between 80-90%. Multiple binary classifiers outperformed single multiclass classifiers. Our results impact the design of review analytics tools which help app vendors, developers, and users to deal with the large amount of reviews, filter critical reviews, and assign them to the appropriate stakeholders.",
            "referenceCount": 37,
            "citationCount": 396,
            "influentialCitationCount": 43,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": "2015-08-01",
            "journal": {
                "name": "2015 IEEE 23rd International Requirements Engineering Conference (RE)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Maalej2015BugRF,\n author = {W. Maalej and H. Nabil},\n booktitle = {IEEE International Requirements Engineering Conference},\n journal = {2015 IEEE 23rd International Requirements Engineering Conference (RE)},\n pages = {116-125},\n title = {Bug report, feature request, or simply praise? On automatically classifying app reviews},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c7d3f610b528226f1c862c4f9cd6b37623f7390f",
            "@type": "ScholarlyArticle",
            "paperId": "c7d3f610b528226f1c862c4f9cd6b37623f7390f",
            "corpusId": 9210201,
            "url": "https://www.semanticscholar.org/paper/c7d3f610b528226f1c862c4f9cd6b37623f7390f",
            "title": "The CoNLL-2009 Shared Task: Syntactic and Semantic Dependencies in Multiple Languages",
            "venue": "CoNLL Shared Task",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2009,
            "externalIds": {
                "ACL": "W09-1201",
                "DBLP": "conf/conll/HajicCJKMMMNPSSSXZ09",
                "MAG": "2142222368",
                "DOI": "10.3115/1596409.1596411",
                "CorpusId": 9210201
            },
            "abstract": "For the 11th straight year, the Conference on Computational Natural Language Learning has been accompanied by a shared task whose purpose is to promote natural language processing applications and evaluate them in a standard setting. In 2009, the shared task was dedicated to the joint parsing of syntactic and semantic dependencies in multiple languages. This shared task combines the shared tasks of the previous five years under a unique dependency-based formalism similar to the 2008 task. In this paper, we define the shared task, describe how the data sets were created and show their quantitative properties, report the results and summarize the approaches of the participating systems.",
            "referenceCount": 34,
            "citationCount": 605,
            "influentialCitationCount": 73,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2009-06-04",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hajic2009TheCS,\n author = {Jan Hajic and Massimiliano Ciaramita and Richard Johansson and Daisuke Kawahara and M. A. Mart\u00ed and Llu\u00eds M\u00e0rquez i Villodre and Adam Meyers and Joakim Nivre and Sebastian Pad\u00f3 and J. Step\u00e1nek and P. Stran\u00e1k and M. Surdeanu and Nianwen Xue and Yi Zhang},\n booktitle = {CoNLL Shared Task},\n pages = {1-18},\n title = {The CoNLL-2009 Shared Task: Syntactic and Semantic Dependencies in Multiple Languages},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4ad6fd43ab7dc8711b272306a2049e7a38beb841",
            "@type": "ScholarlyArticle",
            "paperId": "4ad6fd43ab7dc8711b272306a2049e7a38beb841",
            "corpusId": 59704075,
            "url": "https://www.semanticscholar.org/paper/4ad6fd43ab7dc8711b272306a2049e7a38beb841",
            "title": "A Proposal for a Natural Lan-guage Processing Syntactic Backbone",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1997,
            "externalIds": {
                "MAG": "72853833",
                "CorpusId": 59704075
            },
            "abstract": "The purpose of this paper is to present a grammatical formalism that extends context-free grammars and aims at being a convincing challenger as a syntactic base for various tasks, especially in natural language processing. These grammars are powerful, they strictly include mildly context-sensitive languages, while staying computationally tractable, since sentences are parsed in polynomial time. Moreover, this formalism allows a form of modularit- y which may lead to the design of libraries of reusable generic grammatical components. And, last, it can act as a syntactic backbone upon which decoratio- ns from other domains (say feature structures) can be grafted.",
            "referenceCount": 0,
            "citationCount": 70,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Boullier1997APF,\n author = {Pierre Boullier},\n title = {A Proposal for a Natural Lan-guage Processing Syntactic Backbone},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:02ef251d85542a527bc032b910395f27d6511400",
            "@type": "ScholarlyArticle",
            "paperId": "02ef251d85542a527bc032b910395f27d6511400",
            "corpusId": 1439805,
            "url": "https://www.semanticscholar.org/paper/02ef251d85542a527bc032b910395f27d6511400",
            "title": "Acquisition by processing: A modular perspective on language development",
            "venue": "Bilingualism: Language and Cognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2004,
            "externalIds": {
                "MAG": "2055248635",
                "DOI": "10.1017/S1366728904001178",
                "CorpusId": 1439805
            },
            "abstract": "The paper offers a model of language development, first and second, within a processing perspective. We first sketch a modular view of language, in which competence is embodied in the processing mechanisms. We then propose a novel approach to language acquisition (Acquisition by Processing Theory, or APT), in which development of the module occurs as a natural product of processing activity, without any acquisition mechanisms as such. The approach is illustrated and explicated through examples of the development of content words, derivational morphology, the functional category I with its variable features, and Case and thematic roles, as well as apparent cross-linguistic variation in processing strategies and the status of bootstrapping in the model. We then examine some possible applications to issues in second language acquisition \u2013 noticing the gap, the initial state, transfer, and the apparent limits of SLA \u2013 and finally offer a broader perspective on the model: its scope, its relations to other approaches, and its possible limits.",
            "referenceCount": 177,
            "citationCount": 136,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2004-04-01",
            "journal": {
                "name": "Bilingualism: Language and Cognition",
                "volume": "7"
            },
            "citationStyles": {
                "bibtex": "@Article{Truscott2004AcquisitionBP,\n author = {J. Truscott and M. Smith},\n booktitle = {Bilingualism: Language and Cognition},\n journal = {Bilingualism: Language and Cognition},\n pages = {1 - 20},\n title = {Acquisition by processing: A modular perspective on language development},\n volume = {7},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4e23321871d5ad2dbbddd4f34a4b7eda870f9ee1",
            "@type": "ScholarlyArticle",
            "paperId": "4e23321871d5ad2dbbddd4f34a4b7eda870f9ee1",
            "corpusId": 15991743,
            "url": "https://www.semanticscholar.org/paper/4e23321871d5ad2dbbddd4f34a4b7eda870f9ee1",
            "title": "Formulaic Language in Native and Second Language Speakers: Psycholinguistics, Corpus Linguistics, and TESOL",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2008,
            "externalIds": {
                "MAG": "1848318613",
                "DOI": "10.1002/J.1545-7249.2008.TB00137.X",
                "CorpusId": 15991743
            },
            "abstract": "Natural language makes considerable use of recurrent formulaic patterns of words. This article triangulates the construct of formula from corpus linguistic, psycholinguistic, and educational perspectives. It describes the corpus linguistic extraction of pedagogically useful formulaic sequences for academic speech and writing. It determines English as a second language (ESL) and English for academic purposes (EAP) instructors' evaluations of their pedagogical importance. It summarizes three experiments which show that different aspects of formulaicity affect the accuracy and fluency of processing of these formulas in native speakers and in advanced L2 learners of English. The language processing tasks were selected to sample an ecologically valid range of language processing skills: spoken and written, production and comprehension. Processing in all experiments was affected by various corpus-derived metrics: length, frequency, and mutual information (MI), but to different degrees in the different populations. For native speakers, it is predominantly the MI of the formula which determines processability; for nonnative learners of the language, it is predominantly the frequency of the formula. The implications of these findings are discussed for (a) the psycholinguistic validity of corpus-derived formulas, (b) a model of their acquisition, (c) ESL and EAP instruction and the prioritization of which formulas to teach.",
            "referenceCount": 81,
            "citationCount": 495,
            "influentialCitationCount": 29,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://deepblue.lib.umich.edu/bitstream/2027.42/89473/1/j.1545-7249.2008.tb00137.x.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2008-09-01",
            "journal": {
                "name": "TESOL Quarterly",
                "volume": "42"
            },
            "citationStyles": {
                "bibtex": "@Article{Ellis2008FormulaicLI,\n author = {N. Ellis and Rita Simpson-Vlach and C. Maynard},\n journal = {TESOL Quarterly},\n pages = {375-396},\n title = {Formulaic Language in Native and Second Language Speakers: Psycholinguistics, Corpus Linguistics, and TESOL},\n volume = {42},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7441116c5b5a745708a9d7c5aa0ecf04e0c76c93",
            "@type": "ScholarlyArticle",
            "paperId": "7441116c5b5a745708a9d7c5aa0ecf04e0c76c93",
            "corpusId": 7747235,
            "url": "https://www.semanticscholar.org/paper/7441116c5b5a745708a9d7c5aa0ecf04e0c76c93",
            "title": "Dependency-Based Construction of Semantic Space Models",
            "venue": "International Conference on Computational Logic",
            "publicationVenue": {
                "id": "urn:research:30a8645d-22d4-42e2-b3f6-304bf4ce3a02",
                "name": "International Conference on Computational Logic",
                "alternate_names": [
                    "CL",
                    "Int Conf Comput Log"
                ],
                "issn": null,
                "url": null
            },
            "year": 2007,
            "externalIds": {
                "ACL": "J07-2002",
                "MAG": "2005181355",
                "DBLP": "journals/coling/PadoL07",
                "DOI": "10.1162/coli.2007.33.2.161",
                "CorpusId": 7747235
            },
            "abstract": "Traditionally, vector-based semantic space models use word co-occurrence counts from large corpora to represent lexical meaning. In this article we present a novel framework for constructing semantic spaces that takes syntactic relations into account. We introduce a formalization for this class of models, which allows linguistic knowledge to guide the construction process. We evaluate our framework on a range of tasks relevant for cognitive science and natural language processing: semantic priming, synonymy detection, and word sense disambiguation. In all cases, our framework obtains results that are comparable or superior to the state of the art.",
            "referenceCount": 90,
            "citationCount": 716,
            "influentialCitationCount": 55,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://direct.mit.edu/coli/article-pdf/33/2/161/1798388/coli.2007.33.2.161.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2007-06-01",
            "journal": {
                "name": "Computational Linguistics",
                "volume": "33"
            },
            "citationStyles": {
                "bibtex": "@Article{Pad\u00f32007DependencyBasedCO,\n author = {Sebastian Pad\u00f3 and Mirella Lapata},\n booktitle = {International Conference on Computational Logic},\n journal = {Computational Linguistics},\n pages = {161-199},\n title = {Dependency-Based Construction of Semantic Space Models},\n volume = {33},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c0927ffb79810318daab8821068629975cab67ad",
            "@type": "ScholarlyArticle",
            "paperId": "c0927ffb79810318daab8821068629975cab67ad",
            "corpusId": 9413935,
            "url": "https://www.semanticscholar.org/paper/c0927ffb79810318daab8821068629975cab67ad",
            "title": "Deep Learning for Classification of Malware System Call Sequences",
            "venue": "Australasian Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/ausai/KolosnjajiZWE16",
                "MAG": "2557513839",
                "DOI": "10.1007/978-3-319-50127-7_11",
                "CorpusId": 9413935
            },
            "abstract": null,
            "referenceCount": 37,
            "citationCount": 425,
            "influentialCitationCount": 18,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-12-05",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Kolosnjaji2016DeepLF,\n author = {Bojan Kolosnjaji and Apostolis Zarras and George D. Webster and C. Eckert},\n booktitle = {Australasian Conference on Artificial Intelligence},\n pages = {137-149},\n title = {Deep Learning for Classification of Malware System Call Sequences},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:00cc08c90bc4ae7d3523e4dad2ca3a8fafc8501a",
            "@type": "ScholarlyArticle",
            "paperId": "00cc08c90bc4ae7d3523e4dad2ca3a8fafc8501a",
            "corpusId": 15026764,
            "url": "https://www.semanticscholar.org/paper/00cc08c90bc4ae7d3523e4dad2ca3a8fafc8501a",
            "title": "Embeddings for Word Sense Disambiguation: An Evaluation Study",
            "venue": "Annual Meeting of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                "name": "Annual Meeting of the Association for Computational Linguistics",
                "alternate_names": [
                    "Annu Meet Assoc Comput Linguistics",
                    "Meeting of the Association for Computational Linguistics",
                    "ACL",
                    "Meet Assoc Comput Linguistics"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/acl/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/acl/IacobacciPN16",
                "MAG": "2518202280",
                "ACL": "P16-1085",
                "DOI": "10.18653/v1/P16-1085",
                "CorpusId": 15026764
            },
            "abstract": "Recent years have seen a dramatic growth in the popularity of word embeddings mainly owing to their ability to capture semantic information from massive amounts of textual content. As a result, many tasks in Natural Language Processing have tried to take advantage of the potential of these distributional models. In this work, we study how word embeddings can be used in Word Sense Disambiguation, one of the oldest tasks in Natural Language Processing and Artificial Intelligence. We propose different methods through which word embeddings can be leveraged in a state-of-the-art supervised WSD system architecture, and perform a deep analysis of how different parameters affect performance. We show how a WSD system that makes use of word embeddings alone, if designed properly, can provide significant performance improvement over a state-ofthe-art WSD system that incorporates several standard WSD features.",
            "referenceCount": 55,
            "citationCount": 272,
            "influentialCitationCount": 39,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aclweb.org/anthology/P16-1085.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-08-01",
            "journal": {
                "name": "",
                "volume": "1"
            },
            "citationStyles": {
                "bibtex": "@Article{Iacobacci2016EmbeddingsFW,\n author = {Ignacio Iacobacci and Mohammad Taher Pilehvar and Roberto Navigli},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {897-907},\n title = {Embeddings for Word Sense Disambiguation: An Evaluation Study},\n volume = {1},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e703e928bc07900527c368db2428d0d5c57148c2",
            "@type": "ScholarlyArticle",
            "paperId": "e703e928bc07900527c368db2428d0d5c57148c2",
            "corpusId": 1854720,
            "url": "https://www.semanticscholar.org/paper/e703e928bc07900527c368db2428d0d5c57148c2",
            "title": "Learning Syntactic Patterns for Automatic Hypernym Discovery",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2004,
            "externalIds": {
                "MAG": "2142086811",
                "DBLP": "conf/nips/SnowJN04",
                "CorpusId": 1854720
            },
            "abstract": "Semantic taxonomies such as WordNet provide a rich source of knowledge for natural language processing applications, but are expensive to build, maintain, and extend. Motivated by the problem of automatically constructing and extending such taxonomies, in this paper we present a new algorithm for automatically learning hypernym (is-a) relations from text. Our method generalizes earlier work that had relied on using small numbers of hand-crafted regular expression patterns to identify hypernym pairs. Using \"dependency path\" features extracted from parse trees, we introduce a general-purpose formalization and generalization of these patterns. Given a training set of text containing known hypernym pairs, our algorithm automatically extracts useful dependency paths and applies them to new corpora to identify novel pairs. On our evaluation task (determining whether two nouns in a news article participate in a hypernym relationship), our automatically extracted database of hypernyms attains both higher precision and higher recall than WordNet.",
            "referenceCount": 23,
            "citationCount": 811,
            "influentialCitationCount": 79,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2004-12-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Snow2004LearningSP,\n author = {R. Snow and Dan Jurafsky and A. Ng},\n booktitle = {Neural Information Processing Systems},\n pages = {1297-1304},\n title = {Learning Syntactic Patterns for Automatic Hypernym Discovery},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:343e06bae852f74a98573e798b501f6003bcb1c0",
            "@type": "ScholarlyArticle",
            "paperId": "343e06bae852f74a98573e798b501f6003bcb1c0",
            "corpusId": 225068329,
            "url": "https://www.semanticscholar.org/paper/343e06bae852f74a98573e798b501f6003bcb1c0",
            "title": "Measuring Association Between Labels and Free-Text Rationales",
            "venue": "Conference on Empirical Methods in Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:41bf9ed3-85b3-4c90-b015-150e31690253",
                "name": "Conference on Empirical Methods in Natural Language Processing",
                "alternate_names": [
                    "Empir Method Nat Lang Process",
                    "Empirical Methods in Natural Language Processing",
                    "Conf Empir Method Nat Lang Process",
                    "EMNLP"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/emnlp"
            },
            "year": 2020,
            "externalIds": {
                "ACL": "2021.emnlp-main.804",
                "ArXiv": "2010.12762",
                "DBLP": "journals/corr/abs-2010-12762",
                "MAG": "3093530468",
                "DOI": "10.18653/v1/2021.emnlp-main.804",
                "CorpusId": 225068329
            },
            "abstract": "In interpretable NLP, we require faithful rationales that reflect the model\u2019s decision-making process for an explained instance. While prior work focuses on extractive rationales (a subset of the input words), we investigate their less-studied counterpart: free-text natural language rationales. We demonstrate that *pipelines*, models for faithful rationalization on information-extraction style tasks, do not work as well on \u201creasoning\u201d tasks requiring free-text rationales. We turn to models that *jointly* predict and rationalize, a class of widely used high-performance models for free-text rationalization. We investigate the extent to which the labels and rationales predicted by these models are associated, a necessary property of faithful explanation. Via two tests, *robustness equivalence* and *feature importance agreement*, we find that state-of-the-art T5-based joint models exhibit desirable properties for explaining commonsense question-answering and natural language inference, indicating their potential for producing faithful free-text rationales.",
            "referenceCount": 87,
            "citationCount": 111,
            "influentialCitationCount": 17,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://aclanthology.org/2021.emnlp-main.804.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2020-10-24",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wiegreffe2020MeasuringAB,\n author = {Sarah Wiegreffe and Ana Marasovi\u0107 and Noah A. Smith},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {10266-10284},\n title = {Measuring Association Between Labels and Free-Text Rationales},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b91c4edd30b63cd1cb1b86cbeefb33a461535e09",
            "@type": "ScholarlyArticle",
            "paperId": "b91c4edd30b63cd1cb1b86cbeefb33a461535e09",
            "corpusId": 201070022,
            "url": "https://www.semanticscholar.org/paper/b91c4edd30b63cd1cb1b86cbeefb33a461535e09",
            "title": "Build it Break it Fix it for Dialogue Safety: Robustness from Adversarial Human Attack",
            "venue": "Conference on Empirical Methods in Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:41bf9ed3-85b3-4c90-b015-150e31690253",
                "name": "Conference on Empirical Methods in Natural Language Processing",
                "alternate_names": [
                    "Empir Method Nat Lang Process",
                    "Empirical Methods in Natural Language Processing",
                    "Conf Empir Method Nat Lang Process",
                    "EMNLP"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/emnlp"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2971173235",
                "DBLP": "journals/corr/abs-1908-06083",
                "ArXiv": "1908.06083",
                "ACL": "D19-1461",
                "DOI": "10.18653/v1/D19-1461",
                "CorpusId": 201070022
            },
            "abstract": "The detection of offensive language in the context of a dialogue has become an increasingly important application of natural language processing. The detection of trolls in public forums (Gal\u00e1n-Garc\u00eda et al., 2016), and the deployment of chatbots in the public domain (Wolf et al., 2017) are two examples that show the necessity of guarding against adversarially offensive behavior on the part of humans. In this work, we develop a training scheme for a model to become robust to such human attacks by an iterative build it, break it, fix it scheme with humans and models in the loop. In detailed experiments we show this approach is considerably more robust than previous systems. Further, we show that offensive language used within a conversation critically depends on the dialogue context, and cannot be viewed as a single sentence offensive detection task as in most previous work. Our newly collected tasks and methods are all made open source and publicly available.",
            "referenceCount": 35,
            "citationCount": 175,
            "influentialCitationCount": 27,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aclweb.org/anthology/D19-1461.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-08-17",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1908.06083"
            },
            "citationStyles": {
                "bibtex": "@Article{Dinan2019BuildIB,\n author = {Emily Dinan and Samuel Humeau and Bharath Chintagunta and J. Weston},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {Build it Break it Fix it for Dialogue Safety: Robustness from Adversarial Human Attack},\n volume = {abs/1908.06083},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fd4dbe9c9252b7ac63f51baa3f23da0e98f157f3",
            "@type": "ScholarlyArticle",
            "paperId": "fd4dbe9c9252b7ac63f51baa3f23da0e98f157f3",
            "corpusId": 23018795,
            "url": "https://www.semanticscholar.org/paper/fd4dbe9c9252b7ac63f51baa3f23da0e98f157f3",
            "title": "Cohort profile of the South London and Maudsley NHS Foundation Trust Biomedical Research Centre (SLaM BRC) Case Register: current status and recent enhancement of an Electronic Mental Health Record-derived data resource",
            "venue": "BMJ Open",
            "publicationVenue": {
                "id": "urn:research:e6216b43-2428-4aaf-8101-b40e1dfd2810",
                "name": "BMJ Open",
                "alternate_names": null,
                "issn": "2044-6055",
                "url": "https://bmjopen.bmj.com/"
            },
            "year": 2016,
            "externalIds": {
                "PubMedCentral": "4785292",
                "MAG": "2290646566",
                "DOI": "10.1136/bmjopen-2015-008721",
                "CorpusId": 23018795,
                "PubMed": "26932138"
            },
            "abstract": "Purpose The South London and Maudsley National Health Service (NHS) Foundation Trust Biomedical Research Centre (SLaM BRC) Case Register and its Clinical Record Interactive Search (CRIS) application were developed in 2008, generating a research repository of real-time, anonymised, structured and open-text data derived from the electronic health record system used by SLaM, a large mental healthcare provider in southeast London. In this paper, we update this register's descriptive data, and describe the substantial expansion and extension of the data resource since its original development. Participants Descriptive data were generated from the SLaM BRC Case Register on 31 December 2014. Currently, there are over 250\u2005000 patient records accessed through CRIS. Findings to date Since 2008, the most significant developments in the SLaM BRC Case Register have been the introduction of natural language processing to extract structured data from open-text fields, linkages to external sources of data, and the addition of a parallel relational database (Structured Query Language) output. Natural language processing applications to date have brought in new and hitherto inaccessible data on cognitive function, education, social care receipt, smoking, diagnostic statements and pharmacotherapy. In addition, through external data linkages, large volumes of supplementary information have been accessed on mortality, hospital attendances and cancer registrations. Future plans Coupled with robust data security and governance structures, electronic health records provide potentially transformative information on mental disorders and outcomes in routine clinical care. The SLaM BRC Case Register continues to grow as a database, with approximately 20\u2005000 new cases added each year, in addition to extension of follow-up for existing cases. Data linkages and natural language processing present important opportunities to enhance this type of research resource further, achieving both volume and depth of data. However, research projects still need to be carefully tailored, so that they take into account the nature and quality of the source information.",
            "referenceCount": 88,
            "citationCount": 398,
            "influentialCitationCount": 12,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://bmjopen.bmj.com/content/bmjopen/6/3/e008721.full.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-03-01",
            "journal": {
                "name": "BMJ Open",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Perera2016CohortPO,\n author = {G. Perera and M. Broadbent and F. Callard and Chin-Kuo Chang and J. Downs and R. Dutta and A. Fernandes and R. Hayes and M. Henderson and R. Jackson and A. Jewell and G. Kadra and Ryan Little and M. Pritchard and H. Shetty and A. Tulloch and R. Stewart},\n booktitle = {BMJ Open},\n journal = {BMJ Open},\n title = {Cohort profile of the South London and Maudsley NHS Foundation Trust Biomedical Research Centre (SLaM BRC) Case Register: current status and recent enhancement of an Electronic Mental Health Record-derived data resource},\n volume = {6},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0f2381ed901cae839f3a873ac36de5a2b8e4fa1d",
            "@type": "ScholarlyArticle",
            "paperId": "0f2381ed901cae839f3a873ac36de5a2b8e4fa1d",
            "corpusId": 3427175,
            "url": "https://www.semanticscholar.org/paper/0f2381ed901cae839f3a873ac36de5a2b8e4fa1d",
            "title": "Sentiment Analysis Is a Big Suitcase",
            "venue": "IEEE Intelligent Systems",
            "publicationVenue": {
                "id": "urn:research:7404efea-88b2-4c7c-8cb1-b3a8ced6363f",
                "name": "IEEE Intelligent Systems",
                "alternate_names": [
                    "IEEE Intell Syst"
                ],
                "issn": "1541-1672",
                "url": "https://ieeexplore.ieee.org/servlet/opac?punumber=9670"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2786411768",
                "DBLP": "journals/expert/CambriaPGT17",
                "DOI": "10.1109/MIS.2017.4531228",
                "CorpusId": 3427175
            },
            "abstract": "Although most works approach it as a simple categorization problem, sentiment analysis is actually a suitcase research problem that requires tackling many natural language processing (NLP) tasks. The expression \u201csentiment analysis\u201d itself is a big suitcase (like many others related to affective computing, such as emotion recognition or opinion mining) that all of us use to encapsulate our jumbled idea about how our minds convey emotions and opinions through natural language. The authors address the composite nature of the problem via a three-layer structure inspired by the \u201cjumping NLP curves\u201d paradigm. In particular, they argue that there are (at least) 15 NLP problems that need to be solved to achieve human-like performance in sentiment analysis.",
            "referenceCount": 22,
            "citationCount": 332,
            "influentialCitationCount": 10,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-11-01",
            "journal": {
                "name": "IEEE Intelligent Systems",
                "volume": "32"
            },
            "citationStyles": {
                "bibtex": "@Article{Cambria2017SentimentAI,\n author = {E. Cambria and Soujanya Poria and Alexander Gelbukh and M. Thelwall},\n booktitle = {IEEE Intelligent Systems},\n journal = {IEEE Intelligent Systems},\n pages = {74-80},\n title = {Sentiment Analysis Is a Big Suitcase},\n volume = {32},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c7c30eeb02519ed682d3838a50b2e1048d7d7802",
            "@type": "ScholarlyArticle",
            "paperId": "c7c30eeb02519ed682d3838a50b2e1048d7d7802",
            "corpusId": 56939427,
            "url": "https://www.semanticscholar.org/paper/c7c30eeb02519ed682d3838a50b2e1048d7d7802",
            "title": "Book Reviews: An Introduction to Corpus Linguistics",
            "venue": "International Conference on Computational Logic",
            "publicationVenue": {
                "id": "urn:research:30a8645d-22d4-42e2-b3f6-304bf4ce3a02",
                "name": "International Conference on Computational Logic",
                "alternate_names": [
                    "CL",
                    "Int Conf Comput Log"
                ],
                "issn": null,
                "url": null
            },
            "year": 1999,
            "externalIds": {
                "ACL": "J99-2010",
                "CorpusId": 56939427
            },
            "abstract": "This timely book joins the growing number of leading introductory volumes on corpus linguistics, including McEnery and Wilson (1996) and Biber, Conrad, and Reppen (1998). The former volume represents the first-ever introductory textbook on corpus linguistics; the latter, also recently published, is strong on reporting many of the authors' own analyses of speech and writing and providing \"methodology boxes\" for the computer processing of text using the corpus-based paradigm. Space constraints do not permit the comparison of all three volumes, especially in relation to the use of the corpus-based approach for natural language processing. In the present instance, it is to his credit that Graeme Kennedy has single-handedly achieved the difficult task of systematically providing an historical overview and evaluating the significance of many important studies that currently define the corpus-based approach. The book is organized as follows:",
            "referenceCount": 3,
            "citationCount": 816,
            "influentialCitationCount": 56,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Ooi1999BookRA,\n author = {Vincent B.Y. Ooi},\n booktitle = {International Conference on Computational Logic},\n title = {Book Reviews: An Introduction to Corpus Linguistics},\n year = {1999}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:14c146d457bbd201f3a117ee9c848300d341e5d0",
            "@type": "ScholarlyArticle",
            "paperId": "14c146d457bbd201f3a117ee9c848300d341e5d0",
            "corpusId": 6534839,
            "url": "https://www.semanticscholar.org/paper/14c146d457bbd201f3a117ee9c848300d341e5d0",
            "title": "The CoNLL 2008 Shared Task on Joint Parsing of Syntactic and Semantic Dependencies",
            "venue": "Conference on Computational Natural Language Learning",
            "publicationVenue": {
                "id": "urn:research:3779a5a7-9119-4f69-84fe-f7eef193eb49",
                "name": "Conference on Computational Natural Language Learning",
                "alternate_names": [
                    "CoNLL",
                    "Conf Comput Nat Lang Learn"
                ],
                "issn": null,
                "url": null
            },
            "year": 2008,
            "externalIds": {
                "ACL": "W08-2121",
                "MAG": "1970849810",
                "DBLP": "conf/conll/SurdeanuJMMN08",
                "DOI": "10.3115/1596324.1596352",
                "CorpusId": 6534839
            },
            "abstract": "The Conference on Computational Natural Language Learning is accompanied every year by a shared task whose purpose is to promote natural language processing applications and evaluate them in a standard setting. In 2008 the shared task was dedicated to the joint parsing of syntactic and semantic dependencies. This shared task not only unifies the shared tasks of the previous four years under a unique dependency-based formalism, but also extends them significantly: this year's syntactic dependencies include more information such as named-entity boundaries; the semantic dependencies model roles of both verbal and nominal predicates. In this paper, we define the shared task and describe how the data sets were created. Furthermore, we report and analyze the results and describe the approaches of the participating systems.",
            "referenceCount": 41,
            "citationCount": 552,
            "influentialCitationCount": 73,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.5555/1596324.1596352",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2008-08-16",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Surdeanu2008TheC2,\n author = {M. Surdeanu and Richard Johansson and Adam Meyers and Llu\u00eds M\u00e0rquez i Villodre and Joakim Nivre},\n booktitle = {Conference on Computational Natural Language Learning},\n pages = {159-177},\n title = {The CoNLL 2008 Shared Task on Joint Parsing of Syntactic and Semantic Dependencies},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8626531209284ba1eaba9e41422ef45337d88f01",
            "@type": "ScholarlyArticle",
            "paperId": "8626531209284ba1eaba9e41422ef45337d88f01",
            "corpusId": 138716,
            "url": "https://www.semanticscholar.org/paper/8626531209284ba1eaba9e41422ef45337d88f01",
            "title": "A Deeper Look into Sarcastic Tweets Using Deep Convolutional Neural Networks",
            "venue": "International Conference on Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:f51ff783-cdff-4e22-94fb-28e6336d17b3",
                "name": "International Conference on Computational Linguistics",
                "alternate_names": [
                    "Int Conf Comput Linguistics",
                    "COLING"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/coling/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/PoriaCHV16",
                "MAG": "2950695998",
                "ArXiv": "1610.08815",
                "ACL": "C16-1151",
                "CorpusId": 138716
            },
            "abstract": "Sarcasm detection is a key task for many natural language processing tasks. In sentiment analysis, for example, sarcasm can flip the polarity of an \u201capparently positive\u201d sentence and, hence, negatively affect polarity detection performance. To date, most approaches to sarcasm detection have treated the task primarily as a text categorization problem. Sarcasm, however, can be expressed in very subtle ways and requires a deeper understanding of natural language that standard text categorization techniques cannot grasp. In this work, we develop models based on a pre-trained convolutional neural network for extracting sentiment, emotion and personality features for sarcasm detection. Such features, along with the network\u2019s baseline features, allow the proposed models to outperform the state of the art on benchmark datasets. We also address the often ignored generalizability issue of classifying data that have not been seen by the models at learning phase.",
            "referenceCount": 41,
            "citationCount": 292,
            "influentialCitationCount": 22,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-10-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Poria2016ADL,\n author = {Soujanya Poria and E. Cambria and Devamanyu Hazarika and Prateek Vij},\n booktitle = {International Conference on Computational Linguistics},\n pages = {1601-1612},\n title = {A Deeper Look into Sarcastic Tweets Using Deep Convolutional Neural Networks},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:39084fb5e7f083aa07b21271fe66322ef940d048",
            "@type": "ScholarlyArticle",
            "paperId": "39084fb5e7f083aa07b21271fe66322ef940d048",
            "corpusId": 118054511,
            "url": "https://www.semanticscholar.org/paper/39084fb5e7f083aa07b21271fe66322ef940d048",
            "title": "Handbook of Weighted Automata",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2009,
            "externalIds": {
                "MAG": "1643571618",
                "DOI": "10.1007/978-3-642-01492-5",
                "CorpusId": 118054511
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 598,
            "influentialCitationCount": 27,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://swbplus.bsz-bw.de/bsz30826343xkap.htm",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2009-09-24",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Droste2009HandbookOW,\n author = {M. Droste and W. Kuich and H. Vogler},\n title = {Handbook of Weighted Automata},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d3cf28ab36ff7f7601a55c1e832736b2473a07f0",
            "@type": "ScholarlyArticle",
            "paperId": "d3cf28ab36ff7f7601a55c1e832736b2473a07f0",
            "corpusId": 7819391,
            "url": "https://www.semanticscholar.org/paper/d3cf28ab36ff7f7601a55c1e832736b2473a07f0",
            "title": "Representing word meaning and order information in a composite holographic lexicon.",
            "venue": "Psychology Review",
            "publicationVenue": {
                "id": "urn:research:dfb7f114-609c-4c34-9ee7-8cb1fc3e4a6b",
                "name": "Psychology Review",
                "alternate_names": [
                    "Psychol rev",
                    "Psychological review",
                    "Psychol Rev",
                    "Psychological Review"
                ],
                "issn": "1354-1129",
                "url": "http://www.apa.org/journals/rev/"
            },
            "year": 2007,
            "externalIds": {
                "MAG": "1986707196",
                "DOI": "10.1037/0033-295X.114.1.1",
                "CorpusId": 7819391,
                "PubMed": "17227180"
            },
            "abstract": "The authors present a computational model that builds a holographic lexicon representing both word meaning and word order from unsupervised experience with natural language. The model uses simple convolution and superposition mechanisms (cf. B. B. Murdock, 1982) to learn distributed holographic representations for words. The structure of the resulting lexicon can account for empirical data from classic experiments studying semantic typicality, categorization, priming, and semantic constraint in sentence completions. Furthermore, order information can be retrieved from the holographic representations, allowing the model to account for limited word transitions without the need for built-in transition rules. The model demonstrates that a broad range of psychological data can be accounted for directly from the structure of lexical representations learned in this way, without the need for complexity to be built into either the processing mechanisms or the representations. The holographic representations are an appropriate knowledge representation to be used by higher order models of language comprehension, relieving the complexity required at the higher level.",
            "referenceCount": 149,
            "citationCount": 609,
            "influentialCitationCount": 65,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Psychological review",
                "volume": "114 1"
            },
            "citationStyles": {
                "bibtex": "@Article{Jones2007RepresentingWM,\n author = {Michael N. Jones and D. Mewhort},\n booktitle = {Psychology Review},\n journal = {Psychological review},\n pages = {\n          1-37\n        },\n title = {Representing word meaning and order information in a composite holographic lexicon.},\n volume = {114 1},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1c252bc2434f55ac4e0f31f4a055748b444712b3",
            "@type": "ScholarlyArticle",
            "paperId": "1c252bc2434f55ac4e0f31f4a055748b444712b3",
            "corpusId": 1770055,
            "url": "https://www.semanticscholar.org/paper/1c252bc2434f55ac4e0f31f4a055748b444712b3",
            "title": "Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures",
            "venue": "Journal of Artificial Intelligence Research",
            "publicationVenue": {
                "id": "urn:research:aef12dca-60a0-4ca3-819b-cad26d309d4e",
                "name": "Journal of Artificial Intelligence Research",
                "alternate_names": [
                    "JAIR",
                    "J Artif Intell Res",
                    "The Journal of Artificial Intelligence Research"
                ],
                "issn": "1076-9757",
                "url": "http://www.jair.org/"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/BernardiCEEEIKM16",
                "ArXiv": "1601.03896",
                "MAG": "2951674897",
                "DOI": "10.1613/jair.4900",
                "CorpusId": 1770055
            },
            "abstract": "Automatic description generation from natural images is a challenging problem that has recently received a large amount of interest from the computer vision and natural language processing communities. In this survey, we classify the existing approaches based on how they conceptualize this problem, viz., models that cast description as either generation problem or as a retrieval problem over a visual or multimodal representational space. We provide a detailed review of existing models, highlighting their advantages and disadvantages. Moreover, we give an overview of the benchmark image datasets and the evaluation measures that have been developed to assess the quality of machine-generated image descriptions. Finally we extrapolate future directions in the area of automatic image description generation.",
            "referenceCount": 129,
            "citationCount": 332,
            "influentialCitationCount": 14,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://jair.org/index.php/jair/article/download/10985/26134",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2016-01-15",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1601.03896"
            },
            "citationStyles": {
                "bibtex": "@Article{Bernardi2016AutomaticDG,\n author = {R. Bernardi and Ruken Cakici and Desmond Elliott and Aykut Erdem and Erkut Erdem and Nazli Ikizler-Cinbis and Frank Keller and A. Muscat and Barbara Plank},\n booktitle = {Journal of Artificial Intelligence Research},\n journal = {ArXiv},\n title = {Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures},\n volume = {abs/1601.03896},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:41c8cabe475d85d7548c25935da19ea5b96dfe06",
            "@type": "ScholarlyArticle",
            "paperId": "41c8cabe475d85d7548c25935da19ea5b96dfe06",
            "corpusId": 49314097,
            "url": "https://www.semanticscholar.org/paper/41c8cabe475d85d7548c25935da19ea5b96dfe06",
            "title": "Neural Code Comprehension: A Learnable Representation of Code Semantics",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "conf/nips/Ben-NunJH18",
                "MAG": "2952389078",
                "ArXiv": "1806.07336",
                "CorpusId": 49314097
            },
            "abstract": "With the recent success of embeddings in natural language processing, research has been conducted into applying similar methods to code analysis. Most works attempt to process the code directly or use a syntactic tree representation, treating it like sentences written in a natural language. However, none of the existing methods are sufficient to comprehend program semantics robustly, due to structural features such as function calls, branching, and interchangeable order of statements. In this paper, we propose a novel processing technique to learn code semantics, and apply it to a variety of program analysis tasks. In particular, we stipulate that a robust distributional hypothesis of code applies to both human- and machine-generated programs. Following this hypothesis, we define an embedding space, inst2vec, based on an Intermediate Representation (IR) of the code that is independent of the source programming language. We provide a novel definition of contextual flow for this IR, leveraging both the underlying data- and control-flow of the program. We then analyze the embeddings qualitatively using analogies and clustering, and evaluate the learned representation on three different high-level tasks. We show that even without fine-tuning, a single RNN architecture and fixed inst2vec embeddings outperform specialized approaches for performance prediction (compute device mapping, optimal thread coarsening); and algorithm classification from raw code (104 classes), where we set a new state-of-the-art.",
            "referenceCount": 63,
            "citationCount": 201,
            "influentialCitationCount": 37,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-06-01",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1806.07336"
            },
            "citationStyles": {
                "bibtex": "@Article{Ben-Nun2018NeuralCC,\n author = {Tal Ben-Nun and Alice Shoshana Jakobovits and T. Hoefler},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Neural Code Comprehension: A Learnable Representation of Code Semantics},\n volume = {abs/1806.07336},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:996e591bbeab149a8f624a89048c7a10be8322d6",
            "@type": "ScholarlyArticle",
            "paperId": "996e591bbeab149a8f624a89048c7a10be8322d6",
            "corpusId": 28114065,
            "url": "https://www.semanticscholar.org/paper/996e591bbeab149a8f624a89048c7a10be8322d6",
            "title": "Ontology learning and population from text - algorithms, evaluation and applications",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2006,
            "externalIds": {
                "DBLP": "books/daglib/0017553",
                "MAG": "1509392121",
                "CorpusId": 28114065
            },
            "abstract": "In the last decade, ontologies have received much attention within computer science and related disciplines, most often as the semantic web. Ontology Learning and Population from Text: Algorithms, Evaluation and Applications discusses ontologies for the semantic web, as well as knowledge management, information retrieval, text clustering and classification, as well as natural language processing. Ontology Learning and Population from Text: Algorithms, Evaluation and Applications is structured for research scientists and practitioners in industry. This book is also suitable for graduate-level students in computer science.",
            "referenceCount": 0,
            "citationCount": 603,
            "influentialCitationCount": 60,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2006-10-12",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Cimiano2006OntologyLA,\n author = {P. Cimiano},\n pages = {I-XXVIII, 1-347},\n title = {Ontology learning and population from text - algorithms, evaluation and applications},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:878783964ab23c97052ea82685368099d85c500d",
            "@type": "ScholarlyArticle",
            "paperId": "878783964ab23c97052ea82685368099d85c500d",
            "corpusId": 6249194,
            "url": "https://www.semanticscholar.org/paper/878783964ab23c97052ea82685368099d85c500d",
            "title": "A Comparison of Algorithms for Maximum Entropy Parameter Estimation",
            "venue": "Conference on Computational Natural Language Learning",
            "publicationVenue": {
                "id": "urn:research:3779a5a7-9119-4f69-84fe-f7eef193eb49",
                "name": "Conference on Computational Natural Language Learning",
                "alternate_names": [
                    "CoNLL",
                    "Conf Comput Nat Lang Learn"
                ],
                "issn": null,
                "url": null
            },
            "year": 2002,
            "externalIds": {
                "MAG": "2102667697",
                "ACL": "W02-2018",
                "DBLP": "conf/conll/Malouf02",
                "DOI": "10.3115/1118853.1118871",
                "CorpusId": 6249194
            },
            "abstract": "Conditional maximum entropy (ME) models provide a general purpose machine learning technique which has been successfully applied to fields as diverse as computer vision and econometrics, and which is used for a wide variety of classification problems in natural language processing. However, the flexibility of ME models is not without cost. While parameter estimation for ME models is conceptually straightforward, in practice ME models for typical natural language tasks are very large, and may well contain many thousands of free parameters. In this paper, we consider a number of algorithms for estimating the parameters of ME models, including iterative scaling, gradient ascent, conjugate gradient, and variable metric methods. Sur-prisingly, the standardly used iterative scaling algorithms perform quite poorly in comparison to the others, and for all of the test problems, a limited-memory variable metric algorithm outperformed the other choices.",
            "referenceCount": 28,
            "citationCount": 766,
            "influentialCitationCount": 53,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.3115/1118853.1118871",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2002-08-31",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Malouf2002ACO,\n author = {Robert Malouf},\n booktitle = {Conference on Computational Natural Language Learning},\n pages = {1-7},\n title = {A Comparison of Algorithms for Maximum Entropy Parameter Estimation},\n year = {2002}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:20c1909492638f6a5f716673d6fefa796bb5ff8c",
            "@type": "ScholarlyArticle",
            "paperId": "20c1909492638f6a5f716673d6fefa796bb5ff8c",
            "corpusId": 42396450,
            "url": "https://www.semanticscholar.org/paper/20c1909492638f6a5f716673d6fefa796bb5ff8c",
            "title": "Costly Information Processing: Evidence from Earnings Announcements",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2008,
            "externalIds": {
                "MAG": "2126640908",
                "DOI": "10.2139/ssrn.1107998",
                "CorpusId": 42396450
            },
            "abstract": "I examine the role of information processing costs on post earnings announcement drift. I distinguish between hard information - quantitative information that is more easily processed - and soft information which has higher processing costs. I find that qualitative earnings information has additional predictability for asset prices beyond the predictability in quantitative information. I also find that qualitative information has greater predictability for returns at longer horizons, suggesting that frictions in information processing generate price drift. Using a tool from natural language processing called typed dependency parsing, I demonstrate that qualitative information relating to positive fundamentals and future performance is the most difficult information to process.",
            "referenceCount": 65,
            "citationCount": 303,
            "influentialCitationCount": 40,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Economics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Economics",
                    "source": "external"
                },
                {
                    "category": "Economics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2008-01-18",
            "journal": {
                "name": "American Finance Association Meetings (AFA)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Engelberg2008CostlyIP,\n author = {Joseph Engelberg},\n journal = {American Finance Association Meetings (AFA)},\n title = {Costly Information Processing: Evidence from Earnings Announcements},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:12fe040502b47ba9b1f1638b932f1cb907b2d402",
            "@type": "ScholarlyArticle",
            "paperId": "12fe040502b47ba9b1f1638b932f1cb907b2d402",
            "corpusId": 12423826,
            "url": "https://www.semanticscholar.org/paper/12fe040502b47ba9b1f1638b932f1cb907b2d402",
            "title": "Similar neural correlates for language and sequential learning: Evidence from event-related brain potentials",
            "venue": "Language and Cognitive Processes",
            "publicationVenue": {
                "id": "urn:research:b0902944-35ea-4d7b-a15e-c87a511e5767",
                "name": "Language and Cognitive Processes",
                "alternate_names": [
                    "Lang Cogn Process"
                ],
                "issn": "0169-0965",
                "url": "http://www.informaworld.com/1464-0732"
            },
            "year": 2012,
            "externalIds": {
                "MAG": "1988591936",
                "DOI": "10.1080/01690965.2011.606666",
                "CorpusId": 12423826,
                "PubMed": "23678205"
            },
            "abstract": "We used event-related potentials (ERPs) to investigate the time course and distribution of brain activity while adults performed (1) a sequential learning task involving complex structured sequences and (2) a language processing task. The same positive ERP deflection, the P600 effect, typically linked to difficult or ungrammatical syntactic processing, was found for structural incongruencies in both sequential learning as well as natural language and with similar topographical distributions. Additionally, a left anterior negativity (LAN) was observed for language but not for sequential learning. These results are interpreted as an indication that the P600 provides an index of violations and the cost of integration of expectations for upcoming material when processing complex sequential structure. We conclude that the same neural mechanisms may be recruited for both syntactic processing of linguistic stimuli and sequential learning of structured sequence patterns more generally.",
            "referenceCount": 153,
            "citationCount": 100,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc3652480?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2012-02-01",
            "journal": {
                "name": "Language and Cognitive Processes",
                "volume": "27"
            },
            "citationStyles": {
                "bibtex": "@Article{Christiansen2012SimilarNC,\n author = {Morten H. Christiansen and Christopher M. Conway and Luca Onnis},\n booktitle = {Language and Cognitive Processes},\n journal = {Language and Cognitive Processes},\n pages = {231 - 256},\n title = {Similar neural correlates for language and sequential learning: Evidence from event-related brain potentials},\n volume = {27},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:80270172e6c341626458b1daaf0c642e85d205ec",
            "@type": "ScholarlyArticle",
            "paperId": "80270172e6c341626458b1daaf0c642e85d205ec",
            "corpusId": 59316881,
            "url": "https://www.semanticscholar.org/paper/80270172e6c341626458b1daaf0c642e85d205ec",
            "title": "Evaluating word embedding models: methods and experimental results",
            "venue": "APSIPA Transactions on Signal and Information Processing",
            "publicationVenue": {
                "id": "urn:research:d081062e-f8a7-4018-9072-ca99195f38d8",
                "name": "APSIPA Transactions on Signal and Information Processing",
                "alternate_names": [
                    "APSIPA Trans Signal Inf Process"
                ],
                "issn": "2048-7703",
                "url": "https://www.cambridge.org/core/journals/apsipa-transactions-on-signal-and-information-processing"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "3105248300",
                "DBLP": "journals/corr/abs-1901-09785",
                "ArXiv": "1901.09785",
                "DOI": "10.1017/ATSIP.2019.12",
                "CorpusId": 59316881
            },
            "abstract": "Abstract Extensive evaluation on a large number of word embedding models for language processing applications is conducted in this work. First, we introduce popular word embedding models and discuss desired properties of word models and evaluation methods (or evaluators). Then, we categorize evaluators into intrinsic and extrinsic two types. Intrinsic evaluators test the quality of a representation independent of specific natural language processing tasks while extrinsic evaluators use word embeddings as input features to a downstream task and measure changes in performance metrics specific to that task. We report experimental results of intrinsic and extrinsic evaluators on six word embedding models. It is shown that different evaluators focus on different aspects of word models, and some are more correlated with natural language processing tasks. Finally, we adopt correlation analysis to study performance consistency of extrinsic and intrinsic evaluators.",
            "referenceCount": 82,
            "citationCount": 191,
            "influentialCitationCount": 13,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/EDF43F837150B94E71DBB36B28B85E79/S204877031900012Xa.pdf/div-class-title-evaluating-word-embedding-models-methods-and-experimental-results-div.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-01-28",
            "journal": {
                "name": "APSIPA Transactions on Signal and Information Processing",
                "volume": "8"
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2019EvaluatingWE,\n author = {Bin Wang and Angela Wang and Fenxiao Chen and Yun Cheng Wang and C.-C. Jay Kuo},\n booktitle = {APSIPA Transactions on Signal and Information Processing},\n journal = {APSIPA Transactions on Signal and Information Processing},\n title = {Evaluating word embedding models: methods and experimental results},\n volume = {8},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:415efb7b4d9d1e5b64dbaf3fe4229ad462acce71",
            "@type": "ScholarlyArticle",
            "paperId": "415efb7b4d9d1e5b64dbaf3fe4229ad462acce71",
            "corpusId": 207852771,
            "url": "https://www.semanticscholar.org/paper/415efb7b4d9d1e5b64dbaf3fe4229ad462acce71",
            "title": "Multimodal Intelligence: Representation Learning, Information Fusion, and Applications",
            "venue": "IEEE Journal on Selected Topics in Signal Processing",
            "publicationVenue": {
                "id": "urn:research:e93ebb7d-cfa6-4361-8051-3c6dff3eed1f",
                "name": "IEEE Journal on Selected Topics in Signal Processing",
                "alternate_names": [
                    "IEEE J Sel Top Signal Process",
                    "IEEE Journal of Selected Topics in Signal Processing"
                ],
                "issn": "1932-4553",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=4200690"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1911-03977",
                "MAG": "3017276853",
                "ArXiv": "1911.03977",
                "DOI": "10.1109/JSTSP.2020.2987728",
                "CorpusId": 207852771
            },
            "abstract": "Deep learning methods haverevolutionized speech recognition, image recognition, and natural language processing since 2010. Each of these tasks involves a single modality in their input signals. However, many applications in the artificial intelligence field involve multiple modalities. Therefore, it is of broad interest to study the more difficult and complex problem of modeling and learning across multiple modalities. In this paper, we provide a technical review of available models and learning methods for multimodal intelligence. The main focus of this review is the combination of vision and natural language modalities, which has become an important topic in both the computer vision and natural language processing research communities. This review provides a comprehensive analysis of recent works on multimodal deep learning from three perspectives: learning multimodal representations, fusing multimodal signals at various levels, and multimodal applications. Regarding multimodal representation learning, we review the key concepts of embedding, which unify multimodal signals into a single vector space and thereby enable cross-modality signal processing. We also review the properties of many types of embeddings that are constructed and learned for general downstream tasks. Regarding multimodal fusion, this review focuses on special architectures for the integration of representations of unimodal signals for a particular task. Regarding applications, selected areas of a broad interest in the current literature are covered, including image-to-text caption generation, text-to-image generation, and visual question answering. We believe that this review will facilitate future studies in the emerging field of multimodal intelligence for related communities.",
            "referenceCount": 284,
            "citationCount": 197,
            "influentialCitationCount": 8,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1911.03977",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-11-10",
            "journal": {
                "name": "IEEE Journal of Selected Topics in Signal Processing",
                "volume": "14"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2019MultimodalIR,\n author = {Chao Zhang and Zichao Yang and Xiaodong He and L. Deng},\n booktitle = {IEEE Journal on Selected Topics in Signal Processing},\n journal = {IEEE Journal of Selected Topics in Signal Processing},\n pages = {478-493},\n title = {Multimodal Intelligence: Representation Learning, Information Fusion, and Applications},\n volume = {14},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:02809fc23aecf33e3ed95b83d1d03b54fb5c3d0a",
            "@type": "ScholarlyArticle",
            "paperId": "02809fc23aecf33e3ed95b83d1d03b54fb5c3d0a",
            "corpusId": 218516872,
            "url": "https://www.semanticscholar.org/paper/02809fc23aecf33e3ed95b83d1d03b54fb5c3d0a",
            "title": "An Empirical Study of Multi-Task Learning on BERT for Biomedical Text Mining",
            "venue": "Workshop on Biomedical Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:3afb600a-49ad-40aa-858c-081def027584",
                "name": "Workshop on Biomedical Natural Language Processing",
                "alternate_names": [
                    "BioNLP",
                    "Workshop Biomed Nat Lang Process"
                ],
                "issn": null,
                "url": null
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2005-02799",
                "MAG": "3021010716",
                "ACL": "2020.bionlp-1.22",
                "ArXiv": "2005.02799",
                "DOI": "10.18653/v1/2020.bionlp-1.22",
                "CorpusId": 218516872
            },
            "abstract": "Multi-task learning (MTL) has achieved remarkable success in natural language processing applications. In this work, we study a multi-task learning model with multiple decoders on varieties of biomedical and clinical natural language processing tasks such as text similarity, relation extraction, named entity recognition, and text inference. Our empirical results demonstrate that the MTL fine-tuned models outperform state-of-the-art transformer models (e.g., BERT and its variants) by 2.0% and 1.3% in biomedical and clinical domain adaptation, respectively. Pairwise MTL further demonstrates more details about which tasks can improve or decrease others. This is particularly helpful in the context that researchers are in the hassle of choosing a suitable model for new problems. The code and models are publicly available at https://github.com/ncbi-nlp/bluebert.",
            "referenceCount": 47,
            "citationCount": 77,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2005.02799",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-05-06",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Peng2020AnES,\n author = {Yifan Peng and Qingyu Chen and Zhiyong Lu},\n booktitle = {Workshop on Biomedical Natural Language Processing},\n pages = {205-214},\n title = {An Empirical Study of Multi-Task Learning on BERT for Biomedical Text Mining},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bd2fbe5f6c7f26851c004e659a1e38a8f5005d80",
            "@type": "ScholarlyArticle",
            "paperId": "bd2fbe5f6c7f26851c004e659a1e38a8f5005d80",
            "corpusId": 203905846,
            "url": "https://www.semanticscholar.org/paper/bd2fbe5f6c7f26851c004e659a1e38a8f5005d80",
            "title": "Fine-grained Sentiment Classification using BERT",
            "venue": "2019 Artificial Intelligence for Transforming Business and Society (AITB)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2979771119",
                "DBLP": "journals/corr/abs-1910-03474",
                "ArXiv": "1910.03474",
                "DOI": "10.1109/AITB48515.2019.8947435",
                "CorpusId": 203905846
            },
            "abstract": "Sentiment classification is an important process in understanding people's perception towards a product, service, or topic. Many natural language processing models have been proposed to solve the sentiment classification problem. However, most of them have focused on binary sentiment classification. In this paper, we use a promising deep learning model called BERT to solve the fine-grained sentiment classification task. Experiments show that our model outperforms other popular models for this task without sophisticated architecture. We also demonstrate the effectiveness of transfer learning in natural language processing in the process.",
            "referenceCount": 15,
            "citationCount": 152,
            "influentialCitationCount": 12,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1910.03474",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Business",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-10-04",
            "journal": {
                "name": "2019 Artificial Intelligence for Transforming Business and Society (AITB)",
                "volume": "1"
            },
            "citationStyles": {
                "bibtex": "@Article{Munikar2019FinegrainedSC,\n author = {Manish Munikar and Sushil Shakya and Aakash Shrestha},\n booktitle = {2019 Artificial Intelligence for Transforming Business and Society (AITB)},\n journal = {2019 Artificial Intelligence for Transforming Business and Society (AITB)},\n pages = {1-5},\n title = {Fine-grained Sentiment Classification using BERT},\n volume = {1},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2ae9b68fafd226fed7a7702afd0d9227b79745e2",
            "@type": "ScholarlyArticle",
            "paperId": "2ae9b68fafd226fed7a7702afd0d9227b79745e2",
            "corpusId": 1769326,
            "url": "https://www.semanticscholar.org/paper/2ae9b68fafd226fed7a7702afd0d9227b79745e2",
            "title": "Resources for Turkish morphological processing",
            "venue": "Language Resources and Evaluation",
            "publicationVenue": {
                "id": "urn:research:7dda5bd1-752f-45e5-bc7b-09633096916e",
                "name": "Language Resources and Evaluation",
                "alternate_names": [
                    "Lang Resour Evaluation"
                ],
                "issn": "1574-020X",
                "url": "https://link.springer.com/journal/10579"
            },
            "year": 2011,
            "externalIds": {
                "MAG": "2112302671",
                "DBLP": "journals/lre/SakGS11",
                "DOI": "10.1007/s10579-010-9128-6",
                "CorpusId": 1769326
            },
            "abstract": null,
            "referenceCount": 36,
            "citationCount": 63,
            "influentialCitationCount": 8,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.cmpe.boun.edu.tr/~gungort/papers/Resources for Turkish Morphological Processing.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2011-05-01",
            "journal": {
                "name": "Language Resources and Evaluation",
                "volume": "45"
            },
            "citationStyles": {
                "bibtex": "@Article{Sak2011ResourcesFT,\n author = {H. Sak and Tunga G\u00fcng\u00f6r and M. Sara\u00e7lar},\n booktitle = {Language Resources and Evaluation},\n journal = {Language Resources and Evaluation},\n pages = {249-261},\n title = {Resources for Turkish morphological processing},\n volume = {45},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:22616702da06431668022c649a017af9b333c530",
            "@type": "ScholarlyArticle",
            "paperId": "22616702da06431668022c649a017af9b333c530",
            "corpusId": 49320819,
            "url": "https://www.semanticscholar.org/paper/22616702da06431668022c649a017af9b333c530",
            "title": "Automated Fact Checking: Task Formulations, Methods and Future Directions",
            "venue": "International Conference on Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:f51ff783-cdff-4e22-94fb-28e6336d17b3",
                "name": "International Conference on Computational Linguistics",
                "alternate_names": [
                    "Int Conf Comput Linguistics",
                    "COLING"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/coling/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2963567867",
                "ACL": "C18-1283",
                "ArXiv": "1806.07687",
                "DBLP": "journals/corr/abs-1806-07687",
                "CorpusId": 49320819
            },
            "abstract": "The recently increased focus on misinformation has stimulated research in fact checking, the task of assessing the truthfulness of a claim. Research in automating this task has been conducted in a variety of disciplines including natural language processing, machine learning, knowledge representation, databases, and journalism. While there has been substantial progress, relevant papers and articles have been published in research communities that are often unaware of each other and use inconsistent terminology, thus impeding understanding and further progress. In this paper we survey automated fact checking research stemming from natural language processing and related disciplines, unifying the task formulations and methodologies across papers and authors. Furthermore, we highlight the use of evidence as an important distinguishing factor among them cutting across task formulations and methods. We conclude with proposing avenues for future NLP research on automated fact checking.",
            "referenceCount": 74,
            "citationCount": 232,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Law",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": "2018-06-20",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1806.07687"
            },
            "citationStyles": {
                "bibtex": "@Article{Thorne2018AutomatedFC,\n author = {James Thorne and Andreas Vlachos},\n booktitle = {International Conference on Computational Linguistics},\n journal = {ArXiv},\n title = {Automated Fact Checking: Task Formulations, Methods and Future Directions},\n volume = {abs/1806.07687},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b84720c6a517c7db44c2ff54a082e1a98b765eed",
            "@type": "ScholarlyArticle",
            "paperId": "b84720c6a517c7db44c2ff54a082e1a98b765eed",
            "corpusId": 7717201,
            "url": "https://www.semanticscholar.org/paper/b84720c6a517c7db44c2ff54a082e1a98b765eed",
            "title": "A brief survey of web data extraction tools",
            "venue": "SGMD",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2002,
            "externalIds": {
                "MAG": "2005646337",
                "DBLP": "journals/sigmod/LaenderRST02",
                "DOI": "10.1145/565117.565137",
                "CorpusId": 7717201
            },
            "abstract": "In the last few years, several works in the literature have addressed the problem of data extraction from Web pages. The importance of this problem derives from the fact that, once extracted, the data can be handled in a way similar to instances of a traditional database. The approaches proposed in the literature to address the problem of Web data extraction use techniques borrowed from areas such as natural language processing, languages and grammars, machine learning, information retrieval, databases, and ontologies. As a consequence, they present very distinct features and capabilities which make a direct comparison difficult to be done. In this paper, we propose a taxonomy for characterizing Web data extraction fools, briefly survey major Web data extraction tools described in the literature, and provide a qualitative analysis of them. Hopefully, this work will stimulate other studies aimed at a more comprehensive analysis of data extraction approaches and tools for Web data.",
            "referenceCount": 35,
            "citationCount": 795,
            "influentialCitationCount": 26,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2002-06-01",
            "journal": {
                "name": "SIGMOD Rec.",
                "volume": "31"
            },
            "citationStyles": {
                "bibtex": "@Article{Laender2002ABS,\n author = {Alberto H. F. Laender and B. Ribeiro-Neto and A. D. Silva and Juliana S. Teixeira},\n booktitle = {SGMD},\n journal = {SIGMOD Rec.},\n pages = {84-93},\n title = {A brief survey of web data extraction tools},\n volume = {31},\n year = {2002}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ac0f9bd6d00644215515be42d203f59945a41107",
            "@type": "ScholarlyArticle",
            "paperId": "ac0f9bd6d00644215515be42d203f59945a41107",
            "corpusId": 204548602,
            "url": "https://www.semanticscholar.org/paper/ac0f9bd6d00644215515be42d203f59945a41107",
            "title": "Text-mined dataset of inorganic materials synthesis recipes",
            "venue": "Scientific Data",
            "publicationVenue": {
                "id": "urn:research:62924b2a-8fb8-4b93-92c6-735516b49af0",
                "name": "Scientific Data",
                "alternate_names": [
                    "Sci Data"
                ],
                "issn": "2052-4463",
                "url": "http://www.nature.com/sdata/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2980932864",
                "PubMedCentral": "6794279",
                "DOI": "10.1038/s41597-019-0224-1",
                "CorpusId": 204548602,
                "PubMed": "31615989"
            },
            "abstract": null,
            "referenceCount": 48,
            "citationCount": 149,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s41597-019-0224-1.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Materials Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-10-01",
            "journal": {
                "name": "Scientific Data",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Kononova2019TextminedDO,\n author = {O. Kononova and Haoyan Huo and T. He and Ziqin Rong and T. Botari and Wenhao Sun and V. Tshitoyan and G. Ceder},\n booktitle = {Scientific Data},\n journal = {Scientific Data},\n title = {Text-mined dataset of inorganic materials synthesis recipes},\n volume = {6},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7e6d09530490561f1fc4dbfbd82fc4ff456f046c",
            "@type": "ScholarlyArticle",
            "paperId": "7e6d09530490561f1fc4dbfbd82fc4ff456f046c",
            "corpusId": 41263,
            "url": "https://www.semanticscholar.org/paper/7e6d09530490561f1fc4dbfbd82fc4ff456f046c",
            "title": "The Web as a Parallel Corpus",
            "venue": "International Conference on Computational Logic",
            "publicationVenue": {
                "id": "urn:research:30a8645d-22d4-42e2-b3f6-304bf4ce3a02",
                "name": "International Conference on Computational Logic",
                "alternate_names": [
                    "CL",
                    "Int Conf Comput Log"
                ],
                "issn": null,
                "url": null
            },
            "year": 2003,
            "externalIds": {
                "DBLP": "journals/coling/ResnikS03",
                "ACL": "J03-3002",
                "MAG": "2047295649",
                "DOI": "10.1162/089120103322711578",
                "CorpusId": 41263
            },
            "abstract": "Parallel corpora have become an essential resource for work in multilingual natural language processing. In this article, we report on our work using the STRAND system for mining parallel text on the World Wide Web, first reviewing the original algorithm and results and then presenting a set of significant enhancements. These enhancements include the use of supervised learning based on structural features of documents to improve classification performance, a new content-based measure of translational equivalence, and adaptation of the system to take advantage of the Internet Archive for mining parallel text from the Web on a large scale. Finally, the value of these techniques is demonstrated in the construction of a significant parallel corpus for a low-density language pair.",
            "referenceCount": 54,
            "citationCount": 678,
            "influentialCitationCount": 66,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.mitpressjournals.org/doi/pdf/10.1162/089120103322711578",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2003-09-01",
            "journal": {
                "name": "Computational Linguistics",
                "volume": "29"
            },
            "citationStyles": {
                "bibtex": "@Article{Resnik2003TheWA,\n author = {P. Resnik and Noah A. Smith},\n booktitle = {International Conference on Computational Logic},\n journal = {Computational Linguistics},\n pages = {349-380},\n title = {The Web as a Parallel Corpus},\n volume = {29},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3eff9e60cb12777f30747698e63294722348e43d",
            "@type": "ScholarlyArticle",
            "paperId": "3eff9e60cb12777f30747698e63294722348e43d",
            "corpusId": 20264071,
            "url": "https://www.semanticscholar.org/paper/3eff9e60cb12777f30747698e63294722348e43d",
            "title": "Extracting medication information from clinical text",
            "venue": "J. Am. Medical Informatics Assoc.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2010,
            "externalIds": {
                "MAG": "2114039834",
                "DBLP": "journals/jamia/UzunerSC10",
                "DOI": "10.1136/jamia.2010.003947",
                "CorpusId": 20264071,
                "PubMed": "20819854"
            },
            "abstract": "The Third i2b2 Workshop on Natural Language Processing Challenges for Clinical Records focused on the identification of medications, their dosages, modes (routes) of administration, frequencies, durations, and reasons for administration in discharge summaries. This challenge is referred to as the medication challenge. For the medication challenge, i2b2 released detailed annotation guidelines along with a set of annotated discharge summaries. Twenty teams representing 23 organizations and nine countries participated in the medication challenge. The teams produced rule-based, machine learning, and hybrid systems targeted to the task. Although rule-based systems dominated the top 10, the best performing system was a hybrid. Of all medication-related fields, durations and reasons were the most difficult for all systems to detect. While medications themselves were identified with better than 0.75 F-measure by all of the top 10 systems, the best F-measure for durations and reasons were 0.525 and 0.459, respectively. State-of-the-art natural language processing systems go a long way toward extracting medication names, dosages, modes, and frequencies. However, they are limited in recognizing duration and reason fields and would benefit from future research.",
            "referenceCount": 35,
            "citationCount": 468,
            "influentialCitationCount": 25,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://academic.oup.com/jamia/article-pdf/17/5/514/9713258/17-5-514.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2010-09-01",
            "journal": {
                "name": "Journal of the American Medical Informatics Association : JAMIA",
                "volume": "17 5"
            },
            "citationStyles": {
                "bibtex": "@Article{Uzuner2010ExtractingMI,\n author = {\u00d6zlem Uzuner and I. Solti and Eithon Cadag},\n booktitle = {J. Am. Medical Informatics Assoc.},\n journal = {Journal of the American Medical Informatics Association : JAMIA},\n pages = {\n          514-8\n        },\n title = {Extracting medication information from clinical text},\n volume = {17 5},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c4e7410be72006f91462fb291668069efe8dcc33",
            "@type": "ScholarlyArticle",
            "paperId": "c4e7410be72006f91462fb291668069efe8dcc33",
            "corpusId": 2807312,
            "url": "https://www.semanticscholar.org/paper/c4e7410be72006f91462fb291668069efe8dcc33",
            "title": "The Logic Programming Paradigm: A 25-Year Perspective",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2011,
            "externalIds": {
                "MAG": "2886271628",
                "CorpusId": 2807312
            },
            "abstract": "This exciting new text reveals both the evolution of this programming paradigm since its inception and the impressively broad scope of current research in the field. The contributors to this book are all leading world experts in Logic Programming, and they deal with both theoretical and practical issues. They address such diverse topics as: computational molecular biology, machine learning, mobile computing, multi-agent systems, planning, numerical computing and dynamical systems, database systems, an alternative to the \"formulas as types\" approach, program semantics and analysis, and natural language processing. XXXXXXX Neuer Text Logic Programming was founded 25 years ago. This exciting book reveals both the evolution of this programming paradigm and its impressively broad scope of current research. The contributions by leading computer scientists deal with both theoretical and practical issues. They address diverse topics such as: computational molecular biology, machine learning, mobile computing, multi-agent systems, numerical computing and dynamical systems, database systems, program semantics, natural language processing, and promising future directions.",
            "referenceCount": 38,
            "citationCount": 524,
            "influentialCitationCount": 16,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Physics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Philosophy",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2011-09-19",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Apt2011TheLP,\n author = {K. Apt and V. Marek and M. Truszczynski and D. Warren},\n pages = {472-472},\n title = {The Logic Programming Paradigm: A 25-Year Perspective},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5b1516c87818084dc5d195cc274e1ee8923210d2",
            "@type": "ScholarlyArticle",
            "paperId": "5b1516c87818084dc5d195cc274e1ee8923210d2",
            "corpusId": 52117484,
            "url": "https://www.semanticscholar.org/paper/5b1516c87818084dc5d195cc274e1ee8923210d2",
            "title": "Neural Cross-Lingual Named Entity Recognition with Minimal Resources",
            "venue": "Conference on Empirical Methods in Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:41bf9ed3-85b3-4c90-b015-150e31690253",
                "name": "Conference on Empirical Methods in Natural Language Processing",
                "alternate_names": [
                    "Empir Method Nat Lang Process",
                    "Empirical Methods in Natural Language Processing",
                    "Conf Empir Method Nat Lang Process",
                    "EMNLP"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/emnlp"
            },
            "year": 2018,
            "externalIds": {
                "ACL": "D18-1034",
                "ArXiv": "1808.09861",
                "DBLP": "conf/emnlp/XieYNSC18",
                "MAG": "2889191148",
                "DOI": "10.18653/v1/D18-1034",
                "CorpusId": 52117484
            },
            "abstract": "For languages with no annotated resources, unsupervised transfer of natural language processing models such as named-entity recognition (NER) from resource-rich languages would be an appealing capability. However, differences in words and word order across languages make it a challenging problem. To improve mapping of lexical items across languages, we propose a method that finds translations based on bilingual word embeddings. To improve robustness to word order differences, we propose to use self-attention, which allows for a degree of flexibility with respect to word order. We demonstrate that these methods achieve state-of-the-art or competitive NER performance on commonly tested languages under a cross-lingual setting, with much lower resource requirements than past approaches. We also evaluate the challenges of applying these methods to Uyghur, a low-resource language.",
            "referenceCount": 59,
            "citationCount": 175,
            "influentialCitationCount": 18,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aclweb.org/anthology/D18-1034.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-08-01",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1808.09861"
            },
            "citationStyles": {
                "bibtex": "@Article{Xie2018NeuralCN,\n author = {Jiateng Xie and Zhilin Yang and Graham Neubig and Noah A. Smith and J. Carbonell},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n journal = {ArXiv},\n title = {Neural Cross-Lingual Named Entity Recognition with Minimal Resources},\n volume = {abs/1808.09861},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9a296c206ef66031684152cbd3764a0f642cb688",
            "@type": "ScholarlyArticle",
            "paperId": "9a296c206ef66031684152cbd3764a0f642cb688",
            "corpusId": 148028,
            "url": "https://www.semanticscholar.org/paper/9a296c206ef66031684152cbd3764a0f642cb688",
            "title": "A Survey on Automatic Text Summarization",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2007,
            "externalIds": {
                "MAG": "2143205289",
                "CorpusId": 148028
            },
            "abstract": "The increasing availability of online information has necessitated intensive research in the area of automatic text summarization within the Natural Language Processing (NLP) community. Over the past half a century, the problem has been addressed from many dierent perspectives, in varying domains and using various paradigms. This survey intends to investigate some of the most relevant approaches both in the areas of single-document and multipledocument summarization, giving special emphasis to empirical methods and extractive techniques. Some promising approaches that concentrate on specic details of the summarization problem are also discussed. Special attention is devoted to automatic evaluation of summarization systems, as future research on summarization is strongly dependent on progress in this area.",
            "referenceCount": 49,
            "citationCount": 580,
            "influentialCitationCount": 23,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Das2007ASO,\n author = {Dipanjan Das},\n title = {A Survey on Automatic Text Summarization},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:60140406ec6990d7d82fea14730a60609a9009c0",
            "@type": "ScholarlyArticle",
            "paperId": "60140406ec6990d7d82fea14730a60609a9009c0",
            "corpusId": 7819714,
            "url": "https://www.semanticscholar.org/paper/60140406ec6990d7d82fea14730a60609a9009c0",
            "title": "emoji2vec: Learning Emoji Representations from their Description",
            "venue": "SocialNLP@EMNLP",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/acl-socialnlp/EisnerRABR16",
                "ArXiv": "1609.08359",
                "MAG": "2963291843",
                "ACL": "W16-6208",
                "DOI": "10.18653/v1/W16-6208",
                "CorpusId": 7819714
            },
            "abstract": "Many current natural language processing applications for social media rely on representation learning and utilize pre-trained word embeddings. There currently exist several publicly-available, pre-trained sets of word embeddings, but they contain few or no emoji representations even as emoji usage in social media has increased. In this paper we release emoji2vec, pre-trained embeddings for all Unicode emoji which are learned from their description in the Unicode emoji standard. The resulting emoji embeddings can be readily used in downstream social natural language processing applications alongside word2vec. We demonstrate, for the downstream task of sentiment analysis, that emoji embeddings learned from short descriptions outperforms a skip-gram model trained on a large collection of tweets, while avoiding the need for contexts in which emoji need to appear frequently in order to estimate a representation.",
            "referenceCount": 28,
            "citationCount": 253,
            "influentialCitationCount": 16,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://doi.org/10.18653/v1/w16-6208",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-09-27",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1609.08359"
            },
            "citationStyles": {
                "bibtex": "@Article{Eisner2016emoji2vecLE,\n author = {Ben Eisner and Tim Rockt\u00e4schel and Isabelle Augenstein and Matko Bosnjak and S. Riedel},\n booktitle = {SocialNLP@EMNLP},\n journal = {ArXiv},\n title = {emoji2vec: Learning Emoji Representations from their Description},\n volume = {abs/1609.08359},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f7158bd1635bf7bb87c557c429774d5236703e64",
            "@type": "ScholarlyArticle",
            "paperId": "f7158bd1635bf7bb87c557c429774d5236703e64",
            "corpusId": 13911587,
            "url": "https://www.semanticscholar.org/paper/f7158bd1635bf7bb87c557c429774d5236703e64",
            "title": "Dialog-based Interactive Image Retrieval",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2963131783",
                "DBLP": "journals/corr/abs-1805-00145",
                "ArXiv": "1805.00145",
                "CorpusId": 13911587
            },
            "abstract": "Existing methods for interactive image retrieval have demonstrated the merit of integrating user feedback, improving retrieval results. However, most current systems rely on restricted forms of user feedback, such as binary relevance responses, or feedback based on a fixed set of relative attributes, which limits their impact. In this paper, we introduce a new approach to interactive image search that enables users to provide feedback via natural language, allowing for more natural and effective interaction. We formulate the task of dialog-based interactive image retrieval as a reinforcement learning problem, and reward the dialog system for improving the rank of the target image during each dialog turn. To mitigate the cumbersome and costly process of collecting human-machine conversations as the dialog system learns, we train our system with a user simulator, which is itself trained to describe the differences between target and candidate images. The efficacy of our approach is demonstrated in a footwear retrieval application. Experiments on both simulated and real-world data show that 1) our proposed learning framework achieves better accuracy than other supervised and reinforcement learning baselines and 2) user feedback based on natural language rather than pre-specified attributes leads to more effective retrieval results, and a more natural and expressive communication interface.",
            "referenceCount": 66,
            "citationCount": 158,
            "influentialCitationCount": 32,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-05-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Guo2018DialogbasedII,\n author = {Xiaoxiao Guo and Hui Wu and Yu Cheng and Steven J. Rennie and R. Feris},\n booktitle = {Neural Information Processing Systems},\n pages = {676-686},\n title = {Dialog-based Interactive Image Retrieval},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d1f37d9cab68eb8cda669cc949394732f33264b4",
            "@type": "ScholarlyArticle",
            "paperId": "d1f37d9cab68eb8cda669cc949394732f33264b4",
            "corpusId": 6758088,
            "url": "https://www.semanticscholar.org/paper/d1f37d9cab68eb8cda669cc949394732f33264b4",
            "title": "Inducing Crosslingual Distributed Representations of Words",
            "venue": "International Conference on Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:f51ff783-cdff-4e22-94fb-28e6336d17b3",
                "name": "International Conference on Computational Linguistics",
                "alternate_names": [
                    "Int Conf Comput Linguistics",
                    "COLING"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/coling/"
            },
            "year": 2012,
            "externalIds": {
                "DBLP": "conf/coling/KlementievTB12",
                "MAG": "2251033195",
                "ACL": "C12-1089",
                "CorpusId": 6758088
            },
            "abstract": "Distributed representations of words have proven extremely useful in numerous natural language processing tasks. Their appeal is that they can help alleviate data sparsity problems common to supervised learning. Methods for inducing these representations require only unlabeled language data, which are plentiful for many natural languages. In this work, we induce distributed representations for a pair of languages jointly. We treat it as a multitask learning problem where each task corresponds to a single word, and task relatedness is derived from co-occurrence statistics in bilingual parallel data. These representations can be used for a number of crosslingual learning tasks, where a learner can be trained on annotations present in one language and applied to test data in another. We show that our representations are informative by using them for crosslingual document classification, where classifiers trained on these representations substantially outperform strong baselines (e.g. machine translation) when applied to a new language.",
            "referenceCount": 34,
            "citationCount": 380,
            "influentialCitationCount": 55,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2012-12-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Klementiev2012InducingCD,\n author = {A. Klementiev and Ivan Titov and Binod Bhattarai},\n booktitle = {International Conference on Computational Linguistics},\n pages = {1459-1474},\n title = {Inducing Crosslingual Distributed Representations of Words},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8b1aa4727eb2a83db1bd3ae54e078b0b7ce5eccb",
            "@type": "ScholarlyArticle",
            "paperId": "8b1aa4727eb2a83db1bd3ae54e078b0b7ce5eccb",
            "corpusId": 47019554,
            "url": "https://www.semanticscholar.org/paper/8b1aa4727eb2a83db1bd3ae54e078b0b7ce5eccb",
            "title": "Retrieval on source code: a neural code search",
            "venue": "MAPL@PLDI",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "conf/pldi/SachdevLLKS018",
                "MAG": "2805788202",
                "DOI": "10.1145/3211346.3211353",
                "CorpusId": 47019554
            },
            "abstract": "Searching over large code corpora can be a powerful productivity tool for both beginner and experienced developers because it helps them quickly find examples of code related to their intent. Code search becomes even more attractive if developers could express their intent in natural language, similar to the interaction that Stack Overflow supports. In this paper, we investigate the use of natural language processing and information retrieval techniques to carry out natural language search directly over source code, i.e. without having a curated Q&A forum such as Stack Overflow at hand. Our experiments using a benchmark suite derived from Stack Overflow and GitHub repositories show promising results. We find that while a basic word\u2013embedding based search procedure works acceptably, better results can be obtained by adding a layer of supervision, as well as by a customized ranking strategy.",
            "referenceCount": 19,
            "citationCount": 145,
            "influentialCitationCount": 21,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle"
            ],
            "publicationDate": "2018-06-18",
            "journal": {
                "name": "Proceedings of the 2nd ACM SIGPLAN International Workshop on Machine Learning and Programming Languages",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Sachdev2018RetrievalOS,\n author = {Saksham Sachdev and Hongyu Li and Sifei Luan and Seohyun Kim and Koushik Sen and S. Chandra},\n booktitle = {MAPL@PLDI},\n journal = {Proceedings of the 2nd ACM SIGPLAN International Workshop on Machine Learning and Programming Languages},\n title = {Retrieval on source code: a neural code search},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fe638b5610475d4524684fb2c2b7b08c119c8700",
            "@type": "ScholarlyArticle",
            "paperId": "fe638b5610475d4524684fb2c2b7b08c119c8700",
            "corpusId": 7506864,
            "url": "https://www.semanticscholar.org/paper/fe638b5610475d4524684fb2c2b7b08c119c8700",
            "title": "New Ranking Algorithms for Parsing and Tagging: Kernels over Discrete Structures, and the Voted Perceptron",
            "venue": "Annual Meeting of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                "name": "Annual Meeting of the Association for Computational Linguistics",
                "alternate_names": [
                    "Annu Meet Assoc Comput Linguistics",
                    "Meeting of the Association for Computational Linguistics",
                    "ACL",
                    "Meet Assoc Comput Linguistics"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/acl/"
            },
            "year": 2002,
            "externalIds": {
                "ACL": "P02-1034",
                "DBLP": "conf/acl/CollinsD02",
                "MAG": "2131297983",
                "DOI": "10.3115/1073083.1073128",
                "CorpusId": 7506864
            },
            "abstract": "This paper introduces new learning algorithms for natural language processing based on the perceptron algorithm. We show how the algorithms can be efficiently applied to exponential sized representations of parse trees, such as the \"all subtrees\" (DOP) representation described by (Bod 1998), or a representation tracking all sub-fragments of a tagged sentence. We give experimental results showing significant improvements on two tasks: parsing Wall Street Journal text, and named-entity extraction from web data.",
            "referenceCount": 27,
            "citationCount": 631,
            "influentialCitationCount": 97,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://dl.acm.org/ft_gateway.cfm?id=1073128&type=pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2002-07-06",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Collins2002NewRA,\n author = {M. Collins and Nigel P. Duffy},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {263-270},\n title = {New Ranking Algorithms for Parsing and Tagging: Kernels over Discrete Structures, and the Voted Perceptron},\n year = {2002}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9ef911fea38b43aedad131d5d08efa6a1833d747",
            "@type": "ScholarlyArticle",
            "paperId": "9ef911fea38b43aedad131d5d08efa6a1833d747",
            "corpusId": 12671905,
            "url": "https://www.semanticscholar.org/paper/9ef911fea38b43aedad131d5d08efa6a1833d747",
            "title": "On the localness of software",
            "venue": "SIGSOFT FSE",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2165747537",
                "DBLP": "conf/sigsoft/TuSD14",
                "DOI": "10.1145/2635868.2635875",
                "CorpusId": 12671905
            },
            "abstract": "The n-gram language model, which has its roots in statistical natural language processing, has been shown to successfully capture the repetitive and predictable regularities (\u201cnaturalness\") of source code, and help with tasks such as code suggestion, porting, and designing assistive coding devices. However, we show in this paper that this natural-language-based model fails to exploit a special property of source code: localness. We find that human-written programs are localized: they have useful local regularities that can be captured and exploited. We introduce a novel cache language model that consists of both an n-gram and an added \u201ccache\" component to exploit localness. We show empirically that the additional cache component greatly improves the n-gram approach by capturing the localness of software, as measured by both cross-entropy and suggestion accuracy. Our model\u2019s suggestion accuracy is actually comparable to a state-of-the-art, semantically augmented language model; but it is simpler and easier to implement. Our cache language model requires nothing beyond lexicalization, and thus is applicable to all programming languages.",
            "referenceCount": 52,
            "citationCount": 236,
            "influentialCitationCount": 30,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle"
            ],
            "publicationDate": "2014-11-11",
            "journal": {
                "name": "Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Tu2014OnTL,\n author = {Zhaopeng Tu and Z. Su and Premkumar T. Devanbu},\n booktitle = {SIGSOFT FSE},\n journal = {Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering},\n title = {On the localness of software},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:95d3001ed7782fecea29bdb41e598aa5b41a615b",
            "@type": "ScholarlyArticle",
            "paperId": "95d3001ed7782fecea29bdb41e598aa5b41a615b",
            "corpusId": 17375754,
            "url": "https://www.semanticscholar.org/paper/95d3001ed7782fecea29bdb41e598aa5b41a615b",
            "title": "A Shared Task on Multimodal Machine Translation and Crosslingual Image Description",
            "venue": "Conference on Machine Translation",
            "publicationVenue": {
                "id": "urn:research:9aacb914-3edf-4e02-b8fe-5abf21c4d2ba",
                "name": "Conference on Machine Translation",
                "alternate_names": [
                    "WMT",
                    "Conf Mach Transl"
                ],
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "ACL": "W16-2346",
                "MAG": "2509282593",
                "DBLP": "conf/wmt/SpeciaFSE16",
                "DOI": "10.18653/v1/W16-2346",
                "CorpusId": 17375754
            },
            "abstract": "This paper introduces and summarises the findings of a new shared task at the intersection of Natural Language Processing and Computer Vision: the generation of image descriptions in a target language, given an image and/or one or more descriptions in a different (source) language. This challenge was organised along with the Conference on Machine Translation (WMT16), and called for system submissions for two task variants: (i) a translation task, in which a source language image description needs to be translated to a target language, (optionally) with additional cues from the corresponding image, and (ii) a description generation task, in which a target language description needs to be generated for an image, (optionally) with additional cues from source language descriptions of the same image. In this first edition of the shared task, 16 systems were submitted for the translation task and seven for the image description task, from a total of 10 teams.",
            "referenceCount": 37,
            "citationCount": 215,
            "influentialCitationCount": 26,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aclweb.org/anthology/W16-2346.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-08-12",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Specia2016AST,\n author = {Lucia Specia and Stella Frank and K. Sima'an and Desmond Elliott},\n booktitle = {Conference on Machine Translation},\n pages = {543-553},\n title = {A Shared Task on Multimodal Machine Translation and Crosslingual Image Description},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7a2629a97aafddd645c4633fa7c835ff0d3bc44a",
            "@type": "ScholarlyArticle",
            "paperId": "7a2629a97aafddd645c4633fa7c835ff0d3bc44a",
            "corpusId": 9885132,
            "url": "https://www.semanticscholar.org/paper/7a2629a97aafddd645c4633fa7c835ff0d3bc44a",
            "title": "Pathway studio - the analysis and navigation of molecular networks",
            "venue": "Bioinform.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2003,
            "externalIds": {
                "DBLP": "journals/bioinformatics/NikitinEDM03",
                "MAG": "2110280725",
                "DOI": "10.1093/BIOINFORMATICS/BTG290",
                "CorpusId": 9885132,
                "PubMed": "14594725"
            },
            "abstract": "SUMMARY\nPathwayAssist is a software application developed for navigation and analysis of biological pathways, gene regulation networks and protein interaction maps. It comes with the built-in natural language processing module MedScan and the comprehensive database describing more than 100 000 events of regulation, interaction and modification between proteins, cell processes and small molecules.\n\n\nAVAILABILITY\nPathwayAssist is available for commercial licensing from Ariadne Genomics, Inc. The light version with limited functionality will be available for free for academic users at www.ariadnegenomics.com/downloads/.",
            "referenceCount": 2,
            "citationCount": 646,
            "influentialCitationCount": 56,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://academic.oup.com/bioinformatics/article-pdf/19/16/2155/48904746/bioinformatics_19_16_2155.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2003-11-01",
            "journal": {
                "name": "Bioinformatics",
                "volume": "19 16"
            },
            "citationStyles": {
                "bibtex": "@Article{Nikitin2003PathwayS,\n author = {Alexander Nikitin and S. Egorov and N. Daraselia and I. Mazo},\n booktitle = {Bioinform.},\n journal = {Bioinformatics},\n pages = {\n          2155-7\n        },\n title = {Pathway studio - the analysis and navigation of molecular networks},\n volume = {19 16},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c432268dd885d9ae02190d8662321f3a3e325a4a",
            "@type": "ScholarlyArticle",
            "paperId": "c432268dd885d9ae02190d8662321f3a3e325a4a",
            "corpusId": 9483510,
            "url": "https://www.semanticscholar.org/paper/c432268dd885d9ae02190d8662321f3a3e325a4a",
            "title": "Biomedical Named Entity Recognition using Conditional Random Fields and Rich Feature Sets",
            "venue": "NLPBA/BioNLP",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2004,
            "externalIds": {
                "ACL": "W04-1221",
                "MAG": "2114361266",
                "DBLP": "conf/bionlp/Settles04",
                "DOI": "10.3115/1567594.1567618",
                "CorpusId": 9483510
            },
            "abstract": "As the wealth of biomedical knowledge in the form of literature increases, there is a rising need for effective natural language processing tools to assist in organizing, curating, and retrieving this information. To that end, named entity recognition (the task of identifying words and phrases in free text that belong to certain classes of interest) is an important first step for many of these larger information management goals.",
            "referenceCount": 7,
            "citationCount": 627,
            "influentialCitationCount": 58,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.5555/1567594.1567618",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2004-08-28",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Settles2004BiomedicalNE,\n author = {Burr Settles},\n booktitle = {NLPBA/BioNLP},\n pages = {104-107},\n title = {Biomedical Named Entity Recognition using Conditional Random Fields and Rich Feature Sets},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4aba54ea82bf99ed4690d45051f1b25d8b9554b5",
            "@type": "ScholarlyArticle",
            "paperId": "4aba54ea82bf99ed4690d45051f1b25d8b9554b5",
            "corpusId": 14617645,
            "url": "https://www.semanticscholar.org/paper/4aba54ea82bf99ed4690d45051f1b25d8b9554b5",
            "title": "A Deep Architecture for Matching Short Texts",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2013,
            "externalIds": {
                "DBLP": "conf/nips/LuL13",
                "MAG": "2128892113",
                "CorpusId": 14617645
            },
            "abstract": "Many machine learning problems can be interpreted as learning for matching two types of objects (e.g., images and captions, users and products, queries and documents, etc.). The matching level of two objects is usually measured as the inner product in a certain feature space, while the modeling effort focuses on mapping of objects from the original space to the feature space. This schema, although proven successful on a range of matching tasks, is insufficient for capturing the rich structure in the matching process of more complicated objects. In this paper, we propose a new deep architecture to more effectively model the complicated matching relations between two objects from heterogeneous domains. More specifically, we apply this model to matching tasks in natural language, e.g., finding sensible responses for a tweet, or relevant answers to a given question. This new architecture naturally combines the localness and hierarchy intrinsic to the natural language problems, and therefore greatly improves upon the state-of-the-art models.",
            "referenceCount": 21,
            "citationCount": 255,
            "influentialCitationCount": 15,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2013-12-05",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Lu2013ADA,\n author = {Zhengdong Lu and Hang Li},\n booktitle = {Neural Information Processing Systems},\n pages = {1367-1375},\n title = {A Deep Architecture for Matching Short Texts},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:606cb863449e847f4ded99a0afad1b2c808bcab0",
            "@type": "ScholarlyArticle",
            "paperId": "606cb863449e847f4ded99a0afad1b2c808bcab0",
            "corpusId": 4654482,
            "url": "https://www.semanticscholar.org/paper/606cb863449e847f4ded99a0afad1b2c808bcab0",
            "title": "Findings of the VarDial Evaluation Campaign 2017",
            "venue": "Workshop on NLP for Similar Languages, Varieties and Dialects",
            "publicationVenue": {
                "id": "urn:research:1a1f5a1c-fa53-4ce6-beb0-ab9ce8be9d12",
                "name": "Workshop on NLP for Similar Languages, Varieties and Dialects",
                "alternate_names": [
                    "VarDial",
                    "Workshop NLP Similar Lang Var Dialect"
                ],
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2620806258",
                "ACL": "W17-1201",
                "DBLP": "conf/vardial/ZampieriMLNATSA17",
                "DOI": "10.18653/v1/W17-1201",
                "CorpusId": 4654482
            },
            "abstract": "We present the results of the VarDial Evaluation Campaign on Natural Language Processing (NLP) for Similar Languages, Varieties and Dialects, which we organized as part of the fourth edition of the VarDial workshop at EACL\u20192017. This year, we included four shared tasks: Discriminating between Similar Languages (DSL), Arabic Dialect Identification (ADI), German Dialect Identification (GDI), and Cross-lingual Dependency Parsing (CLP). A total of 19 teams submitted runs across the four tasks, and 15 of them wrote system description papers.",
            "referenceCount": 71,
            "citationCount": 167,
            "influentialCitationCount": 23,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aclweb.org/anthology/W17-1201.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-04-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zampieri2017FindingsOT,\n author = {Marcos Zampieri and S. Malmasi and Nikola Ljubesic and Preslav Nakov and Ahmed Ali and J. Tiedemann and Yves Scherrer and No\u00ebmi Aepli},\n booktitle = {Workshop on NLP for Similar Languages, Varieties and Dialects},\n pages = {1-15},\n title = {Findings of the VarDial Evaluation Campaign 2017},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a9a5d671271fff45429084e184a788f611b6f194",
            "@type": "ScholarlyArticle",
            "paperId": "a9a5d671271fff45429084e184a788f611b6f194",
            "corpusId": 52301591,
            "url": "https://www.semanticscholar.org/paper/a9a5d671271fff45429084e184a788f611b6f194",
            "title": "FRAGE: Frequency-Agnostic Word Representation",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1809.06858",
                "DBLP": "journals/corr/abs-1809-06858",
                "MAG": "2890560993",
                "CorpusId": 52301591
            },
            "abstract": "Continuous word representation (aka word embedding) is a basic building block in many neural network-based models used in natural language processing tasks. Although it is widely accepted that words with similar semantics should be close to each other in the embedding space, we find that word embeddings learned in several tasks are biased towards word frequency: the embeddings of high-frequency and low-frequency words lie in different subregions of the embedding space, and the embedding of a rare word and a popular word can be far from each other even if they are semantically similar. This makes learned word embeddings ineffective, especially for rare words, and consequently limits the performance of these neural network models. In this paper, we develop a neat, simple yet effective way to learn \\emph{FRequency-AGnostic word Embedding} (FRAGE) using adversarial training. We conducted comprehensive studies on ten datasets across four natural language processing tasks, including word similarity, language modeling, machine translation and text classification. Results show that with FRAGE, we achieve higher performance than the baselines in all tasks.",
            "referenceCount": 46,
            "citationCount": 131,
            "influentialCitationCount": 15,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-09-18",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1809.06858"
            },
            "citationStyles": {
                "bibtex": "@Article{Gong2018FRAGEFW,\n author = {Chengyue Gong and Di He and Xu Tan and Tao Qin and Liwei Wang and Tie-Yan Liu},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {FRAGE: Frequency-Agnostic Word Representation},\n volume = {abs/1809.06858},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:328eeead2e4eac607886671057f1b100411e759f",
            "@type": "ScholarlyArticle",
            "paperId": "328eeead2e4eac607886671057f1b100411e759f",
            "corpusId": 8402367,
            "url": "https://www.semanticscholar.org/paper/328eeead2e4eac607886671057f1b100411e759f",
            "title": "FCA-MERGE: Bottom-Up Merging of Ontologies",
            "venue": "International Joint Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:67f7f831-711a-43c8-8785-1e09005359b5",
                "name": "International Joint Conference on Artificial Intelligence",
                "alternate_names": [
                    "Int Jt Conf Artif Intell",
                    "IJCAI"
                ],
                "issn": null,
                "url": "http://www.ijcai.org/"
            },
            "year": 2001,
            "externalIds": {
                "MAG": "1501979881",
                "DBLP": "conf/ijcai/StummeM01",
                "CorpusId": 8402367
            },
            "abstract": "Ontologies have been established for knowledge sharing and are widely used as a means for conceptually structuring domains of interest. With the growing usage of ontologies, the problem of overlapping knowledge in a common domain becomes critical. We propose the new method FCA-MERGE for merging ontologies following a bottom-up approach which offers a structural description of the merging process. The method is guided by application-specific instances of the given source ontologies, that are to be merged. We apply techniques from natural language processing and formal concept analysis to derive a lattice of concepts as a structural result of FCA-MERGE. The generated result is then explored and transformed into the merged ontology with human interaction.",
            "referenceCount": 9,
            "citationCount": 728,
            "influentialCitationCount": 37,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2001-08-04",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Stumme2001FCAMERGEBM,\n author = {Gerd Stumme and A. Maedche},\n booktitle = {International Joint Conference on Artificial Intelligence},\n pages = {225-234},\n title = {FCA-MERGE: Bottom-Up Merging of Ontologies},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:10ee4bfd16c2784adf54703daa24c37520fda1f3",
            "@type": "ScholarlyArticle",
            "paperId": "10ee4bfd16c2784adf54703daa24c37520fda1f3",
            "corpusId": 43797694,
            "url": "https://www.semanticscholar.org/paper/10ee4bfd16c2784adf54703daa24c37520fda1f3",
            "title": "Pattern for Python",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2012,
            "externalIds": {
                "MAG": "2110453538",
                "DBLP": "journals/jmlr/SmedtD12",
                "DOI": "10.5555/2503308.2343710",
                "CorpusId": 43797694
            },
            "abstract": "Pattern is a package for Python 2.4+ with functionality for web mining (Google + Twitter + Wikipedia, web spider, HTML DOM parser), natural language processing (tagger/chunker, n-gram search, sentiment analysis, WordNet), machine learning (vector space model, k-means clustering, Naive Bayes + k-NN + SVM classifiers) and network analysis (graph centrality and visualization). It is well documented and bundled with 30+ examples and 350+ unit tests. The source code is licensed under BSD and available from http://www.clips.ua.ac.be/pages/pattern.",
            "referenceCount": 19,
            "citationCount": 372,
            "influentialCitationCount": 18,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "J. Mach. Learn. Res.",
                "volume": "13"
            },
            "citationStyles": {
                "bibtex": "@Article{Smedt2012PatternFP,\n author = {T. Smedt and Walter Daelemans},\n booktitle = {Journal of machine learning research},\n journal = {J. Mach. Learn. Res.},\n pages = {2063-2067},\n title = {Pattern for Python},\n volume = {13},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:81161b744b1347be5269dee3965ab169971aa158",
            "@type": "ScholarlyArticle",
            "paperId": "81161b744b1347be5269dee3965ab169971aa158",
            "corpusId": 60654869,
            "url": "https://www.semanticscholar.org/paper/81161b744b1347be5269dee3965ab169971aa158",
            "title": "An introduction to text-to-speech synthesis",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1997,
            "externalIds": {
                "MAG": "1510007267",
                "DOI": "10.1007/978-94-011-5730-8",
                "CorpusId": 60654869
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 726,
            "influentialCitationCount": 70,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Dutoit1997AnIT,\n author = {T. Dutoit},\n title = {An introduction to text-to-speech synthesis},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e9fd1a7ae0322d417ab2d32017e373dd50efc063",
            "@type": "ScholarlyArticle",
            "paperId": "e9fd1a7ae0322d417ab2d32017e373dd50efc063",
            "corpusId": 16894634,
            "url": "https://www.semanticscholar.org/paper/e9fd1a7ae0322d417ab2d32017e373dd50efc063",
            "title": "A comparison of two learning algorithms for text categorization",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1994,
            "externalIds": {
                "MAG": "1669876765",
                "CorpusId": 16894634
            },
            "abstract": "This paper examines the use of inductive learning to categorize natural language documents into predeened content categories. Categorization of text is of increasing importance in information retrieval and natural language processing systems. Previous research on automated text categorization has mixed machine learning and knowledge engineering methods, making it diicult to draw conclusions about the performance of particular methods. In this paper we present empirical results on the performance of a Bayesian classiier and a decision tree learning algorithm on two text categorization data sets. We nd that both algorithms achieve reasonable performance and allow controlled tradeoos between false positives and false negatives. The stepwise feature selection in the decision tree algorithm is particularly eeective in dealing with the large feature sets common in text categorization. However, even this algorithm is aided by an initial preeltering of features, connrming the results found by Almuallim and Dietterich on artiicial data sets. We also demonstrate the impact of the time-varying nature of category deenitions.",
            "referenceCount": 26,
            "citationCount": 737,
            "influentialCitationCount": 41,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Lewis1994ACO,\n author = {D. Lewis and M. Ringuette},\n title = {A comparison of two learning algorithms for text categorization},\n year = {1994}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8d3feb186556ead77590979b42c42374549a1166",
            "@type": "ScholarlyArticle",
            "paperId": "8d3feb186556ead77590979b42c42374549a1166",
            "corpusId": 32923127,
            "url": "https://www.semanticscholar.org/paper/8d3feb186556ead77590979b42c42374549a1166",
            "title": "Earth Mover\u2019s Distance Minimization for Unsupervised Bilingual Lexicon Induction",
            "venue": "Conference on Empirical Methods in Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:41bf9ed3-85b3-4c90-b015-150e31690253",
                "name": "Conference on Empirical Methods in Natural Language Processing",
                "alternate_names": [
                    "Empir Method Nat Lang Process",
                    "Empirical Methods in Natural Language Processing",
                    "Conf Empir Method Nat Lang Process",
                    "EMNLP"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/emnlp"
            },
            "year": 2017,
            "externalIds": {
                "ACL": "D17-1207",
                "DBLP": "conf/emnlp/ZhangLLS17",
                "MAG": "2760424551",
                "DOI": "10.18653/v1/D17-1207",
                "CorpusId": 32923127
            },
            "abstract": "Cross-lingual natural language processing hinges on the premise that there exists invariance across languages. At the word level, researchers have identified such invariance in the word embedding semantic spaces of different languages. However, in order to connect the separate spaces, cross-lingual supervision encoded in parallel data is typically required. In this paper, we attempt to establish the cross-lingual connection without relying on any cross-lingual supervision. By viewing word embedding spaces as distributions, we propose to minimize their earth mover\u2019s distance, a measure of divergence between distributions. We demonstrate the success on the unsupervised bilingual lexicon induction task. In addition, we reveal an interesting finding that the earth mover\u2019s distance shows potential as a measure of language difference.",
            "referenceCount": 74,
            "citationCount": 140,
            "influentialCitationCount": 27,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aclweb.org/anthology/D17-1207.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-09-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2017EarthMD,\n author = {Meng Zhang and Yang Liu and Huanbo Luan and Maosong Sun},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {1934-1945},\n title = {Earth Mover\u2019s Distance Minimization for Unsupervised Bilingual Lexicon Induction},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:14f157daceb1ef540a68f8aec39b41de4657690f",
            "@type": "ScholarlyArticle",
            "paperId": "14f157daceb1ef540a68f8aec39b41de4657690f",
            "corpusId": 449999,
            "url": "https://www.semanticscholar.org/paper/14f157daceb1ef540a68f8aec39b41de4657690f",
            "title": "Visualizing the non-visual: spatial analysis and interaction with information from text documents",
            "venue": "Proceedings of Visualization 1995 Conference",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1995,
            "externalIds": {
                "MAG": "2141018272",
                "DBLP": "conf/infovis/WiseTPLPSC95",
                "DOI": "10.1109/INFVIS.1995.528686",
                "CorpusId": 449999
            },
            "abstract": "The paper describes an approach to IV that involves spatializing text content for enhanced visual browsing and analysis. The application arena is large text document corpora such as digital libraries, regulations and procedures, archived reports, etc. The basic idea is that text content from these sources may be transformed to a spatial representation that preserves informational characteristics from the documents. The spatial representation may then be visually browsed and analyzed in ways that avoid language processing and that reduce the analysts mental workload. The result is an interaction with text that more nearly resembles perception and action with the natural world than with the abstractions of written language.",
            "referenceCount": 45,
            "citationCount": 756,
            "influentialCitationCount": 33,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1995-10-30",
            "journal": {
                "name": "Proceedings of Visualization 1995 Conference",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wise1995VisualizingTN,\n author = {J. Wise and James J. Thomas and K. Pennock and D. Lantrip and M. Pottier and A. Schur and V. Crow},\n booktitle = {Proceedings of Visualization 1995 Conference},\n journal = {Proceedings of Visualization 1995 Conference},\n pages = {51-58},\n title = {Visualizing the non-visual: spatial analysis and interaction with information from text documents},\n year = {1995}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d8fc5fc99a485ad8690433467b10448fb58da352",
            "@type": "ScholarlyArticle",
            "paperId": "d8fc5fc99a485ad8690433467b10448fb58da352",
            "corpusId": 38521628,
            "url": "https://www.semanticscholar.org/paper/d8fc5fc99a485ad8690433467b10448fb58da352",
            "title": "Tracking the mind during reading: the influence of past, present, and future words on fixation durations.",
            "venue": "Journal of experimental psychology. General",
            "publicationVenue": {
                "id": "urn:research:ba388b36-981e-4c1b-8048-464cdaa9c9fc",
                "name": "Journal of experimental psychology. General",
                "alternate_names": [
                    "J Exp Psychol Gen",
                    "J exp psychol Gen",
                    "Journal of Experimental Psychology: General"
                ],
                "issn": "0096-3445",
                "url": "http://www.apa.org/journals/xge.html"
            },
            "year": 2006,
            "externalIds": {
                "MAG": "2030330674",
                "DOI": "10.1037/0096-3445.135.1.12",
                "CorpusId": 38521628,
                "PubMed": "16478314"
            },
            "abstract": "Reading requires the orchestration of visual, attentional, language-related, and oculomotor processing constraints. This study replicates previous effects of frequency, predictability, and length of fixated words on fixation durations in natural reading and demonstrates new effects of these variables related to 144 sentences. Such evidence for distributed processing of words across fixation durations challenges psycholinguistic immediacy-of-processing and eye-mind assumptions. Most of the time the mind processes several words in parallel at different perceptual and cognitive levels. Eye movements can help to unravel these processes.",
            "referenceCount": 109,
            "citationCount": 560,
            "influentialCitationCount": 46,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://publishup.uni-potsdam.de/files/5521/phr_263_2011_12_13.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Psychology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2006-02-01",
            "journal": {
                "name": "Journal of experimental psychology. General",
                "volume": "135 1"
            },
            "citationStyles": {
                "bibtex": "@Article{Kliegl2006TrackingTM,\n author = {R. Kliegl and A. Nuthmann and Ralf Engbert},\n booktitle = {Journal of experimental psychology. General},\n journal = {Journal of experimental psychology. General},\n pages = {\n          12-35\n        },\n title = {Tracking the mind during reading: the influence of past, present, and future words on fixation durations.},\n volume = {135 1},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e8dbae782c706db14d4b906fc71abad685834f1f",
            "@type": "ScholarlyArticle",
            "paperId": "e8dbae782c706db14d4b906fc71abad685834f1f",
            "corpusId": 15113857,
            "url": "https://www.semanticscholar.org/paper/e8dbae782c706db14d4b906fc71abad685834f1f",
            "title": "Cerebral organization for language in deaf and hearing subjects: biological constraints and effects of experience.",
            "venue": "Proceedings of the National Academy of Sciences of the United States of America",
            "publicationVenue": {
                "id": "urn:research:bb95bf2e-8383-4748-bf9d-d6906d091085",
                "name": "Proceedings of the National Academy of Sciences of the United States of America",
                "alternate_names": [
                    "PNAS",
                    "PNAS online",
                    "Proceedings of the National Academy of Sciences of the United States of America.",
                    "Proc National Acad Sci",
                    "Proceedings of the National Academy of Sciences",
                    "Proc National Acad Sci u s Am"
                ],
                "issn": "0027-8424",
                "url": "https://www.jstor.org/journal/procnatiacadscie"
            },
            "year": 1998,
            "externalIds": {
                "MAG": "2149301988",
                "DOI": "10.1073/PNAS.95.3.922",
                "CorpusId": 15113857,
                "PubMed": "9448260"
            },
            "abstract": "Cerebral organization during sentence processing in English and in American Sign Language (ASL) was characterized by employing functional magnetic resonance imaging (fMRI) at 4 T. Effects of deafness, age of language acquisition, and bilingualism were assessed by comparing results from (i) normally hearing, monolingual, native speakers of English, (ii) congenitally, genetically deaf, native signers of ASL who learned English late and through the visual modality, and (iii) normally hearing bilinguals who were native signers of ASL and speakers of English. All groups, hearing and deaf, processing their native language, English or ASL, displayed strong and repeated activation within classical language areas of the left hemisphere. Deaf subjects reading English did not display activation in these regions. These results suggest that the early acquisition of a natural language is important in the expression of the strong bias for these areas to mediate language, independently of the form of the language. In addition, native signers, hearing and deaf, displayed extensive activation of homologous areas within the right hemisphere, indicating that the specific processing requirements of the language also in part determine the organization of the language systems of the brain.",
            "referenceCount": 61,
            "citationCount": 506,
            "influentialCitationCount": 22,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc33817?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Study"
            ],
            "publicationDate": "1998-02-03",
            "journal": {
                "name": "Proceedings of the National Academy of Sciences of the United States of America",
                "volume": "95 3"
            },
            "citationStyles": {
                "bibtex": "@Article{Neville1998CerebralOF,\n author = {H. Neville and D. Bavelier and D. Corina and J. Rauschecker and A. Karni and A. Lalwani and A. Braun and V. Clark and P. Jezzard and R. Turner},\n booktitle = {Proceedings of the National Academy of Sciences of the United States of America},\n journal = {Proceedings of the National Academy of Sciences of the United States of America},\n pages = {\n          922-9\n        },\n title = {Cerebral organization for language in deaf and hearing subjects: biological constraints and effects of experience.},\n volume = {95 3},\n year = {1998}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:16bd1fbe3694173eda4ad4338a85f8288d19bf02",
            "@type": "ScholarlyArticle",
            "paperId": "16bd1fbe3694173eda4ad4338a85f8288d19bf02",
            "corpusId": 489775,
            "url": "https://www.semanticscholar.org/paper/16bd1fbe3694173eda4ad4338a85f8288d19bf02",
            "title": "Relational Learning of Pattern-Match Rules for Information Extraction",
            "venue": "Conference on Computational Natural Language Learning",
            "publicationVenue": {
                "id": "urn:research:3779a5a7-9119-4f69-84fe-f7eef193eb49",
                "name": "Conference on Computational Natural Language Learning",
                "alternate_names": [
                    "CoNLL",
                    "Conf Comput Nat Lang Learn"
                ],
                "issn": null,
                "url": null
            },
            "year": 1999,
            "externalIds": {
                "MAG": "2395895772",
                "DBLP": "conf/aaai/CaliffM99",
                "ACL": "W97-1002",
                "CorpusId": 489775
            },
            "abstract": "Information extraction is a form of shallow text processing that locates a specified set of relevant items in a natural-language document. Systems for this task require significant domain-specific knowledge and are time-consuming and difficult to build by hand, making them a good application for machine learning. We present a system, RAPIER, that uses pairs of sample documents and filled templates to induce pattern-match rules that directly extract fillers for the slots in the template. RAPIER employs a bottom-up learning algorithm which incorporates techniques from several inductive logic programming systems and acquires unbounded patterns that include constraints on the words, part-of-speech tags, and semantic classes present in the filler and the surrounding text. We present encouraging experimental results on two domains.",
            "referenceCount": 29,
            "citationCount": 703,
            "influentialCitationCount": 36,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1999-07-18",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Califf1999RelationalLO,\n author = {Mary Elaine Califf and R. Mooney},\n booktitle = {Conference on Computational Natural Language Learning},\n pages = {9-15},\n title = {Relational Learning of Pattern-Match Rules for Information Extraction},\n year = {1999}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6149eea0b589fddbbeda46a0a92da3c097d2ef39",
            "@type": "ScholarlyArticle",
            "paperId": "6149eea0b589fddbbeda46a0a92da3c097d2ef39",
            "corpusId": 60966843,
            "url": "https://www.semanticscholar.org/paper/6149eea0b589fddbbeda46a0a92da3c097d2ef39",
            "title": "Semantic NLP-Based Information Extraction from Construction Regulatory Documents for Automated Compliance Checking",
            "venue": "Journal of computing in civil engineering",
            "publicationVenue": {
                "id": "urn:research:c16064f2-6ce5-4d27-a13c-4f9a0210ceb6",
                "name": "Journal of computing in civil engineering",
                "alternate_names": [
                    "J comput civ eng",
                    "Journal of Computing in Civil Engineering",
                    "J Comput Civ Eng"
                ],
                "issn": "0887-3801",
                "url": "https://ascelibrary.org/journal/jccee5"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/jccee/ZhangE16",
                "MAG": "1967622519",
                "DOI": "10.1061/(ASCE)CP.1943-5487.0000346",
                "CorpusId": 60966843
            },
            "abstract": "AbstractAutomated regulatory compliance checking requires automated extraction of requirements from regulatory textual documents and their formalization in a computer-processable rule representation. Such information extraction (IE) is a challenging task that requires complex analysis and processing of text. Natural language processing (NLP) aims to enable computers to process natural language text in a human-like manner. This paper proposes a semantic, rule-based NLP approach for automated IE from construction regulatory documents. The proposed approach uses a set of pattern-matching-based IE rules and conflict resolution (CR) rules in IE. A variety of syntactic (syntax/grammar-related) and semantic (meaning/context-related) text features are used in the patterns of the IE and CR rules. Phrase structure grammar (PSG)-based phrasal tags and separation and sequencing of semantic information elements are proposed and used to reduce the number of needed patterns. An ontology is used to aid in the recognition...",
            "referenceCount": 38,
            "citationCount": 182,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-03-01",
            "journal": {
                "name": "J. Comput. Civ. Eng.",
                "volume": "30"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2016SemanticNI,\n author = {Jiansong Zhang and N. El-Gohary},\n booktitle = {Journal of computing in civil engineering},\n journal = {J. Comput. Civ. Eng.},\n title = {Semantic NLP-Based Information Extraction from Construction Regulatory Documents for Automated Compliance Checking},\n volume = {30},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c43693c4f22362769e75da2274dff97bcc57f602",
            "@type": "ScholarlyArticle",
            "paperId": "c43693c4f22362769e75da2274dff97bcc57f602",
            "corpusId": 13870599,
            "url": "https://www.semanticscholar.org/paper/c43693c4f22362769e75da2274dff97bcc57f602",
            "title": "A massively parallel corpus: the Bible in 100 languages",
            "venue": "Language Resources and Evaluation",
            "publicationVenue": {
                "id": "urn:research:7dda5bd1-752f-45e5-bc7b-09633096916e",
                "name": "Language Resources and Evaluation",
                "alternate_names": [
                    "Lang Resour Evaluation"
                ],
                "issn": "1574-020X",
                "url": "https://link.springer.com/journal/10579"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2041532239",
                "DBLP": "journals/lre/Christodoulopoulos15",
                "PubMedCentral": "4551210",
                "DOI": "10.1007/s10579-014-9287-y",
                "CorpusId": 13870599,
                "PubMed": "26321896"
            },
            "abstract": null,
            "referenceCount": 49,
            "citationCount": 206,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/s10579-014-9287-y.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-11-19",
            "journal": {
                "name": "Language Resources and Evaluation",
                "volume": "49"
            },
            "citationStyles": {
                "bibtex": "@Article{Christodoulopoulos2014AMP,\n author = {Christos Christodoulopoulos and Mark Steedman},\n booktitle = {Language Resources and Evaluation},\n journal = {Language Resources and Evaluation},\n pages = {375 - 395},\n title = {A massively parallel corpus: the Bible in 100 languages},\n volume = {49},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bb56b7f09ef7fa4f4741b6bcbd4ffb7ea6c828c4",
            "@type": "ScholarlyArticle",
            "paperId": "bb56b7f09ef7fa4f4741b6bcbd4ffb7ea6c828c4",
            "corpusId": 9234833,
            "url": "https://www.semanticscholar.org/paper/bb56b7f09ef7fa4f4741b6bcbd4ffb7ea6c828c4",
            "title": "A Survey of Paraphrasing and Textual Entailment Methods",
            "venue": "Journal of Artificial Intelligence Research",
            "publicationVenue": {
                "id": "urn:research:aef12dca-60a0-4ca3-819b-cad26d309d4e",
                "name": "Journal of Artificial Intelligence Research",
                "alternate_names": [
                    "JAIR",
                    "J Artif Intell Res",
                    "The Journal of Artificial Intelligence Research"
                ],
                "issn": "1076-9757",
                "url": "http://www.jair.org/"
            },
            "year": 2009,
            "externalIds": {
                "DBLP": "journals/corr/abs-0912-3747",
                "MAG": "2145815109",
                "ArXiv": "0912.3747",
                "DOI": "10.1613/jair.2985",
                "CorpusId": 9234833
            },
            "abstract": "Paraphrasing methods recognize, generate, or extract phrases, sentences, or longer natural language expressions that convey almost the same information. Textual entailment methods, on the other hand, recognize, generate, or extract pairs of natural language expressions, such that a human who reads (and trusts) the first element of a pair would most likely infer that the other element is also true. Paraphrasing can be seen as bidirectional textual entailment and methods from the two areas are often similar. Both kinds of methods are useful, at least in principle, in a wide range of natural language processing applications, including question answering, summarization, text generation, and machine translation. We summarize key ideas from the two areas by considering in turn recognition, generation, and extraction methods, also pointing to prominent articles and resources.",
            "referenceCount": 267,
            "citationCount": 452,
            "influentialCitationCount": 25,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://jair.org/index.php/jair/article/download/10651/25463",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2009-12-18",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/0912.3747"
            },
            "citationStyles": {
                "bibtex": "@Article{Androutsopoulos2009ASO,\n author = {Ion Androutsopoulos and Prodromos Malakasiotis},\n booktitle = {Journal of Artificial Intelligence Research},\n journal = {ArXiv},\n title = {A Survey of Paraphrasing and Textual Entailment Methods},\n volume = {abs/0912.3747},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2a911eba95814258ff14502b49e5342c0a05f395",
            "@type": "ScholarlyArticle",
            "paperId": "2a911eba95814258ff14502b49e5342c0a05f395",
            "corpusId": 40012866,
            "url": "https://www.semanticscholar.org/paper/2a911eba95814258ff14502b49e5342c0a05f395",
            "title": "From word models to executable models of signaling networks using automated assembly",
            "venue": "bioRxiv",
            "publicationVenue": {
                "id": "urn:research:027ffd21-ebb0-4af8-baf5-911124292fd0",
                "name": "bioRxiv",
                "alternate_names": null,
                "issn": null,
                "url": "http://biorxiv.org/"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2952755768",
                "PubMedCentral": "5731347",
                "DOI": "10.15252/msb.20177651",
                "CorpusId": 40012866,
                "PubMed": "29175850"
            },
            "abstract": "Word models (natural language descriptions of molecular mechanisms) are a common currency in spoken and written communication in biomedicine but are of limited use in predicting the behavior of complex biological networks. We present an approach to building computational models directly from natural language using automated assembly. Molecular mechanisms described in simple English are read by natural language processing algorithms, converted into an intermediate representation and assembled into executable or network models. We have implemented this approach in the Integrated Network and Dynamical Reasoning Assembler (INDRA), which draws on existing natural language processing systems as well as pathway information in Pathway Commons and other online resources. We demonstrate the use of INDRA and natural language to model three biological processes of increasing scope: (i) p53 dynamics in response to DNA damage; (ii) adaptive drug resistance in BRAF-V600E mutant melanomas; and (iii) the RAS signaling pathway. The use of natural language for modeling makes routine tasks more efficient for modeling practitioners and increases the accessibility and transparency of models for the broader biology community. Standfirst text INDRA uses natural language processing systems to read descriptions of molecular mechanisms and assembles them into executable models. Highlights INDRA decouples the curation of knowledge as word models from model implementation INDRA is connected to multiple natural language processing systems and can draw on information from curated databases INDRA can assemble dynamical models in rule-based and reaction network formalisms, as well as Boolean networks and visualization formats We used INDRA to build models of p53 dynamics, resistance to targeted inhibitors of BRAF in melanoma, and the Ras signaling pathway from natural language",
            "referenceCount": 162,
            "citationCount": 134,
            "influentialCitationCount": 8,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Biology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-03-24",
            "journal": {
                "name": "Molecular Systems Biology",
                "volume": "13"
            },
            "citationStyles": {
                "bibtex": "@Article{Gyori2017FromWM,\n author = {Benjamin M. Gyori and John A. Bachman and K. Subramanian and Jeremy L. Muhlich and Lucian Galescu and P. Sorger},\n booktitle = {bioRxiv},\n journal = {Molecular Systems Biology},\n title = {From word models to executable models of signaling networks using automated assembly},\n volume = {13},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fb752a8856a3433e881fb9132bd3c3ba14e93266",
            "@type": "ScholarlyArticle",
            "paperId": "fb752a8856a3433e881fb9132bd3c3ba14e93266",
            "corpusId": 203902566,
            "url": "https://www.semanticscholar.org/paper/fb752a8856a3433e881fb9132bd3c3ba14e93266",
            "title": "Fake News Detection Using Deep Learning",
            "venue": "Journal of Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:09b0b51d-d7ec-4963-bdb1-cab388c49830",
                "name": "Journal of Information Processing Systems",
                "alternate_names": [
                    "J Inf Process Syst"
                ],
                "issn": "1976-913X",
                "url": "http://jips-k.org/q.jips?cp=ab"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "3033109449",
                "DBLP": "journals/jips/LeeKKPY19",
                "DOI": "10.3745/JIPS.04.0142",
                "CorpusId": 203902566
            },
            "abstract": "News is a routine in everyone's life. It helps in\nenhancing the knowledge on what happens around the world.\nFake news is a fictional information madeup with the intension to\ndelude and hence the knowledge acquired becomes of no use. As\nfake news spreads extensively it has a negative impact in the\nsociety and so fake news detection has become an emerging\nresearch area. The paper deals with a solution to fake news\ndetection using the methods, deep learning and Natural Language\nProcessing. The dataset is trained using deep neural network. The\ndataset needs to be well formatted before given to the network\nwhich is made possible using the technique of Natural Language\nProcessing and thus predicts whether a news is fake or not.",
            "referenceCount": 23,
            "citationCount": 78,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-10-01",
            "journal": {
                "name": "J. Inf. Process. Syst.",
                "volume": "15"
            },
            "citationStyles": {
                "bibtex": "@Article{Lee2019FakeND,\n author = {Dong-Ho Lee and Yu-Ri Kim and Hyeong-Jun Kim and Seung-Myun Park and Yu-Jun Yang},\n booktitle = {Journal of Information Processing Systems},\n journal = {J. Inf. Process. Syst.},\n pages = {1119-1130},\n title = {Fake News Detection Using Deep Learning},\n volume = {15},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:03a4205aabde54d34115399c9c7291335a1f027d",
            "@type": "ScholarlyArticle",
            "paperId": "03a4205aabde54d34115399c9c7291335a1f027d",
            "corpusId": 6565772,
            "url": "https://www.semanticscholar.org/paper/03a4205aabde54d34115399c9c7291335a1f027d",
            "title": "Word sense disambiguation",
            "venue": "Scholarpedia",
            "publicationVenue": {
                "id": "urn:research:856e61df-ae80-4713-a1f1-6afd81e6e2b1",
                "name": "Scholarpedia",
                "alternate_names": null,
                "issn": "1941-6016",
                "url": "http://www.scholarpedia.org/"
            },
            "year": 2013,
            "externalIds": {
                "MAG": "2507992556",
                "DBLP": "reference/ml/Mihalcea10",
                "DOI": "10.4249/scholarpedia.4358",
                "CorpusId": 6565772
            },
            "abstract": "Word Sense Disambiguation (WSD) \u2013 a challenge of Natural Language Processing, for Gujarati language. All natural languages have words that mean different thing in different contexts. Human beings are generally good at sensing those ambiguities but it is difficult for computers to understand that. But computers can sense that by following certain algorithms and rules. Four methodologies were discussed in this paper for implementing word sense disambiguation: AI-based method, Knowledge-based method, supervised method and unsupervised method. Seeming that knowledge based method is more accurate, the algorithms that are of knowledge based method, are used for further processing. It includes the standard Lesk algorithm, the simplified lesk algorithm, the lesk algorithm with synonyms and a baseline algorithm. With the comparison of these algorithms it is finally decided to use simplified lesk algorithm and it will be implemented on Java.",
            "referenceCount": 43,
            "citationCount": 222,
            "influentialCitationCount": 16,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2013-11-13",
            "journal": {
                "name": "Scholarpedia",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{Edmonds2013WordSD,\n author = {Philip Edmonds and Eneko Agirre},\n booktitle = {Scholarpedia},\n journal = {Scholarpedia},\n pages = {4358},\n title = {Word sense disambiguation},\n volume = {3},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f6c035de37e797f7e5167d655b246a2f9426a9eb",
            "@type": "ScholarlyArticle",
            "paperId": "f6c035de37e797f7e5167d655b246a2f9426a9eb",
            "corpusId": 17337432,
            "url": "https://www.semanticscholar.org/paper/f6c035de37e797f7e5167d655b246a2f9426a9eb",
            "title": "Reading Level Assessment Using Support Vector Machines and Statistical Language Models",
            "venue": "Annual Meeting of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                "name": "Annual Meeting of the Association for Computational Linguistics",
                "alternate_names": [
                    "Annu Meet Assoc Comput Linguistics",
                    "Meeting of the Association for Computational Linguistics",
                    "ACL",
                    "Meet Assoc Comput Linguistics"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/acl/"
            },
            "year": 2005,
            "externalIds": {
                "MAG": "2153081451",
                "DBLP": "conf/acl/SchwarmO05",
                "ACL": "P05-1065",
                "DOI": "10.3115/1219840.1219905",
                "CorpusId": 17337432
            },
            "abstract": "Reading proficiency is a fundamental component of language competency. However, finding topical texts at an appropriate reading level for foreign and second language learners is a challenge for teachers. This task can be addressed with natural language processing technology to assess reading level. Existing measures of reading level are not well suited to this task, but previous work and our own pilot experiments have shown the benefit of using statistical language models. In this paper, we also use support vector machines to combine features from traditional reading level measures, statistical language models, and other language processing tools to produce a better method of assessing reading level.",
            "referenceCount": 31,
            "citationCount": 349,
            "influentialCitationCount": 37,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.3115/1219840.1219905",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2005-06-25",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Schwarm2005ReadingLA,\n author = {S. Schwarm and Mari Ostendorf},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {523-530},\n title = {Reading Level Assessment Using Support Vector Machines and Statistical Language Models},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3807a517403cfc7ed67fdfea64baf62b9948bcfe",
            "@type": "ScholarlyArticle",
            "paperId": "3807a517403cfc7ed67fdfea64baf62b9948bcfe",
            "corpusId": 21616326,
            "url": "https://www.semanticscholar.org/paper/3807a517403cfc7ed67fdfea64baf62b9948bcfe",
            "title": "A Parallel Corpus of Python Functions and Documentation Strings for Automated Code Documentation and Code Generation",
            "venue": "International Joint Conference on Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:e783305c-5d8a-44b9-b7a2-449d474a85b2",
                "name": "International Joint Conference on Natural Language Processing",
                "alternate_names": [
                    "IJCNLP",
                    "Int Jt Conf Nat Lang Process"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/ijcnlp"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/ijcnlp/BaroneS17",
                "MAG": "2728773317",
                "ACL": "I17-2053",
                "ArXiv": "1707.02275",
                "CorpusId": 21616326
            },
            "abstract": "Automated documentation of programming source code and automated code generation from natural language are challenging tasks of both practical and scientific interest. Progress in these areas has been limited by the low availability of parallel corpora of code and natural language descriptions, which tend to be small and constrained to specific domains. In this work we introduce a large and diverse parallel corpus of a hundred thousands Python functions with their documentation strings (\u201cdocstrings\u201d) generated by scraping open source repositories on GitHub. We describe baseline results for the code documentation and code generation tasks obtained by neural machine translation. We also experiment with data augmentation techniques to further increase the amount of training data. We release our datasets and processing scripts in order to stimulate research in these areas.",
            "referenceCount": 21,
            "citationCount": 126,
            "influentialCitationCount": 18,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-07-07",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Barone2017APC,\n author = {Antonio Valerio Miceli Barone and Rico Sennrich},\n booktitle = {International Joint Conference on Natural Language Processing},\n pages = {314-319},\n title = {A Parallel Corpus of Python Functions and Documentation Strings for Automated Code Documentation and Code Generation},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:737bb106a35d1ebe6b0acd1cb77582738cf0e09c",
            "@type": "ScholarlyArticle",
            "paperId": "737bb106a35d1ebe6b0acd1cb77582738cf0e09c",
            "corpusId": 14021168,
            "url": "https://www.semanticscholar.org/paper/737bb106a35d1ebe6b0acd1cb77582738cf0e09c",
            "title": "Demographic Factors Improve Classification Performance",
            "venue": "Annual Meeting of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                "name": "Annual Meeting of the Association for Computational Linguistics",
                "alternate_names": [
                    "Annu Meet Assoc Comput Linguistics",
                    "Meeting of the Association for Computational Linguistics",
                    "ACL",
                    "Meet Assoc Comput Linguistics"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/acl/"
            },
            "year": 2015,
            "externalIds": {
                "ACL": "P15-1073",
                "MAG": "2252241921",
                "DBLP": "conf/acl/Hovy15",
                "DOI": "10.3115/v1/P15-1073",
                "CorpusId": 14021168
            },
            "abstract": "Extra-linguistic factors influence language use, and are accounted for by speakers and listeners. Most natural language processing (NLP) tasks to date, however, treat language as uniform. This assumption can harm performance. We investigate the effect of including demographic information on performance in a variety of text-classification tasks. We find that by including age or gender information, we consistently and significantly improve performance over demographic-agnostic models. These results hold across three text-classification tasks in five languages.",
            "referenceCount": 47,
            "citationCount": 161,
            "influentialCitationCount": 11,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-07-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hovy2015DemographicFI,\n author = {Dirk Hovy},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {752-762},\n title = {Demographic Factors Improve Classification Performance},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:73995ae8b7011abb9ce36a91271d836876950d7e",
            "@type": "ScholarlyArticle",
            "paperId": "73995ae8b7011abb9ce36a91271d836876950d7e",
            "corpusId": 10232742,
            "url": "https://www.semanticscholar.org/paper/73995ae8b7011abb9ce36a91271d836876950d7e",
            "title": "Spoken language understanding",
            "venue": "IEEE Signal Processing Magazine",
            "publicationVenue": {
                "id": "urn:research:f62e5eab-173a-4e0a-a963-ed8de9835d22",
                "name": "IEEE Signal Processing Magazine",
                "alternate_names": [
                    "IEEE Signal Process Mag"
                ],
                "issn": "1053-5888",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=79"
            },
            "year": 2008,
            "externalIds": {
                "DBLP": "journals/spm/MoriBHMRT08",
                "MAG": "2120375264",
                "DOI": "10.1109/MSP.2008.918413",
                "CorpusId": 10232742
            },
            "abstract": "Semantics deals with the organization of meanings and the relations between sensory signs or symbols and what they denote or mean. Computational semantics performs a conceptualization of the world using computational processes for composing a meaning representation structure from available signs and their features present, for example, in words and sentences. Spoken language understanding (SLU) is the interpretation of signs conveyed by a speech signal. SLU and natural language understanding (NLU) share the goal of obtaining a conceptual representation of natural language sentences. Specific to SLU is the fact that signs to be used for interpretation are coded into signals along with other information such as speaker identity. Furthermore, spoken sentences often do not follow the grammar of a language; they exhibit self-corrections, hesitations, repetitions, and other irregular phenomena. SLU systems contain an automatic speech recognition (ASR) component and must be robust to noise due to the spontaneous nature of spoken language and the errors introduced by ASR. Moreover, ASR components output a stream of words with no structure information like punctuation and sentence boundaries. Therefore, SLU systems cannot rely on such markers and must perform text segmentation and understanding at the same time.",
            "referenceCount": 57,
            "citationCount": 216,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2008-04-18",
            "journal": {
                "name": "IEEE Signal Processing Magazine",
                "volume": "25"
            },
            "citationStyles": {
                "bibtex": "@Article{Mori2008SpokenLU,\n author = {R. de Mori and Fr\u00e9d\u00e9ric B\u00e9chet and Dilek Z. Hakkani-T\u00fcr and M. McTear and G. Riccardi and G. Tur},\n booktitle = {IEEE Signal Processing Magazine},\n journal = {IEEE Signal Processing Magazine},\n title = {Spoken language understanding},\n volume = {25},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b31c9d44d2c6b90c050ad65b15a6c3d9b199f04c",
            "@type": "ScholarlyArticle",
            "paperId": "b31c9d44d2c6b90c050ad65b15a6c3d9b199f04c",
            "corpusId": 58862,
            "url": "https://www.semanticscholar.org/paper/b31c9d44d2c6b90c050ad65b15a6c3d9b199f04c",
            "title": "Consistent Streaming Through Time: A Vision for Event Stream Processing",
            "venue": "Conference on Innovative Data Systems Research",
            "publicationVenue": {
                "id": "urn:research:528ced1f-e949-4e1a-8fee-2ffbf0be551d",
                "name": "Conference on Innovative Data Systems Research",
                "alternate_names": [
                    "CIDR",
                    "Conf Innov Data Syst Res"
                ],
                "issn": null,
                "url": "http://cidrdb.org/"
            },
            "year": 2006,
            "externalIds": {
                "MAG": "2953310312",
                "DBLP": "conf/cidr/BargaGAH07",
                "ArXiv": "cs/0612115",
                "CorpusId": 58862
            },
            "abstract": "processing will play an increasingly important role in constructing enterprise applications that can immediately react to business critical events. Various technologies have been proposed in recent years, such as event processing, data streams and asynchronous messaging (e.g. pub/sub). We believe these technologies share a common processing model and differ only in target workload, including query language features and consistency requirements. We argue that integrating these technologies is the next step in a natural progression. In this paper, we present an overview and discuss the foundations of CEDR, an event streaming system that embraces a temporal stream model to unify and further enrich query language features, handle imperfections in event delivery, define correctness guarantees, and define operator semantics. We describe specific contributions made so far and outline next steps in developing the CEDR system.",
            "referenceCount": 14,
            "citationCount": 266,
            "influentialCitationCount": 28,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": "2006-12-21",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Barga2006ConsistentST,\n author = {R. Barga and J. Goldstein and Mohamed H. Ali and Mingsheng Hong},\n booktitle = {Conference on Innovative Data Systems Research},\n pages = {363-374},\n title = {Consistent Streaming Through Time: A Vision for Event Stream Processing},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2f9d2a96a96377eac1c7d93502ea3721f2762f55",
            "@type": "ScholarlyArticle",
            "paperId": "2f9d2a96a96377eac1c7d93502ea3721f2762f55",
            "corpusId": 208022445,
            "url": "https://www.semanticscholar.org/paper/2f9d2a96a96377eac1c7d93502ea3721f2762f55",
            "title": "Cognitive Models of Speech Processing: Psycholinguistic and Computational Perspectives - Workshop Overview",
            "venue": "The AI Magazine",
            "publicationVenue": {
                "id": "urn:research:6fedff74-7525-4b7f-bbb4-4df4e23948e4",
                "name": "The AI Magazine",
                "alternate_names": [
                    "AI Mag",
                    "Ai Mag",
                    "Ai Magazine"
                ],
                "issn": "0738-4602",
                "url": "https://www.aaai.org/Library/Magazine/magazine-library.php"
            },
            "year": 1989,
            "externalIds": {
                "MAG": "304968476",
                "DBLP": "journals/aim/Altmann89",
                "DOI": "10.1609/aimag.v10i4.969",
                "CorpusId": 208022445
            },
            "abstract": "The 1988 Workshop on Cognitive Models of Speech Processing was held at Park Hotel Fiorelle, Sperlonga, Italy, on 16-20 May 1988. Twenty-five participants gathered in this small coastal village, where the Emperor Tiberius once kept a summer house, to discuss psycholinguistic and computational issues in speech and natural language processing.",
            "referenceCount": 0,
            "citationCount": 483,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "1989-11-01",
            "journal": {
                "name": "AI Mag.",
                "volume": "10"
            },
            "citationStyles": {
                "bibtex": "@Article{Altmann1989CognitiveMO,\n author = {G. Altmann},\n booktitle = {The AI Magazine},\n journal = {AI Mag.},\n pages = {20-22},\n title = {Cognitive Models of Speech Processing: Psycholinguistic and Computational Perspectives - Workshop Overview},\n volume = {10},\n year = {1989}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7324f18f8fa0ef857f03ff486df0f2ac51d99afb",
            "@type": "ScholarlyArticle",
            "paperId": "7324f18f8fa0ef857f03ff486df0f2ac51d99afb",
            "corpusId": 17652653,
            "url": "https://www.semanticscholar.org/paper/7324f18f8fa0ef857f03ff486df0f2ac51d99afb",
            "title": "Generating Phrasal and Sentential Paraphrases: A Survey of Data-Driven Methods",
            "venue": "International Conference on Computational Logic",
            "publicationVenue": {
                "id": "urn:research:30a8645d-22d4-42e2-b3f6-304bf4ce3a02",
                "name": "International Conference on Computational Logic",
                "alternate_names": [
                    "CL",
                    "Int Conf Comput Log"
                ],
                "issn": null,
                "url": null
            },
            "year": 2010,
            "externalIds": {
                "DBLP": "journals/coling/MadnaniD10",
                "MAG": "2051593977",
                "ACL": "J10-3003",
                "DOI": "10.1162/coli_a_00002",
                "CorpusId": 17652653
            },
            "abstract": "The task of paraphrasing is inherently familiar to speakers of all languages. Moreover, the task of automatically generating or extracting semantic equivalences for the various units of language\u2014words, phrases, and sentences\u2014is an important part of natural language processing (NLP) and is being increasingly employed to improve the performance of several NLP applications. In this article, we attempt to conduct a comprehensive and application-independent survey of data-driven phrasal and sentential paraphrase generation methods, while also conveying an appreciation for the importance and potential use of paraphrases in the field of NLP research. Recent work done in manual and automatic construction of paraphrase corpora is also examined. We also discuss the strategies used for evaluating paraphrase generation techniques and briefly explore some future trends in paraphrase generation.",
            "referenceCount": 143,
            "citationCount": 299,
            "influentialCitationCount": 11,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.mitpressjournals.org/doi/pdf/10.1162/coli_a_00002",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2010-09-01",
            "journal": {
                "name": "Computational Linguistics",
                "volume": "36"
            },
            "citationStyles": {
                "bibtex": "@Article{Madnani2010GeneratingPA,\n author = {Nitin Madnani and B. Dorr},\n booktitle = {International Conference on Computational Logic},\n journal = {Computational Linguistics},\n pages = {341-387},\n title = {Generating Phrasal and Sentential Paraphrases: A Survey of Data-Driven Methods},\n volume = {36},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:21c7324bb0ed64a2d045a5036a181427919fdecb",
            "@type": "ScholarlyArticle",
            "paperId": "21c7324bb0ed64a2d045a5036a181427919fdecb",
            "corpusId": 7923675,
            "url": "https://www.semanticscholar.org/paper/21c7324bb0ed64a2d045a5036a181427919fdecb",
            "title": "Bayesian Nonparametrics: Hierarchical Bayesian nonparametric models with applications",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2010,
            "externalIds": {
                "MAG": "166614460",
                "DOI": "10.1017/CBO9780511802478.006",
                "CorpusId": 7923675
            },
            "abstract": "Hierarchical modeling is a fundamental concept in Bayesian statistics. The basic idea is that parameters are endowed with distributions which may themselves introduce new parameters, and this construction recurses. In this review we discuss the role of hierarchical modeling in Bayesian nonparametrics, focusing on models in which the infinite-dimensional parameters are treated hierarchically. For example, we consider a model in which the base measure for a Dirichlet process is itself treated as a draw from another Dirichlet process. This yields a natural recursion that we refer to as a hierarchical Dirichlet process. We also discuss hierarchies based on the Pitman-Yor process and on completely random processes. We demonstrate the value of these hierarchical constructions in a wide range of practical applications, in problems in computational biology, computer vision and natural language processing.",
            "referenceCount": 69,
            "citationCount": 269,
            "influentialCitationCount": 15,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.stat.berkeley.edu/tech-reports/770.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Teh2010BayesianNH,\n author = {Y. Teh and Gatsby and Michael I. Jordan},\n title = {Bayesian Nonparametrics: Hierarchical Bayesian nonparametric models with applications},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ceeff20111ac3309c2edb832a0af1784c02bb9ed",
            "@type": "ScholarlyArticle",
            "paperId": "ceeff20111ac3309c2edb832a0af1784c02bb9ed",
            "corpusId": 10348932,
            "url": "https://www.semanticscholar.org/paper/ceeff20111ac3309c2edb832a0af1784c02bb9ed",
            "title": "Temporal Processing with the TARSQI Toolkit",
            "venue": "International Conference on Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:f51ff783-cdff-4e22-94fb-28e6336d17b3",
                "name": "International Conference on Computational Linguistics",
                "alternate_names": [
                    "Int Conf Comput Linguistics",
                    "COLING"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/coling/"
            },
            "year": 2008,
            "externalIds": {
                "MAG": "1523160384",
                "ACL": "C08-3012",
                "DBLP": "conf/coling/VerhagenP08",
                "CorpusId": 10348932
            },
            "abstract": "We present the TARSQI Toolkit (TTK), a modular system for automatic temporal and event annotation of natural language texts. TTK identifies temporal expressions and events in natural language texts, and parses the document to order events and to anchor them to temporal expressions.",
            "referenceCount": 16,
            "citationCount": 112,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2008-08-18",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Verhagen2008TemporalPW,\n author = {M. Verhagen and J. Pustejovsky},\n booktitle = {International Conference on Computational Linguistics},\n pages = {189-192},\n title = {Temporal Processing with the TARSQI Toolkit},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3bf23a5b741f14ad611ba3aa14ba8d541ee01d5e",
            "@type": "ScholarlyArticle",
            "paperId": "3bf23a5b741f14ad611ba3aa14ba8d541ee01d5e",
            "corpusId": 4360854,
            "url": "https://www.semanticscholar.org/paper/3bf23a5b741f14ad611ba3aa14ba8d541ee01d5e",
            "title": "IXA pipeline: Efficient and Ready to Use Multilingual NLP tools",
            "venue": "International Conference on Language Resources and Evaluation",
            "publicationVenue": {
                "id": "urn:research:7474c4a0-75d9-4105-9809-8e7d5201c5e1",
                "name": "International Conference on Language Resources and Evaluation",
                "alternate_names": [
                    "LREC",
                    "Int Conf Lang Resour Evaluation"
                ],
                "issn": null,
                "url": "http://www.lrec-conf.org/"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "conf/lrec/AgerriBR14",
                "ACL": "L14-1605",
                "MAG": "2251463950",
                "CorpusId": 4360854
            },
            "abstract": "IXA pipeline is a modular set of Natural Language Processing tools (or pipes) which provide easy access to NLP technology. It offers robust and efficient linguistic annotation to both researchers and non-NLP experts with the aim of lowering the barriers of using NLP technology either for research purposes or for small industrial developers and SMEs. IXA pipeline can be used \u201cas is\u201d or exploit its modularity to pick and change different components. Given its open-source nature, it can also be modified and extended for it to work with other languages. This paper describes the general data-centric architecture of IXA pipeline and presents competitive results in several NLP annotations for English and Spanish.",
            "referenceCount": 27,
            "citationCount": 136,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2014-05-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Agerri2014IXAPE,\n author = {Rodrigo Agerri and Josu Bermudez and German Rigau},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {3823-3828},\n title = {IXA pipeline: Efficient and Ready to Use Multilingual NLP tools},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fc73f38bbedfc9e81c7da3959f71e25a2678f1b3",
            "@type": "ScholarlyArticle",
            "paperId": "fc73f38bbedfc9e81c7da3959f71e25a2678f1b3",
            "corpusId": 16151068,
            "url": "https://www.semanticscholar.org/paper/fc73f38bbedfc9e81c7da3959f71e25a2678f1b3",
            "title": "A Stochastic Quasi-Newton Method for Online Convex Optimization",
            "venue": "International Conference on Artificial Intelligence and Statistics",
            "publicationVenue": {
                "id": "urn:research:2d136b11-c2b5-484b-b008-7f4a852fd61e",
                "name": "International Conference on Artificial Intelligence and Statistics",
                "alternate_names": [
                    "AISTATS",
                    "Int Conf Artif Intell Stat"
                ],
                "issn": null,
                "url": null
            },
            "year": 2007,
            "externalIds": {
                "DBLP": "journals/jmlr/SchraudolphYG07",
                "MAG": "1491622225",
                "CorpusId": 16151068
            },
            "abstract": "We develop stochastic variants of the wellknown BFGS quasi-Newton optimization method, in both full and memory-limited (LBFGS) forms, for online optimization of convex functions. The resulting algorithm performs comparably to a well-tuned natural gradient descent but is scalable to very high-dimensional problems. On standard benchmarks in natural language processing, it asymptotically outperforms previous stochastic gradient methods for parameter estimation in conditional random fields. We are working on analyzing the convergence of online (L)BFGS, and extending it to nonconvex optimization problems.",
            "referenceCount": 17,
            "citationCount": 387,
            "influentialCitationCount": 33,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2007-03-11",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Schraudolph2007ASQ,\n author = {N. Schraudolph and Jin Yu and Simon G\u00fcnter},\n booktitle = {International Conference on Artificial Intelligence and Statistics},\n pages = {436-443},\n title = {A Stochastic Quasi-Newton Method for Online Convex Optimization},\n year = {2007}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:be75cab7f8acdb3063132751a096b5bfdad193ac",
            "@type": "ScholarlyArticle",
            "paperId": "be75cab7f8acdb3063132751a096b5bfdad193ac",
            "corpusId": 34191712,
            "url": "https://www.semanticscholar.org/paper/be75cab7f8acdb3063132751a096b5bfdad193ac",
            "title": "Dynamic syntax - the flow of language understanding",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2000,
            "externalIds": {
                "MAG": "1560002237",
                "DBLP": "books/daglib/0005780",
                "CorpusId": 34191712
            },
            "abstract": "1.Towards a Syntactic Model of Interpretation. Natural Language as a Formal Language?. Underspecification in Language Processing. The Representational Theory of Mind. Pronominal Anaphora: Semantic Problems. The Problem of Multiple Ambiguity. The Problem of Uniqueness. The Problem of Indirect Reference. Quantification. Syntactic Processes of Anaphora. The Anaphora Solution ---- Towards a Representational Account. 2. The General Framework. A Preliminary Sketch. The Data Structures of the Parsing Model. Atomic Formulae. Tree Modalities. Basic Tree Structures. Partial Tree Structures. Requirements. Descriptions of Tree Structures. 3. The Dynamics of Tree Building. The Parsing Process -- A Sketch. A Basic Example. A Left--Dislocation Example. Verb--final Languages and the Grammar--parser Problem. The Parsing Process Defined. Computational Rules. Lexical Transitions. Pragmatic Actions and Lexical Constraints. Summary. 4. Linked Tree Structures. Relative Clauses ---- Preliminaries. The LINK Relation. The Data Reviewed. The Analysis ---- A Sketch for English. Defining Linked Tree Structures. Relativisers Annotating Unfixed Nodes. Relatives: Towards a Dynamic Typology. Relativisers Projecting a Requirement. Variation in Locality. Topic Structures and Relatives. Variation in Order ---- Head--Final Relatives. Head--internal Relatives. The Potential for Lexical Variation. Genitive Constructions as LINK Structures. Summary. 5. Wh Questions: A General Perspective. Introduction. The Semantic Diversity of wh Questions. Scopal Properties of wh Expressions. Wh--initial vs wh--in--situ Structures. Wh--in--situ Structures. Wh--in--situ from a Dynamic Perspective. Expletive wh Structures. Partial Movement. Partial Movement as a Reflex of a Requirement. Wh Expressions and Scope Effects. 6. Crossover Phenomena. Crossover ---- The Problem. Crossover ---- The Dynamic Account. Crossover in Relatives. Crossover Phenomena in Questions. Summary. 7. Quantification Preliminaries. Introduction. Scope Effects and Indefinites. Quantification. Quantified NPs. Scope. Term Reconstructions. Applications ---- E--type Anaphora. 8. Reflections on Language Design. The Overall Perspective. Underspecification and the Formal Language Metaphor. English is not a Formal Language. Wellformedness and Availability of Interpretations. Universals and Language Variation. On Knowledge of Language. 9. Appendix: The Formal Framework. Introduction. Declarative Structure. Feature Decorated Tree Construction. Goal--directedness. The Structure of Goal--directed Pointed Partial Tree Models. Tree Descriptions. Procedural Structure. Actions over Goal--directed Partial Tree Models. Natural Languages. Axioms. Finite Binary trees. Partial Trees. Requirements. Actions. Partial Order. Logical Forms. Computational Rules. Update Actions. Pragmatic Actions. General Index. Symbol Index.",
            "referenceCount": 0,
            "citationCount": 317,
            "influentialCitationCount": 37,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2000-12-22",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Kempson2000DynamicS,\n author = {Ruth Kempson and W. Meyer-Viol and D. Gabbay},\n pages = {I-XII, 1-348},\n title = {Dynamic syntax - the flow of language understanding},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d4e7f9076d697b14ea800e2b5a88269bd5d96b36",
            "@type": "ScholarlyArticle",
            "paperId": "d4e7f9076d697b14ea800e2b5a88269bd5d96b36",
            "corpusId": 9609288,
            "url": "https://www.semanticscholar.org/paper/d4e7f9076d697b14ea800e2b5a88269bd5d96b36",
            "title": "Restrictions on biological adaptation in language evolution",
            "venue": "Proceedings of the National Academy of Sciences of the United States of America",
            "publicationVenue": {
                "id": "urn:research:bb95bf2e-8383-4748-bf9d-d6906d091085",
                "name": "Proceedings of the National Academy of Sciences of the United States of America",
                "alternate_names": [
                    "PNAS",
                    "PNAS online",
                    "Proceedings of the National Academy of Sciences of the United States of America.",
                    "Proc National Acad Sci",
                    "Proceedings of the National Academy of Sciences",
                    "Proc National Acad Sci u s Am"
                ],
                "issn": "0027-8424",
                "url": "https://www.jstor.org/journal/procnatiacadscie"
            },
            "year": 2009,
            "externalIds": {
                "MAG": "2127103730",
                "DOI": "10.1073/pnas.0807191106",
                "CorpusId": 9609288,
                "PubMed": "19164588"
            },
            "abstract": "Language acquisition and processing are governed by genetic constraints. A crucial unresolved question is how far these genetic constraints have coevolved with language, perhaps resulting in a highly specialized and species-specific language \u201cmodule,\u201d and how much language acquisition and processing redeploy preexisting cognitive machinery. In the present work, we explored the circumstances under which genes encoding language-specific properties could have coevolved with language itself. We present a theoretical model, implemented in computer simulations, of key aspects of the interaction of genes and language. Our results show that genes for language could have coevolved only with highly stable aspects of the linguistic environment; a rapidly changing linguistic environment does not provide a stable target for natural selection. Thus, a biological endowment could not coevolve with properties of language that began as learned cultural conventions, because cultural conventions change much more rapidly than genes. We argue that this rules out the possibility that arbitrary properties of language, including abstract syntactic principles governing phrase structure, case marking, and agreement, have been built into a \u201clanguage module\u201d by natural selection. The genetic basis of human language acquisition and processing did not coevolve with language, but primarily predates the emergence of language. As suggested by Darwin, the fit between language and its underlying mechanisms arose because language has evolved to fit the human brain, rather than the reverse.",
            "referenceCount": 71,
            "citationCount": 148,
            "influentialCitationCount": 8,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc2633574?pdf=render",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2009-01-27",
            "journal": {
                "name": "Proceedings of the National Academy of Sciences",
                "volume": "106"
            },
            "citationStyles": {
                "bibtex": "@Article{Chater2009RestrictionsOB,\n author = {N. Chater and Florencia Reali and Morten H. Christiansen},\n booktitle = {Proceedings of the National Academy of Sciences of the United States of America},\n journal = {Proceedings of the National Academy of Sciences},\n pages = {1015 - 1020},\n title = {Restrictions on biological adaptation in language evolution},\n volume = {106},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9b85157a5c0d2d329046f1fca98b194a3a9053bb",
            "@type": "ScholarlyArticle",
            "paperId": "9b85157a5c0d2d329046f1fca98b194a3a9053bb",
            "corpusId": 89607408,
            "url": "https://www.semanticscholar.org/paper/9b85157a5c0d2d329046f1fca98b194a3a9053bb",
            "title": "PROCESSING COMPLEXITY AND FILLER-GAP DEPENDENCIES ACROSS GRAMMARS",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1999,
            "externalIds": {
                "MAG": "2071641904",
                "DOI": "10.2307/417261",
                "CorpusId": 89607408
            },
            "abstract": "This article examines crosslinguistic variation in FILLER-GAP DEPENDENCIES (wH-questions and relative clauses) from a processing perspective, and integrates research findings from psycholinguistics, language typology and generative grammar. Numerous implicational universals and hierarchies are proposed that receive a natural explanation in terms of processing and complexity. Filler-gap domains are complex in proportion to their size and in proportion to the amount of simultaneous syntactic and semantic processing that is required in addition to gap identification. They are simplified by making the gap easier to identify and process, or by avoiding a gap structure altogether. When grammatical variation is viewed from this perspective many descriptive insights and implicational patterns can be motivated that have either been stipulated or that have gone unnoticed hitherto. This approach provides an alternative to the assumption of innate parameterized subjacency constraints in this area.*",
            "referenceCount": 76,
            "citationCount": 349,
            "influentialCitationCount": 19,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1999-06-01",
            "journal": {
                "name": "Language",
                "volume": "75"
            },
            "citationStyles": {
                "bibtex": "@Article{Hawkins1999PROCESSINGCA,\n author = {J. Hawkins},\n journal = {Language},\n pages = {244-285},\n title = {PROCESSING COMPLEXITY AND FILLER-GAP DEPENDENCIES ACROSS GRAMMARS},\n volume = {75},\n year = {1999}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7784ccf43d4c6f5bcb9f430207ec79278d172dc5",
            "@type": "ScholarlyArticle",
            "paperId": "7784ccf43d4c6f5bcb9f430207ec79278d172dc5",
            "corpusId": 50263509,
            "url": "https://www.semanticscholar.org/paper/7784ccf43d4c6f5bcb9f430207ec79278d172dc5",
            "title": "Parallel Distributed Processing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "CorpusId": 50263509
            },
            "abstract": "What makes people smarter than machines? They certainly are not quicker or more precise. Yet people are far better at perceiving objects in natural scenes and noting their relations , at understanding language and retrieving contextually appropriate information from memory, at making plans and carrying out contextually appropriate actions , and at a wide range of other natural cognitive .tasks. People are also far better at learning to do these things more accurately and fluently through processing experience. What is the basis for these differences? One answer, perhaps the classic one we might expect from artificial intelligence , is \" software.\" If we only had the right computer program, the argument goes , we might be able to capture the fluidity and adaptability of human information proceSSIng. Certainly this answer is partially correct. There have been great breakthroughs in our understanding of cognition as a result of the development of expressive highlevel computer languages and powerful algorithms. No doubt there will be more such breakthroughs in the",
            "referenceCount": 0,
            "citationCount": 270,
            "influentialCitationCount": 7,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{McClelland2005ParallelDP,\n author = {James L. McClelland},\n title = {Parallel Distributed Processing},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9b032a1f1a64ceaa36f473625ff05ad2a7a27e0a",
            "@type": "ScholarlyArticle",
            "paperId": "9b032a1f1a64ceaa36f473625ff05ad2a7a27e0a",
            "corpusId": 141626512,
            "url": "https://www.semanticscholar.org/paper/9b032a1f1a64ceaa36f473625ff05ad2a7a27e0a",
            "title": "Approaches to studying world-situated language use : bridging the language-as-product and language-as-action traditions",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "MAG": "600536299",
                "CorpusId": 141626512
            },
            "abstract": "Recent approaches to language processing have focused either on individual cognitive processes in producing and understanding language or on social cognitive factors in interactive conversation. Although the cognitive and social approaches to language processing would seem to have little theoretical or methodological common ground, the goal of this book is to encourage the merging of these two traditions. The contributors to this volume hope to demonstrate that attention to both cognitive and social approaches is important for understanding how language is processed in natural settings.The book opens with four review/position papers; these are followed by shorter reports of experimental findings -- \"a snapshot of current work that begins to bridge the product and action traditions.\" These treat linguistic processing issues in conversational settings, the interactions of language and nonlinguistic information from visual scenes, product approaches to issues traditionally discussed in the action tradition, and Gricean phenomena.",
            "referenceCount": 0,
            "citationCount": 261,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Trueswell2005ApproachesTS,\n author = {J. Trueswell and M. Tanenhaus},\n title = {Approaches to studying world-situated language use : bridging the language-as-product and language-as-action traditions},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3caf81efd058062b839d1e07a564a66d2457c412",
            "@type": "ScholarlyArticle",
            "paperId": "3caf81efd058062b839d1e07a564a66d2457c412",
            "corpusId": 62245406,
            "url": "https://www.semanticscholar.org/paper/3caf81efd058062b839d1e07a564a66d2457c412",
            "title": "Language in Action: Categories, Lambdas and Dynamic Logic",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1997,
            "externalIds": {
                "MAG": "130150459",
                "DOI": "10.2307/416057",
                "CorpusId": 62245406
            },
            "abstract": "Language in Action demonstrates the viability of mathematical research into the foundations of categorial grammar, a topic at the border between logic and linguistics. Since its initial publication it has become the classic work in the foundations of categorial grammar. A new introduction to this paperback edition updates the open research problems and records relevant results through pointers to the literature.Van Benthem presents the categorial processing of syntax and semantics as a central component in a more general dynamic logic of information flow, in tune with computational developments in artificial intelligence and cognitive science. Using the paradigm of categorial grammar, he describes the substructural logics driving the dynamics of natural language syntax and semantics. This is a general type-theoretic approach that lends itself easily to proof-theoretic and semantic studies in tandem with standard logic. The emphasis is on a broad landscape of substructural categorial logics and their proof-theoretical and semantic peculiarities. This provides a systematic theory for natural language understanding, admitting of significant mathematical results. Moreover, the theory makes possible dynamic interpretations that view natural languages as programming formalisms for various cognitive activities.",
            "referenceCount": 0,
            "citationCount": 331,
            "influentialCitationCount": 14,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1997-06-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Benthem1997LanguageIA,\n author = {J. Benthem},\n title = {Language in Action: Categories, Lambdas and Dynamic Logic},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9f6d90b5c974a11d271e2171d0f9d0198fe3c55c",
            "@type": "ScholarlyArticle",
            "paperId": "9f6d90b5c974a11d271e2171d0f9d0198fe3c55c",
            "corpusId": 11636573,
            "url": "https://www.semanticscholar.org/paper/9f6d90b5c974a11d271e2171d0f9d0198fe3c55c",
            "title": "Foma: a Finite-State Compiler and Library",
            "venue": "Conference of the European Chapter of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:8de18c35-6785-4e54-99f2-21ee961302c6",
                "name": "Conference of the European Chapter of the Association for Computational Linguistics",
                "alternate_names": [
                    "Conf Eur Chapter Assoc Comput Linguistics",
                    "EACL"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/eacl/"
            },
            "year": 2009,
            "externalIds": {
                "DBLP": "conf/eacl/Hulden09",
                "ACL": "E09-2008",
                "MAG": "2014611589",
                "DOI": "10.3115/1609049.1609057",
                "CorpusId": 11636573
            },
            "abstract": "Foma is a compiler, programming language, and C library for constructing finite-state automata and transducers for various uses. It has specific support for many natural language processing applications such as producing morphological and phonological analyzers. Foma is largely compatible with the Xerox/PARC finite-state toolkit. It also embraces Unicode fully and supports various different formats for specifying regular expressions: the Xerox/PARC format, a Perl-like format, and a mathematical format that takes advantage of the 'Mathematical Operators' Unicode block.",
            "referenceCount": 6,
            "citationCount": 276,
            "influentialCitationCount": 34,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.5555/1609049.1609057",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2009-04-03",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hulden2009FomaAF,\n author = {Mans Hulden},\n booktitle = {Conference of the European Chapter of the Association for Computational Linguistics},\n pages = {29-32},\n title = {Foma: a Finite-State Compiler and Library},\n year = {2009}\n}\n"
            }
        }
    }
]