[
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:069e0d896da7c79faeee4cf057548d5da7ce885e",
            "@type": "ScholarlyArticle",
            "paperId": "069e0d896da7c79faeee4cf057548d5da7ce885e",
            "corpusId": 209202658,
            "url": "https://www.semanticscholar.org/paper/069e0d896da7c79faeee4cf057548d5da7ce885e",
            "title": "FlauBERT: Unsupervised Language Model Pre-training for French",
            "venue": "International Conference on Language Resources and Evaluation",
            "publicationVenue": {
                "id": "urn:research:7474c4a0-75d9-4105-9809-8e7d5201c5e1",
                "name": "International Conference on Language Resources and Evaluation",
                "alternate_names": [
                    "LREC",
                    "Int Conf Lang Resour Evaluation"
                ],
                "issn": null,
                "url": "http://www.lrec-conf.org/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "3032532958",
                "DBLP": "conf/lrec/LeVFSCLACBS20",
                "ACL": "2020.lrec-1.302",
                "ArXiv": "1912.05372",
                "CorpusId": 209202658
            },
            "abstract": "Language models have become a key step to achieve state-of-the art results in many different Natural Language Processing (NLP) tasks. Leveraging the huge amount of unlabeled texts nowadays available, they provide an efficient way to pre-train continuous word representations that can be fine-tuned for a downstream task, along with their contextualization at the sentence level. This has been widely demonstrated for English using contextualized representations (Dai and Le, 2015; Peters et al., 2018; Howard and Ruder, 2018; Radford et al., 2018; Devlin et al., 2019; Yang et al., 2019b). In this paper, we introduce and share FlauBERT, a model learned on a very large and heterogeneous French corpus. Models of different sizes are trained using the new CNRS (French National Centre for Scientific Research) Jean Zay supercomputer. We apply our French language models to diverse NLP tasks (text classification, paraphrasing, natural language inference, parsing, word sense disambiguation) and show that most of the time they outperform other pre-training approaches. Different versions of FlauBERT as well as a unified evaluation protocol for the downstream tasks, called FLUE (French Language Understanding Evaluation), are shared to the research community for further reproducible experiments in French NLP.",
            "referenceCount": 81,
            "citationCount": 301,
            "influentialCitationCount": 47,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-12-11",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1912.05372"
            },
            "citationStyles": {
                "bibtex": "@Article{Le2019FlauBERTUL,\n author = {Hang Le and Lo\u00efc Vial and Jibril Frej and V. Segonne and Maximin Coavoux and B. Lecouteux and A. Allauzen and Benoit Crabb'e and L. Besacier and D. Schwab},\n booktitle = {International Conference on Language Resources and Evaluation},\n journal = {ArXiv},\n title = {FlauBERT: Unsupervised Language Model Pre-training for French},\n volume = {abs/1912.05372},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:893186c6bc08a17cb3f9f94fa3f14e9ad20b0525",
            "@type": "ScholarlyArticle",
            "paperId": "893186c6bc08a17cb3f9f94fa3f14e9ad20b0525",
            "corpusId": 46979001,
            "url": "https://www.semanticscholar.org/paper/893186c6bc08a17cb3f9f94fa3f14e9ad20b0525",
            "title": "Speaker-Follower Models for Vision-and-Language Navigation",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "conf/nips/FriedHCRAMBSKD18",
                "ArXiv": "1806.02724",
                "MAG": "2805984364",
                "CorpusId": 46979001
            },
            "abstract": "Navigation guided by natural language instructions presents a challenging reasoning problem for instruction followers. Natural language instructions typically identify only a few high-level decisions and landmarks rather than complete low-level motor behaviors; much of the missing information must be inferred based on perceptual context. In machine learning settings, this is doubly challenging: it is difficult to collect enough annotated data to enable learning of this reasoning process from scratch, and also difficult to implement the reasoning process using generic sequence models. Here we describe an approach to vision-and-language navigation that addresses both these issues with an embedded speaker model. We use this speaker model to (1) synthesize new instructions for data augmentation and to (2) implement pragmatic reasoning, which evaluates how well candidate action sequences explain an instruction. Both steps are supported by a panoramic action space that reflects the granularity of human-generated instructions. Experiments show that all three components of this approach---speaker-driven data augmentation, pragmatic reasoning and panoramic action space---dramatically improve the performance of a baseline instruction follower, more than doubling the success rate over the best existing approach on a standard benchmark.",
            "referenceCount": 61,
            "citationCount": 386,
            "influentialCitationCount": 103,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-06-01",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1806.02724"
            },
            "citationStyles": {
                "bibtex": "@Article{Fried2018SpeakerFollowerMF,\n author = {Daniel Fried and Ronghang Hu and Volkan Cirik and Anna Rohrbach and Jacob Andreas and Louis-Philippe Morency and Taylor Berg-Kirkpatrick and Kate Saenko and D. Klein and Trevor Darrell},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Speaker-Follower Models for Vision-and-Language Navigation},\n volume = {abs/1806.02724},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c5f5bb3131f5f1082bd82cce8a0ac08dea1e9366",
            "@type": "ScholarlyArticle",
            "paperId": "c5f5bb3131f5f1082bd82cce8a0ac08dea1e9366",
            "corpusId": 246647,
            "url": "https://www.semanticscholar.org/paper/c5f5bb3131f5f1082bd82cce8a0ac08dea1e9366",
            "title": "UDPipe: Trainable Pipeline for Processing CoNLL-U Files Performing Tokenization, Morphological Analysis, POS Tagging and Parsing",
            "venue": "International Conference on Language Resources and Evaluation",
            "publicationVenue": {
                "id": "urn:research:7474c4a0-75d9-4105-9809-8e7d5201c5e1",
                "name": "International Conference on Language Resources and Evaluation",
                "alternate_names": [
                    "LREC",
                    "Int Conf Lang Resour Evaluation"
                ],
                "issn": null,
                "url": "http://www.lrec-conf.org/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2574640638",
                "DBLP": "conf/lrec/StrakaHS16",
                "ACL": "L16-1680",
                "CorpusId": 246647
            },
            "abstract": "Automatic natural language processing of large texts often presents recurring challenges in multiple languages: even for most advanced tasks, the texts are first processed by basic processing steps \u2013 from tokenization to parsing. We present an extremely simple-to-use tool consisting of one binary and one model (per language), which performs these tasks for multiple languages without the need for any other external data. UDPipe, a pipeline processing CoNLL-U-formatted files, performs tokenization, morphological analysis, part-of-speech tagging, lemmatization and dependency parsing for nearly all treebanks of Universal Dependencies 1.2 (namely, the whole pipeline is currently available for 32 out of 37 treebanks). In addition, the pipeline is easily trainable with training data in CoNLL-U format (and in some cases also with additional raw corpora) and requires minimal linguistic knowledge on the users\u2019 part. The training code is also released.",
            "referenceCount": 25,
            "citationCount": 386,
            "influentialCitationCount": 100,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-05-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Straka2016UDPipeTP,\n author = {Milan Straka and Jan Hajic and Jana Strakov\u00e1},\n booktitle = {International Conference on Language Resources and Evaluation},\n pages = {4290-4297},\n title = {UDPipe: Trainable Pipeline for Processing CoNLL-U Files Performing Tokenization, Morphological Analysis, POS Tagging and Parsing},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bc23dfb70e109dbe666b979f995e2779b96e1073",
            "@type": "ScholarlyArticle",
            "paperId": "bc23dfb70e109dbe666b979f995e2779b96e1073",
            "corpusId": 213739887,
            "url": "https://www.semanticscholar.org/paper/bc23dfb70e109dbe666b979f995e2779b96e1073",
            "title": "Robots That Use Language",
            "venue": "Annu. Rev. Control. Robotics Auton. Syst.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/arcras/TellexGKM20",
                "MAG": "3003205975",
                "DOI": "10.1146/annurev-control-101119-071628",
                "CorpusId": 213739887
            },
            "abstract": "This article surveys the use of natural language in robotics from a robotics point of view. To use human language, robots must map words to aspects of the physical world, mediated by the robot's sensors and actuators. This problem differs from other natural language processing domains due to the need to ground the language to noisy percepts and physical actions. Here, we describe central aspects of language use by robots, including understanding natural language requests, using language to drive learning about the physical world, and engaging in collaborative dialogue with a human partner. We describe common approaches, roughly divided into learning methods, logic-based methods, and methods that focus on questions of human\u2013robot interaction. Finally, we describe several application domains for language-using robots.",
            "referenceCount": 192,
            "citationCount": 140,
            "influentialCitationCount": 8,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://mdsoar.org/bitstream/11603/19469/1/annurev-control-101119-071628.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-05-03",
            "journal": {
                "name": "Annu. Rev. Control. Robotics Auton. Syst.",
                "volume": "3"
            },
            "citationStyles": {
                "bibtex": "@Article{Tellex2020RobotsTU,\n author = {Stefanie Tellex and N. Gopalan and H. Kress-Gazit and Cynthia Matuszek},\n booktitle = {Annu. Rev. Control. Robotics Auton. Syst.},\n journal = {Annu. Rev. Control. Robotics Auton. Syst.},\n pages = {25-55},\n title = {Robots That Use Language},\n volume = {3},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:22d77807b5ba35cab90f4eaf1f2b68a55852221b",
            "@type": "ScholarlyArticle",
            "paperId": "22d77807b5ba35cab90f4eaf1f2b68a55852221b",
            "corpusId": 1631332,
            "url": "https://www.semanticscholar.org/paper/22d77807b5ba35cab90f4eaf1f2b68a55852221b",
            "title": "Process Model Generation from Natural Language Text",
            "venue": "International Conference on Advanced Information Systems Engineering",
            "publicationVenue": {
                "id": "urn:research:91785da4-7c6a-4e13-936c-0a801a1ef895",
                "name": "International Conference on Advanced Information Systems Engineering",
                "alternate_names": [
                    "Int Conf Adv Inf Syst Eng",
                    "Conference on Advanced Information Systems Engineering",
                    "CAiSE",
                    "Conf Adv Inf Syst Eng"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/caise"
            },
            "year": 2011,
            "externalIds": {
                "MAG": "207431025",
                "DBLP": "conf/caise/FriedrichMP11",
                "DOI": "10.1007/978-3-642-21640-4_36",
                "CorpusId": 1631332
            },
            "abstract": null,
            "referenceCount": 41,
            "citationCount": 234,
            "influentialCitationCount": 21,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007%2F978-3-642-21640-4_36.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Business",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2011-06-20",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Friedrich2011ProcessMG,\n author = {Fabian Friedrich and J. Mendling and Frank Puhlmann},\n booktitle = {International Conference on Advanced Information Systems Engineering},\n pages = {482-496},\n title = {Process Model Generation from Natural Language Text},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:47570e7f63e296f224a0e7f9a0d08b0de3cbaf40",
            "@type": "ScholarlyArticle",
            "paperId": "47570e7f63e296f224a0e7f9a0d08b0de3cbaf40",
            "corpusId": 14223,
            "url": "https://www.semanticscholar.org/paper/47570e7f63e296f224a0e7f9a0d08b0de3cbaf40",
            "title": "Grammar as a Foreign Language",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "conf/nips/VinyalsKKPSH15",
                "MAG": "2951648188",
                "ArXiv": "1412.7449",
                "CorpusId": 14223
            },
            "abstract": "Syntactic constituency parsing is a fundamental problem in natural language processing and has been the subject of intensive research and engineering for decades. As a result, the most accurate parsers are domain specific, complex, and inefficient. In this paper we show that the domain agnostic attention-enhanced sequence-to-sequence model achieves state-of-the-art results on the most widely used syntactic constituency parsing dataset, when trained on a large synthetic corpus that was annotated using existing parsers. It also matches the performance of standard parsers when trained only on a small human-annotated dataset, which shows that this model is highly data-efficient, in contrast to sequence-to-sequence models without the attention mechanism. Our parser is also fast, processing over a hundred sentences per second with an unoptimized CPU implementation.",
            "referenceCount": 35,
            "citationCount": 892,
            "influentialCitationCount": 104,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-12-23",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1412.7449"
            },
            "citationStyles": {
                "bibtex": "@Article{Vinyals2014GrammarAA,\n author = {Oriol Vinyals and Lukasz Kaiser and Terry Koo and Slav Petrov and Ilya Sutskever and Geoffrey E. Hinton},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Grammar as a Foreign Language},\n volume = {abs/1412.7449},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5d2f5c2dc11c18c0d45203e2b980fe375a56d774",
            "@type": "ScholarlyArticle",
            "paperId": "5d2f5c2dc11c18c0d45203e2b980fe375a56d774",
            "corpusId": 13548281,
            "url": "https://www.semanticscholar.org/paper/5d2f5c2dc11c18c0d45203e2b980fe375a56d774",
            "title": "Emergence of Grounded Compositional Language in Multi-Agent Populations",
            "venue": "AAAI Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:bdc2e585-4e48-4e36-8af1-6d859763d405",
                "name": "AAAI Conference on Artificial Intelligence",
                "alternate_names": [
                    "National Conference on Artificial Intelligence",
                    "National Conf Artif Intell",
                    "AAAI Conf Artif Intell",
                    "AAAI"
                ],
                "issn": null,
                "url": "http://www.aaai.org/"
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1703.04908",
                "MAG": "2602275733",
                "DBLP": "journals/corr/MordatchA17",
                "DOI": "10.1609/aaai.v32i1.11492",
                "CorpusId": 13548281
            },
            "abstract": "\n \n By capturing statistical patterns in large corpora, machine learning has enabled significant advances in natural language processing, including in machine translation, question answering, and sentiment analysis. However, for agents to intelligently interact with humans, simply capturing the statistical patterns is insufficient. In this paper we investigate if, and how, grounded compositional language can emerge as a means to achieve goals in multi-agent populations. Towards this end, we propose a multi-agent learning environment and learning methods that bring about emergence of a basic compositional language. This language is represented as streams of abstract discrete symbols uttered by agents over time, but nonetheless has a coherent structure that possesses a defined vocabulary and syntax. We also observe emergence of non-verbal communication such as pointing and guiding when language communication is unavailable.\n \n",
            "referenceCount": 39,
            "citationCount": 586,
            "influentialCitationCount": 51,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ojs.aaai.org/index.php/AAAI/article/download/11492/11351",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-03-15",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Mordatch2017EmergenceOG,\n author = {Igor Mordatch and P. Abbeel},\n booktitle = {AAAI Conference on Artificial Intelligence},\n pages = {1495-1502},\n title = {Emergence of Grounded Compositional Language in Multi-Agent Populations},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0ae8715044f270f0032f71ee369a3008363cb048",
            "@type": "ScholarlyArticle",
            "paperId": "0ae8715044f270f0032f71ee369a3008363cb048",
            "corpusId": 9170792,
            "url": "https://www.semanticscholar.org/paper/0ae8715044f270f0032f71ee369a3008363cb048",
            "title": "Wikipedia Vandalism Detection: Combining Natural Language, Metadata, and Reputation Features",
            "venue": "Conference on Intelligent Text Processing and Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:a1c1b2d2-5629-4b8f-b764-20ea10fa588c",
                "name": "Conference on Intelligent Text Processing and Computational Linguistics",
                "alternate_names": [
                    "Conf Intell Text Process Comput Linguistics",
                    "CICLing"
                ],
                "issn": null,
                "url": "http://www.cicling.org/"
            },
            "year": 2011,
            "externalIds": {
                "MAG": "2148517649",
                "DBLP": "conf/cicling/AdlerAMRW11",
                "DOI": "10.1007/978-3-642-19437-5_23",
                "CorpusId": 9170792
            },
            "abstract": null,
            "referenceCount": 28,
            "citationCount": 145,
            "influentialCitationCount": 22,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://riunet.upv.es/bitstream/10251/36621/2/Wikipedia%20vandalism%20detection.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2011-02-20",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Adler2011WikipediaVD,\n author = {B. Adler and L. D. Alfaro and S. M. Mola-Velasco and Paolo Rosso and Andrew G. West},\n booktitle = {Conference on Intelligent Text Processing and Computational Linguistics},\n pages = {277-288},\n title = {Wikipedia Vandalism Detection: Combining Natural Language, Metadata, and Reputation Features},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:eabbf28902292c8e4aefd282cbe61113a14d7621",
            "@type": "ScholarlyArticle",
            "paperId": "eabbf28902292c8e4aefd282cbe61113a14d7621",
            "corpusId": 13396177,
            "url": "https://www.semanticscholar.org/paper/eabbf28902292c8e4aefd282cbe61113a14d7621",
            "title": "PowerGraph: Distributed Graph-Parallel Computation on Natural Graphs",
            "venue": "USENIX Symposium on Operating Systems Design and Implementation",
            "publicationVenue": {
                "id": "urn:research:86c43745-31d9-4c1a-b33f-ce3aa0042dbb",
                "name": "USENIX Symposium on Operating Systems Design and Implementation",
                "alternate_names": [
                    "Oper Syst Des Implement",
                    "Operating Systems Design and Implementation",
                    "OSDI",
                    "USENIX Symp Oper Syst Des Implement"
                ],
                "issn": null,
                "url": null
            },
            "year": 2012,
            "externalIds": {
                "MAG": "78077100",
                "DBLP": "conf/osdi/GonzalezLGBG12",
                "CorpusId": 13396177
            },
            "abstract": "Large-scale graph-structured computation is central to tasks ranging from targeted advertising to natural language processing and has led to the development of several graph-parallel abstractions including Pregel and GraphLab. However, the natural graphs commonly found in the real-world have highly skewed power-law degree distributions, which challenge the assumptions made by these abstractions, limiting performance and scalability. \n \nIn this paper, we characterize the challenges of computation on natural graphs in the context of existing graph-parallel abstractions. We then introduce the PowerGraph abstraction which exploits the internal structure of graph programs to address these challenges. Leveraging the PowerGraph abstraction we introduce a new approach to distributed graph placement and representation that exploits the structure of power-law graphs. We provide a detailed analysis and experimental evaluation comparing PowerGraph to two popular graph-parallel systems. Finally, we describe three different implementation strategies for PowerGraph and discuss their relative merits with empirical evaluations on large-scale real-world problems demonstrating order of magnitude gains.",
            "referenceCount": 42,
            "citationCount": 1817,
            "influentialCitationCount": 416,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2012-10-08",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gonzalez2012PowerGraphDG,\n author = {Joseph E. Gonzalez and Yucheng Low and Haijie Gu and Danny Bickson and Carlos Guestrin},\n booktitle = {USENIX Symposium on Operating Systems Design and Implementation},\n pages = {17-30},\n title = {PowerGraph: Distributed Graph-Parallel Computation on Natural Graphs},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e0508665054689834a5b10d882700e8b50038fee",
            "@type": "ScholarlyArticle",
            "paperId": "e0508665054689834a5b10d882700e8b50038fee",
            "corpusId": 7827661,
            "url": "https://www.semanticscholar.org/paper/e0508665054689834a5b10d882700e8b50038fee",
            "title": "The Natural Language of Playlists",
            "venue": "International Society for Music Information Retrieval Conference",
            "publicationVenue": {
                "id": "urn:research:cfc287e4-4c04-4848-ab16-633b33a61a09",
                "name": "International Society for Music Information Retrieval Conference",
                "alternate_names": [
                    "International Symposium/Conference on Music Information Retrieval",
                    "ISMIR",
                    "Int Soc Music Inf Retr Conf",
                    "Int Symp Music Inf Retr"
                ],
                "issn": null,
                "url": "http://www.ismir.net/"
            },
            "year": 2011,
            "externalIds": {
                "DBLP": "conf/ismir/McFeeL11a",
                "MAG": "2295247772",
                "CorpusId": 7827661
            },
            "abstract": "We propose a simple, scalable, and objective evaluation procedure for playlist generation algorithms. Drawing on standard techniques for statistical natural language processing, we characterize playlist algorithms as generative models of strings of songs belonging to some unknown language. To demonstrate the procedure, we compare several playlist algorithms derived from content, semantics, and meta-data. We then develop an efficient algorithm to learn an optimal combination of simple playlist algorithms. Experiments on a large collection of naturally occurring playlists demonstrate the efficacy of the evaluation procedure and learning algorithm.",
            "referenceCount": 21,
            "citationCount": 111,
            "influentialCitationCount": 18,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{McFee2011TheNL,\n author = {Brian McFee and Gert R. G. Lanckriet},\n booktitle = {International Society for Music Information Retrieval Conference},\n pages = {537-542},\n title = {The Natural Language of Playlists},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c60b11d0708714809d374074c745d935de563057",
            "@type": "ScholarlyArticle",
            "paperId": "c60b11d0708714809d374074c745d935de563057",
            "corpusId": 207079169,
            "url": "https://www.semanticscholar.org/paper/c60b11d0708714809d374074c745d935de563057",
            "title": "A survey of grammatical inference methods for natural language learning",
            "venue": "Artificial Intelligence Review",
            "publicationVenue": {
                "id": "urn:research:ea8553fe-2467-4367-afee-c4deb3754820",
                "name": "Artificial Intelligence Review",
                "alternate_names": [
                    "Artif Intell Rev"
                ],
                "issn": "0269-2821",
                "url": "https://link.springer.com/journal/10462"
            },
            "year": 2011,
            "externalIds": {
                "DBLP": "journals/air/DUliziaFG11",
                "MAG": "2046432510",
                "DOI": "10.1007/s10462-010-9199-1",
                "CorpusId": 207079169
            },
            "abstract": null,
            "referenceCount": 48,
            "citationCount": 80,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2011-06-01",
            "journal": {
                "name": "Artificial Intelligence Review",
                "volume": "36"
            },
            "citationStyles": {
                "bibtex": "@Article{D\u2019ulizia2011ASO,\n author = {Arianna D\u2019ulizia and F. Ferri and P. Grifoni},\n booktitle = {Artificial Intelligence Review},\n journal = {Artificial Intelligence Review},\n pages = {1-27},\n title = {A survey of grammatical inference methods for natural language learning},\n volume = {36},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7721319d1a55632f20517a4f3b4d220b0be544c5",
            "@type": "ScholarlyArticle",
            "paperId": "7721319d1a55632f20517a4f3b4d220b0be544c5",
            "corpusId": 9333371,
            "url": "https://www.semanticscholar.org/paper/7721319d1a55632f20517a4f3b4d220b0be544c5",
            "title": "Artificial Intelligence and Language Processing Talking to Unix in English: an Overview of Uc",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": null,
            "externalIds": {
                "CorpusId": 9333371
            },
            "abstract": "UC is a natural language help facility which advises users in using the UNIX operating system. Users can query UC about how to do things, command names and formats, online definitions of UNIX or general operating systems terminology, and debugging problems in using commands. UC is comprised of the following components: a language analyzer and generator, a context and memory model an experimental common-sense planner, highly extensible knowledge bases on both the UNIX domain and the English language, a goal analysis component, and a system for acquisition of new knowledge through instruction in English. The language interface of UC is based on a \"phrasal analysis\" approach which integrates semantic, grammatical and other types of information. In addition, it includes capabilities for ellipsis resolution and reference disambiguation.",
            "referenceCount": 33,
            "citationCount": 232,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Misc{None,\n author = {David Waltz Editor and Robert Wllensky and Yigal Arens and David N. Chin},\n title = {Artificial Intelligence and Language Processing Talking to Unix in English: an Overview of Uc}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d58ecdc6d40fe401903930f74b82614bf833fd56",
            "@type": "ScholarlyArticle",
            "paperId": "d58ecdc6d40fe401903930f74b82614bf833fd56",
            "corpusId": 9283262,
            "url": "https://www.semanticscholar.org/paper/d58ecdc6d40fe401903930f74b82614bf833fd56",
            "title": "Structure Discovery in Natural Language",
            "venue": "Theory and Applications of Natural Language Processing",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2011,
            "externalIds": {
                "MAG": "643027706",
                "DBLP": "books/daglib/0033302",
                "DOI": "10.1007/978-3-642-25923-4",
                "CorpusId": 9283262
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 35,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/bfm:978-3-642-25923-4/1?pdf=chapter%20toc",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2011-12-08",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Biemann2011StructureDI,\n author = {Chris Biemann},\n booktitle = {Theory and Applications of Natural Language Processing},\n pages = {I-XX, 1-178},\n title = {Structure Discovery in Natural Language},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c7fd5973a2cb3f7c6a5df0120400bc47b2f2bacf",
            "@type": "ScholarlyArticle",
            "paperId": "c7fd5973a2cb3f7c6a5df0120400bc47b2f2bacf",
            "corpusId": 201645446,
            "url": "https://www.semanticscholar.org/paper/c7fd5973a2cb3f7c6a5df0120400bc47b2f2bacf",
            "title": "Sign Language Recognition, Generation, and Translation: An Interdisciplinary Perspective",
            "venue": "International ACM SIGACCESS Conference on Computers and Accessibility",
            "publicationVenue": {
                "id": "urn:research:6864fc0f-dd47-4798-a829-ac53dd78862f",
                "name": "International ACM SIGACCESS Conference on Computers and Accessibility",
                "alternate_names": [
                    "Conference on Computers and Accessibility",
                    "Conf Comput Access",
                    "Int ACM SIGACCESS Conf Comput Access",
                    "ASSETS"
                ],
                "issn": null,
                "url": "https://dl.acm.org/conference/assets"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2968458594",
                "ArXiv": "1908.08597",
                "DBLP": "conf/assets/BraggKBBBBCHKVV19",
                "DOI": "10.1145/3308561.3353774",
                "CorpusId": 201645446
            },
            "abstract": "Developing successful sign language recognition, generation, and translation systems requires expertise in a wide range of fields, including computer vision, computer graphics, natural language processing, human-computer interaction, linguistics, and Deaf culture. Despite the need for deep interdisciplinary knowledge, existing research occurs in separate disciplinary silos, and tackles separate portions of the sign language processing pipeline. This leads to three key questions: 1) What does an interdisciplinary view of the current landscape reveal? 2) What are the biggest challenges facing the field? and 3) What are the calls to action for people working in the field? To help answer these questions, we brought together a diverse group of experts for a two-day workshop. This paper presents the results of that interdisciplinary workshop, providing key background that is often overlooked by computer scientists, a review of the state-of-the-art, a set of pressing challenges, and a call to action for the research community.",
            "referenceCount": 160,
            "citationCount": 247,
            "influentialCitationCount": 15,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/3308561.3353774",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": "2019-08-22",
            "journal": {
                "name": "Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Bragg2019SignLR,\n author = {Danielle Bragg and Oscar Koller and Mary Bellard and Larwan Berke and Patrick Boudreault and Annelies Braffort and Naomi K. Caselli and Matt Huenerfauth and Hernisa Kacorri and T. Verhoef and Christian Vogler and M. Morris},\n booktitle = {International ACM SIGACCESS Conference on Computers and Accessibility},\n journal = {Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility},\n title = {Sign Language Recognition, Generation, and Translation: An Interdisciplinary Perspective},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:88613469cb9faf3cc5f5676169b9e558957f24ab",
            "@type": "ScholarlyArticle",
            "paperId": "88613469cb9faf3cc5f5676169b9e558957f24ab",
            "corpusId": 7428261,
            "url": "https://www.semanticscholar.org/paper/88613469cb9faf3cc5f5676169b9e558957f24ab",
            "title": "Cortical oscillations and speech processing: emerging computational principles and operations",
            "venue": "Nature Neuroscience",
            "publicationVenue": {
                "id": "urn:research:7892f01e-f701-4d07-8c36-e108b84ec6ab",
                "name": "Nature Neuroscience",
                "alternate_names": [
                    "Nat Neurosci"
                ],
                "issn": "1097-6256",
                "url": "http://www.nature.com/neuro/"
            },
            "year": 2012,
            "externalIds": {
                "MAG": "2056486423",
                "DOI": "10.1038/nn.3063",
                "CorpusId": 7428261,
                "PubMed": "22426255"
            },
            "abstract": null,
            "referenceCount": 50,
            "citationCount": 1394,
            "influentialCitationCount": 90,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://archive-ouverte.unige.ch/unige:26184/ATTACHMENT01",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2012-03-18",
            "journal": {
                "name": "Nature Neuroscience",
                "volume": "15"
            },
            "citationStyles": {
                "bibtex": "@Article{Giraud2012CorticalOA,\n author = {A. Giraud and D. Poeppel},\n booktitle = {Nature Neuroscience},\n journal = {Nature Neuroscience},\n pages = {511-517},\n title = {Cortical oscillations and speech processing: emerging computational principles and operations},\n volume = {15},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:558786e225e944c587a3c78b544cb126aefae7f7",
            "@type": "ScholarlyArticle",
            "paperId": "558786e225e944c587a3c78b544cb126aefae7f7",
            "corpusId": 8830314,
            "url": "https://www.semanticscholar.org/paper/558786e225e944c587a3c78b544cb126aefae7f7",
            "title": "FreeLing 2.1: Five Years of Open-source Language Processing Tools",
            "venue": "International Conference on Language Resources and Evaluation",
            "publicationVenue": {
                "id": "urn:research:7474c4a0-75d9-4105-9809-8e7d5201c5e1",
                "name": "International Conference on Language Resources and Evaluation",
                "alternate_names": [
                    "LREC",
                    "Int Conf Lang Resour Evaluation"
                ],
                "issn": null,
                "url": "http://www.lrec-conf.org/"
            },
            "year": 2010,
            "externalIds": {
                "ACL": "L10-1002",
                "MAG": "1595961126",
                "DBLP": "conf/lrec/PadroCRLC10",
                "CorpusId": 8830314
            },
            "abstract": "FreeLing is an open-source multilingual language processing library providing a wide range of language analyzers for several languages. It offers text processing and language annotation facilities to natural language processing application developers, simplifying the task of building those applications. FreeLing is customizable and extensible. Developers can use the default linguistic resources (dictionaries, lexicons, grammars, etc.) directly, or extend them, adapt them to specific domains, or even develop new ones for specific languages. This paper overviews the recent history of this tool, summarizes the improvements and extensions incorporated in the latest version, and depicts the architecture of the library. Special focus is brought to the fact and consequences of the library being open-source: After five years and over 35,000 downloads, a growing user community has extended the initial threelanguages (English, Spanish and Catalan) to eight (adding Galician, Italian, Welsh, Portuguese, and Asturian), proving that the collaborative open model is a productive approach for the development of NLP tools and resources.",
            "referenceCount": 14,
            "citationCount": 154,
            "influentialCitationCount": 19,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2010-05-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Padr\u00f32010FreeLing2F,\n author = {Llu\u00eds Padr\u00f3 and M. Collado and S. Reese and Marina Lloberes and Irene Castell\u00f3n},\n booktitle = {International Conference on Language Resources and Evaluation},\n title = {FreeLing 2.1: Five Years of Open-source Language Processing Tools},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ae916205cdae8210b147d7637f74186e57d15973",
            "@type": "ScholarlyArticle",
            "paperId": "ae916205cdae8210b147d7637f74186e57d15973",
            "corpusId": 3525280,
            "url": "https://www.semanticscholar.org/paper/ae916205cdae8210b147d7637f74186e57d15973",
            "title": "Towards End-to-end Spoken Language Understanding",
            "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
            "publicationVenue": {
                "id": "urn:research:0d6f7fba-7092-46b3-8039-93458dba736b",
                "name": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
                "alternate_names": [
                    "Int Conf Acoust Speech Signal Process",
                    "IEEE Int Conf Acoust Speech Signal Process",
                    "ICASSP",
                    "International Conference on Acoustics, Speech, and Signal Processing"
                ],
                "issn": null,
                "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000002"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2787948962",
                "ArXiv": "1802.08395",
                "DBLP": "conf/icassp/SerdyukWFKLB18",
                "DOI": "10.1109/ICASSP.2018.8461785",
                "CorpusId": 3525280
            },
            "abstract": "Spoken language understanding system is traditionally designed as a pipeline of a number of components. First, the audio signal is processed by an automatic speech recognizer for transcription or n-best hypotheses. With the recognition results, a natural language understanding system classifies the text to structured data as domain, intent and slots for down-streaming consumers, such as dialog system, hands-free applications. These components are usually developed and optimized independently. In this paper, we present our study on an end-to-end learning system for spoken language understanding. With this unified approach, we can infer the semantic meaning directly from audio features without the intermediate text representation. This study showed that the trained model can achieve reasonable good result and demonstrated that the model can capture the semantic attention directly from the audio features.",
            "referenceCount": 30,
            "citationCount": 201,
            "influentialCitationCount": 14,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1802.08395",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-02-23",
            "journal": {
                "name": "2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Serdyuk2018TowardsES,\n author = {Dmitriy Serdyuk and Yongqiang Wang and Christian Fuegen and Anuj Kumar and Baiyang Liu and Yoshua Bengio},\n booktitle = {IEEE International Conference on Acoustics, Speech, and Signal Processing},\n journal = {2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},\n pages = {5754-5758},\n title = {Towards End-to-end Spoken Language Understanding},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1e688be9f4554aa981fe3db9e2a66388b05bd167",
            "@type": "ScholarlyArticle",
            "paperId": "1e688be9f4554aa981fe3db9e2a66388b05bd167",
            "corpusId": 13040187,
            "url": "https://www.semanticscholar.org/paper/1e688be9f4554aa981fe3db9e2a66388b05bd167",
            "title": "Code completion with statistical language models",
            "venue": "ACM-SIGPLAN Symposium on Programming Language Design and Implementation",
            "publicationVenue": {
                "id": "urn:research:a00a1a4f-16c6-4360-a8b3-a3f88d2fe78f",
                "name": "ACM-SIGPLAN Symposium on Programming Language Design and Implementation",
                "alternate_names": [
                    "ACM-SIGPLAN Symp Program Lang Des Implement",
                    "Program Lang Des Implement",
                    "Programming Language Design and Implementation",
                    "PLDI"
                ],
                "issn": null,
                "url": "http://portal.acm.org/proceedings/pldi/"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2143861926",
                "DBLP": "conf/pldi/RaychevVY14",
                "DOI": "10.1145/2594291.2594321",
                "CorpusId": 13040187
            },
            "abstract": "We address the problem of synthesizing code completions for programs using APIs. Given a program with holes, we synthesize completions for holes with the most likely sequences of method calls. Our main idea is to reduce the problem of code completion to a natural-language processing problem of predicting probabilities of sentences. We design a simple and scalable static analysis that extracts sequences of method calls from a large codebase, and index these into a statistical language model. We then employ the language model to find the highest ranked sentences, and use them to synthesize a code completion. Our approach is able to synthesize sequences of calls across multiple objects together with their arguments. Experiments show that our approach is fast and effective. Virtually all computed completions typecheck, and the desired completion appears in the top 3 results in 90% of the cases.",
            "referenceCount": 45,
            "citationCount": 548,
            "influentialCitationCount": 39,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-06-09",
            "journal": {
                "name": "Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Raychev2014CodeCW,\n author = {Veselin Raychev and Martin T. Vechev and Eran Yahav},\n booktitle = {ACM-SIGPLAN Symposium on Programming Language Design and Implementation},\n journal = {Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation},\n title = {Code completion with statistical language models},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e6c7adc28e20d361d5c35aa9808094b10f6a34d1",
            "@type": "ScholarlyArticle",
            "paperId": "e6c7adc28e20d361d5c35aa9808094b10f6a34d1",
            "corpusId": 396794,
            "url": "https://www.semanticscholar.org/paper/e6c7adc28e20d361d5c35aa9808094b10f6a34d1",
            "title": "Convolution Kernels for Natural Language",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2001,
            "externalIds": {
                "MAG": "2127713198",
                "DBLP": "conf/nips/CollinsD01",
                "DOI": "10.7551/mitpress/1120.003.0085",
                "CorpusId": 396794
            },
            "abstract": "We describe the application of kernel methods to Natural Language Processing (NLP) problems. In many NLP tasks the objects being modeled are strings, trees, graphs or other discrete structures which require some mechanism to convert them into feature vectors. We describe kernels for various natural language structures, allowing rich, high dimensional representations of these structures. We show how a kernel over trees can be applied to parsing using the voted perceptron algorithm, and we give experimental results on the ATIS corpus of parse trees.",
            "referenceCount": 19,
            "citationCount": 925,
            "influentialCitationCount": 124,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2001-01-03",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Collins2001ConvolutionKF,\n author = {M. Collins and Nigel P. Duffy},\n booktitle = {Neural Information Processing Systems},\n pages = {625-632},\n title = {Convolution Kernels for Natural Language},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f56cb5dc32b5b280546998418fda7769d0858629",
            "@type": "ScholarlyArticle",
            "paperId": "f56cb5dc32b5b280546998418fda7769d0858629",
            "corpusId": 53186236,
            "url": "https://www.semanticscholar.org/paper/f56cb5dc32b5b280546998418fda7769d0858629",
            "title": "How2: A Large-scale Dataset for Multimodal Language Understanding",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2018,
            "externalIds": {
                "ArXiv": "1811.00347",
                "MAG": "2899274165",
                "DBLP": "journals/corr/abs-1811-00347",
                "CorpusId": 53186236
            },
            "abstract": "In this paper, we introduce How2, a multimodal collection of instructional videos with English subtitles and crowdsourced Portuguese translations. We also present integrated sequence-to-sequence baselines for machine translation, automatic speech recognition, spoken language translation, and multimodal summarization. By making available data and code for several multimodal natural language tasks, we hope to stimulate more research on these and similar challenges, to obtain a deeper understanding of multimodality in language processing.",
            "referenceCount": 57,
            "citationCount": 214,
            "influentialCitationCount": 31,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-11-01",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1811.00347"
            },
            "citationStyles": {
                "bibtex": "@Article{Sanabria2018How2AL,\n author = {Ramon Sanabria and Ozan Caglayan and Shruti Palaskar and Desmond Elliott and Lo\u00efc Barrault and Lucia Specia and Florian Metze},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {How2: A Large-scale Dataset for Multimodal Language Understanding},\n volume = {abs/1811.00347},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:97796fcf3736c9b6950f35b6a3db074fdd50807b",
            "@type": "ScholarlyArticle",
            "paperId": "97796fcf3736c9b6950f35b6a3db074fdd50807b",
            "corpusId": 17035249,
            "url": "https://www.semanticscholar.org/paper/97796fcf3736c9b6950f35b6a3db074fdd50807b",
            "title": "Fuzzy ontology for natural language",
            "venue": "2010 Annual Meeting of the North American Fuzzy Information Processing Society",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2010,
            "externalIds": {
                "MAG": "2170753698",
                "DOI": "10.1109/NAFIPS.2010.5548416",
                "CorpusId": 17035249
            },
            "abstract": "The paper outlines a framework for a full incorporation of fuzziness into a comprehensive system of natural language meaning processing with the help of ontological semantic technology. It goes far beyond the traditional examples of fuzziness for natural language modifiers, claiming that fuzziness is pervasive throughout natural language and cannot be avoided without a considerable penalty on accuracy.",
            "referenceCount": 21,
            "citationCount": 35,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2010-07-12",
            "journal": {
                "name": "2010 Annual Meeting of the North American Fuzzy Information Processing Society",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Rayz2010FuzzyOF,\n author = {Julia Taylor Rayz and V. Raskin},\n booktitle = {2010 Annual Meeting of the North American Fuzzy Information Processing Society},\n journal = {2010 Annual Meeting of the North American Fuzzy Information Processing Society},\n pages = {1-6},\n title = {Fuzzy ontology for natural language},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bdf79b95f8ffdd3177878037f61ad87744cc2725",
            "@type": "ScholarlyArticle",
            "paperId": "bdf79b95f8ffdd3177878037f61ad87744cc2725",
            "corpusId": 60817977,
            "url": "https://www.semanticscholar.org/paper/bdf79b95f8ffdd3177878037f61ad87744cc2725",
            "title": "Memory-Based Language Processing",
            "venue": "Studies in natural language processing",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2009,
            "externalIds": {
                "MAG": "2297880325",
                "DBLP": "books/daglib/0033304",
                "DOI": "10.1017/CBO9780511486579.002",
                "CorpusId": 60817977
            },
            "abstract": "Memory-based language processing--a machine learning and problem solving method for language technology--is based on the idea that the direct re-use of examples using analogical reasoning is more suited for solving language processing problems than the application of rules extracted from those examples. This book discusses the theory and practice of memory-based language processing, showing its comparative strengths over alternative methods of language modelling. Language is complex, with few generalizations, many sub-regularities and exceptions, and the advantage of memory-based language processing is that it does not abstract away from this valuable low-frequency information.",
            "referenceCount": 11,
            "citationCount": 435,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Daelemans2009MemoryBasedLP,\n author = {Walter Daelemans and Antal van den Bosch},\n booktitle = {Studies in natural language processing},\n pages = {I-VII, 1-189},\n title = {Memory-Based Language Processing},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:afd975a296886e89722891ad13c8dba0d26b1ed2",
            "@type": "ScholarlyArticle",
            "paperId": "afd975a296886e89722891ad13c8dba0d26b1ed2",
            "corpusId": 196183669,
            "url": "https://www.semanticscholar.org/paper/afd975a296886e89722891ad13c8dba0d26b1ed2",
            "title": "Generating Fluent Adversarial Examples for Natural Languages",
            "venue": "Annual Meeting of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                "name": "Annual Meeting of the Association for Computational Linguistics",
                "alternate_names": [
                    "Annu Meet Assoc Comput Linguistics",
                    "Meeting of the Association for Computational Linguistics",
                    "ACL",
                    "Meet Assoc Comput Linguistics"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/acl/"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "2007.06174",
                "ACL": "P19-1559",
                "MAG": "2950606982",
                "DBLP": "conf/acl/ZhangZML19",
                "DOI": "10.18653/v1/P19-1559",
                "CorpusId": 196183669
            },
            "abstract": "Efficiently building an adversarial attacker for natural language processing (NLP) tasks is a real challenge. Firstly, as the sentence space is discrete, it is difficult to make small perturbations along the direction of gradients. Secondly, the fluency of the generated examples cannot be guaranteed. In this paper, we propose MHA, which addresses both problems by performing Metropolis-Hastings sampling, whose proposal is designed with the guidance of gradients. Experiments on IMDB and SNLI show that our proposed MHAoutperforms the baseline model on attacking capability. Adversarial training with MHA also leads to better robustness and performance.",
            "referenceCount": 15,
            "citationCount": 121,
            "influentialCitationCount": 18,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aclweb.org/anthology/P19-1559.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-07-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2019GeneratingFA,\n author = {Huangzhao Zhang and Hao Zhou and Ning Miao and Lei Li},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {5564-5569},\n title = {Generating Fluent Adversarial Examples for Natural Languages},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7be3afdb7b7894321027ec90ea0a990aa7a0f266",
            "@type": "ScholarlyArticle",
            "paperId": "7be3afdb7b7894321027ec90ea0a990aa7a0f266",
            "corpusId": 28817116,
            "url": "https://www.semanticscholar.org/paper/7be3afdb7b7894321027ec90ea0a990aa7a0f266",
            "title": "Natural Language Understanding",
            "venue": "New Trends in Software Methodologies, Tools and Techniques",
            "publicationVenue": {
                "id": "urn:research:f294a093-a7c8-422a-9518-837b347650d0",
                "name": "New Trends in Software Methodologies, Tools and Techniques",
                "alternate_names": [
                    "New Trends Softw Methodol Tool Tech",
                    "SoMeT"
                ],
                "issn": null,
                "url": null
            },
            "year": 2009,
            "externalIds": {
                "MAG": "75593468",
                "DBLP": "conf/somet/Sciullo09",
                "DOI": "10.3233/978-1-60750-049-0-551",
                "CorpusId": 28817116
            },
            "abstract": "I focus on three characteristics of natural language understanding systems that incorporate the properties that make humans able to understand language naturally. The first characteristic of such systems is that they handle recursion. A second property of these systems is that they process abstract hierarchical structures, and they are not limited to the processing of strings of characters or keywords. A third characteristic is that they connect physical forms and interpretations.",
            "referenceCount": 29,
            "citationCount": 474,
            "influentialCitationCount": 32,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2009-07-19",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Sciullo2009NaturalLU,\n author = {A. Sciullo},\n booktitle = {New Trends in Software Methodologies, Tools and Techniques},\n pages = {551-563},\n title = {Natural Language Understanding},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:296e8ceeba6550d7ec9b9ee727e0c17420ebb926",
            "@type": "ScholarlyArticle",
            "paperId": "296e8ceeba6550d7ec9b9ee727e0c17420ebb926",
            "corpusId": 119309472,
            "url": "https://www.semanticscholar.org/paper/296e8ceeba6550d7ec9b9ee727e0c17420ebb926",
            "title": "UR-FUNNY: A Multimodal Language Dataset for Understanding Humor",
            "venue": "Conference on Empirical Methods in Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:41bf9ed3-85b3-4c90-b015-150e31690253",
                "name": "Conference on Empirical Methods in Natural Language Processing",
                "alternate_names": [
                    "Empir Method Nat Lang Process",
                    "Empirical Methods in Natural Language Processing",
                    "Conf Empir Method Nat Lang Process",
                    "EMNLP"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/emnlp"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2971320745",
                "ACL": "D19-1211",
                "ArXiv": "1904.06618",
                "DBLP": "conf/emnlp/HasanRZZTMH19",
                "DOI": "10.18653/v1/D19-1211",
                "CorpusId": 119309472
            },
            "abstract": "Humor is a unique and creative communicative behavior often displayed during social interactions. It is produced in a multimodal manner, through the usage of words (text), gestures (visual) and prosodic cues (acoustic). Understanding humor from these three modalities falls within boundaries of multimodal language; a recent research trend in natural language processing that models natural language as it happens in face-to-face communication. Although humor detection is an established research area in NLP, in a multimodal context it has been understudied. This paper presents a diverse multimodal dataset, called UR-FUNNY, to open the door to understanding multimodal language used in expressing humor. The dataset and accompanying studies, present a framework in multimodal humor detection for the natural language processing community. UR-FUNNY is publicly available for research.",
            "referenceCount": 48,
            "citationCount": 111,
            "influentialCitationCount": 13,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.aclweb.org/anthology/D19-1211.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-04-14",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hasan2019URFUNNYAM,\n author = {M. Hasan and Wasifur Rahman and Amir Zadeh and Jianyuan Zhong and Md. Iftekhar Tanveer and Louis-Philippe Morency and Ehsan Hoque},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n pages = {2046-2056},\n title = {UR-FUNNY: A Multimodal Language Dataset for Understanding Humor},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a251dac6589a83e0bbcf9bef9a80c21222aeecbb",
            "@type": "ScholarlyArticle",
            "paperId": "a251dac6589a83e0bbcf9bef9a80c21222aeecbb",
            "corpusId": 1801271,
            "url": "https://www.semanticscholar.org/paper/a251dac6589a83e0bbcf9bef9a80c21222aeecbb",
            "title": "Learning Models for Object Recognition from Natural Language Descriptions",
            "venue": "British Machine Vision Conference",
            "publicationVenue": {
                "id": "urn:research:78a7fbcc-41c5-4258-b633-04b8637d4a9f",
                "name": "British Machine Vision Conference",
                "alternate_names": [
                    "Br Mach Vis Conf",
                    "BMVC"
                ],
                "issn": null,
                "url": "http://www.bmva.org/bmvc/"
            },
            "year": 2009,
            "externalIds": {
                "DBLP": "conf/bmvc/WangME09",
                "MAG": "2080171500",
                "DOI": "10.5244/C.23.2",
                "CorpusId": 1801271
            },
            "abstract": "We investigate the task of learning models for visual object recognition from natural language descriptions alone. The approach contributes to the recognition of fine-grain object categories, such as animal and plant species, where it may be difficult to collect many images for training, but where textual descriptions of visual attributes are readily available. As an example we tackle recognition of butterfly species, learning models from descriptions in an online nature guide. We propose natural language processing methods for extracting salient visual attributes from these descriptions to use as \u2018templates\u2019 for the object categories, and apply vision methods to extract corresponding attributes from test images. A generative model is used to connect textual terms in the learnt templates to visual attributes. We report experiments comparing the performance of humans and the proposed method on a dataset of ten butterfly categories.",
            "referenceCount": 20,
            "citationCount": 216,
            "influentialCitationCount": 24,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2009LearningMF,\n author = {Josiah Wang and K. Markert and M. Everingham},\n booktitle = {British Machine Vision Conference},\n pages = {1-11},\n title = {Learning Models for Object Recognition from Natural Language Descriptions},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:93ff001eb7ddd019c107879943126c74a973993b",
            "@type": "ScholarlyArticle",
            "paperId": "93ff001eb7ddd019c107879943126c74a973993b",
            "corpusId": 2437629,
            "url": "https://www.semanticscholar.org/paper/93ff001eb7ddd019c107879943126c74a973993b",
            "title": "Learning natural coding conventions",
            "venue": "SIGSOFT FSE",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "conf/sigsoft/AllamanisBBS14",
                "MAG": "2892156642",
                "ArXiv": "1402.4182",
                "DOI": "10.1145/2635868.2635883",
                "CorpusId": 2437629
            },
            "abstract": "Every programmer has a characteristic style, ranging from preferences about identifier naming to preferences about object relationships and design patterns. Coding conventions define a consistent syntactic style, fostering readability and hence maintainability. When collaborating, programmers strive to obey a project\u2019s coding conventions. However, one third of reviews of changes contain feedback about coding conventions, indicating that programmers do not always follow them and that project members care deeply about adherence. Unfortunately, programmers are often unaware of coding conventions because inferring them requires a global view, one that aggregates the many local decisions programmers make and identifies emergent consensus on style. We present NATURALIZE, a framework that learns the style of a codebase, and suggests revisions to improve stylistic consistency. NATURALIZE builds on recent work in applying statistical natural language processing to source code. We apply NATURALIZE to suggest natural identifier names and formatting conventions. We present four tools focused on ensuring natural code during development and release management, including code review. NATURALIZE achieves 94 % accuracy in its top suggestions for identifier names. We used NATURALIZE to generate 18 patches for 5 open source projects: 14 were accepted.",
            "referenceCount": 294,
            "citationCount": 351,
            "influentialCitationCount": 29,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://homepages.inf.ed.ac.uk/csutton/publications/naturalize.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book",
                "Review"
            ],
            "publicationDate": "2014-02-17",
            "journal": {
                "name": "Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Allamanis2014LearningNC,\n author = {Miltiadis Allamanis and Earl T. Barr and Charles Sutton},\n booktitle = {SIGSOFT FSE},\n journal = {Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering},\n title = {Learning natural coding conventions},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:efe3fe661d2be1bc7151064457d8f821b4d912b7",
            "@type": "ScholarlyArticle",
            "paperId": "efe3fe661d2be1bc7151064457d8f821b4d912b7",
            "corpusId": 16932735,
            "url": "https://www.semanticscholar.org/paper/efe3fe661d2be1bc7151064457d8f821b4d912b7",
            "title": "Multidisciplinary Instruction with the Natural Language Toolkit",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2008,
            "externalIds": {
                "ACL": "W08-0208",
                "MAG": "2105989239",
                "DOI": "10.3115/1627306.1627317",
                "CorpusId": 16932735
            },
            "abstract": "The Natural Language Toolkit (NLTK) is widely used for teaching natural language processing to students majoring in linguistics or computer science. This paper describes the design of NLTK, and reports on how it has been used effectively in classes that involve different mixes of linguistics and computer science students. We focus on three key issues: getting started with a course, delivering interactive demonstrations in the classroom, and organizing assignments and projects. In each case, we report on practical experience and make recommendations on how to use NLTK to maximum effect.",
            "referenceCount": 21,
            "citationCount": 69,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://dl.acm.org/ft_gateway.cfm?id=1627317&type=pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2008-06-19",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Bird2008MultidisciplinaryIW,\n author = {Steven Bird and Ewan Klein and E. Loper and Jason Baldridge},\n pages = {62-70},\n title = {Multidisciplinary Instruction with the Natural Language Toolkit},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a662d1af0f936c31072c2c1611687c624fd9414c",
            "@type": "ScholarlyArticle",
            "paperId": "a662d1af0f936c31072c2c1611687c624fd9414c",
            "corpusId": 13469304,
            "url": "https://www.semanticscholar.org/paper/a662d1af0f936c31072c2c1611687c624fd9414c",
            "title": "Linguistic modelling and language-processing technologies for Avatar-based sign language presentation",
            "venue": "Universal Access in the Information Society",
            "publicationVenue": {
                "id": "urn:research:824ae05b-523b-471a-9469-5ed98ae762cc",
                "name": "Universal Access in the Information Society",
                "alternate_names": [
                    "Universal Access in The Information Society",
                    "Univers Access Inf Soc"
                ],
                "issn": "1615-5289",
                "url": "https://rd.springer.com/journal/10209"
            },
            "year": 2008,
            "externalIds": {
                "DBLP": "journals/uais/ElliottGKMS08",
                "MAG": "2080378008",
                "DOI": "10.1007/s10209-007-0102-z",
                "CorpusId": 13469304
            },
            "abstract": null,
            "referenceCount": 35,
            "citationCount": 150,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2008-01-30",
            "journal": {
                "name": "Universal Access in the Information Society",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Elliott2008LinguisticMA,\n author = {R. Elliott and J. Glauert and R. Kennaway and I. Marshall and \u00c9. S\u00e1f\u00e1r},\n booktitle = {Universal Access in the Information Society},\n journal = {Universal Access in the Information Society},\n pages = {375-391},\n title = {Linguistic modelling and language-processing technologies for Avatar-based sign language presentation},\n volume = {6},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f196a79c5e4b570013e4aa031cdd0fc0c98fc07d",
            "@type": "ScholarlyArticle",
            "paperId": "f196a79c5e4b570013e4aa031cdd0fc0c98fc07d",
            "corpusId": 4389330,
            "url": "https://www.semanticscholar.org/paper/f196a79c5e4b570013e4aa031cdd0fc0c98fc07d",
            "title": "Interactively Picking Real-World Objects with Unconstrained Spoken Language Instructions",
            "venue": "IEEE International Conference on Robotics and Automation",
            "publicationVenue": {
                "id": "urn:research:3f2626a8-9d78-42ca-9e0d-4b853b59cdcc",
                "name": "IEEE International Conference on Robotics and Automation",
                "alternate_names": [
                    "International Conference on Robotics and Automation",
                    "Int Conf Robot Autom",
                    "ICRA",
                    "IEEE Int Conf Robot Autom"
                ],
                "issn": "2152-4092",
                "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000639"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/icra/HatoriKKTTUKT18",
                "MAG": "2765804957",
                "ArXiv": "1710.06280",
                "DOI": "10.1109/ICRA.2018.8460699",
                "CorpusId": 4389330
            },
            "abstract": "Comprehension of spoken natural language is an essential skill for robots to communicate with humans effectively. However, handling unconstrained spoken instructions is challenging due to (1) complex structures and the wide variety of expressions used in spoken language, and (2) inherent ambiguity of human instructions. In this paper, we propose the first comprehensive system for controlling robots with unconstrained spoken language, which is able to effectively resolve ambiguity in spoken instructions. Specifically, we integrate deep learning-based object detection together with natural language processing technologies to handle unconstrained spoken instructions, and propose a method for robots to resolve instruction ambiguity through dialogue. Through our experiments on both a simulated environment as well as a physical industrial robot arm, we demonstrate the ability of our system to understand natural instructions from human operators effectively, and show how higher success rates of the object picking task can be achieved through an interactive clarification process.",
            "referenceCount": 29,
            "citationCount": 128,
            "influentialCitationCount": 13,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1710.06280",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-10-17",
            "journal": {
                "name": "2018 IEEE International Conference on Robotics and Automation (ICRA)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hatori2017InteractivelyPR,\n author = {Jun Hatori and Yuta Kikuchi and Sosuke Kobayashi and K. Takahashi and Yuta Tsuboi and Y. Unno and W. Ko and Jethro Tan},\n booktitle = {IEEE International Conference on Robotics and Automation},\n journal = {2018 IEEE International Conference on Robotics and Automation (ICRA)},\n pages = {3774-3781},\n title = {Interactively Picking Real-World Objects with Unconstrained Spoken Language Instructions},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e1f9ad97af9f09b206e3681f080fcf996e56a5e3",
            "@type": "ScholarlyArticle",
            "paperId": "e1f9ad97af9f09b206e3681f080fcf996e56a5e3",
            "corpusId": 6265951,
            "url": "https://www.semanticscholar.org/paper/e1f9ad97af9f09b206e3681f080fcf996e56a5e3",
            "title": "Making Tree Kernels Practical for Natural Language Learning",
            "venue": "Conference of the European Chapter of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:8de18c35-6785-4e54-99f2-21ee961302c6",
                "name": "Conference of the European Chapter of the Association for Computational Linguistics",
                "alternate_names": [
                    "Conf Eur Chapter Assoc Comput Linguistics",
                    "EACL"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/eacl/"
            },
            "year": 2006,
            "externalIds": {
                "DBLP": "conf/eacl/Moschitti06",
                "MAG": "224064951",
                "ACL": "E06-1015",
                "CorpusId": 6265951
            },
            "abstract": "In recent years tree kernels have been proposed for the automatic learning of natural language applications. Unfortunately, they show (a) an inherent super linear complexity and (b) a lower accuracy than traditional attribute/value methods. In this paper, we show that tree kernels are very helpful in the processing of natural language as (a) we provide a simple algorithm to compute tree kernels in linear average running time and (b) our study on the classification properties of diverse tree kernels show that kernel combinations always improve the traditional methods. Experiments with Support Vector Machines on the predicate argument classification task provide empirical support to our thesis.",
            "referenceCount": 19,
            "citationCount": 341,
            "influentialCitationCount": 47,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2006-04-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Moschitti2006MakingTK,\n author = {Alessandro Moschitti},\n booktitle = {Conference of the European Chapter of the Association for Computational Linguistics},\n pages = {113-120},\n title = {Making Tree Kernels Practical for Natural Language Learning},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:79f537759e7f1e0674a1dd6941ec5912528cd234",
            "@type": "ScholarlyArticle",
            "paperId": "79f537759e7f1e0674a1dd6941ec5912528cd234",
            "corpusId": 206982354,
            "url": "https://www.semanticscholar.org/paper/79f537759e7f1e0674a1dd6941ec5912528cd234",
            "title": "Research Paper: A General Natural-language Text Processor for Clinical Radiology",
            "venue": "J. Am. Medical Informatics Assoc.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1994,
            "externalIds": {
                "DBLP": "journals/jamia/FriedmanAACJ94",
                "MAG": "1504212872",
                "DOI": "10.1136/jamia.1994.95236146",
                "CorpusId": 206982354,
                "PubMed": "7719797"
            },
            "abstract": "OBJECTIVE\nDevelopment of a general natural-language processor that identifies clinical information in narrative reports and maps that information into a structured representation containing clinical terms.\n\n\nDESIGN\nThe natural-language processor provides three phases of processing, all of which are driven by different knowledge sources. The first phase performs the parsing. It identifies the structure of the text through use of a grammar that defines semantic patterns and a target form. The second phase, regularization, standardizes the terms in the initial target structure via a compositional mapping of multi-word phrases. The third phase, encoding, maps the terms to a controlled vocabulary. Radiology is the test domain for the processor and the target structure is a formal model for representing clinical information in that domain.\n\n\nMEASUREMENTS\nThe impression sections of 230 radiology reports were encoded by the processor. Results of an automated query of the resultant database for the occurrences of four diseases were compared with the analysis of a panel of three physicians to determine recall and precision.\n\n\nRESULTS\nWithout training specific to the four diseases, recall and precision of the system (combined effect of the processor and query generator) were 70% and 87%. Training of the query component increased recall to 85% without changing precision.",
            "referenceCount": 9,
            "citationCount": 734,
            "influentialCitationCount": 30,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc116194?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1994-03-01",
            "journal": {
                "name": "Journal of the American Medical Informatics Association : JAMIA",
                "volume": "1 2"
            },
            "citationStyles": {
                "bibtex": "@Article{Friedman1994ResearchPA,\n author = {C. Friedman and P. Alderson and J. Austin and J. Cimino and Stephen B. Johnson},\n booktitle = {J. Am. Medical Informatics Assoc.},\n journal = {Journal of the American Medical Informatics Association : JAMIA},\n pages = {\n          161-74\n        },\n title = {Research Paper: A General Natural-language Text Processor for Clinical Radiology},\n volume = {1 2},\n year = {1994}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:96364af2d208ea75ca3aeb71892d2f7ce7326b55",
            "@type": "ScholarlyArticle",
            "paperId": "96364af2d208ea75ca3aeb71892d2f7ce7326b55",
            "corpusId": 68116583,
            "url": "https://www.semanticscholar.org/paper/96364af2d208ea75ca3aeb71892d2f7ce7326b55",
            "title": "Statistical Language Models Based on Neural Networks",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2012,
            "externalIds": {
                "MAG": "2908906764",
                "CorpusId": 68116583
            },
            "abstract": "Statistical language models are crucial part of many successful applications, such as automatic speech recognition and statistical machine translation (for example well-known Google Translate). Traditional techniques for estimating these models are based on N gram counts. Despite known weaknesses of N -grams and huge efforts of research communities across many fields (speech recognition, machine translation, neuroscience, artificial intelligence, natural language processing, data compression, psychology etc.), N -grams remained basically the state-of-the-art. The goal of this thesis is to present various architectures of language models that are based on artificial neural networks. Although these models are computationally more expensive than N -gram models, with the presented techniques it is possible to apply them to state-of-the-art systems efficiently. Achieved reductions of word error rate of speech recognition systems are up to 20%, against stateof-the-art N -gram model. The presented recurrent neural network based model achieves the best published performance on well-known Penn Treebank setup. K\u013a\u0131\u010dov\u00e1 slova jazykov\u00fd model, neuronov\u00e1 \u015b\u0131t\u2019, rekurent\u0144\u0131, maxim\u00e1l\u0144\u0131 entropie, rozpozn\u00e1v\u00e1\u0144\u0131 \u0159e\u010di, komprese dat, um\u011bl\u00e1 inteligence",
            "referenceCount": 80,
            "citationCount": 604,
            "influentialCitationCount": 71,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{U\u010den\u00ed2012StatisticalLM,\n author = {Vysok\u00e9 U\u010den\u00ed and Technick\u00e9 V Brn\u011b and Grafiky A Multim\u00e9di\u00ed and Diserta\u010dn\u00ed Pr\u00e1ce},\n title = {Statistical Language Models Based on Neural Networks},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f4cc5563c694355ddcf746ff9a55ccdb22d86a98",
            "@type": "ScholarlyArticle",
            "paperId": "f4cc5563c694355ddcf746ff9a55ccdb22d86a98",
            "corpusId": 5548799,
            "url": "https://www.semanticscholar.org/paper/f4cc5563c694355ddcf746ff9a55ccdb22d86a98",
            "title": "Finite-State Transducers in Language and Speech Processing",
            "venue": "Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:ee37a78c-f3d8-407a-bd24-bb97fe6dbab9",
                "name": "Computational Linguistics",
                "alternate_names": [
                    "Comput Linguistics"
                ],
                "issn": "0891-2017",
                "url": "http://aclanthology.info/venues/cl"
            },
            "year": 1997,
            "externalIds": {
                "ACL": "J97-2003",
                "MAG": "2125529971",
                "DBLP": "journals/coling/Mohri97",
                "CorpusId": 5548799
            },
            "abstract": "Finite-machines have been used in various domains of natural language processing. We consider here the use of a type of transducer that supports very efficient programs: sequential transducers. We recall classical theorems and give new ones characterizing sequential string-to-string transducers. Transducers that outpur weights also play an important role in language and speech processing. We give a specific study of string-to-weight transducers, including algorithms for determinizing and minizizing these transducers very efficiently, and characterizations of the transducers admitting determinization and the corresponding algorithms. Some applications of these algorithms in speech recognition are described and illustrated.",
            "referenceCount": 50,
            "citationCount": 1079,
            "influentialCitationCount": 110,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1997-06-01",
            "journal": {
                "name": "Comput. Linguistics",
                "volume": "23"
            },
            "citationStyles": {
                "bibtex": "@Article{Mohri1997FiniteStateTI,\n author = {Mehryar Mohri},\n booktitle = {Computational Linguistics},\n journal = {Comput. Linguistics},\n pages = {269-311},\n title = {Finite-State Transducers in Language and Speech Processing},\n volume = {23},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:14235d852e9a823519093a1eba63874f236d77b0",
            "@type": "ScholarlyArticle",
            "paperId": "14235d852e9a823519093a1eba63874f236d77b0",
            "corpusId": 15252797,
            "url": "https://www.semanticscholar.org/paper/14235d852e9a823519093a1eba63874f236d77b0",
            "title": "An Introduction to Language Processing with Perl and Prolog: An Outline of Theories, Implementation, and Application with Special Consideration of English, French, and German",
            "venue": "Cognitive Technologies",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2006,
            "externalIds": {
                "MAG": "1511244878",
                "DBLP": "series/cogtech/Nugues2006",
                "DOI": "10.1007/3-540-34336-9",
                "CorpusId": 15252797
            },
            "abstract": null,
            "referenceCount": 11,
            "citationCount": 74,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2006-04-05",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Nugues2006AnIT,\n author = {P. Nugues},\n booktitle = {Cognitive Technologies},\n title = {An Introduction to Language Processing with Perl and Prolog: An Outline of Theories, Implementation, and Application with Special Consideration of English, French, and German},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ba4b975a6b1fe8dc71ead9ba516b7f3a122f78aa",
            "@type": "ScholarlyArticle",
            "paperId": "ba4b975a6b1fe8dc71ead9ba516b7f3a122f78aa",
            "corpusId": 15466554,
            "url": "https://www.semanticscholar.org/paper/ba4b975a6b1fe8dc71ead9ba516b7f3a122f78aa",
            "title": "Some Aspects of Optimality in Natural Language Interpretation",
            "venue": "Journal of Semantics",
            "publicationVenue": {
                "id": "urn:research:a986ba6e-51cb-478a-967c-8802bafdcc16",
                "name": "Journal of Semantics",
                "alternate_names": [
                    "J Semant"
                ],
                "issn": "0167-5133",
                "url": "https://academic.oup.com/jos/issue"
            },
            "year": 2000,
            "externalIds": {
                "MAG": "2162925602",
                "DBLP": "journals/jsemantics/Blutner00",
                "DOI": "10.1093/jos/17.3.189",
                "CorpusId": 15466554
            },
            "abstract": "In a series of papers, Petra Hendriks, Helen de Hoop, and Henriette de Swart Lave applied optimality theory (OT) to semantics. These authors argue that there is a fundamental difference between the form of OT as used in syntax on the one hand and its form as used in semantics on the other hand. Whereas in the first case OT takes the point of view of the speaker, in the second case the point of view of the hearer is taken. The aim of this paper is to argue that the proper treatment of OT in natural language interpretation has to take both perspectives at the same time. A conceptual framework is established that realizes the integration of both perspectives. It will be argued that this framework captures the essence of the Gricean maxims and gives a precise explication of Atlas & Levinson's (1981) idea of balancing between informativeness and efficiency in natural language processing. The ideas are then applied to resolve some puzzles in natural language interpretation.",
            "referenceCount": 59,
            "citationCount": 461,
            "influentialCitationCount": 49,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://academic.oup.com/jos/article-pdf/17/3/189/4744123/17-3-189.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Philosophy",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Philosophy",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2000-08-01",
            "journal": {
                "name": "J. Semant.",
                "volume": "17"
            },
            "citationStyles": {
                "bibtex": "@Article{Blutner2000SomeAO,\n author = {Reinhard Blutner},\n booktitle = {Journal of Semantics},\n journal = {J. Semant.},\n pages = {189-216},\n title = {Some Aspects of Optimality in Natural Language Interpretation},\n volume = {17},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:31b4c03d721dc10b87c178277c1d369f91db8f0e",
            "@type": "ScholarlyArticle",
            "paperId": "31b4c03d721dc10b87c178277c1d369f91db8f0e",
            "corpusId": 14740218,
            "url": "https://www.semanticscholar.org/paper/31b4c03d721dc10b87c178277c1d369f91db8f0e",
            "title": "Semi-Supervised Learning for Natural Language",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "MAG": "2158049734",
                "CorpusId": 14740218
            },
            "abstract": "Statistical supervised learning techniques have been successful for many natural language processing tasks, but they require labeled datasets, which can be expensive to obtain. On the other hand, unlabeled data (raw text) is often available \"for free\" in large quantities. Unlabeled data has shown promise in improving the performance of a number of tasks, e.g. word sense disambiguation, information extraction, and natural language parsing. In this thesis, we focus on two segmentation tasks, named-entity recognition and Chinese word segmentation. The goal of named-entity recognition is to detect and classify names of people, organizations, and locations in a sentence. The goal of Chinese word segmentation is to find the word boundaries in a sentence that has been written as a string of characters without spaces. Our approach is as follows: In a preprocessing step, we use raw text to cluster words and calculate mutual information statistics. The output of this step is then used as features in a supervised model, specifically a global linear model trained using the Perceptron algorithm. We also compare Markov and semi-Markov models on the two segmentation tasks. Our results show that features derived from unlabeled data substantially improves performance, both in terms of reducing the amount of labeled data needed to achieve a certain performance level and in terms of reducing the error using a fixed amount of labeled data. We find that sometimes semi-Markov models can also improve performance over Markov models. Thesis Supervisor: Michael Collins Title: Assistant Professor, CSAIL",
            "referenceCount": 80,
            "citationCount": 365,
            "influentialCitationCount": 34,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Liang2005SemiSupervisedLF,\n author = {P. Liang},\n title = {Semi-Supervised Learning for Natural Language},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:59b4f770abec2e7487cee2717ef33958d5465b30",
            "@type": "ScholarlyArticle",
            "paperId": "59b4f770abec2e7487cee2717ef33958d5465b30",
            "corpusId": 207660078,
            "url": "https://www.semanticscholar.org/paper/59b4f770abec2e7487cee2717ef33958d5465b30",
            "title": "An iterative design methodology for user-friendly natural language office information applications",
            "venue": "TOIS",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1984,
            "externalIds": {
                "MAG": "1969152782",
                "DBLP": "journals/tois/Kelley84",
                "DOI": "10.1145/357417.357420",
                "CorpusId": 207660078
            },
            "abstract": "A six-step, iterative, empirical human factors design methodology was used to develop CAL, a natural language computer application to help computer-naive business professionals manage their personal calenders. Input language is processed by a simple, nonparsing algorithm with limited storage requirements and a quick response time. CAL allows unconstrained English inputs from users with no training (except for a five minute introduction to the keyboard and display) and no manual (except for a two-page overview of the system). In a controlled test of performance, CAL correctly responded to between 86 percent and 97 percent of the storage and retrieval requests it received, according to various criteria. This level of performance could never have been achieved with such a simple processing model were it not for the empirical approach used in the development of the program and its dictionaries. The tools of the engineering psychologist are clearly invaluable in the development of user-friendly software, if that software is to accommodate the unruly language of computer-naive, first-time users. The key is elicit the cooperation of such users as partners in an iterative, empirical development process. 15 references.",
            "referenceCount": 20,
            "citationCount": 722,
            "influentialCitationCount": 34,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/357417.357420",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "ACM Trans. Inf. Syst.",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{J.1984AnID,\n author = {J. and F. Kelley and T. J. Watson},\n booktitle = {TOIS},\n journal = {ACM Trans. Inf. Syst.},\n pages = {26-41},\n title = {An iterative design methodology for user-friendly natural language office information applications},\n volume = {2},\n year = {1984}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d2560a8697013f6428f16238d0ec46a3a0b0f6e7",
            "@type": "ScholarlyArticle",
            "paperId": "d2560a8697013f6428f16238d0ec46a3a0b0f6e7",
            "corpusId": 14249124,
            "url": "https://www.semanticscholar.org/paper/d2560a8697013f6428f16238d0ec46a3a0b0f6e7",
            "title": "Finite-State Language Processing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1997,
            "externalIds": {
                "MAG": "2093476618",
                "DOI": "10.2307/417760",
                "CorpusId": 14249124
            },
            "abstract": "From the Publisher: \n\"Emmanuel Roche and Yves Schabes have put together a picture of the state of the art in using finite-state techniques in computational linguistics. The contributing authors comprise an impressive collection -- essentially the originating sources for much of the important recent work in this area.\" \n-- Philip Resnik, Assistant Professor, Department of Linguistics and Institute for Advanced Computer Studies, University of Maryland at College Park Finite-state devices, which include finite-state automata, graphs, and finite-state transducers, are in wide use in many areas of computer science. Recently, there has been a resurgence of the use of finite-state devices in all aspects of computational linguistics, including dictionary encoding, text processing, and speech processing. This book describes the fundamental properties of finite-state devices and illustrates their uses. Many of the contributors pioneered the use of finite-automata for different aspects of natural language processing. The topics, which range from the theoretical to the applied, include finite-state morphology, approximation of phrase-structure grammars, deterministic part-of-speech tagging, application of a finite-state intersection grammar, a finite-state transducer for extracting information from text, and speech recognition using weighted finite automata. The introduction presents the basic theoretical results in finite-state automata and transducers. These results and algorithms are described and illustrated with simple formal language examples as well as natural language examples. \nContributors: Douglas Appelt, John Bear, David Clemenceau, Maurice Gross, Jerry R. Hobbs, David Israel, Megumi Kameyama, Lauri Karttunen, Kimmo Koskenniemi, Mehryar Mohri, Eric Laporte, Fernando C. N. Pereira, Michael D. Riley, Emmanuel Roche, Yves Schabes, Max D. Silberztein, Mark Stickel, Pasi Tapanainen, Mabry Tyson, Atro Voutilainen, Rebecca N. Wright. \nLanguage, Speech, and Communication series",
            "referenceCount": 0,
            "citationCount": 463,
            "influentialCitationCount": 17,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1997-07-01",
            "journal": {
                "name": "Language",
                "volume": "75"
            },
            "citationStyles": {
                "bibtex": "@Article{Roche1997FiniteStateLP,\n author = {Emmanuel Roche and Yves Shabes},\n journal = {Language},\n pages = {850},\n title = {Finite-State Language Processing},\n volume = {75},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e408cfd6b8433fea02e2fd13d0c75cead0dc8023",
            "@type": "ScholarlyArticle",
            "paperId": "e408cfd6b8433fea02e2fd13d0c75cead0dc8023",
            "corpusId": 1796337,
            "url": "https://www.semanticscholar.org/paper/e408cfd6b8433fea02e2fd13d0c75cead0dc8023",
            "title": "FASTUS: A Cascaded Finite-State Transducer for Extracting Information from Natural-Language Text",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 1997,
            "externalIds": {
                "DBLP": "journals/corr/cmp-lg-9705013",
                "MAG": "1667964228",
                "ArXiv": "cmp-lg/9705013",
                "CorpusId": 1796337
            },
            "abstract": "FASTUS is a system for extracting information from natural language text for entry into a database and for other applications. It works essentially as a cascaded, nondeterministic finite-state automaton. There are five stages in the operation of FASTUS. In Stage 1, names and other fixed form expressions are recognized. In Stage 2, basic noun groups, verb groups, and prepositions and some other particles are recognized. In Stage 3, certain complex noun groups and verb groups are constructed. Patterns for events of interest are identified in Stage 4 and corresponding ``event structures'' are built. In Stage 5, distinct event structures that describe the same event are identified and merged, and these are used in generating database entries. This decomposition of language processing enables the system to do exactly the right amount of domain-independent syntax, so that domain-dependent semantic and pragmatic processing can be applied to the right larger-scale structures. FASTUS is very efficient and effective, and has been used successfully in a number of applications.",
            "referenceCount": 26,
            "citationCount": 364,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1997-05-20",
            "journal": {
                "name": "ArXiv",
                "volume": "cmp-lg/9705013"
            },
            "citationStyles": {
                "bibtex": "@Article{Hobbs1997FASTUSAC,\n author = {Jerry R. Hobbs and D. Appelt and J. Bear and David J. Israel and M. Kameyama and M. Stickel and M. Tyson},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {FASTUS: A Cascaded Finite-State Transducer for Extracting Information from Natural-Language Text},\n volume = {cmp-lg/9705013},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c96fe25817c5fca96719cfa56cdaeeb2d17c93d7",
            "@type": "ScholarlyArticle",
            "paperId": "c96fe25817c5fca96719cfa56cdaeeb2d17c93d7",
            "corpusId": 17836106,
            "url": "https://www.semanticscholar.org/paper/c96fe25817c5fca96719cfa56cdaeeb2d17c93d7",
            "title": "Massively Parallel Parsing: A Strongly Interactive Model of Natural Language Interpretation",
            "venue": "Cognitive Sciences",
            "publicationVenue": {
                "id": "urn:research:c33b01b0-31b4-470e-a9f9-8432e02c3cb9",
                "name": "Cognitive Sciences",
                "alternate_names": [
                    "Cognitive Science",
                    "Cogn Sci"
                ],
                "issn": "1935-8059",
                "url": "http://www.informaworld.com/openurl?genre=journal&issn=1551-6709"
            },
            "year": 1988,
            "externalIds": {
                "MAG": "2142131598",
                "DBLP": "journals/cogsci/WaltzP85",
                "DOI": "10.1207/s15516709cog0901_4",
                "CorpusId": 17836106
            },
            "abstract": "This is a description of research in developing a natural language processing system with modular knowledge sources but strongly interactive processing. The system offers insights into a variety of linguistic phenomena and allows easy testing of a variety of hypotheses. Language interpretation takes place on a activation network which is dynamically created from input, recent context, and long-term knowledge. Initially ambiguous and unstable, the network settles on a single interpretation, using a parallel, analog relaxation process. We also describe a parallel model for the representation of context and of the priming of concepts. Examples illustrating contextual influence on meaning interpretation and \u201csemantic garden path\u201d sentence processing, among other issues, are included.",
            "referenceCount": 68,
            "citationCount": 526,
            "influentialCitationCount": 12,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1207/s15516709cog0901_4",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1988-05-01",
            "journal": {
                "name": "Cogn. Sci.",
                "volume": "9"
            },
            "citationStyles": {
                "bibtex": "@Article{Waltz1988MassivelyPP,\n author = {D. Waltz and J. Pollack},\n booktitle = {Cognitive Sciences},\n journal = {Cogn. Sci.},\n pages = {51-74},\n title = {Massively Parallel Parsing: A Strongly Interactive Model of Natural Language Interpretation},\n volume = {9},\n year = {1988}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:37c9408d511cbc1122b5b570694eed52b04e9636",
            "@type": "ScholarlyArticle",
            "paperId": "37c9408d511cbc1122b5b570694eed52b04e9636",
            "corpusId": 1371723,
            "url": "https://www.semanticscholar.org/paper/37c9408d511cbc1122b5b570694eed52b04e9636",
            "title": "Active Learning for Natural Language Parsing and Information Extraction",
            "venue": "International Conference on Machine Learning",
            "publicationVenue": {
                "id": "urn:research:fc0a208c-acb7-47dc-a0d4-af8190e21d29",
                "name": "International Conference on Machine Learning",
                "alternate_names": [
                    "ICML",
                    "Int Conf Mach Learn"
                ],
                "issn": null,
                "url": "https://icml.cc/"
            },
            "year": 1999,
            "externalIds": {
                "MAG": "2114663556",
                "DBLP": "conf/icml/ThompsonCM99",
                "CorpusId": 1371723
            },
            "abstract": "In natural language acquisition, it is dicult to gather the annotated data needed for supervised learning; however, unannotated data is fairly plentiful. Active learning methods attempt to select for annotation and training only the most informative examples, and therefore are potentially very useful in natural language applications. However, existing results for active learning have only considered standard classication tasks. To reduce annotation eort while maintaining accuracy, we apply active learning to two non-classication tasks in natural language processing: semantic parsing and information extraction. We show that active learning can signicantly reduce the number of annotated examples required to achieve a given level of performance for these complex tasks.",
            "referenceCount": 16,
            "citationCount": 380,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1999-06-27",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Thompson1999ActiveLF,\n author = {Cynthia A. Thompson and Mary Elaine Califf and R. Mooney},\n booktitle = {International Conference on Machine Learning},\n pages = {406-414},\n title = {Active Learning for Natural Language Parsing and Information Extraction},\n year = {1999}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6f0aa57820d5f1700461b317faabad9b98d0f70d",
            "@type": "ScholarlyArticle",
            "paperId": "6f0aa57820d5f1700461b317faabad9b98d0f70d",
            "corpusId": 15391397,
            "url": "https://www.semanticscholar.org/paper/6f0aa57820d5f1700461b317faabad9b98d0f70d",
            "title": "Developing a natural language interface to complex data",
            "venue": "TODS",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1977,
            "externalIds": {
                "MAG": "1651669872",
                "DBLP": "conf/vldb/HendrixSSS77",
                "DOI": "10.1145/320251.320253",
                "CorpusId": 15391397
            },
            "abstract": "Aspects of an intelligent interface that provides natural language access to a large body of data distributed over a computer network are described. The overall system architecture is presented, showing how a user is buffered from the actual database management systems (DBMSs) by three layers of insulating components. These layers operate in series to convert natural language queries into calls to DBMSs at remote sites. Attention is then focused on the first of the insulating components, the natural language system. A pragmatic approach to language access that has proved useful for building interfaces to databases is described and illustrated by examples. Special language features that increase system usability, such as spelling correction, processing of incomplete inputs, and run-time system personalization, are also discussed. The language system is contrasted with other work in applied natural language processing, and the system's limitations are analyzed.",
            "referenceCount": 32,
            "citationCount": 595,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1977-10-06",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Hendrix1977DevelopingAN,\n author = {G. Hendrix and E. Sacerdoti and Daniel Sagalowicz and Jonathan Slocum},\n booktitle = {TODS},\n pages = {292},\n title = {Developing a natural language interface to complex data},\n year = {1977}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8facac2e5a8d7f3aa0ef55382fd465e0612c1066",
            "@type": "ScholarlyArticle",
            "paperId": "8facac2e5a8d7f3aa0ef55382fd465e0612c1066",
            "corpusId": 2349594,
            "url": "https://www.semanticscholar.org/paper/8facac2e5a8d7f3aa0ef55382fd465e0612c1066",
            "title": "BioC: a minimalist approach to interoperability for biomedical text processing",
            "venue": "American Medical Informatics Association Annual Symposium",
            "publicationVenue": {
                "id": "urn:research:c9e16b3c-2fdf-4b4c-82bf-5cdf3d3435b7",
                "name": "American Medical Informatics Association Annual Symposium",
                "alternate_names": [
                    "Conference of American Medical Informatics Association",
                    "Am Med Informatics Assoc Annu Symp",
                    "Conf Am Med Informatics Assoc",
                    "AMIA"
                ],
                "issn": null,
                "url": "https://knowledge.amia.org/"
            },
            "year": 2013,
            "externalIds": {
                "DBLP": "conf/amia/ComeauDW13",
                "PubMedCentral": "3889917",
                "MAG": "2104148262",
                "DOI": "10.1093/database/bat064",
                "CorpusId": 2349594,
                "PubMed": "24048470"
            },
            "abstract": "A vast amount of scientific information is encoded in natural language text, and the quantity of such text has become so great that it is no longer economically feasible to have a human as the first step in the search process. Natural language processing and text mining tools have become essential to facilitate the search for and extraction of information from text. This has led to vigorous research efforts to create useful tools and to create humanly labeled text corpora, which can be used to improve such tools. To encourage combining these efforts into larger, more powerful and more capable systems, a common interchange format to represent, store and exchange the data in a simple manner between different language processing systems and text mining tools is highly desirable. Here we propose a simple extensible mark-up language format to share text documents and annotations. The proposed annotation approach allows a large number of different annotations to be represented including sentences, tokens, parts of speech, named entities such as genes or diseases and relationships between named entities. In addition, we provide simple code to hold this data, read it from and write it back to extensible mark-up language files and perform some sample processing. We also describe completed as well as ongoing work to apply the approach in several directions. Code and data are available at http://bioc.sourceforge.net/. Database URL: http://bioc.sourceforge.net/",
            "referenceCount": 79,
            "citationCount": 189,
            "influentialCitationCount": 18,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://academic.oup.com/database/article-pdf/doi/10.1093/database/bat064/16734311/bat064.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2013-09-18",
            "journal": {
                "name": "Database: The Journal of Biological Databases and Curation",
                "volume": "2013"
            },
            "citationStyles": {
                "bibtex": "@Article{Comeau2013BioCAM,\n author = {Donald C. Comeau and R. Dogan and P. Ciccarese and K. Cohen and Martin Krallinger and F. Leitner and Zhiyong Lu and Yifan Peng and Fabio Rinaldi and Manabu Torii and Alfonso Valencia and Karin M. Verspoor and Thomas C. Wiegers and Cathy H. Wu and John Wilbur},\n booktitle = {American Medical Informatics Association Annual Symposium},\n journal = {Database: The Journal of Biological Databases and Curation},\n title = {BioC: a minimalist approach to interoperability for biomedical text processing},\n volume = {2013},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:547d483ed1e80066693af561f63daa30ffa8e9fa",
            "@type": "ScholarlyArticle",
            "paperId": "547d483ed1e80066693af561f63daa30ffa8e9fa",
            "corpusId": 264203475,
            "url": "https://www.semanticscholar.org/paper/547d483ed1e80066693af561f63daa30ffa8e9fa",
            "title": "Prolog and Natural-Language Analysis",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1987,
            "externalIds": {
                "MAG": "1973180461",
                "CorpusId": 264203475
            },
            "abstract": "From the Publisher: \nA concise and practical introduction to logic programming and the logic-programming language Prolog, both as vehicles for understanding elementary computational linguistics and as tools for implementing the basic components of natural-language-processing systems.",
            "referenceCount": 156,
            "citationCount": 362,
            "influentialCitationCount": 21,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1987-06-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Pereira1987PrologAN,\n author = {Fernando Pereira and Stuart M. Shieber},\n title = {Prolog and Natural-Language Analysis},\n year = {1987}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fb32ddb26472dcddeb64b768d1137b955fcc596a",
            "@type": "ScholarlyArticle",
            "paperId": "fb32ddb26472dcddeb64b768d1137b955fcc596a",
            "corpusId": 60404960,
            "url": "https://www.semanticscholar.org/paper/fb32ddb26472dcddeb64b768d1137b955fcc596a",
            "title": "Towards a Computational Theory of Grounding in Natural Language Conversation",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1991,
            "externalIds": {
                "MAG": "266665507",
                "DOI": "10.21236/ada248777",
                "CorpusId": 60404960
            },
            "abstract": "Abstract : Theories of speech acts view utterances as actions which attempt to change the mental states of agents participating in a conversation. Recent work in computer science has tried to formalize speech acts in terms of the logic of action in AI planning systems. However most of these planning systems make simplifying assumptions about the world which are too strong to capture many features of conversation. One of these assumptions has been that the intent of an utterance is mutually understood by participants in a conversation, merely in virtue of its having been uttered in their presence. Clark and Marshall, 1981 have assumptions of attention, rationality, and understandability to accomplish this. Perrault, 1990 uses an assumption of observability. While these assumptions may be acceptable for processing written discourse without time constraints, they are not able to handle a large class of natural language utterances, including acknowledgements, and repairs. These phenomena have been studied in a descriptive fashion by sociologists and psychologists. I present ideas leading to a computational processing model of how agents come to reach a state of mutual understanding about intentions behind utterances. This involves a richer, hierarchical notion of speech acts, and models for tracking the state of knowledge in the conversation.",
            "referenceCount": 64,
            "citationCount": 478,
            "influentialCitationCount": 23,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://urresearch.rochester.edu/fileDownloadForInstitutionalItem.action?itemId=4906&itemFileId=7463",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1991-10-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Traum1991TowardsAC,\n author = {D. Traum},\n title = {Towards a Computational Theory of Grounding in Natural Language Conversation},\n year = {1991}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:df3520f52fcf42b4f10ed4b35b3b3f9cd050f290",
            "@type": "ScholarlyArticle",
            "paperId": "df3520f52fcf42b4f10ed4b35b3b3f9cd050f290",
            "corpusId": 13999155,
            "url": "https://www.semanticscholar.org/paper/df3520f52fcf42b4f10ed4b35b3b3f9cd050f290",
            "title": "Limitations of Co-Training for Natural Language Learning from Large Datasets",
            "venue": "Conference on Empirical Methods in Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:41bf9ed3-85b3-4c90-b015-150e31690253",
                "name": "Conference on Empirical Methods in Natural Language Processing",
                "alternate_names": [
                    "Empir Method Nat Lang Process",
                    "Empirical Methods in Natural Language Processing",
                    "Conf Empir Method Nat Lang Process",
                    "EMNLP"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/portal/emnlp"
            },
            "year": 2001,
            "externalIds": {
                "MAG": "1579429723",
                "DBLP": "conf/emnlp/PierceC01",
                "ACL": "W01-0501",
                "CorpusId": 13999155
            },
            "abstract": "Co-Training is a weakly supervised learning paradigm in which the redundancy of the learning task is captured by training two classifiers using separate views of the same data. This enables bootstrapping from a small set of labeled training data via a large set of unlabeled data. This study examines the learning behavior of co-training on natural language processing tasks that typically require large numbers of training instances to achieve usable performance levels. Using base noun phrase bracketing as a case study, we find that co-training reduces by 36% the difference in error between co-trained classifiers and fully supervised classifiers trained on a labeled version of all available data. However, degradation in the quality of the bootstrapped data arises as an obstacle to further improvement. To address this, we propose a moderately supervised variant of cotraining in which a human corrects the mistakes made during automatic labeling. Our analysis suggests that corrected co-training and similar moderately supervised methods may help cotraining scale to large natural language learning tasks.",
            "referenceCount": 18,
            "citationCount": 207,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Pierce2001LimitationsOC,\n author = {D. Pierce and Claire Cardie},\n booktitle = {Conference on Empirical Methods in Natural Language Processing},\n title = {Limitations of Co-Training for Natural Language Learning from Large Datasets},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6d0d60e6502a76eeeb0cc10c724a9de2686dc458",
            "@type": "ScholarlyArticle",
            "paperId": "6d0d60e6502a76eeeb0cc10c724a9de2686dc458",
            "corpusId": 2745545,
            "url": "https://www.semanticscholar.org/paper/6d0d60e6502a76eeeb0cc10c724a9de2686dc458",
            "title": "A critical period for right hemisphere recruitment in American Sign Language processing",
            "venue": "Nature Neuroscience",
            "publicationVenue": {
                "id": "urn:research:7892f01e-f701-4d07-8c36-e108b84ec6ab",
                "name": "Nature Neuroscience",
                "alternate_names": [
                    "Nat Neurosci"
                ],
                "issn": "1097-6256",
                "url": "http://www.nature.com/neuro/"
            },
            "year": 2002,
            "externalIds": {
                "MAG": "1996415504",
                "DOI": "10.1038/nn775",
                "CorpusId": 2745545,
                "PubMed": "11753419"
            },
            "abstract": null,
            "referenceCount": 36,
            "citationCount": 198,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Nature Neuroscience",
                "volume": "5"
            },
            "citationStyles": {
                "bibtex": "@Article{Newman2002ACP,\n author = {A. Newman and D. Bavelier and D. Corina and P. Jezzard and H. Neville},\n booktitle = {Nature Neuroscience},\n journal = {Nature Neuroscience},\n pages = {76-80},\n title = {A critical period for right hemisphere recruitment in American Sign Language processing},\n volume = {5},\n year = {2002}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3aee2d33f8a266749976a78673458e8277b0f4b8",
            "@type": "ScholarlyArticle",
            "paperId": "3aee2d33f8a266749976a78673458e8277b0f4b8",
            "corpusId": 647719,
            "url": "https://www.semanticscholar.org/paper/3aee2d33f8a266749976a78673458e8277b0f4b8",
            "title": "Natural Language Information Retrieval: TREC-8 Report",
            "venue": "Text Retrieval Conference",
            "publicationVenue": {
                "id": "urn:research:b444b4a6-0cd0-46a9-839f-3d2113eaabc4",
                "name": "Text Retrieval Conference",
                "alternate_names": [
                    "TREC",
                    "Text Retr Conf",
                    "Text REtrieval Conference"
                ],
                "issn": null,
                "url": "http://trec.nist.gov/"
            },
            "year": 1994,
            "externalIds": {
                "MAG": "2915677652",
                "DBLP": "conf/trec/StrzalkowskiCKHTL99",
                "CorpusId": 647719
            },
            "abstract": "In this paper we report on the joint GE/Lockheed Martin/Rutgers/NYU natural language information retrieval project as related to the 5th Text Retrieval Conference (TREC-5). The main thrust of this project is to use natural language processing techniques to enhance the effectiveness of full-text document retrieval. Since our first TREC entry in 1992 (as NYU team) the basic premise of our research was to demonstrate that robust if relatively shallow NLP can help to derive a better representation of text documents for statistical search. TREC-5 marks a shift in this approach away from text representation issues and towards query development problems. While our TREC-5 system still performs extensive text processing in order to extract phrasal and other indexing terms, our main focus this year was on query construction using words, sentences, and entire passages to expand initial topic specifications in an attempt to cover their various angles, aspects and contexts. Based on our earlier TREC results indicating that NLP is more effective when long, descriptive queries are used, we allowed for liberal expansion with long passages from related documents imported verbatim into the queries. This method appears to have produced a dramatic improvement in the performance of two different statistical search engines that we tested (Cornell\u2019s SMART and NIST\u2019s Prise) boosting the average precision by at least 40%. \n \nThe overall architecture of TREC-5 system has also changed in a number of ways from TREC-4. The most notable new feature is the stream architecture in which several independent, parallel indexes are built for a given collection, each index reflecting a different representation strategy for text documents. Stream indexes are built using a mixture of different indexing approaches, term extracting, and weighting strategies. We used both SMART and Prise base indexing engines, and selected optimal term weighting strategies for each stream, based on a training collection of approximately 500 MBytes. The final results are produced by a merging procedure that combines ranked list of documents obtained by searching all stream indexes with appropriately preprocessed queries. This allows for an effective combination of alternative retrieval and filtering methods, creating into a meta-search where the contribution of each stream can be optimized through training.",
            "referenceCount": 45,
            "citationCount": 231,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1994-11-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Strzalkowski1994NaturalLI,\n author = {T. Strzalkowski and Louise Guthrie and Jussi Karlgren and Jim Leistensnider and Fang Lin and Jose Perez Carballo and T. Straszheim and Jing Wang and J. Wilding},\n booktitle = {Text Retrieval Conference},\n pages = {39-54},\n title = {Natural Language Information Retrieval: TREC-8 Report},\n year = {1994}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9c7f922903ac2135abf40d40fa993cc9e5b3efae",
            "@type": "ScholarlyArticle",
            "paperId": "9c7f922903ac2135abf40d40fa993cc9e5b3efae",
            "corpusId": 5089747,
            "url": "https://www.semanticscholar.org/paper/9c7f922903ac2135abf40d40fa993cc9e5b3efae",
            "title": "Annotating the World Wide Web using Natural Language",
            "venue": "RIAO Conference",
            "publicationVenue": {
                "id": "urn:research:ea003d98-cb1c-4330-8b54-126ed1761a30",
                "name": "RIAO Conference",
                "alternate_names": [
                    "RIAO",
                    "RIAO Conf"
                ],
                "issn": null,
                "url": null
            },
            "year": 1997,
            "externalIds": {
                "MAG": "164524185",
                "DBLP": "conf/riao/Katz97",
                "DOI": "10.5555/2856695.2856709",
                "CorpusId": 5089747
            },
            "abstract": "This paper describes the START Information Server built at the MIT Artificial Intelligence Laboratory. Available on the World Wide Web since December 1993, the START Server provides users with access to multi-media information in response to questions formulated in English. Over the last 3 years, the START Server answered hundreds of thousands of questions from users all over the world. \n \nThe START Server is built on two foundations: the sentence-level Natural Language processing capability provided by the START Natural Language system and the idea of natural language annotations for multi-media information segments. This paper starts with an overview of sentence-level processing in the START system and then explains how annotating information segments with collections of English sentences makes it possible to use the power of sentence-level natural language processing in the service of multi-media information access. The paper ends with a proposal to annotate the World Wide Web.",
            "referenceCount": 20,
            "citationCount": 199,
            "influentialCitationCount": 14,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "1997-06-25",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Katz1997AnnotatingTW,\n author = {Boris Katz},\n booktitle = {RIAO Conference},\n pages = {136-155},\n title = {Annotating the World Wide Web using Natural Language},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8150a7126a6c43b19cf024732ea3e9d0e35e116b",
            "@type": "ScholarlyArticle",
            "paperId": "8150a7126a6c43b19cf024732ea3e9d0e35e116b",
            "corpusId": 19421712,
            "url": "https://www.semanticscholar.org/paper/8150a7126a6c43b19cf024732ea3e9d0e35e116b",
            "title": "CM-Builder: A Natural Language-Based CASE Tool for Object-Oriented Analysis",
            "venue": "International Conference on Automated Software Engineering",
            "publicationVenue": {
                "id": "urn:research:1c2ab05c-7d69-465e-929d-0920857aedce",
                "name": "International Conference on Automated Software Engineering",
                "alternate_names": [
                    "Autom Softw Eng",
                    "ASE",
                    "Automated Software Engineering",
                    "Int Conf Autom Softw Eng"
                ],
                "issn": null,
                "url": "http://ase.informatik.uni-essen.de/"
            },
            "year": 2003,
            "externalIds": {
                "MAG": "1599578480",
                "DBLP": "journals/ase/HarmainG03",
                "DOI": "10.1023/A:1022916028950",
                "CorpusId": 19421712
            },
            "abstract": null,
            "referenceCount": 59,
            "citationCount": 152,
            "influentialCitationCount": 28,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2003-04-01",
            "journal": {
                "name": "Automated Software Engineering",
                "volume": "10"
            },
            "citationStyles": {
                "bibtex": "@Article{Harmain2003CMBuilderAN,\n author = {H. Harmain and R. Gaizauskas},\n booktitle = {International Conference on Automated Software Engineering},\n journal = {Automated Software Engineering},\n pages = {157-181},\n title = {CM-Builder: A Natural Language-Based CASE Tool for Object-Oriented Analysis},\n volume = {10},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5a434e7edc86f581b1345f04c640581eb580390e",
            "@type": "ScholarlyArticle",
            "paperId": "5a434e7edc86f581b1345f04c640581eb580390e",
            "corpusId": 12817647,
            "url": "https://www.semanticscholar.org/paper/5a434e7edc86f581b1345f04c640581eb580390e",
            "title": "A search engine for natural language applications",
            "venue": "The Web Conference",
            "publicationVenue": {
                "id": "urn:research:e07422f9-c065-40c3-a37b-75e98dce79fe",
                "name": "The Web Conference",
                "alternate_names": [
                    "Web Conf",
                    "WWW"
                ],
                "issn": null,
                "url": "http://www.iw3c2.org/"
            },
            "year": 2005,
            "externalIds": {
                "DBLP": "conf/www/CafarellaE05",
                "MAG": "2154148563",
                "DOI": "10.1145/1060745.1060811",
                "CorpusId": 12817647
            },
            "abstract": "Many modern natural language-processing applications utilize search engines to locate large numbers of Web documents or to compute statistics over the Web corpus. Yet Web search engines are designed and optimized for simple human queries---they are not well suited to support such applications. As a result, these applications are forced to issue millions of successive queries resulting in unnecessary search engine load and in slow applications with limited scalability.In response, this paper introduces the Bindings Engine (BE), which supports queries containing typed variables and  string-processing functions. For example, in response to the query  \"powerful \u2039noun\u203a\" BE will return all the nouns in its index that immediately follow the word \"powerful\", sorted by frequency. In response to the query  \"Cities such as ProperNoun(Head(\u2039NounPhrase\u203a))\", BE will return a list of proper nouns likely to be city names.BE's novel  neighborhood index enables it to do so with O(k) random disk seeks and O(k) serial disk reads, where k is the number of non-variable terms in its query. As a result, BE can yield several orders of magnitude speedup for large-scale language-processing applications. The main cost is a modest increase in space to store the index. We report on experiments validating these claims, and analyze how BE's space-time tradeoff scales with the size of its index and the number of variable types. Finally, we describe how a BE-based application extracts thousands of facts from the Web at interactive speeds in response to simple user queries.",
            "referenceCount": 24,
            "citationCount": 99,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.www2005.org/cdrom/docs/p442.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2005-05-10",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Cafarella2005ASE,\n author = {Michael J. Cafarella and Oren Etzioni},\n booktitle = {The Web Conference},\n pages = {442-452},\n title = {A search engine for natural language applications},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2f785c33bc8ed5bf45a690e28fbc69dffe2f88f8",
            "@type": "ScholarlyArticle",
            "paperId": "2f785c33bc8ed5bf45a690e28fbc69dffe2f88f8",
            "corpusId": 14686719,
            "url": "https://www.semanticscholar.org/paper/2f785c33bc8ed5bf45a690e28fbc69dffe2f88f8",
            "title": "Automatic Transition of Natural Language Software Requirements Specification into Formal Presentation",
            "venue": "International Conference on Applications of Natural Language to Data Bases",
            "publicationVenue": {
                "id": "urn:research:7c0b75bf-65e3-4094-9d72-e8f59ebb154d",
                "name": "International Conference on Applications of Natural Language to Data Bases",
                "alternate_names": [
                    "Appl Nat Lang Data Base",
                    "Int Conf Appl Nat Lang Data Base",
                    "Applications of Natural Language to Data Bases",
                    "NLDB"
                ],
                "issn": null,
                "url": "http://www.nldb.org/"
            },
            "year": 2005,
            "externalIds": {
                "MAG": "1599004321",
                "DBLP": "conf/nldb/IlievaO05",
                "DOI": "10.1007/11428817_45",
                "CorpusId": 14686719
            },
            "abstract": null,
            "referenceCount": 11,
            "citationCount": 96,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://nlping.com/Articles/35130392_NLDB_05.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2005-06-15",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ilieva2005AutomaticTO,\n author = {Magda Ilieva and O. Ormandjieva},\n booktitle = {International Conference on Applications of Natural Language to Data Bases},\n pages = {392-397},\n title = {Automatic Transition of Natural Language Software Requirements Specification into Formal Presentation},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7869fc49e9650b164a18f618f02b318ae41709f5",
            "@type": "ScholarlyArticle",
            "paperId": "7869fc49e9650b164a18f618f02b318ae41709f5",
            "corpusId": 10329681,
            "url": "https://www.semanticscholar.org/paper/7869fc49e9650b164a18f618f02b318ae41709f5",
            "title": "Natural language question-answering systems: 1969",
            "venue": "CACM",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1970,
            "externalIds": {
                "MAG": "2037043950",
                "DBLP": "journals/cacm/Simmons70",
                "DOI": "10.1145/361953.361963",
                "CorpusId": 10329681
            },
            "abstract": "Recent experiments in programming natural language question-answering systems are reviewed to summarize the methods that have been developed for syntactic, semantic, and logical analysis of English strings. It is concluded that at least minimally effective techniques have been devised for answering questions from natural language subsets in small scale experimental systems and that a useful paradigm has evolved to guide research efforts in the field. Current approaches to semantic analysis and logical inference are seen to be effective beginnings but of questionable generality with respect either to subtle aspects of meaning or to applications over large subsets of English. Generalizing from current small-scale experiments to language-processing systems based on dictionaries with thousands of entries\u2014with correspondingly large grammars and semantic systems\u2014may entail a new order of complexity and require the invention and development of entirely different approaches to semantic analysis and question answering.",
            "referenceCount": 73,
            "citationCount": 165,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/361953.361963",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Commun. ACM",
                "volume": "13"
            },
            "citationStyles": {
                "bibtex": "@Article{Simmons1970NaturalLQ,\n author = {R. F. Simmons},\n booktitle = {CACM},\n journal = {Commun. ACM},\n pages = {15-30},\n title = {Natural language question-answering systems: 1969},\n volume = {13},\n year = {1970}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2e3dacb61fdb975bd648d2b26b4b6d566d1043c5",
            "@type": "ScholarlyArticle",
            "paperId": "2e3dacb61fdb975bd648d2b26b4b6d566d1043c5",
            "corpusId": 476793,
            "url": "https://www.semanticscholar.org/paper/2e3dacb61fdb975bd648d2b26b4b6d566d1043c5",
            "title": "The development of language processing support for the ViSiCAST project",
            "venue": "International ACM SIGACCESS Conference on Computers and Accessibility",
            "publicationVenue": {
                "id": "urn:research:6864fc0f-dd47-4798-a829-ac53dd78862f",
                "name": "International ACM SIGACCESS Conference on Computers and Accessibility",
                "alternate_names": [
                    "Conference on Computers and Accessibility",
                    "Conf Comput Access",
                    "Int ACM SIGACCESS Conf Comput Access",
                    "ASSETS"
                ],
                "issn": null,
                "url": "https://dl.acm.org/conference/assets"
            },
            "year": 2000,
            "externalIds": {
                "DBLP": "conf/assets/ElliottGKM00",
                "MAG": "2071661729",
                "DOI": "10.1145/354324.354349",
                "CorpusId": 476793
            },
            "abstract": "ViSiCAST is a major new project funded by the European Union, aiming to provide improved access to services and facilities for deaf citizens through sign language presented by a virtual human, or avatar. We give here an outline of the project, and describe early work in the area of linguistics and language processing. This work covers two distinct but related areas: first, the development of an XML-compliant notation for deaf sign language gestures, which can be used to drive the signing avatar; and, second, the development of a framework supporting the translation of natural language text into this gesture-orientated notation.",
            "referenceCount": 22,
            "citationCount": 139,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/354324.354349",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2000-11-13",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Elliott2000TheDO,\n author = {R. Elliott and J. Glauert and R. Kennaway and I. Marshall},\n booktitle = {International ACM SIGACCESS Conference on Computers and Accessibility},\n pages = {101-108},\n title = {The development of language processing support for the ViSiCAST project},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3532f761369459c91e49e3b0f082bc05fb1efce4",
            "@type": "ScholarlyArticle",
            "paperId": "3532f761369459c91e49e3b0f082bc05fb1efce4",
            "corpusId": 27393564,
            "url": "https://www.semanticscholar.org/paper/3532f761369459c91e49e3b0f082bc05fb1efce4",
            "title": "Natural language interfaces to databases",
            "venue": "Knowledge engineering review (Print)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1990,
            "externalIds": {
                "MAG": "2096619464",
                "DBLP": "journals/ker/CopestakeJ90",
                "DOI": "10.1017/S0269888900005476",
                "CorpusId": 27393564
            },
            "abstract": "Abstract This paper reviews the current state of the art in natural language access to databases. This has been a long-standing area of work in natural language processing. But though some commercial systems are now available, providing front ends has proved much harder than was expected, and the necessary limitations on front ends have to be recognized. The paper discusses the issues, both general to language and task-specific, involved in front end design, and the way these have been addressed, concentrating on the work of the last decade. The focus is on the central process of translating a natural language question into a database query, but other supporting functions are also covered. The points are illustrated by the use of a single example application. The paper concludes with an evaluation of the current state, indicating that future progress will depend on the one hand on general advances in natural language processing, and on the other on expanding the capabilities of traditional databases.",
            "referenceCount": 91,
            "citationCount": 180,
            "influentialCitationCount": 10,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "1990-12-01",
            "journal": {
                "name": "The Knowledge Engineering Review",
                "volume": "5"
            },
            "citationStyles": {
                "bibtex": "@Article{Copestake1990NaturalLI,\n author = {Ann A. Copestake and Karen Sp\u00e4rck Jones},\n booktitle = {Knowledge engineering review (Print)},\n journal = {The Knowledge Engineering Review},\n pages = {225 - 249},\n title = {Natural language interfaces to databases},\n volume = {5},\n year = {1990}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:21c4381856184156b869f610134ba016b58c708e",
            "@type": "ScholarlyArticle",
            "paperId": "21c4381856184156b869f610134ba016b58c708e",
            "corpusId": 15847506,
            "url": "https://www.semanticscholar.org/paper/21c4381856184156b869f610134ba016b58c708e",
            "title": "The role of natural language in requirements engineering",
            "venue": "[1993] Proceedings of the IEEE International Symposium on Requirements Engineering",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1993,
            "externalIds": {
                "MAG": "2128830091",
                "DBLP": "conf/re/Ryan93a",
                "DOI": "10.1109/ISRE.1993.324852",
                "CorpusId": 15847506
            },
            "abstract": "The potential role of natural language processing in the requirements engineering process has been overstated in the past, possibly due to fundamental misunderstandings of the requirements engineering process itself. Since more realistic ambitions are likely to lead to less disappointment in the future, an effort is made to identify some phases and tasks where natural language processing may usefully be applied. It is suggested that the validation of requirements must remain an informal, social process.<<ETX>>",
            "referenceCount": 16,
            "citationCount": 205,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www-public.int-evry.fr/~gibson/Teaching/CSC4504/ReadingMaterial/Ryan93.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1993-01-04",
            "journal": {
                "name": "[1993] Proceedings of the IEEE International Symposium on Requirements Engineering",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ryan1993TheRO,\n author = {K. Ryan},\n booktitle = {[1993] Proceedings of the IEEE International Symposium on Requirements Engineering},\n journal = {[1993] Proceedings of the IEEE International Symposium on Requirements Engineering},\n pages = {240-242},\n title = {The role of natural language in requirements engineering},\n year = {1993}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:572cb39ec0eb6e61e29d4a9c109ab943df82ea2e",
            "@type": "ScholarlyArticle",
            "paperId": "572cb39ec0eb6e61e29d4a9c109ab943df82ea2e",
            "corpusId": 13355900,
            "url": "https://www.semanticscholar.org/paper/572cb39ec0eb6e61e29d4a9c109ab943df82ea2e",
            "title": "Natural Language Generation in Artificial Intelligence and Computational Linguistics",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1990,
            "externalIds": {
                "MAG": "1546928450",
                "DOI": "10.1007/978-1-4757-5945-7",
                "CorpusId": 13355900
            },
            "abstract": null,
            "referenceCount": 5,
            "citationCount": 173,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "1990-11-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Paris1990NaturalLG,\n author = {C\u00e9cile Paris and W. Swartout and W. Mann},\n title = {Natural Language Generation in Artificial Intelligence and Computational Linguistics},\n year = {1990}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b1251807ffb08f881a6cb67c2ec6eb322206bfaf",
            "@type": "ScholarlyArticle",
            "paperId": "b1251807ffb08f881a6cb67c2ec6eb322206bfaf",
            "corpusId": 5598004,
            "url": "https://www.semanticscholar.org/paper/b1251807ffb08f881a6cb67c2ec6eb322206bfaf",
            "title": "Natural Language in Information Retrieval",
            "venue": "Conference on Intelligent Text Processing and Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:a1c1b2d2-5629-4b8f-b764-20ea10fa588c",
                "name": "Conference on Intelligent Text Processing and Computational Linguistics",
                "alternate_names": [
                    "Conf Intell Text Process Comput Linguistics",
                    "CICLing"
                ],
                "issn": null,
                "url": "http://www.cicling.org/"
            },
            "year": 2003,
            "externalIds": {
                "MAG": "9662544",
                "DBLP": "conf/cicling/Dura03",
                "DOI": "10.1007/3-540-36456-0_57",
                "CorpusId": 5598004
            },
            "abstract": null,
            "referenceCount": 5,
            "citationCount": 117,
            "influentialCitationCount": 7,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2003-02-16",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Dura2003NaturalLI,\n author = {E. Dura},\n booktitle = {Conference on Intelligent Text Processing and Computational Linguistics},\n pages = {537-540},\n title = {Natural Language in Information Retrieval},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:935e6d11a84071b259ec5e1c33210239e6fdc7e1",
            "@type": "ScholarlyArticle",
            "paperId": "935e6d11a84071b259ec5e1c33210239e6fdc7e1",
            "corpusId": 11766542,
            "url": "https://www.semanticscholar.org/paper/935e6d11a84071b259ec5e1c33210239e6fdc7e1",
            "title": "Towards a comprehensive medical language processing system: methods and issues",
            "venue": "American Medical Informatics Association Annual Symposium",
            "publicationVenue": {
                "id": "urn:research:c9e16b3c-2fdf-4b4c-82bf-5cdf3d3435b7",
                "name": "American Medical Informatics Association Annual Symposium",
                "alternate_names": [
                    "Conference of American Medical Informatics Association",
                    "Am Med Informatics Assoc Annu Symp",
                    "Conf Am Med Informatics Assoc",
                    "AMIA"
                ],
                "issn": null,
                "url": "https://knowledge.amia.org/"
            },
            "year": 1997,
            "externalIds": {
                "DBLP": "conf/amia/Friedman97",
                "MAG": "152117303",
                "CorpusId": 11766542,
                "PubMed": "9357695"
            },
            "abstract": "Natural language processing (NLP) systems can help solve the data entry problem by providing coded data from textual reports for clinical applications. A number of NLP systems have shown promise, but have not yet achieved wide-spread use for practical applications. In order to achieve such use, a system must have broad coverage of the clinical domain and not be restricted to limited applications. In addition, an NLP system must perform satisfactorily for real-world applications. This paper describes methods and issues associated with an ongoing extension of MedLEE, an operational NLP system, from a limited domain to a domain that encompasses comprehensive clinical information.",
            "referenceCount": 18,
            "citationCount": 139,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Proceedings : a conference of the American Medical Informatics Association. AMIA Fall Symposium",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Friedman1997TowardsAC,\n author = {C. Friedman},\n booktitle = {American Medical Informatics Association Annual Symposium},\n journal = {Proceedings : a conference of the American Medical Informatics Association. AMIA Fall Symposium},\n pages = {\n          595-9\n        },\n title = {Towards a comprehensive medical language processing system: methods and issues},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:93473b7af4ee57bfa3f6d61884c13b68aa064a3f",
            "@type": "ScholarlyArticle",
            "paperId": "93473b7af4ee57bfa3f6d61884c13b68aa064a3f",
            "corpusId": 15368223,
            "url": "https://www.semanticscholar.org/paper/93473b7af4ee57bfa3f6d61884c13b68aa064a3f",
            "title": "Assisting requirement formalization by means of natural language translation",
            "venue": "Formal Methods Syst. Des.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1994,
            "externalIds": {
                "MAG": "2022890244",
                "DBLP": "journals/fmsd/FantechiGRCVM94",
                "DOI": "10.1007/BF01384048",
                "CorpusId": 15368223
            },
            "abstract": null,
            "referenceCount": 25,
            "citationCount": 110,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1994-05-01",
            "journal": {
                "name": "Formal Methods in System Design",
                "volume": "4"
            },
            "citationStyles": {
                "bibtex": "@Article{Fantechi1994AssistingRF,\n author = {A. Fantechi and S. Gnesi and G. Ristori and M. Carenini and Massimo Vanocchi and P. Moreschini},\n booktitle = {Formal Methods Syst. Des.},\n journal = {Formal Methods in System Design},\n pages = {243-263},\n title = {Assisting requirement formalization by means of natural language translation},\n volume = {4},\n year = {1994}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d609fd5e328a06a67f883c08e609bc57583100f0",
            "@type": "ScholarlyArticle",
            "paperId": "d609fd5e328a06a67f883c08e609bc57583100f0",
            "corpusId": 10618934,
            "url": "https://www.semanticscholar.org/paper/d609fd5e328a06a67f883c08e609bc57583100f0",
            "title": "Building Probabilistic Models for Natural Language",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 1996,
            "externalIds": {
                "DBLP": "journals/corr/cmp-lg-9606014",
                "MAG": "1512277306",
                "ArXiv": "cmp-lg/9606014",
                "CorpusId": 10618934
            },
            "abstract": "Building models of language is a central task in natural language processing. Traditionally, language has been modeled with manually-constructed grammars that describe which strings are grammatical and which are not; however, with the recent availability of massive amounts of on-line text, statistically-trained models are an attractive alternative. These models are generally probabilistic, yielding a score reflecting sentence frequency instead of a binary grammaticality judgement. Probabilistic models of language are a fundamental tool in speech recognition for resolving acoustically ambiguous utterances. For example, we prefer the transcription forbear to four bear as the former string is far more frequent in English text. Probabilistic models also have application in optical character recognition, handwriting recognition, spelling correction, part-of-speech tagging, and machine translation. \nIn this thesis, we investigate three problems involving the probabilistic modeling of language: smoothing n-gram models, statistical grammar induction, and bilingual sentence alignment. These three problems employ models at three different levels of language; they involve word-based, constituent-based, and sentence-based models, respectively. We describe techniques for improving the modeling of language at each of these levels, and surpass the performance of existing algorithms for each problem. We approach the three problems using three different frameworks. We relate each of these frameworks to the Bayesian paradigm, and show why each framework used was appropriate for the given problem. Finally, we show how our research addresses two central issues in probabilistic modeling: the sparse data problem and the problem of inducing hidden structure.",
            "referenceCount": 91,
            "citationCount": 118,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1996-06-11",
            "journal": {
                "name": "ArXiv",
                "volume": "cmp-lg/9606014"
            },
            "citationStyles": {
                "bibtex": "@Article{Chen1996BuildingPM,\n author = {Stanley F. Chen},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Building Probabilistic Models for Natural Language},\n volume = {cmp-lg/9606014},\n year = {1996}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:573897b237f58d4c564f2b15344d5a52a1cc13a6",
            "@type": "ScholarlyArticle",
            "paperId": "573897b237f58d4c564f2b15344d5a52a1cc13a6",
            "corpusId": 9010570,
            "url": "https://www.semanticscholar.org/paper/573897b237f58d4c564f2b15344d5a52a1cc13a6",
            "title": "The role of natural language in a multimodal interface",
            "venue": "ACM Symposium on User Interface Software and Technology",
            "publicationVenue": {
                "id": "urn:research:c62b1316-0733-4b4c-8017-c07e18afa954",
                "name": "ACM Symposium on User Interface Software and Technology",
                "alternate_names": [
                    "User Interface Software and Technology",
                    "ACM Symp User Interface Softw Technol",
                    "User Interface Softw Technol",
                    "UIST"
                ],
                "issn": null,
                "url": "http://www.acm.org/uist/"
            },
            "year": 1992,
            "externalIds": {
                "DBLP": "conf/uist/Cohen92",
                "MAG": "1982678125",
                "DOI": "10.1145/142621.142641",
                "CorpusId": 9010570
            },
            "abstract": "Although graphics and direct manipulation are effective interface technologies for some classes of problems, they are limited in many ways. In particular, they provide little support for identifying objects not on the screen, for specifying temporal relations, for identifying and operating on large sets and subsets of entities, and for using the context of interaction. On the other hand, these are precisely strengths of natural language. This paper presents an interface that blends natural language processing and direct manipulation technologies, using each for their characteristic advantages. Specifically, the paper shows how to use natural language to describe objects and temporal relations, and how to use direct manipulation for overcoming hard natural language problems involving the establishment and use of context and pronominal reference. This work has been implemented in SRI's Shoptalk system, a prototype information and decision-support system for manufacturing.",
            "referenceCount": 24,
            "citationCount": 218,
            "influentialCitationCount": 18,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1992-12-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Cohen1992TheRO,\n author = {Philip R. Cohen},\n booktitle = {ACM Symposium on User Interface Software and Technology},\n pages = {143-149},\n title = {The role of natural language in a multimodal interface},\n year = {1992}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6ad8c686b2ba2c85f7f8bc18bbbf21695c7b8349",
            "@type": "ScholarlyArticle",
            "paperId": "6ad8c686b2ba2c85f7f8bc18bbbf21695c7b8349",
            "corpusId": 16394105,
            "url": "https://www.semanticscholar.org/paper/6ad8c686b2ba2c85f7f8bc18bbbf21695c7b8349",
            "title": "Evaluating Natural Language Processors in the Clinical Domain",
            "venue": "Methods of Information in Medicine",
            "publicationVenue": {
                "id": "urn:research:95f5bdab-1f05-4090-899f-3869a15b5707",
                "name": "Methods of Information in Medicine",
                "alternate_names": [
                    "Method Inf Med"
                ],
                "issn": "0026-1270",
                "url": "https://methods.schattauer.de/en/contents/methods-open.html"
            },
            "year": 1998,
            "externalIds": {
                "MAG": "1598801177",
                "DOI": "10.1055/s-0038-1634566",
                "CorpusId": 16394105,
                "PubMed": "9865031"
            },
            "abstract": "Abstract Evaluating natural language processing (NLP) systems in the clinical domain is a difficult task which is important for advancement of the field. A number of NLP systems have been reported that extract information from free-text clinical reports, but not many of the systems have been evaluated. Those that were evaluated noted good performance measures but the results were often weakened by ineffective evaluation methods. In this paper we describe a set of criteria aimed at improving the quality of NLP evaluation studies. We present an overview of NLP evaluations in the clinical domain and also discuss the Message Understanding Conferences (MUC) [1-41. Although these conferences constitute a series of NLP evaluation studies performed outside of the clinical domain, some of the results are relevant within medicine. In addition, we discuss a number of factors which contribute to the complexity that is inherent in the task of evaluating natural language systems.",
            "referenceCount": 39,
            "citationCount": 114,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "1998-10-01",
            "journal": {
                "name": "Methods of Information in Medicine",
                "volume": "37"
            },
            "citationStyles": {
                "bibtex": "@Article{Friedman1998EvaluatingNL,\n author = {Carol Friedman and G. Hripcsak},\n booktitle = {Methods of Information in Medicine},\n journal = {Methods of Information in Medicine},\n pages = {334 - 344},\n title = {Evaluating Natural Language Processors in the Clinical Domain},\n volume = {37},\n year = {1998}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4ce6d2581c409c1ae4ed6be9894acedb3baab6c4",
            "@type": "ScholarlyArticle",
            "paperId": "4ce6d2581c409c1ae4ed6be9894acedb3baab6c4",
            "corpusId": 26009264,
            "url": "https://www.semanticscholar.org/paper/4ce6d2581c409c1ae4ed6be9894acedb3baab6c4",
            "title": "UMLS knowledge for biomedical language processing.",
            "venue": "Bulletin of the Medical Library Association",
            "publicationVenue": {
                "id": "urn:research:51436ebf-d56c-4d87-bcd1-aee8788e2ced",
                "name": "Bulletin of the Medical Library Association",
                "alternate_names": [
                    "Bull Med Libr Assoc",
                    "Bulletin of The Medical Library Association"
                ],
                "issn": "0025-7338",
                "url": "http://www.pubmedcentral.nih.gov/tocrender.fcgi?action=archive&journal=72"
            },
            "year": 1993,
            "externalIds": {
                "MAG": "116322939",
                "CorpusId": 26009264,
                "PubMed": "8472004"
            },
            "abstract": "This paper describes efforts to provide access to the free text in biomedical databases. The focus of the effort is the development of SPECIALIST, an experimental natural language processing system for the biomedical domain. The system includes a broad coverage parser supported by a large lexicon, modules that provide access to the extensive Unified Medical Language System (UMLS) Knowledge Sources, and a retrieval module that permits experiments in information retrieval. The UMLS Metathesaurus and Semantic Network provide a rich source of biomedical concepts and their interrelationships. Investigations have been conducted to determine the type of information required to effect a map between the language of queries and the language of relevant documents. Mappings are never straightforward and often involve multiple inferences.",
            "referenceCount": 14,
            "citationCount": 117,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1993-04-01",
            "journal": {
                "name": "Bulletin of the Medical Library Association",
                "volume": "81 2"
            },
            "citationStyles": {
                "bibtex": "@Article{McCray1993UMLSKF,\n author = {A. McCray and A. Aronson and Allen C. Browne and Rindflesch Tc and A. Razi and S. Srinivasan},\n booktitle = {Bulletin of the Medical Library Association},\n journal = {Bulletin of the Medical Library Association},\n pages = {\n          184-94\n        },\n title = {UMLS knowledge for biomedical language processing.},\n volume = {81 2},\n year = {1993}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:eba5bcf2676112eeff0d953754ffde515e69031b",
            "@type": "ScholarlyArticle",
            "paperId": "eba5bcf2676112eeff0d953754ffde515e69031b",
            "corpusId": 60960056,
            "url": "https://www.semanticscholar.org/paper/eba5bcf2676112eeff0d953754ffde515e69031b",
            "title": "Text Mining: Natural Language techniques and Text Mining applications",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1998,
            "externalIds": {
                "MAG": "1663435917",
                "DOI": "10.1007/978-0-387-35300-5_3",
                "CorpusId": 60960056
            },
            "abstract": null,
            "referenceCount": 10,
            "citationCount": 171,
            "influentialCitationCount": 12,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007%2F978-0-387-35300-5_3.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Rajman1998TextMN,\n author = {M. Rajman and Romaric Besan\u00e7on},\n pages = {50-64},\n title = {Text Mining: Natural Language techniques and Text Mining applications},\n year = {1998}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6443636a690b3595ec63321db5c4c95d8ea44d53",
            "@type": "ScholarlyArticle",
            "paperId": "6443636a690b3595ec63321db5c4c95d8ea44d53",
            "corpusId": 7591554,
            "url": "https://www.semanticscholar.org/paper/6443636a690b3595ec63321db5c4c95d8ea44d53",
            "title": "GEMINI: A Natural Language System for Spoken-Language Understanding",
            "venue": "Annual Meeting of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                "name": "Annual Meeting of the Association for Computational Linguistics",
                "alternate_names": [
                    "Annu Meet Assoc Comput Linguistics",
                    "Meeting of the Association for Computational Linguistics",
                    "ACL",
                    "Meet Assoc Comput Linguistics"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/acl/"
            },
            "year": 1993,
            "externalIds": {
                "MAG": "2118620946",
                "ACL": "H93-1008",
                "DBLP": "conf/naacl/DowdingGABCMM93",
                "ArXiv": "cmp-lg/9407007",
                "DOI": "10.3115/981574.981582",
                "CorpusId": 7591554
            },
            "abstract": "The demands on a natural language understanding system used for spoken language differ somewhat from the demands of text processing. For processing spoken language, there is a tension between the system being as robust as necessary, and as constrained as possible. The robust system will a t tempt to find as sensible an interpretation as possible, even in the presence of performance errors by the speaker, or recognition errors by the speech recognizer. In contrast, in order to provide language constraints to a speech recognizer, a system should be able to detect that a recognized string is not a sentence of English, and disprefer that recognition hypothesis from the speech recognizer. If the coupling is to be tight, with parsing and recognition interleaved, then the parser should be able to enforce as many constraints as possible for partial utterances. The approach taken in Gemini is to tightly constrain language recognition to limit overgeneration, but to extend the language analysis to recognize certain characteristic patterns of spoken utterances (but not generally thought of as part of grammar) and to recognize specific types of performance errors by the speaker.",
            "referenceCount": 29,
            "citationCount": 257,
            "influentialCitationCount": 12,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.3115/1075671.1075680",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1993-03-21",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Dowding1993GEMINIAN,\n author = {J. Dowding and J. Gawron and D. Appelt and J. Bear and Lynn Cherny and Robert C. Moore and D. Moran},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {54-61},\n title = {GEMINI: A Natural Language System for Spoken-Language Understanding},\n year = {1993}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:180b427ba2d06e44df1bb8acbea7e5481b1ff8b8",
            "@type": "ScholarlyArticle",
            "paperId": "180b427ba2d06e44df1bb8acbea7e5481b1ff8b8",
            "corpusId": 13415776,
            "url": "https://www.semanticscholar.org/paper/180b427ba2d06e44df1bb8acbea7e5481b1ff8b8",
            "title": "Natural language watermarking",
            "venue": "IS&T/SPIE Electronic Imaging",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "DBLP": "conf/sswmc/TopkaraTD05",
                "DOI": "10.1117/12.593790",
                "CorpusId": 13415776
            },
            "abstract": "In this paper we discuss natural language watermarking, which uses the structure of the sentence constituents in natural language text in order to insert a watermark. This approach is different from techniques, collectively referred to as \"text watermarking,\" which embed information by modifying the appearance of text elements, such as lines, words, or characters. We provide a survey of the current state of the art in natural language watermarking and introduce terminology, techniques, and tools for text processing. We also examine the parallels and differences of the two watermarking domains and outline how techniques from the image watermarking domain may be applicable to the natural language watermarking domain.",
            "referenceCount": 28,
            "citationCount": 90,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.cerias.purdue.edu/ssl/techreports-ssl/PSI000441.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": "5681"
            },
            "citationStyles": {
                "bibtex": "@Article{Topkara2005NaturalLW,\n author = {Mercan Topkara and C. Taskiran and E. Delp},\n booktitle = {IS&T/SPIE Electronic Imaging},\n title = {Natural language watermarking},\n volume = {5681},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c00c04dc5fa1bf6cb395f91bbe3eea4c6561508c",
            "@type": "ScholarlyArticle",
            "paperId": "c00c04dc5fa1bf6cb395f91bbe3eea4c6561508c",
            "corpusId": 260815175,
            "url": "https://www.semanticscholar.org/paper/c00c04dc5fa1bf6cb395f91bbe3eea4c6561508c",
            "title": "Language processing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1998,
            "externalIds": {
                "MAG": "2337962706",
                "CorpusId": 260815175
            },
            "abstract": "Work in computational linguistics began very soon after the development of the first computers (Booth, Brandwood and Cleave 1958), yet in the intervening four decades there has been a pervasive feeling that progress in computer understanding of natural language has not been commensurate with progress in other computer applications. Recently, a number of prominent researchers in natural language processing met to assess the state of the discipline and discuss future directions (Bates and Weischedel 1993). The consensus of this meeting was that increased attention to large amounts of lexical and domain knowledge was essential for significant progress, and current research efforts in the field reflect this point of view.",
            "referenceCount": 56,
            "citationCount": 112,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1998-10-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Wu1998LanguageP,\n author = {Stephen T Wu and V. Kaggal and Dmitriy Dligach and James J. Masanz and Pei J. Chen and Lee Becker and Wendy W. Chapman and G. Savova and Hongfang Liu and C. Chute},\n pages = {508-513},\n title = {Language processing},\n year = {1998}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1efe8329c9dec8fb276605c388a538220608b608",
            "@type": "ScholarlyArticle",
            "paperId": "1efe8329c9dec8fb276605c388a538220608b608",
            "corpusId": 60831967,
            "url": "https://www.semanticscholar.org/paper/1efe8329c9dec8fb276605c388a538220608b608",
            "title": "Computational complexity and natural language",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1987,
            "externalIds": {
                "MAG": "1486922765",
                "CorpusId": 60831967
            },
            "abstract": "From the Publisher: \nComputational Complexity and Natural Language heralds an entirely new way of looking at grammatical systems. It applies the recently developed computer science tool of complexity theory to the study of natural language. A unified and coherent account emerges of how complexity theory can probe the information-processing structure of grammars, discovering why a grammar is easy or difficult to process and suggesting where to look for additional grammatical constraints. \nFor the linguist or cognitive scientist, the book presents a nontechnical introduction to complexity theory and discusses its strengths, its weaknesses, and how it can be used to study grammars. For the computer scientist, it offers a more sophisticated and efficient computational analysis of linguistic theories. Given the variety of new techniques rising from complexity theory, the authors foresee a developing cooperation among linguists, cognitive scientists, and computer scientists toward understanding the nature of human language. \nThe book also describes a set of case studies that use complexity theory to analyze grammatical problems. And it examines several grammatical systems currently of interest to computational linguists - including spelling-change/dictionary lookup and morphological analysis, agreement processes in natural language, and lexical-functional grammar - demonstrating how complexity analysis can illuminate and improve each one. \nAll of the authors are at the MIT Artificial Intelligence Laboratory. Robert C. Berwick is an Associate Professor in the Department of Electrical Engineering and Computer Science. A Bradford Book.",
            "referenceCount": 3,
            "citationCount": 253,
            "influentialCitationCount": 15,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Hoffman1987ComputationalCA,\n author = {Donald D. Hoffman and C. Prakash and E. Klima and U. Bellugi and Edward Barton and R. Berwick and E. Ristad},\n title = {Computational complexity and natural language},\n year = {1987}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e9c1f510bcf5933d3cf8ec8108a04a9ba601a843",
            "@type": "ScholarlyArticle",
            "paperId": "e9c1f510bcf5933d3cf8ec8108a04a9ba601a843",
            "corpusId": 10983275,
            "url": "https://www.semanticscholar.org/paper/e9c1f510bcf5933d3cf8ec8108a04a9ba601a843",
            "title": "A Fully Statistical Approach to Natural Language Interfaces",
            "venue": "Annual Meeting of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:1e33b3be-b2ab-46e9-96e8-d4eb4bad6e44",
                "name": "Annual Meeting of the Association for Computational Linguistics",
                "alternate_names": [
                    "Annu Meet Assoc Comput Linguistics",
                    "Meeting of the Association for Computational Linguistics",
                    "ACL",
                    "Meet Assoc Comput Linguistics"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/acl/"
            },
            "year": 1996,
            "externalIds": {
                "MAG": "2162455891",
                "DBLP": "conf/acl/MillerSBS96",
                "ACL": "P96-1008",
                "DOI": "10.3115/981863.981871",
                "CorpusId": 10983275
            },
            "abstract": "We present a natural language interface system which is based entirely on trained statistical models. The system consists of three stages of processing: parsing, semantic interpretation, and discourse. Each of these stages is modeled as a statistical process. The models are fully integrated, resulting in an end-to-end system that maps input utterances into meaning representation frames.",
            "referenceCount": 18,
            "citationCount": 156,
            "influentialCitationCount": 12,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://dl.acm.org/ft_gateway.cfm?id=981871&type=pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1996-06-24",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Miller1996AFS,\n author = {Scott Miller and D. Stallard and R. Bobrow and R. Schwartz},\n booktitle = {Annual Meeting of the Association for Computational Linguistics},\n pages = {55-61},\n title = {A Fully Statistical Approach to Natural Language Interfaces},\n year = {1996}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5fcfedf758df620d0888c1ce666e4a55da6bf3e8",
            "@type": "ScholarlyArticle",
            "paperId": "5fcfedf758df620d0888c1ce666e4a55da6bf3e8",
            "corpusId": 60686914,
            "url": "https://www.semanticscholar.org/paper/5fcfedf758df620d0888c1ce666e4a55da6bf3e8",
            "title": "Interpreting anaphors in natural language texts",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1987,
            "externalIds": {
                "MAG": "1539573729",
                "CorpusId": 60686914
            },
            "abstract": "This book explores an approach to text understanding, in particular anaphora resolution, that tries to limit the use of detailed domain knowledge and commonsense inference by exploiting general linguistic knowledge as much as possible. Carter proposes that, because natural language texts are relatively redundant and are constructed considerately, it should be possible in many cases to recover the interpretation of the text by using either linguistic or nonlinguistic techniques. Linguistic techniques are preferable because they are more general and less open-ended. Carter's approach is called \"shallow processing.\" Since domain knowledge and reasoning tend to be expensive to implement, maintain, and use during processing, the shallow processing approach should be much more efficient and portable than an approach based heavily on domain-specific knowledge. If it can at the same time provide reasonable accuracy, then it should be very useful. This seems to be a very sensible approach in principle, and Carter demonstrates that it is quite effective in practice. The shallow processing hypothesis is tested in a program called SPAR (Shallow Processing Anaphor Resolver), which was implemented as part of the author's University of Cambridge thesis. Shallow processing is presented as an engineering solution to the problem of dealing with the use of domain knowledge in text understanding, for certain applications, not as a psychological hypothesis. In the SPAR architecture, general linguistic techniques, such as focusing, are used first. Domain reasoning is only used if more than one candidate referent remains after the application of linguistic knowledge. Although this approach is tested specifically only for reference resolution, obviously it could be extended to other areas of natural language processing in which both linguistic and domain knowledge could be used, such as reasoning. The book presents an excellent and very clear review of both current and older approaches to anaphora resolution, as well as a clear description of the SPAR system. For this reason, it would serve as a very good text for a seminar on reference resolution as well as an extra reading for a class on knowledge representation. One attractive aspect of the SPAR system is that it builds on previous work where appropriate, and extends it where required. In particular, it integrates the work of Boguraev (1979) in parsing, the work of Sidner (1979) in focusing, and the work of Wilks (1975) in preference semantics. Where Sidner's work, for example, is incomplete, as in the treatment of intrasentential anaphora, Carter presents a reasonable extension to handle the additional phenomena. One minor oversight in this work is that, in the treatment of one-anaphora, Carter fails to explore recent pragmatically oriented approaches, such as those discussed by Webber (1983) and Dahl (1984), who propose unified treatments of definite pronouns and one-anaphora. Instead, SPAR uses the older, and probably less effective, syntactic approach suggested by Webber (1978) and Halliday and Hasan (1976). Another commendable aspect of this work is that Carter presents specific statistics on the accuracy of his system-93% of pronominal anaphors (out of 242) and 82% of nonpronominal anaphors (out of 80) are resolved correctly. Although these statistics go beyond what is usually reported, it would have been even more interesting to see a detailed breakdown of anaphor types and accuracy. It would also have been interesting to see statistics on the efficiency of the system, since the overall algorithm is quite complex. This high level of accuracy provides evidence that shallow processing is a promising approach. However, these statistics do raise the issue that we don't really know what level of accuracy in anaphora resolution is \"good enough.\" In fact, the \"good enough\" level of accuracy may vary by application. Ninety-three percent may be accurate enough for some applications, such as machine translation, or message routing, but not for others, such as database update. Perhaps the relatively inexpensive shallow processing approach will turn out to be the method of choice for applications with lower accuracy requirements. A related issue that this work raises is how accurate we can expect to get-that is, how good is human performance on anaphora resolution, and how close is Carter's system to that level? These are questions that we simply don't know the answers to, and that await future research, Carter has done a valuable service in providing his statistics, but it is difficult to interpret them without having these bases of comparison and without having comparable statistics from other approaches. In addition to supporting the shallow processing hypothesis, this work also supports the usefulness (at least from an",
            "referenceCount": 10,
            "citationCount": 131,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "1987-12-28",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Carter1987InterpretingAI,\n author = {D. Carter},\n title = {Interpreting anaphors in natural language texts},\n year = {1987}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:975e196e36420d30bb1df0ebab815aeab81a8fab",
            "@type": "ScholarlyArticle",
            "paperId": "975e196e36420d30bb1df0ebab815aeab81a8fab",
            "corpusId": 33339437,
            "url": "https://www.semanticscholar.org/paper/975e196e36420d30bb1df0ebab815aeab81a8fab",
            "title": "Models of natural language understanding.",
            "venue": "Proceedings of the National Academy of Sciences of the United States of America",
            "publicationVenue": {
                "id": "urn:research:bb95bf2e-8383-4748-bf9d-d6906d091085",
                "name": "Proceedings of the National Academy of Sciences of the United States of America",
                "alternate_names": [
                    "PNAS",
                    "PNAS online",
                    "Proceedings of the National Academy of Sciences of the United States of America.",
                    "Proc National Acad Sci",
                    "Proceedings of the National Academy of Sciences",
                    "Proc National Acad Sci u s Am"
                ],
                "issn": "0027-8424",
                "url": "https://www.jstor.org/journal/procnatiacadscie"
            },
            "year": 1994,
            "externalIds": {
                "MAG": "2612708122",
                "DOI": "10.1073/PNAS.92.22.9977",
                "CorpusId": 33339437,
                "PubMed": "7479812"
            },
            "abstract": "This paper surveys some of the fundamental problems in natural language (NL) understanding (syntax, semantics, pragmatics, and discourse) and the current approaches to solving them. Some recent developments in NL processing include increased emphasis on corpus-based rather than example- or intuition-based work, attempts to measure the coverage and effectiveness of NL systems, dealing with discourse and dialogue phenomena, and attempts to use both analytic and stochastic knowledge. Critical areas for the future include grammars that are appropriate to processing large amounts of real language; automatic (or at least semi-automatic) methods for deriving models of syntax, semantics, and pragmatics; self-adapting systems; and integration with speech processing. Of particular importance are techniques that can be tuned to such requirements as full versus partial understanding and spoken language versus text. Portability (the ease with which one can configure an NL system for a particular application) is one of the largest barriers to application of this technology.",
            "referenceCount": 1,
            "citationCount": 130,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Study",
                "Review"
            ],
            "publicationDate": "1994-11-01",
            "journal": {
                "name": "Proceedings of the National Academy of Sciences of the United States of America",
                "volume": "92 22"
            },
            "citationStyles": {
                "bibtex": "@Article{Bates1994ModelsON,\n author = {M. Bates},\n booktitle = {Proceedings of the National Academy of Sciences of the United States of America},\n journal = {Proceedings of the National Academy of Sciences of the United States of America},\n pages = {\n          9977-82\n        },\n title = {Models of natural language understanding.},\n volume = {92 22},\n year = {1994}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6958e58fcaf3f45572bc4e7cf7d45798f0cad175",
            "@type": "ScholarlyArticle",
            "paperId": "6958e58fcaf3f45572bc4e7cf7d45798f0cad175",
            "corpusId": 8126183,
            "url": "https://www.semanticscholar.org/paper/6958e58fcaf3f45572bc4e7cf7d45798f0cad175",
            "title": "Relational learning techniques for natural language information extraction",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1998,
            "externalIds": {
                "MAG": "33293566",
                "CorpusId": 8126183
            },
            "abstract": "The recent growth of online information available in the form of natural language documents creates a greater need for computing systems with the ability to process those documents to simplify access to the information. One type of processing appropriate for many tasks is information extraction, a type of text skimming that retrieves speci c types of information from text. Although information extraction systems have existed for two decades, these systems have generally been built by hand and contain domain speci c information, making them di cult to port to other domains. A few researchers have begun to apply machine learning to information extraction tasks, but most of this work has involved applying learning to pieces of a much larger system. This paper presents a novel rule representation speci c to natural language and a learning system, Rapier, which learns information extraction rules. Rapier takes pairs of documents and lled templates indicating the information to be extracted and learns patterns to extract llers for the slots in the template. This proposal presents initial results on a small corpus of computer-related job postings with a preliminary version of Rapier. Future research will involve several enhancements to Rapier as well as more thorough testing on several domains and extension to additional natural language processing tasks. We intend to extend the rule representation and algorithm to allow for more types of constraints than are currently supported. We also plan to incorporate active learning, or sample selection, methods, speci cally query by committee, into Rapier. These methods have the potential to substantially reduce the amount of annotation required. We will explore the issue of distinguishing relevant and irrelevant messages, since currently Rapier only extracts from the any messages given to it, assuming that all are relevant. We also intend to run much larger tests with Rapier on multiple domains including the terrorism domain from the third and fourth Message Uncderstanding Conferences, which will allow comparison against other systems. Finally, we plan to demonstrate the generality of Rapier`s representation and algorithm by applying it to other natural language processing tasks such as word sense disambiguation.",
            "referenceCount": 84,
            "citationCount": 112,
            "influentialCitationCount": 21,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Cali1998RelationalLT,\n author = {Mary Elaine Cali and R. Mooney and R. Miikkulainen and B. Porter and B. Kuipers and E. Riloff and Ben Kuipers and W. Cohen and R. V. D. Geijn},\n title = {Relational learning techniques for natural language information extraction},\n year = {1998}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7ae3c73cee30ce7c03b5ee38a3934065d22d7bd7",
            "@type": "ScholarlyArticle",
            "paperId": "7ae3c73cee30ce7c03b5ee38a3934065d22d7bd7",
            "corpusId": 11408831,
            "url": "https://www.semanticscholar.org/paper/7ae3c73cee30ce7c03b5ee38a3934065d22d7bd7",
            "title": "AbstFinder, A Prototype Natural Language Text Abstraction Finder for Use in Requirements Elicitation",
            "venue": "International Conference on Automated Software Engineering",
            "publicationVenue": {
                "id": "urn:research:1c2ab05c-7d69-465e-929d-0920857aedce",
                "name": "International Conference on Automated Software Engineering",
                "alternate_names": [
                    "Autom Softw Eng",
                    "ASE",
                    "Automated Software Engineering",
                    "Int Conf Autom Softw Eng"
                ],
                "issn": null,
                "url": "http://ase.informatik.uni-essen.de/"
            },
            "year": 1997,
            "externalIds": {
                "DBLP": "journals/ase/GoldinB97",
                "MAG": "2095037572",
                "DOI": "10.1023/A:1008617922496",
                "CorpusId": 11408831
            },
            "abstract": null,
            "referenceCount": 79,
            "citationCount": 178,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://se.math.uwaterloo.ca/~dberry/FTP_SITE/reprints.journals.conferences/abstfinder.journal.paper.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1997-10-01",
            "journal": {
                "name": "Automated Software Engineering",
                "volume": "4"
            },
            "citationStyles": {
                "bibtex": "@Article{Goldin1997AbstFinderAP,\n author = {L. Goldin and D. Berry},\n booktitle = {International Conference on Automated Software Engineering},\n journal = {Automated Software Engineering},\n pages = {375-412},\n title = {AbstFinder, A Prototype Natural Language Text Abstraction Finder for Use in Requirements Elicitation},\n volume = {4},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:22889b91aea1d42dd5cc39a2d5d4002b0d5e7262",
            "@type": "ScholarlyArticle",
            "paperId": "22889b91aea1d42dd5cc39a2d5d4002b0d5e7262",
            "corpusId": 2326389,
            "url": "https://www.semanticscholar.org/paper/22889b91aea1d42dd5cc39a2d5d4002b0d5e7262",
            "title": "Metric details for natural-language spatial relations",
            "venue": "TOIS",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1998,
            "externalIds": {
                "DBLP": "journals/tois/EgenhoferS98",
                "MAG": "2015428026",
                "DOI": "10.1145/291128.291129",
                "CorpusId": 2326389
            },
            "abstract": "Spatial relations often are desired answers that a geographic information system (GIS) should generate in response to a user's query. Current GIS's provide only rudimentary support for processing and interpreting natural-language-like spatial relations, because their models and representations are primarily quantitative, while natural-language spatial relations are usually dominated by qualitative properties. Studies of the use of spatial relations in natural language showed that topology accounts for a significant portion of the geometric properties. This article develops a formal model that captures metric details for the description of natural-language spatial relations. The metric details are expressed as refinements of the categories identified by the 9-intersection, a model for topological spatial relations, and provide a more precise measure than does topology alone as to whether a geometric configuration matches with a spatial term or not. Similarly, these measures help in identifying the spatial term that describes a particular configuration. Two groups of metric details are derived: splitting ratios as the normalized values of lengths and areas of intersections; and closeness measures as the normalized distances between disjoint object parts. The resulting model of topological and metric properties was calibrated for 64 spatial terms in English, providing values for the best fit as well as value ranges for the significant parameters of each term. Three examples demonstrate how the framework and its calibrated values are used to determine the best spatial term for a relationship between two geometric objects.",
            "referenceCount": 47,
            "citationCount": 135,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/291128.291129",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Geography",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1998-10-01",
            "journal": {
                "name": "ACM Trans. Inf. Syst.",
                "volume": "16"
            },
            "citationStyles": {
                "bibtex": "@Article{Egenhofer1998MetricDF,\n author = {M. Egenhofer and A. R. B. M. Shariff},\n booktitle = {TOIS},\n journal = {ACM Trans. Inf. Syst.},\n pages = {295-321},\n title = {Metric details for natural-language spatial relations},\n volume = {16},\n year = {1998}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bb3769d5d427a11fc324635ce32ed611af9ec82d",
            "@type": "ScholarlyArticle",
            "paperId": "bb3769d5d427a11fc324635ce32ed611af9ec82d",
            "corpusId": 14038010,
            "url": "https://www.semanticscholar.org/paper/bb3769d5d427a11fc324635ce32ed611af9ec82d",
            "title": "TEAM: A Transportable Natural-Language Interface System",
            "venue": "Applied Natural Language Processing Conference",
            "publicationVenue": {
                "id": "urn:research:a8d0722b-8d14-4675-ae77-47b7d0e3fd64",
                "name": "Applied Natural Language Processing Conference",
                "alternate_names": [
                    "Conf Appl Nat Lang Process",
                    "Appl Nat Lang Process Conf",
                    "Conference on Applied Natural Language Processing",
                    "ANLP"
                ],
                "issn": null,
                "url": "https://aclweb.org/anthology/venues/anlp/"
            },
            "year": 1983,
            "externalIds": {
                "MAG": "2159934185",
                "DBLP": "conf/anlp/Grosz83",
                "ACL": "A83-1006",
                "DOI": "10.3115/974194.974201",
                "CorpusId": 14038010
            },
            "abstract": "A majo r b e n e f i t of u s i n g n a t u r a l l anguage to a c c e s s the i n f o r m a t i o n in a d a t a b a s e i s t h a t i t shifts onto the system the burden of m e d i a t i n g between two views of the d a t a : the way in which the da ta i s s t o r e d ( t h e \" d a t a b a s e v i e w \" ) , and the way in which an e n d u s e r t h i n k s abou t i t ( t h e \" u s e r * s v i e w \" ) . Da tabase i n f o r m a t i o n i s r eco rded in terms of files, r e c o r d s , and fields, while natural-language expressions refer to the same information i n terms of entities and relationships in the world. A major problem in constructing a natural-language interface is determining how to encode and use the information needed to bridge these two views. Current natural-language interface systems require extensive efforts by specialists in natural-language processing to p r o v i d e them w i t h the i n f o r m a t i o n they need to do the b r i d g i n g . The systems are, in effect, handtallored to provide access to particular databases.",
            "referenceCount": 10,
            "citationCount": 105,
            "influentialCitationCount": 11,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.3115/974194.974201",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1983-02-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Grosz1983TEAMAT,\n author = {B. Grosz},\n booktitle = {Applied Natural Language Processing Conference},\n pages = {39-45},\n title = {TEAM: A Transportable Natural-Language Interface System},\n year = {1983}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:27c5f8458a5c2daf6bad6129de93d707f2fe4b32",
            "@type": "ScholarlyArticle",
            "paperId": "27c5f8458a5c2daf6bad6129de93d707f2fe4b32",
            "corpusId": 683832,
            "url": "https://www.semanticscholar.org/paper/27c5f8458a5c2daf6bad6129de93d707f2fe4b32",
            "title": "VIsual TRAnslator: Linking perceptions and natural language descriptions",
            "venue": "Artificial Intelligence Review",
            "publicationVenue": {
                "id": "urn:research:ea8553fe-2467-4367-afee-c4deb3754820",
                "name": "Artificial Intelligence Review",
                "alternate_names": [
                    "Artif Intell Rev"
                ],
                "issn": "0269-2821",
                "url": "https://link.springer.com/journal/10462"
            },
            "year": 1994,
            "externalIds": {
                "DBLP": "journals/air/HerzogW94",
                "MAG": "2008307669",
                "DOI": "10.1007/BF00849073",
                "CorpusId": 683832
            },
            "abstract": null,
            "referenceCount": 46,
            "citationCount": 75,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "1994-03-01",
            "journal": {
                "name": "Artificial Intelligence Review",
                "volume": "8"
            },
            "citationStyles": {
                "bibtex": "@Article{Herzog1994VIsualTL,\n author = {G. Herzog and P. Wazinski},\n booktitle = {Artificial Intelligence Review},\n journal = {Artificial Intelligence Review},\n pages = {175-187},\n title = {VIsual TRAnslator: Linking perceptions and natural language descriptions},\n volume = {8},\n year = {1994}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:12ca5687b9c9972d64e1eba3c8c46d7751e30403",
            "@type": "ScholarlyArticle",
            "paperId": "12ca5687b9c9972d64e1eba3c8c46d7751e30403",
            "corpusId": 62181913,
            "url": "https://www.semanticscholar.org/paper/12ca5687b9c9972d64e1eba3c8c46d7751e30403",
            "title": "Automatic Natural Language Parsing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1985,
            "externalIds": {
                "MAG": "2060862769",
                "DOI": "10.2307/413482",
                "CorpusId": 62181913
            },
            "abstract": "This collection of papers on automatic natural language parsing examines research and development in language processing over the past decade. It focuses on current trends toward a phrase structure grammar and deterministic parsing.",
            "referenceCount": 0,
            "citationCount": 63,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1985-03-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Sparck1985AutomaticNL,\n author = {J. Sparck and Y. Wilks},\n title = {Automatic Natural Language Parsing},\n year = {1985}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:33e854c87a54f8efcc11271763d78abb14de73b7",
            "@type": "ScholarlyArticle",
            "paperId": "33e854c87a54f8efcc11271763d78abb14de73b7",
            "corpusId": 5986993,
            "url": "https://www.semanticscholar.org/paper/33e854c87a54f8efcc11271763d78abb14de73b7",
            "title": "An approach to program understanding by natural language understanding",
            "venue": "Natural Language Engineering",
            "publicationVenue": {
                "id": "urn:research:b0dc264e-1ef6-4c58-be54-d2e6137ac35f",
                "name": "Natural Language Engineering",
                "alternate_names": [
                    "Nat Lang Eng"
                ],
                "issn": "1351-3249",
                "url": "https://www.cambridge.org/core/journals/natural-language-engineering"
            },
            "year": 1999,
            "externalIds": {
                "DBLP": "journals/nle/EtzkornBD99",
                "MAG": "2158235009",
                "DOI": "10.1017/S1351324999002120",
                "CorpusId": 5986993
            },
            "abstract": "An automated tool to assist in the understanding of legacy code components can be useful both in the areas of software reuse and software maintenance. Most previous work in this area has concentrated on functionally-oriented code. Whereas object-oriented code has been shown to be inherently more reusable than functionally-oriented code, in many cases the eventual reuse of the object-oriented code was not considered during development. A knowledge-based, natural language processing approach to the automated understanding of object-oriented code as an aid to the reuse of object-oriented code is described. A system, called the PATRicia system (Program Analysis Tool for Reuse) that implements the approach is examined. The natural language processing/information extraction system that comprises a large part of the PATRicia system is discussed and the knowledge-base of the PATRicia system, in the form of conceptual graphs, is described. Reports provided by natural language-generation in the PATRicia system are described.",
            "referenceCount": 32,
            "citationCount": 41,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.cs.uah.edu/~letzkorn/jnle.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1999-09-01",
            "journal": {
                "name": "Natural Language Engineering",
                "volume": "5"
            },
            "citationStyles": {
                "bibtex": "@Article{Etzkorn1999AnAT,\n author = {L. Etzkorn and Lisa L. Bowen and C. Davis},\n booktitle = {Natural Language Engineering},\n journal = {Natural Language Engineering},\n pages = {219 - 236},\n title = {An approach to program understanding by natural language understanding},\n volume = {5},\n year = {1999}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:70623eb30f076d6de599c4dff13b04bd62e29e0c",
            "@type": "ScholarlyArticle",
            "paperId": "70623eb30f076d6de599c4dff13b04bd62e29e0c",
            "corpusId": 59702970,
            "url": "https://www.semanticscholar.org/paper/70623eb30f076d6de599c4dff13b04bd62e29e0c",
            "title": "Several Studies on Natural Language \u00b7and Back-Propagation",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1987,
            "externalIds": {
                "MAG": "23305027",
                "CorpusId": 59702970
            },
            "abstract": "Recent developments in neural algorithms provide a new approach to natural language processing. Two sets of brief studies show how networks may be developed for processing simple demonstratives and analogies. Two longer studies consider pronoun reference and natural language translation. Taken together, the studies provide additional support for the applicability of these algorithms to natural language processing.",
            "referenceCount": 16,
            "citationCount": 66,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Allen1987SeveralSO,\n author = {R. Allen},\n title = {Several Studies on Natural Language \u00b7and Back-Propagation},\n year = {1987}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0b76ec0d0b9c4e318fc11bc2e70b117c8f5de282",
            "@type": "ScholarlyArticle",
            "paperId": "0b76ec0d0b9c4e318fc11bc2e70b117c8f5de282",
            "corpusId": 260813523,
            "url": "https://www.semanticscholar.org/paper/0b76ec0d0b9c4e318fc11bc2e70b117c8f5de282",
            "title": "The unsupervised learning of natural language structure",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "MAG": "28418033",
                "DBLP": "phd/us/Klein05",
                "CorpusId": 260813523
            },
            "abstract": "There is precisely one complete language processing system to date: the human brain. Though there is debate on how much built-in bias human learners might have, we definitely acquire language in a primarily unsupervised fashion. On the other hand, computational approaches to language processing are almost exclusively supervised, relying on hand-labeled corpora for training. This reliance is largely due to unsupervised approaches having repeatedly exhibited discouraging performance. In particular, the problem of learning syntax (grammar) from completely unannotated text has received a great deal of attention for well over a decade, with little in the way of positive results. We argue that previous methods for this task have generally underperformed because of the representations they used. Overly complex models are easily distracted by non-syntactic correlations (such as topical associations), while overly simple models aren't rich enough to capture important first-order properties of language (such as directionality, adjacency, and valence). \nIn this work, we describe several syntactic representations and associated probabilistic models which are designed to capture the basic character of natural language syntax as directly as possible. First, we examine a nested, distributional method which induces bracketed tree structures. Second, we examine a dependency model which induces word-to-word dependency structures. Finally, we demonstrate that these two models perform better in combination than they do alone. With these representations, high-quality analyses can be learned from surprisingly little text, with no labeled examples, in several languages (we show experiments with English, German, and Chinese). Our results show above-baseline performance in unsupervised parsing in each of these languages. \nGrammar induction methods are useful since parsed corpora exist for only a small number of languages. More generally, most high-level NLP tasks, such as machine translation and question-answering, lack richly annotated corpora, making unsupervised methods extremely appealing even for common languages like English. Finally, while the models in this work are not intended to be cognitively plausible, their effectiveness can inform the investigation of what biases are or are not needed in the human acquisition of language.",
            "referenceCount": 69,
            "citationCount": 153,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Manning2005TheUL,\n author = {Christopher D. Manning and D. Klein},\n title = {The unsupervised learning of natural language structure},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:338d104a0984e05ccdc751538aeb8602d5974595",
            "@type": "ScholarlyArticle",
            "paperId": "338d104a0984e05ccdc751538aeb8602d5974595",
            "corpusId": 28513089,
            "url": "https://www.semanticscholar.org/paper/338d104a0984e05ccdc751538aeb8602d5974595",
            "title": "Natural Language I",
            "venue": "Human Language Technology - The Baltic Perspectiv",
            "publicationVenue": {
                "id": "urn:research:f8e3f8d0-0f40-48c0-b3c0-0c540237b859",
                "name": "Human Language Technology - The Baltic Perspectiv",
                "alternate_names": [
                    "Human Language Technology",
                    "HLT",
                    "Hum Lang Technol",
                    "Hum Lang Technol  Balt Perspect"
                ],
                "issn": null,
                "url": null
            },
            "year": 1989,
            "externalIds": {
                "ACL": "H89-2010",
                "MAG": "2033054767",
                "DBLP": "conf/naacl/Webber89",
                "DOI": "10.3115/1075434.1075447",
                "CorpusId": 28513089
            },
            "abstract": "Except for the final presentation by Hovy, this session focussed on the use of superficial features of Natural Language in text processing (messages, in the case of the first two presentations, unrestricted text in the case of the second two). This is a very brief summary of a moderator's view of the action.",
            "referenceCount": 3,
            "citationCount": 87,
            "influentialCitationCount": 5,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1989-10-15",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Webber1989NaturalLI,\n author = {B. Webber},\n booktitle = {Human Language Technology - The Baltic Perspectiv},\n pages = {69-69},\n title = {Natural Language I},\n year = {1989}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d82c38fb15f18bf22ae71f2d529f346a0edc7f63",
            "@type": "ScholarlyArticle",
            "paperId": "d82c38fb15f18bf22ae71f2d529f346a0edc7f63",
            "corpusId": 2157233,
            "url": "https://www.semanticscholar.org/paper/d82c38fb15f18bf22ae71f2d529f346a0edc7f63",
            "title": "Natural Language with Integrated Deictic and Graphic Gestures",
            "venue": "Human Language Technology - The Baltic Perspectiv",
            "publicationVenue": {
                "id": "urn:research:f8e3f8d0-0f40-48c0-b3c0-0c540237b859",
                "name": "Human Language Technology - The Baltic Perspectiv",
                "alternate_names": [
                    "Human Language Technology",
                    "HLT",
                    "Hum Lang Technol",
                    "Hum Lang Technol  Balt Perspect"
                ],
                "issn": null,
                "url": null
            },
            "year": 1989,
            "externalIds": {
                "MAG": "1520474019",
                "ACL": "H89-2054",
                "DBLP": "conf/naacl/NealTDHS89",
                "DOI": "10.3115/1075434.1075499",
                "CorpusId": 2157233
            },
            "abstract": "People frequently and effectively integrate deictic and graphic gestures with their natural language (NL) when conducting human-to-human dialogue. Similar multi-modal communication can facilitate human interaction with modern sophisticated information processing and decision-aiding computer systems. As part of the CUBRICON project, we are developing NL processing technology that incorporates deictic and graphic gestures with simultaneous coordinated NL for both user inputs and system-generated outputs. Such multi-modal language should be natural and efficient for human-computer dialogue, particularly for presenting or requesting information about objects that are visible, or can be presented visibly, on a graphics display. This paper discusses unique interface capabilities that the CUBRICON system provides including the ability to: (1) accept and understand multi-media input such that references to entities in (spoken or typed) natural language sentences can include coordinated simultaneous pointing to the respective entities on a graphics display; use simultaneous pointing and NL references to disambiguate one another when appropriate; infer the intended referent of a point gesture which is inconsistent with the accompanying NL; (2) dynamically compose and generate multi-modal language that combines NL with deictic gestures and graphic expressions; synchronously present the spoken natural language and coordinated pointing gestures and graphic expressions; discriminate between spoken and written NL.",
            "referenceCount": 29,
            "citationCount": 78,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.3115/1075434.1075499",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1989-10-15",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Article{Neal1989NaturalLW,\n author = {J. Neal and C. Thielman and Z. Dobes and S. Haller and S. Shapiro},\n booktitle = {Human Language Technology - The Baltic Perspectiv},\n pages = {37-52},\n title = {Natural Language with Integrated Deictic and Graphic Gestures},\n year = {1989}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bb731f04c92e30017a28bdbe298255865ef5fa62",
            "@type": "ScholarlyArticle",
            "paperId": "bb731f04c92e30017a28bdbe298255865ef5fa62",
            "corpusId": 60112007,
            "url": "https://www.semanticscholar.org/paper/bb731f04c92e30017a28bdbe298255865ef5fa62",
            "title": "Natural Language Understanding.",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1979,
            "externalIds": {
                "MAG": "269793231",
                "CorpusId": 60112007
            },
            "abstract": "Abstract : Contents: Natural Language Processing Overview; Mechanical Translation, Grammars--Formal Grammars; Transformational Grammars; Systemic Grammar; Case Grammar; Parsing--Overview of Parsing Techniques; Augmented Transition Nets; The General Syntactic Processor; Text Generation; Natural Language Processing Systems--Early Natural Language Systems; Wilk's Mechanical Translation System; LUNAR, SHRDLU, MARGIE, SAM and PAM, LIFER.",
            "referenceCount": 0,
            "citationCount": 62,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "1979-07-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Gardner1979NaturalLU,\n author = {A. Gardner and J. Davidson and T. Winograd},\n title = {Natural Language Understanding.},\n year = {1979}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:692a7abe5aae7171b777833f4c4537e510c89b91",
            "@type": "ScholarlyArticle",
            "paperId": "692a7abe5aae7171b777833f4c4537e510c89b91",
            "corpusId": 35582087,
            "url": "https://www.semanticscholar.org/paper/692a7abe5aae7171b777833f4c4537e510c89b91",
            "title": "Brain signatures of artificial language processing: Evidence challenging the critical period hypothesis",
            "venue": "Proceedings of the National Academy of Sciences of the United States of America",
            "publicationVenue": {
                "id": "urn:research:bb95bf2e-8383-4748-bf9d-d6906d091085",
                "name": "Proceedings of the National Academy of Sciences of the United States of America",
                "alternate_names": [
                    "PNAS",
                    "PNAS online",
                    "Proceedings of the National Academy of Sciences of the United States of America.",
                    "Proc National Acad Sci",
                    "Proceedings of the National Academy of Sciences",
                    "Proc National Acad Sci u s Am"
                ],
                "issn": "0027-8424",
                "url": "https://www.jstor.org/journal/procnatiacadscie"
            },
            "year": 2002,
            "externalIds": {
                "MAG": "2031917397",
                "DOI": "10.1073/pnas.012611199",
                "CorpusId": 35582087,
                "PubMed": "11773629"
            },
            "abstract": "Adult second language learning seems to be more difficult and less efficient than first language acquisition during childhood. By using event-related brain potentials, we show that adults who learned a miniature artificial language display a similar real-time pattern of brain activation when processing this language as native speakers do when processing natural languages. Participants trained in the artificial language showed two event-related brain potential components taken to reflect early automatic and late controlled syntactic processes, whereas untrained participants did not. This result challenges the common view that late second language learners process language in a principally different way from native speakers. Our findings demonstrate that a small system of grammatical rules can be syntactically instantiated by the adult speaker in a way that strongly resembles native-speaker sentence processing.",
            "referenceCount": 43,
            "citationCount": 343,
            "influentialCitationCount": 24,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2002-01-02",
            "journal": {
                "name": "Proceedings of the National Academy of Sciences of the United States of America",
                "volume": "99"
            },
            "citationStyles": {
                "bibtex": "@Article{Friederici2002BrainSO,\n author = {A. Friederici and Karsten Steinhauer and Erdmut Pfeifer},\n booktitle = {Proceedings of the National Academy of Sciences of the United States of America},\n journal = {Proceedings of the National Academy of Sciences of the United States of America},\n pages = {529 - 534},\n title = {Brain signatures of artificial language processing: Evidence challenging the critical period hypothesis},\n volume = {99},\n year = {2002}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8454ccb8edd87d695959358a0b6a993e105f85fa",
            "@type": "ScholarlyArticle",
            "paperId": "8454ccb8edd87d695959358a0b6a993e105f85fa",
            "corpusId": 58487626,
            "url": "https://www.semanticscholar.org/paper/8454ccb8edd87d695959358a0b6a993e105f85fa",
            "title": "Evaluation of Natural Language Processors",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1981,
            "externalIds": {
                "MAG": "1605152559",
                "DBLP": "phd/us/Tennant81",
                "CorpusId": 58487626
            },
            "abstract": "Despite a large amount of research on developing natural language understanding programs, little work has been done on evaluating their performance or potential. The evaluations that have been done have been unsystematic and incomplete. This has lead to uncertainty and confusion over the accomplishments of natural language processing research. \nThe lack of evaluation can be primarily attributed to the difficulty of the problem. The desired behavior of natural language processors has not been clearly specified. Partial progress toward the eventual goals for natural language processors has not been delineated, much less measured. \nThis thesis attempts to clarify some of the difficulties behind evaluating the performance of natural language processors. It also proposes an evaluation method that is designed to be systematic and thorough. The method relies on considering a natural language processor from three viewpoints in the light of several taxonomies of issues relevant to natural language processing. Finally, an evaluation is described of PLANES, a natural language database query system.",
            "referenceCount": 0,
            "citationCount": 42,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Tennant1981EvaluationON,\n author = {H. Tennant},\n title = {Evaluation of Natural Language Processors},\n year = {1981}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6186d5296e377f10600279c84b19fa2258d61c13",
            "@type": "ScholarlyArticle",
            "paperId": "6186d5296e377f10600279c84b19fa2258d61c13",
            "corpusId": 62708639,
            "url": "https://www.semanticscholar.org/paper/6186d5296e377f10600279c84b19fa2258d61c13",
            "title": "Natural language parsing: Contributors",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1985,
            "externalIds": {
                "MAG": "564619820",
                "DOI": "10.1017/CBO9780511597855",
                "CorpusId": 62708639
            },
            "abstract": "Introduction Laurie Karttunen and Arnold M. Zwicky 1. Measuring syntactic complexity relative to discourse context Alice Davison and Richard Lutz 2. Interpreting questions Elisabet Engdahl 3. How can grammars help parsers? Stephen Crain and Janet Dean Fodor 4. Syntactic complexity Lyn Frazier 5. Processing of sentences with intrasentential code switching Aravind K. Joshi 6. Tree adjoining grammars: how much context-sensitivity is required to provide reasonable structural descriptions Aravind K. Joshi 7. Parsing in functional unification grammar Martin Kay 8. Parsing in a free word order language Lauri Karttunen and Martin Kay 9. A new characterization of attachment preferences Fernando C. N. Pereira 10. On not being led up the garden path: the use of context by the pscyhological syntax processor Stephen Crain and Mark Steedman 11. Do listeners compute linguistic representations? Michael K. Tanenhaus, Greg N. Carlson and Mark S. Seidenberg Notes References Index.",
            "referenceCount": 4,
            "citationCount": 274,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1985-05-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Dowty1985NaturalLP,\n author = {David R. Dowty and L. Karttunen and A. Zwicky},\n title = {Natural language parsing: Contributors},\n year = {1985}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b71f7e55305e237698f4e2aebe70cadb310895e8",
            "@type": "ScholarlyArticle",
            "paperId": "b71f7e55305e237698f4e2aebe70cadb310895e8",
            "corpusId": 32858343,
            "url": "https://www.semanticscholar.org/paper/b71f7e55305e237698f4e2aebe70cadb310895e8",
            "title": "The Effectiveness of Stemming for Natural-Language Access to Slovene Textual Data",
            "venue": "Journal of the American Society for Information Science",
            "publicationVenue": {
                "id": "urn:research:e0706bac-2807-4453-89b8-cc7094693384",
                "name": "Journal of the American Society for Information Science",
                "alternate_names": [
                    "J Am Soc Inf Sci"
                ],
                "issn": "0002-8231",
                "url": "http://www3.interscience.wiley.com/cgi-bin/jtoc?ID=27981"
            },
            "year": 1992,
            "externalIds": {
                "DBLP": "journals/jasis/PopovicW92",
                "DOI": "10.1002/(SICI)1097-4571(199206)43:5%3C384::AID-ASI6%3E3.0.CO;2-L",
                "CorpusId": 32858343
            },
            "abstract": "There have been several studies of the use of stemming algorithms for conflating morphological variants in freetext retrieval systems. Comparison of stemmed and nonconflated searches suggests that there are no significant increases in the effectiveness of retrieval when stemming is applied to English-language documents and queries. This article reports the use of stemming on Slovene-language documents and queries, and demonstrates that the use of an appropriate stemming algorithm results in a large, and statistically significant, increase in retrieval effectiveness when compared with nonconflated processing; similar comments apply to the use of manual, right-hand truncation. A comparison is made with stemming of English versions of the same documents and queries and it is concluded that the effectiveness of a stemming algorithm is determined by the morphological complexity of the language that it is designed to process.",
            "referenceCount": 19,
            "citationCount": 162,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "J. Am. Soc. Inf. Sci.",
                "volume": "43"
            },
            "citationStyles": {
                "bibtex": "@Article{Popovic1992TheEO,\n author = {M. Popovic and P. Willett},\n booktitle = {Journal of the American Society for Information Science},\n journal = {J. Am. Soc. Inf. Sci.},\n pages = {384-390},\n title = {The Effectiveness of Stemming for Natural-Language Access to Slovene Textual Data},\n volume = {43},\n year = {1992}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:24b634b4981c29e989a4005dd64fc85588f76d89",
            "@type": "ScholarlyArticle",
            "paperId": "24b634b4981c29e989a4005dd64fc85588f76d89",
            "corpusId": 227287781,
            "url": "https://www.semanticscholar.org/paper/24b634b4981c29e989a4005dd64fc85588f76d89",
            "title": "Spoken Natural Language Dialog Systems: A Practical Approach",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1994,
            "externalIds": {
                "MAG": "1562973825",
                "CorpusId": 227287781
            },
            "abstract": "1. Achieving Spoken Communication with Computers 2. Foundational Work in Integrated Dialog Processing 3. Dialog Processing Theory 4. Computational Model 5. Parsing 6. System Implementation 7. Experimental Results 8. Performance of the Speech Recognizer and Parser 9. Enhanced Dialog Processing: Verifying Doubtful Inputs 10. Extending the State of the Art A. The Goal and Action Description Language B. User's Guide for the Interruptible Prolog Simulator (IPSIM) C. Obtaining the System Software Via the Anonymous FTP",
            "referenceCount": 0,
            "citationCount": 110,
            "influentialCitationCount": 8,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Smith1994SpokenNL,\n author = {Ronnie W. Smith and D. R. Hipp},\n title = {Spoken Natural Language Dialog Systems: A Practical Approach},\n year = {1994}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:efece20355d005fe0dc605d34fb268f94172f3ed",
            "@type": "ScholarlyArticle",
            "paperId": "efece20355d005fe0dc605d34fb268f94172f3ed",
            "corpusId": 932172,
            "url": "https://www.semanticscholar.org/paper/efece20355d005fe0dc605d34fb268f94172f3ed",
            "title": "Cluster processes: a natural language for network traffic",
            "venue": "IEEE Transactions on Signal Processing",
            "publicationVenue": {
                "id": "urn:research:1f6f3f05-6a23-42f0-8d31-98ab8089c1f2",
                "name": "IEEE Transactions on Signal Processing",
                "alternate_names": [
                    "IEEE Trans Signal Process"
                ],
                "issn": "1053-587X",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=78"
            },
            "year": 2003,
            "externalIds": {
                "DBLP": "journals/tsp/HohnVA03",
                "MAG": "2110574819",
                "DOI": "10.1109/TSP.2003.814460",
                "CorpusId": 932172
            },
            "abstract": "We introduce a new approach to the modeling of network traffic, consisting of a semi-experimental methodology combining models with data and a class of point processes (cluster models) to represent the process of packet arrivals in a physically meaningful way. Wavelets are used to examine second-order statistics, and particular attention is paid to the modeling of long-range dependence and to the question of scale invariance at small scales. We analyze in depth the properties of several large traces of packet data and determine unambiguously the influence of network variables such as arrival patterns, durations, and volumes of transport control protocol (TCP) flows and internal flow structure. We show that session-level modeling is not relevant at the packet level. Our findings naturally suggest the use of cluster models. We define a class where TCP flows are directly modeled, and each model parameter has a direct meaning in network terms, allowing the model to be used to predict traffic properties as networks and traffic evolve. The class has the key advantage of being mathematically tractable, in particular, its spectrum is known and can be readily calculated, its wavelet spectrum deduced, interarrival distributions can be obtained, and it can be simulated in a straightforward way. The model reproduces the main second-order features, and results are compared against a simple black box point process alternative. Discrepancies with the model are discussed and explained, and enhancements are outlined. The elephant and mice view of traffic flows is revisited in the light of our findings.",
            "referenceCount": 33,
            "citationCount": 127,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2003-08-01",
            "journal": {
                "name": "IEEE Trans. Signal Process.",
                "volume": "51"
            },
            "citationStyles": {
                "bibtex": "@Article{Hohn2003ClusterPA,\n author = {N. Hohn and D. Veitch and P. Abry},\n booktitle = {IEEE Transactions on Signal Processing},\n journal = {IEEE Trans. Signal Process.},\n pages = {2229-2244},\n title = {Cluster processes: a natural language for network traffic},\n volume = {51},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:11da034f83068898495440030db391cde5e41459",
            "@type": "ScholarlyArticle",
            "paperId": "11da034f83068898495440030db391cde5e41459",
            "corpusId": 1066652,
            "url": "https://www.semanticscholar.org/paper/11da034f83068898495440030db391cde5e41459",
            "title": "Natural Language Computing: The Commercial Applications",
            "venue": "Knowledge engineering review (Print)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1984,
            "externalIds": {
                "DBLP": "journals/ker/Johnson84a",
                "MAG": "2108418355",
                "DOI": "10.1017/S0269888900000588",
                "CorpusId": 1066652
            },
            "abstract": "The computer industry is in the early stages of a revolution. Its capability for processing natural languages will advance dramatically over the next few years. As a result, computer systems which deal with human language will begin to play a central role in the industry. Computers will becooome significantly more accessible to many people, and many tasks which are wholly manual will be handled electronically.",
            "referenceCount": 0,
            "citationCount": 73,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1984-09-01",
            "journal": {
                "name": "The Knowledge Engineering Review",
                "volume": "1"
            },
            "citationStyles": {
                "bibtex": "@Article{Johnson1984NaturalLC,\n author = {T. Johnson},\n booktitle = {Knowledge engineering review (Print)},\n journal = {The Knowledge Engineering Review},\n pages = {11 - 23},\n title = {Natural Language Computing: The Commercial Applications},\n volume = {1},\n year = {1984}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7f1cf767e96f7391bd55950344182d60367463a8",
            "@type": "ScholarlyArticle",
            "paperId": "7f1cf767e96f7391bd55950344182d60367463a8",
            "corpusId": 3908274,
            "url": "https://www.semanticscholar.org/paper/7f1cf767e96f7391bd55950344182d60367463a8",
            "title": "Bidirectional Grammars and the Design of Natural Language Generation Systems",
            "venue": "Theoretical Issues In Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:4d8a0c72-3d6e-4b0c-a0ba-5fac0749e04b",
                "name": "Theoretical Issues In Natural Language Processing",
                "alternate_names": [
                    "TINLAP",
                    "Theor Issue Nat Lang Process"
                ],
                "issn": null,
                "url": null
            },
            "year": 1987,
            "externalIds": {
                "ACL": "T87-1042",
                "MAG": "1970027833",
                "DBLP": "conf/tinlap/Appelt87a",
                "DOI": "10.3115/980304.980352",
                "CorpusId": 3908274
            },
            "abstract": "Intuit ively considered, a grammar is bidirectional if it can be used by processes of approximately equal computat ional complexity to parse and generate sentences of a language. Because we, as computat ional linguists, are concerned with the meaning of the sentences we process, a bidirectional grammar must specify a correspondence between sentences and meaning representations, and this correspondence must be represented in a manner tha t allows one to be computed from the other. Most research in computat ional linguistics has focused on one or the other of the two sides of the problem, with the result tha t relatively little a t tent ion has been given to the issues raised by the incorporation of a single grammar into a system for tasks of both comprehension and generation. Clearly, if it were possible to have t ruly bidirectional grammars in which both parsing and generation processes were efficient, there would be some compelling reasons for adopting them. First , Occam's razor suggests tha t , if language behavior can be explained by hypothesizing only one linguistic representation, such an explanation is clearly preferable to two tha t are applicable in complementary circumstances. Also, from the practical s tandpoint of designing systems tha t will carry on sophisticated dialogues with their users, a single unified formalism for specifying the syntax and semantics of the language is likely to result in a simpler, more robust implementation. The problems of mainta ining consistency between comprehension and generation components when one of them changes have been eliminated. The lexicon is also simpler because its entries need be made but once, and there is no problem of mainta ining consistency between different lexical entries for unders tanding and generation. It is obvious tha t not all grammars are bidirectional. The most fundamental requirement of any bidirectional grammar is tha t it be represented declaratively. If any information is represented procedurally, it must of necessity be represented differently for parsing and generation processes, resulting in an asymmetry between the two. Any change in the grammar would have to be made in two places to mainta in the equivalence between the syntactic and semantic analyses given to sentences by each process. A grammar like DIAGRAM [8] is an example of a grammar for which the encoding of linguistic information",
            "referenceCount": 10,
            "citationCount": 79,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1987-01-07",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Appelt1987BidirectionalGA,\n author = {D. Appelt},\n booktitle = {Theoretical Issues In Natural Language Processing},\n pages = {206-212},\n title = {Bidirectional Grammars and the Design of Natural Language Generation Systems},\n year = {1987}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9f8eb04dbafdfda997ac5e06cd6c521f82bf4e4c",
            "@type": "ScholarlyArticle",
            "paperId": "9f8eb04dbafdfda997ac5e06cd6c521f82bf4e4c",
            "corpusId": 26266327,
            "url": "https://www.semanticscholar.org/paper/9f8eb04dbafdfda997ac5e06cd6c521f82bf4e4c",
            "title": "UIMA: an architectural approach to unstructured information processing in the corporate research environment",
            "venue": "Natural Language Engineering",
            "publicationVenue": {
                "id": "urn:research:b0dc264e-1ef6-4c58-be54-d2e6137ac35f",
                "name": "Natural Language Engineering",
                "alternate_names": [
                    "Nat Lang Eng"
                ],
                "issn": "1351-3249",
                "url": "https://www.cambridge.org/core/journals/natural-language-engineering"
            },
            "year": 2004,
            "externalIds": {
                "DBLP": "journals/nle/FerrucciL04",
                "MAG": "2096797897",
                "DOI": "10.1017/S1351324904003523",
                "CorpusId": 26266327
            },
            "abstract": "IBM Research has over 200 people working on Unstructured Information Management (UIM) technologies with a strong focus on Natural Language Processing (NLP). These researchers are engaged in activities ranging from natural language dialog, information retrieval, topic-tracking, named-entity detection, document classification and machine translation to bioinformatics and open-domain question answering. An analysis of these activities strongly suggested that improving the organization's ability to quickly discover each other's results and rapidly combine different technologies and approaches would accelerate scientific advance. Furthermore, the ability to reuse and combine results through a common architecture and a robust software framework would accelerate the transfer of research results in NLP into IBM's product platforms. Market analyses indicating a growing need to process unstructured information, specifically multilingual, natural language text, coupled with IBM Research's investment in NLP, led to the development of middleware architecture for processing unstructured information dubbed UIMA. At the heart of UIMA are powerful search capabilities and a data-driven framework for the development, composition and distributed deployment of analysis engines. In this paper we give a general introduction to UIMA focusing on the design points of its analysis engine architecture and we discuss how UIMA is helping to accelerate research and technology transfer.",
            "referenceCount": 22,
            "citationCount": 1015,
            "influentialCitationCount": 133,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Business",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2004-09-01",
            "journal": {
                "name": "Natural Language Engineering",
                "volume": "10"
            },
            "citationStyles": {
                "bibtex": "@Article{Ferrucci2004UIMAAA,\n author = {D. Ferrucci and Adam Lally},\n booktitle = {Natural Language Engineering},\n journal = {Natural Language Engineering},\n pages = {327 - 348},\n title = {UIMA: an architectural approach to unstructured information processing in the corporate research environment},\n volume = {10},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6c4b76232bb72897685d19b3d264c6ee3005bc2b",
            "@type": "ScholarlyArticle",
            "paperId": "6c4b76232bb72897685d19b3d264c6ee3005bc2b",
            "corpusId": 204838007,
            "url": "https://www.semanticscholar.org/paper/6c4b76232bb72897685d19b3d264c6ee3005bc2b",
            "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
            "venue": "Journal of machine learning research",
            "publicationVenue": {
                "id": "urn:research:c22e7c36-3bfa-43e1-bb7b-edccdea2a780",
                "name": "Journal of machine learning research",
                "alternate_names": [
                    "Journal of Machine Learning Research",
                    "J mach learn res",
                    "J Mach Learn Res"
                ],
                "issn": "1532-4435",
                "url": "http://www.ai.mit.edu/projects/jmlr/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/jmlr/RaffelSRLNMZLL20",
                "MAG": "2981852735",
                "ArXiv": "1910.10683",
                "CorpusId": 204838007
            },
            "abstract": "Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts every language problem into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new \"Colossal Clean Crawled Corpus\", we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our dataset, pre-trained models, and code.",
            "referenceCount": 133,
            "citationCount": 10929,
            "influentialCitationCount": 1714,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-10-23",
            "journal": {
                "name": "J. Mach. Learn. Res.",
                "volume": "21"
            },
            "citationStyles": {
                "bibtex": "@Article{Raffel2019ExploringTL,\n author = {Colin Raffel and Noam M. Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},\n booktitle = {Journal of machine learning research},\n journal = {J. Mach. Learn. Res.},\n pages = {140:1-140:67},\n title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},\n volume = {21},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a54b56af24bb4873ed0163b77df63b92bd018ddc",
            "@type": "ScholarlyArticle",
            "paperId": "a54b56af24bb4873ed0163b77df63b92bd018ddc",
            "corpusId": 203626972,
            "url": "https://www.semanticscholar.org/paper/a54b56af24bb4873ed0163b77df63b92bd018ddc",
            "title": "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/corr/abs-1910-01108",
                "ArXiv": "1910.01108",
                "MAG": "2978017171",
                "CorpusId": 203626972
            },
            "abstract": "As Transfer Learning from large-scale pre-trained models becomes more prevalent in Natural Language Processing (NLP), operating these large models in on-the-edge and/or under constrained computational training or inference budgets remains challenging. In this work, we propose a method to pre-train a smaller general-purpose language representation model, called DistilBERT, which can then be fine-tuned with good performances on a wide range of tasks like its larger counterparts. While most prior work investigated the use of distillation for building task-specific models, we leverage knowledge distillation during the pre-training phase and show that it is possible to reduce the size of a BERT model by 40%, while retaining 97% of its language understanding capabilities and being 60% faster. To leverage the inductive biases learned by larger models during pre-training, we introduce a triple loss combining language modeling, distillation and cosine-distance losses. Our smaller, faster and lighter model is cheaper to pre-train and we demonstrate its capabilities for on-device computations in a proof-of-concept experiment and a comparative on-device study.",
            "referenceCount": 27,
            "citationCount": 4617,
            "influentialCitationCount": 901,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-10-02",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1910.01108"
            },
            "citationStyles": {
                "bibtex": "@Article{Sanh2019DistilBERTAD,\n author = {Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},\n volume = {abs/1910.01108},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e2dba792360873aef125572812f3673b1a85d850",
            "@type": "ScholarlyArticle",
            "paperId": "e2dba792360873aef125572812f3673b1a85d850",
            "corpusId": 207556454,
            "url": "https://www.semanticscholar.org/paper/e2dba792360873aef125572812f3673b1a85d850",
            "title": "Enriching Word Vectors with Subword Information",
            "venue": "Transactions of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:e0dbf116-86aa-418d-859f-a49952d7e44a",
                "name": "Transactions of the Association for Computational Linguistics",
                "alternate_names": [
                    "Trans Assoc Comput Linguistics",
                    "TACL"
                ],
                "issn": "2307-387X",
                "url": "https://www.mitpressjournals.org/loi/tacl"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2952566282",
                "ACL": "Q17-1010",
                "ArXiv": "1607.04606",
                "DBLP": "journals/tacl/BojanowskiGJM17",
                "DOI": "10.1162/tacl_a_00051",
                "CorpusId": 207556454
            },
            "abstract": "Continuous word representations, trained on large unlabeled corpora are useful for many natural language processing tasks. Popular models that learn such representations ignore the morphology of words, by assigning a distinct vector to each word. This is a limitation, especially for languages with large vocabularies and many rare words. In this paper, we propose a new approach based on the skipgram model, where each word is represented as a bag of character n-grams. A vector representation is associated to each character n-gram; words being represented as the sum of these representations. Our method is fast, allowing to train models on large corpora quickly and allows us to compute word representations for words that did not appear in the training data. We evaluate our word representations on nine different languages, both on word similarity and analogy tasks. By comparing to recently proposed morphological word representations, we show that our vectors achieve state-of-the-art performance on these tasks.",
            "referenceCount": 52,
            "citationCount": 8596,
            "influentialCitationCount": 1158,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00051",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-07-15",
            "journal": {
                "name": "Transactions of the Association for Computational Linguistics",
                "volume": "5"
            },
            "citationStyles": {
                "bibtex": "@Article{Bojanowski2016EnrichingWV,\n author = {Piotr Bojanowski and Edouard Grave and Armand Joulin and Tomas Mikolov},\n booktitle = {Transactions of the Association for Computational Linguistics},\n journal = {Transactions of the Association for Computational Linguistics},\n pages = {135-146},\n title = {Enriching Word Vectors with Subword Information},\n volume = {5},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d",
            "@type": "ScholarlyArticle",
            "paperId": "9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d",
            "corpusId": 5707386,
            "url": "https://www.semanticscholar.org/paper/9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d",
            "title": "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2271840356",
                "ArXiv": "1603.04467",
                "DBLP": "journals/corr/AbadiABBCCCDDDG16",
                "CorpusId": 5707386
            },
            "abstract": "TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.",
            "referenceCount": 60,
            "citationCount": 10166,
            "influentialCitationCount": 1042,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-03-14",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1603.04467"
            },
            "citationStyles": {
                "bibtex": "@Article{Abadi2016TensorFlowLM,\n author = {Mart\u00edn Abadi and Ashish Agarwal and P. Barham and E. Brevdo and Z. Chen and C. Citro and G. Corrado and Andy Davis and J. Dean and Matthieu Devin and S. Ghemawat and I. Goodfellow and A. Harp and G. Irving and M. Isard and Yangqing Jia and R. J\u00f3zefowicz and Lukasz Kaiser and M. Kudlur and J. Levenberg and Dandelion Man\u00e9 and R. Monga and Sherry Moore and D. Murray and C. Olah and M. Schuster and Jonathon Shlens and Benoit Steiner and Ilya Sutskever and Kunal Talwar and P. Tucker and Vincent Vanhoucke and Vijay Vasudevan and F. Vi\u00e9gas and Oriol Vinyals and P. Warden and M. Wattenberg and M. Wicke and Yuan Yu and Xiaoqiang Zheng},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems},\n volume = {abs/1603.04467},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:87f714f3534c7a3ca2bf41ce5825139ddc8247bf",
            "@type": "ScholarlyArticle",
            "paperId": "87f714f3534c7a3ca2bf41ce5825139ddc8247bf",
            "corpusId": 2424256,
            "url": "https://www.semanticscholar.org/paper/87f714f3534c7a3ca2bf41ce5825139ddc8247bf",
            "title": "What to do about non-standard (or non-canonical) language in NLP",
            "venue": "Conference on Natural Language Processing",
            "publicationVenue": {
                "id": "urn:research:7c27a198-3114-4f59-a627-c1ff5aa6ef3d",
                "name": "Conference on Natural Language Processing",
                "alternate_names": [
                    "Sprachkommunikation",
                    "Conf Nat Lang Process",
                    "KONVENS"
                ],
                "issn": null,
                "url": "http://www.wikicfp.com/cfp/program?id=1914"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1608.07836",
                "MAG": "2508920525",
                "DBLP": "conf/konvens/Plank16",
                "CorpusId": 2424256
            },
            "abstract": "Real world data differs radically from the benchmark corpora we use in natural language processing (NLP). As soon as we apply our technologies to the real world, performance drops. The reason for this problem is obvious: NLP models are trained on samples from a limited set of canonical varieties that are considered standard, most prominently English newswire. However, there are many dimensions, e.g., socio-demographics, language, genre, sentence type, etc. on which texts can differ from the standard. The solution is not obvious: we cannot control for all factors, and it is not clear how to best go beyond the current practice of training on homogeneous data from a single domain and language. \nIn this paper, I review the notion of canonicity, and how it shapes our community's approach to language. I argue for leveraging what I call fortuitous data, i.e., non-obvious data that is hitherto neglected, hidden in plain sight, or raw data that needs to be refined. If we embrace the variety of this heterogeneous data by combining it with proper algorithms, we will not only produce more robust models, but will also enable adaptive language technology capable of addressing natural language variation.",
            "referenceCount": 36,
            "citationCount": 81,
            "influentialCitationCount": 7,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2016-08-28",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1608.07836"
            },
            "citationStyles": {
                "bibtex": "@Article{Plank2016WhatTD,\n author = {Barbara Plank},\n booktitle = {Conference on Natural Language Processing},\n journal = {ArXiv},\n title = {What to do about non-standard (or non-canonical) language in NLP},\n volume = {abs/1608.07836},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0",
            "@type": "ScholarlyArticle",
            "paperId": "d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0",
            "corpusId": 1169492,
            "url": "https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0",
            "title": "Show and tell: A neural image caption generator",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "journals/corr/VinyalsTBE14",
                "MAG": "2951912364",
                "ArXiv": "1411.4555",
                "DOI": "10.1109/CVPR.2015.7298935",
                "CorpusId": 1169492
            },
            "abstract": "Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing. In this paper, we present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image. The model is trained to maximize the likelihood of the target description sentence given the training image. Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions. Our model is often quite accurate, which we verify both qualitatively and quantitatively. For instance, while the current state-of-the-art BLEU-1 score (the higher the better) on the Pascal dataset is 25, our approach yields 59, to be compared to human performance around 69. We also show BLEU-1 score improvements on Flickr30k, from 56 to 66, and on SBU, from 19 to 28. Lastly, on the newly released COCO dataset, we achieve a BLEU-4 of 27.7, which is the current state-of-the-art.",
            "referenceCount": 35,
            "citationCount": 5393,
            "influentialCitationCount": 662,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1411.4555",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-11-17",
            "journal": {
                "name": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Vinyals2014ShowAT,\n author = {Oriol Vinyals and Alexander Toshev and Samy Bengio and D. Erhan},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {3156-3164},\n title = {Show and tell: A neural image caption generator},\n year = {2014}\n}\n"
            }
        }
    }
]