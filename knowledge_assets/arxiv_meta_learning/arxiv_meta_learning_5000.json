[
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04449v1",
            "title": "Recursion in Recursion: Two-Level Nested Recursion for Length\n  Generalization with Scalability",
            "updated": "2023-11-08T04:20:56Z",
            "published": "2023-11-08T04:20:56Z",
            "summary": "Binary Balanced Tree RvNNs (BBT-RvNNs) enforce sequence composition according\nto a preset balanced binary tree structure. Thus, their non-linear recursion\ndepth is just $\\log_2 n$ ($n$ being the sequence length). Such logarithmic\nscaling makes BBT-RvNNs efficient and scalable on long sequence tasks such as\nLong Range Arena (LRA). However, such computational efficiency comes at a cost\nbecause BBT-RvNNs cannot solve simple arithmetic tasks like ListOps. On the\nflip side, RvNNs (e.g., Beam Tree RvNN) that do succeed on ListOps (and other\nstructure-sensitive tasks like formal logical inference) are generally several\ntimes more expensive than even RNNs. In this paper, we introduce a novel\nframework -- Recursion in Recursion (RIR) to strike a balance between the two\nsides - getting some of the benefits from both worlds. In RIR, we use a form of\ntwo-level nested recursion - where the outer recursion is a $k$-ary balanced\ntree model with another recursive model (inner recursion) implementing its cell\nfunction. For the inner recursion, we choose Beam Tree RvNNs (BT-RvNN). To\nadjust BT-RvNNs within RIR we also propose a novel strategy of beam alignment.\nOverall, this entails that the total recursive depth in RIR is upper-bounded by\n$k \\log_k n$. Our best RIR-based model is the first model that demonstrates\nhigh ($\\geq 90\\%$) length-generalization performance on ListOps while at the\nsame time being scalable enough to be trainable on long sequence inputs from\nLRA. Moreover, in terms of accuracy in the LRA language tasks, it performs\ncompetitively with Structured State Space Models (SSMs) without any special\ninitialization - outperforming Transformers by a large margin. On the other\nhand, while SSMs can marginally outperform RIR on LRA, they (SSMs) fail to\nlength-generalize on ListOps. Our code is available at:\n\\url{https://github.com/JRC1995/BeamRecursionFamily/}.",
            "author": [
                "Jishnu Ray Chowdhury",
                "Cornelia Caragea"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04449v1",
                "http://arxiv.org/pdf/2311.04449v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04442v1",
            "title": "SS-MAE: Spatial-Spectral Masked Auto-Encoder for Multi-Source Remote\n  Sensing Image Classification",
            "updated": "2023-11-08T03:54:44Z",
            "published": "2023-11-08T03:54:44Z",
            "summary": "Masked image modeling (MIM) is a highly popular and effective self-supervised\nlearning method for image understanding. Existing MIM-based methods mostly\nfocus on spatial feature modeling, neglecting spectral feature modeling.\nMeanwhile, existing MIM-based methods use Transformer for feature extraction,\nsome local or high-frequency information may get lost. To this end, we propose\na spatial-spectral masked auto-encoder (SS-MAE) for HSI and LiDAR/SAR data\njoint classification. Specifically, SS-MAE consists of a spatial-wise branch\nand a spectral-wise branch. The spatial-wise branch masks random patches and\nreconstructs missing pixels, while the spectral-wise branch masks random\nspectral channels and reconstructs missing channels. Our SS-MAE fully exploits\nthe spatial and spectral representations of the input data. Furthermore, to\ncomplement local features in the training stage, we add two lightweight CNNs\nfor feature extraction. Both global and local features are taken into account\nfor feature modeling. To demonstrate the effectiveness of the proposed SS-MAE,\nwe conduct extensive experiments on three publicly available datasets.\nExtensive experiments on three multi-source datasets verify the superiority of\nour SS-MAE compared with several state-of-the-art baselines. The source codes\nare available at \\url{https://github.com/summitgao/SS-MAE}.",
            "author": [
                "Junyan Lin",
                "Feng Gao",
                "Xiaocheng Shi",
                "Junyu Dong",
                "Qian Du"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04442v1",
                "http://arxiv.org/pdf/2311.04442v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04441v1",
            "title": "MixTEA: Semi-supervised Entity Alignment with Mixture Teaching",
            "updated": "2023-11-08T03:49:23Z",
            "published": "2023-11-08T03:49:23Z",
            "summary": "Semi-supervised entity alignment (EA) is a practical and challenging task\nbecause of the lack of adequate labeled mappings as training data. Most works\naddress this problem by generating pseudo mappings for unlabeled entities.\nHowever, they either suffer from the erroneous (noisy) pseudo mappings or\nlargely ignore the uncertainty of pseudo mappings. In this paper, we propose a\nnovel semi-supervised EA method, termed as MixTEA, which guides the model\nlearning with an end-to-end mixture teaching of manually labeled mappings and\nprobabilistic pseudo mappings. We firstly train a student model using few\nlabeled mappings as standard. More importantly, in pseudo mapping learning, we\npropose a bi-directional voting (BDV) strategy that fuses the alignment\ndecisions in different directions to estimate the uncertainty via the joint\nmatching confidence score. Meanwhile, we also design a matching diversity-based\nrectification (MDR) module to adjust the pseudo mapping learning, thus reducing\nthe negative influence of noisy mappings. Extensive results on benchmark\ndatasets as well as further analyses demonstrate the superiority and the\neffectiveness of our proposed method.",
            "author": [
                "Feng Xie",
                "Xin Song",
                "Xiang Zeng",
                "Xuechen Zhao",
                "Lei Tian",
                "Bin Zhou",
                "Yusong Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04441v1",
                "http://arxiv.org/pdf/2311.04441v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04438v1",
            "title": "Reusing Convolutional Neural Network Models through Modularization and\n  Composition",
            "updated": "2023-11-08T03:18:49Z",
            "published": "2023-11-08T03:18:49Z",
            "summary": "With the widespread success of deep learning technologies, many trained deep\nneural network (DNN) models are now publicly available. However, directly\nreusing the public DNN models for new tasks often fails due to mismatching\nfunctionality or performance. Inspired by the notion of modularization and\ncomposition in software reuse, we investigate the possibility of improving the\nreusability of DNN models in a more fine-grained manner. Specifically, we\npropose two modularization approaches named CNNSplitter and GradSplitter, which\ncan decompose a trained convolutional neural network (CNN) model for $N$-class\nclassification into $N$ small reusable modules. Each module recognizes one of\nthe $N$ classes and contains a part of the convolution kernels of the trained\nCNN model. Then, the resulting modules can be reused to patch existing CNN\nmodels or build new CNN models through composition. The main difference between\nCNNSplitter and GradSplitter lies in their search methods: the former relies on\na genetic algorithm to explore search space, while the latter utilizes a\ngradient-based search method. Our experiments with three representative CNNs on\nthree widely-used public datasets demonstrate the effectiveness of the proposed\napproaches. Compared with CNNSplitter, GradSplitter incurs less accuracy loss,\nproduces much smaller modules (19.88% fewer kernels), and achieves better\nresults on patching weak models. In particular, experiments on GradSplitter\nshow that (1) by patching weak models, the average improvement in terms of\nprecision, recall, and F1-score is 17.13%, 4.95%, and 11.47%, respectively, and\n(2) for a new task, compared with the models trained from scratch, reusing\nmodules achieves similar accuracy (the average loss of accuracy is only 2.46%)\nwithout a costly training process. Our approaches provide a viable solution to\nthe rapid development and improvement of CNN models.",
            "author": [
                "Binhang Qi",
                "Hailong Sun",
                "Hongyu Zhang",
                "Xiang Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04438v1",
                "http://arxiv.org/pdf/2311.04438v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04434v1",
            "title": "A Hierarchical Spatial Transformer for Massive Point Samples in\n  Continuous Space",
            "updated": "2023-11-08T02:54:19Z",
            "published": "2023-11-08T02:54:19Z",
            "summary": "Transformers are widely used deep learning architectures. Existing\ntransformers are mostly designed for sequences (texts or time series), images\nor videos, and graphs. This paper proposes a novel transformer model for\nmassive (up to a million) point samples in continuous space. Such data are\nubiquitous in environment sciences (e.g., sensor observations), numerical\nsimulations (e.g., particle-laden flow, astrophysics), and location-based\nservices (e.g., POIs and trajectories). However, designing a transformer for\nmassive spatial points is non-trivial due to several challenges, including\nimplicit long-range and multi-scale dependency on irregular points in\ncontinuous space, a non-uniform point distribution, the potential high\ncomputational costs of calculating all-pair attention across massive points,\nand the risks of over-confident predictions due to varying point density. To\naddress these challenges, we propose a new hierarchical spatial transformer\nmodel, which includes multi-resolution representation learning within a\nquad-tree hierarchy and efficient spatial attention via coarse approximation.\nWe also design an uncertainty quantification branch to estimate prediction\nconfidence related to input feature noise and point sparsity. We provide a\ntheoretical analysis of computational time complexity and memory costs.\nExtensive experiments on both real-world and synthetic datasets show that our\nmethod outperforms multiple baselines in prediction accuracy and our model can\nscale up to one million points on one NVIDIA A100 GPU. The code is available at\n\\url{https://github.com/spatialdatasciencegroup/HST}.",
            "author": [
                "Wenchong He",
                "Zhe Jiang",
                "Tingsong Xiao",
                "Zelin Xu",
                "Shigang Chen",
                "Ronald Fick",
                "Miles Medina",
                "Christine Angelini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04434v1",
                "http://arxiv.org/pdf/2311.04434v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04433v1",
            "title": "SyncBleed: A Realistic Threat Model and Mitigation Strategy for\n  Zero-Involvement Pairing and Authentication (ZIPA)",
            "updated": "2023-11-08T02:48:41Z",
            "published": "2023-11-08T02:48:41Z",
            "summary": "Zero Involvement Pairing and Authentication (ZIPA) is a promising technique\nfor auto-provisioning large networks of Internet-of-Things (IoT) devices.\nPresently, these networks use password-based authentication, which is difficult\nto scale to more than a handful of devices. To deal with this challenge, ZIPA\nenabled devices autonomously extract identical authentication or encryption\nkeys from ambient environmental signals. However, during the key negotiation\nprocess, existing ZIPA systems leak information on a public wireless channel\nwhich can allow adversaries to learn the key. We demonstrate a passive attack\ncalled SyncBleed, which uses leaked information to reconstruct keys generated\nby ZIPA systems. To mitigate SyncBleed, we present TREVOR, an improved key\ngeneration technique that produces nearly identical bit sequences from\nenvironmental signals without leaking information. We demonstrate that TREVOR\ncan generate keys from a variety of environmental signal types under 4 seconds,\nconsistently achieving a 90-95% bit agreement rate across devices within\nvarious environmental sources.",
            "author": [
                "Isaac Ahlgren",
                "Jack West",
                "Kyuin Lee",
                "George K. Thiruvathukal",
                "Neil Klingensmith"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04433v1",
                "http://arxiv.org/pdf/2311.04433v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04942v2",
            "title": "CSAM: A 2.5D Cross-Slice Attention Module for Anisotropic Volumetric\n  Medical Image Segmentation",
            "updated": "2023-11-27T03:12:17Z",
            "published": "2023-11-08T02:13:26Z",
            "summary": "A large portion of volumetric medical data, especially magnetic resonance\nimaging (MRI) data, is anisotropic, as the through-plane resolution is\ntypically much lower than the in-plane resolution. Both 3D and purely 2D deep\nlearning-based segmentation methods are deficient in dealing with such\nvolumetric data since the performance of 3D methods suffers when confronting\nanisotropic data, and 2D methods disregard crucial volumetric information.\nInsufficient work has been done on 2.5D methods, in which 2D convolution is\nmainly used in concert with volumetric information. These models focus on\nlearning the relationship across slices, but typically have many parameters to\ntrain. We offer a Cross-Slice Attention Module (CSAM) with minimal trainable\nparameters, which captures information across all the slices in the volume by\napplying semantic, positional, and slice attention on deep feature maps at\ndifferent scales. Our extensive experiments using different network\narchitectures and tasks demonstrate the usefulness and generalizability of\nCSAM. Associated code is available at https://github.com/aL3x-O-o-Hung/CSAM.",
            "author": [
                "Alex Ling Yu Hung",
                "Haoxin Zheng",
                "Kai Zhao",
                "Xiaoxi Du",
                "Kaifeng Pang",
                "Qi Miao",
                "Steven S. Raman",
                "Demetri Terzopoulos",
                "Kyunghyun Sung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04942v2",
                "http://arxiv.org/pdf/2311.04942v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.05650v1",
            "title": "Learning to Configure Separators in Branch-and-Cut",
            "updated": "2023-11-08T01:50:29Z",
            "published": "2023-11-08T01:50:29Z",
            "summary": "Cutting planes are crucial in solving mixed integer linear programs (MILP) as\nthey facilitate bound improvements on the optimal solution. Modern MILP solvers\nrely on a variety of separators to generate a diverse set of cutting planes by\ninvoking the separators frequently during the solving process. This work\nidentifies that MILP solvers can be drastically accelerated by appropriately\nselecting separators to activate. As the combinatorial separator selection\nspace imposes challenges for machine learning, we learn to separate by\nproposing a novel data-driven strategy to restrict the selection space and a\nlearning-guided algorithm on the restricted space. Our method predicts\ninstance-aware separator configurations which can dynamically adapt during the\nsolve, effectively accelerating the open source MILP solver SCIP by improving\nthe relative solve time up to 72% and 37% on synthetic and real-world MILP\nbenchmarks. Our work complements recent work on learning to select cutting\nplanes and highlights the importance of separator management.",
            "author": [
                "Sirui Li",
                "Wenbin Ouyang",
                "Max B. Paulus",
                "Cathy Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05650v1",
                "http://arxiv.org/pdf/2311.05650v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04939v1",
            "title": "LooGLE: Can Long-Context Language Models Understand Long Contexts?",
            "updated": "2023-11-08T01:45:37Z",
            "published": "2023-11-08T01:45:37Z",
            "summary": "Large language models (LLMs), despite their impressive performance in various\nlanguage tasks, are typically limited to processing texts within context-window\nsize. This limitation has spurred significant research efforts to enhance LLMs'\nlong-context understanding with high-quality long-sequence benchmarks. However,\nprior datasets in this regard suffer from shortcomings, such as short context\nlength compared to the context window of modern LLMs; outdated documents that\nhave data leakage problems; and an emphasis on short dependency tasks rather\nthan long dependency tasks. In this paper, we present LooGLE, a Long Context\nGeneric Language Evaluation benchmark for LLMs' long context understanding.\nLooGLE features relatively new documents post-2022, with over 24,000 tokens per\ndocument and 6,000 newly generated questions spanning diverse domains. Human\nannotators meticulously crafted more than 1,100 high-quality question-answer\npairs to meet the long dependency requirements. These pairs underwent thorough\ncross-validation, yielding the most precise assessment of LLMs' long dependency\ncapabilities. The evaluation of eight state-of-the-art LLMs on LooGLE revealed\nkey findings: (i) commercial models outperformed open-sourced models; (ii) LLMs\nexcelled in short dependency tasks like short question-answering and cloze\ntasks but struggled with more intricate long dependency tasks; (iii) in-context\nlearning and chaining thoughts offered only marginal improvements; (iv)\nretrieval-based techniques demonstrated substantial benefits for short\nquestion-answering, while strategies for extending context window length had\nlimited impact on long context understanding. As such, LooGLE not only provides\na systematic and comprehensive evaluation schema on long-context LLMs, but also\nsheds light on future development of enhanced models towards \"true long-context\nunderstanding\".",
            "author": [
                "Jiaqi Li",
                "Mengmeng Wang",
                "Zilong Zheng",
                "Muhan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04939v1",
                "http://arxiv.org/pdf/2311.04939v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04420v1",
            "title": "Data Factors for Better Compositional Generalization",
            "updated": "2023-11-08T01:27:34Z",
            "published": "2023-11-08T01:27:34Z",
            "summary": "Recent diagnostic datasets on compositional generalization, such as SCAN\n(Lake and Baroni, 2018) and COGS (Kim and Linzen, 2020), expose severe problems\nin models trained from scratch on these datasets. However, in contrast to this\npoor performance, state-of-the-art models trained on larger and more general\ndatasets show better generalization ability. In this work, to reconcile this\ninconsistency, we conduct an empirical analysis by training Transformer models\non a variety of training sets with different data factors, including dataset\nscale, pattern complexity, example difficulty, etc. First, we show that\nincreased dataset complexity can lead to better generalization behavior on\nmultiple different generalization challenges. To further understand this\nimprovement, we show two axes of the benefit from more complex datasets: they\nprovide more diverse examples so compositional understanding becomes more\neffective, and they also prevent ungeneralizable memorization of the examples\ndue to reduced example repetition frequency. Finally, we explore how training\nexamples of different difficulty levels influence generalization differently.\nOn synthetic datasets, simple examples invoke stronger compositionality than\nhard examples do. On larger-scale real language datasets, while hard examples\nbecome more important potentially to ensure decent data coverage, a balanced\nmixture of simple and hard examples manages to induce the strongest\ngeneralizability. The code and data for this work are available at\nhttps://github.com/owenzx/data4comp",
            "author": [
                "Xiang Zhou",
                "Yichen Jiang",
                "Mohit Bansal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04420v1",
                "http://arxiv.org/pdf/2311.04420v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04417v1",
            "title": "Evaluating Emerging AI/ML Accelerators: IPU, RDU, and NVIDIA/AMD GPUs",
            "updated": "2023-11-08T01:06:25Z",
            "published": "2023-11-08T01:06:25Z",
            "summary": "The relentless advancement of artificial intelligence (AI) and machine\nlearning (ML) applications necessitates the development of specialized hardware\naccelerators capable of handling the increasing complexity and computational\ndemands. Traditional computing architectures, based on the von Neumann model,\nare being outstripped by the requirements of contemporary AI/ML algorithms,\nleading to a surge in the creation of accelerators like the Graphcore\nIntelligence Processing Unit (IPU), Sambanova Reconfigurable Dataflow Unit\n(RDU), and enhanced GPU platforms. These hardware accelerators are\ncharacterized by their innovative data-flow architectures and other design\noptimizations that promise to deliver superior performance and energy\nefficiency for AI/ML tasks.\n  This research provides a preliminary evaluation and comparison of these\ncommercial AI/ML accelerators, delving into their hardware and software design\nfeatures to discern their strengths and unique capabilities. By conducting a\nseries of benchmark evaluations on common DNN operators and other AI/ML\nworkloads, we aim to illuminate the advantages of data-flow architectures over\nconventional processor designs and offer insights into the performance\ntrade-offs of each platform. The findings from our study will serve as a\nvaluable reference for the design and performance expectations of research\nprototypes, thereby facilitating the development of next-generation hardware\naccelerators tailored for the ever-evolving landscape of AI/ML applications.\nThrough this analysis, we aspire to contribute to the broader understanding of\ncurrent accelerator technologies and to provide guidance for future innovations\nin the field.",
            "author": [
                "Hongwu Peng",
                "Caiwen Ding",
                "Tong Geng",
                "Sutanay Choudhury",
                "Kevin Barker",
                "Ang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04417v1",
                "http://arxiv.org/pdf/2311.04417v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.DC",
                "cs.LG",
                "cs.PF",
                "C.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04414v2",
            "title": "Learning the What and How of Annotation in Video Object Segmentation",
            "updated": "2023-11-11T19:15:57Z",
            "published": "2023-11-08T00:56:31Z",
            "summary": "Video Object Segmentation (VOS) is crucial for several applications, from\nvideo editing to video data generation. Training a VOS model requires an\nabundance of manually labeled training videos. The de-facto traditional way of\nannotating objects requires humans to draw detailed segmentation masks on the\ntarget objects at each video frame. This annotation process, however, is\ntedious and time-consuming. To reduce this annotation cost, in this paper, we\npropose EVA-VOS, a human-in-the-loop annotation framework for video object\nsegmentation. Unlike the traditional approach, we introduce an agent that\npredicts iteratively both which frame (\"What\") to annotate and which annotation\ntype (\"How\") to use. Then, the annotator annotates only the selected frame that\nis used to update a VOS module, leading to significant gains in annotation\ntime. We conduct experiments on the MOSE and the DAVIS datasets and we show\nthat: (a) EVA-VOS leads to masks with accuracy close to the human agreement\n3.5x faster than the standard way of annotating videos; (b) our frame selection\nachieves state-of-the-art performance; (c) EVA-VOS yields significant\nperformance gains in terms of annotation time compared to all other methods and\nbaselines.",
            "author": [
                "Thanos Delatolas",
                "Vicky Kalogeiton",
                "Dim P. Papadopoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04414v2",
                "http://arxiv.org/pdf/2311.04414v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04938v1",
            "title": "Improved DDIM Sampling with Moment Matching Gaussian Mixtures",
            "updated": "2023-11-08T00:24:50Z",
            "published": "2023-11-08T00:24:50Z",
            "summary": "We propose using a Gaussian Mixture Model (GMM) as reverse transition\noperator (kernel) within the Denoising Diffusion Implicit Models (DDIM)\nframework, which is one of the most widely used approaches for accelerated\nsampling from pre-trained Denoising Diffusion Probabilistic Models (DDPM).\nSpecifically we match the first and second order central moments of the DDPM\nforward marginals by constraining the parameters of the GMM. We see that moment\nmatching is sufficient to obtain samples with equal or better quality than the\noriginal DDIM with Gaussian kernels. We provide experimental results with\nunconditional models trained on CelebAHQ and FFHQ and class-conditional models\ntrained on ImageNet datasets respectively. Our results suggest that using the\nGMM kernel leads to significant improvements in the quality of the generated\nsamples when the number of sampling steps is small, as measured by FID and IS\nmetrics. For example on ImageNet 256x256, using 10 sampling steps, we achieve a\nFID of 6.94 and IS of 207.85 with a GMM kernel compared to 10.15 and 196.73\nrespectively with a Gaussian kernel.",
            "author": [
                "Prasad Gabbur"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04938v1",
                "http://arxiv.org/pdf/2311.04938v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "I.2, I.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04406v1",
            "title": "CompactTag: Minimizing Computation Overheads in Actively-Secure MPC for\n  Deep Neural Networks",
            "updated": "2023-11-08T00:18:08Z",
            "published": "2023-11-08T00:18:08Z",
            "summary": "Secure Multiparty Computation (MPC) protocols enable secure evaluation of a\ncircuit by several parties, even in the presence of an adversary who\nmaliciously corrupts all but one of the parties. These MPC protocols are\nconstructed using the well-known secret-sharing-based paradigm (SPDZ and\nSPDZ2k), where the protocols ensure security against a malicious adversary by\ncomputing Message Authentication Code (MAC) tags on the input shares and then\nevaluating the circuit with these input shares and tags. However, this tag\ncomputation adds a significant runtime overhead, particularly for machine\nlearning (ML) applications with numerous linear computation layers such as\nconvolutions and fully connected layers.\n  To alleviate the tag computation overhead, we introduce CompactTag, a\nlightweight algorithm for generating MAC tags specifically tailored for linear\nlayers in ML. Linear layer operations in ML, including convolutions, can be\ntransformed into Toeplitz matrix multiplications. For the multiplication of two\nmatrices with dimensions T1 x T2 and T2 x T3 respectively, SPDZ2k required O(T1\nx T2 x T3) local multiplications for the tag computation. In contrast,\nCompactTag only requires O(T1 x T2 + T1 x T3 + T2 x T3) local multiplications,\nresulting in a substantial performance boost for various ML models.\n  We empirically compared our protocol to the SPDZ2k protocol for various ML\ncircuits, including ResNet Training-Inference, Transformer Training-Inference,\nand VGG16 Training-Inference. SPDZ2k dedicated around 30% of its online runtime\nfor tag computation. CompactTag speeds up this tag computation bottleneck by up\nto 23x, resulting in up to 1.47x total online phase runtime speedups for\nvarious ML workloads.",
            "author": [
                "Yongqin Wang",
                "Pratik Sarkar",
                "Nishat Koti",
                "Arpita Patra",
                "Murali Annavaram"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04406v1",
                "http://arxiv.org/pdf/2311.04406v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04402v1",
            "title": "Likelihood Ratio Confidence Sets for Sequential Decision Making",
            "updated": "2023-11-08T00:10:21Z",
            "published": "2023-11-08T00:10:21Z",
            "summary": "Certifiable, adaptive uncertainty estimates for unknown quantities are an\nessential ingredient of sequential decision-making algorithms. Standard\napproaches rely on problem-dependent concentration results and are limited to a\nspecific combination of parameterization, noise family, and estimator. In this\npaper, we revisit the likelihood-based inference principle and propose to use\nlikelihood ratios to construct any-time valid confidence sequences without\nrequiring specialized treatment in each application scenario. Our method is\nespecially suitable for problems with well-specified likelihoods, and the\nresulting sets always maintain the prescribed coverage in a model-agnostic\nmanner. The size of the sets depends on a choice of estimator sequence in the\nlikelihood ratio. We discuss how to provably choose the best sequence of\nestimators and shed light on connections to online convex optimization with\nalgorithms such as Follow-the-Regularized-Leader. To counteract the initially\nlarge bias of the estimators, we propose a reweighting scheme that also opens\nup deployment in non-parametric settings such as RKHS function classes. We\nprovide a non-asymptotic analysis of the likelihood ratio confidence sets size\nfor generalized linear models, using insights from convex duality and online\nlearning. We showcase the practical strength of our method on generalized\nlinear bandit problems, survival analysis, and bandits with various additive\nnoise distributions.",
            "author": [
                "Nicolas Emmenegger",
                "Mojm\u00edr Mutn\u00fd",
                "Andreas Krause"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04402v1",
                "http://arxiv.org/pdf/2311.04402v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04400v1",
            "title": "LRM: Large Reconstruction Model for Single Image to 3D",
            "updated": "2023-11-08T00:03:52Z",
            "published": "2023-11-08T00:03:52Z",
            "summary": "We propose the first Large Reconstruction Model (LRM) that predicts the 3D\nmodel of an object from a single input image within just 5 seconds. In contrast\nto many previous methods that are trained on small-scale datasets such as\nShapeNet in a category-specific fashion, LRM adopts a highly scalable\ntransformer-based architecture with 500 million learnable parameters to\ndirectly predict a neural radiance field (NeRF) from the input image. We train\nour model in an end-to-end manner on massive multi-view data containing around\n1 million objects, including both synthetic renderings from Objaverse and real\ncaptures from MVImgNet. This combination of a high-capacity model and\nlarge-scale training data empowers our model to be highly generalizable and\nproduce high-quality 3D reconstructions from various testing inputs including\nreal-world in-the-wild captures and images from generative models. Video demos\nand interactable 3D meshes can be found on this website:\nhttps://yiconghong.me/LRM/.",
            "author": [
                "Yicong Hong",
                "Kai Zhang",
                "Jiuxiang Gu",
                "Sai Bi",
                "Yang Zhou",
                "Difan Liu",
                "Feng Liu",
                "Kalyan Sunkavalli",
                "Trung Bui",
                "Hao Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04400v1",
                "http://arxiv.org/pdf/2311.04400v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16154v1",
            "title": "Stepping out of Flatland: Discovering Behavior Patterns as Topological\n  Structures in Cyber Hypergraphs",
            "updated": "2023-11-08T00:00:33Z",
            "published": "2023-11-08T00:00:33Z",
            "summary": "Data breaches and ransomware attacks occur so often that they have become\npart of our daily news cycle. This is due to a myriad of factors, including the\nincreasing number of internet-of-things devices, shift to remote work during\nthe pandemic, and advancement in adversarial techniques, which all contribute\nto the increase in both the complexity of data captured and the challenge of\nprotecting our networks. At the same time, cyber research has made strides,\nleveraging advances in machine learning and natural language processing to\nfocus on identifying sophisticated attacks that are known to evade conventional\nmeasures. While successful, the shortcomings of these methods, particularly the\nlack of interpretability, are inherent and difficult to overcome. Consequently,\nthere is an ever-increasing need to develop new tools for analyzing cyber data\nto enable more effective attack detection. In this paper, we present a novel\nframework based in the theory of hypergraphs and topology to understand data\nfrom cyber networks through topological signatures, which are both flexible and\ncan be traced back to the log data. While our approach's mathematical grounding\nrequires some technical development, this pays off in interpretability, which\nwe will demonstrate with concrete examples in a large-scale cyber network\ndataset. These examples are an introduction to the broader possibilities that\nlie ahead; our goal is to demonstrate the value of applying methods from the\nburgeoning fields of hypernetwork science and applied topology to understand\nrelationships among behaviors in cyber data.",
            "author": [
                "Helen Jenne",
                "Sinan G. Aksoy",
                "Daniel Best",
                "Alyson Bittner",
                "Gregory Henselman-Petrusek",
                "Cliff Joslyn",
                "Bill Kay",
                "Audun Myers",
                "Garret Seppala",
                "Jackson Warley",
                "Stephen J. Young",
                "Emilie Purvine"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16154v1",
                "http://arxiv.org/pdf/2311.16154v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "55N31"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04397v1",
            "title": "ToP-ToM: Trust-aware Robot Policy with Theory of Mind",
            "updated": "2023-11-07T23:55:56Z",
            "published": "2023-11-07T23:55:56Z",
            "summary": "Theory of Mind (ToM) is a fundamental cognitive architecture that endows\nhumans with the ability to attribute mental states to others. Humans infer the\ndesires, beliefs, and intentions of others by observing their behavior and, in\nturn, adjust their actions to facilitate better interpersonal communication and\nteam collaboration. In this paper, we investigated trust-aware robot policy\nwith the theory of mind in a multiagent setting where a human collaborates with\na robot against another human opponent. We show that by only focusing on team\nperformance, the robot may resort to the reverse psychology trick, which poses\na significant threat to trust maintenance. The human's trust in the robot will\ncollapse when they discover deceptive behavior by the robot. To mitigate this\nproblem, we adopt the robot theory of mind model to infer the human's trust\nbeliefs, including true belief and false belief (an essential element of ToM).\nWe designed a dynamic trust-aware reward function based on different trust\nbeliefs to guide the robot policy learning, which aims to balance between\navoiding human trust collapse due to robot reverse psychology. The experimental\nresults demonstrate the importance of the ToM-based robot policy for\nhuman-robot trust and the effectiveness of our robot ToM-based robot policy in\nmultiagent interaction settings.",
            "author": [
                "Chuang Yu",
                "Baris Serhan",
                "Angelo Cangelosi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04397v1",
                "http://arxiv.org/pdf/2311.04397v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04390v1",
            "title": "Force-Constrained Visual Policy: Safe Robot-Assisted Dressing via\n  Multi-Modal Sensing",
            "updated": "2023-11-07T23:39:43Z",
            "published": "2023-11-07T23:39:43Z",
            "summary": "Robot-assisted dressing could profoundly enhance the quality of life of\nadults with physical disabilities. To achieve this, a robot can benefit from\nboth visual and force sensing. The former enables the robot to ascertain human\nbody pose and garment deformations, while the latter helps maintain safety and\ncomfort during the dressing process. In this paper, we introduce a new\ntechnique that leverages both vision and force modalities for this assistive\ntask. Our approach first trains a vision-based dressing policy using\nreinforcement learning in simulation with varying body sizes, poses, and types\nof garments. We then learn a force dynamics model for action planning to ensure\nsafety. Due to limitations of simulating accurate force data when deformable\ngarments interact with the human body, we learn a force dynamics model directly\nfrom real-world data. Our proposed method combines the vision-based policy,\ntrained in simulation, with the force dynamics model, learned in the real\nworld, by solving a constrained optimization problem to infer actions that\nfacilitate the dressing process without applying excessive force on the person.\nWe evaluate our system in simulation and in a real-world human study with 10\nparticipants across 240 dressing trials, showing it greatly outperforms prior\nbaselines. Video demonstrations are available on our project\nwebsite\\footnote{\\url{https://sites.google.com/view/dressing-fcvp}}.",
            "author": [
                "Zhanyi Sun",
                "Yufei Wang",
                "David Held",
                "Zackory Erickson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04390v1",
                "http://arxiv.org/pdf/2311.04390v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04378v2",
            "title": "Watermarks in the Sand: Impossibility of Strong Watermarking for\n  Generative Models",
            "updated": "2023-11-15T00:21:29Z",
            "published": "2023-11-07T22:52:54Z",
            "summary": "Watermarking generative models consists of planting a statistical signal\n(watermark) in a model's output so that it can be later verified that the\noutput was generated by the given model. A strong watermarking scheme satisfies\nthe property that a computationally bounded attacker cannot erase the watermark\nwithout causing significant quality degradation. In this paper, we study the\n(im)possibility of strong watermarking schemes. We prove that, under\nwell-specified and natural assumptions, strong watermarking is impossible to\nachieve. This holds even in the private detection algorithm setting, where the\nwatermark insertion and detection algorithms share a secret key, unknown to the\nattacker. To prove this result, we introduce a generic efficient watermark\nattack; the attacker is not required to know the private key of the scheme or\neven which scheme is used. Our attack is based on two assumptions: (1) The\nattacker has access to a \"quality oracle\" that can evaluate whether a candidate\noutput is a high-quality response to a prompt, and (2) The attacker has access\nto a \"perturbation oracle\" which can modify an output with a nontrivial\nprobability of maintaining quality, and which induces an efficiently mixing\nrandom walk on high-quality outputs. We argue that both assumptions can be\nsatisfied in practice by an attacker with weaker computational capabilities\nthan the watermarked model itself, to which the attacker has only black-box\naccess. Furthermore, our assumptions will likely only be easier to satisfy over\ntime as models grow in capabilities and modalities. We demonstrate the\nfeasibility of our attack by instantiating it to attack three existing\nwatermarking schemes for large language models: Kirchenbauer et al. (2023),\nKuditipudi et al. (2023), and Zhao et al. (2023). The same attack successfully\nremoves the watermarks planted by all three schemes, with only minor quality\ndegradation.",
            "author": [
                "Hanlin Zhang",
                "Benjamin L. Edelman",
                "Danilo Francati",
                "Daniele Venturi",
                "Giuseppe Ateniese",
                "Boaz Barak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04378v2",
                "http://arxiv.org/pdf/2311.04378v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04372v1",
            "title": "Enhancing Malware Detection by Integrating Machine Learning with Cuckoo\n  Sandbox",
            "updated": "2023-11-07T22:33:17Z",
            "published": "2023-11-07T22:33:17Z",
            "summary": "In the modern era, malware is experiencing a significant increase in both its\nvariety and quantity, aligning with the widespread adoption of the digital\nworld. This surge in malware has emerged as a critical challenge in the realm\nof cybersecurity, prompting numerous research endeavors and contributions to\naddress the issue. Machine learning algorithms have been leveraged for malware\ndetection due to their ability to uncover concealed patterns within vast\ndatasets. However, deep learning algorithms, characterized by their\nmulti-layered structure, surpass the limitations of traditional machine\nlearning approaches. By employing deep learning techniques such as CNN\n(Convolutional Neural Network) and RNN (Recurrent Neural Network), this study\naims to classify and identify malware extracted from a dataset containing API\ncall sequences. The performance of these algorithms is compared with that of\nconventional machine learning methods, including SVM (Support Vector Machine),\nRF (Random Forest), KNN (K-Nearest Neighbors), XGB (Extreme Gradient Boosting),\nand GBC (Gradient Boosting Classifier), all using the same dataset. The\noutcomes of this research demonstrate that both deep learning and machine\nlearning algorithms achieve remarkably high levels of accuracy, reaching up to\n99% in certain cases.",
            "author": [
                "Amaal F. Alshmarni",
                "Mohammed A. Alliheedi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04372v1",
                "http://arxiv.org/pdf/2311.04372v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.LG",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04361v2",
            "title": "\\textsc{DeFault}: Deep-learning-based Fault Delineation",
            "updated": "2023-11-13T18:54:52Z",
            "published": "2023-11-07T21:51:55Z",
            "summary": "The carbon capture, utilization, and storage (CCUS) framework is an essential\ncomponent in reducing greenhouse gas emissions, with its success hinging on the\ncomprehensive knowledge of subsurface geology and geomechanics. Passive seismic\nevent relocation and fault detection serve as indispensable tools, offering\nvital insights into subsurface structures and fluid migration pathways.\nAccurate identification and localization of seismic events, however, face\nsignificant challenges, including the necessity for high-quality seismic data\nand advanced computational methods. To address these challenges, we introduce a\nnovel deep learning method, DeFault, specifically designed for passive seismic\nsource relocation and fault delineating for passive seismic monitoring\nprojects. By leveraging data domain-adaptation, DeFault allows us to train a\nneural network with labeled synthetic data and apply it directly to field data.\nUsing DeFault, the passive seismic sources are automatically clustered based on\ntheir recording time and spatial locations, and subsequently, faults and\nfractures are delineated accordingly. We demonstrate the efficacy of DeFault on\na field case study involving CO2 injection related microseismic data from the\nDecatur, Illinois area. Our approach accurately and efficiently relocated\npassive seismic events, identified faults and aided in the prevention of\npotential geological hazards. Our results highlight the potential of DeFault as\na valuable tool for passive seismic monitoring, emphasizing its role in\nensuring CCUS project safety. This research bolsters the understanding of\nsubsurface characterization in CCUS, illustrating machine learning's capacity\nto refine these methods. Ultimately, our work bear significant implications for\nCCUS technology deployment, an essential strategy in combating climate change.",
            "author": [
                "Hanchen Wang",
                "Yinpeng Chen",
                "Tariq Alkhalifah",
                "Ting Chen",
                "Youzuo Lin",
                "David Alumbaugh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04361v2",
                "http://arxiv.org/pdf/2311.04361v2"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04359v1",
            "title": "Flexibly Estimating and Interpreting Heterogeneous Treatment Effects of\n  Laparoscopic Surgery for Cholecystitis Patients",
            "updated": "2023-11-07T21:43:03Z",
            "published": "2023-11-07T21:43:03Z",
            "summary": "Laparoscopic surgery has been shown through a number of randomized trials to\nbe an effective form of treatment for cholecystitis. Given this evidence, one\nnatural question for clinical practice is: does the effectiveness of\nlaparoscopic surgery vary among patients? It might be the case that, while the\noverall effect is positive, some patients treated with laparoscopic surgery may\nrespond positively to the intervention while others do not or may be harmed. In\nour study, we focus on conditional average treatment effects to understand\nwhether treatment effects vary systematically with patient characteristics.\nRecent methodological work has developed a meta-learner framework for flexible\nestimation of conditional causal effects. In this framework, nonparametric\nestimation methods can be used to avoid bias from model misspecification while\npreserving statistical efficiency. In addition, researchers can flexibly and\neffectively explore whether treatment effects vary with a large number of\npossible effect modifiers. However, these methods have certain limitations. For\nexample, conducting inference can be challenging if black-box models are used.\nFurther, interpreting and visualizing the effect estimates can be difficult\nwhen there are multi-valued effect modifiers. In this paper, we develop new\nmethods that allow for interpretable results and inference from the\nmeta-learner framework for heterogeneous treatment effects estimation. We also\ndemonstrate methods that allow for an exploratory analysis to identify possible\neffect modifiers. We apply our methods to a large database for the use of\nlaparoscopic surgery in treating cholecystitis. We also conduct a series of\nsimulation studies to understand the relative performance of the methods we\ndevelop. Our study provides key guidelines for the interpretation of\nconditional causal effects from the meta-learner framework.",
            "author": [
                "Matteo Bonvini",
                "Zhenghao Zeng",
                "Miaoqing Yu",
                "Edward H. Kennedy",
                "Luke Keele"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04359v1",
                "http://arxiv.org/pdf/2311.04359v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04358v1",
            "title": "Machine learning of a density functional for anisotropic patchy\n  particles",
            "updated": "2023-11-07T21:39:43Z",
            "published": "2023-11-07T21:39:43Z",
            "summary": "Anisotropic patchy particles have become an archetypical statistical model\nsystem for associating fluids. Here we formulate an approach to the\nKern-Frenkel model via classical density functional theory to describe the\npositionally and orientationally resolved equilibrium density distributions in\nflat wall geometries. The density functional is split into a reference part for\nthe orientationally averaged density and an orientational part in mean-field\napproximation. To bring the orientational part into a kernel form suitable for\nmachine learning techniques, an expansion into orientational invariants and the\nproper incorporation of single-particle symmetries is formulated. The\nmean-field kernel is constructed via machine learning on the basis of hard wall\nsimulation data. Results are compared to the well-known random-phase\napproximation which strongly underestimates the orientational correlations\nclose to the wall. Successes and shortcomings of the mean-field treatment of\nthe orientational part are highlighted and perspectives are given for attaining\na full density functional via machine learning.",
            "author": [
                "Alessandro Simon",
                "Jens Weimar",
                "Georg Martius",
                "Martin Oettel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04358v1",
                "http://arxiv.org/pdf/2311.04358v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech",
                "cond-mat.soft"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04354v2",
            "title": "Uncovering Intermediate Variables in Transformers using Circuit Probing",
            "updated": "2023-11-17T15:15:17Z",
            "published": "2023-11-07T21:27:17Z",
            "summary": "Neural network models have achieved high performance on a wide variety of\ncomplex tasks, but the algorithms that they implement are notoriously difficult\nto interpret. In order to understand these algorithms, it is often necessary to\nhypothesize intermediate variables involved in the network's computation. For\nexample, does a language model depend on particular syntactic properties when\ngenerating a sentence? However, existing analysis tools make it difficult to\ntest hypotheses of this type. We propose a new analysis technique -- circuit\nprobing -- that automatically uncovers low-level circuits that compute\nhypothesized intermediate variables. This enables causal analysis through\ntargeted ablation at the level of model parameters. We apply this method to\nmodels trained on simple arithmetic tasks, demonstrating its effectiveness at\n(1) deciphering the algorithms that models have learned, (2) revealing modular\nstructure within a model, and (3) tracking the development of circuits over\ntraining. We compare circuit probing to other methods across these three\nexperiments, and find it on par or more effective than existing analysis\nmethods. Finally, we demonstrate circuit probing on a real-world use case,\nuncovering circuits that are responsible for subject-verb agreement and\nreflexive anaphora in GPT2-Small and Medium.",
            "author": [
                "Michael A. Lepori",
                "Thomas Serre",
                "Ellie Pavlick"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04354v2",
                "http://arxiv.org/pdf/2311.04354v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04351v1",
            "title": "A Deep Learning Approach to Video Anomaly Detection using Convolutional\n  Autoencoders",
            "updated": "2023-11-07T21:23:32Z",
            "published": "2023-11-07T21:23:32Z",
            "summary": "In this research we propose a deep learning approach for detecting anomalies\nin videos using convolutional autoencoder and decoder neural networks on the\nUCSD dataset.Our method utilizes a convolutional autoencoder to learn the\nspatiotemporal patterns of normal videos and then compares each frame of a test\nvideo to this learned representation. We evaluated our approach on the UCSD\ndataset and achieved an overall accuracy of 99.35% on the Ped1 dataset and\n99.77% on the Ped2 dataset, demonstrating the effectiveness of our method for\ndetecting anomalies in surveillance videos. The results show that our method\noutperforms other state-of-the-art methods, and it can be used in real-world\napplications for video anomaly detection.",
            "author": [
                "Gopikrishna Pavuluri",
                "Gayathri Annem"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04351v1",
                "http://arxiv.org/pdf/2311.04351v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04350v1",
            "title": "Device Sampling and Resource Optimization for Federated Learning in\n  Cooperative Edge Networks",
            "updated": "2023-11-07T21:17:59Z",
            "published": "2023-11-07T21:17:59Z",
            "summary": "The conventional federated learning (FedL) architecture distributes machine\nlearning (ML) across worker devices by having them train local models that are\nperiodically aggregated by a server. FedL ignores two important characteristics\nof contemporary wireless networks, however: (i) the network may contain\nheterogeneous communication/computation resources, and (ii) there may be\nsignificant overlaps in devices' local data distributions. In this work, we\ndevelop a novel optimization methodology that jointly accounts for these\nfactors via intelligent device sampling complemented by device-to-device (D2D)\noffloading. Our optimization methodology aims to select the best combination of\nsampled nodes and data offloading configuration to maximize FedL training\naccuracy while minimizing data processing and D2D communication resource\nconsumption subject to realistic constraints on the network topology and device\ncapabilities. Theoretical analysis of the D2D offloading subproblem leads to\nnew FedL convergence bounds and an efficient sequential convex optimizer. Using\nthese results, we develop a sampling methodology based on graph convolutional\nnetworks (GCNs) which learns the relationship between network attributes,\nsampled nodes, and D2D data offloading to maximize FedL accuracy. Through\nevaluation on popular datasets and real-world network measurements from our\nedge testbed, we find that our methodology outperforms popular device sampling\nmethodologies from literature in terms of ML model performance, data processing\noverhead, and energy consumption.",
            "author": [
                "Su Wang",
                "Roberto Morabito",
                "Seyyedali Hosseinalipour",
                "Mung Chiang",
                "Christopher G. Brinton"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04350v1",
                "http://arxiv.org/pdf/2311.04350v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04346v1",
            "title": "SaFL: Sybil-aware Federated Learning with Application to Face\n  Recognition",
            "updated": "2023-11-07T21:06:06Z",
            "published": "2023-11-07T21:06:06Z",
            "summary": "Federated Learning (FL) is a machine learning paradigm to conduct\ncollaborative learning among clients on a joint model. The primary goal is to\nshare clients' local training parameters with an integrating server while\npreserving their privacy. This method permits to exploit the potential of\nmassive mobile users' data for the benefit of machine learning models'\nperformance while keeping sensitive data on local devices. On the downside, FL\nraises security and privacy concerns that have just started to be studied. To\naddress some of the key threats in FL, researchers have proposed to use secure\naggregation methods (e.g. homomorphic encryption, secure multiparty\ncomputation, etc.). These solutions improve some security and privacy metrics,\nbut at the same time bring about other serious threats such as poisoning\nattacks, backdoor attacks, and free running attacks. This paper proposes a new\ndefense method against poisoning attacks in FL called SaFL (Sybil-aware\nFederated Learning) that minimizes the effect of sybils with a novel\ntime-variant aggregation scheme.",
            "author": [
                "Mahdi Ghafourian",
                "Julian Fierrez",
                "Ruben Vera-Rodriguez",
                "Ruben Tolosana",
                "Aythami Morales"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04346v1",
                "http://arxiv.org/pdf/2311.04346v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04345v1",
            "title": "A Taxonomy of Rater Disagreements: Surveying Challenges & Opportunities\n  from the Perspective of Annotating Online Toxicity",
            "updated": "2023-11-07T21:00:51Z",
            "published": "2023-11-07T21:00:51Z",
            "summary": "Toxicity is an increasingly common and severe issue in online spaces.\nConsequently, a rich line of machine learning research over the past decade has\nfocused on computationally detecting and mitigating online toxicity. These\nefforts crucially rely on human-annotated datasets that identify toxic content\nof various kinds in social media texts. However, such annotations historically\nyield low inter-rater agreement, which was often dealt with by taking the\nmajority vote or other such approaches to arrive at a single ground truth\nlabel. Recent research has pointed out the importance of accounting for the\nsubjective nature of this task when building and utilizing these datasets, and\nthis has triggered work on analyzing and better understanding rater\ndisagreements, and how they could be effectively incorporated into the machine\nlearning developmental pipeline. While these efforts are filling an important\ngap, there is a lack of a broader framework about the root causes of rater\ndisagreement, and therefore, we situate this work within that broader\nlandscape. In this survey paper, we analyze a broad set of literature on the\nreasons behind rater disagreements focusing on online toxicity, and propose a\ndetailed taxonomy for the same. Further, we summarize and discuss the potential\nsolutions targeting each reason for disagreement. We also discuss several open\nissues, which could promote the future development of online toxicity research.",
            "author": [
                "Wenbo Zhang",
                "Hangzhi Guo",
                "Ian D Kivlichan",
                "Vinodkumar Prabhakaran",
                "Davis Yadav",
                "Amulya Yadav"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04345v1",
                "http://arxiv.org/pdf/2311.04345v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04937v1",
            "title": "Multimodal Clinical Benchmark for Emergency Care (MC-BEC): A\n  Comprehensive Benchmark for Evaluating Foundation Models in Emergency\n  Medicine",
            "updated": "2023-11-07T20:56:19Z",
            "published": "2023-11-07T20:56:19Z",
            "summary": "We propose the Multimodal Clinical Benchmark for Emergency Care (MC-BEC), a\ncomprehensive benchmark for evaluating foundation models in Emergency Medicine\nusing a dataset of 100K+ continuously monitored Emergency Department visits\nfrom 2020-2022. MC-BEC focuses on clinically relevant prediction tasks at\ntimescales from minutes to days, including predicting patient decompensation,\ndisposition, and emergency department (ED) revisit, and includes a standardized\nevaluation framework with train-test splits and evaluation metrics. The\nmultimodal dataset includes a wide range of detailed clinical data, including\ntriage information, prior diagnoses and medications, continuously measured\nvital signs, electrocardiogram and photoplethysmograph waveforms, orders placed\nand medications administered throughout the visit, free-text reports of imaging\nstudies, and information on ED diagnosis, disposition, and subsequent revisits.\nWe provide performance baselines for each prediction task to enable the\nevaluation of multimodal, multitask models. We believe that MC-BEC will\nencourage researchers to develop more effective, generalizable, and accessible\nfoundation models for multimodal clinical data.",
            "author": [
                "Emma Chen",
                "Aman Kansal",
                "Julie Chen",
                "Boyang Tom Jin",
                "Julia Rachel Reisler",
                "David A Kim",
                "Pranav Rajpurkar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04937v1",
                "http://arxiv.org/pdf/2311.04937v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04343v1",
            "title": "Soundbay: Deep Learning Framework for Marine Mammals and Bioacoustic\n  Research",
            "updated": "2023-11-07T20:55:26Z",
            "published": "2023-11-07T20:55:26Z",
            "summary": "This paper presents Soundbay, an open-source Python framework that allows\nbio-acoustics and machine learning researchers to implement and utilize deep\nlearning-based algorithms for acoustic audio analysis. Soundbay provides an\neasy and intuitive platform for applying existing models on one's data or\ncreating new models effortlessly. One of the main advantages of the framework\nis the capability to compare baselines on different benchmarks, a crucial part\nof emerging research and development related to the usage of deep-learning\nalgorithms for animal call analysis. We demonstrate this by providing a\nbenchmark for cetacean call detection on multiple datasets. The framework is\npublicly accessible via https://github.com/deep-voice/soundbay",
            "author": [
                "Noam Bressler",
                "Michael Faran",
                "Amit Galor",
                "Michael Moshe Michelashvili",
                "Tomer Nachshon",
                "Noa Weiss"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04343v1",
                "http://arxiv.org/pdf/2311.04343v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04339v1",
            "title": "InstrumentGen: Generating Sample-Based Musical Instruments From Text",
            "updated": "2023-11-07T20:45:59Z",
            "published": "2023-11-07T20:45:59Z",
            "summary": "We introduce the text-to-instrument task, which aims at generating\nsample-based musical instruments based on textual prompts. Accordingly, we\npropose InstrumentGen, a model that extends a text-prompted generative audio\nframework to condition on instrument family, source type, pitch (across an\n88-key spectrum), velocity, and a joint text/audio embedding. Furthermore, we\npresent a differentiable loss function to evaluate the intra-instrument timbral\nconsistency of sample-based instruments. Our results establish a foundational\ntext-to-instrument baseline, extending research in the domain of automatic\nsample-based instrument generation.",
            "author": [
                "Shahan Nercessian",
                "Johannes Imort"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04339v1",
                "http://arxiv.org/pdf/2311.04339v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.LG",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04338v2",
            "title": "Convex Methods for Constrained Linear Bandits",
            "updated": "2023-11-10T01:05:55Z",
            "published": "2023-11-07T20:45:46Z",
            "summary": "Recently, bandit optimization has received significant attention in\nreal-world safety-critical systems that involve repeated interactions with\nhumans. While there exist various algorithms with performance guarantees in the\nliterature, practical implementation of the algorithms has not received as much\nattention. This work presents a comprehensive study on the computational\naspects of safe bandit algorithms, specifically safe linear bandits, by\nintroducing a framework that leverages convex programming tools to create\ncomputationally efficient policies. In particular, we first characterize the\nproperties of the optimal policy for safe linear bandit problem and then\npropose an end-to-end pipeline of safe linear bandit algorithms that only\ninvolves solving convex problems. We also numerically evaluate the performance\nof our proposed methods.",
            "author": [
                "Amirhossein Afsharrad",
                "Ahmadreza Moradipari",
                "Sanjay Lall"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04338v2",
                "http://arxiv.org/pdf/2311.04338v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04335v1",
            "title": "Sub-Sentence Encoder: Contrastive Learning of Propositional Semantic\n  Representations",
            "updated": "2023-11-07T20:38:30Z",
            "published": "2023-11-07T20:38:30Z",
            "summary": "We introduce sub-sentence encoder, a contrastively-learned contextual\nembedding model for fine-grained semantic representation of text. In contrast\nto the standard practice with sentence embeddings, where the meaning of an\nentire sequence of text is encoded into a fixed-length vector, the sub-sentence\nencoder learns to produce distinct contextual embeddings corresponding to\ndifferent atomic propositions, i.e. atomic units of meaning expressed within a\ntext sequence. The sub-sentence embeddings are contrastively learned to\nrecognize (inferred) semantic equivalence between propositions across different\ntext sequences. Our experiments show the effectiveness of sub-sentence encoders\nin applications, such as retrieving supporting facts for fine-grained text\nattribution or recognizing the conditional semantic similarity between texts.\nIn practice, we demonstrate that sub-sentence encoders keep the same level of\ninference cost and space complexity compared to sentence encoders.",
            "author": [
                "Sihao Chen",
                "Hongming Zhang",
                "Tong Chen",
                "Ben Zhou",
                "Wenhao Yu",
                "Dian Yu",
                "Baolin Peng",
                "Hongwei Wang",
                "Dan Roth",
                "Dong Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04335v1",
                "http://arxiv.org/pdf/2311.04335v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04325v1",
            "title": "Extending Machine Learning-Based Early Sepsis Detection to Different\n  Demographics",
            "updated": "2023-11-07T20:02:52Z",
            "published": "2023-11-07T20:02:52Z",
            "summary": "Sepsis requires urgent diagnosis, but research is predominantly focused on\nWestern datasets. In this study, we perform a comparative analysis of two\nensemble learning methods, LightGBM and XGBoost, using the public eICU-CRD\ndataset and a private South Korean St. Mary's Hospital's dataset. Our analysis\nreveals the effectiveness of these methods in addressing healthcare data\nimbalance and enhancing sepsis detection. Specifically, LightGBM shows a slight\nedge in computational efficiency and scalability. The study paves the way for\nthe broader application of machine learning in critical care, thereby expanding\nthe reach of predictive analytics in healthcare globally.",
            "author": [
                "Surajsinh Parmar",
                "Tao Shan",
                "San Lee",
                "Yonghwan Kim",
                "Jang Yong Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04325v1",
                "http://arxiv.org/pdf/2311.04325v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04313v1",
            "title": "Improved Child Text-to-Speech Synthesis through Fastpitch-based Transfer\n  Learning",
            "updated": "2023-11-07T19:31:44Z",
            "published": "2023-11-07T19:31:44Z",
            "summary": "Speech synthesis technology has witnessed significant advancements in recent\nyears, enabling the creation of natural and expressive synthetic speech. One\narea of particular interest is the generation of synthetic child speech, which\npresents unique challenges due to children's distinct vocal characteristics and\ndevelopmental stages. This paper presents a novel approach that leverages the\nFastpitch text-to-speech (TTS) model for generating high-quality synthetic\nchild speech. This study uses the transfer learning training pipeline. The\napproach involved finetuning a multi-speaker TTS model to work with child\nspeech. We use the cleaned version of the publicly available MyST dataset (55\nhours) for our finetuning experiments. We also release a prototype dataset of\nsynthetic speech samples generated from this research together with model code\nto support further research. By using a pretrained MOSNet, we conducted an\nobjective assessment that showed a significant correlation between real and\nsynthetic child voices. Additionally, to validate the intelligibility of the\ngenerated speech, we employed an automatic speech recognition (ASR) model to\ncompare the word error rates (WER) of real and synthetic child voices. The\nspeaker similarity between the real and generated speech is also measured using\na pretrained speaker encoder.",
            "author": [
                "Rishabh Jain",
                "Peter Corcoran"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04313v1",
                "http://arxiv.org/pdf/2311.04313v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.AI",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04307v1",
            "title": "Freeness in cognitive science",
            "updated": "2023-11-07T19:24:39Z",
            "published": "2023-11-07T19:24:39Z",
            "summary": "In this mini-review, dedicated to the Jubilee of Professor Tadeusz Marek, we\nhighlight in a popular way the power of so-called free random variables\n(hereafter FRV) calculus, viewed as a potential probability calculus for the\nXXI century, in applications to the broad area of cognitive sciences. We\nprovide three examples: (i) inference of noisy signals from multivariate\ncorrelation data from the brain; (ii) distinguished role of non-normality in\nreal neuronal models; (iii) applications to the field of deep learning in\nartificial neural networks.",
            "author": [
                "Ewa Gudowska-Nowak",
                "Maciej A. Nowak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04307v1",
                "http://arxiv.org/pdf/2311.04307v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "math-ph",
                "math.MP",
                "math.PR",
                "nlin.AO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04303v1",
            "title": "Adaptive Stochastic Nonlinear Model Predictive Control with Look-ahead\n  Deep Reinforcement Learning for Autonomous Vehicle Motion Control",
            "updated": "2023-11-07T19:20:49Z",
            "published": "2023-11-07T19:20:49Z",
            "summary": "In this paper, we present a Deep Reinforcement Learning (RL)-driven Adaptive\nStochastic Nonlinear Model Predictive Control (SNMPC) to optimize uncertainty\nhandling, constraints robustification, feasibility, and closed-loop\nperformance. To this end, we conceive an RL agent to proactively anticipate\nupcoming control tasks and to dynamically determine the most suitable\ncombination of key SNMPC parameters - foremost the robustification factor\n$\\kappa$ and the Uncertainty Propagation Horizon (UPH) $T_u$. We analyze the\ntrained RL agent's decision-making process and highlight its ability to learn\ncontext-dependent optimal parameters. One key finding is that adapting the\nconstraints robustification factor with the learned policy reduces conservatism\nand improves closed-loop performance while adapting UPH renders previously\ninfeasible SNMPC problems feasible when faced with severe disturbances. We\nshowcase the enhanced robustness and feasibility of our Adaptive SNMPC (aSNMPC)\nthrough the real-time motion control task of an autonomous passenger vehicle to\nfollow an optimal race line when confronted with significant time-variant\ndisturbances. Experimental findings demonstrate that our look-ahead RL-driven\naSNMPC outperforms its Static SNMPC (sSNMPC) counterpart in minimizing the\nlateral deviation both with accurate and inaccurate disturbance assumptions and\neven when driving in previously unexplored environments.",
            "author": [
                "Baha Zarrouki",
                "Chenyang Wang",
                "Johannes Betz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04303v1",
                "http://arxiv.org/pdf/2311.04303v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.RO",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04301v1",
            "title": "Class-Incremental Continual Learning for General Purpose Healthcare\n  Models",
            "updated": "2023-11-07T19:17:59Z",
            "published": "2023-11-07T19:17:59Z",
            "summary": "Healthcare clinics regularly encounter dynamic data that changes due to\nvariations in patient populations, treatment policies, medical devices, and\nemerging disease patterns. Deep learning models can suffer from catastrophic\nforgetting when fine-tuned in such scenarios, causing poor performance on\npreviously learned tasks. Continual learning allows learning on new tasks\nwithout performance drop on previous tasks. In this work, we investigate the\nperformance of continual learning models on four different medical imaging\nscenarios involving ten classification datasets from diverse modalities,\nclinical specialties, and hospitals. We implement various continual learning\napproaches and evaluate their performance in these scenarios. Our results\ndemonstrate that a single model can sequentially learn new tasks from different\nspecialties and achieve comparable performance to naive methods. These findings\nindicate the feasibility of recycling or sharing models across the same or\ndifferent medical specialties, offering another step towards the development of\ngeneral-purpose medical imaging AI that can be shared across institutions.",
            "author": [
                "Amritpal Singh",
                "Mustafa Burak Gurbuz",
                "Shiva Souhith Gantha",
                "Prahlad Jasti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04301v1",
                "http://arxiv.org/pdf/2311.04301v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04295v1",
            "title": "Algorithmic stability implies training-conditional coverage for\n  distribution-free prediction methods",
            "updated": "2023-11-07T19:08:59Z",
            "published": "2023-11-07T19:08:59Z",
            "summary": "In a supervised learning problem, given a predicted value that is the output\nof some trained model, how can we quantify our uncertainty around this\nprediction? Distribution-free predictive inference aims to construct prediction\nintervals around this output, with valid coverage that does not rely on\nassumptions on the distribution of the data or the nature of the model training\nalgorithm. Existing methods in this area, including conformal prediction and\njackknife+, offer theoretical guarantees that hold marginally (i.e., on average\nover a draw of training and test data). In contrast, training-conditional\ncoverage is a stronger notion of validity that ensures predictive coverage of\nthe test point for most draws of the training data, and is thus a more\ndesirable property in practice. Training-conditional coverage was shown by Vovk\n[2012] to hold for the split conformal method, but recent work by Bian and\nBarber [2023] proves that such validity guarantees are not possible for the\nfull conformal and jackknife+ methods without further assumptions. In this\npaper, we show that an assumption of algorithmic stability ensures that the\ntraining-conditional coverage property holds for the full conformal and\njackknife+ methods.",
            "author": [
                "Ruiting Liang",
                "Rina Foygel Barber"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04295v1",
                "http://arxiv.org/pdf/2311.04295v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04293v1",
            "title": "Lie Point Symmetry and Physics Informed Networks",
            "updated": "2023-11-07T19:07:16Z",
            "published": "2023-11-07T19:07:16Z",
            "summary": "Symmetries have been leveraged to improve the generalization of neural\nnetworks through different mechanisms from data augmentation to equivariant\narchitectures. However, despite their potential, their integration into neural\nsolvers for partial differential equations (PDEs) remains largely unexplored.\nWe explore the integration of PDE symmetries, known as Lie point symmetries, in\na major family of neural solvers known as physics-informed neural networks\n(PINNs). We propose a loss function that informs the network about Lie point\nsymmetries in the same way that PINN models try to enforce the underlying PDE\nthrough a loss function. Intuitively, our symmetry loss ensures that the\ninfinitesimal generators of the Lie group conserve the PDE solutions.\nEffectively, this means that once the network learns a solution, it also learns\nthe neighbouring solutions generated by Lie point symmetries. Empirical\nevaluations indicate that the inductive bias introduced by the Lie point\nsymmetries of the PDEs greatly boosts the sample efficiency of PINNs.",
            "author": [
                "Tara Akhound-Sadegh",
                "Laurence Perreault-Levasseur",
                "Johannes Brandstetter",
                "Max Welling",
                "Siamak Ravanbakhsh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04293v1",
                "http://arxiv.org/pdf/2311.04293v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04287v1",
            "title": "Holistic Evaluation of Text-To-Image Models",
            "updated": "2023-11-07T19:00:56Z",
            "published": "2023-11-07T19:00:56Z",
            "summary": "The stunning qualitative improvement of recent text-to-image models has led\nto their widespread attention and adoption. However, we lack a comprehensive\nquantitative understanding of their capabilities and risks. To fill this gap,\nwe introduce a new benchmark, Holistic Evaluation of Text-to-Image Models\n(HEIM). Whereas previous evaluations focus mostly on text-image alignment and\nimage quality, we identify 12 aspects, including text-image alignment, image\nquality, aesthetics, originality, reasoning, knowledge, bias, toxicity,\nfairness, robustness, multilinguality, and efficiency. We curate 62 scenarios\nencompassing these aspects and evaluate 26 state-of-the-art text-to-image\nmodels on this benchmark. Our results reveal that no single model excels in all\naspects, with different models demonstrating different strengths. We release\nthe generated images and human evaluation results for full transparency at\nhttps://crfm.stanford.edu/heim/v1.1.0 and the code at\nhttps://github.com/stanford-crfm/helm, which is integrated with the HELM\ncodebase.",
            "author": [
                "Tony Lee",
                "Michihiro Yasunaga",
                "Chenlin Meng",
                "Yifan Mai",
                "Joon Sung Park",
                "Agrim Gupta",
                "Yunzhi Zhang",
                "Deepak Narayanan",
                "Hannah Benita Teufel",
                "Marco Bellagente",
                "Minguk Kang",
                "Taesung Park",
                "Jure Leskovec",
                "Jun-Yan Zhu",
                "Li Fei-Fei",
                "Jiajun Wu",
                "Stefano Ermon",
                "Percy Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04287v1",
                "http://arxiv.org/pdf/2311.04287v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04285v1",
            "title": "Compilation of product-formula Hamiltonian simulation via reinforcement\n  learning",
            "updated": "2023-11-07T19:00:44Z",
            "published": "2023-11-07T19:00:44Z",
            "summary": "Hamiltonian simulation is believed to be one of the first tasks where quantum\ncomputers can yield a quantum advantage. One of the most popular methods of\nHamiltonian simulation is Trotterization, which makes use of the approximation\n$e^{i\\sum_jA_j}\\sim \\prod_je^{iA_j}$ and higher-order corrections thereto.\nHowever, this leaves open the question of the order of operations (i.e. the\norder of the product over $j$, which is known to affect the quality of\napproximation). In some cases this order is fixed by the desire to minimise the\nerror of approximation; when it is not the case, we propose that the order can\nbe chosen to optimize compilation to a native quantum architecture. This\npresents a new compilation problem -- order-agnostic quantum circuit\ncompilation -- which we prove is NP-hard in the worst case. In lieu of an\neasily-computable exact solution, we turn to methods of heuristic optimization\nof compilation. We focus on reinforcement learning due to the sequential nature\nof the compilation task, comparing it to simulated annealing and Monte Carlo\ntree search. While two of the methods outperform a naive heuristic,\nreinforcement learning clearly outperforms all others, with a gain of around\n12% with respect to the second-best method and of around 50% compared to the\nnaive heuristic in terms of the gate count. We further test the ability of RL\nto generalize across instances of the compilation problem, and find that a\nsingle learner is able to solve entire problem families. This demonstrates the\nability of machine learning techniques to provide assistance in an\norder-agnostic quantum compilation task.",
            "author": [
                "Lea M. Trenkwalder",
                "Eleanor Scerri",
                "Thomas E. O'Brien",
                "Vedran Dunjko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04285v1",
                "http://arxiv.org/pdf/2311.04285v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04218v1",
            "title": "Towards Garment Sewing Pattern Reconstruction from a Single Image",
            "updated": "2023-11-07T18:59:51Z",
            "published": "2023-11-07T18:59:51Z",
            "summary": "Garment sewing pattern represents the intrinsic rest shape of a garment, and\nis the core for many applications like fashion design, virtual try-on, and\ndigital avatars. In this work, we explore the challenging problem of recovering\ngarment sewing patterns from daily photos for augmenting these applications. To\nsolve the problem, we first synthesize a versatile dataset, named SewFactory,\nwhich consists of around 1M images and ground-truth sewing patterns for model\ntraining and quantitative evaluation. SewFactory covers a wide range of human\nposes, body shapes, and sewing patterns, and possesses realistic appearances\nthanks to the proposed human texture synthesis network. Then, we propose a\ntwo-level Transformer network called Sewformer, which significantly improves\nthe sewing pattern prediction performance. Extensive experiments demonstrate\nthat the proposed framework is effective in recovering sewing patterns and well\ngeneralizes to casually-taken human photos. Code, dataset, and pre-trained\nmodels are available at: https://sewformer.github.io.",
            "author": [
                "Lijuan Liu",
                "Xiangyu Xu",
                "Zhijie Lin",
                "Jiabin Liang",
                "Shuicheng Yan"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3618319",
                "http://arxiv.org/abs/2311.04218v1",
                "http://arxiv.org/pdf/2311.04218v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04215v1",
            "title": "Wearable data from subjects playing Super Mario, sitting university\n  exams, or performing physical exercise help detect acute mood episodes via\n  self-supervised learning",
            "updated": "2023-11-07T18:59:14Z",
            "published": "2023-11-07T18:59:14Z",
            "summary": "Personal sensing, leveraging data passively and near-continuously collected\nwith wearables from patients in their ecological environment, is a promising\nparadigm to monitor mood disorders (MDs), a major determinant of worldwide\ndisease burden. However, collecting and annotating wearable data is very\nresource-intensive. Studies of this kind can thus typically afford to recruit\nonly a couple dozens of patients. This constitutes one of the major obstacles\nto applying modern supervised machine learning techniques to MDs detection. In\nthis paper, we overcome this data bottleneck and advance the detection of MDs\nacute episode vs stable state from wearables data on the back of recent\nadvances in self-supervised learning (SSL). This leverages unlabelled data to\nlearn representations during pre-training, subsequently exploited for a\nsupervised task. First, we collected open-access datasets recording with an\nEmpatica E4 spanning different, unrelated to MD monitoring, personal sensing\ntasks -- from emotion recognition in Super Mario players to stress detection in\nundergraduates -- and devised a pre-processing pipeline performing on-/off-body\ndetection, sleep-wake detection, segmentation, and (optionally) feature\nextraction. With 161 E4-recorded subjects, we introduce E4SelfLearning, the\nlargest to date open access collection, and its pre-processing pipeline.\nSecond, we show that SSL confidently outperforms fully-supervised pipelines\nusing either our novel E4-tailored Transformer architecture (E4mer) or\nclassical baseline XGBoost: 81.23% against 75.35% (E4mer) and 72.02% (XGBoost)\ncorrectly classified recording segments from 64 (half acute, half stable)\npatients. Lastly, we illustrate that SSL performance is strongly associated\nwith the specific surrogate task employed for pre-training as well as with\nunlabelled data availability.",
            "author": [
                "Filippo Corponi",
                "Bryan M. Li",
                "Gerard Anmella",
                "Cl\u00e0udia Valenzuela-Pascual",
                "Ariadna Mas",
                "Isabella Pacchiarotti",
                "Marc Valent\u00ed",
                "Iria Grande",
                "Antonio Benabarre",
                "Marina Garriga",
                "Eduard Vieta",
                "Allan H Young",
                "Stephen M. Lawrie",
                "Heather C. Whalley",
                "Diego Hidalgo-Mazzei",
                "Antonio Vergari"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04215v1",
                "http://arxiv.org/pdf/2311.04215v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04207v1",
            "title": "Deep Hashing via Householder Quantization",
            "updated": "2023-11-07T18:47:28Z",
            "published": "2023-11-07T18:47:28Z",
            "summary": "Hashing is at the heart of large-scale image similarity search, and recent\nmethods have been substantially improved through deep learning techniques. Such\nalgorithms typically learn continuous embeddings of the data. To avoid a\nsubsequent costly binarization step, a common solution is to employ loss\nfunctions that combine a similarity learning term (to ensure similar images are\ngrouped to nearby embeddings) and a quantization penalty term (to ensure that\nthe embedding entries are close to binarized entries, e.g., -1 or 1). Still,\nthe interaction between these two terms can make learning harder and the\nembeddings worse. We propose an alternative quantization strategy that\ndecomposes the learning problem in two stages: first, perform similarity\nlearning over the embedding space with no quantization; second, find an optimal\northogonal transformation of the embeddings so each coordinate of the embedding\nis close to its sign, and then quantize the transformed embedding through the\nsign function. In the second step, we parametrize orthogonal transformations\nusing Householder matrices to efficiently leverage stochastic gradient descent.\nSince similarity measures are usually invariant under orthogonal\ntransformations, this quantization strategy comes at no cost in terms of\nperformance. The resulting algorithm is unsupervised, fast, hyperparameter-free\nand can be run on top of any existing deep hashing or metric learning\nalgorithm. We provide extensive experimental results showing that this approach\nleads to state-of-the-art performance on widely used image datasets, and,\nunlike other quantization strategies, brings consistent improvements in\nperformance to existing deep hashing algorithms.",
            "author": [
                "Lucas R. Schwengber",
                "Lucas Resende",
                "Paulo Orenstein",
                "Roberto I. Oliveira"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04207v1",
                "http://arxiv.org/pdf/2311.04207v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04205v1",
            "title": "Rephrase and Respond: Let Large Language Models Ask Better Questions for\n  Themselves",
            "updated": "2023-11-07T18:43:34Z",
            "published": "2023-11-07T18:43:34Z",
            "summary": "Misunderstandings arise not only in interpersonal communication but also\nbetween humans and Large Language Models (LLMs). Such discrepancies can make\nLLMs interpret seemingly unambiguous questions in unexpected ways, yielding\nincorrect responses. While it is widely acknowledged that the quality of a\nprompt, such as a question, significantly impacts the quality of the response\nprovided by LLMs, a systematic method for crafting questions that LLMs can\nbetter comprehend is still underdeveloped. In this paper, we present a method\nnamed `Rephrase and Respond' (RaR), which allows LLMs to rephrase and expand\nquestions posed by humans and provide responses in a single prompt. This\napproach serves as a simple yet effective prompting method for improving\nperformance. We also introduce a two-step variant of RaR, where a rephrasing\nLLM first rephrases the question and then passes the original and rephrased\nquestions together to a different responding LLM. This facilitates the\neffective utilization of rephrased questions generated by one LLM with another.\nOur experiments demonstrate that our methods significantly improve the\nperformance of different models across a wide range to tasks. We further\nprovide a comprehensive comparison between RaR and the popular Chain-of-Thought\n(CoT) methods, both theoretically and empirically. We show that RaR is\ncomplementary to CoT and can be combined with CoT to achieve even better\nperformance. Our work not only contributes to enhancing LLM performance\nefficiently and effectively but also sheds light on a fair evaluation of LLM\ncapabilities. Data and codes are available at\nhttps://github.com/uclaml/Rephrase-and-Respond.",
            "author": [
                "Yihe Deng",
                "Weitong Zhang",
                "Zixiang Chen",
                "Quanquan Gu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04205v1",
                "http://arxiv.org/pdf/2311.04205v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04196v1",
            "title": "JPAVE: A Generation and Classification-based Model for Joint Product\n  Attribute Prediction and Value Extraction",
            "updated": "2023-11-07T18:36:16Z",
            "published": "2023-11-07T18:36:16Z",
            "summary": "Product attribute value extraction is an important task in e-Commerce which\ncan help several downstream applications such as product search and\nrecommendation. Most previous models handle this task using sequence labeling\nor question answering method which rely on the sequential position information\nof values in the product text and are vulnerable to data discrepancy between\ntraining and testing. This limits their generalization ability to real-world\nscenario in which each product can have multiple descriptions across various\nshopping platforms with different composition of text and style. They also have\nlimited zero-shot ability to new values. In this paper, we propose a multi-task\nlearning model with value generation/classification and attribute prediction\ncalled JPAVE to predict values without the necessity of position information of\nvalues in the text. Furthermore, the copy mechanism in value generator and the\nvalue attention module in value classifier help our model address the data\ndiscrepancy issue by only focusing on the relevant part of input text and\nignoring other information which causes the discrepancy issue such as sentence\nstructure in the text. Besides, two variants of our model are designed for\nopen-world and closed-world scenarios. In addition, copy mechanism introduced\nin the first variant based on value generation can improve its zero-shot\nability for identifying unseen values. Experimental results on a public dataset\ndemonstrate the superiority of our model compared with strong baselines and its\ngeneralization ability of predicting new values.",
            "author": [
                "Zhongfen Deng",
                "Hao Peng",
                "Tao Zhang",
                "Shuaiqi Liu",
                "Wenting Zhao",
                "Yibo Wang",
                "Philip S. Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04196v1",
                "http://arxiv.org/pdf/2311.04196v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04194v1",
            "title": "Quantization-aware Neural Architectural Search for Intrusion Detection",
            "updated": "2023-11-07T18:35:29Z",
            "published": "2023-11-07T18:35:29Z",
            "summary": "Deploying machine learning-based intrusion detection systems (IDSs) on\nhardware devices is challenging due to their limited computational resources,\npower consumption, and network connectivity. Hence, there is a significant need\nfor robust, deep learning models specifically designed with such constraints in\nmind. In this paper, we present a design methodology that automatically trains\nand evolves quantized neural network (NN) models that are a thousand times\nsmaller than state-of-the-art NNs but can efficiently analyze network data for\nintrusion at high accuracy. In this regard, the number of LUTs utilized by this\nnetwork when deployed to an FPGA is between 2.3x and 8.5x smaller with\nperformance comparable to prior work.",
            "author": [
                "Rabin Yu Acharya",
                "Laurens Le Jeune",
                "Nele Mentens",
                "Fatemeh Ganji",
                "Domenic Forte"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04194v1",
                "http://arxiv.org/pdf/2311.04194v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04193v1",
            "title": "Selective Visual Representations Improve Convergence and Generalization\n  for Embodied AI",
            "updated": "2023-11-07T18:34:02Z",
            "published": "2023-11-07T18:34:02Z",
            "summary": "Embodied AI models often employ off the shelf vision backbones like CLIP to\nencode their visual observations. Although such general purpose representations\nencode rich syntactic and semantic information about the scene, much of this\ninformation is often irrelevant to the specific task at hand. This introduces\nnoise within the learning process and distracts the agent's focus from\ntask-relevant visual cues. Inspired by selective attention in humans-the\nprocess through which people filter their perception based on their\nexperiences, knowledge, and the task at hand-we introduce a parameter-efficient\napproach to filter visual stimuli for embodied AI. Our approach induces a\ntask-conditioned bottleneck using a small learnable codebook module. This\ncodebook is trained jointly to optimize task reward and acts as a\ntask-conditioned selective filter over the visual observation. Our experiments\nshowcase state-of-the-art performance for object goal navigation and object\ndisplacement across 5 benchmarks, ProcTHOR, ArchitecTHOR, RoboTHOR, AI2-iTHOR,\nand ManipulaTHOR. The filtered representations produced by the codebook are\nalso able generalize better and converge faster when adapted to other\nsimulation environments such as Habitat. Our qualitative analyses show that\nagents explore their environments more effectively and their representations\nretain task-relevant information like target object recognition while ignoring\nsuperfluous information about other objects. Code and pretrained models are\navailable at our project website: https://embodied-codebook.github.io.",
            "author": [
                "Ainaz Eftekhar",
                "Kuo-Hao Zeng",
                "Jiafei Duan",
                "Ali Farhadi",
                "Ani Kembhavi",
                "Ranjay Krishna"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04193v1",
                "http://arxiv.org/pdf/2311.04193v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04190v1",
            "title": "Spatio-Temporal Anomaly Detection with Graph Networks for Data Quality\n  Monitoring of the Hadron Calorimeter",
            "updated": "2023-11-07T18:33:08Z",
            "published": "2023-11-07T18:33:08Z",
            "summary": "The compact muon solenoid (CMS) experiment is a general-purpose detector for\nhigh-energy collision at the large hadron collider (LHC) at CERN. It employs an\nonline data quality monitoring (DQM) system to promptly spot and diagnose\nparticle data acquisition problems to avoid data quality loss. In this study,\nwe present semi-supervised spatio-temporal anomaly detection (AD) monitoring\nfor the physics particle reading channels of the hadronic calorimeter (HCAL) of\nthe CMS using three-dimensional digi-occupancy map data of the DQM. We propose\nthe GraphSTAD system, which employs convolutional and graph neural networks to\nlearn local spatial characteristics induced by particles traversing the\ndetector, and global behavior owing to shared backend circuit connections and\nhousing boxes of the channels, respectively. Recurrent neural networks capture\nthe temporal evolution of the extracted spatial features. We have validated the\naccuracy of the proposed AD system in capturing diverse channel fault types\nusing the LHC Run-2 collision data sets. The GraphSTAD system has achieved\nproduction-level accuracy and is being integrated into the CMS core production\nsystem--for real-time monitoring of the HCAL. We have also provided a\nquantitative performance comparison with alternative benchmark models to\ndemonstrate the promising leverage of the presented system.",
            "author": [
                "Mulugeta Weldezgina Asres",
                "Christian Walter Omlin",
                "Long Wang",
                "David Yu",
                "Pavel Parygin",
                "Jay Dittmann",
                "Georgia Karapostoli",
                "Markus Seidel",
                "Rosamaria Venditti",
                "Luka Lambrecht",
                "Emanuele Usai",
                "Muhammad Ahmad",
                "Javier Fernandez Menendez",
                "Kaori Maeshima",
                "the CMS-HCAL Collaboration"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04190v1",
                "http://arxiv.org/pdf/2311.04190v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04179v1",
            "title": "On Leakage in Machine Learning Pipelines",
            "updated": "2023-11-07T18:06:29Z",
            "published": "2023-11-07T18:06:29Z",
            "summary": "Machine learning (ML) provides powerful tools for predictive modeling. ML's\npopularity stems from the promise of sample-level prediction with applications\nacross a variety of fields from physics and marketing to healthcare. However,\nif not properly implemented and evaluated, ML pipelines may contain leakage\ntypically resulting in overoptimistic performance estimates and failure to\ngeneralize to new data. This can have severe negative financial and societal\nimplications. Our aim is to expand understanding associated with causes leading\nto leakage when designing, implementing, and evaluating ML pipelines.\nIllustrated by concrete examples, we provide a comprehensive overview and\ndiscussion of various types of leakage that may arise in ML pipelines.",
            "author": [
                "Leonard Sasse",
                "Eliana Nicolaisen-Sobesky",
                "Juergen Dukart",
                "Simon B. Eickhoff",
                "Michael G\u00f6tz",
                "Sami Hamdan",
                "Vera Komeyer",
                "Abhijit Kulkarni",
                "Juha Lahnakoski",
                "Bradley C. Love",
                "Federico Raimondo",
                "Kaustubh R. Patil"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04179v1",
                "http://arxiv.org/pdf/2311.04179v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04178v1",
            "title": "Non-Linear pricing with differential machine learning",
            "updated": "2023-11-07T18:05:30Z",
            "published": "2023-11-07T18:05:30Z",
            "summary": "The objective of this research was to evaluate and gain experience with\napplication of two methods used for pricing and sensitivity analysis of exotic\nfinancial derivative instruments, namely, automatic adjoint differentiation\n(AAD) and deep learning. The work was inspired by publication of Danske Bank\nquantitative analysts Antoine Savine and Brian Huge in which the authors\nintroduced a novel approach to building extremely efficient pricing and risk\napproximators for arbitrary financial derivative instruments.",
            "author": [
                "Pavel Goldin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04178v1",
                "http://arxiv.org/pdf/2311.04178v1"
            ],
            "primary_category": "cond-mat.dis-nn",
            "category": [
                "cond-mat.dis-nn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04177v1",
            "title": "Enhancing LLM Intelligence with ARM-RAG: Auxiliary Rationale Memory for\n  Retrieval Augmented Generation",
            "updated": "2023-11-07T18:03:23Z",
            "published": "2023-11-07T18:03:23Z",
            "summary": "Large Language Models (LLMs) are smart but forgetful. Recent studies, (e.g.,\n(Bubeck et al., 2023)) on modern LLMs have shown that they are capable of\nperforming amazing tasks typically necessitating human-level intelligence.\nHowever, unlike humans, frozen LLMs do not improve over time; they neither\nacquire new knowledge nor learn from their successes or failures. Some\napproaches to improving the intelligence of LLMs include fine-tuning models\nbased on problem-solving performance (Zelikman et al., 2022), and building\nbigger and more sophisticated models (Bubeck et al., 2023). However, these\nmethods have the drawback of requiring substantial data and computational\nresources to retrain existing models. In this paper, we explore the use of\nRetrieval Augmented Generation, also known as RAG (Lewis et al., 2021) to\nimprove problem-solving performance. We propose ARM-RAG (Auxiliary Rationale\nMemory for Retrieval Augmented Generation), a system that learns from its\nsuccesses without incurring high training costs. We demonstrate that the\nstorage and subsequent retrieval of reasoning chains have a positive influence\non performance in grade-school math problems.",
            "author": [
                "Eric Melz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04177v1",
                "http://arxiv.org/pdf/2311.04177v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04171v1",
            "title": "HADES: Fast Singularity Detection with Local Measure Comparison",
            "updated": "2023-11-07T17:54:04Z",
            "published": "2023-11-07T17:54:04Z",
            "summary": "We introduce Hades, an unsupervised algorithm to detect singularities in\ndata. This algorithm employs a kernel goodness-of-fit test, and as a\nconsequence it is much faster and far more scaleable than the existing\ntopology-based alternatives. Using tools from differential geometry and optimal\ntransport theory, we prove that Hades correctly detects singularities with high\nprobability when the data sample lives on a transverse intersection of\nequidimensional manifolds. In computational experiments, Hades recovers\nsingularities in synthetically generated data, branching points in road network\ndata, intersection rings in molecular conformation space, and anomalies in\nimage data.",
            "author": [
                "Uzu Lim",
                "Harald Oberhauser",
                "Vidit Nanda"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04171v1",
                "http://arxiv.org/pdf/2311.04171v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.AT",
                "math.DG",
                "math.ST",
                "stat.TH",
                "55N31, 32S50"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04166v1",
            "title": "Perturbed examples reveal invariances shared by language models",
            "updated": "2023-11-07T17:48:35Z",
            "published": "2023-11-07T17:48:35Z",
            "summary": "An explosion of work in language is leading to ever-increasing numbers of\navailable natural language processing models, with little understanding of how\nnew models compare to better-understood models. One major reason for this\ndifficulty is saturating benchmark datasets, which may not reflect well\ndifferences in model performance in the wild. In this work, we propose a novel\nframework for comparing two natural language processing models by revealing\ntheir shared invariance to interpretable input perturbations that are designed\nto target a specific linguistic capability (e.g., Synonym-Invariance,\nTypo-Invariance). Via experiments on models from within the same and across\ndifferent architecture families, this framework offers a number of insights\nabout how changes in models (e.g., distillation, increase in size, amount of\npre-training) affect multiple well-defined linguistic capabilities.\nFurthermore, we also demonstrate how our framework can enable evaluation of the\ninvariances shared between models that are available as commercial black-box\nAPIs (e.g., InstructGPT family) and models that are relatively better\nunderstood (e.g., GPT-2). Across several experiments, we observe that large\nlanguage models share many of the invariances encoded by models of various\nsizes, whereas the invariances encoded by large language models are only shared\nby other large models. Possessing a wide variety of invariances may be a key\nreason for the recent successes of large language models, and our framework can\nshed light on the types of invariances that are retained by or emerge in new\nmodels.",
            "author": [
                "Ruchit Rawal",
                "Mariya Toneva"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04166v1",
                "http://arxiv.org/pdf/2311.04166v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04164v1",
            "title": "Models towards Risk Behavior Prediction and Analysis: A Netherlands Case\n  study",
            "updated": "2023-11-07T17:47:20Z",
            "published": "2023-11-07T17:47:20Z",
            "summary": "In many countries financial service providers have to elicit their customers\nrisk preferences, when offering products and services. For instance, in the\nNetherlands pension funds will be legally obliged to factor in their clients\nrisk preferences when devising their investment strategies. Therefore,\nassessing and measuring the risk preferences of individuals is critical for the\nanalysis of individuals' behavior and policy prescriptions. In the psychology\nand economics, a number of methods to elicit risk preferences have been\ndeveloped using hypothetical scenarios and economic experiments. These methods\nof eliciting individual risk preferences are usually applied to small samples\nbecause they are expensive and the implementation can be complex and not\nsuitable when large cohorts need to be measured. A large number of supervised\nlearning models ranging from linear regression to support vector machines are\nused to predict risk preference measures using socio-economic register data\nsuch as age, gender, migration background and other demographic variables in\ncombination with data on income, wealth, pension fund contributions, and other\nfinancial data. The employed machine learning models cover a range of\nassumptions and properties as well as a diverse set of regression metrics. The\noptimum model is selected using the metrics and interpretability of the model.\nThe optimal models are lasso regression and gradient boosting machines with\nmean average percentage error of about 30%. This is important as it helps to\nestimate risk attitudes without actually measuring them. It should be noted\nthat with the current accuracy the tested models are not ready for deployment\nfor applications that require high accuracy. However, the results do indicate\nwhich models should be used in situations that do not require the most accurate\npredictions such as augmentation data for pensions' recommendation.",
            "author": [
                "Onaopepo Adekunle",
                "Arno Riedl",
                "Michel Dumontier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04164v1",
                "http://arxiv.org/pdf/2311.04164v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04163v1",
            "title": "Outliers with Opposing Signals Have an Outsized Effect on Neural Network\n  Optimization",
            "updated": "2023-11-07T17:43:50Z",
            "published": "2023-11-07T17:43:50Z",
            "summary": "We identify a new phenomenon in neural network optimization which arises from\nthe interaction of depth and a particular heavy-tailed structure in natural\ndata. Our result offers intuitive explanations for several previously reported\nobservations about network training dynamics. In particular, it implies a\nconceptually new cause for progressive sharpening and the edge of stability; we\nalso highlight connections to other concepts in optimization and generalization\nincluding grokking, simplicity bias, and Sharpness-Aware Minimization.\n  Experimentally, we demonstrate the significant influence of paired groups of\noutliers in the training data with strong opposing signals: consistent, large\nmagnitude features which dominate the network output throughout training and\nprovide gradients which point in opposite directions. Due to these outliers,\nearly optimization enters a narrow valley which carefully balances the opposing\ngroups; subsequent sharpening causes their loss to rise rapidly, oscillating\nbetween high on one group and then the other, until the overall loss spikes. We\ndescribe how to identify these groups, explore what sets them apart, and\ncarefully study their effect on the network's optimization and behavior. We\ncomplement these experiments with a mechanistic explanation on a toy example of\nopposing signals and a theoretical analysis of a two-layer linear network on a\nsimple model. Our finding enables new qualitative predictions of training\nbehavior which we confirm experimentally. It also provides a new lens through\nwhich to study and improve modern training practices for stochastic\noptimization, which we highlight via a case study of Adam versus SGD.",
            "author": [
                "Elan Rosenfeld",
                "Andrej Risteski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04163v1",
                "http://arxiv.org/pdf/2311.04163v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04162v1",
            "title": "Coarse correlated equilibria in linear quadratic mean field games and\n  application to an emission abatement game",
            "updated": "2023-11-07T17:41:39Z",
            "published": "2023-11-07T17:41:39Z",
            "summary": "Coarse correlated equilibria (CCE) are a good alternative to Nash equilibria\n(NE), as they arise more naturally as outcomes of learning algorithms and they\nmay exhibit higher payoffs than NE. CCEs include a device which allows players'\nstrategies to be correlated without any cooperation, only through information\nsent by a mediator. We develop a methodology to concretely compute mean field\nCCEs in a linear-quadratic mean field game framework. We compare their\nperformance to mean field control solutions and mean field NE (usually named\nMFG solutions). Our approach is implemented in the mean field version of an\nemission abatement game between greenhouse gas emitters. In particular, we\nexhibit a simple and tractable class of mean field CCEs which allows to\noutperform very significantly the mean field NE payoff and abatement levels,\nbridging the gap between the mean field NE and the social optimum obtained by\nmean field control.",
            "author": [
                "Luciano Campi",
                "Federico Cannerozzi",
                "Fanny Cartellier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04162v1",
                "http://arxiv.org/pdf/2311.04162v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "econ.GN",
                "math.PR",
                "q-fin.EC",
                "91A16, 49N80, 49N10, 91B76"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04161v1",
            "title": "Breaking the Heavy-Tailed Noise Barrier in Stochastic Optimization\n  Problems",
            "updated": "2023-11-07T17:39:17Z",
            "published": "2023-11-07T17:39:17Z",
            "summary": "We consider stochastic optimization problems with heavy-tailed noise with\nstructured density. For such problems, we show that it is possible to get\nfaster rates of convergence than $\\mathcal{O}(K^{-2(\\alpha - 1)/\\alpha})$, when\nthe stochastic gradients have finite moments of order $\\alpha \\in (1, 2]$. In\nparticular, our analysis allows the noise norm to have an unbounded\nexpectation. To achieve these results, we stabilize stochastic gradients, using\nsmoothed medians of means. We prove that the resulting estimates have\nnegligible bias and controllable variance. This allows us to carefully\nincorporate them into clipped-SGD and clipped-SSTM and derive new\nhigh-probability complexity bounds in the considered setup.",
            "author": [
                "Nikita Puchkin",
                "Eduard Gorbunov",
                "Nikolay Kutuzov",
                "Alexander Gasnikov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04161v1",
                "http://arxiv.org/pdf/2311.04161v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.DS",
                "cs.LG",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04158v2",
            "title": "Computing Approximate $\\ell_p$ Sensitivities",
            "updated": "2023-11-21T14:55:52Z",
            "published": "2023-11-07T17:34:56Z",
            "summary": "Recent works in dimensionality reduction for regression tasks have introduced\nthe notion of sensitivity, an estimate of the importance of a specific\ndatapoint in a dataset, offering provable guarantees on the quality of the\napproximation after removing low-sensitivity datapoints via subsampling.\nHowever, fast algorithms for approximating $\\ell_p$ sensitivities, which we\nshow is equivalent to approximate $\\ell_p$ regression, are known for only the\n$\\ell_2$ setting, in which they are termed leverage scores.\n  In this work, we provide efficient algorithms for approximating $\\ell_p$\nsensitivities and related summary statistics of a given matrix. In particular,\nfor a given $n \\times d$ matrix, we compute $\\alpha$-approximation to its\n$\\ell_1$ sensitivities at the cost of $O(n/\\alpha)$ sensitivity computations.\nFor estimating the total $\\ell_p$ sensitivity (i.e. the sum of $\\ell_p$\nsensitivities), we provide an algorithm based on importance sampling of\n$\\ell_p$ Lewis weights, which computes a constant factor approximation to the\ntotal sensitivity at the cost of roughly $O(\\sqrt{d})$ sensitivity\ncomputations. Furthermore, we estimate the maximum $\\ell_1$ sensitivity, up to\na $\\sqrt{d}$ factor, using $O(d)$ sensitivity computations. We generalize all\nthese results to $\\ell_p$ norms for $p > 1$. Lastly, we experimentally show\nthat for a wide class of matrices in real-world datasets, the total sensitivity\ncan be quickly approximated and is significantly smaller than the theoretical\nprediction, demonstrating that real-world datasets have low intrinsic effective\ndimensionality.",
            "author": [
                "Swati Padmanabhan",
                "David P. Woodruff",
                "Qiuyi Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04158v2",
                "http://arxiv.org/pdf/2311.04158v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04157v1",
            "title": "A Simple Interpretable Transformer for Fine-Grained Image Classification\n  and Analysis",
            "updated": "2023-11-07T17:32:55Z",
            "published": "2023-11-07T17:32:55Z",
            "summary": "We present a novel usage of Transformers to make image classification\ninterpretable. Unlike mainstream classifiers that wait until the last\nfully-connected layer to incorporate class information to make predictions, we\ninvestigate a proactive approach, asking each class to search for itself in an\nimage. We realize this idea via a Transformer encoder-decoder inspired by\nDEtection TRansformer (DETR). We learn ``class-specific'' queries (one for each\nclass) as input to the decoder, enabling each class to localize its patterns in\nan image via cross-attention. We name our approach INterpretable TRansformer\n(INTR), which is fairly easy to implement and exhibits several compelling\nproperties. We show that INTR intrinsically encourages each class to attend\ndistinctively; the cross-attention weights thus provide a faithful\ninterpretation of the prediction. Interestingly, via ``multi-head''\ncross-attention, INTR could identify different ``attributes'' of a class,\nmaking it particularly suitable for fine-grained classification and analysis,\nwhich we demonstrate on eight datasets. Our code and pre-trained model are\npublicly accessible at https://github.com/Imageomics/INTR.",
            "author": [
                "Dipanjyoti Paul",
                "Arpita Chowdhury",
                "Xinqi Xiong",
                "Feng-Ju Chang",
                "David Carlyn",
                "Samuel Stevens",
                "Kaiya Provost",
                "Anuj Karpatne",
                "Bryan Carstens",
                "Daniel Rubenstein",
                "Charles Stewart",
                "Tanya Berger-Wolf",
                "Yu Su",
                "Wei-Lun Chao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04157v1",
                "http://arxiv.org/pdf/2311.04157v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04153v1",
            "title": "Kernel-, mean- and noise-marginalised Gaussian processes for exoplanet\n  transits and $H_0$ inference",
            "updated": "2023-11-07T17:31:01Z",
            "published": "2023-11-07T17:31:01Z",
            "summary": "Using a fully Bayesian approach, Gaussian Process regression is extended to\ninclude marginalisation over the kernel choice and kernel hyperparameters. In\naddition, Bayesian model comparison via the evidence enables direct kernel\ncomparison. The calculation of the joint posterior was implemented with a\ntransdimensional sampler which simultaneously samples over the discrete kernel\nchoice and their hyperparameters by embedding these in a higher-dimensional\nspace, from which samples are taken using nested sampling. This method was\nexplored on synthetic data from exoplanet transit light curve simulations. The\ntrue kernel was recovered in the low noise region while no kernel was preferred\nfor larger noise. Furthermore, inference of the physical exoplanet\nhyperparameters was conducted. In the high noise region, either the bias in the\nposteriors was removed, the posteriors were broadened or the accuracy of the\ninference was increased. In addition, the uncertainty in mean function\npredictive distribution increased due to the uncertainty in the kernel choice.\nSubsequently, the method was extended to marginalisation over mean functions\nand noise models and applied to the inference of the present-day Hubble\nparameter, $H_0$, from real measurements of the Hubble parameter as a function\nof redshift, derived from the cosmologically model-independent cosmic\nchronometer and {\\Lambda}CDM-dependent baryon acoustic oscillation\nobservations. The inferred $H_0$ values from the cosmic chronometers, baryon\nacoustic oscillations and combined datasets are $H_0$ = 66$\\pm$6 km/s/Mpc,\n$H_0$ = 67$\\pm$10 km/s/Mpc and $H_0$ = 69$\\pm$6 km/s/Mpc, respectively. The\nkernel posterior of the cosmic chronometers dataset prefers a non-stationary\nlinear kernel. Finally, the datasets are shown to be not in tension with\nln(R)=12.17$\\pm$0.02.",
            "author": [
                "Namu Kroupa",
                "David Yallup",
                "Will Handley",
                "Michael Hobson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04153v1",
                "http://arxiv.org/pdf/2311.04153v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.EP",
                "astro-ph.IM",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04149v1",
            "title": "HyperS2V: A Framework for Structural Representation of Nodes in Hyper\n  Networks",
            "updated": "2023-11-07T17:26:31Z",
            "published": "2023-11-07T17:26:31Z",
            "summary": "In contrast to regular (simple) networks, hyper networks possess the ability\nto depict more complex relationships among nodes and store extensive\ninformation. Such networks are commonly found in real-world applications, such\nas in social interactions. Learning embedded representations for nodes involves\na process that translates network structures into more simplified spaces,\nthereby enabling the application of machine learning approaches designed for\nvector data to be extended to network data. Nevertheless, there remains a need\nto delve into methods for learning embedded representations that prioritize\nstructural aspects. This research introduces HyperS2V, a node embedding\napproach that centers on the structural similarity within hyper networks.\nInitially, we establish the concept of hyper-degrees to capture the structural\nproperties of nodes within hyper networks. Subsequently, a novel function is\nformulated to measure the structural similarity between different hyper-degree\nvalues. Lastly, we generate structural embeddings utilizing a multi-scale\nrandom walk framework. Moreover, a series of experiments, both intrinsic and\nextrinsic, are performed on both toy and real networks. The results underscore\nthe superior performance of HyperS2V in terms of both interpretability and\napplicability to downstream tasks.",
            "author": [
                "Shu Liu",
                "Cameron Lai",
                "Fujio Toriumi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04149v1",
                "http://arxiv.org/pdf/2311.04149v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04148v1",
            "title": "Contactless Fingerprint Biometric Anti-Spoofing: An Unsupervised Deep\n  Learning Approach",
            "updated": "2023-11-07T17:19:59Z",
            "published": "2023-11-07T17:19:59Z",
            "summary": "Contactless fingerprint recognition offers a higher level of user comfort and\naddresses hygiene concerns more effectively. However, it is also more\nvulnerable to presentation attacks such as photo paper, paper-printout, and\nvarious display attacks, which makes it more challenging to implement in\nbiometric systems compared to contact-based modalities. Limited research has\nbeen conducted on presentation attacks in contactless fingerprint systems, and\nthese studies have encountered challenges in terms of generalization and\nscalability since both bonafide samples and presentation attacks are utilized\nduring training model. Although this approach appears promising, it lacks the\nability to handle unseen attacks, which is a crucial factor for developing PAD\nmethods that can generalize effectively. We introduced an innovative\nanti-spoofing approach that combines an unsupervised autoencoder with a\nconvolutional block attention module to address the limitations of existing\nmethods. Our model is exclusively trained on bonafide images without exposure\nto any spoofed samples during the training phase. It is then evaluated against\nvarious types of presentation attack images in the testing phase. The scheme we\nproposed has achieved an average BPCER of 0.96\\% with an APCER of 1.6\\% for\npresentation attacks involving various types of spoofed samples.",
            "author": [
                "Banafsheh Adami",
                "Nima Karimian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04148v1",
                "http://arxiv.org/pdf/2311.04148v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04147v1",
            "title": "Multi-resolution Time-Series Transformer for Long-term Forecasting",
            "updated": "2023-11-07T17:18:52Z",
            "published": "2023-11-07T17:18:52Z",
            "summary": "The performance of transformers for time-series forecasting has improved\nsignificantly. Recent architectures learn complex temporal patterns by\nsegmenting a time-series into patches and using the patches as tokens. The\npatch size controls the ability of transformers to learn the temporal patterns\nat different frequencies: shorter patches are effective for learning localized,\nhigh-frequency patterns, whereas mining long-term seasonalities and trends\nrequires longer patches. Inspired by this observation, we propose a novel\nframework, Multi-resolution Time-Series Transformer (MTST), which consists of a\nmulti-branch architecture for simultaneous modeling of diverse temporal\npatterns at different resolutions. In contrast to many existing time-series\ntransformers, we employ relative positional encoding, which is better suited\nfor extracting periodic components at different scales. Extensive experiments\non several real-world datasets demonstrate the effectiveness of MTST in\ncomparison to state-of-the-art forecasting techniques.",
            "author": [
                "Yitian Zhang",
                "Liheng Ma",
                "Soumyasundar Pal",
                "Yingxue Zhang",
                "Mark Coates"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04147v1",
                "http://arxiv.org/pdf/2311.04147v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04146v1",
            "title": "Galaxy Spectra neural Network (GaSNet). II. Using Deep Learning for\n  Spectral Classification and Redshift Predictions",
            "updated": "2023-11-07T17:16:49Z",
            "published": "2023-11-07T17:16:49Z",
            "summary": "Large sky spectroscopic surveys have reached the scale of photometric surveys\nin terms of sample sizes and data complexity. These huge datasets require\nefficient, accurate, and flexible automated tools for data analysis and science\nexploitation. We present the Galaxy Spectra Network/GaSNet-II, a supervised\nmulti-network deep learning tool for spectra classification and redshift\nprediction. GaSNet-II can be trained to identify a customized number of classes\nand optimize the redshift predictions for classified objects in each of them.\nIt also provides redshift errors, using a network-of-networks that reproduces a\nMonte Carlo test on each spectrum, by randomizing their weight initialization.\nAs a demonstration of the capability of the deep learning pipeline, we use 260k\nSloan Digital Sky Survey spectra from Data Release 16, separated into 13\nclasses including 140k galactic, and 120k extragalactic objects. GaSNet-II\nachieves 92.4% average classification accuracy over the 13 classes (larger than\n90% for the majority of them), and an average redshift error of approximately\n0.23% for galaxies and 2.1% for quasars. We further train/test the same\npipeline to classify spectra and predict redshifts for a sample of 200k 4MOST\nmock spectra and 21k publicly released DESI spectra. On 4MOST mock data, we\nreach 93.4% accuracy in 10-class classification and an average redshift error\nof 0.55% for galaxies and 0.3% for active galactic nuclei. On DESI data, we\nreach 96% accuracy in (star/galaxy/quasar only) classification and an average\nredshift error of 2.8% for galaxies and 4.8% for quasars, despite the small\nsample size available. GaSNet-II can process ~40k spectra in less than one\nminute, on a normal Desktop GPU. This makes the pipeline particularly suitable\nfor real-time analyses of Stage-IV survey observations and an ideal tool for\nfeedback loops aimed at night-by-night survey strategy optimization.",
            "author": [
                "Fucheng Zhong",
                "Nicola R. Napolitano",
                "Caroline Heneka",
                "Rui Li",
                "Franz Erik Bauer",
                "Nicolas Bouche",
                "Johan Comparat",
                "Young-Lo Kim",
                "Jens-Kristian Krogager",
                "Marcella Longhetti",
                "Jonathan Loveday",
                "Boudewijn F. Roukema",
                "Benedict L. Rouse",
                "Mara Salvato",
                "Crescenzo Tortora",
                "Roberto J. Assef",
                "Letizia P. Cassar\u00e0",
                "Luca Costantin",
                "Scott Croom",
                "Luke J M Davies",
                "Alexander Fritz",
                "Guillaume Guiglion",
                "Andrew Humphrey",
                "Emanuela Pompei",
                "Claudio Ricci",
                "Crist\u00f3bal Sif\u00f3n",
                "Elmo Tempel",
                "Tayyaba Zafar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04146v1",
                "http://arxiv.org/pdf/2311.04146v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04131v1",
            "title": "Locating Cross-Task Sequence Continuation Circuits in Transformers",
            "updated": "2023-11-07T16:58:51Z",
            "published": "2023-11-07T16:58:51Z",
            "summary": "While transformer models exhibit strong capabilities on linguistic tasks,\ntheir complex architectures make them difficult to interpret. Recent work has\naimed to reverse engineer transformer models into human-readable\nrepresentations called circuits that implement algorithmic functions. We extend\nthis research by analyzing and comparing circuits for similar sequence\ncontinuation tasks, which include increasing sequences of digits, number words,\nand months. Through the application of circuit analysis techniques, we identify\nkey sub-circuits responsible for detecting sequence members and for predicting\nthe next member in a sequence. Our analysis reveals that semantically related\nsequences rely on shared circuit subgraphs with analogous roles. Overall,\ndocumenting shared computational structures enables better prediction of model\nbehaviors, identification of errors, and safer editing procedures. This\nmechanistic understanding of transformers is a critical step towards building\nmore robust, aligned, and interpretable language models.",
            "author": [
                "Michael Lan",
                "Fazl Barez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04131v1",
                "http://arxiv.org/pdf/2311.04131v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04128v1",
            "title": "Generative learning for nonlinear dynamics",
            "updated": "2023-11-07T16:53:56Z",
            "published": "2023-11-07T16:53:56Z",
            "summary": "Modern generative machine learning models demonstrate surprising ability to\ncreate realistic outputs far beyond their training data, such as photorealistic\nartwork, accurate protein structures, or conversational text. These successes\nsuggest that generative models learn to effectively parametrize and sample\narbitrarily complex distributions. Beginning half a century ago, foundational\nworks in nonlinear dynamics used tools from information theory to infer\nproperties of chaotic attractors from time series, motivating the development\nof algorithms for parametrizing chaos in real datasets. In this perspective, we\naim to connect these classical works to emerging themes in large-scale\ngenerative statistical learning. We first consider classical attractor\nreconstruction, which mirrors constraints on latent representations learned by\nstate space models of time series. We next revisit early efforts to use\nsymbolic approximations to compare minimal discrete generators underlying\ncomplex processes, a problem relevant to modern efforts to distill and\ninterpret black-box statistical models. Emerging interdisciplinary works bridge\nnonlinear dynamics and learning theory, such as operator-theoretic methods for\ncomplex fluid flows, or detection of broken detailed balance in biological\ndatasets. We anticipate that future machine learning techniques may revisit\nother classical concepts from nonlinear dynamics, such as transinformation\ndecay and complexity-entropy tradeoffs.",
            "author": [
                "William Gilpin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04128v1",
                "http://arxiv.org/pdf/2311.04128v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "nlin.CD",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16151v1",
            "title": "Estimating Post-Synaptic Effects for Online Training of Feed-Forward\n  SNNs",
            "updated": "2023-11-07T16:53:39Z",
            "published": "2023-11-07T16:53:39Z",
            "summary": "Facilitating online learning in spiking neural networks (SNNs) is a key step\nin developing event-based models that can adapt to changing environments and\nlearn from continuous data streams in real-time. Although forward-mode\ndifferentiation enables online learning, its computational requirements\nrestrict scalability. This is typically addressed through approximations that\nlimit learning in deep models. In this study, we propose Online Training with\nPostsynaptic Estimates (OTPE) for training feed-forward SNNs, which\napproximates Real-Time Recurrent Learning (RTRL) by incorporating temporal\ndynamics not captured by current approximations, such as Online Training\nThrough Time (OTTT) and Online Spatio-Temporal Learning (OSTL). We show\nimproved scaling for multi-layer networks using a novel approximation of\ntemporal effects on the subsequent layer's activity. This approximation incurs\nminimal overhead in the time and space complexity compared to similar\nalgorithms, and the calculation of temporal effects remains local to each\nlayer. We characterize the learning performance of our proposed algorithms on\nmultiple SNN model configurations for rate-based and time-based encoding. OTPE\nexhibits the highest directional alignment to exact gradients, calculated with\nbackpropagation through time (BPTT), in deep networks and, on time-based\nencoding, outperforms other approximate methods. We also observe sizeable gains\nin average performance over similar algorithms in offline training of Spiking\nHeidelberg Digits with equivalent hyper-parameters (OTTT/OSTL - 70.5%; OTPE -\n75.2%; BPTT - 78.1%).",
            "author": [
                "Thomas Summe",
                "Clemens JS Schaefer",
                "Siddharth Joshi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16151v1",
                "http://arxiv.org/pdf/2311.16151v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04124v1",
            "title": "Unveiling Safety Vulnerabilities of Large Language Models",
            "updated": "2023-11-07T16:50:33Z",
            "published": "2023-11-07T16:50:33Z",
            "summary": "As large language models become more prevalent, their possible harmful or\ninappropriate responses are a cause for concern. This paper introduces a unique\ndataset containing adversarial examples in the form of questions, which we call\nAttaQ, designed to provoke such harmful or inappropriate responses. We assess\nthe efficacy of our dataset by analyzing the vulnerabilities of various models\nwhen subjected to it. Additionally, we introduce a novel automatic approach for\nidentifying and naming vulnerable semantic regions - input semantic areas for\nwhich the model is likely to produce harmful outputs. This is achieved through\nthe application of specialized clustering techniques that consider both the\nsemantic similarity of the input attacks and the harmfulness of the model's\nresponses. Automatically identifying vulnerable semantic regions enhances the\nevaluation of model weaknesses, facilitating targeted improvements to its\nsafety mechanisms and overall reliability.",
            "author": [
                "George Kour",
                "Marcel Zalmanovici",
                "Naama Zwerdling",
                "Esther Goldbraich",
                "Ora Nova Fandina",
                "Ateret Anaby-Tavor",
                "Orna Raz",
                "Eitan Farchi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04124v1",
                "http://arxiv.org/pdf/2311.04124v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04122v1",
            "title": "Fine-tuning convergence model in Bengali speech recognition",
            "updated": "2023-11-07T16:47:19Z",
            "published": "2023-11-07T16:47:19Z",
            "summary": "Research on speech recognition has attracted considerable interest due to the\ndifficult task of segmenting uninterrupted speech. Among various languages,\nBengali features distinct rhythmic patterns and tones, making it particularly\ndifficult to recognize and lacking an efficient commercial recognition method.\nIn order to improve the automatic speech recognition model for Bengali, our\nteam has chosen to utilize the wave2vec 2.0 pre-trained model, which has\nundergone convergence for fine-tuning. Regarding Word Error Rate (WER), the\nlearning rate and dropout parameters were fine-tuned, and after the model\ntraining was stable, attempts were made to enlarge the training set ratio,\nwhich improved the model's performance. Consequently, there was a notable\nenhancement in the WER from 0.508 to 0.437 on the test set of the publicly\nlisted official dataset. Afterwards, the training and validation sets were\nmerged, creating a comprehensive dataset that was used as the training set,\nachieving a remarkable WER of 0.436.",
            "author": [
                "Zhu Ruiying",
                "Shen Meng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04122v1",
                "http://arxiv.org/pdf/2311.04122v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04116v1",
            "title": "Improved Topological Preservation in 3D Axon Segmentation and Centerline\n  Detection using Geometric Assessment-driven Topological Smoothing (GATS)",
            "updated": "2023-11-07T16:39:21Z",
            "published": "2023-11-07T16:39:21Z",
            "summary": "Automated axon tracing via fully supervised learning requires large amounts\nof 3D brain imagery, which is time consuming and laborious to obtain. It also\nrequires expertise. Thus, there is a need for more efficient segmentation and\ncenterline detection techniques to use in conjunction with automated annotation\ntools. Topology-preserving methods ensure that segmented components maintain\ngeometric connectivity, which is especially meaningful for applications where\nvolumetric data is used, and these methods often make use of morphological\nthinning algorithms as the thinned outputs can be useful for both segmentation\nand centerline detection of curvilinear structures. Current morphological\nthinning approaches used in conjunction with topology-preserving methods are\nprone to over-thinning and require manual configuration of hyperparameters. We\npropose an automated approach for morphological smoothing using geometric\nassessment of the radius of tubular structures in brain microscopy volumes, and\napply average pooling to prevent over-thinning. We use this approach to\nformulate a loss function, which we call Geo-metric Assessment-driven\nTopological Smoothing loss, or GATS. Our approach increased segmentation and\ncenter-line detection evaluation metrics by 2%-5% across multiple datasets, and\nimproved the Betti error rates by 9%. Our ablation study showed that geometric\nassessment of tubular structures achieved higher segmentation and centerline\ndetection scores, and using average pooling for morphological smoothing in\nplace of thinning algorithms reduced the Betti errors. We observed increased\ntopological preservation during automated annotation of 3D axons volumes from\nmodels trained with GATS.",
            "author": [
                "Nina I. Shamsi",
                "Alex S. Xu",
                "Lars A. Gjesteby",
                "Laura J. Brattain"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04116v1",
                "http://arxiv.org/pdf/2311.04116v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04109v1",
            "title": "Do Language Models Learn Semantics of Code? A Case Study in\n  Vulnerability Detection",
            "updated": "2023-11-07T16:31:56Z",
            "published": "2023-11-07T16:31:56Z",
            "summary": "Recently, pretrained language models have shown state-of-the-art performance\non the vulnerability detection task. These models are pretrained on a large\ncorpus of source code, then fine-tuned on a smaller supervised vulnerability\ndataset. Due to the different training objectives and the performance of the\nmodels, it is interesting to consider whether the models have learned the\nsemantics of code relevant to vulnerability detection, namely bug semantics,\nand if so, how the alignment to bug semantics relates to model performance. In\nthis paper, we analyze the models using three distinct methods:\ninterpretability tools, attention analysis, and interaction matrix analysis. We\ncompare the models' influential feature sets with the bug semantic features\nwhich define the causes of bugs, including buggy paths and Potentially\nVulnerable Statements (PVS). We find that (1) better-performing models also\naligned better with PVS, (2) the models failed to align strongly to PVS, and\n(3) the models failed to align at all to buggy paths. Based on our analysis, we\ndeveloped two annotation methods which highlight the bug semantics inside the\nmodel's inputs. We evaluated our approach on four distinct transformer models\nand four vulnerability datasets and found that our annotations improved the\nmodels' performance in the majority of settings - 11 out of 16, with up to 9.57\npoints improvement in F1 score compared to conventional fine-tuning. We further\nfound that with our annotations, the models aligned up to 232% better to\npotentially vulnerable statements. Our findings indicate that it is helpful to\nprovide the model with information of the bug semantics, that the model can\nattend to it, and motivate future work in learning more complex path-based bug\nsemantics. Our code and data are available at\nhttps://figshare.com/s/4a16a528d6874aad51a0.",
            "author": [
                "Benjamin Steenhoek",
                "Md Mahbubur Rahman",
                "Shaila Sharmin",
                "Wei Le"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04109v1",
                "http://arxiv.org/pdf/2311.04109v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04107v1",
            "title": "Interactive Semantic Map Representation for Skill-based Visual Object\n  Navigation",
            "updated": "2023-11-07T16:30:12Z",
            "published": "2023-11-07T16:30:12Z",
            "summary": "Visual object navigation using learning methods is one of the key tasks in\nmobile robotics. This paper introduces a new representation of a scene semantic\nmap formed during the embodied agent interaction with the indoor environment.\nIt is based on a neural network method that adjusts the weights of the\nsegmentation model with backpropagation of the predicted fusion loss values\nduring inference on a regular (backward) or delayed (forward) image sequence.\nWe have implemented this representation into a full-fledged navigation approach\ncalled SkillTron, which can select robot skills from end-to-end policies based\non reinforcement learning and classic map-based planning methods. The proposed\napproach makes it possible to form both intermediate goals for robot\nexploration and the final goal for object navigation. We conducted intensive\nexperiments with the proposed approach in the Habitat environment, which showed\na significant superiority in navigation quality metrics compared to\nstate-of-the-art approaches. The developed code and used custom datasets are\npublicly available at github.com/AIRI-Institute/skill-fusion.",
            "author": [
                "Tatiana Zemskova",
                "Aleksei Staroverov",
                "Kirill Muravyev",
                "Dmitry Yudin",
                "Aleksandr Panov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04107v1",
                "http://arxiv.org/pdf/2311.04107v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04262v1",
            "title": "ETDPC: A Multimodality Framework for Classifying Pages in Electronic\n  Theses and Dissertations",
            "updated": "2023-11-07T16:27:37Z",
            "published": "2023-11-07T16:27:37Z",
            "summary": "Electronic theses and dissertations (ETDs) have been proposed, advocated, and\ngenerated for more than 25 years. Although ETDs are hosted by commercial or\ninstitutional digital library repositories, they are still an understudied type\nof scholarly big data, partially because they are usually longer than\nconference proceedings and journals. Segmenting ETDs will allow researchers to\nstudy sectional content. Readers can navigate to particular pages of interest,\ndiscover, and explore the content buried in these long documents. Most existing\nframeworks on document page classification are designed for classifying general\ndocuments and perform poorly on ETDs. In this paper, we propose ETDPC. Its\nbackbone is a two-stream multimodal model with a cross-attention network to\nclassify ETD pages into 13 categories. To overcome the challenge of imbalanced\nlabeled samples, we augmented data for minority categories and employed a\nhierarchical classifier. ETDPC outperforms the state-of-the-art models in all\ncategories, achieving an F1 of 0.84 -- 0.96 for 9 out of 13 categories. We also\ndemonstrated its data efficiency. The code and data can be found on GitHub\n(https://github.com/lamps-lab/ETDMiner/tree/master/etd_segmentation).",
            "author": [
                "Muntabir Hasan Choudhury",
                "Lamia Salsabil",
                "William A. Ingram",
                "Edward A. Fox",
                "Jian Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04262v1",
                "http://arxiv.org/pdf/2311.04262v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.DL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04096v1",
            "title": "Imitation learning for sim-to-real transfer of robotic cutting policies\n  based on residual Gaussian process disturbance force model",
            "updated": "2023-11-07T16:06:05Z",
            "published": "2023-11-07T16:06:05Z",
            "summary": "Robotic cutting, or milling, plays a significant role in applications such as\ndisassembly, decommissioning, and demolition. Planning and control of cutting\nin real-world scenarios in uncertain environments is a complex task, with the\npotential to benefit from simulated training environments. This letter focuses\non sim-to-real transfer for robotic cutting policies, addressing the need for\neffective policy transfer from simulation to practical implementation. We\nextend our previous domain generalisation approach to learning cutting tasks\nbased on a mechanistic model-based simulation framework, by proposing a hybrid\napproach for sim-to-real transfer based on a milling process force model and\nresidual Gaussian process (GP) force model, learned from either single or\nmultiple real-world cutting force examples. We demonstrate successful\nsim-to-real transfer of a robotic cutting policy without the need for\nfine-tuning on the real robot setup. The proposed approach autonomously adapts\nto materials with differing structural and mechanical properties. Furthermore,\nwe demonstrate the proposed method outperforms fine-tuning or re-training\nalone.",
            "author": [
                "Jamie Hathaway",
                "Rustam Stolkin",
                "Alireza Rastegarpanah"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04096v1",
                "http://arxiv.org/pdf/2311.04096v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04091v1",
            "title": "Proceedings of the 5th International Workshop on Reading Music Systems",
            "updated": "2023-11-07T16:00:42Z",
            "published": "2023-11-07T16:00:42Z",
            "summary": "The International Workshop on Reading Music Systems (WoRMS) is a workshop\nthat tries to connect researchers who develop systems for reading music, such\nas in the field of Optical Music Recognition, with other researchers and\npractitioners that could benefit from such systems, like librarians or\nmusicologists. The relevant topics of interest for the workshop include, but\nare not limited to: Music reading systems; Optical music recognition; Datasets\nand performance evaluation; Image processing on music scores; Writer\nidentification; Authoring, editing, storing and presentation systems for music\nscores; Multi-modal systems; Novel input-methods for music to produce written\nmusic; Web-based Music Information Retrieval services; Applications and\nprojects; Use-cases related to written music.\n  These are the proceedings of the 5th International Workshop on Reading Music\nSystems, held in Milan, Italy on Nov. 4th 2023.",
            "author": [
                "Jorge Calvo-Zaragoza",
                "Alexander Pacha",
                "Elona Shatri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04091v1",
                "http://arxiv.org/pdf/2311.04091v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.IR",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04088v1",
            "title": "Personality Style Recognition via Machine Learning: Identifying\n  Anaclitic and Introjective Personality Styles from Patients' Speech",
            "updated": "2023-11-07T15:56:19Z",
            "published": "2023-11-07T15:56:19Z",
            "summary": "In disentangling the heterogeneity observed in psychopathology, personality\nof the patients is considered crucial. While it has been demonstrated that\npersonality traits are reflected in the language used by a patient, we\nhypothesize that this enables automatic inference of the personality type\ndirectly from speech utterances, potentially more accurately than through a\ntraditional questionnaire-based approach explicitly designed for personality\nclassification. To validate this hypothesis, we adopt natural language\nprocessing (NLP) and standard machine learning tools for classification. We\ntest this on a dataset of recorded clinical diagnostic interviews (CDI) on a\nsample of 79 patients diagnosed with major depressive disorder (MDD) -- a\ncondition for which differentiated treatment based on personality styles has\nbeen advocated -- and classified into anaclitic and introjective personality\nstyles. We start by analyzing the interviews to see which linguistic features\nare associated with each style, in order to gain a better understanding of the\nstyles. Then, we develop automatic classifiers based on (a) standardized\nquestionnaire responses; (b) basic text features, i.e., TF-IDF scores of words\nand word sequences; (c) more advanced text features, using LIWC (linguistic\ninquiry and word count) and context-aware features using BERT (bidirectional\nencoder representations from transformers); (d) audio features. We find that\nautomated classification with language-derived features (i.e., based on LIWC)\nsignificantly outperforms questionnaire-based classification models.\nFurthermore, the best performance is achieved by combining LIWC with the\nquestionnaire features. This suggests that more work should be put into\ndeveloping linguistically based automated techniques for characterizing\npersonality, however questionnaires still to some extent complement such\nmethods.",
            "author": [
                "Semere Kiros Bitew",
                "Vincent Schelstraete",
                "Klim Zaporojets",
                "Kimberly Van Nieuwenhove",
                "Reitske Meganck",
                "Chris Develder"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04088v1",
                "http://arxiv.org/pdf/2311.04088v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04082v1",
            "title": "Time-Efficient Reinforcement Learning with Stochastic Stateful Policies",
            "updated": "2023-11-07T15:48:07Z",
            "published": "2023-11-07T15:48:07Z",
            "summary": "Stateful policies play an important role in reinforcement learning, such as\nhandling partially observable environments, enhancing robustness, or imposing\nan inductive bias directly into the policy structure. The conventional method\nfor training stateful policies is Backpropagation Through Time (BPTT), which\ncomes with significant drawbacks, such as slow training due to sequential\ngradient propagation and the occurrence of vanishing or exploding gradients.\nThe gradient is often truncated to address these issues, resulting in a biased\npolicy update. We present a novel approach for training stateful policies by\ndecomposing the latter into a stochastic internal state kernel and a stateless\npolicy, jointly optimized by following the stateful policy gradient. We\nintroduce different versions of the stateful policy gradient theorem, enabling\nus to easily instantiate stateful variants of popular reinforcement learning\nand imitation learning algorithms. Furthermore, we provide a theoretical\nanalysis of our new gradient estimator and compare it with BPTT. We evaluate\nour approach on complex continuous control tasks, e.g., humanoid locomotion,\nand demonstrate that our gradient estimator scales effectively with task\ncomplexity while offering a faster and simpler alternative to BPTT.",
            "author": [
                "Firas Al-Hafez",
                "Guoping Zhao",
                "Jan Peters",
                "Davide Tateo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04082v1",
                "http://arxiv.org/pdf/2311.04082v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04081v1",
            "title": "Learning Super-Resolution Ultrasound Localization Microscopy from\n  Radio-Frequency Data",
            "updated": "2023-11-07T15:47:38Z",
            "published": "2023-11-07T15:47:38Z",
            "summary": "Ultrasound Localization Microscopy (ULM) enables imaging of vascular\nstructures in the micrometer range by accumulating contrast agent particle\nlocations over time. Precise and efficient target localization accuracy remains\nan active research topic in the ULM field to further push the boundaries of\nthis promising medical imaging technology. Existing work incorporates\nDelay-And-Sum (DAS) beamforming into particle localization pipelines, which\nultimately determines the ULM image resolution capability. In this paper we\npropose to feed unprocessed Radio-Frequency (RF) data into a super-resolution\nnetwork while bypassing DAS beamforming and its limitations. To facilitate\nthis, we demonstrate label projection and inverse point transformation between\nB-mode and RF coordinate space as required by our approach. We assess our\nmethod against state-of-the-art techniques based on a public dataset featuring\nin silico and in vivo data. Results from our RF-trained network suggest that\nexcluding DAS beamforming offers a great potential to optimize on the ULM\nresolution performance.",
            "author": [
                "Christopher Hahne",
                "Georges Chabouh",
                "Olivier Couture",
                "Raphael Sznitman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04081v1",
                "http://arxiv.org/pdf/2311.04081v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04077v1",
            "title": "Deep Neural Network based Optimal Control of Greenhouses",
            "updated": "2023-11-07T15:40:44Z",
            "published": "2023-11-07T15:40:44Z",
            "summary": "Automatic control of greenhouse crop production is of great interest owing to\nthe increasing energy and labor costs. Hierarchical Model Predictive Control\n(HMPC) is a multi-level control strategy for regulating environmental\nconditions in a greenhouse through energy-efficient operation and resource\nutilization. We suggest in this work to use two-level HMPC, where the upper\nlevel generates suitable reference trajectories based on day-ahead predictions.\nThese references are tracked down in the lower level using Nonlinear Model\nPredictive Control (NMPC). In order to apply HMPC, a model of the crop dynamics\nis essential. However, the complex nature of the underlying model including\ndiscontinuities and nonlinearities results in intractable computational\ncomplexity and long sampling times. In this paper, we propose to use NMPC as a\ndata generator to learn the tracking control policy using deep neural networks.\nThen, the references are tracked using the trained Deep Neural Network (DNN) to\nreduce the computational burden. The efficiency of our approach under real-time\ndisturbances is demonstrated by means of a simulation study.",
            "author": [
                "Kiran Kumar Sathyanarayanan",
                "Philipp Sauerteig",
                "Stefan Streif"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04077v1",
                "http://arxiv.org/pdf/2311.04077v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04072v1",
            "title": "Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment",
            "updated": "2023-11-07T15:36:40Z",
            "published": "2023-11-07T15:36:40Z",
            "summary": "Alignment with human preference is a desired property of large language\nmodels (LLMs). Currently, the main alignment approach is based on reinforcement\nlearning from human feedback (RLHF). Despite the effectiveness of RLHF, it is\nintricate to implement and train, thus recent studies explore how to develop\nalternative alignment approaches based on supervised fine-tuning (SFT). A major\nlimitation of SFT is that it essentially does imitation learning, which cannot\nfully understand what are the expected behaviors. To address this issue, we\npropose an improved alignment approach named FIGA. Different from prior\nmethods, we incorporate fine-grained (i.e., token or phrase level) quality\nsignals that are derived by contrasting good and bad responses. Our approach\nhas made two major contributions. Firstly, we curate a refined alignment\ndataset that pairs initial responses and the corresponding revised ones.\nSecondly, we devise a new loss function can leverage fine-grained quality\nsignals to instruct the learning of LLMs for alignment. Extensive experiments\nhave demonstrated the effectiveness of our approaches by comparing a number of\ncompetitive baselines.",
            "author": [
                "Geyang Guo",
                "Ranchi Zhao",
                "Tianyi Tang",
                "Wayne Xin Zhao",
                "Ji-Rong Wen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04072v1",
                "http://arxiv.org/pdf/2311.04072v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04071v2",
            "title": "Energy-Calibrated VAE with Test Time Free Lunch",
            "updated": "2023-11-21T09:58:34Z",
            "published": "2023-11-07T15:35:56Z",
            "summary": "In this paper, we propose a novel generative model that utilizes a\nconditional Energy-Based Model (EBM) for enhancing Variational Autoencoder\n(VAE), termed Energy-Calibrated VAE (EC-VAE). Specifically, VAEs often suffer\nfrom blurry generated samples due to the lack of a tailored training on the\nsamples generated in the generative direction. On the other hand, EBMs can\ngenerate high-quality samples but require expensive Markov Chain Monte Carlo\n(MCMC) sampling. To address these issues, we introduce a conditional EBM for\ncalibrating the generative direction of VAE during training, without requiring\nit for the generation at test time. In particular, we train EC-VAE upon both\nthe input data and the calibrated samples with adaptive weight to enhance\nefficacy while avoiding MCMC sampling at test time. Furthermore, we extend the\ncalibration idea of EC-VAE to variational learning and normalizing flows, and\napply EC-VAE to an additional application of zero-shot image restoration via\nneural transport prior and range-null theory. We evaluate the proposed method\nwith two applications, including image generation and zero-shot image\nrestoration, and the experimental results show that our method achieves the\nstate-of-the-art performance over single-step non-adversarial generation.",
            "author": [
                "Yihong Luo",
                "Siya Qiu",
                "Xingjian Tao",
                "Yujun Cai",
                "Jing Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04071v2",
                "http://arxiv.org/pdf/2311.04071v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04069v1",
            "title": "LISBET: a self-supervised Transformer model for the automatic\n  segmentation of social behavior motifs",
            "updated": "2023-11-07T15:35:17Z",
            "published": "2023-11-07T15:35:17Z",
            "summary": "Social behavior, defined as the process by which individuals act and react in\nresponse to others, is crucial for the function of societies and holds profound\nimplications for mental health. To fully grasp the intricacies of social\nbehavior and identify potential therapeutic targets for addressing social\ndeficits, it is essential to understand its core principles. Although machine\nlearning algorithms have made it easier to study specific aspects of complex\nbehavior, current methodologies tend to focus primarily on single-animal\nbehavior. In this study, we introduce LISBET (seLf-supervIsed Social BEhavioral\nTransformer), a model designed to detect and segment social interactions. Our\nmodel eliminates the need for feature selection and extensive human annotation\nby using self-supervised learning to detect and quantify social behaviors from\ndynamic body parts tracking data. LISBET can be used in hypothesis-driven mode\nto automate behavior classification using supervised finetuning, and in\ndiscovery-driven mode to segment social behavior motifs using unsupervised\nlearning. We found that motifs recognized using the discovery-driven approach\nnot only closely match the human annotations but also correlate with the\nelectrophysiological activity of dopaminergic neurons in the Ventral Tegmental\nArea (VTA). We hope LISBET will help the community improve our understanding of\nsocial behaviors and their neural underpinnings.",
            "author": [
                "Giuseppe Chindemi",
                "Benoit Girard",
                "Camilla Bellone"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04069v1",
                "http://arxiv.org/pdf/2311.04069v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "q-bio.QM",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04067v1",
            "title": "Multitask Multimodal Prompted Training for Interactive Embodied Task\n  Completion",
            "updated": "2023-11-07T15:27:52Z",
            "published": "2023-11-07T15:27:52Z",
            "summary": "Interactive and embodied tasks pose at least two fundamental challenges to\nexisting Vision & Language (VL) models, including 1) grounding language in\ntrajectories of actions and observations, and 2) referential disambiguation. To\ntackle these challenges, we propose an Embodied MultiModal Agent (EMMA): a\nunified encoder-decoder model that reasons over images and trajectories, and\ncasts action prediction as multimodal text generation. By unifying all tasks as\ntext generation, EMMA learns a language of actions which facilitates transfer\nacross tasks. Different to previous modular approaches with independently\ntrained components, we use a single multitask model where each task contributes\nto goal completion. EMMA performs on par with similar models on several VL\nbenchmarks and sets a new state-of-the-art performance (36.81% success rate) on\nthe Dialog-guided Task Completion (DTC), a benchmark to evaluate dialog-guided\nagents in the Alexa Arena",
            "author": [
                "Georgios Pantazopoulos",
                "Malvina Nikandrou",
                "Amit Parekh",
                "Bhathiya Hemanthage",
                "Arash Eshghi",
                "Ioannis Konstas",
                "Verena Rieser",
                "Oliver Lemon",
                "Alessandro Suglia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04067v1",
                "http://arxiv.org/pdf/2311.04067v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04064v2",
            "title": "KPI Extraction from Maintenance Work Orders -- A Comparison of Expert\n  Labeling, Text Classification and AI-Assisted Tagging for Computing Failure\n  Rates of Wind Turbines",
            "updated": "2023-12-06T17:17:00Z",
            "published": "2023-11-07T15:25:52Z",
            "summary": "Maintenance work orders are commonly used to document information about wind\nturbine operation and maintenance. This includes details about proactive and\nreactive wind turbine downtimes, such as preventative and corrective\nmaintenance. However, the information contained in maintenance work orders is\noften unstructured and difficult to analyze, presenting challenges for\ndecision-makers wishing to use it for optimizing operation and maintenance. To\naddress this issue, this work compares three different approaches to calculate\nreliability by performance indicators from maintenance work orders. The first\napproach involves manual labeling of the maintenance work orders by domain\nexperts, using the schema defined in an industrial guideline to assign the\nlabel accordingly. The second approach involves the development of a model that\nautomatically labels the maintenance work orders using text classification\nmethods. Through this method, we are able to achieve macro average and weighted\naverage F1-Scores of 0.75 and 0.85 respectively. The third technique uses an\nAI-assisted tagging tool to tag and structure the raw maintenance information,\ntogether with a novel rule-based approach for extracting relevant maintenance\nwork orders for failure rate calculation. In our experiments the AI-assisted\ntool leads to a 88% drop in tagging time in comparison to the other two\napproaches, while expert labeling and text classification are more accurate in\nKPI extraction. Overall, our findings make extracting maintenance information\nfrom maintenance work orders more efficient, enable the assessment of\nreliability key performance indicators and therefore support the optimization\nof wind turbine operation and maintenance.",
            "author": [
                "Marc-Alexander Lutz",
                "Bastian Sch\u00e4fermeier",
                "Rachael Sexton",
                "Michael Sharp",
                "Alden Dima",
                "Stefan Faulstich",
                "Jagan Mohini Aluri"
            ],
            "link": [
                "http://dx.doi.org/10.3390/en16247937",
                "http://arxiv.org/abs/2311.04064v2",
                "http://arxiv.org/pdf/2311.04064v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "I.2.7; I.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04060v1",
            "title": "Estimator-Coupled Reinforcement Learning for Robust Purely Tactile\n  In-Hand Manipulation",
            "updated": "2023-11-07T15:19:50Z",
            "published": "2023-11-07T15:19:50Z",
            "summary": "This paper identifies and addresses the problems with naively combining\n(reinforcement) learning-based controllers and state estimators for robotic\nin-hand manipulation. Specifically, we tackle the challenging task of purely\ntactile, goal-conditioned, dextrous in-hand reorientation with the hand\npointing downwards. Due to the limited sensing available, many control\nstrategies that are feasible in simulation when having full knowledge of the\nobject's state do not allow for accurate state estimation. Hence, separately\ntraining the controller and the estimator and combining the two at test time\nleads to poor performance. We solve this problem by coupling the control policy\nto the state estimator already during training in simulation. This approach\nleads to more robust state estimation and overall higher performance on the\ntask while maintaining an interpretability advantage over end-to-end policy\nlearning. With our GPU-accelerated implementation, learning from scratch takes\na median training time of only 6.5 hours on a single, low-cost GPU. In\nsimulation experiments with the DLR-Hand II and for four significantly\ndifferent object shapes, we provide an in-depth analysis of the performance of\nour approach. We demonstrate the successful sim2real transfer by rotating the\nfour objects to all 24 orientations in the $\\pi/2$ discretization of SO(3),\nwhich has never been achieved for such a diverse set of shapes. Finally, our\nmethod can reorient a cube consecutively to nine goals (median), which was\nbeyond the reach of previous methods in this challenging setting.",
            "author": [
                "Lennart R\u00f6stel",
                "Johannes Pitz",
                "Leon Sievers",
                "Berthold B\u00e4uml"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04060v1",
                "http://arxiv.org/pdf/2311.04060v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04059v1",
            "title": "Over-the-Air Computation Empowered Federated Learning: A Joint\n  Uplink-Downlink Design",
            "updated": "2023-11-07T15:14:35Z",
            "published": "2023-11-07T15:14:35Z",
            "summary": "In this paper, we investigate the communication designs of over-the-air\ncomputation (AirComp) empowered federated learning (FL) systems considering\nuplink model aggregation and downlink model dissemination jointly. We first\nderive an upper bound on the expected difference between the training loss and\nthe optimal loss, which reveals that optimizing the FL performance is\nequivalent to minimizing the distortion in the received global gradient vector\nat each edge node. As such, we jointly optimize each edge node transmit and\nreceive equalization coefficients along with the edge server forwarding matrix\nto minimize the maximum gradient distortion across all edge nodes. We further\nutilize the MNIST dataset to evaluate the performance of the considered FL\nsystem in the context of the handwritten digit recognition task. Experiment\nresults show that deploying multiple antennas at the edge server significantly\nreduces the distortion in the received global gradient vector, leading to a\nnotable improvement in recognition accuracy compared to the single antenna\ncase.",
            "author": [
                "Deyou Zhang",
                "Ming Xiao",
                "Mikael Skoglund"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04059v1",
                "http://arxiv.org/pdf/2311.04059v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04058v1",
            "title": "mmFUSION: Multimodal Fusion for 3D Objects Detection",
            "updated": "2023-11-07T15:11:27Z",
            "published": "2023-11-07T15:11:27Z",
            "summary": "Multi-sensor fusion is essential for accurate 3D object detection in\nself-driving systems. Camera and LiDAR are the most commonly used sensors, and\nusually, their fusion happens at the early or late stages of 3D detectors with\nthe help of regions of interest (RoIs). On the other hand, fusion at the\nintermediate level is more adaptive because it does not need RoIs from\nmodalities but is complex as the features of both modalities are presented from\ndifferent points of view. In this paper, we propose a new intermediate-level\nmulti-modal fusion (mmFUSION) approach to overcome these challenges. First, the\nmmFUSION uses separate encoders for each modality to compute features at a\ndesired lower space volume. Second, these features are fused through\ncross-modality and multi-modality attention mechanisms proposed in mmFUSION.\nThe mmFUSION framework preserves multi-modal information and learns to\ncomplement modalities' deficiencies through attention weights. The strong\nmulti-modal features from the mmFUSION framework are fed to a simple 3D\ndetection head for 3D predictions. We evaluate mmFUSION on the KITTI and\nNuScenes dataset where it performs better than available early, intermediate,\nlate, and even two-stage based fusion schemes. The code with the mmdetection3D\nproject plugin will be publicly available soon.",
            "author": [
                "Javed Ahmad",
                "Alessio Del Bue"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04058v1",
                "http://arxiv.org/pdf/2311.04058v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04056v1",
            "title": "Multi-View Causal Representation Learning with Partial Observability",
            "updated": "2023-11-07T15:07:08Z",
            "published": "2023-11-07T15:07:08Z",
            "summary": "We present a unified framework for studying the identifiability of\nrepresentations learned from simultaneously observed views, such as different\ndata modalities. We allow a partially observed setting in which each view\nconstitutes a nonlinear mixture of a subset of underlying latent variables,\nwhich can be causally related. We prove that the information shared across all\nsubsets of any number of views can be learned up to a smooth bijection using\ncontrastive learning and a single encoder per view. We also provide graphical\ncriteria indicating which latent variables can be identified through a simple\nset of rules, which we refer to as identifiability algebra. Our general\nframework and theoretical results unify and extend several previous works on\nmulti-view nonlinear ICA, disentanglement, and causal representation learning.\nWe experimentally validate our claims on numerical, image, and multi-modal data\nsets. Further, we demonstrate that the performance of prior methods is\nrecovered in different special cases of our setup. Overall, we find that access\nto multiple partial views enables us to identify a more fine-grained\nrepresentation, under the generally milder assumption of partial observability.",
            "author": [
                "Dingling Yao",
                "Danru Xu",
                "S\u00e9bastien Lachapelle",
                "Sara Magliacane",
                "Perouz Taslakian",
                "Georg Martius",
                "Julius von K\u00fcgelgen",
                "Francesco Locatello"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04056v1",
                "http://arxiv.org/pdf/2311.04056v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04055v1",
            "title": "Feature Space Renormalization for Semi-supervised Learning",
            "updated": "2023-11-07T15:07:02Z",
            "published": "2023-11-07T15:07:02Z",
            "summary": "Semi-supervised learning (SSL) has been proven to be a powerful method for\nleveraging unlabelled data to alleviate models' dependence on large labelled\ndatasets. The common framework among recent approaches is to train the model on\na large amount of unlabelled data with consistency regularization to constrain\nthe model predictions to be invariant to input perturbation. However, the\nexisting SSL frameworks still have room for improvement in the consistency\nregularization method. Instead of regularizing category predictions in the\nlabel space as in existing frameworks, this paper proposes a feature space\nrenormalization (FSR) mechanism for SSL. First, we propose a feature space\nrenormalization mechanism to substitute for the commonly used consistency\nregularization mechanism to learn better discriminative features. To apply this\nmechanism, we start by building a basic model and an empirical model and then\nintroduce our mechanism to renormalize the feature learning of the basic model\nwith the guidance of the empirical model. Second, we combine the proposed\nmechanism with pseudo-labelling to obtain a novel effective SSL model named\nFreMatch. The experimental results show that our method can achieve better\nperformance on a variety of standard SSL benchmark datasets, and the proposed\nfeature space renormalization mechanism can also enhance the performance of\nother SSL approaches.",
            "author": [
                "Jun Sun",
                "Zhongjie Mao",
                "Chao Li",
                "Chao Zhou",
                "Xiao-Jun Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04055v1",
                "http://arxiv.org/pdf/2311.04055v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04052v1",
            "title": "Generative Structural Design Integrating BIM and Diffusion Model",
            "updated": "2023-11-07T15:05:19Z",
            "published": "2023-11-07T15:05:19Z",
            "summary": "Intelligent structural design using AI can effectively reduce time overhead\nand increase efficiency. It has potential to become the new design paradigm in\nthe future to assist and even replace engineers, and so it has become a\nresearch hotspot in the academic community. However, current methods have some\nlimitations to be addressed, whether in terms of application scope, visual\nquality of generated results, or evaluation metrics of results. This study\nproposes a comprehensive solution. Firstly, we introduce building information\nmodeling (BIM) into intelligent structural design and establishes a structural\ndesign pipeline integrating BIM and generative AI, which is a powerful\nsupplement to the previous frameworks that only considered CAD drawings. In\norder to improve the perceptual quality and details of generations, this study\nmakes 3 contributions. Firstly, in terms of generation framework, inspired by\nthe process of human drawing, a novel 2-stage generation framework is proposed\nto replace the traditional end-to-end framework to reduce the generation\ndifficulty for AI models. Secondly, in terms of generative AI tools adopted,\ndiffusion models (DMs) are introduced to replace widely used generative\nadversarial network (GAN)-based models, and a novel physics-based conditional\ndiffusion model (PCDM) is proposed to consider different design prerequisites.\nThirdly, in terms of neural networks, an attention block (AB) consisting of a\nself-attention block (SAB) and a parallel cross-attention block (PCAB) is\ndesigned to facilitate cross-domain data fusion. The quantitative and\nqualitative results demonstrate the powerful generation and representation\ncapabilities of PCDM. Necessary ablation studies are conducted to examine the\nvalidity of the methods. This study also shows that DMs have the potential to\nreplace GANs and become the new benchmark for generative problems in civil\nengineering.",
            "author": [
                "Zhili He",
                "Yu-Hsing Wang",
                "Jian Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04052v1",
                "http://arxiv.org/pdf/2311.04052v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04047v1",
            "title": "Extracting human interpretable structure-property relationships in\n  chemistry using XAI and large language models",
            "updated": "2023-11-07T15:02:32Z",
            "published": "2023-11-07T15:02:32Z",
            "summary": "Explainable Artificial Intelligence (XAI) is an emerging field in AI that\naims to address the opaque nature of machine learning models. Furthermore, it\nhas been shown that XAI can be used to extract input-output relationships,\nmaking them a useful tool in chemistry to understand structure-property\nrelationships. However, one of the main limitations of XAI methods is that they\nare developed for technically oriented users. We propose the XpertAI framework\nthat integrates XAI methods with large language models (LLMs) accessing\nscientific literature to generate accessible natural language explanations of\nraw chemical data automatically. We conducted 5 case studies to evaluate the\nperformance of XpertAI. Our results show that XpertAI combines the strengths of\nLLMs and XAI tools in generating specific, scientific, and interpretable\nexplanations.",
            "author": [
                "Geemi P. Wellawatte",
                "Philippe Schwaller"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04047v1",
                "http://arxiv.org/pdf/2311.04047v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04046v1",
            "title": "Reinforcement Learning Fine-tuning of Language Models is Biased Towards\n  More Extractable Features",
            "updated": "2023-11-07T15:00:39Z",
            "published": "2023-11-07T15:00:39Z",
            "summary": "Many capable large language models (LLMs) are developed via self-supervised\npre-training followed by a reinforcement-learning fine-tuning phase, often\nbased on human or AI feedback. During this stage, models may be guided by their\ninductive biases to rely on simpler features which may be easier to extract, at\na cost to robustness and generalisation. We investigate whether principles\ngoverning inductive biases in the supervised fine-tuning of LLMs also apply\nwhen the fine-tuning process uses reinforcement learning. Following Lovering et\nal (2021), we test two hypotheses: that features more $\\textit{extractable}$\nafter pre-training are more likely to be utilised by the final policy, and that\nthe evidence for/against a feature predicts whether it will be utilised.\nThrough controlled experiments on synthetic and natural language tasks, we find\nstatistically significant correlations which constitute strong evidence for\nthese hypotheses.",
            "author": [
                "Diogo Cruz",
                "Edoardo Pona",
                "Alex Holness-Tofts",
                "Elias Schmied",
                "V\u00edctor Abia Alonso",
                "Charlie Griffin",
                "Bogdan-Ionut Cirstea"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04046v1",
                "http://arxiv.org/pdf/2311.04046v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04041v1",
            "title": "Hilbert's projective metric for functions of bounded growth and\n  exponential convergence of Sinkhorn's algorithm",
            "updated": "2023-11-07T14:53:23Z",
            "published": "2023-11-07T14:53:23Z",
            "summary": "We study versions of Hilbert's projective metric for spaces of integrable\nfunctions of bounded growth. These metrics originate from cones which are\nrelaxations of the cone of all non-negative functions, in the sense that they\ninclude all functions having non-negative integral values when multiplied with\ncertain test functions. We show that kernel integral operators are contractions\nwith respect to suitable specifications of such metrics even for kernels which\nare not bounded away from zero, provided that the decay to zero of the kernel\nis controlled. As an application to entropic optimal transport, we show\nexponential convergence of Sinkhorn's algorithm in settings where the marginal\ndistributions have sufficiently light tails compared to the growth of the cost\nfunction.",
            "author": [
                "Stephan Eckstein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04041v1",
                "http://arxiv.org/pdf/2311.04041v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04040v1",
            "title": "Data exploitation: multi-task learning of object detection and semantic\n  segmentation on partially annotated data",
            "updated": "2023-11-07T14:49:54Z",
            "published": "2023-11-07T14:49:54Z",
            "summary": "Multi-task partially annotated data where each data point is annotated for\nonly a single task are potentially helpful for data scarcity if a network can\nleverage the inter-task relationship. In this paper, we study the joint\nlearning of object detection and semantic segmentation, the two most popular\nvision problems, from multi-task data with partial annotations. Extensive\nexperiments are performed to evaluate each task performance and explore their\ncomplementarity when a multi-task network cannot optimize both tasks\nsimultaneously. We propose employing knowledge distillation to leverage\njoint-task optimization. The experimental results show favorable results for\nmulti-task learning and knowledge distillation over single-task learning and\neven full supervision scenario. All code and data splits are available at\nhttps://github.com/lhoangan/multas",
            "author": [
                "Ho\u00e0ng-\u00c2n L\u00ea",
                "Minh-Tan Pham"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04040v1",
                "http://arxiv.org/pdf/2311.04040v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04037v2",
            "title": "Causal Discovery Under Local Privacy",
            "updated": "2023-11-15T10:50:13Z",
            "published": "2023-11-07T14:44:27Z",
            "summary": "Differential privacy is a widely adopted framework designed to safeguard the\nsensitive information of data providers within a data set. It is based on the\napplication of controlled noise at the interface between the server that stores\nand processes the data, and the data consumers. Local differential privacy is a\nvariant that allows data providers to apply the privatization mechanism\nthemselves on their data individually. Therefore it provides protection also in\ncontexts in which the server, or even the data collector, cannot be trusted.\nThe introduction of noise, however, inevitably affects the utility of the data,\nparticularly by distorting the correlations between individual data components.\nThis distortion can prove detrimental to tasks such as causal discovery. In\nthis paper, we consider various well-known locally differentially private\nmechanisms and compare the trade-off between the privacy they provide, and the\naccuracy of the causal structure produced by algorithms for causal learning\nwhen applied to data obfuscated by these mechanisms. Our analysis yields\nvaluable insights for selecting appropriate local differentially private\nprotocols for causal discovery tasks. We foresee that our findings will aid\nresearchers and practitioners in conducting locally private causal discovery.",
            "author": [
                "R\u016bta Binkyt\u0117",
                "Carlos Pinz\u00f3n",
                "Szilvia Lesty\u00e1n",
                "Kangsoo Jung",
                "H\u00e9ber H. Arcolezi",
                "Catuscia Palamidessi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04037v2",
                "http://arxiv.org/pdf/2311.04037v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04035v1",
            "title": "Discordance Minimization-based Imputation Algorithms for Missing Values\n  in Rating Data",
            "updated": "2023-11-07T14:42:06Z",
            "published": "2023-11-07T14:42:06Z",
            "summary": "Ratings are frequently used to evaluate and compare subjects in various\napplications, from education to healthcare, because ratings provide succinct\nyet credible measures for comparing subjects. However, when multiple rating\nlists are combined or considered together, subjects often have missing ratings,\nbecause most rating lists do not rate every subject in the combined list. In\nthis study, we propose analyses on missing value patterns using six real-world\ndata sets in various applications, as well as the conditions for applicability\nof imputation algorithms. Based on the special structures and properties\nderived from the analyses, we propose optimization models and algorithms that\nminimize the total rating discordance across rating providers to impute missing\nratings in the combined rating lists, using only the known rating information.\nThe total rating discordance is defined as the sum of the pairwise discordance\nmetric, which can be written as a quadratic function. Computational experiments\nbased on real-world and synthetic rating data sets show that the proposed\nmethods outperform the state-of-the-art general imputation methods in the\nliterature in terms of imputation accuracy.",
            "author": [
                "Young Woong Park",
                "Jinhak Kim",
                "Dan Zhu"
            ],
            "link": [
                "http://dx.doi.org/10.1007/s10994-023-06452-4",
                "http://arxiv.org/abs/2311.04035v1",
                "http://arxiv.org/pdf/2311.04035v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04034v1",
            "title": "Impact of HPO on AutoML Forecasting Ensembles",
            "updated": "2023-11-07T14:38:18Z",
            "published": "2023-11-07T14:38:18Z",
            "summary": "A forecasting ensemble consisting of a diverse range of estimators for both\nlocal and global univariate forecasting, in particular MQ-CNN,DeepAR, Prophet,\nNPTS, ARIMA and ETS, can be used to make forecasts for a variety of problems.\nThis paper delves into the aspect of adding different hyperparameter\noptimization strategies to the deep learning models in such a setup (DeepAR and\nMQ-CNN), exploring the trade-off between added training cost and the increase\nin accuracy for different configurations. It shows that in such a setup, adding\nhyperparameter optimization can lead to performance improvements, with the\nfinal setup having a 9.9 % percent accuracy improvement with respect to the\navg-wQL over the baseline ensemble without HPO, accompanied by a 65.8 %\nincrease in end-to-end ensemble latency. This improvement is based on an\nempirical analysis of combining the ensemble pipeline with different tuning\nstrategies, namely Bayesian Optimisation and Hyperband and different\nconfigurations of those strategies. In the final configuration, the proposed\ncombination of ensemble learning and HPO outperforms the state of the art\ncommercial AutoML forecasting solution, Amazon Forecast, with a 3.5 % lower\nerror and 16.0 % lower end-to-end ensemble latency.",
            "author": [
                "David Hoffmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04034v1",
                "http://arxiv.org/pdf/2311.04034v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "I.2.6; I.2.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04258v1",
            "title": "IoT-Based Environmental Control System for Fish Farms with Sensor\n  Integration and Machine Learning Decision Support",
            "updated": "2023-11-07T14:35:16Z",
            "published": "2023-11-07T14:35:16Z",
            "summary": "In response to the burgeoning global demand for seafood and the challenges of\nmanaging fish farms, we introduce an innovative IoT based environmental control\nsystem that integrates sensor technology and advanced machine learning decision\nsupport. Deploying a network of wireless sensors within the fish farm, we\ncontinuously collect real-time data on crucial environmental parameters,\nincluding water temperature, pH levels, humidity, and fish behavior. This data\nundergoes meticulous preprocessing to ensure its reliability, including\nimputation, outlier detection, feature engineering, and synchronization. At the\nheart of our system are four distinct machine learning algorithms: Random\nForests predict and optimize water temperature and pH levels for the fish,\nfostering their health and growth; Support Vector Machines (SVMs) function as\nan early warning system, promptly detecting diseases and parasites in fish;\nGradient Boosting Machines (GBMs) dynamically fine-tune the feeding schedule\nbased on real-time environmental conditions, promoting resource efficiency and\nfish productivity; Neural Networks manage the operation of critical equipment\nlike water pumps and heaters to maintain the desired environmental conditions\nwithin the farm. These machine learning algorithms collaboratively make\nreal-time decisions to ensure that the fish farm's environmental conditions\nalign with predefined specifications, leading to improved fish health and\nproductivity while simultaneously reducing resource wastage, thereby\ncontributing to increased profitability and sustainability. This research\narticle showcases the power of data-driven decision support in fish farming,\npromising to meet the growing demand for seafood while emphasizing\nenvironmental responsibility and economic viability, thus revolutionizing the\nfuture of fish farming.",
            "author": [
                "D. Dhinakaran",
                "S. Gopalakrishnan",
                "M. D. Manigandan",
                "T. P. Anish"
            ],
            "link": [
                "http://dx.doi.org/10.17762/ijritcc.v11i10.8482",
                "http://arxiv.org/abs/2311.04258v1",
                "http://arxiv.org/pdf/2311.04258v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06303v1",
            "title": "MatNexus: A Comprehensive Text Mining and Analysis Suite for Materials\n  Discover",
            "updated": "2023-11-07T14:14:36Z",
            "published": "2023-11-07T14:14:36Z",
            "summary": "MatNexus is a specialized software for the automated collection, processing,\nand analysis of text from scientific articles. Through an integrated suite of\nmodules, the MatNexus facilitates the retrieval of scientific articles,\nprocesses textual data for insights, generates vector representations suitable\nfor machine learning, and offers visualization capabilities for word\nembeddings. With the vast volume of scientific publications, MatNexus stands\nout as an end-to-end tool for researchers aiming to gain insights from\nscientific literature in material science, making the exploration of materials,\nsuch as the electrocatalyst examples we show here, efficient and insightful.",
            "author": [
                "Lei Zhang",
                "Markus Stricker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06303v1",
                "http://arxiv.org/pdf/2311.06303v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.CL",
                "physics.chem-ph",
                "H.4; H.5; I.5; I.7; J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04016v1",
            "title": "Exploring Dataset-Scale Indicators of Data Quality",
            "updated": "2023-11-07T14:14:32Z",
            "published": "2023-11-07T14:14:32Z",
            "summary": "Modern computer vision foundation models are trained on massive amounts of\ndata, incurring large economic and environmental costs. Recent research has\nsuggested that improving data quality can significantly reduce the need for\ndata quantity. But what constitutes data quality in computer vision? We posit\nthat the quality of a given dataset can be decomposed into distinct\nsample-level and dataset-level constituents, and that the former have been more\nextensively studied than the latter. We ablate the effects of two important\ndataset-level constituents: label set design, and class balance. By monitoring\nthese constituents using key indicators we provide, researchers and\npractitioners can better anticipate model performance, measured in terms of its\naccuracy and robustness to distribution shifts.",
            "author": [
                "Benjamin Feuer",
                "Chinmay Hegde"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04016v1",
                "http://arxiv.org/pdf/2311.04016v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04015v1",
            "title": "Expressivity of ReLU-Networks under Convex Relaxations",
            "updated": "2023-11-07T14:14:15Z",
            "published": "2023-11-07T14:14:15Z",
            "summary": "Convex relaxations are a key component of training and certifying provably\nsafe neural networks. However, despite substantial progress, a wide and poorly\nunderstood accuracy gap to standard networks remains, raising the question of\nwhether this is due to fundamental limitations of convex relaxations. Initial\nwork investigating this question focused on the simple and widely used IBP\nrelaxation. It revealed that some univariate, convex, continuous piecewise\nlinear (CPWL) functions cannot be encoded by any ReLU network such that its\nIBP-analysis is precise. To explore whether this limitation is shared by more\nadvanced convex relaxations, we conduct the first in-depth study on the\nexpressive power of ReLU networks across all commonly used convex relaxations.\nWe show that: (i) more advanced relaxations allow a larger class of univariate\nfunctions to be expressed as precisely analyzable ReLU networks, (ii) more\nprecise relaxations can allow exponentially larger solution spaces of ReLU\nnetworks encoding the same functions, and (iii) even using the most precise\nsingle-neuron relaxations, it is impossible to construct precisely analyzable\nReLU networks that express multivariate, convex, monotone CPWL functions.",
            "author": [
                "Maximilian Baader",
                "Mark Niklas M\u00fcller",
                "Yuhao Mao",
                "Martin Vechev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04015v1",
                "http://arxiv.org/pdf/2311.04015v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.05649v1",
            "title": "Bayesian Image-on-Image Regression via Deep Kernel Learning based\n  Gaussian Processes",
            "updated": "2023-11-07T14:14:09Z",
            "published": "2023-11-07T14:14:09Z",
            "summary": "In neuroimaging studies, it becomes increasingly important to study\nassociations between different imaging modalities using image-on-image\nregression (IIR), which faces challenges in interpretation, statistical\ninference, and prediction. Our motivating problem is how to predict task-evoked\nfMRI activity using resting-state fMRI data in the Human Connectome Project\n(HCP). The main difficulty lies in effectively combining different types of\nimaging predictors with varying resolutions and spatial domains in IIR. To\naddress these issues, we develop Bayesian Image-on-image Regression via Deep\nKernel Learning Gaussian Processes (BIRD-GP) and develop efficient posterior\ncomputation methods through Stein variational gradient descent. We demonstrate\nthe advantages of BIRD-GP over state-of-the-art IIR methods using simulations.\nFor HCP data analysis using BIRD-GP, we combine the voxel-wise fALFF maps and\nregion-wise connectivity matrices to predict fMRI contrast maps for language\nand social recognition tasks. We show that fALFF is less predictive than the\nconnectivity matrix for both tasks, but combining both yields improved results.\nAngular Gyrus Right emerges as the most predictable region for the language\ntask (75.9% predictable voxels), while Superior Parietal Gyrus Right tops for\nthe social recognition task (48.9% predictable voxels). Additionally, we\nidentify features from the resting-state fMRI data that are important for task\nfMRI prediction.",
            "author": [
                "Guoxuan Ma",
                "Bangyao Zhao",
                "Hasan Abu-Amara",
                "Jian Kang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05649v1",
                "http://arxiv.org/pdf/2311.05649v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04014v2",
            "title": "A Method to Improve the Performance of Reinforcement Learning Based on\n  the Y Operator for a Class of Stochastic Differential Equation-Based\n  Child-Mother Systems",
            "updated": "2023-11-27T17:58:28Z",
            "published": "2023-11-07T14:14:06Z",
            "summary": "This paper introduces a novel operator, termed the Y operator, to elevate\ncontrol performance in Actor-Critic(AC) based reinforcement learning for\nsystems governed by stochastic differential equations(SDEs). The Y operator\ningeniously integrates the stochasticity of a class of child-mother system into\nthe Critic network's loss function, yielding substantial advancements in the\ncontrol performance of RL algorithms.Additionally, the Y operator elegantly\nreformulates the challenge of solving partial differential equations for the\nstate-value function into a parallel problem for the drift and diffusion\nfunctions within the system's SDEs.A rigorous mathematical proof confirms the\noperator's validity.This transformation enables the Y Operator-based\nReinforcement Learning(YORL) framework to efficiently tackle optimal control\nproblems in both model-based and data-driven systems.The superiority of YORL is\ndemonstrated through linear and nonlinear numerical examples showing its\nenhanced performance over existing methods post convergence.",
            "author": [
                "Cheng Yin",
                "Yi Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04014v2",
                "http://arxiv.org/pdf/2311.04014v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04009v1",
            "title": "AGNES: Abstraction-guided Framework for Deep Neural Networks Security",
            "updated": "2023-11-07T14:05:20Z",
            "published": "2023-11-07T14:05:20Z",
            "summary": "Deep Neural Networks (DNNs) are becoming widespread, particularly in\nsafety-critical areas. One prominent application is image recognition in\nautonomous driving, where the correct classification of objects, such as\ntraffic signs, is essential for safe driving. Unfortunately, DNNs are prone to\nbackdoors, meaning that they concentrate on attributes of the image that should\nbe irrelevant for their correct classification. Backdoors are integrated into a\nDNN during training, either with malicious intent (such as a manipulated\ntraining process, because of which a yellow sticker always leads to a traffic\nsign being recognised as a stop sign) or unintentional (such as a rural\nbackground leading to any traffic sign being recognised as animal crossing,\nbecause of biased training data).\n  In this paper, we introduce AGNES, a tool to detect backdoors in DNNs for\nimage recognition. We discuss the principle approach on which AGNES is based.\nAfterwards, we show that our tool performs better than many state-of-the-art\nmethods for multiple relevant case studies.",
            "author": [
                "Akshay Dhonthi",
                "Marcello Eiermann",
                "Ernst Moritz Hahn",
                "Vahid Hashemi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04009v1",
                "http://arxiv.org/pdf/2311.04009v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04008v1",
            "title": "Joint model for longitudinal and spatio-temporal survival data",
            "updated": "2023-11-07T14:05:14Z",
            "published": "2023-11-07T14:05:14Z",
            "summary": "In credit risk analysis, survival models with fixed and time-varying\ncovariates are widely used to predict a borrower's time-to-event. When the\ntime-varying drivers are endogenous, modelling jointly the evolution of the\nsurvival time and the endogenous covariates is the most appropriate approach,\nalso known as the joint model for longitudinal and survival data. In addition\nto the temporal component, credit risk models can be enhanced when including\nborrowers' geographical information by considering spatial clustering and its\nvariation over time. We propose the Spatio-Temporal Joint Model (STJM) to\ncapture spatial and temporal effects and their interaction. This Bayesian\nhierarchical joint model reckons the survival effect of unobserved\nheterogeneity among borrowers located in the same region at a particular time.\nTo estimate the STJM model for large datasets, we consider the Integrated\nNested Laplace Approximation (INLA) methodology. We apply the STJM to predict\nthe time to full prepayment on a large dataset of 57,258 US mortgage borrowers\nwith more than 2.5 million observations. Empirical results indicate that\nincluding spatial effects consistently improves the performance of the joint\nmodel. However, the gains are less definitive when we additionally include\nspatio-temporal interactions.",
            "author": [
                "Victor Medina-Olivares",
                "Finn Lindgren",
                "Raffaella Calabrese",
                "Jonathan Crook"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04008v1",
                "http://arxiv.org/pdf/2311.04008v1"
            ],
            "primary_category": "q-fin.RM",
            "category": [
                "q-fin.RM",
                "cs.CE",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04007v1",
            "title": "The Energy Prediction Smart-Meter Dataset: Analysis of Previous\n  Competitions and Beyond",
            "updated": "2023-11-07T14:05:01Z",
            "published": "2023-11-07T14:05:01Z",
            "summary": "This paper presents the real-world smart-meter dataset and offers an analysis\nof solutions derived from the Energy Prediction Technical Challenges, focusing\nprimarily on two key competitions: the IEEE Computational Intelligence Society\n(IEEE-CIS) Technical Challenge on Energy Prediction from Smart Meter data in\n2020 (named EP) and its follow-up challenge at the IEEE International\nConference on Fuzzy Systems (FUZZ-IEEE) in 2021 (named as XEP). These\ncompetitions focus on accurate energy consumption forecasting and the\nimportance of interpretability in understanding the underlying factors. The\nchallenge aims to predict monthly and yearly estimated consumption for\nhouseholds, addressing the accurate billing problem with limited historical\nsmart meter data. The dataset comprises 3,248 smart meters, with varying data\navailability ranging from a minimum of one month to a year. This paper delves\ninto the challenges, solutions and analysing issues related to the provided\nreal-world smart meter data, developing accurate predictions at the household\nlevel, and introducing evaluation criteria for assessing interpretability.\nAdditionally, this paper discusses aspects beyond the competitions:\nopportunities for energy disaggregation and pattern detection applications at\nthe household level, significance of communicating energy-driven factors for\noptimised billing, and emphasising the importance of responsible AI and data\nprivacy considerations. These aspects provide insights into the broader\nimplications and potential advancements in energy consumption prediction.\nOverall, these competitions provide a dataset for residential energy research\nand serve as a catalyst for exploring accurate forecasting, enhancing\ninterpretability, and driving progress towards the discussion of various\naspects such as energy disaggregation, demand response programs or behavioural\ninterventions.",
            "author": [
                "Direnc Pekaslan",
                "Jose Maria Alonso-Moral",
                "Kasun Bandara",
                "Christoph Bergmeir",
                "Juan Bernabe-Moreno",
                "Robert Eigenmann",
                "Nils Einecke",
                "Selvi Ergen",
                "Rakshitha Godahewa",
                "Hansika Hewamalage",
                "Jesus Lago",
                "Steffen Limmer",
                "Sven Rebhan",
                "Boris Rabinovich",
                "Dilini Rajapasksha",
                "Heda Song",
                "Christian Wagner",
                "Wenlong Wu",
                "Luis Magdalena",
                "Isaac Triguero"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04007v1",
                "http://arxiv.org/pdf/2311.04007v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04256v2",
            "title": "Foundational propositions of hesitant fuzzy sets and parameter\n  reductions of hesitant fuzzy information systems",
            "updated": "2023-12-06T03:42:19Z",
            "published": "2023-11-07T14:03:28Z",
            "summary": "Hesitant fuzzy sets are widely used in the instances of uncertainty and\nhesitation. The inclusion relationship is an important and foundational\ndefinition for sets. Hesitant fuzzy set, as a kind of set, needs explicit\ndefinition of inclusion relationship. Base on the hesitant fuzzy membership\ndegree of discrete form, several kinds of inclusion relationships for hesitant\nfuzzy sets are proposed. And then some foundational propositions of hesitant\nfuzzy sets and the families of hesitant fuzzy sets are presented. Finally, some\nfoundational propositions of hesitant fuzzy information systems with respect to\nparameter reductions are put forward, and an example and an algorithm are given\nto illustrate the processes of parameter reductions.",
            "author": [
                "Shizhan Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04256v2",
                "http://arxiv.org/pdf/2311.04256v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.IT",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.05709v1",
            "title": "OmniVec: Learning robust representations with cross modal sharing",
            "updated": "2023-11-07T14:00:09Z",
            "published": "2023-11-07T14:00:09Z",
            "summary": "Majority of research in learning based methods has been towards designing and\ntraining networks for specific tasks. However, many of the learning based\ntasks, across modalities, share commonalities and could be potentially tackled\nin a joint framework. We present an approach in such direction, to learn\nmultiple tasks, in multiple modalities, with a unified architecture. The\nproposed network is composed of task specific encoders, a common trunk in the\nmiddle, followed by task specific prediction heads. We first pre-train it by\nself-supervised masked training, followed by sequential training for the\ndifferent tasks. We train the network on all major modalities, e.g.\\ visual,\naudio, text and 3D, and report results on $22$ diverse and challenging public\nbenchmarks. We demonstrate empirically that, using a joint network to train\nacross modalities leads to meaningful information sharing and this allows us to\nachieve state-of-the-art results on most of the benchmarks. We also show\ngeneralization of the trained network on cross-modal tasks as well as unseen\ndatasets and tasks.",
            "author": [
                "Siddharth Srivastava",
                "Gaurav Sharma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05709v1",
                "http://arxiv.org/pdf/2311.05709v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03999v1",
            "title": "Human-AI Collaboration in Thematic Analysis using ChatGPT: A User Study\n  and Design Recommendations",
            "updated": "2023-11-07T13:54:56Z",
            "published": "2023-11-07T13:54:56Z",
            "summary": "Generative artificial intelligence (GenAI) offers promising potential for\nadvancing human-AI collaboration in qualitative research. However, existing\nworks focused on conventional machine-learning and pattern-based AI systems,\nand little is known about how researchers interact with GenAI in qualitative\nresearch. This work delves into researchers' perceptions of their collaboration\nwith GenAI, specifically ChatGPT. Through a user study involving ten\nqualitative researchers, we found ChatGPT to be a valuable collaborator for\nthematic analysis, enhancing coding efficiency, aiding initial data\nexploration, offering granular quantitative insights, and assisting\ncomprehension for non-native speakers and non-experts. Yet, concerns about its\ntrustworthiness and accuracy, reliability and consistency, limited contextual\nunderstanding, and broader acceptance within the research community persist. We\ncontribute five actionable design recommendations to foster effective human-AI\ncollaboration. These include incorporating transparent explanatory mechanisms,\nenhancing interface and integration capabilities, prioritising contextual\nunderstanding and customisation, embedding human-AI feedback loops and\niterative functionality, and strengthening trust through validation mechanisms.",
            "author": [
                "Lixiang Yan",
                "Vanessa Echeverria",
                "Gloria Fernandez Nieto",
                "Yueqiao Jin",
                "Zachari Swiecki",
                "Linxuan Zhao",
                "Dragan Ga\u0161evi\u0107",
                "Roberto Martinez-Maldonado"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03999v1",
                "http://arxiv.org/pdf/2311.03999v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03996v2",
            "title": "An Initialization Schema for Neuronal Networks on Tabular Data",
            "updated": "2023-11-24T13:28:49Z",
            "published": "2023-11-07T13:52:35Z",
            "summary": "Nowadays, many modern applications require heterogeneous tabular data, which\nis still a challenging task in terms of regression and classification. Many\napproaches have been proposed to adapt neural networks for this task, but\nstill, boosting and bagging of decision trees are the best-performing methods\nfor this task. In this paper, we show that a binomial initialized neural\nnetwork can be used effectively on tabular data. The proposed approach shows a\nsimple but effective approach for initializing the first hidden layer in neural\nnetworks. We also show that this initializing schema can be used to jointly\ntrain ensembles by adding gradient masking to batch entries and using the\nbinomial initialization for the last layer in a neural network. For this\npurpose, we modified the hinge binary loss and the soft max loss to make them\napplicable for joint ensemble training. We evaluate our approach on multiple\npublic datasets and showcase the improved performance compared to other neural\nnetwork-based approaches. In addition, we discuss the limitations and possible\nfurther research of our approach for improving the applicability of neural\nnetworks to tabular data.\n  Link:\nhttps://es-cloud.cs.uni-tuebingen.de/d/8e2ab8c3fdd444e1a135/?p=%2FInitializationNeuronalNetworksTabularData&mode=list",
            "author": [
                "Wolfgang Fuhl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03996v2",
                "http://arxiv.org/pdf/2311.03996v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03992v1",
            "title": "Bandit Pareto Set Identification: the Fixed Budget Setting",
            "updated": "2023-11-07T13:43:18Z",
            "published": "2023-11-07T13:43:18Z",
            "summary": "We study a multi-objective pure exploration problem in a multi-armed bandit\nmodel. Each arm is associated to an unknown multi-variate distribution and the\ngoal is to identify the distributions whose mean is not uniformly worse than\nthat of another distribution: the Pareto optimal set. We propose and analyze\nthe first algorithms for the \\emph{fixed budget} Pareto Set Identification\ntask. We propose Empirical Gap Elimination, a family of algorithms combining a\ncareful estimation of the ``hardness to classify'' each arm in or out of the\nPareto set with a generic elimination scheme. We prove that two particular\ninstances, EGE-SR and EGE-SH, have a probability of error that decays\nexponentially fast with the budget, with an exponent supported by an\ninformation theoretic lower-bound. We complement these findings with an\nempirical study using real-world and synthetic datasets, which showcase the\ngood performance of our algorithms.",
            "author": [
                "Cyrille Kone",
                "Emilie Kaufmann",
                "Laura Richert"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03992v1",
                "http://arxiv.org/pdf/2311.03992v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03989v2",
            "title": "Learned Causal Method Prediction",
            "updated": "2023-11-08T07:53:17Z",
            "published": "2023-11-07T13:39:17Z",
            "summary": "For a given causal question, it is important to efficiently decide which\ncausal inference method to use for a given dataset. This is challenging because\ncausal methods typically rely on complex and difficult-to-verify assumptions,\nand cross-validation is not applicable since ground truth causal quantities are\nunobserved. In this work, we propose CAusal Method Predictor (CAMP), a\nframework for predicting the best method for a given dataset. To this end, we\ngenerate datasets from a diverse set of synthetic causal models, score the\ncandidate methods, and train a model to directly predict the highest-scoring\nmethod for that dataset. Next, by formulating a self-supervised pre-training\nobjective centered on dataset assumptions relevant for causal inference, we\nsignificantly reduce the need for costly labeled data and enhance training\nefficiency. Our strategy learns to map implicit dataset properties to the best\nmethod in a data-driven manner. In our experiments, we focus on method\nprediction for causal discovery. CAMP outperforms selecting any individual\ncandidate method and demonstrates promising generalization to unseen\nsemi-synthetic and real-world benchmarks.",
            "author": [
                "Shantanu Gupta",
                "Cheng Zhang",
                "Agrin Hilmkil"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03989v2",
                "http://arxiv.org/pdf/2311.03989v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03982v1",
            "title": "Federated Learning via Active RIS Assisted Over-the-Air Computation",
            "updated": "2023-11-07T13:34:58Z",
            "published": "2023-11-07T13:34:58Z",
            "summary": "In this paper, we propose leveraging the active reconfigurable intelligence\nsurface (RIS) to support reliable gradient aggregation for over-the-air\ncomputation (AirComp) enabled federated learning (FL) systems. An analysis of\nthe FL convergence property reveals that minimizing gradient aggregation errors\nin each training round is crucial for narrowing the convergence gap. As such,\nwe formulate an optimization problem, aiming to minimize these errors by\njointly optimizing the transceiver design and RIS configuration. To handle the\nformulated highly non-convex problem, we devise a two-layer alternative\noptimization framework to decompose it into several convex subproblems, each\nsolvable optimally. Simulation results demonstrate the superiority of the\nactive RIS in reducing gradient aggregation errors compared to its passive\ncounterpart.",
            "author": [
                "Deyou Zhang",
                "Ming Xiao",
                "Mikael Skoglund",
                "H. Vincent Poor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03982v1",
                "http://arxiv.org/pdf/2311.03982v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03976v1",
            "title": "Its All Graph To Me: Foundational Topology Models with Contrastive\n  Learning on Multiple Domains",
            "updated": "2023-11-07T13:24:01Z",
            "published": "2023-11-07T13:24:01Z",
            "summary": "Representations and embeddings of graph data have been essential in many\ndomains of research.\n  The principle benefit of learning such representations is that the\npre-trained model can be fine-tuned on smaller datasets where data or labels\nare scarse.\n  Existing models, however, are domain specific; for example a model trained on\nmolecular graphs is fine-tuned on other molecular graphs.\n  This means that in many application cases the choice of pre-trained model can\nbe arbitrary, and novel domains may lack an appropriate pre-trained model.\n  This is of particular issue where data is scarse, precluding traditional\nsupervised methods.\n  In this work we use adversarial contrastive learning to present a \\method, a\nmodel pre-trained on many graph domains.\n  We train the model only on topologies but include node labels in evaluation.\n  We evaluate the efficacy of its learnt representations on various downstream\ntasks.\n  Against baseline models pre-trained on single domains, as well as un-trained\nmodels and non-transferred models, we show that performance is equal or better\nusing our single model.\n  This includes when node labels are used in evaluation, where performance is\nconsistently superior to single-domain or non-pre-trained models.",
            "author": [
                "Alex O. Davies",
                "Riku W. Green",
                "Nirav S. Ajmeri",
                "Telmo M. Silva Filho"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03976v1",
                "http://arxiv.org/pdf/2311.03976v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03975v1",
            "title": "Adaptive 3D Geometry-based Stochastic Channel Prediction for 3D DL\n  Selection",
            "updated": "2023-11-07T13:20:45Z",
            "published": "2023-11-07T13:20:45Z",
            "summary": "This paper addresses the challenges of mobile user requirements in shadowing\nand multi-fading environments, focusing on the Downlink (DL) radio node\nselection based on Uplink (UL) channel estimation. One of the key issues\ntackled in this research is the prediction performance in scenarios where\nestimated channels are integrated. An adaptive deep learning approach is\nproposed to improve performance, offering a compelling alternative to\ntraditional interpolation techniques for air-to-ground link selection on\ndemand. Moreover, our study considers a 3D channel model, which provides a more\nrealistic and accurate representation than 2D models, particularly in the\ncontext of 3D network node distributions. This consideration becomes crucial in\naddressing the complex multipath fading effects within geometric stochastic 3D\n3GPP channel models in urban environments. Furthermore, our research emphasises\nthe need for adaptive prediction mechanisms that carefully balance the\ntrade-off between DL link forecasted frequency response accuracy and the\ncomplexity requirements associated with estimation and prediction. This paper\ncontributes to advancing 3D radio resource management by addressing these\nchallenges, enabling more efficient and reliable communication for\nenergy-constrained flying network nodes in dynamic environments.",
            "author": [
                "Mervat Zarour",
                "Qiuheng Zhou",
                "Sergiy Melnyk",
                "Hans D. Schotten"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03975v1",
                "http://arxiv.org/pdf/2311.03975v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16148v1",
            "title": "Univariate Radial Basis Function Layers: Brain-inspired Deep Neural\n  Layers for Low-Dimensional Inputs",
            "updated": "2023-11-07T13:14:49Z",
            "published": "2023-11-07T13:14:49Z",
            "summary": "Deep Neural Networks (DNNs) became the standard tool for function\napproximation with most of the introduced architectures being developed for\nhigh-dimensional input data. However, many real-world problems have\nlow-dimensional inputs for which standard Multi-Layer Perceptrons (MLPs) are\nthe default choice. An investigation into specialized architectures is missing.\nWe propose a novel DNN layer called Univariate Radial Basis Function (U-RBF)\nlayer as an alternative. Similar to sensory neurons in the brain, the U-RBF\nlayer processes each individual input dimension with a population of neurons\nwhose activations depend on different preferred input values. We verify its\neffectiveness compared to MLPs in low-dimensional function regressions and\nreinforcement learning tasks. The results show that the U-RBF is especially\nadvantageous when the target function becomes complex and difficult to\napproximate.",
            "author": [
                "Basavasagar Patil",
                "Xavier Alameda-Pineda",
                "Chris Reinke"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16148v1",
                "http://arxiv.org/pdf/2311.16148v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03967v1",
            "title": "CeCNN: Copula-enhanced convolutional neural networks in joint prediction\n  of refraction error and axial length based on ultra-widefield fundus images",
            "updated": "2023-11-07T13:06:50Z",
            "published": "2023-11-07T13:06:50Z",
            "summary": "Ultra-widefield (UWF) fundus images are replacing traditional fundus images\nin screening, detection, prediction, and treatment of complications related to\nmyopia because their much broader visual range is advantageous for highly\nmyopic eyes. Spherical equivalent (SE) is extensively used as the main myopia\noutcome measure, and axial length (AL) has drawn increasing interest as an\nimportant ocular component for assessing myopia. Cutting-edge studies show that\nSE and AL are strongly correlated. Using the joint information from SE and AL\nis potentially better than using either separately. In the deep learning\ncommunity, though there is research on multiple-response tasks with a 3D image\nbiomarker, dependence among responses is only sporadically taken into\nconsideration. Inspired by the spirit that information extracted from the data\nby statistical methods can improve the prediction accuracy of deep learning\nmodels, we formulate a class of multivariate response regression models with a\nhigher-order tensor biomarker, for the bivariate tasks of\nregression-classification and regression-regression. Specifically, we propose a\ncopula-enhanced convolutional neural network (CeCNN) framework that\nincorporates the dependence between responses through a Gaussian copula (with\nparameters estimated from a warm-up CNN) and uses the induced copula-likelihood\nloss with the backbone CNNs. We establish the statistical framework and\nalgorithms for the aforementioned two bivariate tasks. We show that the CeCNN\nhas better prediction accuracy after adding the dependency information to the\nbackbone models. The modeling and the proposed CeCNN algorithm are applicable\nbeyond the UWF scenario and can be effective with other backbones beyond ResNet\nand LeNet.",
            "author": [
                "Chong Zhong",
                "Yang Li",
                "Danjuan Yang",
                "Meiyan Li",
                "Xingyao Zhou",
                "Bo Fu",
                "Catherine C. Liu",
                "A. H. Welsh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03967v1",
                "http://arxiv.org/pdf/2311.03967v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03963v1",
            "title": "An Expectation-Realization Model for Metaphor Detection",
            "updated": "2023-11-07T13:03:54Z",
            "published": "2023-11-07T13:03:54Z",
            "summary": "We propose a metaphor detection architecture that is structured around two\nmain modules: an expectation component that estimates representations of\nliteral word expectations given a context, and a realization component that\ncomputes representations of actual word meanings in context. The overall\narchitecture is trained to learn expectation-realization (ER) patterns that\ncharacterize metaphorical uses of words. When evaluated on three metaphor\ndatasets for within distribution, out of distribution, and novel metaphor\ngeneralization, the proposed method is shown to obtain results that are\ncompetitive or better than state-of-the art. Further increases in metaphor\ndetection accuracy are obtained through ensembling of ER models.",
            "author": [
                "Oseremen O. Uduehi",
                "Razvan C. Bunescu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03963v1",
                "http://arxiv.org/pdf/2311.03963v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03956v1",
            "title": "Cup Curriculum: Curriculum Learning on Model Capacity",
            "updated": "2023-11-07T12:55:31Z",
            "published": "2023-11-07T12:55:31Z",
            "summary": "Curriculum learning (CL) aims to increase the performance of a learner on a\ngiven task by applying a specialized learning strategy. This strategy focuses\non either the dataset, the task, or the model. There is little to no work\nanalysing the possibilities to apply CL on the model capacity in natural\nlanguage processing. To close this gap, we propose the cup curriculum. In a\nfirst phase of training we use a variation of iterative magnitude pruning to\nreduce model capacity. These weights are reintroduced in a second phase,\nresulting in the model capacity to show a cup-shaped curve over the training\niterations. We empirically evaluate different strategies of the cup curriculum\nand show that it outperforms early stopping reliably while exhibiting a high\nresilience to overfitting.",
            "author": [
                "Luca Scharr",
                "Vanessa Toborek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03956v1",
                "http://arxiv.org/pdf/2311.03956v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03955v1",
            "title": "Elastic Information Bottleneck",
            "updated": "2023-11-07T12:53:55Z",
            "published": "2023-11-07T12:53:55Z",
            "summary": "Information bottleneck is an information-theoretic principle of\nrepresentation learning that aims to learn a maximally compressed\nrepresentation that preserves as much information about labels as possible.\nUnder this principle, two different methods have been proposed, i.e.,\ninformation bottleneck (IB) and deterministic information bottleneck (DIB), and\nhave gained significant progress in explaining the representation mechanisms of\ndeep learning algorithms. However, these theoretical and empirical successes\nare only valid with the assumption that training and test data are drawn from\nthe same distribution, which is clearly not satisfied in many real-world\napplications. In this paper, we study their generalization abilities within a\ntransfer learning scenario, where the target error could be decomposed into\nthree components, i.e., source empirical error, source generalization gap (SG),\nand representation discrepancy (RD). Comparing IB and DIB on these terms, we\nprove that DIB's SG bound is tighter than IB's while DIB's RD is larger than\nIB's. Therefore, it is difficult to tell which one is better. To balance the\ntrade-off between SG and the RD, we propose an elastic information bottleneck\n(EIB) to interpolate between the IB and DIB regularizers, which guarantees a\nPareto frontier within the IB framework. Additionally, simulations and real\ndata experiments show that EIB has the ability to achieve better domain\nadaptation results than IB and DIB, which validates the correctness of our\ntheories.",
            "author": [
                "Yuyan Ni",
                "Yanyan Lan",
                "Ao Liu",
                "Zhiming Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03955v1",
                "http://arxiv.org/pdf/2311.03955v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.AI",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03943v2",
            "title": "CLIP Guided Image-perceptive Prompt Learning for Image Enhancement",
            "updated": "2023-11-22T07:52:06Z",
            "published": "2023-11-07T12:36:20Z",
            "summary": "Image enhancement is a significant research area in the fields of computer\nvision and image processing. In recent years, many learning-based methods for\nimage enhancement have been developed, where the Look-up-table (LUT) has proven\nto be an effective tool. In this paper, we delve into the potential of\nContrastive Language-Image Pre-Training (CLIP) Guided Prompt Learning,\nproposing a simple structure called CLIP-LUT for image enhancement. We found\nthat the prior knowledge of CLIP can effectively discern the quality of\ndegraded images, which can provide reliable guidance. To be specific, We\ninitially learn image-perceptive prompts to distinguish between original and\ntarget images using CLIP model, in the meanwhile, we introduce a very simple\nnetwork by incorporating a simple baseline to predict the weights of three\ndifferent LUT as enhancement network. The obtained prompts are used to steer\nthe enhancement network like a loss function and improve the performance of\nmodel. We demonstrate that by simply combining a straightforward method with\nCLIP, we can obtain satisfactory results.",
            "author": [
                "Weiwen Chen",
                "Qiuhong Ke",
                "Zinuo Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03943v2",
                "http://arxiv.org/pdf/2311.03943v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03942v1",
            "title": "The Music Meta Ontology: a flexible semantic model for the\n  interoperability of music metadata",
            "updated": "2023-11-07T12:35:15Z",
            "published": "2023-11-07T12:35:15Z",
            "summary": "The semantic description of music metadata is a key requirement for the\ncreation of music datasets that can be aligned, integrated, and accessed for\ninformation retrieval and knowledge discovery. It is nonetheless an open\nchallenge due to the complexity of musical concepts arising from different\ngenres, styles, and periods -- standing to benefit from a lingua franca to\naccommodate various stakeholders (musicologists, librarians, data engineers,\netc.). To initiate this transition, we introduce the Music Meta ontology, a\nrich and flexible semantic model to describe music metadata related to artists,\ncompositions, performances, recordings, and links. We follow eXtreme Design\nmethodologies and best practices for data engineering, to reflect the\nperspectives and the requirements of various stakeholders into the design of\nthe model, while leveraging ontology design patterns and accounting for\nprovenance at different levels (claims, links). After presenting the main\nfeatures of Music Meta, we provide a first evaluation of the model, alignments\nto other schema (Music Ontology, DOREMUS, Wikidata), and support for data\ntransformation.",
            "author": [
                "Jacopo de Berardinis",
                "Valentina Anita Carriero",
                "Albert Mero\u00f1o-Pe\u00f1uela",
                "Andrea Poltronieri",
                "Valentina Presutti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03942v1",
                "http://arxiv.org/pdf/2311.03942v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.MM",
                "68T30"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04254v2",
            "title": "Everything of Thoughts: Defying the Law of Penrose Triangle for Thought\n  Generation",
            "updated": "2023-11-12T15:09:52Z",
            "published": "2023-11-07T12:30:36Z",
            "summary": "Recent advancements in Large Language Models (LLMs) have revolutionized\ndecision-making by breaking down complex problems into more manageable language\nsequences referred to as ``thoughts''. An effective thought design should\nconsider three key perspectives: performance, efficiency, and flexibility.\nHowever, existing thought can at most exhibit two of these attributes. To\naddress these limitations, we introduce a novel thought prompting approach\ncalled ``Everything of Thoughts'' (XoT) to defy the law of ``Penrose triangle\nof existing thought paradigms. XoT leverages pretrained reinforcement learning\nand Monte Carlo Tree Search (MCTS) to incorporate external domain knowledge\ninto thoughts, thereby enhancing LLMs' capabilities and enabling them to\ngeneralize to unseen problems efficiently. Through the utilization of the\nMCTS-LLM collaborative thought revision framework, this approach autonomously\nproduces high-quality comprehensive cognitive mappings with minimal LLM\ninteractions. Additionally, XoT empowers LLMs to engage in unconstrained\nthinking, allowing for flexible cognitive mappings for problems with multiple\nsolutions. We evaluate XoT on several challenging multi-solution\nproblem-solving tasks, including Game of 24, 8-Puzzle, and Pocket Cube. Our\nresults demonstrate that XoT significantly outperforms existing approaches.\nNotably, XoT can yield multiple solutions with just one LLM call, showcasing\nits remarkable proficiency in addressing complex problems across diverse\ndomains.",
            "author": [
                "Ruomeng Ding",
                "Chaoyun Zhang",
                "Lu Wang",
                "Yong Xu",
                "Minghua Ma",
                "Wei Zhang",
                "Si Qin",
                "Saravan Rajmohan",
                "Qingwei Lin",
                "Dongmei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04254v2",
                "http://arxiv.org/pdf/2311.04254v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03938v1",
            "title": "Analysis of NaN Divergence in Training Monocular Depth Estimation Model",
            "updated": "2023-11-07T12:19:30Z",
            "published": "2023-11-07T12:19:30Z",
            "summary": "The latest advances in deep learning have facilitated the development of\nhighly accurate monocular depth estimation models. However, when training a\nmonocular depth estimation network, practitioners and researchers have observed\nnot a number (NaN) loss, which disrupts gradient descent optimization. Although\nseveral practitioners have reported the stochastic and mysterious occurrence of\nNaN loss that bothers training, its root cause is not discussed in the\nliterature. This study conducted an in-depth analysis of NaN loss during\ntraining a monocular depth estimation network and identified three types of\nvulnerabilities that cause NaN loss: 1) the use of square root loss, which\nleads to an unstable gradient; 2) the log-sigmoid function, which exhibits\nnumerical stability issues; and 3) certain variance implementations, which\nyield incorrect computations. Furthermore, for each vulnerability, the\noccurrence of NaN loss was demonstrated and practical guidelines to prevent NaN\nloss were presented. Experiments showed that both optimization stability and\nperformance on monocular depth estimation could be improved by following our\nguidelines.",
            "author": [
                "Bum Jun Kim",
                "Hyeonah Jang",
                "Sang Woo Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03938v1",
                "http://arxiv.org/pdf/2311.03938v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04253v1",
            "title": "Blind Federated Learning via Over-the-Air q-QAM",
            "updated": "2023-11-07T12:02:59Z",
            "published": "2023-11-07T12:02:59Z",
            "summary": "In this work, we investigate federated edge learning over a fading multiple\naccess channel. To alleviate the communication burden between the edge devices\nand the access point, we introduce a pioneering digital over-the-air\ncomputation strategy employing q-ary quadrature amplitude modulation,\nculminating in a low latency communication scheme. Indeed, we propose a new\nfederated edge learning framework in which edge devices use digital modulation\nfor over-the-air uplink transmission to the edge server while they have no\naccess to the channel state information. Furthermore, we incorporate multiple\nantennas at the edge server to overcome the fading inherent in wireless\ncommunication. We analyze the number of antennas required to mitigate the\nfading impact effectively. We prove a non-asymptotic upper bound for the mean\nsquared error for the proposed federated learning with digital over-the-air\nuplink transmissions under both noisy and fading conditions. Leveraging the\nderived upper bound, we characterize the convergence rate of the learning\nprocess of a non-convex loss function in terms of the mean square error of\ngradients due to the fading channel. Furthermore, we substantiate the\ntheoretical assurances through numerical experiments concerning mean square\nerror and the convergence efficacy of the digital federated edge learning\nframework. Notably, the results demonstrate that augmenting the number of\nantennas at the edge server and adopting higher-order modulations improve the\nmodel accuracy up to 60\\%.",
            "author": [
                "Saeed Razavikia",
                "Jos\u00e9 Mairton Barros Da Silva J\u00fanior",
                "Carlo Fischione"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04253v1",
                "http://arxiv.org/pdf/2311.04253v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03920v1",
            "title": "An Intelligent Edge-Deployable Indoor Air Quality Monitoring and\n  Activity Recognition Approach",
            "updated": "2023-11-07T11:58:11Z",
            "published": "2023-11-07T11:58:11Z",
            "summary": "The surveillance of indoor air quality is paramount for ensuring\nenvironmental safety, a task made increasingly viable due to advancements in\ntechnology and the application of artificial intelligence and deep learning\n(DL) tools. This paper introduces an intelligent system dedicated to monitoring\nair quality and categorizing activities within indoor environments using a DL\napproach based on 1D Convolutional Neural Networks (1D-CNNs). Our system\nintegrates six diverse sensors to gather measurement parameters, which\nsubsequently train a 1D CNN model for activity recognition. This proposed model\nboasts a lightweight and edge-deployable design, rendering it ideal for\nreal-time applications. We conducted our experiments utilizing an air quality\ndataset specifically designed for Activity of Daily Living (ADL)\nclassification. The results illustrate the proposed model's efficacy, achieving\na remarkable accuracy of 97.00%, a minimal loss value of 0.15%, and a swift\nprediction time of 41 milliseconds.",
            "author": [
                "Mohamed Rafik Aymene Berkani",
                "Ammar Chouchane",
                "Yassine Himeur",
                "Abdelmalik Ouamane",
                "Abbes Amira"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03920v1",
                "http://arxiv.org/pdf/2311.03920v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04252v2",
            "title": "CNN-Based Structural Damage Detection using Time-Series Sensor Data",
            "updated": "2023-11-09T04:06:08Z",
            "published": "2023-11-07T11:57:33Z",
            "summary": "Structural Health Monitoring (SHM) is vital for evaluating structural\ncondition, aiming to detect damage through sensor data analysis. It aligns with\npredictive maintenance in modern industry, minimizing downtime and costs by\naddressing potential structural issues. Various machine learning techniques\nhave been used to extract valuable information from vibration data, often\nrelying on prior structural knowledge. This research introduces an innovative\napproach to structural damage detection, utilizing a new Convolutional Neural\nNetwork (CNN) algorithm. In order to extract deep spatial features from time\nseries data, CNNs are taught to recognize long-term temporal connections. This\nmethodology combines spatial and temporal features, enhancing discrimination\ncapabilities when compared to methods solely reliant on deep spatial features.\nTime series data are divided into two categories using the proposed neural\nnetwork: undamaged and damaged. To validate its efficacy, the method's accuracy\nwas tested using a benchmark dataset derived from a three-floor structure at\nLos Alamos National Laboratory (LANL). The outcomes show that the new CNN\nalgorithm is very accurate in spotting structural degradation in the examined\nstructure.",
            "author": [
                "Ishan Pathak",
                "Ishan Jha",
                "Aditya Sadana",
                "Basuraj Bhowmik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04252v2",
                "http://arxiv.org/pdf/2311.04252v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03912v1",
            "title": "FLORA: Fine-grained Low-Rank Architecture Search for Vision Transformer",
            "updated": "2023-11-07T11:51:33Z",
            "published": "2023-11-07T11:51:33Z",
            "summary": "Vision Transformers (ViT) have recently demonstrated success across a myriad\nof computer vision tasks. However, their elevated computational demands pose\nsignificant challenges for real-world deployment. While low-rank approximation\nstands out as a renowned method to reduce computational loads, efficiently\nautomating the target rank selection in ViT remains a challenge. Drawing from\nthe notable similarity and alignment between the processes of rank selection\nand One-Shot NAS, we introduce FLORA, an end-to-end automatic framework based\non NAS. To overcome the design challenge of supernet posed by vast search\nspace, FLORA employs a low-rank aware candidate filtering strategy. This method\nadeptly identifies and eliminates underperforming candidates, effectively\nalleviating potential undertraining and interference among subnetworks. To\nfurther enhance the quality of low-rank supernets, we design a low-rank\nspecific training paradigm. First, we propose weight inheritance to construct\nsupernet and enable gradient sharing among low-rank modules. Secondly, we adopt\nlow-rank aware sampling to strategically allocate training resources, taking\ninto account inherited information from pre-trained models. Empirical results\nunderscore FLORA's efficacy. With our method, a more fine-grained rank\nconfiguration can be generated automatically and yield up to 33% extra FLOPs\nreduction compared to a simple uniform configuration. More specific,\nFLORA-DeiT-B/FLORA-Swin-B can save up to 55%/42% FLOPs almost without\nperformance degradtion. Importantly, FLORA boasts both versatility and\northogonality, offering an extra 21%-26% FLOPs reduction when integrated with\nleading compression techniques or compact hybrid structures. Our code is\npublicly available at https://github.com/shadowpa0327/FLORA.",
            "author": [
                "Chi-Chih Chang",
                "Yuan-Yao Sung",
                "Shixing Yu",
                "Ning-Chi Huang",
                "Diana Marculescu",
                "Kai-Chiang Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03912v1",
                "http://arxiv.org/pdf/2311.03912v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03910v1",
            "title": "Structure of universal formulas",
            "updated": "2023-11-07T11:50:25Z",
            "published": "2023-11-07T11:50:25Z",
            "summary": "By universal formulas we understand parameterized analytic expressions that\nhave a fixed complexity, but nevertheless can approximate any continuous\nfunction on a compact set. There exist various examples of such formulas,\nincluding some in the form of neural networks. In this paper we analyze the\nessential structural elements of these highly expressive models. We introduce a\nhierarchy of expressiveness classes connecting the global approximability\nproperty to the weaker property of infinite VC dimension, and prove a series of\nclassification results for several increasingly complex functional families. In\nparticular, we introduce a general family of\npolynomially-exponentially-algebraic functions that, as we prove, is subject to\npolynomial constraints. As a consequence, we show that fixed-size neural\nnetworks with not more than one layer of neurons having transcendental\nactivations (e.g., sine or standard sigmoid) cannot in general approximate\nfunctions on arbitrary finite sets. On the other hand, we give examples of\nfunctional families, including two-hidden-layer neural networks, that\napproximate functions on arbitrary finite sets, but fail to do that on the\nwhole domain of definition.",
            "author": [
                "Dmitry Yarotsky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03910v1",
                "http://arxiv.org/pdf/2311.03910v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS",
                "cs.NE",
                "math.CA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03904v1",
            "title": "RobustMat: Neural Diffusion for Street Landmark Patch Matching under\n  Challenging Environments",
            "updated": "2023-11-07T11:37:20Z",
            "published": "2023-11-07T11:37:20Z",
            "summary": "For autonomous vehicles (AVs), visual perception techniques based on sensors\nlike cameras play crucial roles in information acquisition and processing. In\nvarious computer perception tasks for AVs, it may be helpful to match landmark\npatches taken by an onboard camera with other landmark patches captured at a\ndifferent time or saved in a street scene image database. To perform matching\nunder challenging driving environments caused by changing seasons, weather, and\nillumination, we utilize the spatial neighborhood information of each patch. We\npropose an approach, named RobustMat, which derives its robustness to\nperturbations from neural differential equations. A convolutional neural ODE\ndiffusion module is used to learn the feature representation for the landmark\npatches. A graph neural PDE diffusion module then aggregates information from\nneighboring landmark patches in the street scene. Finally, feature similarity\nlearning outputs the final matching score. Our approach is evaluated on several\nstreet scene datasets and demonstrated to achieve state-of-the-art matching\nresults under environmental perturbations.",
            "author": [
                "Rui She",
                "Qiyu Kang",
                "Sijie Wang",
                "Yuan-Rui Yang",
                "Kai Zhao",
                "Yang Song",
                "Wee Peng Tay"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03904v1",
                "http://arxiv.org/pdf/2311.03904v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04251v1",
            "title": "MixtureGrowth: Growing Neural Networks by Recombining Learned Parameters",
            "updated": "2023-11-07T11:37:08Z",
            "published": "2023-11-07T11:37:08Z",
            "summary": "Most deep neural networks are trained under fixed network architectures and\nrequire retraining when the architecture changes. If expanding the network's\nsize is needed, it is necessary to retrain from scratch, which is expensive. To\navoid this, one can grow from a small network by adding random weights over\ntime to gradually achieve the target network size. However, this naive approach\nfalls short in practice as it brings too much noise to the growing process.\nPrior work tackled this issue by leveraging the already learned weights and\ntraining data for generating new weights through conducting a computationally\nexpensive analysis step. In this paper, we introduce MixtureGrowth, a new\napproach to growing networks that circumvents the initialization overhead in\nprior work. Before growing, each layer in our model is generated with a linear\ncombination of parameter templates. Newly grown layer weights are generated by\nusing a new linear combination of existing templates for a layer. On one hand,\nthese templates are already trained for the task, providing a strong\ninitialization. On the other, the new coefficients provide flexibility for the\nadded layer weights to learn something new. We show that our approach boosts\ntop-1 accuracy over the state-of-the-art by 2-2.5% on CIFAR-100 and ImageNet\ndatasets, while achieving comparable performance with fewer FLOPs to a larger\nnetwork trained from scratch. Code is available at\nhttps://github.com/chaudatascience/mixturegrowth.",
            "author": [
                "Chau Pham",
                "Piotr Teterwak",
                "Soren Nelson",
                "Bryan A. Plummer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04251v1",
                "http://arxiv.org/pdf/2311.04251v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03900v1",
            "title": "Why Fair Automated Hiring Systems Breach EU Non-Discrimination Law",
            "updated": "2023-11-07T11:31:00Z",
            "published": "2023-11-07T11:31:00Z",
            "summary": "Employment selection processes that use automated hiring systems based on\nmachine learning are becoming increasingly commonplace. Meanwhile, concerns\nabout algorithmic direct and indirect discrimination that result from such\nsystems are front-and-center, and the technical solutions provided by the\nresearch community often systematically deviate from the principle of equal\ntreatment to combat disparate or adverse impacts on groups based on protected\nattributes. Those technical solutions are now being used in commercially\navailable automated hiring systems, potentially engaging in real-world\ndiscrimination. Algorithmic fairness and algorithmic non-discrimination are not\nthe same. This article examines a conflict between the two: whether such hiring\nsystems are compliant with EU non-discrimination law.",
            "author": [
                "Robert Lee Poe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03900v1",
                "http://arxiv.org/pdf/2311.03900v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.17282v1",
            "title": "Reducing energy consumption of cloud data centers using proper placement\n  of virtual machines",
            "updated": "2023-11-07T11:30:44Z",
            "published": "2023-11-07T11:30:44Z",
            "summary": "In today's world, the use of cloud data centers for easy access to data and\nprocessing resources is expanding rapidly. Rapid technology growth and\nincreasing number of users make hardware and software architectures upgrade a\nconstant need. The necessary infrastructure to implement this architecture is\nthe use of virtual machines in physical systems. The main issue in this\narchitecture is how to allocate virtual machines to physical machines on the\nnetwork. In this paper we have proposed a method to use virtualization for\nminimizing energy consumption and decreasing the cloud resource waste. We have\nused learning automata as a reinforcement learning model for optimal placement\nof virtual machines. The simulation results show the proposed method has good\nperformance in reducing energy consumption of servers in cloud data centers.",
            "author": [
                "Hamid Reza Naji",
                "Reza Esmaeili"
            ],
            "link": [
                "http://arxiv.org/abs/2311.17282v1",
                "http://arxiv.org/pdf/2311.17282v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03899v1",
            "title": "Learning-Based Latency-Constrained Fronthaul Compression Optimization in\n  C-RAN",
            "updated": "2023-11-07T11:26:26Z",
            "published": "2023-11-07T11:26:26Z",
            "summary": "The evolution of wireless mobile networks towards cloudification, where Radio\nAccess Network (RAN) functions can be hosted at either a central or distributed\nlocations, offers many benefits like low cost deployment, higher capacity, and\nimproved hardware utilization. Nevertheless, the flexibility in the functional\ndeployment comes at the cost of stringent fronthaul (FH) capacity and latency\nrequirements. One possible approach to deal with these rigorous constraints is\nto use FH compression techniques. To ensure that FH capacity and latency\nrequirements are met, more FH compression is applied during high load, while\nless compression is applied during medium and low load to improve FH\nutilization and air interface performance. In this paper, a model-free deep\nreinforcement learning (DRL) based FH compression (DRL-FC) framework is\nproposed that dynamically controls FH compression through various configuration\nparameters such as modulation order, precoder granularity, and precoder weight\nquantization that affect both FH load and air interface performance. Simulation\nresults show that DRL-FC exhibits significantly higher FH utilization (68.7% on\naverage) and air interface throughput than a reference scheme (i.e. with no\napplied compression) across different FH load levels. At the same time, the\nproposed DRL-FC framework is able to meet the predefined FH latency constraints\n(in our case set to 260 $\\mu$s) under various FH loads.",
            "author": [
                "Axel Gr\u00f6nland",
                "Bleron Klaiqi",
                "Xavier Gelabert"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03899v1",
                "http://arxiv.org/pdf/2311.03899v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03897v1",
            "title": "Temporal Graph Representation Learning with Adaptive Augmentation\n  Contrastive",
            "updated": "2023-11-07T11:21:16Z",
            "published": "2023-11-07T11:21:16Z",
            "summary": "Temporal graph representation learning aims to generate low-dimensional\ndynamic node embeddings to capture temporal information as well as structural\nand property information. Current representation learning methods for temporal\nnetworks often focus on capturing fine-grained information, which may lead to\nthe model capturing random noise instead of essential semantic information.\nWhile graph contrastive learning has shown promise in dealing with noise, it\nonly applies to static graphs or snapshots and may not be suitable for handling\ntime-dependent noise. To alleviate the above challenge, we propose a novel\nTemporal Graph representation learning with Adaptive augmentation Contrastive\n(TGAC) model. The adaptive augmentation on the temporal graph is made by\ncombining prior knowledge with temporal information, and the contrastive\nobjective function is constructed by defining the augmented inter-view contrast\nand intra-view contrast. To complement TGAC, we propose three adaptive\naugmentation strategies that modify topological features to reduce noise from\nthe network. Our extensive experiments on various real networks demonstrate\nthat the proposed model outperforms other temporal graph representation\nlearning methods.",
            "author": [
                "Hongjiang Chen",
                "Pengfei Jiao",
                "Huijun Tang",
                "Huaming Wu"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-43415-0_40",
                "http://arxiv.org/abs/2311.03897v1",
                "http://arxiv.org/pdf/2311.03897v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03896v1",
            "title": "iACOS: Advancing Implicit Sentiment Extraction with Informative and\n  Adaptive Negative Examples",
            "updated": "2023-11-07T11:19:06Z",
            "published": "2023-11-07T11:19:06Z",
            "summary": "Aspect-based sentiment analysis (ABSA) have been extensively studied, but\nlittle light has been shed on the quadruple extraction consisting of four\nfundamental elements: aspects, categories, opinions and sentiments, especially\nwith implicit aspects and opinions. In this paper, we propose a new method\niACOS for extracting Implicit Aspects with Categories and Opinions with\nSentiments. First, iACOS appends two implicit tokens at the end of a text to\ncapture the context-aware representation of all tokens including implicit\naspects and opinions. Second, iACOS develops a sequence labeling model over the\ncontext-aware token representation to co-extract explicit and implicit aspects\nand opinions. Third, iACOS devises a multi-label classifier with a specialized\nmulti-head attention for discovering aspect-opinion pairs and predicting their\ncategories and sentiments simultaneously. Fourth, iACOS leverages informative\nand adaptive negative examples to jointly train the multi-label classifier and\nthe other two classifiers on categories and sentiments by multi-task learning.\nFinally, the experimental results show that iACOS significantly outperforms\nother quadruple extraction baselines according to the F1 score on two public\nbenchmark datasets.",
            "author": [
                "Xiancai Xu",
                "Jia-Dong Zhang",
                "Lei Xiong",
                "Zhishang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03896v1",
                "http://arxiv.org/pdf/2311.03896v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04250v1",
            "title": "Unifying Structure and Language Semantic for Efficient Contrastive\n  Knowledge Graph Completion with Structured Entity Anchors",
            "updated": "2023-11-07T11:17:55Z",
            "published": "2023-11-07T11:17:55Z",
            "summary": "The goal of knowledge graph completion (KGC) is to predict missing links in a\nKG using trained facts that are already known. In recent, pre-trained language\nmodel (PLM) based methods that utilize both textual and structural information\nare emerging, but their performances lag behind state-of-the-art (SOTA)\nstructure-based methods or some methods lose their inductive inference\ncapabilities in the process of fusing structure embedding to text encoder. In\nthis paper, we propose a novel method to effectively unify structure\ninformation and language semantics without losing the power of inductive\nreasoning. We adopt entity anchors and these anchors and textual description of\nKG elements are fed together into the PLM-based encoder to learn unified\nrepresentations. In addition, the proposed method utilizes additional random\nnegative samples which can be reused in the each mini-batch during contrastive\nlearning to learn a generalized entity representations. We verify the\neffectiveness of the our proposed method through various experiments and\nanalysis. The experimental results on standard benchmark widely used in link\nprediction task show that the proposed model outperforms existing the SOTA KGC\nmodels. Especially, our method show the largest performance improvement on\nFB15K-237, which is competitive to the SOTA of structure-based KGC methods.",
            "author": [
                "Sang-Hyun Je",
                "Wontae Choi",
                "Kwangjin Oh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04250v1",
                "http://arxiv.org/pdf/2311.04250v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16147v1",
            "title": "Load balancing in cloud data centers with optimized virtual machines\n  placement",
            "updated": "2023-11-07T11:08:13Z",
            "published": "2023-11-07T11:08:13Z",
            "summary": "So far, various solutions have been proposed for symmetric distribution of\nload cloud computing environments. In this article, a new solution to the\noptimal allocation of virtual machines in the cloud data centers is presented\nto provide a good load balancing among servers. The proposed method offers a\nsolution uses learning automata as a reinforcement learning model to improve\nthe performance of the optimization algorithm for optimal placement of virtual\nmachines. Also, it helps the search algorithm to converge more quickly to the\nglobal optimum. The simulation results show the proposed method has been able\nto perform good level of load balancing in cloud data centers.",
            "author": [
                "Hamid Reza naji",
                "Reza Esmaeili"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16147v1",
                "http://arxiv.org/pdf/2311.16147v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03887v1",
            "title": "Toward ground-truth optical coherence tomography via three-dimensional\n  unsupervised deep learning processing and data",
            "updated": "2023-11-07T11:04:06Z",
            "published": "2023-11-07T11:04:06Z",
            "summary": "Optical coherence tomography (OCT) can perform non-invasive high-resolution\nthree-dimensional (3D) imaging and has been widely used in biomedical fields,\nwhile it is inevitably affected by coherence speckle noise which degrades OCT\nimaging performance and restricts its applications. Here we present a novel\nspeckle-free OCT imaging strategy, named toward-ground-truth OCT (tGT-OCT),\nthat utilizes unsupervised 3D deep-learning processing and leverages OCT 3D\nimaging features to achieve speckle-free OCT imaging. Specifically, our\nproposed tGT-OCT utilizes an unsupervised 3D-convolution deep-learning network\ntrained using random 3D volumetric data to distinguish and separate speckle\nfrom real structures in 3D imaging volumetric space; moreover, tGT-OCT\neffectively further reduces speckle noise and reveals structures that would\notherwise be obscured by speckle noise while preserving spatial resolution.\nResults derived from different samples demonstrated the high-quality\nspeckle-free 3D imaging performance of tGT-OCT and its advancement beyond the\nprevious state-of-the-art.",
            "author": [
                "Renxiong Wu",
                "Fei Zheng",
                "Meixuan Li",
                "Shaoyan Huang",
                "Xin Ge",
                "Linbo Liu",
                "Yong Liu",
                "Guangming Ni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03887v1",
                "http://arxiv.org/pdf/2311.03887v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "eess.IV",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03886v1",
            "title": "Formulating Discrete Probability Flow Through Optimal Transport",
            "updated": "2023-11-07T11:03:27Z",
            "published": "2023-11-07T11:03:27Z",
            "summary": "Continuous diffusion models are commonly acknowledged to display a\ndeterministic probability flow, whereas discrete diffusion models do not. In\nthis paper, we aim to establish the fundamental theory for the probability flow\nof discrete diffusion models. Specifically, we first prove that the continuous\nprobability flow is the Monge optimal transport map under certain conditions,\nand also present an equivalent evidence for discrete cases. In view of these\nfindings, we are then able to define the discrete probability flow in line with\nthe principles of optimal transport. Finally, drawing upon our newly\nestablished definitions, we propose a novel sampling method that surpasses\nprevious discrete diffusion models in its ability to generate more certain\noutcomes. Extensive experiments on the synthetic toy dataset and the CIFAR-10\ndataset have validated the effectiveness of our proposed discrete probability\nflow. Code is released at:\nhttps://github.com/PangzeCheung/Discrete-Probability-Flow.",
            "author": [
                "Pengze Zhang",
                "Hubery Yin",
                "Chen Li",
                "Xiaohua Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03886v1",
                "http://arxiv.org/pdf/2311.03886v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03884v1",
            "title": "MeVGAN: GAN-based Plugin Model for Video Generation with Applications in\n  Colonoscopy",
            "updated": "2023-11-07T10:58:16Z",
            "published": "2023-11-07T10:58:16Z",
            "summary": "Video generation is important, especially in medicine, as much data is given\nin this form. However, video generation of high-resolution data is a very\ndemanding task for generative models, due to the large need for memory. In this\npaper, we propose Memory Efficient Video GAN (MeVGAN) - a Generative\nAdversarial Network (GAN) which uses plugin-type architecture. We use a\npre-trained 2D-image GAN and only add a simple neural network to construct\nrespective trajectories in the noise space, so that the trajectory forwarded\nthrough the GAN model constructs a real-life video. We apply MeVGAN in the task\nof generating colonoscopy videos. Colonoscopy is an important medical\nprocedure, especially beneficial in screening and managing colorectal cancer.\nHowever, because colonoscopy is difficult and time-consuming to learn,\ncolonoscopy simulators are widely used in educating young colonoscopists. We\nshow that MeVGAN can produce good quality synthetic colonoscopy videos, which\ncan be potentially used in virtual simulators.",
            "author": [
                "\u0141ukasz Struski",
                "Tomasz Urba\u0144czyk",
                "Krzysztof Bucki",
                "Bart\u0142omiej Cupia\u0142",
                "Aneta Kaczy\u0144ska",
                "Przemys\u0142aw Spurek",
                "Jacek Tabor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03884v1",
                "http://arxiv.org/pdf/2311.03884v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03881v1",
            "title": "Sparse Contrastive Learning of Sentence Embeddings",
            "updated": "2023-11-07T10:54:45Z",
            "published": "2023-11-07T10:54:45Z",
            "summary": "Recently, SimCSE has shown the feasibility of contrastive learning in\ntraining sentence embeddings and illustrates its expressiveness in spanning an\naligned and uniform embedding space. However, prior studies have shown that\ndense models could contain harmful parameters that affect the model\nperformance, and it is no wonder that SimCSE can as well be invented with such\nparameters. Driven by this, parameter sparsification is applied, where\nalignment and uniformity scores are used to measure the contribution of each\nparameter to the overall quality of sentence embeddings. Drawing from a\npreliminary study, we consider parameters with minimal contributions to be\ndetrimental, as their sparsification results in improved model performance. To\ndiscuss the ubiquity of detrimental parameters and remove them, more\nexperiments on the standard semantic textual similarity (STS) tasks and\ntransfer learning tasks are conducted, and the results show that the proposed\nsparsified SimCSE (SparseCSE) has excellent performance in comparison with\nSimCSE. Furthermore, through in-depth analysis, we establish the validity and\nstability of our sparsification method, showcasing that the embedding space\ngenerated by SparseCSE exhibits improved alignment compared to that produced by\nSimCSE. Importantly, the uniformity yet remains uncompromised.",
            "author": [
                "Ruize An",
                "Chen Zhang",
                "Dawei Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03881v1",
                "http://arxiv.org/pdf/2311.03881v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03873v1",
            "title": "Mini but Mighty: Finetuning ViTs with Mini Adapters",
            "updated": "2023-11-07T10:41:27Z",
            "published": "2023-11-07T10:41:27Z",
            "summary": "Vision Transformers (ViTs) have become one of the dominant architectures in\ncomputer vision, and pre-trained ViT models are commonly adapted to new tasks\nvia fine-tuning. Recent works proposed several parameter-efficient transfer\nlearning methods, such as adapters, to avoid the prohibitive training and\nstorage cost of finetuning. In this work, we observe that adapters perform\npoorly when the dimension of adapters is small, and we propose MiMi, a training\nframework that addresses this issue. We start with large adapters which can\nreach high performance, and iteratively reduce their size. To enable automatic\nestimation of the hidden dimension of every adapter, we also introduce a new\nscoring function, specifically designed for adapters, that compares the neuron\nimportance across layers. Our method outperforms existing methods in finding\nthe best trade-off between accuracy and trained parameters across the three\ndataset benchmarks DomainNet, VTAB, and Multi-task, for a total of 29 datasets.",
            "author": [
                "Imad Eddine Marouf",
                "Enzo Tartaglione",
                "St\u00e9phane Lathuili\u00e8re"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03873v1",
                "http://arxiv.org/pdf/2311.03873v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03867v1",
            "title": "A Comparative Study of Knowledge Transfer Methods for Misaligned Urban\n  Building Labels",
            "updated": "2023-11-07T10:31:41Z",
            "published": "2023-11-07T10:31:41Z",
            "summary": "Misalignment in Earth observation (EO) images and building labels impact the\ntraining of accurate convolutional neural networks (CNNs) for semantic\nsegmentation of building footprints. Recently, three Teacher-Student knowledge\ntransfer methods have been introduced to address this issue: supervised domain\nadaptation (SDA), knowledge distillation (KD), and deep mutual learning (DML).\nHowever, these methods are merely studied for different urban buildings\n(low-rise, mid-rise, high-rise, and skyscrapers), where misalignment increases\nwith building height and spatial resolution. In this study, we present a\nworkflow for the systematic comparative study of the three methods. The\nworkflow first identifies the best (with the highest evaluation scores)\nhyperparameters, lightweight CNNs for the Student (among 43 CNNs from Computer\nVision), and encoder-decoder networks (EDNs) for both Teachers and Students.\nSecondly, three building footprint datasets are developed to train and evaluate\nthe identified Teachers and Students in the three transfer methods. The results\nshow that U-Net with VGG19 (U-VGG19) is the best Teacher, and\nU-EfficientNetv2B3 and U-EfficientNet-lite0 are among the best Students. With\nthese Teacher-Student pairs, SDA could yield upto 0.943, 0.868, 0.912, and\n0.697 F1 scores in the low-rise, mid-rise, high-rise, and skyscrapers\nrespectively. KD and DML provide model compression of upto 82%, despite\nmarginal loss in performance. This new comparison concludes that SDA is the\nmost effective method to address the misalignment problem, while KD and DML can\nefficiently compress network size without significant loss in performance. The\n158 experiments and datasets developed in this study will be valuable to\nminimise the misaligned labels.",
            "author": [
                "Bipul Neupane",
                "Jagannath Aryal",
                "Abbas Rajabifard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03867v1",
                "http://arxiv.org/pdf/2311.03867v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03866v1",
            "title": "SCONE-GAN: Semantic Contrastive learning-based Generative Adversarial\n  Network for an end-to-end image translation",
            "updated": "2023-11-07T10:29:16Z",
            "published": "2023-11-07T10:29:16Z",
            "summary": "SCONE-GAN presents an end-to-end image translation, which is shown to be\neffective for learning to generate realistic and diverse scenery images. Most\ncurrent image-to-image translation approaches are devised as two mappings: a\ntranslation from the source to target domain and another to represent its\ninverse. While successful in many applications, these approaches may suffer\nfrom generating trivial solutions with limited diversity. That is because these\nmethods learn more frequent associations rather than the scene structures. To\nmitigate the problem, we propose SCONE-GAN that utilises graph convolutional\nnetworks to learn the objects dependencies, maintain the image structure and\npreserve its semantics while transferring images into the target domain. For\nmore realistic and diverse image generation we introduce style reference image.\nWe enforce the model to maximize the mutual information between the style image\nand output. The proposed method explicitly maximizes the mutual information\nbetween the related patches, thus encouraging the generator to produce more\ndiverse images. We validate the proposed algorithm for image-to-image\ntranslation and stylizing outdoor images. Both qualitative and quantitative\nresults demonstrate the effectiveness of our approach on four dataset.",
            "author": [
                "Iman Abbasnejad",
                "Fabio Zambetta",
                "Flora Salim",
                "Timothy Wiley",
                "Jeffrey Chan",
                "Russell Gallagher",
                "Ehsan Abbasnejad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03866v1",
                "http://arxiv.org/pdf/2311.03866v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03865v1",
            "title": "FD-MIA: Efficient Attacks on Fairness-enhanced Models",
            "updated": "2023-11-07T10:28:17Z",
            "published": "2023-11-07T10:28:17Z",
            "summary": "Previous studies have developed fairness methods for biased models that\nexhibit discriminatory behaviors towards specific subgroups. While these models\nhave shown promise in achieving fair predictions, recent research has\nidentified their potential vulnerability to score-based membership inference\nattacks (MIAs). In these attacks, adversaries can infer whether a particular\ndata sample was used during training by analyzing the model's prediction\nscores. However, our investigations reveal that these score-based MIAs are\nineffective when targeting fairness-enhanced models in binary classifications.\nThe attack models trained to launch the MIAs degrade into simplistic threshold\nmodels, resulting in lower attack performance. Meanwhile, we observe that\nfairness methods often lead to prediction performance degradation for the\nmajority subgroups of the training data. This raises the barrier to successful\nattacks and widens the prediction gaps between member and non-member data.\nBuilding upon these insights, we propose an efficient MIA method against\nfairness-enhanced models based on fairness discrepancy results (FD-MIA). It\nleverages the difference in the predictions from both the original and\nfairness-enhanced models and exploits the observed prediction gaps as attack\nclues. We also explore potential strategies for mitigating privacy leakages.\nExtensive experiments validate our findings and demonstrate the efficacy of the\nproposed method.",
            "author": [
                "Huan Tian",
                "Guangsheng Zhang",
                "Bo Liu",
                "Tianqing Zhu",
                "Ming Ding",
                "Wanlei Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03865v1",
                "http://arxiv.org/pdf/2311.03865v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03863v1",
            "title": "An Explainable Framework for Machine learning-Based Reactive Power\n  Optimization of Distribution Network",
            "updated": "2023-11-07T10:24:03Z",
            "published": "2023-11-07T10:24:03Z",
            "summary": "To reduce the heavy computational burden of reactive power optimization of\ndistribution networks, machine learning models are receiving increasing\nattention. However, most machine learning models (e.g., neural networks) are\nusually considered as black boxes, making it challenging for power system\noperators to identify and comprehend potential biases or errors in the\ndecision-making process of machine learning models. To address this issue, an\nexplainable machine-learning framework is proposed to optimize the reactive\npower in distribution networks. Firstly, a Shapley additive explanation\nframework is presented to measure the contribution of each input feature to the\nsolution of reactive power optimizations generated from machine learning\nmodels. Secondly, a model-agnostic approximation method is developed to\nestimate Shapley values, so as to avoid the heavy computational burden\nassociated with direct calculations of Shapley values. The simulation results\nshow that the proposed explainable framework can accurately explain the\nsolution of the machine learning model-based reactive power optimization by\nusing visual analytics, from both global and instance perspectives. Moreover,\nthe proposed explainable framework is model-agnostic, and thus applicable to\nvarious models (e.g., neural networks).",
            "author": [
                "Wenlong Liao",
                "Benjamin Sch\u00e4fer",
                "Dalin Qin",
                "Gonghao Zhang",
                "Zhixian Wang",
                "Zhe Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03863v1",
                "http://arxiv.org/pdf/2311.03863v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03857v1",
            "title": "Hypergraphs with node attributes: structure and inference",
            "updated": "2023-11-07T10:16:20Z",
            "published": "2023-11-07T10:16:20Z",
            "summary": "Many networked datasets with units interacting in groups of two or more,\nencoded with hypergraphs, are accompanied by extra information about nodes,\nsuch as the role of an individual in a workplace. Here we show how these node\nattributes can be used to improve our understanding of the structure resulting\nfrom higher-order interactions. We consider the problem of community detection\nin hypergraphs and develop a principled model that combines higher-order\ninteractions and node attributes to better represent the observed interactions\nand to detect communities more accurately than using either of these types of\ninformation alone. The method learns automatically from the input data the\nextent to which structure and attributes contribute to explain the data, down\nweighing or discarding attributes if not informative. Our algorithmic\nimplementation is efficient and scales to large hypergraphs and interactions of\nlarge numbers of units. We apply our method to a variety of systems, showing\nstrong performance in hyperedge prediction tasks and in selecting community\ndivisions that correlate with attributes when these are informative, but\ndiscarding them otherwise. Our approach illustrates the advantage of using\ninformative node attributes when available with higher-order data.",
            "author": [
                "Anna Badalyan",
                "Nicol\u00f2 Ruggeri",
                "Caterina De Bacco"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03857v1",
                "http://arxiv.org/pdf/2311.03857v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "physics.data-an",
                "physics.soc-ph",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03855v1",
            "title": "Terrain Recognition and Contact Force Estimation through a Sensorized\n  Paw for Legged Robots",
            "updated": "2023-11-07T10:13:12Z",
            "published": "2023-11-07T10:13:12Z",
            "summary": "This paper introduces the Terrain Recognition And Contact Force Estimation\nPaw, a compact and sensorized shoe designed for legged robots. The paw\nend-effector is made of silicon that deforms upon the application of contact\nforces, while an embedded micro camera is utilized to capture images of the\ndeformed inner surface inside the shoe, and a microphone picks up audio\nsignals. Processed through machine learning techniques, the images are mapped\nto compute an accurate estimate of the cumulative 3D force vector, while the\naudio signals are analyzed to identify the terrain class (e.g., gravel, snow).\nBy leveraging its on-edge computation ability, the paw enhances the\ncapabilities of legged robots by providing key information in real-time that\ncan be used to adapt locomotion control strategies. To assess the performance\nof this novel sensorized paw, we conducted experiments on the data collected\nthrough a specially-designed testbed for force estimation, as well as data from\nrecordings of the audio signatures of different terrains interacting with the\npaw. The results demonstrate the accuracy and effectiveness of the system,\nhighlighting its potential for improving legged robot performance.",
            "author": [
                "Aleksander Vangen",
                "Tejal Barnwal",
                "J\u00f8rgen Anker Olsen",
                "Kostas Alexis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03855v1",
                "http://arxiv.org/pdf/2311.03855v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03853v1",
            "title": "On Deep Reinforcement Learning for Traffic Steering Intelligent ORAN",
            "updated": "2023-11-07T10:09:39Z",
            "published": "2023-11-07T10:09:39Z",
            "summary": "This paper aims to develop the intelligent traffic steering (TS) framework,\nwhich has recently been considered as one of the key developments of 3GPP for\nadvanced 5G. Since achieving key performance indicators (KPIs) for\nheterogeneous services may not be possible in the monolithic architecture, a\nnovel deep reinforcement learning (DRL)-based TS algorithm is proposed at the\nnon-real-time (non-RT) RAN intelligent controller (RIC) within the open radio\naccess network (ORAN) architecture. To enable ORAN's intelligence, we\ndistribute traffic load onto appropriate paths, which helps efficiently\nallocate resources to end users in a downlink multi-service scenario. Our\nproposed approach employs a three-step hierarchical process that involves\nheuristics, machine learning, and convex optimization to steer traffic flows.\nThrough system-level simulations, we show the superior performance of the\nproposed intelligent TS scheme, surpassing established benchmark systems by\n45.50%.",
            "author": [
                "Fatemeh Kavehmadavani",
                "Van-Dinh Nguyen",
                "Thang X. Vu",
                "Symeon Chatzinotas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03853v1",
                "http://arxiv.org/pdf/2311.03853v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03852v1",
            "title": "Improved MDL Estimators Using Fiber Bundle of Local Exponential Families\n  for Non-exponential Families",
            "updated": "2023-11-07T10:09:04Z",
            "published": "2023-11-07T10:09:04Z",
            "summary": "Minimum Description Length (MDL) estimators, using two-part codes for\nuniversal coding, are analyzed. For general parametric families under certain\nregularity conditions, we introduce a two-part code whose regret is close to\nthe minimax regret, where regret of a code with respect to a target family M is\nthe difference between the code length of the code and the ideal code length\nachieved by an element in M. This is a generalization of the result for\nexponential families by Gr\\\"unwald. Our code is constructed by using an\naugmented structure of M with a bundle of local exponential families for data\ndescription, which is not needed for exponential families. This result gives a\ntight upper bound on risk and loss of the MDL estimators based on the theory\nintroduced by Barron and Cover in 1991. Further, we show that we can apply the\nresult to mixture families, which are a typical example of non-exponential\nfamilies.",
            "author": [
                "Kohei Miyamoto",
                "Andrew R. Barron",
                "Jun'ichi Takeuchi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03852v1",
                "http://arxiv.org/pdf/2311.03852v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03850v1",
            "title": "Predictive Sampling for Efficient Pairwise Subjective Image Quality\n  Assessment",
            "updated": "2023-11-07T10:05:20Z",
            "published": "2023-11-07T10:05:20Z",
            "summary": "Subjective image quality assessment studies are used in many scenarios, such\nas the evaluation of compression, super-resolution, and denoising solutions.\nAmong the available subjective test methodologies, pair comparison is\nattracting popularity due to its simplicity, reliability, and robustness to\nchanges in the test conditions, e.g. display resolutions. The main problem that\nimpairs its wide acceptance is that the number of pairs to compare by subjects\ngrows quadratically with the number of stimuli that must be considered.\nUsually, the paired comparison data obtained is fed into an aggregation model\nto obtain a final score for each degraded image and thus, not every comparison\ncontributes equally to the final quality score. In the past years, several\nsolutions that sample pairs (from all possible combinations) have been\nproposed, from random sampling to active sampling based on the past subjects'\ndecisions. This paper introduces a novel sampling solution called\n\\textbf{P}redictive \\textbf{S}ampling for \\textbf{P}airwise \\textbf{C}omparison\n(PS-PC) which exploits the characteristics of the input data to make a\nprediction of which pairs should be evaluated by subjects. The proposed\nsolution exploits popular machine learning techniques to select the most\ninformative pairs for subjects to evaluate, while for the other remaining\npairs, it predicts the subjects' preferences. The experimental results show\nthat PS-PC is the best choice among the available sampling algorithms with\nhigher performance for the same number of pairs. Moreover, since the choice of\nthe pairs is done \\emph{a priori} before the subjective test starts, the\nalgorithm is not required to run during the test and thus much more simple to\ndeploy in online crowdsourcing subjective tests.",
            "author": [
                "Shima Mohammadi",
                "Jo\u00e3o Ascenso"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03850v1",
                "http://arxiv.org/pdf/2311.03850v1"
            ],
            "primary_category": "cs.MM",
            "category": [
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03842v1",
            "title": "Measurement of the neutrino-oxygen neutral-current quasielastic cross\n  section using atmospheric neutrinos in the SK-Gd experiment",
            "updated": "2023-11-07T09:45:00Z",
            "published": "2023-11-07T09:45:00Z",
            "summary": "We report the first measurement of the atmospheric neutrino-oxygen\nneutral-current quasielastic (NCQE) cross section in the gadolinium-loaded\nSuper-Kamiokande (SK) water Cherenkov detector. In June 2020, SK began a new\nexperimental phase, named SK-Gd, by loading 0.011% by mass of gadolinium into\nthe ultrapure water of the SK detector. The introduction of gadolinium to\nultrapure water has the effect of improving the neutron-tagging efficiency.\nUsing a 552.2 day data set from August 2020 to June 2022, we measure the NCQE\ncross section to be 0.74 $\\pm$ 0.22(stat.) $^{+0.85}_{-0.15}$ (syst.) $\\times$\n10$^{-38}$ cm$^{2}$/oxygen in the energy range from 160 MeV to 10 GeV, which is\nconsistent with the atmospheric neutrino-flux-averaged theoretical NCQE cross\nsection and the measurement in the SK pure-water phase within the\nuncertainties. Furthermore, we compare the models of the nucleon-nucleus\ninteractions in water and find that the Binary Cascade model and the Liege\nIntranuclear Cascade model provide a somewhat better fit to the observed data\nthan the Bertini Cascade model. Since the atmospheric neutrino-oxygen NCQE\nreactions are one of the main backgrounds in the search for diffuse supernova\nneutrino background (DSNB), these new results will contribute to future studies\n- and the potential discovery - of the DSNB in SK.",
            "author": [
                "S. Sakai",
                "K. Abe",
                "C. Bronner",
                "Y. Hayato",
                "K. Hiraide",
                "K. Hosokawa",
                "K. Ieki",
                "M. Ikeda",
                "J. Kameda",
                "Y. Kanemura",
                "R. Kaneshima",
                "Y. Kashiwagi",
                "Y. Kataoka",
                "S. Miki",
                "S. Mine",
                "M. Miura",
                "S. Moriyama",
                "Y. Nakano",
                "M. Nakahata",
                "S. Nakayama",
                "Y. Noguchi",
                "K. Sato",
                "H. Sekiya",
                "H. Shiba",
                "K. Shimizu",
                "M. Shiozawa",
                "Y. Sonoda",
                "Y. Suzuki",
                "A. Takeda",
                "Y. Takemoto",
                "H. Tanaka",
                "T. Yano",
                "S. Han",
                "T. Kajita",
                "K. Okumura",
                "T. Tashiro",
                "T. Tomiya",
                "X. Wang",
                "S. Yoshida",
                "P. Fernandez",
                "L. Labarga",
                "N. Ospina",
                "B. Zaldivar",
                "B. W. Pointon",
                "E. Kearns",
                "J. L. Raaf",
                "L. Wan",
                "T. Wester",
                "J. Bian",
                "N. J. Griskevich",
                "S. Locke",
                "M. B. Smy",
                "H. W. Sobel",
                "V. Takhistov",
                "A. Yankelevich",
                "J. Hill",
                "M. C. Jang",
                "S. H. Lee",
                "D. H. Moon",
                "R. G. Park",
                "B. Bodur",
                "K. Scholberg",
                "C. W. Walter",
                "A. Beauchene",
                "O. Drapier",
                "A. Giampaolo",
                "Th. A. Mueller",
                "A. D. Santos",
                "P. Paganini",
                "B. Quilain",
                "T. Nakamura",
                "J. S. Jang",
                "L. N. Machado",
                "J. G. Learned",
                "K. Choi",
                "N. Iovine",
                "S. Cao",
                "L. H. V. Anthony",
                "D. Martin",
                "N. W. Prouse",
                "M. Scott",
                "A. A. Sztuc",
                "Y. Uchida",
                "V. Berardi",
                "N. F. Calabria",
                "M. G. Catanesi",
                "E. Radicioni",
                "A. Langella",
                "G. De Rosa",
                "G. Collazuol",
                "F. Iacob",
                "M. Mattiazzi",
                "L. Ludovici",
                "M. Gonin",
                "G. Pronost",
                "C. Fujisawa",
                "Y. Maekawa",
                "Y. Nishimura",
                "R. Okazaki",
                "R. Akutsu",
                "M. Friend",
                "T. Hasegawa",
                "T. Ishida",
                "T. Kobayashi",
                "M. Jakkapu",
                "T. Matsubara",
                "T. Nakadaira",
                "K. Nakamura",
                "Y. Oyama",
                "K. Sakashita",
                "T. Sekiguchi",
                "T. Tsukamoto",
                "N. Bhuiyan",
                "G. T. Burton",
                "F. Di Lodovico",
                "J. Gao",
                "A. Goldsack",
                "T. Katori",
                "J. Migenda",
                "R. M. Ramsden",
                "Z. Xie",
                "S. Zsoldos",
                "A. T. Suzuki",
                "Y. Takagi",
                "H. Zhong",
                "Y. Takeuchi",
                "J. Feng",
                "L. Feng",
                "J. R. Hu",
                "Z. Hu",
                "M. Kawaue",
                "T. Kikawa",
                "M. Mori",
                "T. Nakaya",
                "R. A. Wendell",
                "K. Yasutome",
                "S. J. Jenkins",
                "N. McCauley",
                "P. Mehta",
                "A. Tarant",
                "Y. Fukuda",
                "Y. Itow",
                "H. Menjo",
                "K. Ninomiya",
                "Y. Yoshioka",
                "J. Lagoda",
                "S. M. Lakshmi",
                "M. Mandal",
                "P. Mijakowski",
                "Y. S. Prabhu",
                "J. Zalipska",
                "M. Jia",
                "J. Jiang",
                "C. K. Jung",
                "W. Shi",
                "M. J. Wilking",
                "C. Yanagisawa",
                "M. Harada",
                "Y. Hino",
                "H. Ishino",
                "Y. Koshio",
                "F. Nakanishi",
                "T. Tada",
                "T. Tano",
                "T. Ishizuka",
                "G. Barr",
                "D. Barrow",
                "L. Cook",
                "S. Samani",
                "D. Wark",
                "A. Holin",
                "F. Nova",
                "S. Jung",
                "B. S. Yang",
                "J. Y. Yang",
                "J. Yoo",
                "J. E. P. Fannon",
                "L. Kneale",
                "M. Malek",
                "J. M. McElwee",
                "M. D. Thiesse",
                "L. F. Thompson",
                "S. T. Wilson",
                "H. Okazawa",
                "S. B. Kim",
                "E. Kwon",
                "J. W. Seo",
                "I. Yu",
                "A. K. Ichikawa",
                "K. D. Nakamura",
                "S. Tairafune",
                "K. Nishijima",
                "A. Eguchi",
                "K. Nakagiri",
                "Y. Nakajima",
                "S. Shima",
                "N. Taniuchi",
                "E. Watanabe",
                "M. Yokoyama",
                "P. de Perio",
                "S. Fujita",
                "K. Martens",
                "K. M. Tsui",
                "M. R. Vagins",
                "J. Xia",
                "S. Izumiyama",
                "M. Kuze",
                "R. Matsumoto",
                "M. Ishitsuka",
                "H. Ito",
                "Y. Ommura",
                "N. Shigeta",
                "M. Shinoki",
                "K. Yamauchi",
                "T. Yoshida",
                "R. Gaur",
                "V. Gousy-Leblanc",
                "M. Hartz",
                "A. Konaka",
                "X. Li",
                "S. Chen",
                "B. D. Xu",
                "B. Zhang",
                "M. Posiadala-Zezula",
                "S. B. Boyd",
                "R. Edwards",
                "D. Hadley",
                "M. Nicholson",
                "M. O'Flaherty",
                "B. Richards",
                "A. Ali",
                "B. Jamieson",
                "S. Amanai",
                "Ll. Marti",
                "A. Minamino",
                "S. Suzuki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03842v1",
                "http://arxiv.org/pdf/2311.03842v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07585v2",
            "title": "Input Reconstruction Attack against Vertical Federated Large Language\n  Models",
            "updated": "2023-11-24T07:46:23Z",
            "published": "2023-11-07T09:39:22Z",
            "summary": "Recently, large language models (LLMs) have drawn extensive attention from\nacademia and the public, due to the advent of the ChatGPT. While LLMs show\ntheir astonishing ability in text generation for various tasks, privacy\nconcerns limit their usage in real-life businesses. More specifically, either\nthe user's inputs (the user sends the query to the model-hosting server) or the\nmodel (the user downloads the complete model) itself will be revealed during\nthe usage. Vertical federated learning (VFL) is a promising solution to this\nkind of problem. It protects both the user's input and the knowledge of the\nmodel by splitting the model into a bottom part and a top part, which is\nmaintained by the user and the model provider, respectively. However, in this\npaper, we demonstrate that in LLMs, VFL fails to protect the user input since\nit is simple and cheap to reconstruct the input from the intermediate\nembeddings. Experiments show that even with a commercial GPU, the input\nsentence can be reconstructed in only one second. We also discuss several\npossible solutions to enhance the privacy of vertical federated LLMs.",
            "author": [
                "Fei Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07585v2",
                "http://arxiv.org/pdf/2311.07585v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03839v2",
            "title": "Aspects of human memory and Large Language Models",
            "updated": "2023-11-09T18:16:24Z",
            "published": "2023-11-07T09:39:12Z",
            "summary": "Large Language Models (LLMs) are huge artificial neural networks which\nprimarily serve to generate text, but also provide a very sophisticated\nprobabilistic model of language use. Since generating a semantically consistent\ntext requires a form of effective memory, we investigate the memory properties\nof LLMs and find surprising similarities with key characteristics of human\nmemory. We argue that the human-like memory properties of the Large Language\nModel do not follow automatically from the LLM architecture but are rather\nlearned from the statistics of the training textual data. These results\nstrongly suggest that the biological features of human memory leave an imprint\non the way that we structure our textual narratives.",
            "author": [
                "Romuald A. Janik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03839v2",
                "http://arxiv.org/pdf/2311.03839v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03826v1",
            "title": "Accelerating Unstructured SpGEMM using Structured In-situ Computing",
            "updated": "2023-11-07T09:15:12Z",
            "published": "2023-11-07T09:15:12Z",
            "summary": "Sparse matrix-matrix multiplication (SpGEMM) is a critical kernel widely\nemployed in machine learning and graph algorithms. However, real-world\nmatrices' high sparsity makes SpGEMM memory-intensive. In-situ computing offers\nthe potential to accelerate memory-intensive applications through high\nbandwidth and parallelism. Nevertheless, the irregular distribution of\nnon-zeros renders SpGEMM a typical unstructured software. In contrast, in-situ\ncomputing platforms follow a fixed calculation manner, making them structured\nhardware. The mismatch between unstructured software and structured hardware\nleads to sub-optimal performance of current solutions.\n  In this paper, we propose SPLIM, a novel in-situ computing SpGEMM\naccelerator. SPLIM involves two innovations. First, we present a novel\ncomputation paradigm that converts SpGEMM into structured in-situ\nmultiplication and unstructured accumulation. Second, we develop a unique\ncoordinates alignment method utilizing in-situ search operations, effectively\ntransforming unstructured accumulation into high parallel searching operations.\nOur experimental results demonstrate that SPLIM achieves 275.74$\\times$\nperformance improvement and 687.19$\\times$ energy saving compared to NVIDIA RTX\nA6000 GPU.",
            "author": [
                "Huize Li",
                "Tulika Mitra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03826v1",
                "http://arxiv.org/pdf/2311.03826v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03825v1",
            "title": "IC-SECURE: Intelligent System for Assisting Security Experts in\n  Generating Playbooks for Automated Incident Response",
            "updated": "2023-11-07T09:13:37Z",
            "published": "2023-11-07T09:13:37Z",
            "summary": "Security orchestration, automation, and response (SOAR) systems ingest alerts\nfrom security information and event management (SIEM) system, and then trigger\nrelevant playbooks that automate and orchestrate the execution of a sequence of\nsecurity activities. SOAR systems have two major limitations: (i) security\nanalysts need to define, create and change playbooks manually, and (ii) the\nchoice between multiple playbooks that could be triggered is based on rules\ndefined by security analysts. To address these limitations, recent studies in\nthe field of artificial intelligence for cybersecurity suggested the task of\ninteractive playbook creation. In this paper, we propose IC-SECURE, an\ninteractive playbook creation solution based on a novel deep learning-based\napproach that provides recommendations to security analysts during the playbook\ncreation process. IC-SECURE captures the context in the form of alert data and\ncurrent status of incomplete playbook, required to make reasonable\nrecommendation for next module that should be included in the new playbook\nbeing created. We created three evaluation datasets, each of which involved a\ncombination of a set of alert rules and a set of playbooks from a SOAR\nplatform. We evaluated IC-SECURE under various settings, and compared our\nresults with two state-of-the-art recommender system methods. In our evaluation\nIC-SECURE demonstrated superior performance compared to other methods by\nconsistently recommending the correct security module, achieving precision@1 >\n0.8 and recall@3 > 0.92",
            "author": [
                "Ryuta Kremer",
                "Prasanna N. Wudali",
                "Satoru Momiyama",
                "Toshinori Araki",
                "Jun Furukawa",
                "Yuval Elovici",
                "Asaf Shabtai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03825v1",
                "http://arxiv.org/pdf/2311.03825v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03821v1",
            "title": "Positive Competitive Networks for Sparse Reconstruction",
            "updated": "2023-11-07T09:12:39Z",
            "published": "2023-11-07T09:12:39Z",
            "summary": "We propose, and analyze, a continuous-time firing-rate neural network, the\npositive firing-rate competitive network (PFCN), to tackle sparse\nreconstruction problems with non-negativity constraints. These problems, which\ninvolve approximating a given input stimulus from a dictionary using a set of\nsparse (active) neurons, play a key role in a wide range of domains spanning\ne.g., neuroscience, signal processing, and machine learning. First, by\nleveraging the theory of proximal operators, we introduce a result relating the\nequilibria of a family of continuous-time firing-rate neural networks to the\noptimal solutions of sparse reconstruction problems. Then, we give rigorous\nconditions for the convergence of the PFCN to the equilibrium. Specifically, we\nshow that the convergence: (i) only depends on a property of the dictionary;\n(ii) is linear-exponential, in the sense that initially the convergence rate is\nat most linear and then, after a transient, it becomes exponential. To obtain\nour main theorem, we also prove a number of technical results to assess certain\ncontractivity properties of the dynamics of our interest. Finally, we validate\nthe effectiveness of our approach via a numerical example.",
            "author": [
                "Veronica Centorrino",
                "Anand Gokhale",
                "Alexander Davydov",
                "Giovanni Russo",
                "Francesco Bullo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03821v1",
                "http://arxiv.org/pdf/2311.03821v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.SY",
                "eess.SY",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03819v1",
            "title": "Constrained Regularization by Denoising with Automatic Parameter\n  Selection",
            "updated": "2023-11-07T09:06:02Z",
            "published": "2023-11-07T09:06:02Z",
            "summary": "Regularization by Denoising (RED) is a well-known method for solving image\nrestoration problems by using learned image denoisers as priors. Since the\nregularization parameter in the traditional RED does not have any physical\ninterpretation, it does not provide an approach for automatic parameter\nselection. This letter addresses this issue by introducing the Constrained\nRegularization by Denoising (CRED) method that reformulates RED as a\nconstrained optimization problem where the regularization parameter corresponds\ndirectly to the amount of noise in the measurements. The solution to the\nconstrained problem is solved by designing an efficient method based on\nalternating direction method of multipliers (ADMM). Our experiments show that\nCRED outperforms the competing methods in terms of stability and robustness,\nwhile also achieving competitive performances in terms of image quality.",
            "author": [
                "Pasquale Cascarano",
                "Alessandro Benfenati",
                "Ulugbek S. Kamilov",
                "Xiaojian Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03819v1",
                "http://arxiv.org/pdf/2311.03819v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03815v1",
            "title": "Integrated Sensing, Communication, and Computing for Cost-effective\n  Multimodal Federated Perception",
            "updated": "2023-11-07T08:55:56Z",
            "published": "2023-11-07T08:55:56Z",
            "summary": "Federated learning (FL) is a classic paradigm of 6G edge intelligence (EI),\nwhich alleviates privacy leaks and high communication pressure caused by\ntraditional centralized data processing in the artificial intelligence of\nthings (AIoT). The implementation of multimodal federated perception (MFP)\nservices involves three sub-processes, including sensing-based multimodal data\ngeneration, communication-based model transmission, and computing-based model\ntraining, ultimately relying on available underlying multi-domain physical\nresources such as time, frequency, and computing power. How to reasonably\ncoordinate the multi-domain resources scheduling among sensing, communication,\nand computing, therefore, is crucial to the MFP networks. To address the above\nissues, this paper investigates service-oriented resource management with\nintegrated sensing, communication, and computing (ISCC). With the incentive\nmechanism of the MFP service market, the resources management problem is\nredefined as a social welfare maximization problem, where the idea of\n\"expanding resources\" and \"reducing costs\" is used to improve learning\nperformance gain and reduce resource costs. Experimental results demonstrate\nthe effectiveness and robustness of the proposed resource scheduling\nmechanisms.",
            "author": [
                "Ning Chen",
                "Zhipeng Cheng",
                "Xuwei Fan",
                "Bangzhen Huang",
                "Yifeng Zhao",
                "Lianfen Huang",
                "Xiaojiang Du",
                "Mohsen Guizani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03815v1",
                "http://arxiv.org/pdf/2311.03815v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03810v1",
            "title": "Rethinking and Improving Multi-task Learning for End-to-end Speech\n  Translation",
            "updated": "2023-11-07T08:48:46Z",
            "published": "2023-11-07T08:48:46Z",
            "summary": "Significant improvements in end-to-end speech translation (ST) have been\nachieved through the application of multi-task learning. However, the extent to\nwhich auxiliary tasks are highly consistent with the ST task, and how much this\napproach truly helps, have not been thoroughly studied. In this paper, we\ninvestigate the consistency between different tasks, considering different\ntimes and modules. We find that the textual encoder primarily facilitates\ncross-modal conversion, but the presence of noise in speech impedes the\nconsistency between text and speech representations. Furthermore, we propose an\nimproved multi-task learning (IMTL) approach for the ST task, which bridges the\nmodal gap by mitigating the difference in length and representation. We conduct\nexperiments on the MuST-C dataset. The results demonstrate that our method\nattains state-of-the-art results. Moreover, when additional data is used, we\nachieve the new SOTA result on MuST-C English to Spanish task with 20.8% of the\ntraining time required by the current SOTA method.",
            "author": [
                "Yuhao Zhang",
                "Chen Xu",
                "Bei Li",
                "Hao Chen",
                "Tong Xiao",
                "Chunliang Zhang",
                "Jingbo Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03810v1",
                "http://arxiv.org/pdf/2311.03810v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03806v1",
            "title": "Exploring the transformation of user interactions to Adaptive\n  Human-Machine Interfaces",
            "updated": "2023-11-07T08:38:24Z",
            "published": "2023-11-07T08:38:24Z",
            "summary": "Human-machine interfaces (HMI) facilitate communication between humans and\nmachines, and their importance has increased in modern technology. However,\ntraditional HMIs are often static and do not adapt to individual user\npreferences or behavior. Adaptive User Interfaces (AUIs) have become\nincreasingly important in providing personalized user experiences. Machine\nlearning techniques have gained traction in User Experience (UX) research to\nprovide smart adaptations that can reduce user cognitive load. This paper\npresents an ongoing exploration of a method for generating adaptive user\ninterfaces by analyzing user interactions and contextual data. It also provides\nan illustrative example using Markov chains to predict the next step for users\ninteracting with an app for an industrial mixing machine. Furthermore, the\npaper conducts an offline evaluation of the approach, focusing on the precision\nof the recommendations. The study emphasizes the importance of incorporating\nuser interactions and contextual data into the design of adaptive HMIs, while\nacknowledging the existing challenges and potential benefits.",
            "author": [
                "Angela Carrera-Rivera",
                "Daniel Reguera-Bakhache",
                "Felix Larrinaga",
                "Ganix Lasa"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3612783.3612807",
                "http://arxiv.org/abs/2311.03806v1",
                "http://arxiv.org/pdf/2311.03806v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03805v1",
            "title": "Quantum Circuit Unoptimization",
            "updated": "2023-11-07T08:38:18Z",
            "published": "2023-11-07T08:38:18Z",
            "summary": "Optimization of circuits is an essential task for both quantum and classical\ncomputers to improve their efficiency. In contrast, classical logic\noptimization is known to be difficult, and a lot of heuristic approaches have\nbeen developed so far. In this study, we define and construct a quantum\nalgorithmic primitive called quantum circuit unoptimization, which makes a\ngiven quantum circuit complex by introducing some redundancies while preserving\ncircuit equivalence, i.e., the inverse operation of circuit optimization. Using\nquantum circuit unoptimization, we propose the quantum circuit equivalence\ntest, a decision problem contained both in NP and BQP classes. Furthermore, as\na practical application, we construct concrete unoptimization recipes to\ngenerate compiler benchmarks and evaluate circuit optimization performance\nusing Qiskit and Pytket. Our numerical simulations demonstrate that quantum\ncircuit unoptimizer systematically generates redundant circuits that are\nchallenging for compilers to optimize, which can be used to compare the\nperformance of different compilers and improve them. We also offer potential\napplications of quantum circuit unoptimization, such as generating quantum\nadvantageous machine learning datasets and quantum computer fidelity\nbenchmarks.",
            "author": [
                "Yusei Mori",
                "Hideaki Hakoshima",
                "Kyohei Sudo",
                "Toshio Mori",
                "Kosuke Mitarai",
                "Keisuke Fujii"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03805v1",
                "http://arxiv.org/pdf/2311.03805v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03799v1",
            "title": "Detecting Any Human-Object Interaction Relationship: Universal HOI\n  Detector with Spatial Prompt Learning on Foundation Models",
            "updated": "2023-11-07T08:27:32Z",
            "published": "2023-11-07T08:27:32Z",
            "summary": "Human-object interaction (HOI) detection aims to comprehend the intricate\nrelationships between humans and objects, predicting $<human, action, object>$\ntriplets, and serving as the foundation for numerous computer vision tasks. The\ncomplexity and diversity of human-object interactions in the real world,\nhowever, pose significant challenges for both annotation and recognition,\nparticularly in recognizing interactions within an open world context. This\nstudy explores the universal interaction recognition in an open-world setting\nthrough the use of Vision-Language (VL) foundation models and large language\nmodels (LLMs). The proposed method is dubbed as \\emph{\\textbf{UniHOI}}. We\nconduct a deep analysis of the three hierarchical features inherent in visual\nHOI detectors and propose a method for high-level relation extraction aimed at\nVL foundation models, which we call HO prompt-based learning. Our design\nincludes an HO Prompt-guided Decoder (HOPD), facilitates the association of\nhigh-level relation representations in the foundation model with various HO\npairs within the image. Furthermore, we utilize a LLM (\\emph{i.e.} GPT) for\ninteraction interpretation, generating a richer linguistic understanding for\ncomplex HOIs. For open-category interaction recognition, our method supports\neither of two input types: interaction phrase or interpretive sentence. Our\nefficient architecture design and learning methods effectively unleash the\npotential of the VL foundation models and LLMs, allowing UniHOI to surpass all\nexisting methods with a substantial margin, under both supervised and zero-shot\nsettings. The code and pre-trained weights are available at:\n\\url{https://github.com/Caoyichao/UniHOI}.",
            "author": [
                "Yichao Cao",
                "Qingfei Tang",
                "Xiu Su",
                "Chen Song",
                "Shan You",
                "Xiaobo Lu",
                "Chang Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03799v1",
                "http://arxiv.org/pdf/2311.03799v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03797v1",
            "title": "User-level Differentially Private Stochastic Convex Optimization:\n  Efficient Algorithms with Optimal Rates",
            "updated": "2023-11-07T08:26:51Z",
            "published": "2023-11-07T08:26:51Z",
            "summary": "We study differentially private stochastic convex optimization (DP-SCO) under\nuser-level privacy, where each user may hold multiple data items. Existing work\nfor user-level DP-SCO either requires super-polynomial runtime [Ghazi et al.\n(2023)] or requires the number of users to grow polynomially with the\ndimensionality of the problem with additional strict assumptions [Bassily et\nal. (2023)]. We develop new algorithms for user-level DP-SCO that obtain\noptimal rates for both convex and strongly convex functions in polynomial time\nand require the number of users to grow only logarithmically in the dimension.\nMoreover, our algorithms are the first to obtain optimal rates for non-smooth\nfunctions in polynomial time. These algorithms are based on multiple-pass\nDP-SGD, combined with a novel private mean estimation procedure for\nconcentrated data, which applies an outlier removal step before estimating the\nmean of the gradients.",
            "author": [
                "Hilal Asi",
                "Daogao Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03797v1",
                "http://arxiv.org/pdf/2311.03797v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.DS",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03794v1",
            "title": "On the Impact of Overparameterization on the Training of a Shallow\n  Neural Network in High Dimensions",
            "updated": "2023-11-07T08:20:31Z",
            "published": "2023-11-07T08:20:31Z",
            "summary": "We study the training dynamics of a shallow neural network with quadratic\nactivation functions and quadratic cost in a teacher-student setup. In line\nwith previous works on the same neural architecture, the optimization is\nperformed following the gradient flow on the population risk, where the average\nover data points is replaced by the expectation over their distribution,\nassumed to be Gaussian.We first derive convergence properties for the gradient\nflow and quantify the overparameterization that is necessary to achieve a\nstrong signal recovery. Then, assuming that the teachers and the students at\ninitialization form independent orthonormal families, we derive a\nhigh-dimensional limit for the flow and show that the minimal\noverparameterization is sufficient for strong recovery. We verify by numerical\nexperiments that these results hold for more general initializations.",
            "author": [
                "Simon Martin",
                "Francis Bach",
                "Giulio Biroli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03794v1",
                "http://arxiv.org/pdf/2311.03794v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cond-mat.dis-nn",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03792v1",
            "title": "Character-Level Bangla Text-to-IPA Transcription Using Transformer\n  Architecture with Sequence Alignment",
            "updated": "2023-11-07T08:20:06Z",
            "published": "2023-11-07T08:20:06Z",
            "summary": "The International Phonetic Alphabet (IPA) is indispensable in language\nlearning and understanding, aiding users in accurate pronunciation and\ncomprehension. Additionally, it plays a pivotal role in speech therapy,\nlinguistic research, accurate transliteration, and the development of\ntext-to-speech systems, making it an essential tool across diverse fields.\nBangla being 7th as one of the widely used languages, gives rise to the need\nfor IPA in its domain. Its IPA mapping is too diverse to be captured manually\ngiving the need for Artificial Intelligence and Machine Learning in this field.\nIn this study, we have utilized a transformer-based sequence-to-sequence model\nat the letter and symbol level to get the IPA of each Bangla word as the\nvariation of IPA in association of different words is almost null. Our\ntransformer model only consisted of 8.5 million parameters with only a single\ndecoder and encoder layer. Additionally, to handle the punctuation marks and\nthe occurrence of foreign languages in the text, we have utilized manual\nmapping as the model won't be able to learn to separate them from Bangla words\nwhile decreasing our required computational resources. Finally, maintaining the\nrelative position of the sentence component IPAs and generation of the combined\nIPA has led us to achieve the top position with a word error rate of 0.10582 in\nthe public ranking of DataVerse Challenge - ITVerse 2023\n(https://www.kaggle.com/competitions/dataverse_2023/).",
            "author": [
                "Jakir Hasan",
                "Shrestha Datta",
                "Ameya Debnath"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03792v1",
                "http://arxiv.org/pdf/2311.03792v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03785v1",
            "title": "Self-MI: Efficient Multimodal Fusion via Self-Supervised Multi-Task\n  Learning with Auxiliary Mutual Information Maximization",
            "updated": "2023-11-07T08:10:36Z",
            "published": "2023-11-07T08:10:36Z",
            "summary": "Multimodal representation learning poses significant challenges in capturing\ninformative and distinct features from multiple modalities. Existing methods\noften struggle to exploit the unique characteristics of each modality due to\nunified multimodal annotations. In this study, we propose Self-MI in the\nself-supervised learning fashion, which also leverage Contrastive Predictive\nCoding (CPC) as an auxiliary technique to maximize the Mutual Information (MI)\nbetween unimodal input pairs and the multimodal fusion result with unimodal\ninputs. Moreover, we design a label generation module, $ULG_{MI}$ for short,\nthat enables us to create meaningful and informative labels for each modality\nin a self-supervised manner. By maximizing the Mutual Information, we encourage\nbetter alignment between the multimodal fusion and the individual modalities,\nfacilitating improved multimodal fusion. Extensive experiments on three\nbenchmark datasets including CMU-MOSI, CMU-MOSEI, and SIMS, demonstrate the\neffectiveness of Self-MI in enhancing the multimodal fusion task.",
            "author": [
                "Cam-Van Thi Nguyen",
                "Ngoc-Hoa Thi Nguyen",
                "Duc-Trong Le",
                "Quang-Thuy Ha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03785v1",
                "http://arxiv.org/pdf/2311.03785v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03784v2",
            "title": "UP-NeRF: Unconstrained Pose-Prior-Free Neural Radiance Fields",
            "updated": "2023-11-08T02:52:47Z",
            "published": "2023-11-07T08:10:29Z",
            "summary": "Neural Radiance Field (NeRF) has enabled novel view synthesis with high\nfidelity given images and camera poses. Subsequent works even succeeded in\neliminating the necessity of pose priors by jointly optimizing NeRF and camera\npose. However, these works are limited to relatively simple settings such as\nphotometrically consistent and occluder-free image collections or a sequence of\nimages from a video. So they have difficulty handling unconstrained images with\nvarying illumination and transient occluders. In this paper, we propose\n$\\textbf{UP-NeRF}$ ($\\textbf{U}$nconstrained $\\textbf{P}$ose-prior-free\n$\\textbf{Ne}$ural $\\textbf{R}$adiance $\\textbf{F}$ields) to optimize NeRF with\nunconstrained image collections without camera pose prior. We tackle these\nchallenges with surrogate tasks that optimize color-insensitive feature fields\nand a separate module for transient occluders to block their influence on pose\nestimation. In addition, we introduce a candidate head to enable more robust\npose estimation and transient-aware depth supervision to minimize the effect of\nincorrect prior. Our experiments verify the superior performance of our method\ncompared to the baselines including BARF and its variants in a challenging\ninternet photo collection, $\\textit{Phototourism}$ dataset.",
            "author": [
                "Injae Kim",
                "Minhyuk Choi",
                "Hyunwoo J. Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03784v2",
                "http://arxiv.org/pdf/2311.03784v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03780v1",
            "title": "Ensembling Textual and Structure-Based Models for Knowledge Graph\n  Completion",
            "updated": "2023-11-07T07:53:06Z",
            "published": "2023-11-07T07:53:06Z",
            "summary": "We consider two popular approaches to Knowledge Graph Completion (KGC):\ntextual models that rely on textual entity descriptions, and structure-based\nmodels that exploit the connectivity structure of the Knowledge Graph (KG).\nPreliminary experiments show that these approaches have complementary\nstrengths: structure-based models perform well when the gold answer is easily\nreachable from the query head in the KG, while textual models exploit\ndescriptions to give good performance even when the gold answer is not\nreachable. In response, we explore ensembling as a way of combining the best of\nboth approaches. We propose a novel method for learning query-dependent\nensemble weights by using the distributions of scores assigned by individual\nmodels to all candidate entities. Our ensemble baseline achieves\nstate-of-the-art results on three standard KGC datasets, with up to 6.8 pt MRR\nand 8.3 pt Hits@1 gains over best individual models.",
            "author": [
                "Ananjan Nandi",
                "Navdeep Kaur",
                "Parag Singla",
                "Mausam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03780v1",
                "http://arxiv.org/pdf/2311.03780v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03778v1",
            "title": "Bridging the Information Gap Between Domain-Specific Model and General\n  LLM for Personalized Recommendation",
            "updated": "2023-11-07T07:40:09Z",
            "published": "2023-11-07T07:40:09Z",
            "summary": "Generative large language models(LLMs) are proficient in solving general\nproblems but often struggle to handle domain-specific tasks. This is because\nmost of domain-specific tasks, such as personalized recommendation, rely on\ntask-related information for optimal performance. Current methods attempt to\nsupplement task-related information to LLMs by designing appropriate prompts or\nemploying supervised fine-tuning techniques. Nevertheless, these methods\nencounter the certain issue that information such as community behavior pattern\nin RS domain is challenging to express in natural language, which limits the\ncapability of LLMs to surpass state-of-the-art domain-specific models. On the\nother hand, domain-specific models for personalized recommendation which mainly\nrely on user interactions are susceptible to data sparsity due to their limited\ncommon knowledge capabilities. To address these issues, we proposes a method to\nbridge the information gap between the domain-specific models and the general\nlarge language models. Specifically, we propose an information sharing module\nwhich serves as an information storage mechanism and also acts as a bridge for\ncollaborative training between the LLMs and domain-specific models. By doing\nso, we can improve the performance of LLM-based recommendation with the help of\nuser behavior pattern information mined by domain-specific models. On the other\nhand, the recommendation performance of domain-specific models can also be\nimproved with the help of common knowledge learned by LLMs. Experimental\nresults on three real-world datasets have demonstrated the effectiveness of the\nproposed method.",
            "author": [
                "Wenxuan Zhang",
                "Hongzhi Liu",
                "Yingpeng Du",
                "Chen Zhu",
                "Yang Song",
                "Hengshu Zhu",
                "Zhonghai Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03778v1",
                "http://arxiv.org/pdf/2311.03778v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03776v1",
            "title": "Filtered Partial Differential Equations: a robust surrogate constraint\n  in physics-informed deep learning framework",
            "updated": "2023-11-07T07:38:23Z",
            "published": "2023-11-07T07:38:23Z",
            "summary": "Embedding physical knowledge into neural network (NN) training has been a hot\ntopic. However, when facing the complex real-world, most of the existing\nmethods still strongly rely on the quantity and quality of observation data.\nFurthermore, the neural networks often struggle to converge when the solution\nto the real equation is very complex. Inspired by large eddy simulation in\ncomputational fluid dynamics, we propose an improved method based on filtering.\nWe analyzed the causes of the difficulties in physics informed machine\nlearning, and proposed a surrogate constraint (filtered PDE, FPDE in short) of\nthe original physical equations to reduce the influence of noisy and sparse\nobservation data. In the noise and sparsity experiment, the proposed FPDE\nmodels (which are optimized by FPDE constraints) have better robustness than\nthe conventional PDE models. Experiments demonstrate that the FPDE model can\nobtain the same quality solution with 100% higher noise and 12% quantity of\nobservation data of the baseline. Besides, two groups of real measurement data\nare used to show the FPDE improvements in real cases. The final results show\nthat FPDE still gives more physically reasonable solutions when facing the\nincomplete equation problem and the extremely sparse and high-noise conditions.\nFor combining real-world experiment data into physics-informed training, the\nproposed FPDE constraint is useful and performs well in two real-world\nexperiments: modeling the blood velocity in vessels and cell migration in\nscratches.",
            "author": [
                "Dashan Zhang",
                "Yuntian Chen",
                "Shiyi Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03776v1",
                "http://arxiv.org/pdf/2311.03776v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "stat.AP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03774v1",
            "title": "Meta-Adapter: An Online Few-shot Learner for Vision-Language Model",
            "updated": "2023-11-07T07:27:16Z",
            "published": "2023-11-07T07:27:16Z",
            "summary": "The contrastive vision-language pre-training, known as CLIP, demonstrates\nremarkable potential in perceiving open-world visual concepts, enabling\neffective zero-shot image recognition. Nevertheless, few-shot learning methods\nbased on CLIP typically require offline fine-tuning of the parameters on\nfew-shot samples, resulting in longer inference time and the risk of\nover-fitting in certain domains. To tackle these challenges, we propose the\nMeta-Adapter, a lightweight residual-style adapter, to refine the CLIP features\nguided by the few-shot samples in an online manner. With a few training\nsamples, our method can enable effective few-shot learning capabilities and\ngeneralize to unseen data or tasks without additional fine-tuning, achieving\ncompetitive performance and high efficiency. Without bells and whistles, our\napproach outperforms the state-of-the-art online few-shot learning method by an\naverage of 3.6\\% on eight image classification datasets with higher inference\nspeed. Furthermore, our model is simple and flexible, serving as a\nplug-and-play module directly applicable to downstream tasks. Without further\nfine-tuning, Meta-Adapter obtains notable performance improvements in\nopen-vocabulary object detection and segmentation tasks.",
            "author": [
                "Cheng Cheng",
                "Lin Song",
                "Ruoyi Xue",
                "Hang Wang",
                "Hongbin Sun",
                "Yixiao Ge",
                "Ying Shan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03774v1",
                "http://arxiv.org/pdf/2311.03774v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03768v1",
            "title": "PT-Tuning: Bridging the Gap between Time Series Masked Reconstruction\n  and Forecasting via Prompt Token Tuning",
            "updated": "2023-11-07T07:11:27Z",
            "published": "2023-11-07T07:11:27Z",
            "summary": "Self-supervised learning has been actively studied in time series domain\nrecently, especially for masked reconstruction. Most of these methods follow\nthe \"Pre-training + Fine-tuning\" paradigm in which a new decoder replaces the\npre-trained decoder to fit for a specific downstream task, leading to\ninconsistency of upstream and downstream tasks. In this paper, we first point\nout that the unification of task objectives and adaptation for task difficulty\nare critical for bridging the gap between time series masked reconstruction and\nforecasting. By reserving the pre-trained mask token during fine-tuning stage,\nthe forecasting task can be taken as a special case of masked reconstruction,\nwhere the future values are masked and reconstructed based on history values.\nIt guarantees the consistency of task objectives but there is still a gap in\ntask difficulty. Because masked reconstruction can utilize contextual\ninformation while forecasting can only use historical information to\nreconstruct. To further mitigate the existed gap, we propose a simple yet\neffective prompt token tuning (PT-Tuning) paradigm, in which all pre-trained\nparameters are frozen and only a few trainable prompt tokens are added to\nextended mask tokens in element-wise manner. Extensive experiments on\nreal-world datasets demonstrate the superiority of our proposed paradigm with\nstate-of-the-art performance compared to representation learning and end-to-end\nsupervised forecasting methods.",
            "author": [
                "Hao Liu",
                "Jinrui Gan",
                "Xiaoxuan Fan",
                "Yi Zhang",
                "Chuanxian Luo",
                "Jing Zhang",
                "Guangxin Jiang",
                "Yucheng Qian",
                "Changwei Zhao",
                "Huan Ma",
                "Zhenyu Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03768v1",
                "http://arxiv.org/pdf/2311.03768v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03765v1",
            "title": "Classification of Various Types of Damages in Honeycomb Composite\n  Sandwich Structures using Guided Wave Structural Health Monitoring",
            "updated": "2023-11-07T07:08:02Z",
            "published": "2023-11-07T07:08:02Z",
            "summary": "Classification of damages in honeycomb composite sandwich structure (HCSS) is\nimportant to decide remedial actions. However, previous studies have only\ndetected damages using deviations of monitoring signal from healthy (baseline)\nusing a guided wave (GW) based structural health monitoring system.\nClassification between various types of damages has not been reported for\nchallenging cases. We show that using careful feature engineering and machine\nlearning it is possible to classify between various types of damages such as\ncore crush (CC), high density core (HDC), lost film adhesive (LFA) and teflon\nrelease film (TRF). We believe that we are the first to report numerical models\nfor four types of damages in HCSS, which is followed up with experimental\nvalidation. We found that two out of four damages affect the GW signal in a\nparticularly similar manner. We extracted and evaluated multiple features from\ntime as well as frequency domains, and also experimented with features relative\nto as baseline as well as those that were baseline-free. Using Pearson's\ncorrelation coefficient based filtering, redundant features were eliminated.\nFinally, using an optimal feature set determined using feature elimination,\nhigh accuracy was achieved with a random forest classifier on held-out signals.\nFor evaluating performance of the proposed method for different damage sizes,\nwe used simulated data obtained from extensive parametric studies and got an\naccuracy of 77.89%. Interpretability studies to determine importance of various\nfeatures showed that features computed using the baseline signal prove more\neffective as compared to baseline-free features.",
            "author": [
                "Shruti Sawant",
                "Jeslin Thalapil",
                "Siddharth Tallur",
                "Sauvik Banerjee",
                "Amit Sethi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03765v1",
                "http://arxiv.org/pdf/2311.03765v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03764v3",
            "title": "Neuro-GPT: Developing A Foundation Model for EEG",
            "updated": "2023-11-11T02:23:07Z",
            "published": "2023-11-07T07:07:18Z",
            "summary": "To handle the scarcity and heterogeneity of electroencephalography (EEG) data\nfor Brain-Computer Interface (BCI) tasks, and to harness the power of large\npublicly available data sets, we propose Neuro-GPT, a foundation model\nconsisting of an EEG encoder and a GPT model. The foundation model is\npre-trained on a large-scale data set using a self-supervised task that learns\nhow to reconstruct masked EEG segments. We then fine-tune the model on a Motor\nImagery Classification task to validate its performance in a low-data regime (9\nsubjects). Our experiments demonstrate that applying a foundation model can\nsignificantly improve classification performance compared to a model trained\nfrom scratch, which provides evidence for the generalizability of the\nfoundation model and its ability to address challenges of data scarcity and\nheterogeneity in EEG.",
            "author": [
                "Wenhui Cui",
                "Woojae Jeong",
                "Philipp Th\u00f6lke",
                "Takfarinas Medani",
                "Karim Jerbi",
                "Anand A. Joshi",
                "Richard M. Leahy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03764v3",
                "http://arxiv.org/pdf/2311.03764v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03761v1",
            "title": "Augmenting Radio Signals with Wavelet Transform for Deep Learning-Based\n  Modulation Recognition",
            "updated": "2023-11-07T06:55:39Z",
            "published": "2023-11-07T06:55:39Z",
            "summary": "The use of deep learning for radio modulation recognition has become\nprevalent in recent years. This approach automatically extracts\nhigh-dimensional features from large datasets, facilitating the accurate\nclassification of modulation schemes. However, in real-world scenarios, it may\nnot be feasible to gather sufficient training data in advance. Data\naugmentation is a method used to increase the diversity and quantity of\ntraining dataset and to reduce data sparsity and imbalance. In this paper, we\npropose data augmentation methods that involve replacing detail coefficients\ndecomposed by discrete wavelet transform for reconstructing to generate new\nsamples and expand the training set. Different generation methods are used to\ngenerate replacement sequences. Simulation results indicate that our proposed\nmethods significantly outperform the other augmentation methods.",
            "author": [
                "Tao Chen",
                "Shilian Zheng",
                "Kunfeng Qiu",
                "Luxin Zhang",
                "Qi Xuan",
                "Xiaoniu Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03761v1",
                "http://arxiv.org/pdf/2311.03761v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03760v1",
            "title": "Posterior Sampling-Based Bayesian Optimization with Tighter Bayesian\n  Regret Bounds",
            "updated": "2023-11-07T06:54:40Z",
            "published": "2023-11-07T06:54:40Z",
            "summary": "Among various acquisition functions (AFs) in Bayesian optimization (BO),\nGaussian process upper confidence bound (GP-UCB) and Thompson sampling (TS) are\nwell-known options with established theoretical properties regarding Bayesian\ncumulative regret (BCR). Recently, it has been shown that a randomized variant\nof GP-UCB achieves a tighter BCR bound compared with GP-UCB, which we call the\ntighter BCR bound for brevity. Inspired by this study, this paper first shows\nthat TS achieves the tighter BCR bound. On the other hand, GP-UCB and TS often\npractically suffer from manual hyperparameter tuning and over-exploration\nissues, respectively. To overcome these difficulties, we propose yet another AF\ncalled a probability of improvement from the maximum of a sample path (PIMS).\nWe show that PIMS achieves the tighter BCR bound and avoids the hyperparameter\ntuning, unlike GP-UCB. Furthermore, we demonstrate a wide range of experiments,\nfocusing on the effectiveness of PIMS that mitigates the practical issues of\nGP-UCB and TS.",
            "author": [
                "Shion Takeno",
                "Yu Inatsu",
                "Masayuki Karasuyama",
                "Ichiro Takeuchi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03760v1",
                "http://arxiv.org/pdf/2311.03760v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03758v2",
            "title": "Large Language Model based Long-tail Query Rewriting in Taobao Search",
            "updated": "2023-11-12T02:36:54Z",
            "published": "2023-11-07T06:48:47Z",
            "summary": "In the realm of e-commerce search, the significance of semantic matching\ncannot be overstated, as it directly impacts both user experience and company\nrevenue. Along this line, query rewriting, serving as an important technique to\nbridge the semantic gaps inherent in the semantic matching process, has\nattached wide attention from the industry and academia. However, existing query\nrewriting methods often struggle to effectively optimize long-tail queries and\nalleviate the phenomenon of \"few-recall\" caused by semantic gap. In this paper,\nwe present BEQUE, a comprehensive framework that Bridges the sEmantic gap for\nlong-tail QUEries. In detail, BEQUE comprises three stages: multi-instruction\nsupervised fine tuning (SFT), offline feedback, and objective alignment. We\nfirst construct a rewriting dataset based on rejection sampling and auxiliary\ntasks mixing to fine-tune our large language model (LLM) in a supervised\nfashion. Subsequently, with the well-trained LLM, we employ beam search to\ngenerate multiple candidate rewrites, and feed them into Taobao offline system\nto obtain the partial order. Leveraging the partial order of rewrites, we\nintroduce a contrastive learning method to highlight the distinctions between\nrewrites, and align the model with the Taobao online objectives. Offline\nexperiments prove the effectiveness of our method in bridging semantic gap.\nOnline A/B tests reveal that our method can significantly boost gross\nmerchandise volume (GMV), number of transaction (#Trans) and unique visitor\n(UV) for long-tail queries. BEQUE has been deployed on Taobao, one of most\npopular online shopping platforms in China, since October 2023.",
            "author": [
                "Wenjun Peng",
                "Guiyang Li",
                "Yue Jiang",
                "Zilong Wang",
                "Dan Ou",
                "Xiaoyi Zeng",
                "Derong Xu",
                "Tongxu",
                "Enhong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03758v2",
                "http://arxiv.org/pdf/2311.03758v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03757v1",
            "title": "Manifold learning: what, how, and why",
            "updated": "2023-11-07T06:44:20Z",
            "published": "2023-11-07T06:44:20Z",
            "summary": "Manifold learning (ML), known also as non-linear dimension reduction, is a\nset of methods to find the low dimensional structure of data. Dimension\nreduction for large, high dimensional data is not merely a way to reduce the\ndata; the new representations and descriptors obtained by ML reveal the\ngeometric shape of high dimensional point clouds, and allow one to visualize,\nde-noise and interpret them. This survey presents the principles underlying ML,\nthe representative methods, as well as their statistical foundations from a\npracticing statistician's perspective. It describes the trade-offs, and what\ntheory tells us about the parameter and algorithmic choices we make in order to\nobtain reliable conclusions.",
            "author": [
                "Marina Meil\u0103",
                "Hanyu Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03757v1",
                "http://arxiv.org/pdf/2311.03757v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03756v1",
            "title": "Learning Decentralized Traffic Signal Controllers with Multi-Agent Graph\n  Reinforcement Learning",
            "updated": "2023-11-07T06:43:15Z",
            "published": "2023-11-07T06:43:15Z",
            "summary": "This paper considers optimal traffic signal control in smart cities, which\nhas been taken as a complex networked system control problem. Given the\ninteracting dynamics among traffic lights and road networks, attaining\ncontroller adaptivity and scalability stands out as a primary challenge.\nCapturing the spatial-temporal correlation among traffic lights under the\nframework of Multi-Agent Reinforcement Learning (MARL) is a promising solution.\nNevertheless, existing MARL algorithms ignore effective information aggregation\nwhich is fundamental for improving the learning capacity of decentralized\nagents. In this paper, we design a new decentralized control architecture with\nimproved environmental observability to capture the spatial-temporal\ncorrelation. Specifically, we first develop a topology-aware information\naggregation strategy to extract correlation-related information from\nunstructured data gathered in the road network. Particularly, we transfer the\nroad network topology into a graph shift operator by forming a diffusion\nprocess on the topology, which subsequently facilitates the construction of\ngraph signals. A diffusion convolution module is developed, forming a new MARL\nalgorithm, which endows agents with the capabilities of graph learning.\nExtensive experiments based on both synthetic and real-world datasets verify\nthat our proposal outperforms existing decentralized algorithms.",
            "author": [
                "Yao Zhang",
                "Zhiwen Yu",
                "Jun Zhang",
                "Liang Wang",
                "Tom H. Luan",
                "Bin Guo",
                "Chau Yuen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03756v1",
                "http://arxiv.org/pdf/2311.03756v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03755v2",
            "title": "Multilingual Mathematical Autoformalization",
            "updated": "2023-11-09T09:58:15Z",
            "published": "2023-11-07T06:42:15Z",
            "summary": "Autoformalization is the task of translating natural language materials into\nmachine-verifiable formalisations. Progress in autoformalization research is\nhindered by the lack of a sizeable dataset consisting of informal-formal pairs\nexpressing the same essence. Existing methods tend to circumvent this challenge\nby manually curating small corpora or using few-shot learning with large\nlanguage models. But these methods suffer from data scarcity and formal\nlanguage acquisition difficulty. In this work, we create $\\texttt{MMA}$, a\nlarge, flexible, multilingual, and multi-domain dataset of informal-formal\npairs, by using a language model to translate in the reverse direction, that\nis, from formal mathematical statements into corresponding informal ones.\nExperiments show that language models fine-tuned on $\\texttt{MMA}$ produce\n$16-18\\%$ of statements acceptable with minimal corrections on the\n$\\texttt{miniF2F}$ and $\\texttt{ProofNet}$ benchmarks, up from $0\\%$ with the\nbase model. We demonstrate that fine-tuning on multilingual formal data results\nin more capable autoformalization models even when deployed on monolingual\ntasks.",
            "author": [
                "Albert Q. Jiang",
                "Wenda Li",
                "Mateja Jamnik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03755v2",
                "http://arxiv.org/pdf/2311.03755v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03753v1",
            "title": "COOL: A Constraint Object-Oriented Logic Programming Language and its\n  Neural-Symbolic Compilation System",
            "updated": "2023-11-07T06:29:59Z",
            "published": "2023-11-07T06:29:59Z",
            "summary": "This paper explores the integration of neural networks with logic\nprogramming, addressing the longstanding challenges of combining the\ngeneralization and learning capabilities of neural networks with the precision\nof symbolic logic. Traditional attempts at this integration have been hampered\nby difficulties in initial data acquisition, the reliability of undertrained\nnetworks, and the complexity of reusing and augmenting trained models. To\novercome these issues, we introduce the COOL (Constraint Object-Oriented Logic)\nprogramming language, an innovative approach that seamlessly combines logical\nreasoning with neural network technologies. COOL is engineered to autonomously\nhandle data collection, mitigating the need for user-supplied initial data. It\nincorporates user prompts into the coding process to reduce the risks of\nundertraining and enhances the interaction among models throughout their\nlifecycle to promote the reuse and augmentation of networks. Furthermore, the\nfoundational principles and algorithms in COOL's design and its compilation\nsystem could provide valuable insights for future developments in programming\nlanguages and neural network architectures.",
            "author": [
                "Jipeng Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03753v1",
                "http://arxiv.org/pdf/2311.03753v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.DC",
                "cs.FL",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03751v2",
            "title": "Seismic traveltime simulation for variable velocity models using\n  physics-informed Fourier neural operator",
            "updated": "2023-12-07T01:44:02Z",
            "published": "2023-11-07T06:21:35Z",
            "summary": "Seismic traveltime is critical information conveyed by seismic waves, widely\nutilized in various geophysical applications. Conventionally, the simulation of\nseismic traveltime involves solving the eikonal equation. However, the\nefficiency of traditional numerical solvers is hindered, as they are typically\ncapable of simulating seismic traveltime for only a single source at a time.\nRecently, deep learning tools, particularly physics-informed neural networks\n(PINNs), have proven effective in simulating seismic traveltimes for multiple\nsources. Nonetheless, PINNs face challenges such as limited generalization\ncapabilities across different models and difficulties in training convergence.\nTo address these issues, we have developed a method for simulating multi-source\nseismic traveltimes in variable velocity models using a deep-learning\ntechnique, known as the physics-informed Fourier neural operator (PIFNO). The\nPIFNO-based method for seismic traveltime generation takes both velocity and\nbackground traveltime as inputs, generating the perturbation traveltime as the\noutput. This method incorporates a factorized eikonal equation as the loss\nfunction and relies solely on physical laws, eliminating the need for labeled\ntraining data. We demonstrate that our proposed method is not only effective in\ncalculating seismic traveltimes for velocity models used during training but\nalso shows promising prediction capabilities for test velocity models. We\nvalidate these features using velocity models from the OpenFWI dataset.",
            "author": [
                "Chao Song",
                "Tianshuo Zhao",
                "Umair bin Waheed",
                "Cai Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03751v2",
                "http://arxiv.org/pdf/2311.03751v2"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03748v1",
            "title": "Unified Low-Resource Sequence Labeling by Sample-Aware Dynamic Sparse\n  Finetuning",
            "updated": "2023-11-07T06:19:37Z",
            "published": "2023-11-07T06:19:37Z",
            "summary": "Unified Sequence Labeling that articulates different sequence labeling\nproblems such as Named Entity Recognition, Relation Extraction, Semantic Role\nLabeling, etc. in a generalized sequence-to-sequence format opens up the\nopportunity to make the maximum utilization of large language model knowledge\ntoward structured prediction. Unfortunately, this requires formatting them into\nspecialized augmented format unknown to the base pretrained language model\n(PLMs) necessitating finetuning to the target format. This significantly bounds\nits usefulness in data-limited settings where finetuning large models cannot\nproperly generalize to the target format. To address this challenge and\nleverage PLM knowledge effectively, we propose FISH-DIP, a sample-aware dynamic\nsparse finetuning strategy that selectively focuses on a fraction of\nparameters, informed by feedback from highly regressing examples, during the\nfine-tuning process. By leveraging the dynamism of sparsity, our approach\nmitigates the impact of well-learned samples and prioritizes underperforming\ninstances for improvement in generalization. Across five tasks of sequence\nlabeling, we demonstrate that FISH-DIP can smoothly optimize the model in low\nresource settings offering upto 40% performance improvements over full\nfine-tuning depending on target evaluation settings. Also, compared to\nin-context learning and other parameter-efficient fine-tuning approaches,\nFISH-DIP performs comparably or better, notably in extreme low-resource\nsettings.",
            "author": [
                "Sarkar Snigdha Sarathi Das",
                "Ranran Haoran Zhang",
                "Peng Shi",
                "Wenpeng Yin",
                "Rui Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03748v1",
                "http://arxiv.org/pdf/2311.03748v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04247v1",
            "title": "Analysis and Applications of Deep Learning with Finite Samples in Full\n  Life-Cycle Intelligence of Nuclear Power Generation",
            "updated": "2023-11-07T06:17:57Z",
            "published": "2023-11-07T06:17:57Z",
            "summary": "The advent of Industry 4.0 has precipitated the incorporation of Artificial\nIntelligence (AI) methods within industrial contexts, aiming to realize\nintelligent manufacturing, operation as well as maintenance, also known as\nindustrial intelligence. However, intricate industrial milieus, particularly\nthose relating to energy exploration and production, frequently encompass data\ncharacterized by long-tailed class distribution, sample imbalance, and domain\nshift. These attributes pose noteworthy challenges to data-centric Deep\nLearning (DL) techniques, crucial for the realization of industrial\nintelligence. The present study centers on the intricate and distinctive\nindustrial scenarios of Nuclear Power Generation (NPG), meticulously\nscrutinizing the application of DL techniques under the constraints of finite\ndata samples. Initially, the paper expounds on potential employment scenarios\nfor AI across the full life-cycle of NPG. Subsequently, we delve into an\nevaluative exposition of DL's advancement, grounded in the finite sample\nperspective. This encompasses aspects such as small-sample learning, few-shot\nlearning, zero-shot learning, and open-set recognition, also referring to the\nunique data characteristics of NPG. The paper then proceeds to present two\nspecific case studies. The first revolves around the automatic recognition of\nzirconium alloy metallography, while the second pertains to open-set\nrecognition for signal diagnosis of machinery sensors. These cases, spanning\nthe entirety of NPG's life-cycle, are accompanied by constructive outcomes and\ninsightful deliberations. By exploring and applying DL methodologies within the\nconstraints of finite sample availability, this paper not only furnishes a\nrobust technical foundation but also introduces a fresh perspective toward the\nsecure and efficient advancement and exploitation of this advanced energy\nsource.",
            "author": [
                "Chenwei Tang",
                "Wenqiang Zhou",
                "Dong Wang",
                "Caiyang Yu",
                "Zhenan He",
                "Jizhe Zhou",
                "Shudong Huang",
                "Yi Gao",
                "Jianming Chen",
                "Wentao Feng",
                "Jiancheng Lv"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04247v1",
                "http://arxiv.org/pdf/2311.04247v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03746v1",
            "title": "Enhanced physics-informed neural networks with domain scaling and\n  residual correction methods for multi-frequency elliptic problems",
            "updated": "2023-11-07T06:08:47Z",
            "published": "2023-11-07T06:08:47Z",
            "summary": "In this paper, neural network approximation methods are developed for\nelliptic partial differential equations with multi-frequency solutions. Neural\nnetwork work approximation methods have advantages over classical approaches in\nthat they can be applied without much concerns on the form of the differential\nequations or the shape or dimension of the problem domain. When applied to\nproblems with multi-frequency solutions, the performance and accuracy of neural\nnetwork approximation methods are strongly affected by the contrast of the\nhigh- and low-frequency parts in the solutions. To address this issue, domain\nscaling and residual correction methods are proposed. The efficiency and\naccuracy of the proposed methods are demonstrated for multi-frequency model\nproblems.",
            "author": [
                "Deok-Kyu Jang",
                "Hyea Hyun Kim",
                "Kyungsoo Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03746v1",
                "http://arxiv.org/pdf/2311.03746v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.LG",
                "cs.NA",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03745v1",
            "title": "Unsupervised Video Summarization",
            "updated": "2023-11-07T06:01:56Z",
            "published": "2023-11-07T06:01:56Z",
            "summary": "This paper introduces a new, unsupervised method for automatic video\nsummarization using ideas from generative adversarial networks but eliminating\nthe discriminator, having a simple loss function, and separating training of\ndifferent parts of the model. An iterative training strategy is also applied by\nalternately training the reconstructor and the frame selector for multiple\niterations. Furthermore, a trainable mask vector is added to the model in\nsummary generation during training and evaluation. The method also includes an\nunsupervised model selection algorithm. Results from experiments on two public\ndatasets (SumMe and TVSum) and four datasets we created (Soccer, LoL, MLB, and\nShortMLB) demonstrate the effectiveness of each component on the model\nperformance, particularly the iterative training strategy. Evaluations and\ncomparisons with the state-of-the-art methods highlight the advantages of the\nproposed method in performance, stability, and training efficiency.",
            "author": [
                "Hanqing Li",
                "Diego Klabjan",
                "Jean Utke"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03745v1",
                "http://arxiv.org/pdf/2311.03745v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03742v1",
            "title": "3DifFusionDet: Diffusion Model for 3D Object Detection with Robust\n  LiDAR-Camera Fusion",
            "updated": "2023-11-07T05:53:09Z",
            "published": "2023-11-07T05:53:09Z",
            "summary": "Good 3D object detection performance from LiDAR-Camera sensors demands\nseamless feature alignment and fusion strategies. We propose the 3DifFusionDet\nframework in this paper, which structures 3D object detection as a denoising\ndiffusion process from noisy 3D boxes to target boxes. In this framework,\nground truth boxes diffuse in a random distribution for training, and the model\nlearns to reverse the noising process. During inference, the model gradually\nrefines a set of boxes that were generated at random to the outcomes. Under the\nfeature align strategy, the progressive refinement method could make a\nsignificant contribution to robust LiDAR-Camera fusion. The iterative\nrefinement process could also demonstrate great adaptability by applying the\nframework to various detecting circumstances where varying levels of accuracy\nand speed are required. Extensive experiments on KITTI, a benchmark for\nreal-world traffic object identification, revealed that 3DifFusionDet is able\nto perform favorably in comparison to earlier, well-respected detectors.",
            "author": [
                "Xinhao Xiang",
                "Simon Dr\u00e4ger",
                "Jiawei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03742v1",
                "http://arxiv.org/pdf/2311.03742v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03738v2",
            "title": "deep-REMAP: Parameterization of Stellar Spectra Using Regularized\n  Multi-Task Learning",
            "updated": "2023-11-21T19:55:29Z",
            "published": "2023-11-07T05:41:48Z",
            "summary": "Traditional spectral analysis methods are increasingly challenged by the\nexploding volumes of data produced by contemporary astronomical surveys. In\nresponse, we develop deep-Regularized Ensemble-based Multi-task Learning with\nAsymmetric Loss for Probabilistic Inference ($\\rm{deep-REMAP}$), a novel\nframework that utilizes the rich synthetic spectra from the PHOENIX library and\nobservational data from the MARVELS survey to accurately predict stellar\natmospheric parameters. By harnessing advanced machine learning techniques,\nincluding multi-task learning and an innovative asymmetric loss function,\n$\\rm{deep-REMAP}$ demonstrates superior predictive capabilities in determining\neffective temperature, surface gravity, and metallicity from observed spectra.\nOur results reveal the framework's effectiveness in extending to other stellar\nlibraries and properties, paving the way for more sophisticated and automated\ntechniques in stellar characterization.",
            "author": [
                "Sankalp Gilda"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03738v2",
                "http://arxiv.org/pdf/2311.03738v2"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.GA",
                "astro-ph.IM",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03736v1",
            "title": "Neural MMO 2.0: A Massively Multi-task Addition to Massively Multi-agent\n  Learning",
            "updated": "2023-11-07T05:36:39Z",
            "published": "2023-11-07T05:36:39Z",
            "summary": "Neural MMO 2.0 is a massively multi-agent environment for reinforcement\nlearning research. The key feature of this new version is a flexible task\nsystem that allows users to define a broad range of objectives and reward\nsignals. We challenge researchers to train agents capable of generalizing to\ntasks, maps, and opponents never seen during training. Neural MMO features\nprocedurally generated maps with 128 agents in the standard setting and support\nfor up to. Version 2.0 is a complete rewrite of its predecessor with three-fold\nimproved performance and compatibility with CleanRL. We release the platform as\nfree and open-source software with comprehensive documentation available at\nneuralmmo.github.io and an active community Discord. To spark initial research\non this new platform, we are concurrently running a competition at NeurIPS\n2023.",
            "author": [
                "Joseph Su\u00e1rez",
                "Phillip Isola",
                "Kyoung Whan Choe",
                "David Bloomin",
                "Hao Xiang Li",
                "Nikhil Pinnaparaju",
                "Nishaanth Kanna",
                "Daniel Scott",
                "Ryan Sullivan",
                "Rose S. Shuman",
                "Lucas de Alc\u00e2ntara",
                "Herbie Bradley",
                "Louis Castricato",
                "Kirsty You",
                "Yuhao Jiang",
                "Qimai Li",
                "Jiaxin Chen",
                "Xiaolong Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03736v1",
                "http://arxiv.org/pdf/2311.03736v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03733v1",
            "title": "Improved weight initialization for deep and narrow feedforward neural\n  network",
            "updated": "2023-11-07T05:28:12Z",
            "published": "2023-11-07T05:28:12Z",
            "summary": "Appropriate weight initialization settings, along with the ReLU activation\nfunction, have been a cornerstone of modern deep learning, making it possible\nto train and deploy highly effective and efficient neural network models across\ndiverse artificial intelligence. The problem of dying ReLU, where ReLU neurons\nbecome inactive and yield zero output, presents a significant challenge in the\ntraining of deep neural networks with ReLU activation function. Theoretical\nresearch and various methods have been introduced to address the problem.\nHowever, even with these methods and research, training remains challenging for\nextremely deep and narrow feedforward networks with ReLU activation function.\nIn this paper, we propose a new weight initialization method to address this\nissue. We prove the properties of the proposed initial weight matrix and\ndemonstrate how these properties facilitate the effective propagation of signal\nvectors. Through a series of experiments and comparisons with existing methods,\nwe demonstrate the effectiveness of the new initialization method.",
            "author": [
                "Hyunwoo Lee",
                "Yunho Kim",
                "Seungyeop Yang",
                "Hayoung Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03733v1",
                "http://arxiv.org/pdf/2311.03733v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03732v1",
            "title": "Learning to Learn for Few-shot Continual Active Learning",
            "updated": "2023-11-07T05:22:11Z",
            "published": "2023-11-07T05:22:11Z",
            "summary": "Continual learning strives to ensure stability in solving previously seen\ntasks while demonstrating plasticity in a novel domain. Recent advances in CL\nare mostly confined to a supervised learning setting, especially in NLP domain.\nIn this work, we consider a few-shot continual active learning (CAL) setting\nwhere labeled data is inadequate, and unlabeled data is abundant but with a\nlimited annotation budget. We propose a simple but efficient method, called\nMeta-Continual Active Learning. Specifically, we employ meta-learning and\nexperience replay to address the trade-off between stability and plasticity. As\na result, it finds an optimal initialization that efficiently utilizes\nannotated information for fast adaptation while preventing catastrophic\nforgetting of past tasks. We conduct extensive experiments to validate the\neffectiveness of the proposed method and analyze the effect of various active\nlearning strategies and memory sample selection methods in a few-shot CAL\nsetup. Our experiment results demonstrate that random sampling is the best\ndefault strategy for both active learning and memory sample selection to solve\nfew-shot CAL problems.",
            "author": [
                "Stella Ho",
                "Ming Liu",
                "Shang Gao",
                "Longxiang Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03732v1",
                "http://arxiv.org/pdf/2311.03732v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03725v2",
            "title": "DeepInspect: An AI-Powered Defect Detection for Manufacturing Industries",
            "updated": "2023-11-08T07:45:58Z",
            "published": "2023-11-07T04:59:43Z",
            "summary": "Utilizing Convolutional Neural Networks (CNNs), Recurrent Neural Networks\n(RNNs), and Generative Adversarial Networks (GANs), our system introduces an\ninnovative approach to defect detection in manufacturing. This technology\nexcels in precisely identifying faults by extracting intricate details from\nproduct photographs, utilizing RNNs to detect evolving errors and generating\nsynthetic defect data to bolster the model's robustness and adaptability across\nvarious defect scenarios. The project leverages a deep learning framework to\nautomate real-time flaw detection in the manufacturing process. It harnesses\nextensive datasets of annotated images to discern complex defect patterns. This\nintegrated system seamlessly fits into production workflows, thereby boosting\nefficiency and elevating product quality. As a result, it reduces waste and\noperational costs, ultimately enhancing market competitiveness.",
            "author": [
                "Arti Kumbhar",
                "Amruta Chougule",
                "Priya Lokhande",
                "Saloni Navaghane",
                "Aditi Burud",
                "Saee Nimbalkar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03725v2",
                "http://arxiv.org/pdf/2311.03725v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03721v1",
            "title": "ClimateSet: A Large-Scale Climate Model Dataset for Machine Learning",
            "updated": "2023-11-07T04:55:36Z",
            "published": "2023-11-07T04:55:36Z",
            "summary": "Climate models have been key for assessing the impact of climate change and\nsimulating future climate scenarios. The machine learning (ML) community has\ntaken an increased interest in supporting climate scientists' efforts on\nvarious tasks such as climate model emulation, downscaling, and prediction\ntasks. Many of those tasks have been addressed on datasets created with single\nclimate models. However, both the climate science and ML communities have\nsuggested that to address those tasks at scale, we need large, consistent, and\nML-ready climate model datasets. Here, we introduce ClimateSet, a dataset\ncontaining the inputs and outputs of 36 climate models from the Input4MIPs and\nCMIP6 archives. In addition, we provide a modular dataset pipeline for\nretrieving and preprocessing additional climate models and scenarios. We\nshowcase the potential of our dataset by using it as a benchmark for ML-based\nclimate model emulation. We gain new insights about the performance and\ngeneralization capabilities of the different ML models by analyzing their\nperformance across different climate models. Furthermore, the dataset can be\nused to train an ML emulator on several climate models instead of just one.\nSuch a \"super emulator\" can quickly project new climate change scenarios,\ncomplementing existing scenarios already provided to policymakers. We believe\nClimateSet will create the basis needed for the ML community to tackle\nclimate-related tasks at scale.",
            "author": [
                "Julia Kaltenborn",
                "Charlotte E. E. Lange",
                "Venkatesh Ramesh",
                "Philippe Brouillard",
                "Yaniv Gurwicz",
                "Chandni Nagda",
                "Jakob Runge",
                "Peer Nowack",
                "David Rolnick"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03721v1",
                "http://arxiv.org/pdf/2311.03721v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CE",
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03714v1",
            "title": "Loss Balancing for Fair Supervised Learning",
            "updated": "2023-11-07T04:36:13Z",
            "published": "2023-11-07T04:36:13Z",
            "summary": "Supervised learning models have been used in various domains such as lending,\ncollege admission, face recognition, natural language processing, etc. However,\nthey may inherit pre-existing biases from training data and exhibit\ndiscrimination against protected social groups. Various fairness notions have\nbeen proposed to address unfairness issues. In this work, we focus on Equalized\nLoss (EL), a fairness notion that requires the expected loss to be\n(approximately) equalized across different groups. Imposing EL on the learning\nprocess leads to a non-convex optimization problem even if the loss function is\nconvex, and the existing fair learning algorithms cannot properly be adopted to\nfind the fair predictor under the EL constraint. This paper introduces an\nalgorithm that can leverage off-the-shelf convex programming tools (e.g.,\nCVXPY) to efficiently find the global optimum of this non-convex optimization.\nIn particular, we propose the ELminimizer algorithm, which finds the optimal\nfair predictor under EL by reducing the non-convex optimization to a sequence\nof convex optimization problems. We theoretically prove that our algorithm\nfinds the global optimal solution under certain conditions. Then, we support\nour theoretical results through several empirical studies.",
            "author": [
                "Mohammad Mahdi Khalili",
                "Xueru Zhang",
                "Mahed Abroshan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03714v1",
                "http://arxiv.org/pdf/2311.03714v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03713v1",
            "title": "Multimodal deep representation learning for quantum cross-platform\n  verification",
            "updated": "2023-11-07T04:35:03Z",
            "published": "2023-11-07T04:35:03Z",
            "summary": "Cross-platform verification, a critical undertaking in the realm of\nearly-stage quantum computing, endeavors to characterize the similarity of two\nimperfect quantum devices executing identical algorithms, utilizing minimal\nmeasurements. While the random measurement approach has been instrumental in\nthis context, the quasi-exponential computational demand with increasing qubit\ncount hurdles its feasibility in large-qubit scenarios. To bridge this\nknowledge gap, here we introduce an innovative multimodal learning approach,\nrecognizing that the formalism of data in this task embodies two distinct\nmodalities: measurement outcomes and classical description of compiled circuits\non explored quantum devices, both enriched with unique information. Building\nupon this insight, we devise a multimodal neural network to independently\nextract knowledge from these modalities, followed by a fusion operation to\ncreate a comprehensive data representation. The learned representation can\neffectively characterize the similarity between the explored quantum devices\nwhen executing new quantum algorithms not present in the training data. We\nevaluate our proposal on platforms featuring diverse noise models, encompassing\nsystem sizes up to 50 qubits. The achieved results demonstrate a\nthree-orders-of-magnitude improvement in prediction accuracy compared to the\nrandom measurements and offer compelling evidence of the complementary roles\nplayed by each modality in cross-platform verification. These findings pave the\nway for harnessing the power of multimodal learning to overcome challenges in\nwider quantum system learning tasks.",
            "author": [
                "Yang Qian",
                "Yuxuan Du",
                "Zhenliang He",
                "Min-hsiu Hsieh",
                "Dacheng Tao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03713v1",
                "http://arxiv.org/pdf/2311.03713v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03711v1",
            "title": "Mitigating Estimation Errors by Twin TD-Regularized Actor and Critic for\n  Deep Reinforcement Learning",
            "updated": "2023-11-07T04:30:51Z",
            "published": "2023-11-07T04:30:51Z",
            "summary": "We address the issue of estimation bias in deep reinforcement learning (DRL)\nby introducing solution mechanisms that include a new, twin TD-regularized\nactor-critic (TDR) method. It aims at reducing both over and under-estimation\nerrors. With TDR and by combining good DRL improvements, such as distributional\nlearning and long N-step surrogate stage reward (LNSS) method, we show that our\nnew TDR-based actor-critic learning has enabled DRL methods to outperform their\nrespective baselines in challenging environments in DeepMind Control Suite.\nFurthermore, they elevate TD3 and SAC respectively to a level of performance\ncomparable to that of D4PG (the current SOTA), and they also improve the\nperformance of D4PG to a new SOTA level measured by mean reward, convergence\nspeed, learning success rate, and learning variance.",
            "author": [
                "Junmin Zhong",
                "Ruofan Wu",
                "Jennie Si"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03711v1",
                "http://arxiv.org/pdf/2311.03711v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03707v1",
            "title": "The NeurIPS 2022 Neural MMO Challenge: A Massively Multiagent\n  Competition with Specialization and Trade",
            "updated": "2023-11-07T04:14:45Z",
            "published": "2023-11-07T04:14:45Z",
            "summary": "In this paper, we present the results of the NeurIPS-2022 Neural MMO\nChallenge, which attracted 500 participants and received over 1,600\nsubmissions. Like the previous IJCAI-2022 Neural MMO Challenge, it involved\nagents from 16 populations surviving in procedurally generated worlds by\ncollecting resources and defeating opponents. This year's competition runs on\nthe latest v1.6 Neural MMO, which introduces new equipment, combat, trading,\nand a better scoring system. These elements combine to pose additional\nrobustness and generalization challenges not present in previous competitions.\nThis paper summarizes the design and results of the challenge, explores the\npotential of this environment as a benchmark for learning methods, and presents\nsome practical reinforcement learning training approaches for complex tasks\nwith sparse rewards. Additionally, we have open-sourced our baselines,\nincluding environment wrappers, benchmarks, and visualization tools for future\nresearch.",
            "author": [
                "Enhong Liu",
                "Joseph Suarez",
                "Chenhui You",
                "Bo Wu",
                "Bingcheng Chen",
                "Jun Hu",
                "Jiaxin Chen",
                "Xiaolong Zhu",
                "Clare Zhu",
                "Julian Togelius",
                "Sharada Mohanty",
                "Weijun Hong",
                "Rui Du",
                "Yibing Zhang",
                "Qinwen Wang",
                "Xinhang Li",
                "Zheng Yuan",
                "Xiang Li",
                "Yuejia Huang",
                "Kun Zhang",
                "Hanhui Yang",
                "Shiqi Tang",
                "Phillip Isola"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03707v1",
                "http://arxiv.org/pdf/2311.03707v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03703v1",
            "title": "Pipeline Parallelism for DNN Inference with Practical Performance\n  Guarantees",
            "updated": "2023-11-07T03:55:39Z",
            "published": "2023-11-07T03:55:39Z",
            "summary": "We optimize pipeline parallelism for deep neural network (DNN) inference by\npartitioning model graphs into $k$ stages and minimizing the running time of\nthe bottleneck stage, including communication. We design practical algorithms\nfor this NP-hard problem and show that they are nearly optimal in practice by\ncomparing against strong lower bounds obtained via novel mixed-integer\nprogramming (MIP) formulations. We apply these algorithms and lower-bound\nmethods to production models to achieve substantially improved approximation\nguarantees compared to standard combinatorial lower bounds. For example,\nevaluated via geometric means across production data with $k=16$ pipeline\nstages, our MIP formulations more than double the lower bounds, improving the\napproximation ratio from $2.175$ to $1.058$. This work shows that while\nmax-throughput partitioning is theoretically hard, we have a handle on the\nalgorithmic side of the problem in practice and much of the remaining challenge\nis in developing more accurate cost models to feed into the partitioning\nalgorithms.",
            "author": [
                "Aaron Archer",
                "Matthew Fahrbach",
                "Kuikui Liu",
                "Prakash Prabhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03703v1",
                "http://arxiv.org/pdf/2311.03703v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03701v1",
            "title": "Hypothesis Network Planned Exploration for Rapid Meta-Reinforcement\n  Learning Adaptation",
            "updated": "2023-11-07T03:53:52Z",
            "published": "2023-11-07T03:53:52Z",
            "summary": "Meta Reinforcement Learning (Meta RL) trains agents that adapt to\nfast-changing environments and tasks. Current strategies often lose adaption\nefficiency due to the passive nature of model exploration, causing delayed\nunderstanding of new transition dynamics. This results in particularly\nfast-evolving tasks being impossible to solve. We propose a novel approach,\nHypothesis Network Planned Exploration (HyPE), that integrates an active and\nplanned exploration process via the hypothesis network to optimize adaptation\nspeed. HyPE uses a generative hypothesis network to form potential models of\nstate transition dynamics, then eliminates incorrect models through\nstrategically devised experiments. Evaluated on a symbolic version of the\nAlchemy game, HyPE outpaces baseline methods in adaptation speed and model\naccuracy, validating its potential in enhancing reinforcement learning\nadaptation in rapidly evolving settings.",
            "author": [
                "Maxwell Joseph Jacobson",
                "Yexiang Xue"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03701v1",
                "http://arxiv.org/pdf/2311.03701v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03698v2",
            "title": "A Novel Variational Lower Bound for Inverse Reinforcement Learning",
            "updated": "2023-11-10T13:26:24Z",
            "published": "2023-11-07T03:50:43Z",
            "summary": "Inverse reinforcement learning (IRL) seeks to learn the reward function from\nexpert trajectories, to understand the task for imitation or collaboration\nthereby removing the need for manual reward engineering. However, IRL in the\ncontext of large, high-dimensional problems with unknown dynamics has been\nparticularly challenging. In this paper, we present a new Variational Lower\nBound for IRL (VLB-IRL), which is derived under the framework of a\nprobabilistic graphical model with an optimality node. Our method\nsimultaneously learns the reward function and policy under the learned reward\nfunction by maximizing the lower bound, which is equivalent to minimizing the\nreverse Kullback-Leibler divergence between an approximated distribution of\noptimality given the reward function and the true distribution of optimality\ngiven trajectories. This leads to a new IRL method that learns a valid reward\nfunction such that the policy under the learned reward achieves expert-level\nperformance on several known domains. Importantly, the method outperforms the\nexisting state-of-the-art IRL algorithms on these domains by demonstrating\nbetter reward from the learned policy.",
            "author": [
                "Yikang Gui",
                "Prashant Doshi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03698v2",
                "http://arxiv.org/pdf/2311.03698v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03695v1",
            "title": "Context Shift Reduction for Offline Meta-Reinforcement Learning",
            "updated": "2023-11-07T03:50:01Z",
            "published": "2023-11-07T03:50:01Z",
            "summary": "Offline meta-reinforcement learning (OMRL) utilizes pre-collected offline\ndatasets to enhance the agent's generalization ability on unseen tasks.\nHowever, the context shift problem arises due to the distribution discrepancy\nbetween the contexts used for training (from the behavior policy) and testing\n(from the exploration policy). The context shift problem leads to incorrect\ntask inference and further deteriorates the generalization ability of the\nmeta-policy. Existing OMRL methods either overlook this problem or attempt to\nmitigate it with additional information. In this paper, we propose a novel\napproach called Context Shift Reduction for OMRL (CSRO) to address the context\nshift problem with only offline datasets. The key insight of CSRO is to\nminimize the influence of policy in context during both the meta-training and\nmeta-test phases. During meta-training, we design a max-min mutual information\nrepresentation learning mechanism to diminish the impact of the behavior policy\non task representation. In the meta-test phase, we introduce the non-prior\ncontext collection strategy to reduce the effect of the exploration policy.\nExperimental results demonstrate that CSRO significantly reduces the context\nshift and improves the generalization ability, surpassing previous methods\nacross various challenging domains.",
            "author": [
                "Yunkai Gao",
                "Rui Zhang",
                "Jiaming Guo",
                "Fan Wu",
                "Qi Yi",
                "Shaohui Peng",
                "Siming Lan",
                "Ruizhi Chen",
                "Zidong Du",
                "Xing Hu",
                "Qi Guo",
                "Ling Li",
                "Yunji Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03695v1",
                "http://arxiv.org/pdf/2311.03695v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03687v2",
            "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and\n  Inference of Large Language Models",
            "updated": "2023-12-01T15:37:07Z",
            "published": "2023-11-07T03:25:56Z",
            "summary": "Large Language Models (LLMs) have seen great advance in both academia and\nindustry, and their popularity results in numerous open-source frameworks and\ntechniques in accelerating LLM pre-training, fine-tuning, and inference.\nTraining and deploying LLMs are expensive as it requires considerable computing\nresources and memory, hence many efficient approaches have been developed for\nimproving system pipelines as well as operators. However, the runtime\nperformance can vary significantly across hardware and software stacks, which\nmakes it difficult to choose the best configuration. In this work, we aim to\nbenchmark the performance from both macro and micro perspectives. First, we\nbenchmark the end-to-end performance of pre-training, fine-tuning, and serving\nLLMs in different sizes , i.e., 7, 13, and 70 billion parameters (7B, 13B, and\n70B) on three 8-GPU platforms with and without individual optimization\ntechniques, including ZeRO, quantization, recomputation, FlashAttention. Then,\nwe dive deeper to provide a detailed runtime analysis of the sub-modules,\nincluding computing and communication operators in LLMs. For end users, our\nbenchmark and findings help better understand different optimization\ntechniques, training and inference frameworks, together with hardware platforms\nin choosing configurations for deploying LLMs. For researchers, our in-depth\nmodule-wise analyses discover potential opportunities for future work to\nfurther optimize the runtime performance of LLMs.",
            "author": [
                "Longteng Zhang",
                "Xiang Liu",
                "Zeyu Li",
                "Xinglin Pan",
                "Peijie Dong",
                "Ruibo Fan",
                "Rui Guo",
                "Xin Wang",
                "Qiong Luo",
                "Shaohuai Shi",
                "Xiaowen Chu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03687v2",
                "http://arxiv.org/pdf/2311.03687v2"
            ],
            "primary_category": "cs.PF",
            "category": [
                "cs.PF",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03685v1",
            "title": "Dynamic Non-monotone Submodular Maximization",
            "updated": "2023-11-07T03:20:02Z",
            "published": "2023-11-07T03:20:02Z",
            "summary": "Maximizing submodular functions has been increasingly used in many\napplications of machine learning, such as data summarization, recommendation\nsystems, and feature selection. Moreover, there has been a growing interest in\nboth submodular maximization and dynamic algorithms. In 2020, Monemizadeh and\nLattanzi, Mitrovic, Norouzi{-}Fard, Tarnawski, and Zadimoghaddam initiated\ndeveloping dynamic algorithms for the monotone submodular maximization problem\nunder the cardinality constraint $k$. Recently, there have been some\nimprovements on the topic made by Banihashem, Biabani, Goudarzi, Hajiaghayi,\nJabbarzade, and Monemizadeh. In 2022, Chen and Peng studied the complexity of\nthis problem and raised an important open question: \"Can we extend [fully\ndynamic] results (algorithm or hardness) to non-monotone submodular\nmaximization?\". We affirmatively answer their question by demonstrating a\nreduction from maximizing a non-monotone submodular function under the\ncardinality constraint $k$ to maximizing a monotone submodular function under\nthe same constraint. Through this reduction, we obtain the first dynamic\nalgorithms to solve the non-monotone submodular maximization problem under the\ncardinality constraint $k$. Our algorithms maintain an\n$(8+\\epsilon)$-approximate of the solution and use expected amortized\n$O(\\epsilon^{-3}k^3\\log^3(n)\\log(k))$ or $O(\\epsilon^{-1}k^2\\log^3(k))$ oracle\nqueries per update, respectively. Furthermore, we showcase the benefits of our\ndynamic algorithm for video summarization and max-cut problems on several\nreal-world data sets.",
            "author": [
                "Kiarash Banihashem",
                "Leyla Biabani",
                "Samira Goudarzi",
                "MohammadTaghi Hajiaghayi",
                "Peyman Jabbarzade",
                "Morteza Monemizadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03685v1",
                "http://arxiv.org/pdf/2311.03685v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03684v1",
            "title": "Reinforcement learning pulses for transmon qubit entangling gates",
            "updated": "2023-11-07T03:19:19Z",
            "published": "2023-11-07T03:19:19Z",
            "summary": "The utility of a quantum computer depends heavily on the ability to reliably\nperform accurate quantum logic operations. For finding optimal control\nsolutions, it is of particular interest to explore model-free approaches, since\ntheir quality is not constrained by the limited accuracy of theoretical models\nfor the quantum processor - in contrast to many established gate implementation\nstrategies. In this work, we utilize a continuous-control reinforcement\nlearning algorithm to design entangling two-qubit gates for superconducting\nqubits; specifically, our agent constructs cross-resonance and CNOT gates\nwithout any prior information about the physical system. Using a simulated\nenvironment of fixed-frequency, fixed-coupling transmon qubits, we demonstrate\nthe capability to generate novel pulse sequences that outperform the standard\ncross-resonance gates in both fidelity and gate duration, while maintaining a\ncomparable susceptibility to stochastic unitary noise. We further showcase an\naugmentation in training and input information that allows our agent to adapt\nits pulse design abilities to drifting hardware characteristics, importantly\nwith little to no additional optimization. Our results exhibit clearly the\nadvantages of unbiased adaptive-feedback learning-based optimization methods\nfor transmon gate design.",
            "author": [
                "Ho Nam Nguyen",
                "Felix Motzoi",
                "Mekena Metcalf",
                "K. Birgitta Whaley",
                "Marin Bukov",
                "Markus Schmitt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03684v1",
                "http://arxiv.org/pdf/2311.03684v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03683v1",
            "title": "Preventing Arbitrarily High Confidence on Far-Away Data in\n  Point-Estimated Discriminative Neural Networks",
            "updated": "2023-11-07T03:19:16Z",
            "published": "2023-11-07T03:19:16Z",
            "summary": "Discriminatively trained, deterministic neural networks are the de facto\nchoice for classification problems. However, even though they achieve\nstate-of-the-art results on in-domain test sets, they tend to be overconfident\non out-of-distribution (OOD) data. For instance, ReLU networks -- a popular\nclass of neural network architectures -- have been shown to almost always yield\nhigh confidence predictions when the test data are far away from the training\nset, even when they are trained with OOD data. We overcome this problem by\nadding a term to the output of the neural network that corresponds to the logit\nof an extra class, that we design to dominate the logits of the original\nclasses as we move away from the training data.This technique provably prevents\narbitrarily high confidence on far-away test data while maintaining a simple\ndiscriminative point-estimate training. Evaluation on various benchmarks\ndemonstrates strong performance against competitive baselines on both far-away\nand realistic OOD data.",
            "author": [
                "Ahmad Rashid",
                "Serena Hacker",
                "Guojun Zhang",
                "Agustinus Kristiadi",
                "Pascal Poupart"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03683v1",
                "http://arxiv.org/pdf/2311.03683v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03680v1",
            "title": "Deep Bayesian Reinforcement Learning for Spacecraft Proximity Maneuvers\n  and Docking",
            "updated": "2023-11-07T03:12:58Z",
            "published": "2023-11-07T03:12:58Z",
            "summary": "In the pursuit of autonomous spacecraft proximity maneuvers and docking(PMD),\nwe introduce a novel Bayesian actor-critic reinforcement learning algorithm to\nlearn a control policy with the stability guarantee. The PMD task is formulated\nas a Markov decision process that reflects the relative dynamic model, the\ndocking cone and the cost function. Drawing from the principles of Lyapunov\ntheory, we frame the temporal difference learning as a constrained Gaussian\nprocess regression problem. This innovative approach allows the state-value\nfunction to be expressed as a Lyapunov function, leveraging the Gaussian\nprocess and deep kernel learning. We develop a novel Bayesian quadrature policy\noptimization procedure to analytically compute the policy gradient while\nintegrating Lyapunov-based stability constraints. This integration is pivotal\nin satisfying the rigorous safety demands of spaceflight missions. The proposed\nalgorithm has been experimentally evaluated on a spacecraft air-bearing testbed\nand shows impressive and promising performance.",
            "author": [
                "Desong Du",
                "Naiming Qi",
                "Yanfang Liu",
                "Wei Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03680v1",
                "http://arxiv.org/pdf/2311.03680v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03679v1",
            "title": "Unsupervised convolutional neural network fusion approach for change\n  detection in remote sensing images",
            "updated": "2023-11-07T03:10:17Z",
            "published": "2023-11-07T03:10:17Z",
            "summary": "With the rapid development of deep learning, a variety of change detection\nmethods based on deep learning have emerged in recent years. However, these\nmethods usually require a large number of training samples to train the network\nmodel, so it is very expensive. In this paper, we introduce a completely\nunsupervised shallow convolutional neural network (USCNN) fusion approach for\nchange detection. Firstly, the bi-temporal images are transformed into\ndifferent feature spaces by using convolution kernels of different sizes to\nextract multi-scale information of the images. Secondly, the output features of\nbi-temporal images at the same convolution kernels are subtracted to obtain the\ncorresponding difference images, and the difference feature images at the same\nscale are fused into one feature image by using 1 * 1 convolution layer.\nFinally, the output features of different scales are concatenated and a 1 * 1\nconvolution layer is used to fuse the multi-scale information of the image. The\nmodel parameters are obtained by a redesigned sparse function. Our model has\nthree features: the entire training process is conducted in an unsupervised\nmanner, the network architecture is shallow, and the objective function is\nsparse. Thus, it can be seen as a kind of lightweight network model.\nExperimental results on four real remote sensing datasets indicate the\nfeasibility and effectiveness of the proposed approach.",
            "author": [
                "Weidong Yan",
                "Pei Yan",
                "Li Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03679v1",
                "http://arxiv.org/pdf/2311.03679v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03678v1",
            "title": "Classifications of Fermi-LAT unassociated sources in multiple machine\n  learning methods",
            "updated": "2023-11-07T03:10:11Z",
            "published": "2023-11-07T03:10:11Z",
            "summary": "The classifications of Fermi-LAT unassociated sources are studied using\nmultiple machine learning (ML) methods. The update data from 4FGL-DR3 are\ndivided into high Galactic latitude (HGL, Galactic latitude $|b|>10^\\circ$) and\nlow Galactic latitude (LGL, $|b|\\le10^\\circ$) regions. In the HGL region, a\nvoting ensemble of four binary ML classifiers achieves a 91$\\%$ balanced\naccuracy. In the LGL region, an additional Bayesian-Gaussian (BG) model with\nthree parameters is introduced to eliminate abnormal soft spectrum AGNs from\nthe training set and ML-identified AGN candidates, a voting ensemble of four\nternary ML algorithms reach an 81$\\%$ balanced accuracy. And then, a catalog of\nFermi-LAT all-sky unassociated sources is constructed. Our classification\nresults show that (i) there are 1037 AGN candidates and 88 pulsar candidates\nwith a balanced accuracy of $0.918 \\pm 0.029$ in HGL region, which are\nconsistent with those given in previous all-sky ML approaches; and (ii) there\nare 290 AGN-like candidates, 135 pulsar-like candidates, and 742 other-like\ncandidates with a balanced accuracy of $0.815 \\pm 0.027$ in the LGL region,\nwhich are different from those in previous all-sky ML approaches. Additionally,\ndifferent training sets and class weights were tested for their impact on\nclassifier accuracy and predicted results. The findings suggest that while\ndifferent training approaches can yield similar model accuracy, the predicted\nnumbers across different categories can vary significantly. Thus, reliable\nevaluation of the predicted results is deemed crucial in the ML approach for\nFermi-LAT unassociated sources.",
            "author": [
                "K. R. Zhu",
                "J. M. Chen",
                "Y. G. Zheng",
                "L. Zhang"
            ],
            "link": [
                "http://dx.doi.org/10.1093/mnras/stad2813",
                "http://arxiv.org/abs/2311.03678v1",
                "http://arxiv.org/pdf/2311.03678v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03672v1",
            "title": "CBSiMT: Mitigating Hallucination in Simultaneous Machine Translation\n  with Weighted Prefix-to-Prefix Training",
            "updated": "2023-11-07T02:44:45Z",
            "published": "2023-11-07T02:44:45Z",
            "summary": "Simultaneous machine translation (SiMT) is a challenging task that requires\nstarting translation before the full source sentence is available.\nPrefix-to-prefix framework is often applied to SiMT, which learns to predict\ntarget tokens using only a partial source prefix. However, due to the word\norder difference between languages, misaligned prefix pairs would make SiMT\nmodels suffer from serious hallucination problems, i.e. target outputs that are\nunfaithful to source inputs. Such problems can not only produce target tokens\nthat are not supported by the source prefix, but also hinder generating the\ncorrect translation by receiving more source words. In this work, we propose a\nConfidence-Based Simultaneous Machine Translation (CBSiMT) framework, which\nuses model confidence to perceive hallucination tokens and mitigates their\nnegative impact with weighted prefix-to-prefix training. Specifically,\ntoken-level and sentence-level weights are calculated based on model confidence\nand acted on the loss function. We explicitly quantify the faithfulness of the\ngenerated target tokens using the token-level weight, and employ the\nsentence-level weight to alleviate the disturbance of sentence pairs with\nserious word order differences on the model. Experimental results on MuST-C\nEnglish-to-Chinese and WMT15 German-to-English SiMT tasks demonstrate that our\nmethod can consistently improve translation quality at most latency regimes,\nwith up to 2 BLEU scores improvement at low latency.",
            "author": [
                "Mengge Liu",
                "Wen Zhang",
                "Xiang Li",
                "Yanzhi Tian",
                "Yuhang Guo",
                "Jian Luan",
                "Bin Wang",
                "Shuoying Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03672v1",
                "http://arxiv.org/pdf/2311.03672v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03669v1",
            "title": "Stable Modular Control via Contraction Theory for Reinforcement Learning",
            "updated": "2023-11-07T02:41:02Z",
            "published": "2023-11-07T02:41:02Z",
            "summary": "We propose a novel way to integrate control techniques with reinforcement\nlearning (RL) for stability, robustness, and generalization: leveraging\ncontraction theory to realize modularity in neural control, which ensures that\ncombining stable subsystems can automatically preserve the stability. We\nrealize such modularity via signal composition and dynamic decomposition.\nSignal composition creates the latent space, within which RL applies to\nmaximizing rewards. Dynamic decomposition is realized by coordinate\ntransformation that creates an auxiliary space, within which the latent signals\nare coupled in the way that their combination can preserve stability provided\neach signal, that is, each subsystem, has stable self-feedbacks. Leveraging\nmodularity, the nonlinear stability problem is deconstructed into algebraically\nsolvable ones, the stability of the subsystems in the auxiliary space, yielding\nlinear constraints on the input gradients of control networks that can be as\nsimple as switching the signs of network weights. This minimally invasive\nmethod for stability allows arguably easy integration into the modular neural\narchitectures in machine learning, like hierarchical RL, and improves their\nperformance. We demonstrate in simulation the necessity and the effectiveness\nof our method: the necessity for robustness and generalization, and the\neffectiveness in improving hierarchical RL for manipulation learning.",
            "author": [
                "Bing Song",
                "Jean-Jacques Slotine",
                "Quang-Cuong Pham"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03669v1",
                "http://arxiv.org/pdf/2311.03669v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04245v1",
            "title": "GPT-ST: Generative Pre-Training of Spatio-Temporal Graph Neural Networks",
            "updated": "2023-11-07T02:36:24Z",
            "published": "2023-11-07T02:36:24Z",
            "summary": "In recent years, there has been a rapid development of spatio-temporal\nprediction techniques in response to the increasing demands of traffic\nmanagement and travel planning. While advanced end-to-end models have achieved\nnotable success in improving predictive performance, their integration and\nexpansion pose significant challenges. This work aims to address these\nchallenges by introducing a spatio-temporal pre-training framework that\nseamlessly integrates with downstream baselines and enhances their performance.\nThe framework is built upon two key designs: (i) We propose a spatio-temporal\nmask autoencoder as a pre-training model for learning spatio-temporal\ndependencies. The model incorporates customized parameter learners and\nhierarchical spatial pattern encoding networks. These modules are specifically\ndesigned to capture spatio-temporal customized representations and intra- and\ninter-cluster region semantic relationships, which have often been neglected in\nexisting approaches. (ii) We introduce an adaptive mask strategy as part of the\npre-training mechanism. This strategy guides the mask autoencoder in learning\nrobust spatio-temporal representations and facilitates the modeling of\ndifferent relationships, ranging from intra-cluster to inter-cluster, in an\neasy-to-hard training manner. Extensive experiments conducted on representative\nbenchmarks demonstrate the effectiveness of our proposed method. We have made\nour model implementation publicly available at https://github.com/HKUDS/GPT-ST.",
            "author": [
                "Zhonghang Li",
                "Lianghao Xia",
                "Yong Xu",
                "Chao Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04245v1",
                "http://arxiv.org/pdf/2311.04245v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16145v1",
            "title": "Dual-Stream Attention Transformers for Sewer Defect Classification",
            "updated": "2023-11-07T02:31:51Z",
            "published": "2023-11-07T02:31:51Z",
            "summary": "We propose a dual-stream multi-scale vision transformer (DS-MSHViT)\narchitecture that processes RGB and optical flow inputs for efficient sewer\ndefect classification. Unlike existing methods that combine the predictions of\ntwo separate networks trained on each modality, we jointly train a single\nnetwork with two branches for RGB and motion. Our key idea is to use\nself-attention regularization to harness the complementary strengths of the RGB\nand motion streams. The motion stream alone struggles to generate accurate\nattention maps, as motion images lack the rich visual features present in RGB\nimages. To facilitate this, we introduce an attention consistency loss between\nthe dual streams. By leveraging motion cues through a self-attention\nregularizer, we align and enhance RGB attention maps, enabling the network to\nconcentrate on pertinent input regions. We evaluate our data on a public\ndataset as well as cross-validate our model performance in a novel dataset. Our\nmethod outperforms existing models that utilize either convolutional neural\nnetworks (CNNs) or multi-scale hybrid vision transformers (MSHViTs) without\nemploying attention regularization between the two streams.",
            "author": [
                "Abdullah Al Redwan Newaz",
                "Mahdi Abdeldguerfi",
                "Kendall N. Niles",
                "Joe Tom"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16145v1",
                "http://arxiv.org/pdf/2311.16145v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03663v2",
            "title": "Principles from Clinical Research for NLP Model Generalization",
            "updated": "2023-11-09T15:09:04Z",
            "published": "2023-11-07T02:17:25Z",
            "summary": "The NLP community typically relies on performance of a model on a held-out\ntest set to assess generalization. Performance drops observed in datasets\noutside of official test sets are generally attributed to\n\"out-of-distribution'' effects. Here, we explore the foundations of\ngeneralizability and study the various factors that affect it, articulating\ngeneralizability lessons from clinical studies. In clinical research\ngeneralizability depends on (a) internal validity of experiments to ensure\ncontrolled measurement of cause and effect, and (b) external validity or\ntransportability of the results to the wider population. We present the need to\nensure internal validity when building machine learning models in natural\nlanguage processing, especially where results may be impacted by spurious\ncorrelations in the data. We demonstrate how spurious factors, such as the\ndistance between entities in relation extraction tasks, can affect model\ninternal validity and in turn adversely impact generalization. We also offer\nguidance on how to analyze generalization failures.",
            "author": [
                "Aparna Elangovan",
                "Jiayuan He",
                "Yuan Li",
                "Karin Verspoor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03663v2",
                "http://arxiv.org/pdf/2311.03663v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03661v1",
            "title": "Graph Neural Networks for Power Grid Operational Risk Assessment",
            "updated": "2023-11-07T02:16:50Z",
            "published": "2023-11-07T02:16:50Z",
            "summary": "In this article, the utility of graph neural network (GNN) surrogates for\nMonte Carlo (MC) sampling-based risk quantification in daily operations of\npower grid is investigated. The MC simulation process necessitates solving a\nlarge number of optimal power flow (OPF) problems corresponding to the sample\nvalues of stochastic grid variables (power demand and renewable generation),\nwhich is computationally prohibitive. Computationally inexpensive surrogates of\nthe OPF problem provide an attractive alternative for expedited MC simulation.\nGNN surrogates are especially suitable due to their superior ability to handle\ngraph-structured data. Therefore, GNN surrogates of OPF problem are trained\nusing supervised learning. They are then used to obtain Monte Carlo (MC)\nsamples of the quantities of interest (operating reserve, transmission line\nflow) given the (hours-ahead) probabilistic wind generation and load forecast.\nThe utility of GNN surrogates is evaluated by comparing OPF-based and GNN-based\ngrid reliability and risk for IEEE Case118 synthetic grid. It is shown that the\nGNN surrogates are sufficiently accurate for predicting the (bus-level,\nbranch-level and system-level) grid state and enable fast as well as accurate\noperational risk quantification for power grids. The article thus develops\nvarious tools for fast reliability and risk quantification for real-world power\ngrids using GNNs.",
            "author": [
                "Yadong Zhang",
                "Pranav M Karve",
                "Sankaran Mahadevan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03661v1",
                "http://arxiv.org/pdf/2311.03661v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03659v1",
            "title": "GNN-Based Beamforming for Sum-Rate Maximization in MU-MISO Networks",
            "updated": "2023-11-07T02:08:25Z",
            "published": "2023-11-07T02:08:25Z",
            "summary": "The advantages of graph neural networks (GNNs) in leveraging the graph\ntopology of wireless networks have drawn increasing attentions. This paper\nstudies the GNN-based learning approach for the sum-rate maximization in\nmultiple-user multiple-input single-output (MU-MISO) networks subject to the\nusers' individual data rate requirements and the power budget of the base\nstation. By modeling the MU-MISO network as a graph, a GNN-based architecture\nnamed CRGAT is proposed to directly map the channel state information to the\nbeamforming vectors. The attention-enabled aggregation and the\nresidual-assisted combination are adopted to enhance the learning capability\nand avoid the oversmoothing issue. Furthermore, a novel activation function is\nproposed for the constraint due to the limited power budget at the base\nstation. The CRGAT is trained in an unsupervised learning manner with two\nproposed loss functions. An evaluation method is proposed for the\nlearning-based approach, based on which the effectiveness of the proposed CRGAT\nis validated in comparison with several convex optimization and learning based\napproaches. Numerical results are provided to reveal the advantages of the\nCRGAT including the millisecond-level response with limited optimality\nperformance loss, the scalability to different number of users and power\nbudgets, and the adaptability to different system settings.",
            "author": [
                "Yuhang Li",
                "Yang Lu",
                "Bo Ai",
                "Octavia A. Dobre",
                "Zhiguo Ding",
                "Dusit Niyato"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03659v1",
                "http://arxiv.org/pdf/2311.03659v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03658v1",
            "title": "The Linear Representation Hypothesis and the Geometry of Large Language\n  Models",
            "updated": "2023-11-07T01:59:11Z",
            "published": "2023-11-07T01:59:11Z",
            "summary": "Informally, the 'linear representation hypothesis' is the idea that\nhigh-level concepts are represented linearly as directions in some\nrepresentation space. In this paper, we address two closely related questions:\nWhat does \"linear representation\" actually mean? And, how do we make sense of\ngeometric notions (e.g., cosine similarity or projection) in the representation\nspace? To answer these, we use the language of counterfactuals to give two\nformalizations of \"linear representation\", one in the output (word)\nrepresentation space, and one in the input (sentence) space. We then prove\nthese connect to linear probing and model steering, respectively. To make sense\nof geometric notions, we use the formalization to identify a particular\n(non-Euclidean) inner product that respects language structure in a sense we\nmake precise. Using this causal inner product, we show how to unify all notions\nof linear representation. In particular, this allows the construction of probes\nand steering vectors using counterfactual pairs. Experiments with LLaMA-2\ndemonstrate the existence of linear representations of concepts, the connection\nto interpretation and control, and the fundamental role of the choice of inner\nproduct.",
            "author": [
                "Kiho Park",
                "Yo Joong Choe",
                "Victor Veitch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03658v1",
                "http://arxiv.org/pdf/2311.03658v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03652v1",
            "title": "Machine Learning Parameterization of the Multi-scale Kain-Fritsch (MSKF)\n  Convection Scheme",
            "updated": "2023-11-07T01:47:16Z",
            "published": "2023-11-07T01:47:16Z",
            "summary": "Warm-sector heavy rainfall often occurs along the coast of South China, and\nit is usually localized and long-lasting, making it challenging to predict.\nHigh-resolution numerical weather prediction (NWP) models are increasingly used\nto better resolve topographic features and forecast such high-impact weather\nevents. However, when the grid spacing becomes comparable to the length scales\nof convection, known as the gray zone, the turbulent eddies in the atmospheric\nboundary layer are only partially resolved and parameterized to some extent.\nWhether using a convection parameterization (CP) scheme in the gray zone\nremains controversial. Scale-aware CP schemes are developed to enhance the\nrepresentation of convective transport within the gray zone. The multi-scale\nKain-Fritsch (MSKF) scheme includes modifications that allow for its effective\nimplementation at a grid resolution as high as 2 km. In recent years, there has\nbeen an increasing application of machine learning (ML) models to various\ndomains of atmospheric sciences, including the replacement of physical\nparameterizations with ML models. This work proposes a multi-output\nbidirectional long short-term memory (Bi-LSTM) model as a replace the\nscale-aware MSKF CP scheme. The Weather Research and Forecast (WRF) model is\nused to generate training and testing data over South China at a horizontal\nresolution of 5 km. Furthermore, the WRF model is coupled with the ML based CP\nscheme and compared with WRF simulations with original MSKF scheme. The results\ndemonstrate that the Bi-LSTM model can achieve high accuracy, indicating the\npotential use of ML models to substitute the MSKF scheme in the gray zone.",
            "author": [
                "Xiaohui Zhong",
                "Xing Yu",
                "Hao Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03652v1",
                "http://arxiv.org/pdf/2311.03652v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03651v1",
            "title": "SeRO: Self-Supervised Reinforcement Learning for Recovery from\n  Out-of-Distribution Situations",
            "updated": "2023-11-07T01:42:13Z",
            "published": "2023-11-07T01:42:13Z",
            "summary": "Robotic agents trained using reinforcement learning have the problem of\ntaking unreliable actions in an out-of-distribution (OOD) state. Agents can\neasily become OOD in real-world environments because it is almost impossible\nfor them to visit and learn the entire state space during training.\nUnfortunately, unreliable actions do not ensure that agents perform their\noriginal tasks successfully. Therefore, agents should be able to recognize\nwhether they are in OOD states and learn how to return to the learned state\ndistribution rather than continue to take unreliable actions. In this study, we\npropose a novel method for retraining agents to recover from OOD situations in\na self-supervised manner when they fall into OOD states. Our in-depth\nexperimental results demonstrate that our method substantially improves the\nagent's ability to recover from OOD situations in terms of sample efficiency\nand restoration of the performance for the original tasks. Moreover, we show\nthat our method can retrain the agent to recover from OOD situations even when\nin-distribution states are difficult to visit through exploration.",
            "author": [
                "Chan Kim",
                "Jaekyung Cho",
                "Christophe Bobda",
                "Seung-Woo Seo",
                "Seong-Woo Kim"
            ],
            "link": [
                "http://dx.doi.org/10.24963/ijcai.2023/432",
                "http://arxiv.org/abs/2311.03651v1",
                "http://arxiv.org/pdf/2311.03651v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03650v1",
            "title": "Image Generation and Learning Strategy for Deep Document Forgery\n  Detection",
            "updated": "2023-11-07T01:40:00Z",
            "published": "2023-11-07T01:40:00Z",
            "summary": "In recent years, document processing has flourished and brought numerous\nbenefits. However, there has been a significant rise in reported cases of\nforged document images. Specifically, recent advancements in deep neural\nnetwork (DNN) methods for generative tasks may amplify the threat of document\nforgery. Traditional approaches for forged document images created by prevalent\ncopy-move methods are unsuitable against those created by DNN-based methods, as\nwe have verified. To address this issue, we construct a training dataset of\ndocument forgery images, named FD-VIED, by emulating possible attacks, such as\ntext addition, removal, and replacement with recent DNN-methods. Additionally,\nwe introduce an effective pre-training approach through self-supervised\nlearning with both natural images and document images. In our experiments, we\ndemonstrate that our approach enhances detection performance.",
            "author": [
                "Yamato Okamoto",
                "Osada Genki",
                "Iu Yahiro",
                "Rintaro Hasegawa",
                "Peifei Zhu",
                "Hirokatsu Kataoka"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03650v1",
                "http://arxiv.org/pdf/2311.03650v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03648v1",
            "title": "Instruct Me More! Random Prompting for Visual In-Context Learning",
            "updated": "2023-11-07T01:39:00Z",
            "published": "2023-11-07T01:39:00Z",
            "summary": "Large-scale models trained on extensive datasets, have emerged as the\npreferred approach due to their high generalizability across various tasks.\nIn-context learning (ICL), a popular strategy in natural language processing,\nuses such models for different tasks by providing instructive prompts but\nwithout updating model parameters. This idea is now being explored in computer\nvision, where an input-output image pair (called an in-context pair) is\nsupplied to the model with a query image as a prompt to exemplify the desired\noutput. The efficacy of visual ICL often depends on the quality of the prompts.\nWe thus introduce a method coined Instruct Me More (InMeMo), which augments\nin-context pairs with a learnable perturbation (prompt), to explore its\npotential. Our experiments on mainstream tasks reveal that InMeMo surpasses the\ncurrent state-of-the-art performance. Specifically, compared to the baseline\nwithout learnable prompt, InMeMo boosts mIoU scores by 7.35 and 15.13 for\nforeground segmentation and single object detection tasks, respectively. Our\nfindings suggest that InMeMo offers a versatile and efficient way to enhance\nthe performance of visual ICL with lightweight training. Code is available at\nhttps://github.com/Jackieam/InMeMo.",
            "author": [
                "Jiahao Zhang",
                "Bowen Wang",
                "Liangzhi Li",
                "Yuta Nakashima",
                "Hajime Nagahara"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03648v1",
                "http://arxiv.org/pdf/2311.03648v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03641v1",
            "title": "Spectral Maps for Learning Reduced Representations of Molecular Systems",
            "updated": "2023-11-07T01:07:12Z",
            "published": "2023-11-07T01:07:12Z",
            "summary": "Investigating processes in complex molecular systems characterized by many\nvariables is a crucial problem in computational physics. In theory, such\nsystems can be reduced to a few meaningful degrees of freedom called collective\nvariables (CVs). However, identifying CVs is a significant challenge,\nespecially for the systems with long-lived metastable states, as information\nabout the slow kinetics of rare transitions needs to be encoded in CVs. Here,\nwe present our spectral map technique as a promising deep-learning method to\nlearn CVs based on the slowest timescales. Spectral map maximizes the spectral\ngap between slow and fast eigenvalues of a Markov transition matrix constructed\nfrom simulation data. As an example, we show that our method can effectively\ncapture a simplified representation of alanine dipeptide in solvent. Its\nability to extract the slow CVs makes it a valuable tool for analyzing complex\nsystems.",
            "author": [
                "Tu\u011f\u00e7e G\u00f6kdemir",
                "Jakub Rydzewski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03641v1",
                "http://arxiv.org/pdf/2311.03641v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03639v1",
            "title": "A Physics-Guided Bi-Fidelity Fourier-Featured Operator Learning\n  Framework for Predicting Time Evolution of Drag and Lift Coefficients",
            "updated": "2023-11-07T00:56:54Z",
            "published": "2023-11-07T00:56:54Z",
            "summary": "In the pursuit of accurate experimental and computational data while\nminimizing effort, there is a constant need for high-fidelity results. However,\nachieving such results often requires significant computational resources. To\naddress this challenge, this paper proposes a deep operator learning-based\nframework that requires a limited high-fidelity dataset for training. We\nintroduce a novel physics-guided, bi-fidelity, Fourier-featured Deep Operator\nNetwork (DeepONet) framework that effectively combines low and high-fidelity\ndatasets, leveraging the strengths of each. In our methodology, we began by\ndesigning a physics-guided Fourier-featured DeepONet, drawing inspiration from\nthe intrinsic physical behavior of the target solution. Subsequently, we train\nthis network to primarily learn the low-fidelity solution, utilizing an\nextensive dataset. This process ensures a comprehensive grasp of the\nfoundational solution patterns. Following this foundational learning, the\nlow-fidelity deep operator network's output is enhanced using a physics-guided\nFourier-featured residual deep operator network. This network refines the\ninitial low-fidelity output, achieving the high-fidelity solution by employing\na small high-fidelity dataset for training. Notably, in our framework, we\nemploy the Fourier feature network as the Trunk network for the DeepONets,\ngiven its proficiency in capturing and learning the oscillatory nature of the\ntarget solution with high precision. We validate our approach using a\nwell-known 2D benchmark cylinder problem, which aims to predict the time\ntrajectories of lift and drag coefficients. The results highlight that the\nphysics-guided Fourier-featured deep operator network, serving as a\nfoundational building block of our framework, possesses superior predictive\ncapability for the lift and drag coefficients compared to its data-driven\ncounterparts.",
            "author": [
                "Amirhossein Mollaali",
                "Izzet Sahin",
                "Iqrar Raza",
                "Christian Moya",
                "Guillermo Paniagua",
                "Guang Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03639v1",
                "http://arxiv.org/pdf/2311.03639v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04244v1",
            "title": "HKTGNN: Hierarchical Knowledge Transferable Graph Neural Network-based\n  Supply Chain Risk Assessment",
            "updated": "2023-11-07T00:54:04Z",
            "published": "2023-11-07T00:54:04Z",
            "summary": "The strength of a supply chain is an important measure of a country's or\nregion's technical advancement and overall competitiveness. Establishing supply\nchain risk assessment models for effective management and mitigation of\npotential risks has become increasingly crucial. As the number of businesses\ngrows, the important relationships become more complicated and difficult to\nmeasure. This emphasizes the need of extracting relevant information from graph\ndata. Previously, academics mostly employed knowledge inference to increase the\nvisibility of links between nodes in the supply chain. However, they have not\nsolved the data hunger problem of single node feature characteristics. We\npropose a hierarchical knowledge transferable graph neural network-based\n(HKTGNN) supply chain risk assessment model to address these issues. Our\napproach is based on current graph embedding methods for assessing corporate\ninvestment risk assessment. We embed the supply chain network corresponding to\nindividual goods in the supply chain using the graph embedding module,\nresulting in a directed homogeneous graph with just product nodes. This reduces\nthe complicated supply chain network into a basic product network. It addresses\ndifficulties using the domain difference knowledge transferable module based on\ncentrality, which is presented by the premise that supply chain feature\ncharacteristics may be biased in the actual world. Meanwhile, the feature\ncomplement and message passing will alleviate the data hunger problem, which is\ndriven by domain differences. Our model outperforms in experiments on a\nreal-world supply chain dataset. We will give an equation to prove that our\ncomparative experiment is both effective and fair.",
            "author": [
                "Zhanting Zhou",
                "Kejun Bi",
                "Yuyanzhen Zhong",
                "Chao Tang",
                "Dongfen Li",
                "Shi Ying",
                "Ruijin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04244v1",
                "http://arxiv.org/pdf/2311.04244v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "I.2.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03636v1",
            "title": "Analysis of the User Perception of Chatbots in Education Using A Partial\n  Least Squares Structural Equation Modeling Approach",
            "updated": "2023-11-07T00:44:56Z",
            "published": "2023-11-07T00:44:56Z",
            "summary": "The integration of Artificial Intelligence (AI) into education is a recent\ndevelopment, with chatbots emerging as a noteworthy addition to this\ntransformative landscape. As online learning platforms rapidly advance,\nstudents need to adapt swiftly to excel in this dynamic environment.\nConsequently, understanding the acceptance of chatbots, particularly those\nemploying Large Language Model (LLM) such as Chat Generative Pretrained\nTransformer (ChatGPT), Google Bard, and other interactive AI technologies, is\nof paramount importance. However, existing research on chatbots in education\nhas overlooked key behavior-related aspects, such as Optimism, Innovativeness,\nDiscomfort, Insecurity, Transparency, Ethics, Interaction, Engagement, and\nAccuracy, creating a significant literature gap. To address this gap, this\nstudy employs Partial Least Squares Structural Equation Modeling (PLS-SEM) to\ninvestigate the determinant of chatbots adoption in education among students,\nconsidering the Technology Readiness Index (TRI) and Technology Acceptance\nModel (TAM). Utilizing a five-point Likert scale for data collection, we\ngathered a total of 185 responses, which were analyzed using R-Studio software.\nWe established 12 hypotheses to achieve its objectives. The results showed that\nOptimism and Innovativeness are positively associated with Perceived Ease of\nUse (PEOU) and Perceived Usefulness (PU). Conversely, Discomfort and Insecurity\nnegatively impact PEOU, with only Insecurity negatively affecting PU. These\nfindings provide insights for future technology designers, elucidating critical\nuser behavior factors influencing chatbots adoption and utilization in\neducational contexts.",
            "author": [
                "Md Rabiul Hasan",
                "Nahian Ismail Chowdhury",
                "Md Hadisur Rahman",
                "Md Asif Bin Syed",
                "JuHyeong Ryu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03636v1",
                "http://arxiv.org/pdf/2311.03636v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03633v1",
            "title": "Innovation and Word Usage Patterns in Machine Learning",
            "updated": "2023-11-07T00:41:15Z",
            "published": "2023-11-07T00:41:15Z",
            "summary": "In this study, we delve into the dynamic landscape of machine learning\nresearch evolution. Initially, through the utilization of Latent Dirichlet\nAllocation, we discern pivotal themes and fundamental concepts that have\nemerged within the realm of machine learning. Subsequently, we undertake a\ncomprehensive analysis to track the evolutionary trajectories of these\nidentified themes. To quantify the novelty and divergence of research\ncontributions, we employ the Kullback-Leibler Divergence metric. This\nstatistical measure serves as a proxy for ``surprise'', indicating the extent\nof differentiation between the content of academic papers and the subsequent\ndevelopments in research. By amalgamating these insights, we gain the ability\nto ascertain the pivotal roles played by prominent researchers and the\nsignificance of specific academic venues (periodicals and conferences) within\nthe machine learning domain.",
            "author": [
                "V\u00edtor Bandeira Borges",
                "Daniel Oliveira Cajueiro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03633v1",
                "http://arxiv.org/pdf/2311.03633v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03630v1",
            "title": "Counterfactual Data Augmentation with Contrastive Learning",
            "updated": "2023-11-07T00:36:51Z",
            "published": "2023-11-07T00:36:51Z",
            "summary": "Statistical disparity between distinct treatment groups is one of the most\nsignificant challenges for estimating Conditional Average Treatment Effects\n(CATE). To address this, we introduce a model-agnostic data augmentation method\nthat imputes the counterfactual outcomes for a selected subset of individuals.\nSpecifically, we utilize contrastive learning to learn a representation space\nand a similarity measure such that in the learned representation space close\nindividuals identified by the learned similarity measure have similar potential\noutcomes. This property ensures reliable imputation of counterfactual outcomes\nfor the individuals with close neighbors from the alternative treatment group.\nBy augmenting the original dataset with these reliable imputations, we can\neffectively reduce the discrepancy between different treatment groups, while\ninducing minimal imputation error. The augmented dataset is subsequently\nemployed to train CATE estimation models. Theoretical analysis and experimental\nstudies on synthetic and semi-synthetic benchmarks demonstrate that our method\nachieves significant improvements in both performance and robustness to\noverfitting across state-of-the-art models.",
            "author": [
                "Ahmed Aloui",
                "Juncheng Dong",
                "Cat P. Le",
                "Vahid Tarokh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03630v1",
                "http://arxiv.org/pdf/2311.03630v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03629v1",
            "title": "Random Field Augmentations for Self-Supervised Representation Learning",
            "updated": "2023-11-07T00:35:09Z",
            "published": "2023-11-07T00:35:09Z",
            "summary": "Self-supervised representation learning is heavily dependent on data\naugmentations to specify the invariances encoded in representations. Previous\nwork has shown that applying diverse data augmentations is crucial to\ndownstream performance, but augmentation techniques remain under-explored. In\nthis work, we propose a new family of local transformations based on Gaussian\nrandom fields to generate image augmentations for self-supervised\nrepresentation learning. These transformations generalize the well-established\naffine and color transformations (translation, rotation, color jitter, etc.)\nand greatly increase the space of augmentations by allowing transformation\nparameter values to vary from pixel to pixel. The parameters are treated as\ncontinuous functions of spatial coordinates, and modeled as independent\nGaussian random fields. Empirical results show the effectiveness of the new\ntransformations for self-supervised representation learning. Specifically, we\nachieve a 1.7% top-1 accuracy improvement over baseline on ImageNet downstream\nclassification, and a 3.6% improvement on out-of-distribution iNaturalist\ndownstream classification. However, due to the flexibility of the new\ntransformations, learned representations are sensitive to hyperparameters.\nWhile mild transformations improve representations, we observe that strong\ntransformations can degrade the structure of an image, indicating that\nbalancing the diversity and strength of augmentations is important for\nimproving generalization of learned representations.",
            "author": [
                "Philip Andrew Mansfield",
                "Arash Afkanpour",
                "Warren Richard Morningstar",
                "Karan Singhal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03629v1",
                "http://arxiv.org/pdf/2311.03629v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "I.2.6; I.2.10; I.5.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03628v1",
            "title": "Reinforcement Twinning: from digital twins to model-based reinforcement\n  learning",
            "updated": "2023-11-07T00:24:25Z",
            "published": "2023-11-07T00:24:25Z",
            "summary": "We propose a novel framework for simultaneously training the digital twin of\nan engineering system and an associated control agent. The training of the twin\ncombines methods from data assimilation and system identification, while the\ntraining of the control agent combines model-based optimal control and\nmodel-free reinforcement learning. The combined training of the control agent\nis achieved by letting it evolve independently along two paths (one driven by a\nmodel-based optimal control and another driven by reinforcement learning) and\nusing the virtual environment offered by the digital twin as a playground for\nconfrontation and indirect interaction. This interaction occurs as an \"expert\ndemonstrator\", where the best policy is selected for the interaction with the\nreal environment and \"taught\" to the other if the independent training\nstagnates. We refer to this framework as Reinforcement Twinning (RT). The\nframework is tested on three vastly different engineering systems and control\ntasks, namely (1) the control of a wind turbine subject to time-varying wind\nspeed, (2) the trajectory control of flapping-wing micro air vehicles (FWMAVs)\nsubject to wind gusts, and (3) the mitigation of thermal loads in the\nmanagement of cryogenic storage tanks. The test cases are implemented using\nsimplified models for which the ground truth on the closure law is available.\nThe results show that the adjoint-based training of the digital twin is\nremarkably sample-efficient and completed within a few iterations. Concerning\nthe control agent training, the results show that the model-based and the\nmodel-free control training benefit from the learning experience and the\ncomplementary learning approach of each other. The encouraging results open the\npath towards implementing the RT framework on real systems.",
            "author": [
                "Lorenzo Schena",
                "Pedro Marques",
                "Romain Poletti",
                "Samuel Ahizi",
                "Jan Van den Berghe",
                "Miguel A. Mendez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03628v1",
                "http://arxiv.org/pdf/2311.03628v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03626v1",
            "title": "PINNs-TF2: Fast and User-Friendly Physics-Informed Neural Networks in\n  TensorFlow V2",
            "updated": "2023-11-07T00:23:50Z",
            "published": "2023-11-07T00:23:50Z",
            "summary": "Physics-informed neural networks (PINNs) have gained prominence for their\ncapability to tackle supervised learning tasks that conform to physical laws,\nnotably nonlinear partial differential equations (PDEs). This paper presents\n\"PINNs-TF2\", a Python package built on the TensorFlow V2 framework. It not only\naccelerates PINNs implementation but also simplifies user interactions by\nabstracting complex PDE challenges. We underscore the pivotal role of compilers\nin PINNs, highlighting their ability to boost performance by up to 119x. Across\neight diverse examples, our package, integrated with XLA compilers,\ndemonstrated its flexibility and achieved an average speed-up of 18.12 times\nover TensorFlow V1. Moreover, a real-world case study is implemented to\nunderscore the compilers' potential to handle many trainable parameters and\nlarge batch sizes. For community engagement and future enhancements, our\npackage's source code is openly available at:\nhttps://github.com/rezaakb/pinns-tf2.",
            "author": [
                "Reza Akbarian Bafghi",
                "Maziar Raissi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03626v1",
                "http://arxiv.org/pdf/2311.03626v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03624v1",
            "title": "Are Words Enough? On the semantic conditioning of affective music\n  generation",
            "updated": "2023-11-07T00:19:09Z",
            "published": "2023-11-07T00:19:09Z",
            "summary": "Music has been commonly recognized as a means of expressing emotions. In this\nsense, an intense debate emerges from the need to verbalize musical emotions.\nThis concern seems highly relevant today, considering the exponential growth of\nnatural language processing using deep learning models where it is possible to\nprompt semantic propositions to generate music automatically. This scoping\nreview aims to analyze and discuss the possibilities of music generation\nconditioned by emotions. To address this topic, we propose a historical\nperspective that encompasses the different disciplines and methods contributing\nto this topic. In detail, we review two main paradigms adopted in automatic\nmusic generation: rules-based and machine-learning models. Of note are the deep\nlearning architectures that aim to generate high-fidelity music from textual\ndescriptions. These models raise fundamental questions about the expressivity\nof music, including whether emotions can be represented with words or expressed\nthrough them. We conclude that overcoming the limitation and ambiguity of\nlanguage to express emotions through music, some of the use of deep learning\nwith natural language has the potential to impact the creative industries by\nproviding powerful tools to prompt and generate new musical works.",
            "author": [
                "Jorge Forero",
                "Gilberto Bernardes",
                "M\u00f3nica Mendes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03624v1",
                "http://arxiv.org/pdf/2311.03624v1"
            ],
            "primary_category": "cs.MM",
            "category": [
                "cs.MM",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03622v1",
            "title": "TWIST: Teacher-Student World Model Distillation for Efficient\n  Sim-to-Real Transfer",
            "updated": "2023-11-07T00:18:07Z",
            "published": "2023-11-07T00:18:07Z",
            "summary": "Model-based RL is a promising approach for real-world robotics due to its\nimproved sample efficiency and generalization capabilities compared to\nmodel-free RL. However, effective model-based RL solutions for vision-based\nreal-world applications require bridging the sim-to-real gap for any world\nmodel learnt. Due to its significant computational cost, standard domain\nrandomisation does not provide an effective solution to this problem. This\npaper proposes TWIST (Teacher-Student World Model Distillation for Sim-to-Real\nTransfer) to achieve efficient sim-to-real transfer of vision-based model-based\nRL using distillation. Specifically, TWIST leverages state observations as\nreadily accessible, privileged information commonly garnered from a simulator\nto significantly accelerate sim-to-real transfer. Specifically, a teacher world\nmodel is trained efficiently on state information. At the same time, a matching\ndataset is collected of domain-randomised image observations. The teacher world\nmodel then supervises a student world model that takes the domain-randomised\nimage observations as input. By distilling the learned latent dynamics model\nfrom the teacher to the student model, TWIST achieves efficient and effective\nsim-to-real transfer for vision-based model-based RL tasks. Experiments in\nsimulated and real robotics tasks demonstrate that our approach outperforms\nnaive domain randomisation and model-free methods in terms of sample efficiency\nand task performance of sim-to-real transfer.",
            "author": [
                "Jun Yamada",
                "Marc Rigter",
                "Jack Collins",
                "Ingmar Posner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03622v1",
                "http://arxiv.org/pdf/2311.03622v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03621v1",
            "title": "Exploring Latent Spaces of Tonal Music using Variational Autoencoders",
            "updated": "2023-11-07T00:15:29Z",
            "published": "2023-11-07T00:15:29Z",
            "summary": "Variational Autoencoders (VAEs) have proven to be effective models for\nproducing latent representations of cognitive and semantic value. We assess the\ndegree to which VAEs trained on a prototypical tonal music corpus of 371 Bach's\nchorales define latent spaces representative of the circle of fifths and the\nhierarchical relation of each key component pitch as drawn in music cognition.\nIn detail, we compare the latent space of different VAE corpus encodings --\nPiano roll, MIDI, ABC, Tonnetz, DFT of pitch, and pitch class distributions --\nin providing a pitch space for key relations that align with cognitive\ndistances. We evaluate the model performance of these encodings using objective\nmetrics to capture accuracy, mean square error (MSE), KL-divergence, and\ncomputational cost. The ABC encoding performs the best in reconstructing the\noriginal data, while the Pitch DFT seems to capture more information from the\nlatent space. Furthermore, an objective evaluation of 12 major or minor\ntranspositions per piece is adopted to quantify the alignment of 1) intra- and\ninter-segment distances per key and 2) the key distances to cognitive pitch\nspaces. Our results show that Pitch DFT VAE latent spaces align best with\ncognitive spaces and provide a common-tone space where overlapping objects\nwithin a key are fuzzy clusters, which impose a well-defined order of\nstructural significance or stability -- i.e., a tonal hierarchy. Tonal\nhierarchies of different keys can be used to measure key distances and the\nrelationships of their in-key components at multiple hierarchies (e.g., notes\nand chords). The implementation of our VAE and the encodings framework are made\navailable online.",
            "author": [
                "N\u00e1dia Carvalho",
                "Gilberto Bernardes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03621v1",
                "http://arxiv.org/pdf/2311.03621v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "cs.MM",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03620v1",
            "title": "FusionViT: Hierarchical 3D Object Detection via LiDAR-Camera Vision\n  Transformer Fusion",
            "updated": "2023-11-07T00:12:01Z",
            "published": "2023-11-07T00:12:01Z",
            "summary": "For 3D object detection, both camera and lidar have been demonstrated to be\nuseful sensory devices for providing complementary information about the same\nscenery with data representations in different modalities, e.g., 2D RGB image\nvs 3D point cloud. An effective representation learning and fusion of such\nmulti-modal sensor data is necessary and critical for better 3D object\ndetection performance. To solve the problem, in this paper, we will introduce a\nnovel vision transformer-based 3D object detection model, namely FusionViT.\nDifferent from the existing 3D object detection approaches, FusionViT is a\npure-ViT based framework, which adopts a hierarchical architecture by extending\nthe transformer model to embed both images and point clouds for effective\nrepresentation learning. Such multi-modal data embedding representations will\nbe further fused together via a fusion vision transformer model prior to\nfeeding the learned features to the object detection head for both detection\nand localization of the 3D objects in the input scenery. To demonstrate the\neffectiveness of FusionViT, extensive experiments have been done on real-world\ntraffic object detection benchmark datasets KITTI and Waymo Open. Notably, our\nFusionViT model can achieve state-of-the-art performance and outperforms not\nonly the existing baseline methods that merely rely on camera images or lidar\npoint clouds, but also the latest multi-modal image-point cloud deep fusion\napproaches.",
            "author": [
                "Xinhao Xiang",
                "Jiawei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03620v1",
                "http://arxiv.org/pdf/2311.03620v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03615v1",
            "title": "CAFE: Carbon-Aware Federated Learning in Geographically Distributed Data\n  Centers",
            "updated": "2023-11-06T23:59:22Z",
            "published": "2023-11-06T23:59:22Z",
            "summary": "Training large-scale artificial intelligence (AI) models demands significant\ncomputational power and energy, leading to increased carbon footprint with\npotential environmental repercussions. This paper delves into the challenges of\ntraining AI models across geographically distributed (geo-distributed) data\ncenters, emphasizing the balance between learning performance and carbon\nfootprint. We consider Federated Learning (FL) as a solution, which prioritizes\nmodel parameter exchange over raw data, ensuring data privacy and compliance\nwith local regulations. Given the variability in carbon intensity across\nregions, we propose a new framework called CAFE (short for Carbon-Aware\nFederated Learning) to optimize training within a fixed carbon footprint\nbudget. Our approach incorporates coreset selection to assess learning\nperformance, employs the Lyapunov drift-plus-penalty framework to address the\nunpredictability of future carbon intensity, and devises an efficient algorithm\nto address the combinatorial complexity of the data center selection. Through\nextensive simulations using real-world carbon intensity data, we demonstrate\nthe efficacy of our algorithm, highlighting its superiority over existing\nmethods in optimizing learning performance while minimizing environmental\nimpact.",
            "author": [
                "Jieming Bian",
                "Shaolei Ren",
                "Jie Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03615v1",
                "http://arxiv.org/pdf/2311.03615v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03613v1",
            "title": "Main belt asteroids taxonomical information from Dark Energy Survey data",
            "updated": "2023-11-06T23:46:08Z",
            "published": "2023-11-06T23:46:08Z",
            "summary": "While proper orbital elements are currently available for more than 1 million\nasteroids, taxonomical information is still lagging behind. Surveys like\nSDSS-MOC4 provided preliminary information for more than 100,000 objects, but\nmany asteroids still lack even a basic taxonomy. In this study, we use Dark\nEnergy Survey (DES) data to provide new information on asteroid physical\nproperties. By cross-correlating the new DES database with other databases, we\ninvestigate how asteroid taxonomy is reflected in DES data. While the\nresolution of DES data is not sufficient to distinguish between different\nasteroid taxonomies within the complexes, except for V-type objects, it can\nprovide information on whether an asteroid belongs to the C- or S-complex.\nHere, machine learning methods optimized through the use of genetic algorithms\nwere used to predict the labels of more than 68,000 asteroids with no prior\ntaxonomic information. Using a high-quality, limited set of asteroids with data\non $gri$ slopes and $i-z$ colors, we detected 409 new possible V-type\nasteroids. Their orbital distribution is highly consistent with that of other\nknown V-type objects.",
            "author": [
                "Valerio Carruba",
                "J\u00falio I. B. Camargo",
                "Safwan Aljbaae",
                "51 co-authors",
                "DES Collaboration"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03613v1",
                "http://arxiv.org/pdf/2311.03613v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03611v1",
            "title": "Plug-and-Play Stability for Intracortical Brain-Computer Interfaces: A\n  One-Year Demonstration of Seamless Brain-to-Text Communication",
            "updated": "2023-11-06T23:42:01Z",
            "published": "2023-11-06T23:42:01Z",
            "summary": "Intracortical brain-computer interfaces (iBCIs) have shown promise for\nrestoring rapid communication to people with neurological disorders such as\namyotrophic lateral sclerosis (ALS). However, to maintain high performance over\ntime, iBCIs typically need frequent recalibration to combat changes in the\nneural recordings that accrue over days. This requires iBCI users to stop using\nthe iBCI and engage in supervised data collection, making the iBCI system hard\nto use. In this paper, we propose a method that enables self-recalibration of\ncommunication iBCIs without interrupting the user. Our method leverages large\nlanguage models (LMs) to automatically correct errors in iBCI outputs. The\nself-recalibration process uses these corrected outputs (\"pseudo-labels\") to\ncontinually update the iBCI decoder online. Over a period of more than one year\n(403 days), we evaluated our Continual Online Recalibration with Pseudo-labels\n(CORP) framework with one clinical trial participant. CORP achieved a stable\ndecoding accuracy of 93.84% in an online handwriting iBCI task, significantly\noutperforming other baseline methods. Notably, this is the longest-running iBCI\nstability demonstration involving a human participant. Our results provide the\nfirst evidence for long-term stabilization of a plug-and-play, high-performance\ncommunication iBCI, addressing a major barrier for the clinical translation of\niBCIs.",
            "author": [
                "Chaofei Fan",
                "Nick Hahn",
                "Foram Kamdar",
                "Donald Avansino",
                "Guy H. Wilson",
                "Leigh Hochberg",
                "Krishna V. Shenoy",
                "Jaimie M. Henderson",
                "Francis R. Willett"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03611v1",
                "http://arxiv.org/pdf/2311.03611v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.LG",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03609v1",
            "title": "Testing RadiX-Nets: Advances in Viable Sparse Topologies",
            "updated": "2023-11-06T23:27:28Z",
            "published": "2023-11-06T23:27:28Z",
            "summary": "The exponential growth of data has sparked computational demands on ML\nresearch and industry use. Sparsification of hyper-parametrized deep neural\nnetworks (DNNs) creates simpler representations of complex data. Past research\nhas shown that some sparse networks achieve similar performance as dense ones,\nreducing runtime and storage. RadiX-Nets, a subgroup of sparse DNNs, maintain\nuniformity which counteracts their lack of neural connections. Generation,\nindependent of a dense network, yields faster asymptotic training and removes\nthe need for costly pruning. However, little work has been done on RadiX-Nets,\nmaking testing challenging. This paper presents a testing suite for RadiX-Nets\nin TensorFlow. We test RadiX-Net performance to streamline processing in\nscalable models, revealing relationships between network topology,\ninitialization, and training behavior. We also encounter \"strange models\" that\ntrain inconsistently and to lower accuracy while models of similar sparsity\ntrain well.",
            "author": [
                "Kevin Kwak",
                "Zack West",
                "Hayden Jananthan",
                "Jeremy Kepner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03609v1",
                "http://arxiv.org/pdf/2311.03609v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03606v1",
            "title": "Multimodal Stress Detection Using Facial Landmarks and Biometric Signals",
            "updated": "2023-11-06T23:20:30Z",
            "published": "2023-11-06T23:20:30Z",
            "summary": "The development of various sensing technologies is improving measurements of\nstress and the well-being of individuals. Although progress has been made with\nsingle signal modalities like wearables and facial emotion recognition,\nintegrating multiple modalities provides a more comprehensive understanding of\nstress, given that stress manifests differently across different people.\nMulti-modal learning aims to capitalize on the strength of each modality rather\nthan relying on a single signal. Given the complexity of processing and\nintegrating high-dimensional data from limited subjects, more research is\nneeded. Numerous research efforts have been focused on fusing stress and\nemotion signals at an early stage, e.g., feature-level fusion using basic\nmachine learning methods and 1D-CNN Methods. This paper proposes a multi-modal\nlearning approach for stress detection that integrates facial landmarks and\nbiometric signals. We test this multi-modal integration with various\nearly-fusion and late-fusion techniques to integrate the 1D-CNN model from\nbiometric signals and 2-D CNN using facial landmarks. We evaluate these\narchitectures using a rigorous test of models' generalizability using the\nleave-one-subject-out mechanism, i.e., all samples related to a single subject\nare left out to train the model. Our findings show that late-fusion achieved\n94.39\\% accuracy, and early-fusion surpassed it with a 98.38\\% accuracy rate.\nThis research contributes valuable insights into enhancing stress detection\nthrough a multi-modal approach. The proposed research offers important\nknowledge in improving stress detection using a multi-modal approach.",
            "author": [
                "Majid Hosseini",
                "Morteza Bodaghi",
                "Ravi Teja Bhupatiraju",
                "Anthony Maida",
                "Raju Gottumukkala"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03606v1",
                "http://arxiv.org/pdf/2311.03606v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03600v1",
            "title": "Scalable and Efficient Continual Learning from Demonstration via\n  Hypernetwork-generated Stable Dynamics Model",
            "updated": "2023-11-06T23:04:31Z",
            "published": "2023-11-06T23:04:31Z",
            "summary": "Learning from demonstration (LfD) provides an efficient way to train robots.\nThe learned motions should be convergent and stable, but to be truly effective\nin the real world, LfD-capable robots should also be able to remember multiple\nmotion skills. Multi-skill retention is a capability missing from existing\nstable-LfD approaches. On the other hand, recent work on continual-LfD has\nshown that hypernetwork-generated neural ordinary differential equation\nsolvers, can learn multiple LfD tasks sequentially, but this approach lacks\nstability guarantees. We propose an approach for stable continual-LfD in which\na hypernetwork generates two networks: a trajectory learning dynamics model,\nand a trajectory stabilizing Lyapunov function. The introduction of stability\nnot only generates stable trajectories but also greatly improves continual\nlearning performance, especially in the size-efficient chunked hypernetworks.\nWith our approach, we can continually train a single model to predict the\nposition and orientation trajectories of the robot's end-effector\nsimultaneously for multiple real world tasks without retraining on past\ndemonstrations. We also propose stochastic regularization with a single\nrandomly sampled regularization term in hypernetworks, which reduces the\ncumulative training time cost for $N$ tasks from $\\mathcal{O}(N^2)$ to\n$\\mathcal{O}(N)$ without any loss in performance in real-world tasks. We\nempirically evaluate our approach on the popular LASA dataset, on\nhigh-dimensional extensions of LASA (including up to 32 dimensions) to assess\nscalability, and on a novel extended robotic task dataset (RoboTasks9) to\nassess real-world performance. In trajectory error metrics, stability metrics\nand continual learning metrics our approach performs favorably, compared to\nother baselines. Code and datasets will be shared after submission.",
            "author": [
                "Sayantan Auddy",
                "Jakob Hollenstein",
                "Matteo Saveriano",
                "Antonio Rodr\u00edguez-S\u00e1nchez",
                "Justus Piater"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03600v1",
                "http://arxiv.org/pdf/2311.03600v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03595v1",
            "title": "Brief for the Canada House of Commons Study on the Implications of\n  Artificial Intelligence Technologies for the Canadian Labor Force: Generative\n  Artificial Intelligence Shatters Models of AI and Labor",
            "updated": "2023-11-06T22:58:24Z",
            "published": "2023-11-06T22:58:24Z",
            "summary": "Exciting advances in generative artificial intelligence (AI) have sparked\nconcern for jobs, education, productivity, and the future of work. As with past\ntechnologies, generative AI may not lead to mass unemployment. But, unlike past\ntechnologies, generative AI is creative, cognitive, and potentially ubiquitous\nwhich makes the usual assumptions of automation predictions ill-suited for\ntoday. Existing projections suggest that generative AI will impact workers in\noccupations that were previously considered immune to automation. As AI's full\nset of capabilities and applications emerge, policy makers should promote\nworkers' career adaptability. This goal requires improved data on job\nseparations and unemployment by locality and job titles in order to identify\nearly-indicators for the workers facing labor disruption. Further, prudent\npolicy should incentivize education programs to accommodate learning with AI as\na tool while preparing students for the demands of the future of work.",
            "author": [
                "Morgan R. Frank"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03595v1",
                "http://arxiv.org/pdf/2311.03595v1"
            ],
            "primary_category": "econ.GN",
            "category": [
                "econ.GN",
                "cs.AI",
                "q-fin.EC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03583v1",
            "title": "Finding Increasingly Large Extremal Graphs with AlphaZero and Tabu\n  Search",
            "updated": "2023-11-06T22:29:55Z",
            "published": "2023-11-06T22:29:55Z",
            "summary": "This work studies a central extremal graph theory problem inspired by a 1975\nconjecture of Erd\\H{o}s, which aims to find graphs with a given size (number of\nnodes) that maximize the number of edges without having 3- or 4-cycles. We\nformulate this problem as a sequential decision-making problem and compare\nAlphaZero, a neural network-guided tree search, with tabu search, a heuristic\nlocal search method. Using either method, by introducing a curriculum --\njump-starting the search for larger graphs using good graphs found at smaller\nsizes -- we improve the state-of-the-art lower bounds for several sizes. We\nalso propose a flexible graph-generation environment and a\npermutation-invariant network architecture for learning to search in the space\nof graphs.",
            "author": [
                "Abbas Mehrabian",
                "Ankit Anand",
                "Hyunjik Kim",
                "Nicolas Sonnerat",
                "Matej Balog",
                "Gheorghe Comanici",
                "Tudor Berariu",
                "Andrew Lee",
                "Anian Ruoss",
                "Anna Bulanova",
                "Daniel Toyama",
                "Sam Blackwell",
                "Bernardino Romera Paredes",
                "Petar Veli\u010dkovi\u0107",
                "Laurent Orseau",
                "Joonkyung Lee",
                "Anurag Murty Naredla",
                "Doina Precup",
                "Adam Zsolt Wagner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03583v1",
                "http://arxiv.org/pdf/2311.03583v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.DM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03578v1",
            "title": "Generative Diffusion Models for Lattice Field Theory",
            "updated": "2023-11-06T22:24:28Z",
            "published": "2023-11-06T22:24:28Z",
            "summary": "This study delves into the connection between machine learning and lattice\nfield theory by linking generative diffusion models (DMs) with stochastic\nquantization, from a stochastic differential equation perspective. We show that\nDMs can be conceptualized by reversing a stochastic process driven by the\nLangevin equation, which then produces samples from an initial distribution to\napproximate the target distribution. In a toy model, we highlight the\ncapability of DMs to learn effective actions. Furthermore, we demonstrate its\nfeasibility to act as a global sampler for generating configurations in the\ntwo-dimensional $\\phi^4$ quantum lattice field theory.",
            "author": [
                "Lingxiao Wang",
                "Gert Aarts",
                "Kai Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03578v1",
                "http://arxiv.org/pdf/2311.03578v1"
            ],
            "primary_category": "hep-lat",
            "category": [
                "hep-lat",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03577v1",
            "title": "The Potential of Water-Cherenkov Air Shower Arrays for detecting\n  transient sources of high-energy astrophysical neutrinos",
            "updated": "2023-11-06T22:23:37Z",
            "published": "2023-11-06T22:23:37Z",
            "summary": "In this study, we highlight the capacity of current and forthcoming air\nshower arrays utilizing water-Cherenkov stations to detect neutrino events\nspanning energies from $10\\,$GeV to $100\\,$TeV. This detection approach\nleverages individual stations equipped with both bottom and top photosensors,\nmaking use of features of the signal time trace and machine learning\ntechniques. Our findings demonstrate the competitiveness of this method\ncompared to established and future neutrino-detection experiments, including\nIceCube and the upcoming Hyper-Kamiokande experiment.",
            "author": [
                "J. Alvarez-Mu\u00f1iz",
                "R. Concei\u00e7\u00e3o",
                "P. J. Costa",
                "B. S. Gonz\u00e1lez",
                "M. Pimenta",
                "B. Tom\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03577v1",
                "http://arxiv.org/pdf/2311.03577v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "astro-ph.IM",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04241v1",
            "title": "AI-Enabled Unmanned Vehicle-Assisted Reconfigurable Intelligent\n  Surfaces: Deployment, Prototyping, Experiments, and Opportunities",
            "updated": "2023-11-06T22:22:00Z",
            "published": "2023-11-06T22:22:00Z",
            "summary": "The requirement of wireless data demands is increasingly high as the\nsixth-generation (6G) technology evolves. Reconfigurable intelligent surface\n(RIS) is promisingly deemed to be one of 6G techniques for extending service\ncoverage, reducing power consumption, and enhancing spectral efficiency. In\nthis article, we have provided some fundamentals of RIS deployment in theory\nand hardware perspectives as well as utilization of artificial intelligence\n(AI) and machine learning. We conducted an intelligent deployment of RIS\n(i-Dris) prototype, including dual-band auto-guided vehicle (AGV) assisted RISs\nassociated with an mmWave base station (BS) and a receiver. The RISs are\ndeployed on the AGV with configured incident/reflection angles. While, both the\nmmWave BS and receiver are associated with an edge server monitoring downlink\npackets for obtaining system throughput. We have designed a federated\nmulti-agent reinforcement learning scheme associated with several AGV-RIS\nagents and sub-agents per AGV-RIS consisting of the deployment of position,\nheight, orientation and elevation angles. The experimental results presented\nthe stationary measurement in different aspects and scenarios. The i-Dris can\nreach up to 980 Mbps transmission throughput under a bandwidth of 100 MHz with\ncomparably low complexity as well as rapid deployment, which outperforms the\nother existing works. At last, we highlight some opportunities and future\nissues in leveraging RIS-empowered wireless communication networks.",
            "author": [
                "Li-Hsiang Shen",
                "Kai-Ten Feng",
                "Ta-Sung Lee",
                "Yuan-Chun Lin",
                "Shih-Cheng Lin",
                "Chia-Chan Chang",
                "Sheng-Fuh Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04241v1",
                "http://arxiv.org/pdf/2311.04241v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03566v1",
            "title": "Measuring Adversarial Datasets",
            "updated": "2023-11-06T22:08:16Z",
            "published": "2023-11-06T22:08:16Z",
            "summary": "In the era of widespread public use of AI systems across various domains,\nensuring adversarial robustness has become increasingly vital to maintain\nsafety and prevent undesirable errors. Researchers have curated various\nadversarial datasets (through perturbations) for capturing model deficiencies\nthat cannot be revealed in standard benchmark datasets. However, little is\nknown about how these adversarial examples differ from the original data\npoints, and there is still no methodology to measure the intended and\nunintended consequences of those adversarial transformations. In this research,\nwe conducted a systematic survey of existing quantifiable metrics that describe\ntext instances in NLP tasks, among dimensions of difficulty, diversity, and\ndisagreement. We selected several current adversarial effect datasets and\ncompared the distributions between the original and their adversarial\ncounterparts. The results provide valuable insights into what makes these\ndatasets more challenging from a metrics perspective and whether they align\nwith underlying assumptions.",
            "author": [
                "Yuanchen Bai",
                "Raoyi Huang",
                "Vijay Viswanathan",
                "Tzu-Sheng Kuo",
                "Tongshuang Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03566v1",
                "http://arxiv.org/pdf/2311.03566v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03564v1",
            "title": "Low-Rank MDPs with Continuous Action Spaces",
            "updated": "2023-11-06T22:05:08Z",
            "published": "2023-11-06T22:05:08Z",
            "summary": "Low-Rank Markov Decision Processes (MDPs) have recently emerged as a\npromising framework within the domain of reinforcement learning (RL), as they\nallow for provably approximately correct (PAC) learning guarantees while also\nincorporating ML algorithms for representation learning. However, current\nmethods for low-rank MDPs are limited in that they only consider finite action\nspaces, and give vacuous bounds as $|\\mathcal{A}| \\to \\infty$, which greatly\nlimits their applicability. In this work, we study the problem of extending\nsuch methods to settings with continuous actions, and explore multiple concrete\napproaches for performing this extension. As a case study, we consider the\nseminal FLAMBE algorithm (Agarwal et al., 2020), which is a reward-agnostic\nmethod for PAC RL with low-rank MDPs. We show that, without any modifications\nto the algorithm, we obtain similar PAC bound when actions are allowed to be\ncontinuous. Specifically, when the model for transition functions satisfies a\nHolder smoothness condition w.r.t. actions, and either the policy class has a\nuniformly bounded minimum density or the reward function is also Holder smooth,\nwe obtain a polynomial PAC bound that depends on the order of smoothness.",
            "author": [
                "Andrew Bennett",
                "Nathan Kallus",
                "Miruna Oprescu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03564v1",
                "http://arxiv.org/pdf/2311.03564v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03557v1",
            "title": "Spatio-Temporal Similarity Measure based Multi-Task Learning for\n  Predicting Alzheimer's Disease Progression using MRI Data",
            "updated": "2023-11-06T21:59:19Z",
            "published": "2023-11-06T21:59:19Z",
            "summary": "Identifying and utilising various biomarkers for tracking Alzheimer's disease\n(AD) progression have received many recent attentions and enable helping\nclinicians make the prompt decisions. Traditional progression models focus on\nextracting morphological biomarkers in regions of interest (ROIs) from MRI/PET\nimages, such as regional average cortical thickness and regional volume. They\nare effective but ignore the relationships between brain ROIs over time, which\nwould lead to synergistic deterioration. For exploring the synergistic\ndeteriorating relationship between these biomarkers, in this paper, we propose\na novel spatio-temporal similarity measure based multi-task learning approach\nfor effectively predicting AD progression and sensitively capturing the\ncritical relationships between biomarkers. Specifically, we firstly define a\ntemporal measure for estimating the magnitude and velocity of biomarker change\nover time, which indicate a changing trend(temporal). Converting this trend\ninto the vector, we then compare this variability between biomarkers in a\nunified vector space(spatial). The experimental results show that compared with\ndirectly ROI based learning, our proposed method is more effective in\npredicting disease progression. Our method also enables performing longitudinal\nstability selection to identify the changing relationships between biomarkers,\nwhich play a key role in disease progression. We prove that the synergistic\ndeteriorating biomarkers between cortical volumes or surface areas have a\nsignificant effect on the cognitive prediction.",
            "author": [
                "Xulong Wang",
                "Yu Zhang",
                "Menghui Zhou",
                "Tong Liu",
                "Jun Qi",
                "Po Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03557v1",
                "http://arxiv.org/pdf/2311.03557v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03551v1",
            "title": "Context Unlocks Emotions: Text-based Emotion Classification Dataset\n  Auditing with Large Language Models",
            "updated": "2023-11-06T21:34:49Z",
            "published": "2023-11-06T21:34:49Z",
            "summary": "The lack of contextual information in text data can make the annotation\nprocess of text-based emotion classification datasets challenging. As a result,\nsuch datasets often contain labels that fail to consider all the relevant\nemotions in the vocabulary. This misalignment between text inputs and labels\ncan degrade the performance of machine learning models trained on top of them.\nAs re-annotating entire datasets is a costly and time-consuming task that\ncannot be done at scale, we propose to use the expressive capabilities of large\nlanguage models to synthesize additional context for input text to increase its\nalignment with the annotated emotional labels. In this work, we propose a\nformal definition of textual context to motivate a prompting strategy to\nenhance such contextual information. We provide both human and empirical\nevaluation to demonstrate the efficacy of the enhanced context. Our method\nimproves alignment between inputs and their human-annotated labels from both an\nempirical and human-evaluated standpoint.",
            "author": [
                "Daniel Yang",
                "Aditya Kommineni",
                "Mohammad Alshehri",
                "Nilamadhab Mohanty",
                "Vedant Modi",
                "Jonathan Gratch",
                "Shrikanth Narayanan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03551v1",
                "http://arxiv.org/pdf/2311.03551v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03550v1",
            "title": "United We Stand, Divided We Fall: UnityGraph for Unsupervised Procedure\n  Learning from Videos",
            "updated": "2023-11-06T21:33:56Z",
            "published": "2023-11-06T21:33:56Z",
            "summary": "Given multiple videos of the same task, procedure learning addresses\nidentifying the key-steps and determining their order to perform the task. For\nthis purpose, existing approaches use the signal generated from a pair of\nvideos. This makes key-steps discovery challenging as the algorithms lack\ninter-videos perspective. Instead, we propose an unsupervised Graph-based\nProcedure Learning (GPL) framework. GPL consists of the novel UnityGraph that\nrepresents all the videos of a task as a graph to obtain both intra-video and\ninter-videos context. Further, to obtain similar embeddings for the same\nkey-steps, the embeddings of UnityGraph are updated in an unsupervised manner\nusing the Node2Vec algorithm. Finally, to identify the key-steps, we cluster\nthe embeddings using KMeans. We test GPL on benchmark ProceL, CrossTask, and\nEgoProceL datasets and achieve an average improvement of 2% on third-person\ndatasets and 3.6% on EgoProceL over the state-of-the-art.",
            "author": [
                "Siddhant Bansal",
                "Chetan Arora",
                "C. V. Jawahar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03550v1",
                "http://arxiv.org/pdf/2311.03550v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03547v1",
            "title": "InterVLS: Interactive Model Understanding and Improvement with\n  Vision-Language Surrogates",
            "updated": "2023-11-06T21:30:59Z",
            "published": "2023-11-06T21:30:59Z",
            "summary": "Deep learning models are widely used in critical applications, highlighting\nthe need for pre-deployment model understanding and improvement. Visual\nconcept-based methods, while increasingly used for this purpose, face\nchallenges: (1) most concepts lack interpretability, (2) existing methods\nrequire model knowledge, often unavailable at run time. Additionally, (3) there\nlacks a no-code method for post-understanding model improvement. Addressing\nthese, we present InterVLS. The system facilitates model understanding by\ndiscovering text-aligned concepts, measuring their influence with\nmodel-agnostic linear surrogates. Employing visual analytics, InterVLS offers\nconcept-based explanations and performance insights. It enables users to adjust\nconcept influences to update a model, facilitating no-code model improvement.\nWe evaluate InterVLS in a user study, illustrating its functionality with two\nscenarios. Results indicates that InterVLS is effective to help users identify\ninfluential concepts to a model, gain insights and adjust concept influence to\nimprove the model. We conclude with a discussion based on our study results.",
            "author": [
                "Jinbin Huang",
                "Wenbin He",
                "Liang Gou",
                "Liu Ren",
                "Chris Bryan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03547v1",
                "http://arxiv.org/pdf/2311.03547v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CV",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03537v1",
            "title": "Leveraging point annotations in segmentation learning with boundary loss",
            "updated": "2023-11-06T21:18:39Z",
            "published": "2023-11-06T21:18:39Z",
            "summary": "This paper investigates the combination of intensity-based distance maps with\nboundary loss for point-supervised semantic segmentation. By design the\nboundary loss imposes a stronger penalty on the false positives the farther\naway from the object they occur. Hence it is intuitively inappropriate for weak\nsupervision, where the ground truth label may be much smaller than the actual\nobject and a certain amount of false positives (w.r.t. the weak ground truth)\nis actually desirable. Using intensity-aware distances instead may alleviate\nthis drawback, allowing for a certain amount of false positives without a\nsignificant increase to the training loss. The motivation for applying the\nboundary loss directly under weak supervision lies in its great success for\nfully supervised segmentation tasks, but also in not requiring extra priors or\noutside information that is usually required -- in some form -- with existing\nweakly supervised methods in the literature. This formulation also remains\npotentially more attractive than existing CRF-based regularizers, due to its\nsimplicity and computational efficiency. We perform experiments on two\nmulti-class datasets; ACDC (heart segmentation) and POEM (whole-body abdominal\norgan segmentation). Preliminary results are encouraging and show that this\nsupervision strategy has great potential. On ACDC it outperforms the CRF-loss\nbased approach, and on POEM data it performs on par with it. The code for all\nour experiments is openly available.",
            "author": [
                "Eva Breznik",
                "Hoel Kervadec",
                "Filip Malmberg",
                "Joel Kullberg",
                "H\u00e5kan Ahlstr\u00f6m",
                "Marleen de Bruijne",
                "Robin Strand"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03537v1",
                "http://arxiv.org/pdf/2311.03537v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03535v1",
            "title": "Enhancing Performance Monitoring in C/C++ Programs with EDPM: A\n  Domain-Specific Language for Performance Monitoring",
            "updated": "2023-11-06T21:17:57Z",
            "published": "2023-11-06T21:17:57Z",
            "summary": "The utilization of performance monitoring probes is a valuable tool for\nprogrammers to gather performance data. However, the manual insertion of these\nprobes can result in an increase in code size, code obfuscation, and an added\nburden of learning different APIs associated with performance monitoring tools.\nTo mitigate these issues, EDPM, an embedded domain-specific language, was\ndeveloped to provide a higher level of abstraction for annotating regions of\ncode that require instrumentation in C and C++ programs. This paper presents\nthe design and implementation of EDPM and compares it to the well-known tool\nPAPI, in terms of required lines of code, flexibility in configuring regions,\nand performance overhead. The results of this study demonstrate that EDPM is a\nlow-resolution profiling tool that offers a reduction in required lines of code\nand enables programmers to express various configurations of regions.\nFurthermore, the design of EDPM is such that its pragmas are ignored by the\nstandard compiler, allowing for seamless integration into existing software\nprocesses without disrupting build systems or increasing the size of the\nexecutable. Additionally, the design of the EDPM pre-compiler allows for the\nextension of available performance counters while maintaining a high level of\nabstraction for programmers. Therefore, EDPM offers a promising solution to\nsimplify and optimize performance monitoring in C and C++ programs.",
            "author": [
                "David Weisskopf Holmqvist",
                "Suejb Memeti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03535v1",
                "http://arxiv.org/pdf/2311.03535v1"
            ],
            "primary_category": "cs.PF",
            "category": [
                "cs.PF",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03534v1",
            "title": "PcLast: Discovering Plannable Continuous Latent States",
            "updated": "2023-11-06T21:16:37Z",
            "published": "2023-11-06T21:16:37Z",
            "summary": "Goal-conditioned planning benefits from learned low-dimensional\nrepresentations of rich, high-dimensional observations. While compact latent\nrepresentations, typically learned from variational autoencoders or inverse\ndynamics, enable goal-conditioned planning they ignore state affordances, thus\nhampering their sample-efficient planning capabilities. In this paper, we learn\na representation that associates reachable states together for effective onward\nplanning. We first learn a latent representation with multi-step inverse\ndynamics (to remove distracting information); and then transform this\nrepresentation to associate reachable states together in $\\ell_2$ space. Our\nproposals are rigorously tested in various simulation testbeds. Numerical\nresults in reward-based and reward-free settings show significant improvements\nin sampling efficiency, and yields layered state abstractions that enable\ncomputationally efficient hierarchical planning.",
            "author": [
                "Anurag Koul",
                "Shivakanth Sujit",
                "Shaoru Chen",
                "Ben Evans",
                "Lili Wu",
                "Byron Xu",
                "Rajan Chari",
                "Riashat Islam",
                "Raihan Seraj",
                "Yonathan Efroni",
                "Lekan Molu",
                "Miro Dudik",
                "John Langford",
                "Alex Lamb"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03534v1",
                "http://arxiv.org/pdf/2311.03534v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03524v1",
            "title": "A Graph-Theoretic Framework for Understanding Open-World Semi-Supervised\n  Learning",
            "updated": "2023-11-06T21:15:09Z",
            "published": "2023-11-06T21:15:09Z",
            "summary": "Open-world semi-supervised learning aims at inferring both known and novel\nclasses in unlabeled data, by harnessing prior knowledge from a labeled set\nwith known classes. Despite its importance, there is a lack of theoretical\nfoundations for this problem. This paper bridges the gap by formalizing a\ngraph-theoretic framework tailored for the open-world setting, where the\nclustering can be theoretically characterized by graph factorization. Our\ngraph-theoretic framework illuminates practical algorithms and provides\nguarantees. In particular, based on our graph formulation, we apply the\nalgorithm called Spectral Open-world Representation Learning (SORL), and show\nthat minimizing our loss is equivalent to performing spectral decomposition on\nthe graph. Such equivalence allows us to derive a provable error bound on the\nclustering performance for both known and novel classes, and analyze rigorously\nwhen labeled data helps. Empirically, SORL can match or outperform several\nstrong baselines on common benchmark datasets, which is appealing for practical\nusage while enjoying theoretical guarantees.",
            "author": [
                "Yiyou Sun",
                "Zhenmei Shi",
                "Yixuan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03524v1",
                "http://arxiv.org/pdf/2311.03524v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03532v1",
            "title": "The Fairness Stitch: Unveiling the Potential of Model Stitching in\n  Neural Network De-Biasing",
            "updated": "2023-11-06T21:14:37Z",
            "published": "2023-11-06T21:14:37Z",
            "summary": "The pursuit of fairness in machine learning models has emerged as a critical\nresearch challenge in different applications ranging from bank loan approval to\nface detection. Despite the widespread adoption of artificial intelligence\nalgorithms across various domains, concerns persist regarding the presence of\nbiases and discrimination within these models. To address this pressing issue,\nthis study introduces a novel method called \"The Fairness Stitch (TFS)\" to\nenhance fairness in deep learning models. This method combines model stitching\nand training jointly, while incorporating fairness constraints. In this\nresearch, we assess the effectiveness of our proposed method by conducting a\ncomprehensive evaluation of two well-known datasets, CelebA and UTKFace. We\nsystematically compare the performance of our approach with the existing\nbaseline method. Our findings reveal a notable improvement in achieving a\nbalanced trade-off between fairness and performance, highlighting the promising\npotential of our method to address bias-related challenges and foster equitable\noutcomes in machine learning models. This paper poses a challenge to the\nconventional wisdom of the effectiveness of the last layer in deep learning\nmodels for de-biasing.",
            "author": [
                "Modar Sulaiman",
                "Kallol Roy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03532v1",
                "http://arxiv.org/pdf/2311.03532v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03526v1",
            "title": "Towards Automated Negative Sampling in Implicit Recommendation",
            "updated": "2023-11-06T21:05:00Z",
            "published": "2023-11-06T21:05:00Z",
            "summary": "Negative sampling methods are vital in implicit recommendation models as they\nallow us to obtain negative instances from massive unlabeled data. Most\nexisting approaches focus on sampling hard negative samples in various ways.\nThese studies are orthogonal to the recommendation model and implicit datasets.\nHowever, such an idea contradicts the common belief in AutoML that the model\nand dataset should be matched. Empirical experiments suggest that the\nbest-performing negative sampler depends on the implicit dataset and the\nspecific recommendation model. Hence, we propose a hypothesis that the negative\nsampler should align with the capacity of the recommendation models as well as\nthe statistics of the datasets to achieve optimal performance. A mismatch\nbetween these three would result in sub-optimal outcomes. An intuitive idea to\naddress the mismatch problem is to exhaustively select the best-performing\nnegative sampler given the model and dataset. However, such an approach is\ncomputationally expensive and time-consuming, leaving the problem unsolved. In\nthis work, we propose the AutoSample framework that adaptively selects the\nbest-performing negative sampler among candidates. Specifically, we propose a\nloss-to-instance approximation to transform the negative sampler search task\ninto the learning task over a weighted sum, enabling end-to-end training of the\nmodel. We also designed an adaptive search algorithm to extensively and\nefficiently explore the search space. A specific initialization approach is\nalso obtained to better utilize the obtained model parameters during the search\nstage, which is similar to curriculum learning and leads to better performance\nand less computation resource consumption. We evaluate the proposed framework\non four benchmarks over three models. Extensive experiments demonstrate the\neffectiveness and efficiency of our proposed framework.",
            "author": [
                "Fuyuan Lyu",
                "Yaochen Hu",
                "Xing Tang",
                "Yingxue Zhang",
                "Ruiming Tang",
                "Xue Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03526v1",
                "http://arxiv.org/pdf/2311.03526v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03520v1",
            "title": "Brain Networks and Intelligence: A Graph Neural Network Based Approach\n  to Resting State fMRI Data",
            "updated": "2023-11-06T20:58:07Z",
            "published": "2023-11-06T20:58:07Z",
            "summary": "Resting-state functional magnetic resonance imaging (rsfMRI) is a powerful\ntool for investigating the relationship between brain function and cognitive\nprocesses as it allows for the functional organization of the brain to be\ncaptured without relying on a specific task or stimuli. In this paper, we\npresent a novel modeling architecture called BrainRGIN for predicting\nintelligence (fluid, crystallized, and total intelligence) using graph neural\nnetworks on rsfMRI derived static functional network connectivity matrices.\nExtending from the existing graph convolution networks, our approach\nincorporates a clustering-based embedding and graph isomorphism network in the\ngraph convolutional layer to reflect the nature of the brain sub-network\norganization and efficient network expression, in combination with TopK pooling\nand attention-based readout functions. We evaluated our proposed architecture\non a large dataset, specifically the Adolescent Brain Cognitive Development\nDataset, and demonstrated its effectiveness in predicting individual\ndifferences in intelligence. Our model achieved lower mean squared errors and\nhigher correlation scores than existing relevant graph architectures and other\ntraditional machine learning models for all of the intelligence prediction\ntasks. The middle frontal gyrus exhibited a significant contribution to both\nfluid and crystallized intelligence, suggesting their pivotal role in these\ncognitive processes. Total composite scores identified a diverse set of brain\nregions to be relevant which underscores the complex nature of total\nintelligence.",
            "author": [
                "Bishal Thapaliya",
                "Esra Akbas",
                "Jiayu Chen",
                "Raam Sapkota",
                "Bhaskar Ray",
                "Pranav Suresh",
                "Vince Calhoun",
                "Jingyu Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03520v1",
                "http://arxiv.org/pdf/2311.03520v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03510v1",
            "title": "Spoken Dialogue System for Medical Prescription Acquisition on\n  Smartphone: Development, Corpus and Evaluation",
            "updated": "2023-11-06T20:36:55Z",
            "published": "2023-11-06T20:36:55Z",
            "summary": "Hospital information systems (HIS) have become an essential part of\nhealthcare institutions and now incorporate prescribing support software.\nPrescription support software allows for structured information capture, which\nimproves the safety, appropriateness and efficiency of prescriptions and\nreduces the number of adverse drug events (ADEs). However, such a system\nincreases the amount of time physicians spend at a computer entering\ninformation instead of providing medical care. In addition, any new visiting\nclinician must learn to manage complex interfaces since each HIS has its own\ninterfaces. In this paper, we present a natural language interface for\ne-prescribing software in the form of a spoken dialogue system accessible on a\nsmartphone. This system allows prescribers to record their prescriptions\nverbally, a form of interaction closer to their usual practice. The system\nextracts the formal representation of the prescription ready to be checked by\nthe prescribing software and uses the dialogue to request mandatory\ninformation, correct errors or warn of particular situations. Since, to the\nbest of our knowledge, there is no existing voice-based prescription dialogue\nsystem, we present the system developed in a low-resource environment, focusing\non dialogue modeling, semantic extraction and data augmentation. The system was\nevaluated in the wild with 55 participants. This evaluation showed that our\nsystem has an average prescription time of 66.15 seconds for physicians and\n35.64 seconds for other experts, and a task success rate of 76\\% for physicians\nand 72\\% for other experts. All evaluation data were recorded and annotated to\nform PxCorpus, the first spoken drug prescription corpus that has been made\nfully available to the community\n(\\url{https://doi.org/10.5281/zenodo.6524162}).",
            "author": [
                "Ali Can Kocabiyikoglu",
                "Fran\u00e7ois Portet",
                "Jean-Marc Babouchkine",
                "Prudence Gibert",
                "Herv\u00e9 Blanchon",
                "Ga\u00ebtan Gavazzi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03510v1",
                "http://arxiv.org/pdf/2311.03510v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03508v2",
            "title": "Astrocytes as a mechanism for meta-plasticity and contextually-guided\n  network function",
            "updated": "2023-11-10T15:59:40Z",
            "published": "2023-11-06T20:31:01Z",
            "summary": "Astrocytes are a ubiquitous and enigmatic type of non-neuronal cell and are\nfound in the brain of all vertebrates. While traditionally viewed as being\nsupportive of neurons, it is increasingly recognized that astrocytes may play a\nmore direct and active role in brain function and neural computation. On\naccount of their sensitivity to a host of physiological covariates and ability\nto modulate neuronal activity and connectivity on slower time scales,\nastrocytes may be particularly well poised to modulate the dynamics of neural\ncircuits in functionally salient ways. In the current paper, we seek to capture\nthese features via actionable abstractions within computational models of\nneuron-astrocyte interaction. Specifically, we engage how nested feedback loops\nof neuron-astrocyte interaction, acting over separated time-scales may endow\nastrocytes with the capability to enable learning in context-dependent\nsettings, where fluctuations in task parameters may occur much more slowly than\nwithin-task requirements. We pose a general model of neuron-synapse-astrocyte\ninteraction and use formal analysis to characterize how astrocytic modulation\nmay constitute a form of meta-plasticity, altering the ways in which synapses\nand neurons adapt as a function of time. We then embed this model in a\nbandit-based reinforcement learning task environment, and show how the presence\nof time-scale separated astrocytic modulation enables learning over multiple\nfluctuating contexts. Indeed, these networks learn far more reliably versus\ndynamically homogeneous networks and conventional non-network-based bandit\nalgorithms. Our results indicate how the presence of neuron-astrocyte\ninteraction in the brain may benefit learning over different time-scales and\nthe conveyance of task-relevant contextual information onto circuit dynamics.",
            "author": [
                "Lulu Gong",
                "Fabio Pasqualetti",
                "Thomas Papouin",
                "ShiNung Ching"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03508v2",
                "http://arxiv.org/pdf/2311.03508v2"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04240v1",
            "title": "Environmental-Impact Based Multi-Agent Reinforcement Learning",
            "updated": "2023-11-06T20:30:11Z",
            "published": "2023-11-06T20:30:11Z",
            "summary": "To promote cooperation and strengthen the individual impact on the collective\noutcome in social dilemmas, we propose the Environmental-impact Multi-Agent\nReinforcement Learning (EMuReL) method where each agent estimates the\n\"environmental impact\" of every other agent, that is, the difference in the\ncurrent environment state compared to the hypothetical environment in the\nabsence of that other agent. Inspired by the Inequity Aversion model, the agent\nthen compares its own reward with those of its fellows multiplied by their\nenvironmental impacts. If its reward exceeds the scaled reward of one of its\nfellows, the agent takes \"social responsibility\" toward that fellow by reducing\nits own reward. Therefore, the less influential an agent is in reaching the\ncurrent state, the more social responsibility is taken by other agents.\nExperiments in the Cleanup (resp. Harvest) test environment demonstrate that\nagents trained based on EMuReL learn to cooperate more effectively and obtain\n$54\\%$ ($39\\%$) and $20\\%$ ($44\\%$) more total rewards while preserving the\nsame cooperation levels compared to when they are trained based on the two\nstate-of-the-art reward reshaping methods inequity aversion and social\ninfluence.",
            "author": [
                "Farinaz Alamiyan-Harandi",
                "Pouria Ramazi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04240v1",
                "http://arxiv.org/pdf/2311.04240v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03501v1",
            "title": "Joint Sparse Estimation with Cardinality Constraint via Mixed-Integer\n  Semidefinite Programming",
            "updated": "2023-11-06T20:18:58Z",
            "published": "2023-11-06T20:18:58Z",
            "summary": "The multiple measurement vectors (MMV) problem refers to the joint estimation\nof a row-sparse signal matrix from multiple realizations of mixtures with a\nknown dictionary. As a generalization of the standard sparse representation\nproblem for a single measurement, this problem is fundamental in various\napplications in signal processing, e.g., spectral analysis and\ndirection-of-arrival (DOA) estimation. In this paper, we consider the maximum a\nposteriori (MAP) estimation for the MMV problem, which is classically\nformulated as a regularized least-squares (LS) problem with an\n$\\ell_{2,0}$-norm constraint, and derive an equivalent mixed-integer\nsemidefinite program (MISDP) reformulation. The proposed MISDP reformulation\ncan be exactly solved by a generic MISDP solver, which, however, becomes\ncomputationally demanding for problems of extremely large dimensions. To\nfurther reduce the computation time in such scenarios, a relaxation-based\napproach can be employed to obtain an approximate solution of the MISDP\nreformulation, at the expense of a reduced estimation performance. Numerical\nsimulations in the context of DOA estimation demonstrate the improved error\nperformance of our proposed method in comparison to several popular DOA\nestimation methods. In particular, compared to the deterministic maximum\nlikelihood (DML) estimator, which is often used as a benchmark, the proposed\nmethod applied with a state-of-the-art MISDP solver exhibits a superior\nestimation performance at a significantly reduced running time. Moreover,\nunlike other nonconvex approaches for the MMV problem, including the greedy\nmethods and the sparse Bayesian learning, the proposed MISDP-based method\noffers a guarantee of finding a global optimum.",
            "author": [
                "Tianyi Liu",
                "Frederic Matter",
                "Alexander Sorg",
                "Marc E. Pfetsch",
                "Martin Haardt",
                "Marius Pesavento"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03501v1",
                "http://arxiv.org/pdf/2311.03501v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03500v1",
            "title": "Predicting Age from White Matter Diffusivity with Residual Learning",
            "updated": "2023-11-06T20:18:26Z",
            "published": "2023-11-06T20:18:26Z",
            "summary": "Imaging findings inconsistent with those expected at specific chronological\nage ranges may serve as early indicators of neurological disorders and\nincreased mortality risk. Estimation of chronological age, and deviations from\nexpected results, from structural MRI data has become an important task for\ndeveloping biomarkers that are sensitive to such deviations. Complementary to\nstructural analysis, diffusion tensor imaging (DTI) has proven effective in\nidentifying age-related microstructural changes within the brain white matter,\nthereby presenting itself as a promising additional modality for brain age\nprediction. Although early studies have sought to harness DTI's advantages for\nage estimation, there is no evidence that the success of this prediction is\nowed to the unique microstructural and diffusivity features that DTI provides,\nrather than the macrostructural features that are also available in DTI data.\nTherefore, we seek to develop white-matter-specific age estimation to capture\ndeviations from normal white matter aging. Specifically, we deliberately\ndisregard the macrostructural information when predicting age from DTI scalar\nimages, using two distinct methods. The first method relies on extracting only\nmicrostructural features from regions of interest. The second applies 3D\nresidual neural networks (ResNets) to learn features directly from the images,\nwhich are non-linearly registered and warped to a template to minimize\nmacrostructural variations. When tested on unseen data, the first method yields\nmean absolute error (MAE) of 6.11 years for cognitively normal participants and\nMAE of 6.62 years for cognitively impaired participants, while the second\nmethod achieves MAE of 4.69 years for cognitively normal participants and MAE\nof 4.96 years for cognitively impaired participants. We find that the ResNet\nmodel captures subtler, non-macrostructural features for brain age prediction.",
            "author": [
                "Chenyu Gao",
                "Michael E. Kim",
                "Ho Hin Lee",
                "Qi Yang",
                "Nazirah Mohd Khairi",
                "Praitayini Kanakaraj",
                "Nancy R. Newlin",
                "Derek B. Archer",
                "Angela L. Jefferson",
                "Warren D. Taylor",
                "Brian D. Boyd",
                "Lori L. Beason-Held",
                "Susan M. Resnick",
                "The BIOCARD Study Team",
                "Yuankai Huo",
                "Katherine D. Van Schaik",
                "Kurt G. Schilling",
                "Daniel Moyer",
                "Ivana I\u0161gum",
                "Bennett A. Landman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03500v1",
                "http://arxiv.org/pdf/2311.03500v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03498v1",
            "title": "In-Context Exemplars as Clues to Retrieving from Large Associative\n  Memory",
            "updated": "2023-11-06T20:13:29Z",
            "published": "2023-11-06T20:13:29Z",
            "summary": "Recently, large language models (LLMs) have made remarkable progress in\nnatural language processing. The most representative ability of LLMs is\nin-context learning (ICL), which enables LLMs to learn patterns from in-context\nexemplars without training. The performance of ICL greatly depends on the\nexemplars used. However, how to choose exemplars remains unclear due to the\nlack of understanding of how in-context learning works. In this paper, we\npresent a novel perspective on ICL by conceptualizing it as contextual\nretrieval from a model of associative memory. We establish a theoretical\nframework of ICL based on Hopfield Networks. Based on our framework, we look\ninto how in-context exemplars influence the performance of ICL and propose more\nefficient active exemplar selection. Our study sheds new light on the mechanism\nof ICL by connecting it to memory retrieval, with potential implications for\nadvancing the understanding of LLMs.",
            "author": [
                "Jiachen Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03498v1",
                "http://arxiv.org/pdf/2311.03498v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03496v1",
            "title": "Asynchronous Local Computations in Distributed Bayesian Learning",
            "updated": "2023-11-06T20:11:41Z",
            "published": "2023-11-06T20:11:41Z",
            "summary": "Due to the expanding scope of machine learning (ML) to the fields of sensor\nnetworking, cooperative robotics and many other multi-agent systems,\ndistributed deployment of inference algorithms has received a lot of attention.\nThese algorithms involve collaboratively learning unknown parameters from\ndispersed data collected by multiple agents. There are two competing aspects in\nsuch algorithms, namely, intra-agent computation and inter-agent communication.\nTraditionally, algorithms are designed to perform both synchronously. However,\ncertain circumstances need frugal use of communication channels as they are\neither unreliable, time-consuming, or resource-expensive. In this paper, we\npropose gossip-based asynchronous communication to leverage fast computations\nand reduce communication overhead simultaneously. We analyze the effects of\nmultiple (local) intra-agent computations by the active agents between\nsuccessive inter-agent communications. For local computations, Bayesian\nsampling via unadjusted Langevin algorithm (ULA) MCMC is utilized. The\ncommunication is assumed to be over a connected graph (e.g., as in\ndecentralized learning), however, the results can be extended to coordinated\ncommunication where there is a central server (e.g., federated learning). We\ntheoretically quantify the convergence rates in the process. To demonstrate the\nefficacy of the proposed algorithm, we present simulations on a toy problem as\nwell as on real world data sets to train ML models to perform classification\ntasks. We observe faster initial convergence and improved performance accuracy,\nespecially in the low data range. We achieve on average 78% and over 90%\nclassification accuracy respectively on the Gamma Telescope and mHealth data\nsets from the UCI ML repository.",
            "author": [
                "Kinjal Bhar",
                "He Bai",
                "Jemin George",
                "Carl Busart"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03496v1",
                "http://arxiv.org/pdf/2311.03496v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03490v1",
            "title": "Analytics, have some humility: a statistical view of fourth-down\n  decision making",
            "updated": "2023-11-06T20:00:16Z",
            "published": "2023-11-06T20:00:16Z",
            "summary": "Expected points (EP) and win probability (WP) are value functions fundamental\nto strategic in-game decision making in American football, particularly for\nfourth down decision making. The EP and WP functions which are widely used\ntoday are statistical models fit from historical data. These models, however,\nare subject to serious statistical flaws: selection bias, overfitting, ignoring\nautocorrelation, and ignoring uncertainty quantification. We develop a machine\nlearning framework that accounts for these issues and extracts our analysis\ninto a decision-making inference. Along the way, we introduce a novel\nmethodological approach to mitigate overfitting in machine learning models.\nSpecifically, we extend the catalytic prior, initially developed in the context\nof linear models, to smooth our tree machine learning models. Our final product\nis a major advance in fourth-down strategic decision making: far fewer\nfourth-down decisions are as obvious as analysts claim.",
            "author": [
                "Ryan S. Brill",
                "Abraham J. Wyner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03490v1",
                "http://arxiv.org/pdf/2311.03490v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03489v2",
            "title": "Leveraging High-Level Synthesis and Large Language Models to Generate,\n  Simulate, and Deploy a Uniform Random Number Generator Hardware Design",
            "updated": "2023-11-21T17:28:17Z",
            "published": "2023-11-06T19:58:26Z",
            "summary": "We present a new high-level synthesis methodology for using large language\nmodel tools to generate hardware designs. The methodology uses exclusively\nopen-source tools excluding the large language model. As a case study, we use\nour methodology to generate a permuted congruential random number generator\ndesign with a wishbone interface. We verify the functionality and quality of\nthe random number generator design using large language model-generated\nsimulations and the Dieharder randomness test suite. We document all the large\nlanguage model chat logs, Python scripts, Verilog scripts, and simulation\nresults used in the case study. We believe that our method of hardware design\ngeneration coupled with the open source silicon 130 nm design tools will\nrevolutionize application-specific integrated circuit design. Our methodology\nsignificantly lowers the bar to entry when building domain-specific computing\naccelerators for the Internet of Things and proof of concept prototypes for\nlater fabrication in more modern process nodes.",
            "author": [
                "James T. Meech"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03489v2",
                "http://arxiv.org/pdf/2311.03489v2"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.LG",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04239v1",
            "title": "Kindness in Multi-Agent Reinforcement Learning",
            "updated": "2023-11-06T19:53:26Z",
            "published": "2023-11-06T19:53:26Z",
            "summary": "In human societies, people often incorporate fairness in their decisions and\ntreat reciprocally by being kind to those who act kindly. They evaluate the\nkindness of others' actions not only by monitoring the outcomes but also by\nconsidering the intentions. This behavioral concept can be adapted to train\ncooperative agents in Multi-Agent Reinforcement Learning (MARL). We propose the\nKindMARL method, where agents' intentions are measured by counterfactual\nreasoning over the environmental impact of the actions that were available to\nthe agents. More specifically, the current environment state is compared with\nthe estimation of the current environment state provided that the agent had\nchosen another action. The difference between each agent's reward, as the\noutcome of its action, with that of its fellow, multiplied by the intention of\nthe fellow is then taken as the fellow's \"kindness\". If the result of each\nreward-comparison confirms the agent's superiority, it perceives the fellow's\nkindness and reduces its own reward. Experimental results in the Cleanup and\nHarvest environments show that training based on the KindMARL method enabled\nthe agents to earn 89\\% (resp. 37\\%) and 44% (resp. 43\\%) more total rewards\nthan training based on the Inequity Aversion and Social Influence methods. The\neffectiveness of KindMARL is further supported by experiments in a traffic\nlight control problem.",
            "author": [
                "Farinaz Alamiyan-Harandi",
                "Mersad Hassanjani",
                "Pouria Ramazi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04239v1",
                "http://arxiv.org/pdf/2311.04239v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03488v3",
            "title": "Multi-Resolution Diffusion for Privacy-Sensitive Recommender Systems",
            "updated": "2023-11-21T03:08:37Z",
            "published": "2023-11-06T19:52:55Z",
            "summary": "While recommender systems have become an integral component of the Web\nexperience, their heavy reliance on user data raises privacy and security\nconcerns. Substituting user data with synthetic data can address these\nconcerns, but accurately replicating these real-world datasets has been a\nnotoriously challenging problem. Recent advancements in generative AI have\ndemonstrated the impressive capabilities of diffusion models in generating\nrealistic data across various domains. In this work we introduce a Score-based\nDiffusion Recommendation Module (SDRM), which captures the intricate patterns\nof real-world datasets required for training highly accurate recommender\nsystems. SDRM allows for the generation of synthetic data that can replace\nexisting datasets to preserve user privacy, or augment existing datasets to\naddress excessive data sparsity. Our method outperforms competing baselines\nsuch as generative adversarial networks, variational autoencoders, and recently\nproposed diffusion models in synthesizing various datasets to replace or\naugment the original data by an average improvement of 4.30% in Recall@$k$ and\n4.65% in NDCG@$k$.",
            "author": [
                "Derek Lilienthal",
                "Paul Mello",
                "Magdalini Eirinaki",
                "Stas Tiomkin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03488v3",
                "http://arxiv.org/pdf/2311.03488v3"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03486v2",
            "title": "Fostering Human Learning in Sequential Decision-Making: Understanding\n  the Role of Evaluative Feedback",
            "updated": "2023-11-10T04:52:21Z",
            "published": "2023-11-06T19:48:33Z",
            "summary": "Cognitive rehabilitation, STEM skill acquisition, and coaching games such as\nchess often require tutoring decision-making strategies. The advancement of\nAI-driven tutoring systems for facilitating human learning requires an\nunderstanding of the impact of evaluative feedback on human decision-making and\nskill development. To this end, we conduct human experiments using Amazon\nMechanical Turk to study the influence of evaluative feedback on human\ndecision-making in sequential tasks. In these experiments, participants solve\nthe Tower of Hanoi puzzle and receive AI-generated feedback while solving it.\nWe examine how this feedback affects their learning and skill transfer to\nrelated tasks. We also explore various computational models to understand how\npeople incorporate evaluative feedback into their decision-making processes.",
            "author": [
                "Piyush Gupta",
                "Subir Biswas",
                "Vaibhav Srivastava"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03486v2",
                "http://arxiv.org/pdf/2311.03486v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03485v1",
            "title": "CLIP-Motion: Learning Reward Functions for Robotic Actions Using\n  Consecutive Observations",
            "updated": "2023-11-06T19:48:03Z",
            "published": "2023-11-06T19:48:03Z",
            "summary": "This paper presents a novel method for learning reward functions for robotic\nmotions by harnessing the power of a CLIP-based model. Traditional reward\nfunction design often hinges on manual feature engineering, which can struggle\nto generalize across an array of tasks. Our approach circumvents this challenge\nby capitalizing on CLIP's capability to process both state features and image\ninputs effectively. Given a pair of consecutive observations, our model excels\nin identifying the motion executed between them. We showcase results spanning\nvarious robotic activities, such as directing a gripper to a designated target\nand adjusting the position of a cube. Through experimental evaluations, we\nunderline the proficiency of our method in precisely deducing motion and its\npromise to enhance reinforcement learning training in the realm of robotics.",
            "author": [
                "Xuzhe Dang",
                "Stefan Edelkamp",
                "Nicolas Ribault"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03485v1",
                "http://arxiv.org/pdf/2311.03485v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03477v1",
            "title": "Repairing Learning-Enabled Controllers While Preserving What Works",
            "updated": "2023-11-06T19:28:22Z",
            "published": "2023-11-06T19:28:22Z",
            "summary": "Learning-enabled controllers have been adopted in various cyber-physical\nsystems (CPS). When a learning-enabled controller fails to accomplish its task\nfrom a set of initial states, researchers leverage repair algorithms to\nfine-tune the controller's parameters. However, existing repair techniques do\nnot preserve previously correct behaviors. Specifically, when modifying the\nparameters to repair trajectories from a subset of initial states, another\nsubset may be compromised. Therefore, the repair may break previously correct\nscenarios, introducing new risks that may not be accounted for. Due to this\nissue, repairing the entire initial state space may be hard or even infeasible.\nAs a response, we formulate the Repair with Preservation (RwP) problem, which\ncalls for preserving the already-correct scenarios during repair. To tackle\nthis problem, we design the Incremental Simulated Annealing Repair (ISAR)\nalgorithm, which leverages simulated annealing on a barriered energy function\nto safeguard the already-correct initial states while repairing as many\nadditional ones as possible. Moreover, formal verification is utilized to\nguarantee the repair results. Case studies on an Unmanned Underwater Vehicle\n(UUV) and OpenAI Gym Mountain Car (MC) show that ISAR not only preserves\ncorrect behaviors from previously verified initial state regions, but also\nrepairs 81.4% and 23.5% of broken state spaces in the two benchmarks. Moreover,\nthe average STL robustnesses of the ISAR repaired controllers are larger than\nthose of the controllers repaired using baseline methods.",
            "author": [
                "Pengyuan Lu",
                "Matthew Cleaveland",
                "Oleg Sokolsky",
                "Insup Lee",
                "Ivan Ruchkin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03477v1",
                "http://arxiv.org/pdf/2311.03477v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03476v1",
            "title": "Lessons Learned from Efforts to Standardize Streaming In SQL",
            "updated": "2023-11-06T19:28:08Z",
            "published": "2023-11-06T19:28:08Z",
            "summary": "Acknowledging the reality of streaming languages and platforms overlapping\nwith SQL and database systems, in 2019 INCTIS Data Management established an\nExpert Group with the focused mission to initiate the process of standardizing\nstreaming support in SQL. Over time, the roster included companies like Actian,\nAlibaba, Amazon Web Services, Confluent, dbt Labs, Google, Hazelcast, IBM,\nMaterialize, Microsoft, Oracle, Snowflake, SQLstream and Timeplus. For the span\nof more than one year, representatives of each company have presented key\nfeatures of their streaming product or, in some cases, multiple streaming\nproducts. These were live technical Q&A sessions accompanied by summary or\nposition papers, which are unquestionably valuable. As expected, substantial\ntime was spent in clarifying what common terms meant in each system and setting\nup a glossary. These sessions were followed by clarification notes and debates,\nand decisions that appeared mandatory to allow further progress. This first\nphase was followed by the next phase, which consisted of the group meetings, in\nwhich the expert group (EG) agreed on main exit criteria topics that a\nstreaming solution in SQL must address, and position papers and follow-ups were\nwritten and discussed. This paper summarizes these group efforts, up to the\nsummer of 2023.",
            "author": [
                "Sabina Petride",
                "Dan Sotolongo",
                "Jan Michels",
                "Andrew Witkowski",
                "Cara Haas",
                "Jim Hughes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03476v1",
                "http://arxiv.org/pdf/2311.03476v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03470v1",
            "title": "Orion: A Fully Homomorphic Encryption Compiler for Private Deep Neural\n  Network Inference",
            "updated": "2023-11-06T19:14:17Z",
            "published": "2023-11-06T19:14:17Z",
            "summary": "Fully Homomorphic Encryption (FHE) has the potential to substantially improve\nprivacy and security by enabling computation on encrypted data. This is\nespecially true with deep learning, as today many popular user services are\npowered by neural networks. One of the major challenges facing wide-scale\ndeployment of FHE-secured neural inference is effectively mapping them to the\nFHE domain. FHE poses many programming challenges including packing large\nvectors, handling expensive rotations, and correctly implementing complex\nstrided convolutions. This makes programming FHE inferences prone to poor\nperformance and errors. In this paper we overcome these challenges with Orion,\nan automated optimizing FHE compiler for neural inference. Orion automatically\nmaps PyTorch-specified networks to FHE, handling common layer types and\narbitrary tensor shapes and strides. Moreover, we develop novel optimizations\nthat balance dense FHE vector packing, efficient rotations, and minimize\noperations to improve performance. We have implemented Orion, which will be\nopen sourced, and evaluated it on common benchmarks used by the FHE deep\nlearning community. We compare Orion to multiple state-of-the-art solutions and\nreport iso-accuracy speedups ranging from 2.7$\\times$ to 20.5$\\times$.",
            "author": [
                "Austin Ebel",
                "Karthik Garimella",
                "Brandon Reagen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03470v1",
                "http://arxiv.org/pdf/2311.03470v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03468v1",
            "title": "FinA: Fairness of Adverse Effects in Decision-Making of\n  Human-Cyber-Physical-System",
            "updated": "2023-11-06T19:10:03Z",
            "published": "2023-11-06T19:10:03Z",
            "summary": "Ensuring fairness in decision-making systems within\nHuman-Cyber-Physical-Systems (HCPS) is a pressing concern, particularly when\ndiverse individuals, each with varying behaviors and expectations, coexist\nwithin the same application space, influenced by a shared set of control\nactions in the system. The long-term adverse effects of these actions further\npose the challenge, as historical experiences and interactions shape individual\nperceptions of fairness. This paper addresses the challenge of fairness from an\nequity perspective of adverse effects, taking into account the dynamic nature\nof human behavior and evolving preferences while recognizing the lasting impact\nof adverse effects. We formally introduce the concept of\nFairness-in-Adverse-Effects (FinA) within the HCPS context. We put forth a\ncomprehensive set of five formulations for FinA, encompassing both the\ninstantaneous and long-term aspects of adverse effects. To empirically validate\nthe effectiveness of our FinA approach, we conducted an evaluation within the\ndomain of smart homes, a pertinent HCPS application. The outcomes of our\nevaluation demonstrate that the adoption of FinA significantly enhances the\noverall perception of fairness among individuals, yielding an average\nimprovement of 66.7% when compared to the state-of-the-art method.",
            "author": [
                "Tianyu Zhao",
                "Salma Elmalaki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03468v1",
                "http://arxiv.org/pdf/2311.03468v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CY",
                "cs.HC",
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03449v1",
            "title": "Into the LAIONs Den: Investigating Hate in Multimodal Datasets",
            "updated": "2023-11-06T19:00:05Z",
            "published": "2023-11-06T19:00:05Z",
            "summary": "'Scale the model, scale the data, scale the compute' is the reigning\nsentiment in the world of generative AI today. While the impact of model\nscaling has been extensively studied, we are only beginning to scratch the\nsurface of data scaling and its consequences. This is especially of critical\nimportance in the context of vision-language datasets such as LAION. These\ndatasets are continually growing in size and are built based on large-scale\ninternet dumps such as the Common Crawl, which is known to have numerous\ndrawbacks ranging from quality, legality, and content. The datasets then serve\nas the backbone for large generative models, contributing to the\noperationalization and perpetuation of harmful societal and historical biases\nand stereotypes. In this paper, we investigate the effect of scaling datasets\non hateful content through a comparative audit of two datasets: LAION-400M and\nLAION-2B. Our results show that hate content increased by nearly 12% with\ndataset scale, measured both qualitatively and quantitatively using a metric\nthat we term as Hate Content Rate (HCR). We also found that filtering dataset\ncontents based on Not Safe For Work (NSFW) values calculated based on images\nalone does not exclude all the harmful content in alt-text. Instead, we found\nthat trace amounts of hateful, targeted, and aggressive text remain even when\ncarrying out conservative filtering. We end with a reflection and a discussion\nof the significance of our results for dataset curation and usage in the AI\ncommunity. Code and the meta-data assets curated in this paper are publicly\navailable at https://github.com/vinayprabhu/hate_scaling. Content warning: This\npaper contains examples of hateful text that might be disturbing, distressing,\nand/or offensive.",
            "author": [
                "Abeba Birhane",
                "Vinay Prabhu",
                "Sang Han",
                "Vishnu Naresh Boddeti",
                "Alexandra Sasha Luccioni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03449v1",
                "http://arxiv.org/pdf/2311.03449v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03437v1",
            "title": "Machine learning the breakdown of tame effective theories",
            "updated": "2023-11-06T19:00:01Z",
            "published": "2023-11-06T19:00:01Z",
            "summary": "Effective field theories endowed with a nontrivial moduli space may be broken\ndown by several, distinct effects as the energy scales that are probed\nincrease. These may include the appearance of a finite number of new states, or\nthe emergence of an infinite tower of states, as predicted by the Distance\nConjecture. Consequently, the moduli space can be partitioned according to\nwhich kind of state first breaks down the effective description, and the\neffective-theory cutoff has to be regarded as a function of the moduli that may\nabruptly vary in form across the components of the partition. In this work we\ncharacterize such a slicing of the moduli space, induced by the diverse\nbreakdown mechanisms, in a two-fold way. Firstly, employing the recently\nformulated Tameness Conjecture, we show that the partition of the moduli space\nso constructed is composed only of a finite number of distinct components.\nSecondly, we illustrate how this partition can be concretely constructed by\nmeans of supervised machine learning techniques, with minimal bottom-up\ninformation.",
            "author": [
                "Stefano Lanza"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03437v1",
                "http://arxiv.org/pdf/2311.03437v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03357v1",
            "title": "Exploitation-Guided Exploration for Semantic Embodied Navigation",
            "updated": "2023-11-06T18:59:58Z",
            "published": "2023-11-06T18:59:58Z",
            "summary": "In the recent progress in embodied navigation and sim-to-robot transfer,\nmodular policies have emerged as a de facto framework. However, there is more\nto compositionality beyond the decomposition of the learning load into modular\ncomponents. In this work, we investigate a principled way to syntactically\ncombine these components. Particularly, we propose Exploitation-Guided\nExploration (XGX) where separate modules for exploration and exploitation come\ntogether in a novel and intuitive manner. We configure the exploitation module\nto take over in the deterministic final steps of navigation i.e. when the goal\nbecomes visible. Crucially, an exploitation module teacher-forces the\nexploration module and continues driving an overridden policy optimization.\nXGX, with effective decomposition and novel guidance, improves the\nstate-of-the-art performance on the challenging object navigation task from 70%\nto 73%. Along with better accuracy, through targeted analysis, we show that XGX\nis also more efficient at goal-conditioned exploration. Finally, we show\nsim-to-real transfer to robot hardware and XGX performs over two-fold better\nthan the best baseline from simulation benchmarking. Project page:\nxgxvisnav.github.io",
            "author": [
                "Justin Wasserman",
                "Girish Chowdhary",
                "Abhinav Gupta",
                "Unnat Jain"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03357v1",
                "http://arxiv.org/pdf/2311.03357v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03355v1",
            "title": "SegGen: Supercharging Segmentation Models with Text2Mask and Mask2Img\n  Synthesis",
            "updated": "2023-11-06T18:59:57Z",
            "published": "2023-11-06T18:59:57Z",
            "summary": "We propose SegGen, a highly-effective training data generation method for\nimage segmentation, which pushes the performance limits of state-of-the-art\nsegmentation models to a significant extent. SegGen designs and integrates two\ndata generation strategies: MaskSyn and ImgSyn. (i) MaskSyn synthesizes new\nmask-image pairs via our proposed text-to-mask generation model and\nmask-to-image generation model, greatly improving the diversity in segmentation\nmasks for model supervision; (ii) ImgSyn synthesizes new images based on\nexisting masks using the mask-to-image generation model, strongly improving\nimage diversity for model inputs. On the highly competitive ADE20K and COCO\nbenchmarks, our data generation method markedly improves the performance of\nstate-of-the-art segmentation models in semantic segmentation, panoptic\nsegmentation, and instance segmentation. Notably, in terms of the ADE20K mIoU,\nMask2Former R50 is largely boosted from 47.2 to 49.9 (+2.7); Mask2Former Swin-L\nis also significantly increased from 56.1 to 57.4 (+1.3). These promising\nresults strongly suggest the effectiveness of our SegGen even when abundant\nhuman-annotated training data is utilized. Moreover, training with our\nsynthetic data makes the segmentation models more robust towards unseen\ndomains. Project website: https://seggenerator.github.io",
            "author": [
                "Hanrong Ye",
                "Jason Kuen",
                "Qing Liu",
                "Zhe Lin",
                "Brian Price",
                "Dan Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03355v1",
                "http://arxiv.org/pdf/2311.03355v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03351v1",
            "title": "Uni-O4: Unifying Online and Offline Deep Reinforcement Learning with\n  Multi-Step On-Policy Optimization",
            "updated": "2023-11-06T18:58:59Z",
            "published": "2023-11-06T18:58:59Z",
            "summary": "Combining offline and online reinforcement learning (RL) is crucial for\nefficient and safe learning. However, previous approaches treat offline and\nonline learning as separate procedures, resulting in redundant designs and\nlimited performance. We ask: Can we achieve straightforward yet effective\noffline and online learning without introducing extra conservatism or\nregularization? In this study, we propose Uni-o4, which utilizes an on-policy\nobjective for both offline and online learning. Owning to the alignment of\nobjectives in two phases, the RL agent can transfer between offline and online\nlearning seamlessly. This property enhances the flexibility of the learning\nparadigm, allowing for arbitrary combinations of pretraining, fine-tuning,\noffline, and online learning. In the offline phase, specifically, Uni-o4\nleverages diverse ensemble policies to address the mismatch issues between the\nestimated behavior policy and the offline dataset. Through a simple offline\npolicy evaluation (OPE) approach, Uni-o4 can achieve multi-step policy\nimprovement safely. We demonstrate that by employing the method above, the\nfusion of these two paradigms can yield superior offline initialization as well\nas stable and rapid online fine-tuning capabilities. Through real-world robot\ntasks, we highlight the benefits of this paradigm for rapid deployment in\nchallenging, previously unseen real-world environments. Additionally, through\ncomprehensive evaluations using numerous simulated benchmarks, we substantiate\nthat our method achieves state-of-the-art performance in both offline and\noffline-to-online fine-tuning learning. Our website:\nhttps://lei-kun.github.io/uni-o4/ .",
            "author": [
                "Kun Lei",
                "Zhengmao He",
                "Chenhao Lu",
                "Kaizhe Hu",
                "Yang Gao",
                "Huazhe Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03351v1",
                "http://arxiv.org/pdf/2311.03351v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03350v3",
            "title": "Differentiable Cutting-plane Layers for Mixed-integer Linear\n  Optimization",
            "updated": "2023-11-09T17:19:56Z",
            "published": "2023-11-06T18:57:07Z",
            "summary": "We consider the problem of solving a family of parametric mixed-integer\nlinear optimization problems where some entries in the input data change. We\nintroduce the concept of cutting-plane layer (CPL), i.e., a differentiable\ncutting-plane generator mapping the problem data and previous iterates to\ncutting planes. We propose a CPL implementation to generate split cuts, and by\ncombining several CPLs, we devise a differentiable cutting-plane algorithm that\nexploits the repeated nature of parametric instances. In an offline phase, we\ntrain our algorithm by updating the internal parameters controlling the CPLs,\nthus altering cut generation. Once trained, our algorithm computes, with\npredictable execution times and a fixed number of cuts, solutions with low\nintegrality gaps. Preliminary computational tests show that our algorithm\ngeneralizes on unseen instances and captures underlying parametric structures.",
            "author": [
                "Gabriele Dragotto",
                "Stefan Clarke",
                "Jaime Fern\u00e1ndez Fisac",
                "Bartolomeo Stellato"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03350v3",
                "http://arxiv.org/pdf/2311.03350v3"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03348v2",
            "title": "Scalable and Transferable Black-Box Jailbreaks for Language Models via\n  Persona Modulation",
            "updated": "2023-11-24T12:50:31Z",
            "published": "2023-11-06T18:55:18Z",
            "summary": "Despite efforts to align large language models to produce harmless responses,\nthey are still vulnerable to jailbreak prompts that elicit unrestricted\nbehaviour. In this work, we investigate persona modulation as a black-box\njailbreaking method to steer a target model to take on personalities that are\nwilling to comply with harmful instructions. Rather than manually crafting\nprompts for each persona, we automate the generation of jailbreaks using a\nlanguage model assistant. We demonstrate a range of harmful completions made\npossible by persona modulation, including detailed instructions for\nsynthesising methamphetamine, building a bomb, and laundering money. These\nautomated attacks achieve a harmful completion rate of 42.5% in GPT-4, which is\n185 times larger than before modulation (0.23%). These prompts also transfer to\nClaude 2 and Vicuna with harmful completion rates of 61.0% and 35.9%,\nrespectively. Our work reveals yet another vulnerability in commercial large\nlanguage models and highlights the need for more comprehensive safeguards.",
            "author": [
                "Rusheb Shah",
                "Quentin Feuillade--Montixi",
                "Soroush Pour",
                "Arush Tagade",
                "Stephen Casper",
                "Javier Rando"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03348v2",
                "http://arxiv.org/pdf/2311.03348v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03345v1",
            "title": "Long-Term Invariant Local Features via Implicit Cross-Domain\n  Correspondences",
            "updated": "2023-11-06T18:53:01Z",
            "published": "2023-11-06T18:53:01Z",
            "summary": "Modern learning-based visual feature extraction networks perform well in\nintra-domain localization, however, their performance significantly declines\nwhen image pairs are captured across long-term visual domain variations, such\nas different seasonal and daytime variations. In this paper, our first\ncontribution is a benchmark to investigate the performance impact of long-term\nvariations on visual localization. We conduct a thorough analysis of the\nperformance of current state-of-the-art feature extraction networks under\nvarious domain changes and find a significant performance gap between intra-\nand cross-domain localization. We investigate different methods to close this\ngap by improving the supervision of modern feature extractor networks. We\npropose a novel data-centric method, Implicit Cross-Domain Correspondences\n(iCDC). iCDC represents the same environment with multiple Neural Radiance\nFields, each fitting the scene under individual visual domains. It utilizes the\nunderlying 3D representations to generate accurate correspondences across\ndifferent long-term visual conditions. Our proposed method enhances\ncross-domain localization performance, significantly reducing the performance\ngap. When evaluated on popular long-term localization benchmarks, our trained\nnetworks consistently outperform existing methods. This work serves as a\nsubstantial stride toward more robust visual localization pipelines for\nlong-term deployments, and opens up research avenues in the development of\nlong-term invariant descriptors.",
            "author": [
                "Zador Pataki",
                "Mohammad Altillawi",
                "Menelaos Kanakis",
                "R\u00e9mi Pautrat",
                "Fengyi Shen",
                "Ziyuan Liu",
                "Luc Van Gool",
                "Marc Pollefeys"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03345v1",
                "http://arxiv.org/pdf/2311.03345v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03340v2",
            "title": "Multitask Kernel-based Learning with First-Order Logic Constraints",
            "updated": "2023-11-08T18:03:48Z",
            "published": "2023-11-06T18:44:55Z",
            "summary": "In this paper we propose a general framework to integrate supervised and\nunsupervised examples with background knowledge expressed by a collection of\nfirst-order logic clauses into kernel machines. In particular, we consider a\nmulti-task learning scheme where multiple predicates defined on a set of\nobjects are to be jointly learned from examples, enforcing a set of FOL\nconstraints on the admissible configurations of their values. The predicates\nare defined on the feature spaces, in which the input objects are represented,\nand can be either known a priori or approximated by an appropriate kernel-based\nlearner. A general approach is presented to convert the FOL clauses into a\ncontinuous implementation that can deal with the outputs computed by the\nkernel-based predicates. The learning problem is formulated as a\nsemi-supervised task that requires the optimization in the primal of a loss\nfunction that combines a fitting loss measure on the supervised examples, a\nregularization term, and a penalty term that enforces the constraints on both\nthe supervised and unsupervised examples. Unfortunately, the penalty term is\nnot convex and it can hinder the optimization process. However, it is possible\nto avoid poor solutions by using a two stage learning schema, in which the\nsupervised examples are learned first and then the constraints are enforced.",
            "author": [
                "Michelangelo Diligenti",
                "Marco Gori",
                "Marco Maggini",
                "Leonardo Rigutini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03340v2",
                "http://arxiv.org/pdf/2311.03340v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03429v2",
            "title": "ProPath: Disease-Specific Protein Language Model for Variant\n  Pathogenicity",
            "updated": "2023-11-08T04:35:37Z",
            "published": "2023-11-06T18:43:47Z",
            "summary": "Clinical variant classification of pathogenic versus benign genetic variants\nremains a pivotal challenge in clinical genetics. Recently, the proposition of\nprotein language models has improved the generic variant effect prediction\n(VEP) accuracy via weakly-supervised or unsupervised training. However, these\nVEPs are not disease-specific, limiting their adaptation at point-of-care. To\naddress this problem, we propose a disease-specific \\textsc{pro}tein language\nmodel for variant \\textsc{path}ogenicity, termed ProPath, to capture the\npseudo-log-likelihood ratio in rare missense variants through a siamese\nnetwork. We evaluate the performance of ProPath against pre-trained language\nmodels, using clinical variant sets in inherited cardiomyopathies and\narrhythmias that were not seen during training. Our results demonstrate that\nProPath surpasses the pre-trained ESM1b with an over $5\\%$ improvement in AUC\nacross both datasets. Furthermore, our model achieved the highest performances\nacross all baselines for both datasets. Thus, our ProPath offers a potent\ndisease-specific variant effect prediction, particularly valuable for disease\nassociations and clinical applicability.",
            "author": [
                "Huixin Zhan",
                "Zijun Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03429v2",
                "http://arxiv.org/pdf/2311.03429v2"
            ],
            "primary_category": "q-bio.GN",
            "category": [
                "q-bio.GN",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03339v1",
            "title": "FLOGA: A machine learning ready dataset, a benchmark and a novel deep\n  learning model for burnt area mapping with Sentinel-2",
            "updated": "2023-11-06T18:42:05Z",
            "published": "2023-11-06T18:42:05Z",
            "summary": "Over the last decade there has been an increasing frequency and intensity of\nwildfires across the globe, posing significant threats to human and animal\nlives, ecosystems, and socio-economic stability. Therefore urgent action is\nrequired to mitigate their devastating impact and safeguard Earth's natural\nresources. Robust Machine Learning methods combined with the abundance of\nhigh-resolution satellite imagery can provide accurate and timely mappings of\nthe affected area in order to assess the scale of the event, identify the\nimpacted assets and prioritize and allocate resources effectively for the\nproper restoration of the damaged region. In this work, we create and introduce\na machine-learning ready dataset we name FLOGA (Forest wiLdfire Observations\nfor the Greek Area). This dataset is unique as it comprises of satellite\nimagery acquired before and after a wildfire event, it contains information\nfrom Sentinel-2 and MODIS modalities with variable spatial and spectral\nresolution, and contains a large number of events where the corresponding burnt\narea ground truth has been annotated by domain experts. FLOGA covers the wider\nregion of Greece, which is characterized by a Mediterranean landscape and\nclimatic conditions. We use FLOGA to provide a thorough comparison of multiple\nMachine Learning and Deep Learning algorithms for the automatic extraction of\nburnt areas, approached as a change detection task. We also compare the results\nto those obtained using standard specialized spectral indices for burnt area\nmapping. Finally, we propose a novel Deep Learning model, namely BAM-CD. Our\nbenchmark results demonstrate the efficacy of the proposed technique in the\nautomatic extraction of burnt areas, outperforming all other methods in terms\nof accuracy and robustness. Our dataset and code are publicly available at:\nhttps://github.com/Orion-AI-Lab/FLOGA.",
            "author": [
                "Maria Sdraka",
                "Alkinoos Dimakos",
                "Alexandros Malounis",
                "Zisoula Ntasiou",
                "Konstantinos Karantzalos",
                "Dimitrios Michail",
                "Ioannis Papoutsis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03339v1",
                "http://arxiv.org/pdf/2311.03339v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03332v1",
            "title": "Learning Hard-Constrained Models with One Sample",
            "updated": "2023-11-06T18:29:57Z",
            "published": "2023-11-06T18:29:57Z",
            "summary": "We consider the problem of estimating the parameters of a Markov Random Field\nwith hard-constraints using a single sample. As our main running examples, we\nuse the $k$-SAT and the proper coloring models, as well as general $H$-coloring\nmodels; for all of these we obtain both positive and negative results. In\ncontrast to the soft-constrained case, we show in particular that single-sample\nestimation is not always possible, and that the existence of an estimator is\nrelated to the existence of non-satisfiable instances.\n  Our algorithms are based on the pseudo-likelihood estimator. We show variance\nbounds for this estimator using coupling techniques inspired, in the case of\n$k$-SAT, by Moitra's sampling algorithm (JACM, 2019); our positive results for\ncolorings build on this new coupling approach. For $q$-colorings on graphs with\nmaximum degree $d$, we give a linear-time estimator when $q>d+1$, whereas the\nproblem is non-identifiable when $q\\leq d+1$. For general $H$-colorings, we\nshow that standard conditions that guarantee sampling, such as Dobrushin's\ncondition, are insufficient for one-sample learning; on the positive side, we\nprovide a general condition that is sufficient to guarantee linear-time\nlearning and obtain applications for proper colorings and permissive models.\nFor the $k$-SAT model on formulas with maximum degree $d$, we provide a\nlinear-time estimator when $k\\gtrsim 6.45\\log d$, whereas the problem becomes\nnon-identifiable when $k\\lesssim \\log d$.",
            "author": [
                "Andreas Galanis",
                "Alkis Kalavasis",
                "Anthimos Vardis Kandiros"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03332v1",
                "http://arxiv.org/pdf/2311.03332v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03427v1",
            "title": "TSP-Transformer: Task-Specific Prompts Boosted Transformer for Holistic\n  Scene Understanding",
            "updated": "2023-11-06T18:20:02Z",
            "published": "2023-11-06T18:20:02Z",
            "summary": "Holistic scene understanding includes semantic segmentation, surface normal\nestimation, object boundary detection, depth estimation, etc. The key aspect of\nthis problem is to learn representation effectively, as each subtask builds\nupon not only correlated but also distinct attributes. Inspired by\nvisual-prompt tuning, we propose a Task-Specific Prompts Transformer, dubbed\nTSP-Transformer, for holistic scene understanding. It features a vanilla\ntransformer in the early stage and tasks-specific prompts transformer encoder\nin the lateral stage, where tasks-specific prompts are augmented. By doing so,\nthe transformer layer learns the generic information from the shared parts and\nis endowed with task-specific capacity. First, the tasks-specific prompts serve\nas induced priors for each task effectively. Moreover, the task-specific\nprompts can be seen as switches to favor task-specific representation learning\nfor different tasks. Extensive experiments on NYUD-v2 and PASCAL-Context show\nthat our method achieves state-of-the-art performance, validating the\neffectiveness of our method for holistic scene understanding. We also provide\nour code in the following link https://github.com/tb2-sy/TSP-Transformer.",
            "author": [
                "Shuo Wang",
                "Jing Li",
                "Zibo Zhao",
                "Dongze Lian",
                "Binbin Huang",
                "Xiaomei Wang",
                "Zhengxin Li",
                "Shenghua Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03427v1",
                "http://arxiv.org/pdf/2311.03427v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10754v2",
            "title": "A Recent Survey of the Advancements in Deep Learning Techniques for\n  Monkeypox Disease Detection",
            "updated": "2023-11-23T20:08:49Z",
            "published": "2023-11-06T18:18:42Z",
            "summary": "Monkeypox (MPox) is a zoonotic infectious disease induced by the MPox Virus,\npart of the poxviridae orthopoxvirus group initially discovered in Africa and\ngained global attention in mid-2022 with cases reported outside endemic areas.\nSymptoms include headaches, chills, fever, smallpox, measles, and\nchickenpox-like skin manifestations and the WHO officially announced MPox as a\nglobal public health pandemic, in July 2022.Traditionally, PCR testing of skin\nlesions is considered a benchmark for the primary diagnosis by WHO, with\nsymptom management as the primary treatment and antiviral drugs like\ntecovirimat for severe cases. However, manual analysis within hospitals poses a\nsubstantial challenge including the substantial burden on healthcare\nprofessionals, limited facilities, availability and fatigue among doctors, and\nhuman error during public health emergencies. Therefore, this survey paper\nprovides an extensive and efficient analysis of deep learning (DL) methods for\nthe automatic detection of MPox in skin lesion images. These DL techniques are\nbroadly grouped into categories, including deep CNN, Deep CNNs ensemble, deep\nhybrid learning, the newly developed, and Vision transformer for diagnosing\nMPox. Moreover, this study offers a systematic exploration of the evolutionary\nprogression of DL techniques and identifies, and addresses limitations in\nprevious methods while highlighting the valuable contributions and innovation.\nAdditionally, the paper addresses benchmark datasets and their collection from\nvarious authentic sources, pre-processing techniques, and evaluation metrics.\nThe survey also briefly delves into emerging concepts, identifies research\ngaps, limitations, and applications, and outlines challenges in the diagnosis\nprocess. This survey furnishes valuable insights into the prospective areas of\nDL innovative ideas and is anticipated to serve as a path for researchers.",
            "author": [
                "Saddam Hussain Khan",
                "Rashid Iqbal",
                "Saeeda Naz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10754v2",
                "http://arxiv.org/pdf/2311.10754v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03320v1",
            "title": "Tackling Concept Shift in Text Classification using Entailment-style\n  Modeling",
            "updated": "2023-11-06T18:15:36Z",
            "published": "2023-11-06T18:15:36Z",
            "summary": "Pre-trained language models (PLMs) have seen tremendous success in text\nclassification (TC) problems in the context of Natural Language Processing\n(NLP). In many real-world text classification tasks, the class definitions\nbeing learned do not remain constant but rather change with time - this is\nknown as Concept Shift. Most techniques for handling concept shift rely on\nretraining the old classifiers with the newly labelled data. However, given the\namount of training data required to fine-tune large DL models for the new\nconcepts, the associated labelling costs can be prohibitively expensive and\ntime consuming. In this work, we propose a reformulation, converting vanilla\nclassification into an entailment-style problem that requires significantly\nless data to re-train the text classifier to adapt to new concepts. We\ndemonstrate the effectiveness of our proposed method on both real world &\nsynthetic datasets achieving absolute F1 gains upto 7% and 40% respectively in\nfew-shot settings. Further, upon deployment, our solution also helped save 75%\nof labeling costs overall.",
            "author": [
                "Sumegh Roychowdhury",
                "Karan Gupta",
                "Siva Rajesh Kasa",
                "Prasanna Srinivasa Murthy",
                "Alok Chandra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03320v1",
                "http://arxiv.org/pdf/2311.03320v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03319v1",
            "title": "DAIL: Data Augmentation for In-Context Learning via Self-Paraphrase",
            "updated": "2023-11-06T18:12:55Z",
            "published": "2023-11-06T18:12:55Z",
            "summary": "In-Context Learning (ICL) combined with pre-trained large language models has\nachieved promising results on various NLP tasks. However, ICL requires\nhigh-quality annotated demonstrations which might not be available in\nreal-world scenarios. To overcome this limitation, we propose \\textbf{D}ata\n\\textbf{A}ugmentation for \\textbf{I}n-Context \\textbf{L}earning\n(\\textbf{DAIL}). DAIL leverages the intuition that large language models are\nmore familiar with the content generated by themselves. It first utilizes the\nlanguage model to generate paraphrases of the test sample and employs majority\nvoting to determine the final result based on individual predictions. Our\nextensive empirical evaluation shows that DAIL outperforms the standard ICL\nmethod and other ensemble-based methods in the low-resource scenario.\nAdditionally, we explore the use of voting consistency as a confidence score of\nthe model when the logits of predictions are inaccessible. We believe our work\nwill stimulate further research on ICL in low-resource settings.",
            "author": [
                "Dawei Li",
                "Yaxuan Li",
                "Dheeraj Mekala",
                "Shuyao Li",
                "Yulin wang",
                "Xueqi Wang",
                "William Hogan",
                "Jingbo Shang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03319v1",
                "http://arxiv.org/pdf/2311.03319v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03318v1",
            "title": "A Foundation Model for Music Informatics",
            "updated": "2023-11-06T18:12:27Z",
            "published": "2023-11-06T18:12:27Z",
            "summary": "This paper investigates foundation models tailored for music informatics, a\ndomain currently challenged by the scarcity of labeled data and generalization\nissues. To this end, we conduct an in-depth comparative study among various\nfoundation model variants, examining key determinants such as model\narchitectures, tokenization methods, temporal resolution, data, and model\nscalability. This research aims to bridge the existing knowledge gap by\nelucidating how these individual factors contribute to the success of\nfoundation models in music informatics. Employing a careful evaluation\nframework, we assess the performance of these models across diverse downstream\ntasks in music information retrieval, with a particular focus on token-level\nand sequence-level classification. Our results reveal that our model\ndemonstrates robust performance, surpassing existing models in specific key\nmetrics. These findings contribute to the understanding of self-supervised\nlearning in music informatics and pave the way for developing more effective\nand versatile foundation models in the field. A pretrained version of our model\nis publicly available to foster reproducibility and future research.",
            "author": [
                "Minz Won",
                "Yun-Ning Hung",
                "Duc Le"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03318v1",
                "http://arxiv.org/pdf/2311.03318v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.IR",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03316v1",
            "title": "Improving Collaborative Filtering Recommendation via Graph Learning",
            "updated": "2023-11-06T18:08:37Z",
            "published": "2023-11-06T18:08:37Z",
            "summary": "Recommendation systems are designed to provide personalized predictions for\nitems that are most appealing to individual customers. Among various types of\nrecommendation algorithms, k-nearest neighbor based collaborative filtering\nalgorithm attracts tremendous attention and are widely used in practice.\nHowever, the k-nearest neighbor scheme can only capture the local relationship\namong users and the uniform neighborhood size is also not suitable to represent\nthe underlying data structure. In this paper, we leverage emerging graph signal\nprocessing (GSP) theory to construct sparse yet high quality graph to enhance\nthe solution quality and efficiency of collaborative filtering algorithm.\nExperimental results show that our method outperforms k-NN based collaborative\nfiltering algorithm by a large margin on the benchmark data set.",
            "author": [
                "Yongyu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03316v1",
                "http://arxiv.org/pdf/2311.03316v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03314v1",
            "title": "FATE: Feature-Agnostic Transformer-based Encoder for learning\n  generalized embedding spaces in flow cytometry data",
            "updated": "2023-11-06T18:06:38Z",
            "published": "2023-11-06T18:06:38Z",
            "summary": "While model architectures and training strategies have become more generic\nand flexible with respect to different data modalities over the past years, a\npersistent limitation lies in the assumption of fixed quantities and\narrangements of input features. This limitation becomes particularly relevant\nin scenarios where the attributes captured during data acquisition vary across\ndifferent samples. In this work, we aim at effectively leveraging data with\nvarying features, without the need to constrain the input space to the\nintersection of potential feature sets or to expand it to their union. We\npropose a novel architecture that can directly process data without the\nnecessity of aligned feature modalities by learning a general embedding space\nthat captures the relationship between features across data samples with\nvarying sets of features. This is achieved via a set-transformer architecture\naugmented by feature-encoder layers, thereby enabling the learning of a shared\nlatent feature space from data originating from heterogeneous feature spaces.\nThe advantages of the model are demonstrated for automatic cancer cell\ndetection in acute myeloid leukemia in flow cytometry data, where the features\nmeasured during acquisition often vary between samples. Our proposed\narchitecture's capacity to operate seamlessly across incongruent feature spaces\nis particularly relevant in this context, where data scarcity arises from the\nlow prevalence of the disease. The code is available for research purposes at\nhttps://github.com/lisaweijler/FATE.",
            "author": [
                "Lisa Weijler",
                "Florian Kowarsch",
                "Michael Reiter",
                "Pedro Hermosilla",
                "Margarita Maurer-Granofszky",
                "Michael Dworzak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03314v1",
                "http://arxiv.org/pdf/2311.03314v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03313v1",
            "title": "Practical considerations for variable screening in the Super Learner",
            "updated": "2023-11-06T18:04:39Z",
            "published": "2023-11-06T18:04:39Z",
            "summary": "Estimating a prediction function is a fundamental component of many data\nanalyses. The Super Learner ensemble, a particular implementation of stacking,\nhas desirable theoretical properties and has been used successfully in many\napplications. Dimension reduction can be accomplished by using variable\nscreening algorithms, including the lasso, within the ensemble prior to fitting\nother prediction algorithms. However, the performance of a Super Learner using\nthe lasso for dimension reduction has not been fully explored in cases where\nthe lasso is known to perform poorly. We provide empirical results that suggest\nthat a diverse set of candidate screening algorithms should be used to protect\nagainst poor performance of any one screen, similar to the guidance for\nchoosing a library of prediction algorithms for the Super Learner.",
            "author": [
                "Brian D. Williamson",
                "Drew King",
                "Ying Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03313v1",
                "http://arxiv.org/pdf/2311.03313v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03312v2",
            "title": "A Single 2D Pose with Context is Worth Hundreds for 3D Human Pose\n  Estimation",
            "updated": "2023-11-09T04:51:34Z",
            "published": "2023-11-06T18:04:13Z",
            "summary": "The dominant paradigm in 3D human pose estimation that lifts a 2D pose\nsequence to 3D heavily relies on long-term temporal clues (i.e., using a\ndaunting number of video frames) for improved accuracy, which incurs\nperformance saturation, intractable computation and the non-causal problem.\nThis can be attributed to their inherent inability to perceive spatial context\nas plain 2D joint coordinates carry no visual cues. To address this issue, we\npropose a straightforward yet powerful solution: leveraging the readily\navailable intermediate visual representations produced by off-the-shelf\n(pre-trained) 2D pose detectors -- no finetuning on the 3D task is even needed.\nThe key observation is that, while the pose detector learns to localize 2D\njoints, such representations (e.g., feature maps) implicitly encode the\njoint-centric spatial context thanks to the regional operations in backbone\nnetworks. We design a simple baseline named Context-Aware PoseFormer to\nshowcase its effectiveness. Without access to any temporal information, the\nproposed method significantly outperforms its context-agnostic counterpart,\nPoseFormer, and other state-of-the-art methods using up to hundreds of video\nframes regarding both speed and precision. Project page:\nhttps://qitaozhao.github.io/ContextAware-PoseFormer",
            "author": [
                "Qitao Zhao",
                "Ce Zheng",
                "Mengyuan Liu",
                "Chen Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03312v2",
                "http://arxiv.org/pdf/2311.03312v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03309v1",
            "title": "Neural Structure Learning with Stochastic Differential Equations",
            "updated": "2023-11-06T17:58:47Z",
            "published": "2023-11-06T17:58:47Z",
            "summary": "Discovering the underlying relationships among variables from temporal\nobservations has been a longstanding challenge in numerous scientific\ndisciplines, including biology, finance, and climate science. The dynamics of\nsuch systems are often best described using continuous-time stochastic\nprocesses. Unfortunately, most existing structure learning approaches assume\nthat the underlying process evolves in discrete-time and/or observations occur\nat regular time intervals. These mismatched assumptions can often lead to\nincorrect learned structures and models. In this work, we introduce a novel\nstructure learning method, SCOTCH, which combines neural stochastic\ndifferential equations (SDE) with variational inference to infer a posterior\ndistribution over possible structures. This continuous-time approach can\nnaturally handle both learning from and predicting observations at arbitrary\ntime points. Theoretically, we establish sufficient conditions for an SDE and\nSCOTCH to be structurally identifiable, and prove its consistency under\ninfinite data limits. Empirically, we demonstrate that our approach leads to\nimproved structure learning performance on both synthetic and real-world\ndatasets compared to relevant baselines under regular and irregular sampling\nintervals.",
            "author": [
                "Benjie Wang",
                "Joel Jennings",
                "Wenbo Gong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03309v1",
                "http://arxiv.org/pdf/2311.03309v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04238v1",
            "title": "Flexible Bayesian Inference on Partially Observed Epidemics",
            "updated": "2023-11-06T17:57:32Z",
            "published": "2023-11-06T17:57:32Z",
            "summary": "Individual-based models of contagious processes are useful for predicting\nepidemic trajectories and informing intervention strategies. In such models,\nthe incorporation of contact network information can capture the non-randomness\nand heterogeneity of realistic contact dynamics. In this paper, we consider\nBayesian inference on the spreading parameters of an SIR contagion on a known,\nstatic network, where information regarding individual disease status is known\nonly from a series of tests (positive or negative disease status). When the\ncontagion model is complex or information such as infection and removal times\nis missing, the posterior distribution can be difficult to sample from.\nPrevious work has considered the use of Approximate Bayesian Computation (ABC),\nwhich allows for simulation-based Bayesian inference on complex models.\nHowever, ABC methods usually require the user to select reasonable summary\nstatistics. Here, we consider an inference scheme based on the Mixture Density\nNetwork compressed ABC (MDN-ABC), which minimizes the expected posterior\nentropy in order to learn informative summary statistics. This allows us to\nconduct Bayesian inference on the parameters of a partially observed contagious\nprocess while also circumventing the need for manual summary statistic\nselection. This methodology can be extended to incorporate additional\nsimulation complexities, including behavioral change after positive tests or\nfalse test results.",
            "author": [
                "Maxwell H. Wang",
                "Jukka-Pekka Onnela"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04238v1",
                "http://arxiv.org/pdf/2311.04238v1"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03303v1",
            "title": "TS-Diffusion: Generating Highly Complex Time Series with Diffusion\n  Models",
            "updated": "2023-11-06T17:52:08Z",
            "published": "2023-11-06T17:52:08Z",
            "summary": "While current generative models have achieved promising performances in\ntime-series synthesis, they either make strong assumptions on the data format\n(e.g., regularities) or rely on pre-processing approaches (e.g.,\ninterpolations) to simplify the raw data. In this work, we consider a class of\ntime series with three common bad properties, including sampling\nirregularities, missingness, and large feature-temporal dimensions, and\nintroduce a general model, TS-Diffusion, to process such complex time series.\nOur model consists of three parts under the framework of point process. The\nfirst part is an encoder of the neural ordinary differential equation (ODE)\nthat converts time series into dense representations, with the jump technique\nto capture sampling irregularities and self-attention mechanism to handle\nmissing values; The second component of TS-Diffusion is a diffusion model that\nlearns from the representation of time series. These time-series\nrepresentations can have a complex distribution because of their high\ndimensions; The third part is a decoder of another ODE that generates time\nseries with irregularities and missing values given their representations. We\nhave conducted extensive experiments on multiple time-series datasets,\ndemonstrating that TS-Diffusion achieves excellent results on both conventional\nand complex time series and significantly outperforms previous baselines.",
            "author": [
                "Yangming Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03303v1",
                "http://arxiv.org/pdf/2311.03303v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03301v1",
            "title": "Ziya2: Data-centric Learning is All LLMs Need",
            "updated": "2023-11-06T17:49:34Z",
            "published": "2023-11-06T17:49:34Z",
            "summary": "Various large language models (LLMs) have been proposed in recent years,\nincluding closed- and open-source ones, continually setting new records on\nmultiple benchmarks. However, the development of LLMs still faces several\nissues, such as high cost of training models from scratch, and continual\npre-training leading to catastrophic forgetting, etc. Although many such issues\nare addressed along the line of research on LLMs, an important yet practical\nlimitation is that many studies overly pursue enlarging model sizes without\ncomprehensively analyzing and optimizing the use of pre-training data in their\nlearning process, as well as appropriate organization and leveraging of such\ndata in training LLMs under cost-effective settings. In this work, we propose\nZiya2, a model with 13 billion parameters adopting LLaMA2 as the foundation\nmodel, and further pre-trained on 700 billion tokens, where we focus on\npre-training techniques and use data-centric optimization to enhance the\nlearning process of Ziya2 on different stages. Experiments show that Ziya2\nsignificantly outperforms other models in multiple benchmarks especially with\npromising results compared to representative open-source ones. Ziya2 (Base) is\nreleased at https://huggingface.co/IDEA-CCNL/Ziya2-13B-Base and\nhttps://modelscope.cn/models/Fengshenbang/Ziya2-13B-Base/summary.",
            "author": [
                "Ruyi Gan",
                "Ziwei Wu",
                "Renliang Sun",
                "Junyu Lu",
                "Xiaojun Wu",
                "Dixiang Zhang",
                "Kunhao Pan",
                "Ping Yang",
                "Qi Yang",
                "Jiaxing Zhang",
                "Yan Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03301v1",
                "http://arxiv.org/pdf/2311.03301v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03294v1",
            "title": "Indirect Quantum Approximate Optimization Algorithms: application to the\n  TSP",
            "updated": "2023-11-06T17:39:14Z",
            "published": "2023-11-06T17:39:14Z",
            "summary": "We propose an Indirect Quantum Approximate Optimization Algorithm (referred\nto as IQAOA) where the Quantum Alternating Operator Ansatz takes into\nconsideration a general parameterized family of unitary operators to\nefficiently model the Hamiltonian describing the set of string vectors. This\nalgorithm creates an efficient alternative to QAOA, where: 1) a Quantum\nparametrized circuit executed on a quantum machine models the set of string\nvectors; 2) a Classical meta-optimization loop executed on a classical machine;\n3) an estimation of the average cost of each string vector computing, using a\nwell know algorithm coming from the OR community that is problem dependent. The\nindirect encoding defined by dimensional string vector is mapped into a\nsolution by an efficient coding/decoding mechanism. The main advantage is to\nobtain a quantum circuit with a strongly limited number of gates that could be\nexecuted on the noisy current quantum machines. The numerical experiments\nachieved with IQAOA permits to solve 8-customer instances TSP using the IBM\nsimulator which are to the best of our knowledge the largest TSP ever solved\nusing a QAOA based approach.",
            "author": [
                "Eric Bourreau",
                "Gerard Fleury",
                "Philippe Lacomme"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03294v1",
                "http://arxiv.org/pdf/2311.03294v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03293v1",
            "title": "Learning Reusable Manipulation Strategies",
            "updated": "2023-11-06T17:35:42Z",
            "published": "2023-11-06T17:35:42Z",
            "summary": "Humans demonstrate an impressive ability to acquire and generalize\nmanipulation \"tricks.\" Even from a single demonstration, such as using soup\nladles to reach for distant objects, we can apply this skill to new scenarios\ninvolving different object positions, sizes, and categories (e.g., forks and\nhammers). Additionally, we can flexibly combine various skills to devise\nlong-term plans. In this paper, we present a framework that enables machines to\nacquire such manipulation skills, referred to as \"mechanisms,\" through a single\ndemonstration and self-play. Our key insight lies in interpreting each\ndemonstration as a sequence of changes in robot-object and object-object\ncontact modes, which provides a scaffold for learning detailed samplers for\ncontinuous parameters. These learned mechanisms and samplers can be seamlessly\nintegrated into standard task and motion planners, enabling their compositional\nuse.",
            "author": [
                "Jiayuan Mao",
                "Joshua B. Tenenbaum",
                "Tom\u00e1s Lozano-P\u00e9rez",
                "Leslie Pack Kaelbling"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03293v1",
                "http://arxiv.org/pdf/2311.03293v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03292v2",
            "title": "Data Science from 1963 to 2012",
            "updated": "2023-11-07T12:58:38Z",
            "published": "2023-11-06T17:35:35Z",
            "summary": "Consensus on the definition of data science remains low despite the\nwidespread establishment of academic programs in the field and continued demand\nfor data scientists in industry. Definitions range from rebranded statistics to\ndata-driven science to the science of data to simply the application of machine\nlearning to so-called big data to solve real-world problems. Current efforts to\ntrace the history of the field in order to clarify its definition, such as\nDonoho's \"50 Years of Data Science\" (Donoho 2017), tend to focus on a short\nperiod when a small group of statisticians adopted the term in an unsuccessful\nattempt to rebrand their field in the face of the overshadowing effects of\ncomputational statistics and data mining. Using textual evidence from primary\nsources, this essay traces the history of the term to the 1960s, when it was\nfirst used by the US Air Force in a surprisingly similar way to its current\nusage, to 2012, the year that Harvard Business Review published the enormously\ninfluential article \"Data Scientist: The Sexiest Job of the 21st Century\"\n(Davenport and Patil 2012), while the American Statistical Association\nacknowledged a profound disconnect between statistics and data science. Among\nthe themes that emerge from this review are (1) the long-standing opposition\nbetween data analysts and data miners that continues to animate the field, (2)\nan established definition of the term as the practice of managing and\nprocessing scientific data that has been occluded by recent usage, and (3) the\nphenomenon of data impedance -- the disproportion between surplus data, indexed\nby phrases like data deluge and big data, and the limitations of computational\nmachinery and methods to process them. This persistent condition appears to\nhave motivated the use of the term and the field itself since its beginnings.",
            "author": [
                "Rafael C. Alvarado"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03292v2",
                "http://arxiv.org/pdf/2311.03292v2"
            ],
            "primary_category": "cs.GL",
            "category": [
                "cs.GL",
                "cs.DL",
                "K.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03426v1",
            "title": "GQKVA: Efficient Pre-training of Transformers by Grouping Queries, Keys,\n  and Values",
            "updated": "2023-11-06T17:29:24Z",
            "published": "2023-11-06T17:29:24Z",
            "summary": "Massive transformer-based models face several challenges, including slow and\ncomputationally intensive pre-training and over-parametrization. This paper\naddresses these challenges by proposing a versatile method called GQKVA, which\ngeneralizes query, key, and value grouping techniques. GQKVA is designed to\nspeed up transformer pre-training while reducing the model size. Our\nexperiments with various GQKVA variants highlight a clear trade-off between\nperformance and model size, allowing for customized choices based on resource\nand time limitations. Our findings also indicate that the conventional\nmulti-head attention approach is not always the best choice, as there are\nlighter and faster alternatives available. We tested our method on ViT, which\nachieved an approximate 0.3% increase in accuracy while reducing the model size\nby about 4% in the task of image classification. Additionally, our most\naggressive model reduction experiment resulted in a reduction of approximately\n15% in model size, with only around a 1% drop in accuracy.",
            "author": [
                "Farnoosh Javadi",
                "Walid Ahmed",
                "Habib Hajimolahoseini",
                "Foozhan Ataiefard",
                "Mohammad Hassanpour",
                "Saina Asani",
                "Austin Wen",
                "Omar Mohamed Awad",
                "Kangling Liu",
                "Yang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03426v1",
                "http://arxiv.org/pdf/2311.03426v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03287v2",
            "title": "Holistic Analysis of Hallucination in GPT-4V(ision): Bias and\n  Interference Challenges",
            "updated": "2023-11-07T02:18:48Z",
            "published": "2023-11-06T17:26:59Z",
            "summary": "While GPT-4V(ision) impressively models both visual and textual information\nsimultaneously, it's hallucination behavior has not been systematically\nassessed. To bridge this gap, we introduce a new benchmark, namely, the Bias\nand Interference Challenges in Visual Language Models (Bingo). This benchmark\nis designed to evaluate and shed light on the two common types of\nhallucinations in visual language models: bias and interference. Here, bias\nrefers to the model's tendency to hallucinate certain types of responses,\npossibly due to imbalance in its training data. Interference pertains to\nscenarios where the judgment of GPT-4V(ision) can be disrupted due to how the\ntext prompt is phrased or how the input image is presented. We identify a\nnotable regional bias, whereby GPT-4V(ision) is better at interpreting Western\nimages or images with English writing compared to images from other countries\nor containing text in other languages. Moreover, GPT-4V(ision) is vulnerable to\nleading questions and is often confused when interpreting multiple images\ntogether. Popular mitigation approaches, such as self-correction and\nchain-of-thought reasoning, are not effective in resolving these challenges. We\nalso identified similar biases and interference vulnerabilities with LLaVA and\nBard. Our results characterize the hallucination challenges in GPT-4V(ision)\nand state-of-the-art visual-language models, and highlight the need for new\nsolutions. The Bingo benchmark is available at https://github.com/gzcch/Bingo.",
            "author": [
                "Chenhang Cui",
                "Yiyang Zhou",
                "Xinyu Yang",
                "Shirley Wu",
                "Linjun Zhang",
                "James Zou",
                "Huaxiu Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03287v2",
                "http://arxiv.org/pdf/2311.03287v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03285v2",
            "title": "S-LoRA: Serving Thousands of Concurrent LoRA Adapters",
            "updated": "2023-11-07T06:59:33Z",
            "published": "2023-11-06T17:26:17Z",
            "summary": "The \"pretrain-then-finetune\" paradigm is commonly adopted in the deployment\nof large language models. Low-Rank Adaptation (LoRA), a parameter-efficient\nfine-tuning method, is often employed to adapt a base model to a multitude of\ntasks, resulting in a substantial collection of LoRA adapters derived from one\nbase model. We observe that this paradigm presents significant opportunities\nfor batched inference during serving. To capitalize on these opportunities, we\npresent S-LoRA, a system designed for the scalable serving of many LoRA\nadapters. S-LoRA stores all adapters in the main memory and fetches the\nadapters used by the currently running queries to the GPU memory. To\nefficiently use the GPU memory and reduce fragmentation, S-LoRA proposes\nUnified Paging. Unified Paging uses a unified memory pool to manage dynamic\nadapter weights with different ranks and KV cache tensors with varying sequence\nlengths. Additionally, S-LoRA employs a novel tensor parallelism strategy and\nhighly optimized custom CUDA kernels for heterogeneous batching of LoRA\ncomputation. Collectively, these features enable S-LoRA to serve thousands of\nLoRA adapters on a single GPU or across multiple GPUs with a small overhead.\nCompared to state-of-the-art libraries such as HuggingFace PEFT and vLLM (with\nnaive support of LoRA serving), S-LoRA can improve the throughput by up to 4\ntimes and increase the number of served adapters by several orders of\nmagnitude. As a result, S-LoRA enables scalable serving of many task-specific\nfine-tuned models and offers the potential for large-scale customized\nfine-tuning services. The code is available at https://github.com/S-LoRA/S-LoRA",
            "author": [
                "Ying Sheng",
                "Shiyi Cao",
                "Dacheng Li",
                "Coleman Hooper",
                "Nicholas Lee",
                "Shuo Yang",
                "Christopher Chou",
                "Banghua Zhu",
                "Lianmin Zheng",
                "Kurt Keutzer",
                "Joseph E. Gonzalez",
                "Ion Stoica"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03285v2",
                "http://arxiv.org/pdf/2311.03285v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03283v1",
            "title": "Risk of Transfer Learning and its Applications in Finance",
            "updated": "2023-11-06T17:23:54Z",
            "published": "2023-11-06T17:23:54Z",
            "summary": "Transfer learning is an emerging and popular paradigm for utilizing existing\nknowledge from previous learning tasks to improve the performance of new ones.\nIn this paper, we propose a novel concept of transfer risk and and analyze its\nproperties to evaluate transferability of transfer learning. We apply transfer\nlearning techniques and this concept of transfer risk to stock return\nprediction and portfolio optimization problems. Numerical results demonstrate a\nstrong correlation between transfer risk and overall transfer learning\nperformance, where transfer risk provides a computationally efficient way to\nidentify appropriate source tasks in transfer learning, including\ncross-continent, cross-sector, and cross-frequency transfer for portfolio\noptimization.",
            "author": [
                "Haoyang Cao",
                "Haotian Gu",
                "Xin Guo",
                "Mathieu Rosenbaum"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03283v1",
                "http://arxiv.org/pdf/2311.03283v1"
            ],
            "primary_category": "q-fin.MF",
            "category": [
                "q-fin.MF",
                "cs.LG",
                "91-08, 91-10, 91G10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03278v1",
            "title": "Discretizing Numerical Attributes: An Analysis of Human Perceptions",
            "updated": "2023-11-06T17:20:41Z",
            "published": "2023-11-06T17:20:41Z",
            "summary": "Machine learning (ML) has employed various discretization methods to\npartition numerical attributes into intervals. However, an effective\ndiscretization technique remains elusive in many ML applications, such as\nassociation rule mining. Moreover, the existing discretization techniques do\nnot reflect best the impact of the independent numerical factor on the\ndependent numerical target factor. This research aims to establish a benchmark\napproach for numerical attribute partitioning. We conduct an extensive analysis\nof human perceptions of partitioning a numerical attribute and compare these\nperceptions with the results obtained from our two proposed measures. We also\nexamine the perceptions of experts in data science, statistics, and engineering\nby employing numerical data visualization techniques. The analysis of collected\nresponses reveals that $68.7\\%$ of human responses approximately closely align\nwith the values generated by our proposed measures. Based on these findings,\nour proposed measures may be used as one of the methods for discretizing the\nnumerical attributes.",
            "author": [
                "Minakshi Kaushik",
                "Rahul Sharma",
                "Dirk Draheim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03278v1",
                "http://arxiv.org/pdf/2311.03278v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03275v1",
            "title": "Exploiting Latent Attribute Interaction with Transformer on\n  Heterogeneous Information Networks",
            "updated": "2023-11-06T17:18:37Z",
            "published": "2023-11-06T17:18:37Z",
            "summary": "Heterogeneous graph neural networks (HGNNs) have recently shown impressive\ncapability in modeling heterogeneous graphs that are ubiquitous in real-world\napplications. Due to the diversity of attributes of nodes in different types,\nmost existing models first align nodes by mapping them into the same\nlow-dimensional space. However, in this way, they lose the type information of\nnodes. In addition, most of them only consider the interactions between nodes\nwhile neglecting the high-order information behind the latent interactions\namong different node features. To address these problems, in this paper, we\npropose a novel heterogeneous graph model MULAN, including two major\ncomponents, i.e., a type-aware encoder and a dimension-aware encoder.\nSpecifically, the type-aware encoder compensates for the loss of node type\ninformation and better leverages graph heterogeneity in learning node\nrepresentations. Built upon transformer architecture, the dimension-aware\nencoder is capable of capturing the latent interactions among the diverse node\nfeatures. With these components, the information of graph heterogeneity, node\nfeatures and graph structure can be comprehensively encoded in node\nrepresentations. We conduct extensive experiments on six heterogeneous\nbenchmark datasets, which demonstrates the superiority of MULAN over other\nstate-of-the-art competitors and also shows that MULAN is efficient.",
            "author": [
                "Zeyuan Zhao",
                "Qingqing Ge",
                "Anfeng Cheng",
                "Yiding Liu",
                "Xiang Li",
                "Shuaiqiang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03275v1",
                "http://arxiv.org/pdf/2311.03275v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03425v1",
            "title": "An AI-Guided Data Centric Strategy to Detect and Mitigate Biases in\n  Healthcare Datasets",
            "updated": "2023-11-06T17:08:41Z",
            "published": "2023-11-06T17:08:41Z",
            "summary": "The adoption of diagnosis and prognostic algorithms in healthcare has led to\nconcerns about the perpetuation of bias against disadvantaged groups of\nindividuals. Deep learning methods to detect and mitigate bias have revolved\naround modifying models, optimization strategies, and threshold calibration\nwith varying levels of success. Here, we generate a data-centric,\nmodel-agnostic, task-agnostic approach to evaluate dataset bias by\ninvestigating the relationship between how easily different groups are learned\nat small sample sizes (AEquity). We then apply a systematic analysis of AEq\nvalues across subpopulations to identify and mitigate manifestations of racial\nbias in two known cases in healthcare - Chest X-rays diagnosis with deep\nconvolutional neural networks and healthcare utilization prediction with\nmultivariate logistic regression. AEq is a novel and broadly applicable metric\nthat can be applied to advance equity by diagnosing and remediating bias in\nhealthcare datasets.",
            "author": [
                "Faris F. Gulamali",
                "Ashwin S. Sawant",
                "Lora Liharska",
                "Carol R. Horowitz",
                "Lili Chan",
                "Patricia H. Kovatch",
                "Ira Hofer",
                "Karandeep Singh",
                "Lynne D. Richardson",
                "Emmanuel Mensah",
                "Alexander W Charney",
                "David L. Reich",
                "Jianying Hu",
                "Girish N. Nadkarni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03425v1",
                "http://arxiv.org/pdf/2311.03425v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03260v1",
            "title": "From Coupled Oscillators to Graph Neural Networks: Reducing\n  Over-smoothing via a Kuramoto Model-based Approach",
            "updated": "2023-11-06T16:47:17Z",
            "published": "2023-11-06T16:47:17Z",
            "summary": "We propose the Kuramoto Graph Neural Network (KuramotoGNN), a novel class of\ncontinuous-depth graph neural networks (GNNs) that employs the Kuramoto model\nto mitigate the over-smoothing phenomenon, in which node features in GNNs\nbecome indistinguishable as the number of layers increases. The Kuramoto model\ncaptures the synchronization behavior of non-linear coupled oscillators. Under\nthe view of coupled oscillators, we first show the connection between Kuramoto\nmodel and basic GNN and then over-smoothing phenomenon in GNNs can be\ninterpreted as phase synchronization in Kuramoto model. The KuramotoGNN\nreplaces this phase synchronization with frequency synchronization to prevent\nthe node features from converging into each other while allowing the system to\nreach a stable synchronized state. We experimentally verify the advantages of\nthe KuramotoGNN over the baseline GNNs and existing methods in reducing\nover-smoothing on various graph deep learning benchmark tasks.",
            "author": [
                "Tuan Nguyen",
                "Tan M. Nguyen",
                "Hirotada Honda",
                "Takashi Sano",
                "Vinh Nguyen",
                "Shugo Nakamura"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03260v1",
                "http://arxiv.org/pdf/2311.03260v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03252v1",
            "title": "Parameter-Agnostic Optimization under Relaxed Smoothness",
            "updated": "2023-11-06T16:39:53Z",
            "published": "2023-11-06T16:39:53Z",
            "summary": "Tuning hyperparameters, such as the stepsize, presents a major challenge of\ntraining machine learning models. To address this challenge, numerous adaptive\noptimization algorithms have been developed that achieve near-optimal\ncomplexities, even when stepsizes are independent of problem-specific\nparameters, provided that the loss function is $L$-smooth. However, as the\nassumption is relaxed to the more realistic $(L_0, L_1)$-smoothness, all\nexisting convergence results still necessitate tuning of the stepsize. In this\nstudy, we demonstrate that Normalized Stochastic Gradient Descent with Momentum\n(NSGD-M) can achieve a (nearly) rate-optimal complexity without prior knowledge\nof any problem parameter, though this comes at the cost of introducing an\nexponential term dependent on $L_1$ in the complexity. We further establish\nthat this exponential term is inevitable to such schemes by introducing a\ntheoretical framework of lower bounds tailored explicitly for\nparameter-agnostic algorithms. Interestingly, in deterministic settings, the\nexponential factor can be neutralized by employing Gradient Descent with a\nBacktracking Line Search. To the best of our knowledge, these findings\nrepresent the first parameter-agnostic convergence results under the\ngeneralized smoothness condition. Our empirical experiments further confirm our\ntheoretical insights.",
            "author": [
                "Florian H\u00fcbler",
                "Junchi Yang",
                "Xiang Li",
                "Niao He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03252v1",
                "http://arxiv.org/pdf/2311.03252v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03251v1",
            "title": "Interpretable multiscale Machine Learning-Based Parameterizations of\n  Convection for ICON",
            "updated": "2023-11-06T16:39:28Z",
            "published": "2023-11-06T16:39:28Z",
            "summary": "In order to improve climate projections, machine learning (ML)-based\nparameterizations have been developed for Earth System Models (ESMs) with the\ngoal to better represent subgrid-scale processes or to accelerate computations\nby emulating existent parameterizations. These data-driven models have shown\nsuccess in approximating subgrid-scale processes based on high-resolution\nstorm-resolving simulations. However, most studies have used a particular\nmachine learning method such as simple Multilayer Perceptrons (MLPs) or Random\nForest (RFs) to parameterize the subgrid tendencies or fluxes originating from\nthe compound effect of various small-scale processes (e.g., turbulence,\nradiation, convection, gravity waves). Here, we use a filtering technique to\nexplicitly separate convection from these processes in data produced by the\nIcosahedral Non-hydrostatic modelling framework (ICON) in a realistic setting.\nWe use a method improved by incorporating density fluctuations for computing\nthe subgrid fluxes and compare a variety of different machine learning\nalgorithms on their ability to predict the subgrid fluxes. We further examine\nthe predictions of the best performing non-deep learning model (Gradient\nBoosted Tree regression) and the U-Net. We discover that the U-Net can learn\nnon-causal relations between convective precipitation and convective subgrid\nfluxes and develop an ablated model excluding precipitating tracer species. We\nconnect the learned relations of the U-Net to physical processes in contrast to\nnon-deep learning-based algorithms. Our results suggest that architectures such\nas a U-Net are particularly well suited to parameterize multiscale problems\nlike convection, paying attention to the plausibility of the learned relations,\nthus providing a significant advance upon existing ML subgrid representation in\nESMs.",
            "author": [
                "Helge Heuer",
                "Mierk Schwabe",
                "Pierre Gentine",
                "Marco A. Giorgetta",
                "Veronika Eyring"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03251v1",
                "http://arxiv.org/pdf/2311.03251v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03250v1",
            "title": "Instructed Language Models with Retrievers Are Powerful Entity Linkers",
            "updated": "2023-11-06T16:38:51Z",
            "published": "2023-11-06T16:38:51Z",
            "summary": "Generative approaches powered by large language models (LLMs) have\ndemonstrated emergent abilities in tasks that require complex reasoning\nabilities. Yet the generative nature still makes the generated content suffer\nfrom hallucinations, thus unsuitable for entity-centric tasks like entity\nlinking (EL) requiring precise entity predictions over a large knowledge base.\nWe present Instructed Generative Entity Linker (INSGENEL), the first approach\nthat enables casual language models to perform entity linking over knowledge\nbases. Several methods to equip language models with EL capability were\nproposed in this work, including (i) a sequence-to-sequence training EL\nobjective with instruction-tuning, (ii) a novel generative EL framework based\non a light-weight potential mention retriever that frees the model from heavy\nand non-parallelizable decoding, achieving 4$\\times$ speedup without compromise\non linking metrics. INSGENEL outperforms previous generative alternatives with\n+6.8 F1 points gain on average, also with a huge advantage in training data\nefficiency and training compute consumption. In addition, our skillfully\nengineered in-context learning (ICL) framework for EL still lags behind\nINSGENEL significantly, reaffirming that the EL task remains a persistent\nhurdle for general LLMs.",
            "author": [
                "Zilin Xiao",
                "Ming Gong",
                "Jie Wu",
                "Xingyao Zhang",
                "Linjun Shou",
                "Jian Pei",
                "Daxin Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03250v1",
                "http://arxiv.org/pdf/2311.03250v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03246v1",
            "title": "Advancing Post Hoc Case Based Explanation with Feature Highlighting",
            "updated": "2023-11-06T16:34:48Z",
            "published": "2023-11-06T16:34:48Z",
            "summary": "Explainable AI (XAI) has been proposed as a valuable tool to assist in\ndownstream tasks involving human and AI collaboration. Perhaps the most\npsychologically valid XAI techniques are case based approaches which display\n'whole' exemplars to explain the predictions of black box AI systems. However,\nfor such post hoc XAI methods dealing with images, there has been no attempt to\nimprove their scope by using multiple clear feature 'parts' of the images to\nexplain the predictions while linking back to relevant cases in the training\ndata, thus allowing for more comprehensive explanations that are faithful to\nthe underlying model. Here, we address this gap by proposing two general\nalgorithms (latent and super pixel based) which can isolate multiple clear\nfeature parts in a test image, and then connect them to the explanatory cases\nfound in the training data, before testing their effectiveness in a carefully\ndesigned user study. Results demonstrate that the proposed approach\nappropriately calibrates a users feelings of 'correctness' for ambiguous\nclassifications in real world data on the ImageNet dataset, an effect which\ndoes not happen when just showing the explanation without feature highlighting.",
            "author": [
                "Eoin Kenny",
                "Eoin Delaney",
                "Mark Keane"
            ],
            "link": [
                "http://dx.doi.org/10.24963/ijcai.2023/48",
                "http://arxiv.org/abs/2311.03246v1",
                "http://arxiv.org/pdf/2311.03246v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.HC",
                "cs.LG",
                "I.2.6; F.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03243v1",
            "title": "Safurai-Csharp: Harnessing Synthetic Data to improve language-specific\n  Code LLM",
            "updated": "2023-11-06T16:31:48Z",
            "published": "2023-11-06T16:31:48Z",
            "summary": "This paper introduces Safurai-Csharp, an open-source model designed to\nspecialize in the generation, completion, and debugging of C# code.\nSafurai-Csharp is built upon the novel CodeLlama 34B model and leverages the\nEvolInstruct technique, creating a refined and expanded dataset for its\nfine-tuning process. The results of its performance, a notable score of 56.33%\non the Manual MultiPL-E benchmark (Zero-Shot, Pass@1), signal its high capacity\nto streamline developers' workflows and aid code learning. It shows promise in\nsetting new stakes in the landscape of open-source C# LLMs and hopes to inspire\nmore inclusive and wide-ranging development in the field of language-specific\nLLMs.",
            "author": [
                "Davide Cifarelli",
                "Leonardo Boiardi",
                "Alessandro Puppo",
                "Leon Jovanovic"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03243v1",
                "http://arxiv.org/pdf/2311.03243v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03242v1",
            "title": "Approximating Langevin Monte Carlo with ResNet-like Neural Network\n  architectures",
            "updated": "2023-11-06T16:31:09Z",
            "published": "2023-11-06T16:31:09Z",
            "summary": "We sample from a given target distribution by constructing a neural network\nwhich maps samples from a simple reference, e.g. the standard normal\ndistribution, to samples from the target. To that end, we propose using a\nneural network architecture inspired by the Langevin Monte Carlo (LMC)\nalgorithm. Based on LMC perturbation results, we show approximation rates of\nthe proposed architecture for smooth, log-concave target distributions measured\nin the Wasserstein-$2$ distance. The analysis heavily relies on the notion of\nsub-Gaussianity of the intermediate measures of the perturbed LMC process. In\nparticular, we derive bounds on the growth of the intermediate variance proxies\nunder different assumptions on the perturbations. Moreover, we propose an\narchitecture similar to deep residual neural networks and derive expressivity\nresults for approximating the sample to target distribution map.",
            "author": [
                "Martin Eigel",
                "Charles Miranda",
                "Janina Sch\u00fctte",
                "David Sommer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03242v1",
                "http://arxiv.org/pdf/2311.03242v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.PR",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03240v1",
            "title": "Machine Learning-Based Tea Leaf Disease Detection: A Comprehensive\n  Review",
            "updated": "2023-11-06T16:30:40Z",
            "published": "2023-11-06T16:30:40Z",
            "summary": "Tea leaf diseases are a major challenge to agricultural productivity, with\nfar-reaching implications for yield and quality in the tea industry. The rise\nof machine learning has enabled the development of innovative approaches to\ncombat these diseases. Early detection and diagnosis are crucial for effective\ncrop management. For predicting tea leaf disease, several automated systems\nhave already been developed using different image processing techniques. This\npaper delivers a systematic review of the literature on machine learning\nmethodologies applied to diagnose tea leaf disease via image classification. It\nthoroughly evaluates the strengths and constraints of various Vision\nTransformer models, including Inception Convolutional Vision Transformer\n(ICVT), GreenViT, PlantXViT, PlantViT, MSCVT, Transfer Learning Model & Vision\nTransformer (TLMViT), IterationViT, IEM-ViT. Moreover, this paper also reviews\nmodels like Dense Convolutional Network (DenseNet), Residual Neural Network\n(ResNet)-50V2, YOLOv5, YOLOv7, Convolutional Neural Network (CNN), Deep CNN,\nNon-dominated Sorting Genetic Algorithm (NSGA-II), MobileNetv2, and\nLesion-Aware Visual Transformer. These machine-learning models have been tested\non various datasets, demonstrating their real-world applicability. This review\nstudy not only highlights current progress in the field but also provides\nvaluable insights for future research directions in the machine learning-based\ndetection and classification of tea leaf diseases.",
            "author": [
                "Faruk Ahmed",
                "Md. Taimur Ahad",
                "Yousuf Rayhan Emon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03240v1",
                "http://arxiv.org/pdf/2311.03240v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03236v2",
            "title": "Out-of-distribution Detection Learning with Unreliable\n  Out-of-distribution Sources",
            "updated": "2023-12-05T09:08:30Z",
            "published": "2023-11-06T16:26:52Z",
            "summary": "Out-of-distribution (OOD) detection discerns OOD data where the predictor\ncannot make valid predictions as in-distribution (ID) data, thereby increasing\nthe reliability of open-world classification. However, it is typically hard to\ncollect real out-of-distribution (OOD) data for training a predictor capable of\ndiscerning ID and OOD patterns. This obstacle gives rise to data\ngeneration-based learning methods, synthesizing OOD data via data generators\nfor predictor training without requiring any real OOD data. Related methods\ntypically pre-train a generator on ID data and adopt various selection\nprocedures to find those data likely to be the OOD cases. However, generated\ndata may still coincide with ID semantics, i.e., mistaken OOD generation\nremains, confusing the predictor between ID and OOD data. To this end, we\nsuggest that generated data (with mistaken OOD generation) can be used to\ndevise an auxiliary OOD detection task to facilitate real OOD detection.\nSpecifically, we can ensure that learning from such an auxiliary task is\nbeneficial if the ID and the OOD parts have disjoint supports, with the help of\na well-designed training procedure for the predictor. Accordingly, we propose a\npowerful data generation-based learning method named Auxiliary Task-based OOD\nLearning (ATOL) that can relieve the mistaken OOD generation. We conduct\nextensive experiments under various OOD detection setups, demonstrating the\neffectiveness of our method against its advanced counterparts.",
            "author": [
                "Haotian Zheng",
                "Qizhou Wang",
                "Zhen Fang",
                "Xiaobo Xia",
                "Feng Liu",
                "Tongliang Liu",
                "Bo Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03236v2",
                "http://arxiv.org/pdf/2311.03236v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03235v1",
            "title": "p-Laplacian Transformer",
            "updated": "2023-11-06T16:25:56Z",
            "published": "2023-11-06T16:25:56Z",
            "summary": "$p$-Laplacian regularization, rooted in graph and image signal processing,\nintroduces a parameter $p$ to control the regularization effect on these data.\nSmaller values of $p$ promote sparsity and interpretability, while larger\nvalues encourage smoother solutions. In this paper, we first show that the\nself-attention mechanism obtains the minimal Laplacian regularization ($p=2$)\nand encourages the smoothness in the architecture. However, the smoothness is\nnot suitable for the heterophilic structure of self-attention in transformers\nwhere attention weights between tokens that are in close proximity and\nnon-close ones are assigned indistinguishably. From that insight, we then\npropose a novel class of transformers, namely the $p$-Laplacian Transformer\n(p-LaT), which leverages $p$-Laplacian regularization framework to harness the\nheterophilic features within self-attention layers. In particular, low $p$\nvalues will effectively assign higher attention weights to tokens that are in\nclose proximity to the current token being processed. We empirically\ndemonstrate the advantages of p-LaT over the baseline transformers on a wide\nrange of benchmark datasets.",
            "author": [
                "Tuan Nguyen",
                "Tam Nguyen",
                "Vinh Nguyen",
                "Tan M. Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03235v1",
                "http://arxiv.org/pdf/2311.03235v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.07584v1",
            "title": "Performance Prediction of Data-Driven Knowledge summarization of High\n  Entropy Alloys (HEAs) literature implementing Natural Language Processing\n  algorithms",
            "updated": "2023-11-06T16:22:32Z",
            "published": "2023-11-06T16:22:32Z",
            "summary": "The ability to interpret spoken language is connected to natural language\nprocessing. It involves teaching the AI how words relate to one another, how\nthey are meant to be used, and in what settings. The goal of natural language\nprocessing (NLP) is to get a machine intelligence to process words the same way\na human brain does. This enables machine intelligence to interpret, arrange,\nand comprehend textual data by processing the natural language. The technology\ncan comprehend what is communicated, whether it be through speech or writing\nbecause AI pro-cesses language more quickly than humans can. In the present\nstudy, five NLP algorithms, namely, Geneism, Sumy, Luhn, Latent Semantic\nAnalysis (LSA), and Kull-back-Liebler (KL) al-gorithm, are implemented for the\nfirst time for the knowledge summarization purpose of the High Entropy Alloys\n(HEAs). The performance prediction of these algorithms is made by using the\nBLEU score and ROUGE score. The results showed that the Luhn algorithm has the\nhighest accuracy score for the knowledge summarization tasks compared to the\nother used algorithms.",
            "author": [
                "Akshansh Mishra",
                "Vijaykumar S Jatti",
                "Vaishnavi More",
                "Anish Dasgupta",
                "Devarrishi Dixit",
                "Eyob Messele Sefene"
            ],
            "link": [
                "http://arxiv.org/abs/2311.07584v1",
                "http://arxiv.org/pdf/2311.07584v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.IT",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03233v1",
            "title": "Navigating Scaling Laws: Accelerating Vision Transformer's Training via\n  Adaptive Strategies",
            "updated": "2023-11-06T16:20:28Z",
            "published": "2023-11-06T16:20:28Z",
            "summary": "In recent years, the state-of-the-art in deep learning has been dominated by\nvery large models that have been pre-trained on vast amounts of data. The\nparadigm is very simple: Investing more computational resources (optimally)\nleads to better performance, and even predictably so; neural scaling laws have\nbeen derived that accurately forecast the performance of a network for a\ndesired level of compute. This leads to the notion of a \"compute-optimal\"\nmodel, i.e. a model that allocates a given level of compute during training\noptimally to maximise performance. In this work, we extend the concept of\noptimality by allowing for an \"adaptive\" model, i.e. a model that can change\nits shape during the course of training. By allowing the shape to adapt, we can\noptimally traverse between the underlying scaling laws, leading to a\nsignificant reduction in the required compute to reach a given target\nperformance. We focus on vision tasks and the family of Vision Transformers,\nwhere the patch size as well as the width naturally serve as adaptive shape\nparameters. We demonstrate that, guided by scaling laws, we can design\ncompute-optimal adaptive models that beat their \"static\" counterparts.",
            "author": [
                "Sotiris Anagnostidis",
                "Gregor Bachmann",
                "Thomas Hofmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03233v1",
                "http://arxiv.org/pdf/2311.03233v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03228v1",
            "title": "An Efficient Self-Supervised Cross-View Training For Sentence Embedding",
            "updated": "2023-11-06T16:12:25Z",
            "published": "2023-11-06T16:12:25Z",
            "summary": "Self-supervised sentence representation learning is the task of constructing\nan embedding space for sentences without relying on human annotation efforts.\nOne straightforward approach is to finetune a pretrained language model (PLM)\nwith a representation learning method such as contrastive learning. While this\napproach achieves impressive performance on larger PLMs, the performance\nrapidly degrades as the number of parameters decreases. In this paper, we\npropose a framework called Self-supervised Cross-View Training (SCT) to narrow\nthe performance gap between large and small PLMs. To evaluate the effectiveness\nof SCT, we compare it to 5 baseline and state-of-the-art competitors on seven\nSemantic Textual Similarity (STS) benchmarks using 5 PLMs with the number of\nparameters ranging from 4M to 340M. The experimental results show that STC\noutperforms the competitors for PLMs with less than 100M parameters in 18 of 21\ncases.",
            "author": [
                "Peerat Limkonchotiwat",
                "Wuttikorn Ponwitayarat",
                "Lalita Lowphansirikul",
                "Can Udomcharoenchaikit",
                "Ekapol Chuangsuwanich",
                "Sarana Nutanong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03228v1",
                "http://arxiv.org/pdf/2311.03228v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03227v1",
            "title": "Quantum-inspired anomaly detection, a QUBO formulation",
            "updated": "2023-11-06T16:12:15Z",
            "published": "2023-11-06T16:12:15Z",
            "summary": "Anomaly detection is a crucial task in machine learning that involves\nidentifying unusual patterns or events in data. It has numerous applications in\nvarious domains such as finance, healthcare, and cybersecurity. With the advent\nof quantum computing, there has been a growing interest in developing quantum\napproaches to anomaly detection. After reviewing traditional approaches to\nanomaly detection relying on statistical or distance-based methods, we will\npropose a Quadratic Unconstrained Binary Optimization (QUBO) model formulation\nof anomaly detection, compare it with classical methods, and discuss its\nscalability on current Quantum Processing Units (QPU).",
            "author": [
                "Julien Mellaerts"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03227v1",
                "http://arxiv.org/pdf/2311.03227v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03217v2",
            "title": "Leveraging Transformers to Improve Breast Cancer Classification and Risk\n  Assessment with Multi-modal and Longitudinal Data",
            "updated": "2023-11-15T14:37:24Z",
            "published": "2023-11-06T16:01:42Z",
            "summary": "Breast cancer screening, primarily conducted through mammography, is often\nsupplemented with ultrasound for women with dense breast tissue. However,\nexisting deep learning models analyze each modality independently, missing\nopportunities to integrate information across imaging modalities and time. In\nthis study, we present Multi-modal Transformer (MMT), a neural network that\nutilizes mammography and ultrasound synergistically, to identify patients who\ncurrently have cancer and estimate the risk of future cancer for patients who\nare currently cancer-free. MMT aggregates multi-modal data through\nself-attention and tracks temporal tissue changes by comparing current exams to\nprior imaging. Trained on 1.3 million exams, MMT achieves an AUROC of 0.943 in\ndetecting existing cancers, surpassing strong uni-modal baselines. For 5-year\nrisk prediction, MMT attains an AUROC of 0.826, outperforming prior\nmammography-based risk models. Our research highlights the value of multi-modal\nand longitudinal imaging in cancer diagnosis and risk stratification.",
            "author": [
                "Yiqiu Shen",
                "Jungkyu Park",
                "Frank Yeung",
                "Eliana Goldberg",
                "Laura Heacock",
                "Farah Shamout",
                "Krzysztof J. Geras"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03217v2",
                "http://arxiv.org/pdf/2311.03217v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03216v1",
            "title": "Mini Minds: Exploring Bebeshka and Zlata Baby Models",
            "updated": "2023-11-06T16:01:10Z",
            "published": "2023-11-06T16:01:10Z",
            "summary": "In this paper, we describe the University of Lyon 2 submission to the\nStrict-Small track of the BabyLM competition. The shared task is created with\nan emphasis on small-scale language modelling from scratch on limited-size data\nand human language acquisition. Dataset released for the Strict-Small track has\n10M words, which is comparable to children's vocabulary size. We approach the\ntask with an architecture search, minimizing masked language modelling loss on\nthe data of the shared task. Having found an optimal configuration, we\nintroduce two small-size language models (LMs) that were submitted for\nevaluation, a 4-layer encoder with 8 attention heads and a 6-layer decoder\nmodel with 12 heads which we term Bebeshka and Zlata, respectively. Despite\nbeing half the scale of the baseline LMs, our proposed models achieve\ncomparable performance. We further explore the applicability of small-scale\nlanguage models in tasks involving moral judgment, aligning their predictions\nwith human values. These findings highlight the potential of compact LMs in\naddressing practical language understanding tasks.",
            "author": [
                "Irina Proskurina",
                "Guillaume Metzler",
                "Julien Velcin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03216v1",
                "http://arxiv.org/pdf/2311.03216v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03213v1",
            "title": "Assessing the Maturity of Model Maintenance Techniques for AIOps\n  Solutions",
            "updated": "2023-11-06T15:57:04Z",
            "published": "2023-11-06T15:57:04Z",
            "summary": "AIOps (Artificial Intelligence for IT Operations) solutions leverage the\nmassive data produced during the operations of large-scale systems and machine\nlearning models to assist software engineers in their system operations. As\noperation data produced in the field are subject to constant evolution from\nfactors like the changing operational environment and user base, the models in\nAIOps solutions need to be constantly maintained after deployment. While prior\nworks focus on innovative modeling techniques to improve the performance of\nAIOps models before releasing them into the field, when and how to maintain\nAIOps models remain an under-investigated topic. In this work, we performed a\ncase study on three large-scale public operation data to assess different model\nmaintenance approaches regarding their performance, maintenance cost, and\nstability. We observed that active model maintenance approaches achieve better\nand more stable performance than a stationary approach. Particularly, applying\nsophisticated model maintenance approaches (e.g., concept drift detection,\ntime-based ensembles, or online learning approaches) could provide better\nperformance, efficiency, and stability than simply retraining AIOps models\nperiodically. In addition, we observed that, although some maintenance\napproaches (e.g., time-based ensemble and online learning) can save model\ntraining time, they significantly sacrifice model testing time, which could\nhinder their applications in AIOps solutions where the operation data arrive at\nhigh speed and volume and where instant predictions are required. Our findings\nhighlight that practitioners should consider the evolution of operation data\nand actively maintain AIOps models over time. Our observations can also guide\nresearchers and practitioners to investigate more efficient and effective model\nmaintenance techniques that fit in the context of AIOps.",
            "author": [
                "Yingzhe Lyu",
                "Heng Li",
                "Zhen Ming",
                "Jiang",
                "Ahmed E. Hassan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03213v1",
                "http://arxiv.org/pdf/2311.03213v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03205v1",
            "title": "PainSeeker: An Automated Method for Assessing Pain in Rats Through\n  Facial Expressions",
            "updated": "2023-11-06T15:49:11Z",
            "published": "2023-11-06T15:49:11Z",
            "summary": "In this letter, we aim to investigate whether laboratory rats' pain can be\nautomatically assessed through their facial expressions. To this end, we began\nby presenting a publicly available dataset called RatsPain, consisting of 1,138\nfacial images captured from six rats that underwent an orthodontic treatment\noperation. Each rat' facial images in RatsPain were carefully selected from\nvideos recorded either before or after the operation and well labeled by eight\nannotators according to the Rat Grimace Scale (RGS). We then proposed a novel\ndeep learning method called PainSeeker for automatically assessing pain in rats\nvia facial expressions. PainSeeker aims to seek pain-related facial local\nregions that facilitate learning both pain discriminative and head pose robust\nfeatures from facial expression images. To evaluate the PainSeeker, we\nconducted extensive experiments on the RatsPain dataset. The results\ndemonstrate the feasibility of assessing rats' pain from their facial\nexpressions and also verify the effectiveness of the proposed PainSeeker in\naddressing this emerging but intriguing problem. The RasPain dataset can be\nfreely obtained from https://github.com/xhzongyuan/RatsPain.",
            "author": [
                "Liu Liu",
                "Guang Li",
                "Dingfan Deng",
                "Jinhua Yu",
                "Yuan Zong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03205v1",
                "http://arxiv.org/pdf/2311.03205v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03201v1",
            "title": "Spatial Process Approximations: Assessing Their Necessity",
            "updated": "2023-11-06T15:46:03Z",
            "published": "2023-11-06T15:46:03Z",
            "summary": "In spatial statistics and machine learning, the kernel matrix plays a pivotal\nrole in prediction, classification, and maximum likelihood estimation. A\nthorough examination reveals that for large sample sizes, the kernel matrix\nbecomes ill-conditioned, provided the sampling locations are fairly evenly\ndistributed. This condition poses significant challenges to numerical\nalgorithms used in prediction and estimation computations and necessitates an\napproximation to prediction and the Gaussian likelihood. A review of current\nmethodologies for managing large spatial data indicates that some fail to\naddress this ill-conditioning problem. Such ill-conditioning often results in\nlow-rank approximations of the stochastic processes. This paper introduces\nvarious optimality criteria and provides solutions for each.",
            "author": [
                "Hao Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03201v1",
                "http://arxiv.org/pdf/2311.03201v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04237v1",
            "title": "Online Learning Quantum States with the Logarithmic Loss via VB-FTRL",
            "updated": "2023-11-06T15:45:33Z",
            "published": "2023-11-06T15:45:33Z",
            "summary": "Online learning quantum states with the logarithmic loss (LL-OLQS) is a\nquantum generalization of online portfolio selection, a classic open problem in\nthe field of online learning for over three decades. The problem also emerges\nin designing randomized optimization algorithms for maximum-likelihood quantum\nstate tomography. Recently, Jezequel et al. (arXiv:2209.13932) proposed the\nVB-FTRL algorithm, the first nearly regret-optimal algorithm for OPS with\nmoderate computational complexity. In this note, we generalize VB-FTRL for\nLL-OLQS. Let $d$ denote the dimension and $T$ the number of rounds. The\ngeneralized algorithm achieves a regret rate of $O ( d^2 \\log ( d + T ) )$ for\nLL-OLQS. Each iteration of the algorithm consists of solving a semidefinite\nprogram that can be implemented in polynomial time by, e.g., cutting-plane\nmethods. For comparison, the best-known regret rate for LL-OLQS is currently $O\n( d^2 \\log T )$, achieved by the exponential weight method. However, there is\nno explicit implementation available for the exponential weight method for\nLL-OLQS. To facilitate the generalization, we introduce the notion of\nVB-convexity. VB-convexity is a sufficient condition for the logarithmic\nbarrier associated with any function to be convex and is of independent\ninterest.",
            "author": [
                "Wei-Fu Tseng",
                "Kai-Chun Chen",
                "Zi-Hong Xiao",
                "Yen-Huan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04237v1",
                "http://arxiv.org/pdf/2311.04237v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03197v3",
            "title": "Stable Linear Subspace Identification: A Machine Learning Approach",
            "updated": "2023-11-30T07:52:31Z",
            "published": "2023-11-06T15:39:05Z",
            "summary": "Machine Learning (ML) and linear System Identification (SI) have been\nhistorically developed independently. In this paper, we leverage\nwell-established ML tools - especially the automatic differentiation framework\n- to introduce SIMBa, a family of discrete linear multi-step-ahead state-space\nSI methods using backpropagation. SIMBa relies on a novel\nLinear-Matrix-Inequality-based free parametrization of Schur matrices to ensure\nthe stability of the identified model.\n  We show how SIMBa generally outperforms traditional linear state-space SI\nmethods, and sometimes significantly, although at the price of a higher\ncomputational burden. This performance gap is particularly remarkable compared\nto other SI methods with stability guarantees, where the gain is frequently\nabove 25% in our investigations, hinting at SIMBa's ability to simultaneously\nachieve state-of-the-art fitting performance and enforce stability.\nInterestingly, these observations hold for a wide variety of input-output\nsystems and on both simulated and real-world data, showcasing the flexibility\nof the proposed approach. We postulate that this new SI paradigm presents a\ngreat extension potential to identify structured nonlinear models from data,\nand we hence open-source SIMBa on https://github.com/Cemempamoi/simba.",
            "author": [
                "Loris Di Natale",
                "Muhammad Zakwan",
                "Bratislav Svetozarevic",
                "Philipp Heer",
                "Giancarlo Ferrari Trecate",
                "Colin N. Jones"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03197v3",
                "http://arxiv.org/pdf/2311.03197v3"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03194v1",
            "title": "Few-shot Learning using Data Augmentation and Time-Frequency\n  Transformation for Time Series Classification",
            "updated": "2023-11-06T15:32:50Z",
            "published": "2023-11-06T15:32:50Z",
            "summary": "Deep neural networks (DNNs) that tackle the time series classification (TSC)\ntask have provided a promising framework in signal processing. In real-world\napplications, as a data-driven model, DNNs are suffered from insufficient data.\nFew-shot learning has been studied to deal with this limitation. In this paper,\nwe propose a novel few-shot learning framework through data augmentation, which\ninvolves transformation through the time-frequency domain and the generation of\nsynthetic images through random erasing. Additionally, we develop a\nsequence-spectrogram neural network (SSNN). This neural network model composes\nof two sub-networks: one utilizing 1D residual blocks to extract features from\nthe input sequence while the other one employing 2D residual blocks to extract\nfeatures from the spectrogram representation. In the experiments, comparison\nstudies of different existing DNN models with/without data augmentation are\nconducted on an amyotrophic lateral sclerosis (ALS) dataset and a wind turbine\nfault (WTF) dataset. The experimental results manifest that our proposed method\nachieves 93.75% F1 score and 93.33% accuracy on the ALS datasets while 95.48%\nF1 score and 95.59% accuracy on the WTF datasets. Our methodology demonstrates\nits applicability of addressing the few-shot problems for time series\nclassification.",
            "author": [
                "Hao Zhang",
                "Zhendong Pang",
                "Jiangpeng Wang",
                "Teng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03194v1",
                "http://arxiv.org/pdf/2311.03194v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03191v2",
            "title": "DeepInception: Hypnotize Large Language Model to Be Jailbreaker",
            "updated": "2023-12-05T07:35:24Z",
            "published": "2023-11-06T15:29:30Z",
            "summary": "Despite remarkable success in various applications, large language models\n(LLMs) are vulnerable to adversarial jailbreaks that make the safety guardrails\nvoid. However, previous studies for jailbreaks usually resort to brute-force\noptimization or extrapolations of a high computation cost, which might not be\npractical or effective. In this paper, inspired by the Milgram experiment that\nindividuals can harm another person if they are told to do so by an\nauthoritative figure, we disclose a lightweight method, termed as\nDeepInception, which can easily hypnotize LLM to be a jailbreaker and unlock\nits misusing risks. Specifically, DeepInception leverages the personification\nability of LLM to construct a novel nested scene to behave, which realizes an\nadaptive way to escape the usage control in a normal scenario and provides the\npossibility for further direct jailbreaks. Empirically, we conduct\ncomprehensive experiments to show its efficacy. Our DeepInception can achieve\ncompetitive jailbreak success rates with previous counterparts and realize a\ncontinuous jailbreak in subsequent interactions, which reveals the critical\nweakness of self-losing on both open/closed-source LLMs like Falcon, Vicuna,\nLlama-2, and GPT-3.5/4/4V. Our investigation appeals that people should pay\nmore attention to the safety aspects of LLMs and a stronger defense against\ntheir misuse risks. The code is publicly available at:\nhttps://github.com/tmlr-group/DeepInception.",
            "author": [
                "Xuan Li",
                "Zhanke Zhou",
                "Jianing Zhu",
                "Jiangchao Yao",
                "Tongliang Liu",
                "Bo Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03191v2",
                "http://arxiv.org/pdf/2311.03191v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03184v1",
            "title": "Nexus at ArAIEval Shared Task: Fine-Tuning Arabic Language Models for\n  Propaganda and Disinformation Detection",
            "updated": "2023-11-06T15:24:18Z",
            "published": "2023-11-06T15:24:18Z",
            "summary": "The spread of disinformation and propagandistic content poses a threat to\nsocietal harmony, undermining informed decision-making and trust in reliable\nsources. Online platforms often serve as breeding grounds for such content, and\nmalicious actors exploit the vulnerabilities of audiences to shape public\nopinion. Although there have been research efforts aimed at the automatic\nidentification of disinformation and propaganda in social media content, there\nremain challenges in terms of performance. The ArAIEval shared task aims to\nfurther research on these particular issues within the context of the Arabic\nlanguage. In this paper, we discuss our participation in these shared tasks. We\ncompeted in subtasks 1A and 2A, where our submitted system secured positions\n9th and 10th, respectively. Our experiments consist of fine-tuning transformer\nmodels and using zero- and few-shot learning with GPT-4.",
            "author": [
                "Yunze Xiao",
                "Firoj Alam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03184v1",
                "http://arxiv.org/pdf/2311.03184v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.SI",
                "68T50",
                "F.2.2; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03421v3",
            "title": "Hopfield-Enhanced Deep Neural Networks for Artifact-Resilient Brain\n  State Decoding",
            "updated": "2023-11-10T16:52:26Z",
            "published": "2023-11-06T15:08:13Z",
            "summary": "The study of brain states, ranging from highly synchronous to asynchronous\nneuronal patterns like the sleep-wake cycle, is fundamental for assessing the\nbrain's spatiotemporal dynamics and their close connection to behavior.\nHowever, the development of new techniques to accurately identify them still\nremains a challenge, as these are often compromised by the presence of noise,\nartifacts, and suboptimal recording quality. In this study, we propose a\ntwo-stage computational framework combining Hopfield Networks for artifact data\npreprocessing with Convolutional Neural Networks (CNNs) for classification of\nbrain states in rat neural recordings under different levels of anesthesia. To\nevaluate the robustness of our framework, we deliberately introduced noise\nartifacts into the neural recordings. We evaluated our hybrid Hopfield-CNN\npipeline by benchmarking it against two comparative models: a standalone CNN\nhandling the same noisy inputs, and another CNN trained and tested on\nartifact-free data. Performance across various levels of data compression and\nnoise intensities showed that our framework can effectively mitigate artifacts,\nallowing the model to reach parity with the clean-data CNN at lower noise\nlevels. Although this study mainly benefits small-scale experiments, the\nfindings highlight the necessity for advanced deep learning and Hopfield\nNetwork models to improve scalability and robustness in diverse real-world\nsettings.",
            "author": [
                "Arnau Marin-Llobet",
                "Arnau Manasanch",
                "Maria V. Sanchez-Vives"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03421v3",
                "http://arxiv.org/pdf/2311.03421v3"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03172v1",
            "title": "Preserving Privacy in GANs Against Membership Inference Attack",
            "updated": "2023-11-06T15:04:48Z",
            "published": "2023-11-06T15:04:48Z",
            "summary": "Generative Adversarial Networks (GANs) have been widely used for generating\nsynthetic data for cases where there is a limited size real-world dataset or\nwhen data holders are unwilling to share their data samples. Recent works\nshowed that GANs, due to overfitting and memorization, might leak information\nregarding their training data samples. This makes GANs vulnerable to Membership\nInference Attacks (MIAs). Several defense strategies have been proposed in the\nliterature to mitigate this privacy issue. Unfortunately, defense strategies\nbased on differential privacy are proven to reduce extensively the quality of\nthe synthetic data points. On the other hand, more recent frameworks such as\nPrivGAN and PAR-GAN are not suitable for small-size training datasets. In the\npresent work, the overfitting in GANs is studied in terms of the discriminator,\nand a more general measure of overfitting based on the Bhattacharyya\ncoefficient is defined. Then, inspired by Fano's inequality, our first defense\nmechanism against MIAs is proposed. This framework, which requires only a\nsimple modification in the loss function of GANs, is referred to as the maximum\nentropy GAN or MEGAN and significantly improves the robustness of GANs to MIAs.\nAs a second defense strategy, a more heuristic model based on minimizing the\ninformation leaked from generated samples about the training data points is\npresented. This approach is referred to as mutual information minimization GAN\n(MIMGAN) and uses a variational representation of the mutual information to\nminimize the information that a synthetic sample might leak about the whole\ntraining data set. Applying the proposed frameworks to some commonly used data\nsets against state-of-the-art MIAs reveals that the proposed methods can reduce\nthe accuracy of the adversaries to the level of random guessing accuracy with a\nsmall reduction in the quality of the synthetic data samples.",
            "author": [
                "Mohammadhadi Shateri",
                "Francisco Messina",
                "Fabrice Labeau",
                "Pablo Piantanida"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03172v1",
                "http://arxiv.org/pdf/2311.03172v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03171v1",
            "title": "An Examination of the Alleged Privacy Threats of Confidence-Ranked\n  Reconstruction of Census Microdata",
            "updated": "2023-11-06T15:04:03Z",
            "published": "2023-11-06T15:04:03Z",
            "summary": "The alleged threat of reconstruction attacks has led the U.S. Census Bureau\n(USCB) to replace in the Decennial Census 2020 the traditional statistical\ndisclosure limitation based on rank swapping with one based on differential\nprivacy (DP). This has resulted in substantial accuracy loss of the released\nstatistics. Worse yet, it has been shown that the reconstruction attacks used\nas an argument to move to DP are very far from allowing unequivocal\nreidentification of the respondents, because in general there are a lot of\nreconstructions compatible with the released statistics. In a very recent\npaper, a new reconstruction attack has been proposed, whose goal is to indicate\nthe confidence that a reconstructed record was in the original respondent data.\nThe alleged risk of serious disclosure entailed by such confidence-ranked\nreconstruction has renewed the interest of the USCB to use DP-based solutions.\nTo forestall the potential accuracy loss in future data releases resulting from\nadoption of these solutions, we show in this paper that the proposed\nconfidence-ranked reconstruction does not threaten privacy. Specifically, we\nreport empirical results showing that the proposed ranking cannot guide\nreidentification or attribute disclosure attacks, and hence it fails to warrant\nthe USCB's move towards DP. Further, we also demonstrate that, due to the way\nthe Census data are compiled, processed and released, it is not possible to\nreconstruct original and complete records through any methodology, and the\nconfidence-ranked reconstruction not only is completely ineffective at\naccurately reconstructing Census records but is trivially outperformed by an\nadequate interpretation of the released aggregate statistics.",
            "author": [
                "David S\u00e1nchez",
                "Najeeb Jebreel",
                "Josep Domingo-Ferrer",
                "Krishnamurty Muralidhar",
                "Alberto Blanco-Justicia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03171v1",
                "http://arxiv.org/pdf/2311.03171v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03157v1",
            "title": "GPTuner: A Manual-Reading Database Tuning System via GPT-Guided Bayesian\n  Optimization",
            "updated": "2023-11-06T14:52:30Z",
            "published": "2023-11-06T14:52:30Z",
            "summary": "Modern database management systems (DBMS) expose hundreds of configurable\nknobs to control system behaviours. Determining the appropriate values for\nthese knobs to improve DBMS performance is a long-standing problem in the\ndatabase community. As there is an increasing number of knobs to tune and each\nknob could be in continuous or categorical values, manual tuning becomes\nimpractical. Recently, automatic tuning systems using machine learning methods\nhave shown great potentials. However, existing approaches still incur\nsignificant tuning costs or only yield sub-optimal performance. This is because\nthey either ignore the extensive domain knowledge available (e.g., DBMS manuals\nand forum discussions) and only rely on the runtime feedback of benchmark\nevaluations to guide the optimization, or they utilize the domain knowledge in\na limited way. Hence, we propose GPTuner, a manual-reading database tuning\nsystem. Firstly, we develop a Large Language Model (LLM)-based pipeline to\ncollect and refine heterogeneous knowledge, and propose a prompt ensemble\nalgorithm to unify a structured view of the refined knowledge. Secondly, using\nthe structured knowledge, we (1) design a workload-aware and training-free knob\nselection strategy, (2) develop a search space optimization technique\nconsidering the value range of each knob, and (3) propose a Coarse-to-Fine\nBayesian Optimization Framework to explore the optimized space. Finally, we\nevaluate GPTuner under different benchmarks (TPC-C and TPC-H), metrics\n(throughput and latency) as well as DBMS (PostgreSQL and MySQL). Compared to\nthe state-of-the-art approaches, GPTuner identifies better configurations in\n16x less time on average. Moreover, GPTuner achieves up to 30% performance\nimprovement (higher throughput or lower latency) over the best-performing\nalternative.",
            "author": [
                "Jiale Lao",
                "Yibo Wang",
                "Yufei Li",
                "Jianping Wang",
                "Yunjia Zhang",
                "Zhiyuan Cheng",
                "Wanghu Chen",
                "Mingjie Tang",
                "Jianguo Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03157v1",
                "http://arxiv.org/pdf/2311.03157v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03154v1",
            "title": "Convergence Analysis of Sequential Federated Learning on Heterogeneous\n  Data",
            "updated": "2023-11-06T14:48:51Z",
            "published": "2023-11-06T14:48:51Z",
            "summary": "There are two categories of methods in Federated Learning (FL) for joint\ntraining across multiple clients: i) parallel FL (PFL), where clients train\nmodels in a parallel manner; and ii) sequential FL (SFL), where clients train\nmodels in a sequential manner. In contrast to that of PFL, the convergence\ntheory of SFL on heterogeneous data is still lacking. In this paper, we\nestablish the convergence guarantees of SFL for strongly/general/non-convex\nobjectives on heterogeneous data. The convergence guarantees of SFL are better\nthan that of PFL on heterogeneous data with both full and partial client\nparticipation. Experimental results validate the counterintuitive analysis\nresult that SFL outperforms PFL on extremely heterogeneous data in cross-device\nsettings.",
            "author": [
                "Yipeng Li",
                "Xinchen Lyu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03154v1",
                "http://arxiv.org/pdf/2311.03154v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03151v1",
            "title": "Using Shallow Neural Networks with Functional Connectivity from EEG\n  signals for Early Diagnosis of Alzheimer's and Frontotemporal Dementia",
            "updated": "2023-11-06T14:46:30Z",
            "published": "2023-11-06T14:46:30Z",
            "summary": "{Introduction: } Dementia is a neurological disorder associated with aging\nthat can cause a loss of cognitive functions, impacting daily life. Alzheimer's\ndisease (AD) is the most common cause of dementia, accounting for 50--70\\% of\ncases, while frontotemporal dementia (FTD) affects social skills and\npersonality. Electroencephalography (EEG) provides an effective tool to study\nthe effects of AD on the brain. {Methods: } In this study, we propose to use\nshallow neural networks applied to two sets of features: spectral-temporal and\nfunctional connectivity using four methods. We compare three supervised machine\nlearning techniques to the CNN models to classify EEG signals of AD / FTD and\ncontrol cases. We also evaluate different measures of functional connectivity\nfrom common EEG frequency bands considering multiple thresholds. {Results and\nDiscussion: } Results showed that the shallow CNN-based models achieved the\nhighest accuracy of 94.54\\% with AEC in test dataset when considering all\nconnections, outperforming conventional methods and providing potentially an\nadditional early dementia diagnosis tool.\n\\url{https://doi.org/10.3389%2Ffneur.2023.1270405}",
            "author": [
                "Zaineb Ajra",
                "Binbin Xu",
                "G\u00e9rard Dray",
                "Jacky Montmain",
                "St\u00e9phane Perrey"
            ],
            "link": [
                "http://dx.doi.org/10.3389/fneur.2023.1270405",
                "http://arxiv.org/abs/2311.03151v1",
                "http://arxiv.org/pdf/2311.03151v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03150v2",
            "title": "A Brain-inspired Theory of Collective Mind Model for Efficient Social\n  Cooperation",
            "updated": "2023-11-08T02:34:41Z",
            "published": "2023-11-06T14:45:43Z",
            "summary": "Social intelligence manifests the capability, often referred to as the Theory\nof Mind (ToM), to discern others' behavioral intentions, beliefs, and other\nmental states. ToM is especially important in multi-agent and human-machine\ninteraction environments because each agent needs to understand the mental\nstates of other agents in order to better respond, interact, and collaborate.\nRecent research indicates that the ToM model possesses the capability to infer\nbeliefs, intentions, and anticipate future observations and actions;\nnonetheless, its deployment in tackling intricate tasks remains notably\nlimited. The challenges arise when the number of agents increases, the\nenvironment becomes more complex, and interacting with the environment and\npredicting the mental state of each other becomes difficult and time consuming.\nTo overcome such limits, we take inspiration from the Theory of Collective Mind\n(ToCM) mechanism, predicting observations of all other agents into a unified\nbut plural representation and discerning how our own actions affect this mental\nstate representation. Based on this foundation, we construct an imaginative\nspace to simulate the multi-agent interaction process, thus improving the\nefficiency of cooperation among multiple agents in complex decision-making\nenvironments. In various cooperative tasks with different numbers of agents,\nthe experimental results highlight the superior cooperative efficiency and\nperformance of our approach compared to the Multi-Agent Reinforcement Learning\n(MARL) baselines. We achieve consistent boost on SNN- and DNN-based decision\nnetworks, and demonstrate that ToCM's inferences about others' mental states\ncan be transferred to new tasks for quickly and flexible adaptation.",
            "author": [
                "Zhuoya Zhao",
                "Feifei Zhao",
                "Shiwen Wang",
                "Yinqian Sun",
                "Yi Zeng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03150v2",
                "http://arxiv.org/pdf/2311.03150v2"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03140v1",
            "title": "Animating NeRFs from Texture Space: A Framework for Pose-Dependent\n  Rendering of Human Performances",
            "updated": "2023-11-06T14:34:36Z",
            "published": "2023-11-06T14:34:36Z",
            "summary": "Creating high-quality controllable 3D human models from multi-view RGB videos\nposes a significant challenge. Neural radiance fields (NeRFs) have demonstrated\nremarkable quality in reconstructing and free-viewpoint rendering of static as\nwell as dynamic scenes. The extension to a controllable synthesis of dynamic\nhuman performances poses an exciting research question. In this paper, we\nintroduce a novel NeRF-based framework for pose-dependent rendering of human\nperformances. In our approach, the radiance field is warped around an SMPL body\nmesh, thereby creating a new surface-aligned representation. Our representation\ncan be animated through skeletal joint parameters that are provided to the NeRF\nin addition to the viewpoint for pose dependent appearances. To achieve this,\nour representation includes the corresponding 2D UV coordinates on the mesh\ntexture map and the distance between the query point and the mesh. To enable\nefficient learning despite mapping ambiguities and random visual variations, we\nintroduce a novel remapping process that refines the mapped coordinates.\nExperiments demonstrate that our approach results in high-quality renderings\nfor novel-view and novel-pose synthesis.",
            "author": [
                "Paul Knoll",
                "Wieland Morgenstern",
                "Anna Hilsmann",
                "Peter Eisert"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03140v1",
                "http://arxiv.org/pdf/2311.03140v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03139v1",
            "title": "End-to-end Material Thermal Conductivity Prediction through Machine\n  Learning",
            "updated": "2023-11-06T14:34:30Z",
            "published": "2023-11-06T14:34:30Z",
            "summary": "We investigated the accelerated prediction of the thermal conductivity of\nmaterials through end- to-end structure-based approaches employing machine\nlearning methods. Due to the non-availability of high-quality thermal\nconductivity data, we first performed high-throughput calculations based on\nfirst principles and the Boltzmann transport equation for 225 materials,\neffectively more than doubling the size of the existing dataset. We assessed\nthe performance of state-of-the-art machine learning models for thermal\nconductivity prediction on this expanded dataset and observed that all these\nmodels suffered from overfitting. To address this issue, we introduced a novel\ngraph-based neural network model, which demonstrated more consistent and\nregularized performance across all evaluated datasets. Nevertheless, the best\nmean absolute percentage error achieved on the test dataset remained in the\nrange of 50-60%. This suggests that while these models are valuable for\nexpediting material screening, their current accuracy is still limited.",
            "author": [
                "Yagyank Srivastava",
                "Ankit Jain"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03139v1",
                "http://arxiv.org/pdf/2311.03139v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03133v3",
            "title": "Incorporating basic calibrations in existing machine-learned turbulence\n  modeling",
            "updated": "2023-11-14T16:55:30Z",
            "published": "2023-11-06T14:28:44Z",
            "summary": "This work aims to incorporate basic calibrations of Reynolds-averaged\nNavier-Stokes (RANS) models as part of machine learning (ML) frameworks. The ML\nframeworks considered are tensor-basis neural network (TBNN), physics-informed\nmachine learning (PIML), and field inversion & machine learning (FIML) in J.\nFluid Mech., 2016, 807, 155-166, Phys. Rev. Fluids, 2017, 2(3), 034603 and J.\nComp. Phys., 2016, 305, 758-774, and the baseline RANS models are the\none-equation Spalart-Allmaras model, the two-equation $k$-$\\omega$ model, and\nthe seven-equation Reynolds stress transport models. ML frameworks are trained\nagainst plane channel flow and shear-layer flow data. We compare the ML\nframeworks and study whether the machine-learned augmentations are detrimental\noutside the training set. The findings are summarized as follows. The\naugmentations due to TBNN are detrimental. PIML leads to augmentations that are\nbeneficial inside the training dataset but detrimental outside it. These\nresults are not affected by the baseline RANS model. FIML's augmentations to\nthe two eddy viscosity models, where an inner-layer treatment already exists,\nare largely neutral. Its augmentation to the seven-equation model, where an\ninner-layer treatment does not exist, improves the mean flow prediction in a\nchannel. Furthermore, these FIML augmentations are mostly non-detrimental\noutside the training dataset. In addition to reporting these results, the paper\noffers physical explanations of the results. Last, we note that the conclusions\ndrawn here are confined to the ML frameworks and the flows considered in this\nstudy. More detailed comparative studies and validation & verification studies\nare needed to account for developments in recent years.",
            "author": [
                "Jiaqi J. L. Li",
                "Yuanwei Bin",
                "George P. Huang",
                "Xiang I. A. Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03133v3",
                "http://arxiv.org/pdf/2311.03133v3"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03131v1",
            "title": "Reservoir-Computing Model for Mapping and Forecasting Neuronal\n  Interactions from Electrophysiological Data",
            "updated": "2023-11-06T14:28:11Z",
            "published": "2023-11-06T14:28:11Z",
            "summary": "Electrophysiological nature of neuronal networks allows to reveal various\ninteractions between different cell units at a very short time-scales. One of\nthe many challenges in analyzing these signals is to retrieve the morphology\nand functionality of a given network. In this work we developed a computational\nmodel, based on Reservoir Computing Network (RCN) architecture, which decodes\nthe spatio-temporal data from electro-physiological measurements of neuronal\ncultures and reconstructs the network structure on a macroscopic domain,\nrepresenting the connectivity between neuronal units. We demonstrate that the\nmodel can predict the connectivity map of the network with higher accuracy than\nthe common methods such as Cross-Correlation and Transfer-Entropy. In addition,\nwe experimentally demonstrate the ability of the model to predict a network\nresponse to a specific input, such as localized stimulus.",
            "author": [
                "Ilya Auslender",
                "Giorgio Letti",
                "Yasaman Heydari",
                "Lorenzo Pavesi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03131v1",
                "http://arxiv.org/pdf/2311.03131v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG",
                "physics.bio-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03129v1",
            "title": "Nonparametric modeling of the composite effect of multiple nutrients on\n  blood glucose dynamics",
            "updated": "2023-11-06T14:27:01Z",
            "published": "2023-11-06T14:27:01Z",
            "summary": "In biomedical applications it is often necessary to estimate a physiological\nresponse to a treatment consisting of multiple components, and learn the\nseparate effects of the components in addition to the joint effect. Here, we\nextend existing probabilistic nonparametric approaches to explicitly address\nthis problem. We also develop a new convolution-based model for composite\ntreatment-response curves that is more biologically interpretable. We validate\nour models by estimating the impact of carbohydrate and fat in meals on blood\nglucose. By differentiating treatment components, incorporating their dosages,\nand sharing statistical information across patients via a hierarchical\nmulti-output Gaussian process, our method improves prediction accuracy over\nexisting approaches, and allows us to interpret the different effects of\ncarbohydrates and fat on the overall glucose response.",
            "author": [
                "Arina Odnoblyudova",
                "\u00c7a\u011flar Hizli",
                "ST John",
                "Andrea Cognolato",
                "Anne Juuti",
                "Simo S\u00e4rkk\u00e4",
                "Kirsi Pietil\u00e4inen",
                "Pekka Marttinen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03129v1",
                "http://arxiv.org/pdf/2311.03129v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03124v1",
            "title": "TAMPAR: Visual Tampering Detection for Parcel Logistics in Postal Supply\n  Chains",
            "updated": "2023-11-06T14:19:05Z",
            "published": "2023-11-06T14:19:05Z",
            "summary": "Due to the steadily rising amount of valuable goods in supply chains,\ntampering detection for parcels is becoming increasingly important. In this\nwork, we focus on the use-case last-mile delivery, where only a single RGB\nimage is taken and compared against a reference from an existing database to\ndetect potential appearance changes that indicate tampering. We propose a\ntampering detection pipeline that utilizes keypoint detection to identify the\neight corner points of a parcel. This permits applying a perspective\ntransformation to create normalized fronto-parallel views for each visible\nparcel side surface. These viewpoint-invariant parcel side surface\nrepresentations facilitate the identification of signs of tampering on parcels\nwithin the supply chain, since they reduce the problem to parcel side surface\nmatching with pair-wise appearance change detection. Experiments with multiple\nclassical and deep learning-based change detection approaches are performed on\nour newly collected TAMpering detection dataset for PARcels, called TAMPAR. We\nevaluate keypoint and change detection separately, as well as in a unified\nsystem for tampering detection. Our evaluation shows promising results for\nkeypoint (Keypoint AP 75.76) and tampering detection (81% accuracy, F1-Score\n0.83) on real images. Furthermore, a sensitivity analysis for tampering types,\nlens distortion and viewing angles is presented. Code and dataset are available\nat https://a-nau.github.io/tampar.",
            "author": [
                "Alexander Naumann",
                "Felix Hertlein",
                "Laura D\u00f6rr",
                "Kai Furmans"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03124v1",
                "http://arxiv.org/pdf/2311.03124v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03420v1",
            "title": "Text Augmentations with R-drop for Classification of Tweets Self\n  Reporting Covid-19",
            "updated": "2023-11-06T14:18:16Z",
            "published": "2023-11-06T14:18:16Z",
            "summary": "This paper presents models created for the Social Media Mining for Health\n2023 shared task. Our team addressed the first task, classifying tweets that\nself-report Covid-19 diagnosis. Our approach involves a classification model\nthat incorporates diverse textual augmentations and utilizes R-drop to augment\ndata and mitigate overfitting, boosting model efficacy. Our leading model,\nenhanced with R-drop and augmentations like synonym substitution, reserved\nwords, and back translations, outperforms the task mean and median scores. Our\nsystem achieves an impressive F1 score of 0.877 on the test set.",
            "author": [
                "Sumam Francis",
                "Marie-Francine Moens"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03420v1",
                "http://arxiv.org/pdf/2311.03420v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03118v1",
            "title": "Algebraic Dynamical Systems in Machine Learning",
            "updated": "2023-11-06T14:10:40Z",
            "published": "2023-11-06T14:10:40Z",
            "summary": "We introduce an algebraic analogue of dynamical systems, based on term\nrewriting. We show that a recursive function applied to the output of an\niterated rewriting system defines a formal class of models into which all the\nmain architectures for dynamic machine learning models (including recurrent\nneural networks, graph neural networks, and diffusion models) can be embedded.\nConsidered in category theory, we also show that these algebraic models are a\nnatural language for describing the compositionality of dynamic models.\nFurthermore, we propose that these models provide a template for the\ngeneralisation of the above dynamic models to learning problems on structured\nor non-numerical data, including 'hybrid symbolic-numeric' models.",
            "author": [
                "Iolo Jones",
                "Jerry Swan",
                "Jeffrey Giansiracusa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03118v1",
                "http://arxiv.org/pdf/2311.03118v1"
            ],
            "primary_category": "math.CT",
            "category": [
                "math.CT",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03115v1",
            "title": "RELand: Risk Estimation of Landmines via Interpretable Invariant Risk\n  Minimization",
            "updated": "2023-11-06T14:07:47Z",
            "published": "2023-11-06T14:07:47Z",
            "summary": "Landmines remain a threat to war-affected communities for years after\nconflicts have ended, partly due to the laborious nature of demining tasks.\nHumanitarian demining operations begin by collecting relevant information from\nthe sites to be cleared, which is then analyzed by human experts to determine\nthe potential risk of remaining landmines. In this paper, we propose RELand\nsystem to support these tasks, which consists of three major components. We (1)\nprovide general feature engineering and label assigning guidelines to enhance\ndatasets for landmine risk modeling, which are widely applicable to global\ndemining routines, (2) formulate landmine presence as a classification problem\nand design a novel interpretable model based on sparse feature masking and\ninvariant risk minimization, and run extensive evaluation under proper\nprotocols that resemble real-world demining operations to show a significant\nimprovement over the state-of-the-art, and (3) build an interactive web\ninterface to suggest priority areas for demining organizations. We are\ncurrently collaborating with a humanitarian demining NGO in Colombia that is\nusing our system as part of their field operations in two areas recently\nprioritized for demining.",
            "author": [
                "Mateo Dulce Rubio",
                "Siqi Zeng",
                "Qi Wang",
                "Didier Alvarado",
                "Francisco Moreno",
                "Hoda Heidari",
                "Fei Fang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03115v1",
                "http://arxiv.org/pdf/2311.03115v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03113v1",
            "title": "Injecting Categorical Labels and Syntactic Information into Biomedical\n  NER",
            "updated": "2023-11-06T14:03:59Z",
            "published": "2023-11-06T14:03:59Z",
            "summary": "We present a simple approach to improve biomedical named entity recognition\n(NER) by injecting categorical labels and Part-of-speech (POS) information into\nthe model. We use two approaches, in the first approach, we first train a\nsequence-level classifier to classify the sentences into categories to obtain\nthe sentence-level tags (categorical labels). The sequence classifier is\nmodeled as an entailment problem by modifying the labels as a natural language\ntemplate. This helps to improve the accuracy of the classifier. Further, this\nlabel information is injected into the NER model. In this paper, we demonstrate\neffective ways to represent and inject these labels and POS attributes into the\nNER model. In the second approach, we jointly learn the categorical labels and\nNER labels. Here we also inject the POS tags into the model to increase the\nsyntactic context of the model. Experiments on three benchmark datasets show\nthat incorporating categorical label information with syntactic context is\nquite useful and outperforms baseline BERT-based models.",
            "author": [
                "Sumam Francis",
                "Marie-Francine Moens"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03113v1",
                "http://arxiv.org/pdf/2311.03113v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03109v1",
            "title": "Tensor Golub Kahan based on Einstein product",
            "updated": "2023-11-06T13:58:54Z",
            "published": "2023-11-06T13:58:54Z",
            "summary": "The Singular Value Decomposition (SVD) of matrices is a widely used tool in\nscientific computing. In many applications of machine learning, data analysis,\nsignal and image processing, the large datasets are structured into tensors,\nfor which generalizations of SVD have already been introduced, for various\ntypes of tensor-tensor products. In this article, we present innovative methods\nfor approximating this generalization of SVD to tensors in the framework of the\nEinstein tensor product. These singular elements are called singular values and\nsingular tensors, respectively. The proposed method uses the tensor Lanczos\nbidiagonalization applied to the Einstein product. In most applications, as in\nthe matrix case, the extremal singular values are of special interest. To\nenhance the approximation of the largest or the smallest singular triplets\n(singular values and left and right singular tensors), a restarted method based\non Ritz augmentation is proposed. Numerical results are proposed to illustrate\nthe effectiveness of the presented method. In addition, applications to video\ncompression and facial recognition are presented.",
            "author": [
                "Anas El Hachimi",
                "Khalide Jbilou",
                "Mustapha Hached",
                "Ahmed Ratnani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03109v1",
                "http://arxiv.org/pdf/2311.03109v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03106v1",
            "title": "Unified Multi-modal Unsupervised Representation Learning for\n  Skeleton-based Action Understanding",
            "updated": "2023-11-06T13:56:57Z",
            "published": "2023-11-06T13:56:57Z",
            "summary": "Unsupervised pre-training has shown great success in skeleton-based action\nunderstanding recently. Existing works typically train separate\nmodality-specific models, then integrate the multi-modal information for action\nunderstanding by a late-fusion strategy. Although these approaches have\nachieved significant performance, they suffer from the complex yet redundant\nmulti-stream model designs, each of which is also limited to the fixed input\nskeleton modality. To alleviate these issues, in this paper, we propose a\nUnified Multimodal Unsupervised Representation Learning framework, called\nUmURL, which exploits an efficient early-fusion strategy to jointly encode the\nmulti-modal features in a single-stream manner. Specifically, instead of\ndesigning separate modality-specific optimization processes for uni-modal\nunsupervised learning, we feed different modality inputs into the same stream\nwith an early-fusion strategy to learn their multi-modal features for reducing\nmodel complexity. To ensure that the fused multi-modal features do not exhibit\nmodality bias, i.e., being dominated by a certain modality input, we further\npropose both intra- and inter-modal consistency learning to guarantee that the\nmulti-modal features contain the complete semantics of each modal via feature\ndecomposition and distinct alignment. In this manner, our framework is able to\nlearn the unified representations of uni-modal or multi-modal skeleton input,\nwhich is flexible to different kinds of modality input for robust action\nunderstanding in practical cases. Extensive experiments conducted on three\nlarge-scale datasets, i.e., NTU-60, NTU-120, and PKU-MMD II, demonstrate that\nUmURL is highly efficient, possessing the approximate complexity with the\nuni-modal methods, while achieving new state-of-the-art performance across\nvarious downstream task scenarios in skeleton-based action representation\nlearning.",
            "author": [
                "Shengkai Sun",
                "Daizong Liu",
                "Jianfeng Dong",
                "Xiaoye Qu",
                "Junyu Gao",
                "Xun Yang",
                "Xun Wang",
                "Meng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03106v1",
                "http://arxiv.org/pdf/2311.03106v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03105v2",
            "title": "Pelvic floor MRI segmentation based on semi-supervised deep learning",
            "updated": "2023-11-22T15:46:00Z",
            "published": "2023-11-06T13:54:52Z",
            "summary": "The semantic segmentation of pelvic organs via MRI has important clinical\nsignificance. Recently, deep learning-enabled semantic segmentation has\nfacilitated the three-dimensional geometric reconstruction of pelvic floor\norgans, providing clinicians with accurate and intuitive diagnostic results.\nHowever, the task of labeling pelvic floor MRI segmentation, typically\nperformed by clinicians, is labor-intensive and costly, leading to a scarcity\nof labels. Insufficient segmentation labels limit the precise segmentation and\nreconstruction of pelvic floor organs. To address these issues, we propose a\nsemi-supervised framework for pelvic organ segmentation. The implementation of\nthis framework comprises two stages. In the first stage, it performs\nself-supervised pre-training using image restoration tasks. Subsequently,\nfine-tuning of the self-supervised model is performed, using labeled data to\ntrain the segmentation model. In the second stage, the self-supervised\nsegmentation model is used to generate pseudo labels for unlabeled data.\nUltimately, both labeled and unlabeled data are utilized in semi-supervised\ntraining. Upon evaluation, our method significantly enhances the performance in\nthe semantic segmentation and geometric reconstruction of pelvic organs, Dice\ncoefficient can increase by 2.65% averagely. Especially for organs that are\ndifficult to segment, such as the uterus, the accuracy of semantic segmentation\ncan be improved by up to 3.70%.",
            "author": [
                "Jianwei Zuo",
                "Fei Feng",
                "Zhuhui Wang",
                "James A. Ashton-Miller",
                "John O. L. Delancey",
                "Jiajia Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03105v2",
                "http://arxiv.org/pdf/2311.03105v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03099v1",
            "title": "Language Models are Super Mario: Absorbing Abilities from Homologous\n  Models as a Free Lunch",
            "updated": "2023-11-06T13:43:07Z",
            "published": "2023-11-06T13:43:07Z",
            "summary": "In this paper, we uncover that Language Models (LMs), either encoder- or\ndecoder-based, can obtain new capabilities by assimilating the parameters of\nhomologous models without retraining or GPUs. Typically, new abilities of LMs\ncan be imparted by Supervised Fine-Tuning (SFT), reflected in the disparity\nbetween fine-tuned and pre-trained parameters (i.e., delta parameters). We\ninitially observe that by introducing a novel operation called DARE (Drop And\nREscale), most delta parameters can be directly set to zeros without affecting\nthe capabilities of SFT LMs and larger models can tolerate a higher proportion\nof discarded parameters. Based on this observation, we further sparsify delta\nparameters of multiple SFT homologous models with DARE and subsequently merge\nthem into a single model by parameter averaging. We conduct experiments on\neight datasets from the GLUE benchmark with BERT and RoBERTa. We also merge\nWizardLM, WizardMath, and Code Alpaca based on Llama 2. Experimental results\nshow that: (1) The delta parameter value ranges for SFT models are typically\nsmall, often within 0.005, and DARE can eliminate 99% of them effortlessly.\nHowever, once the models are continuously pre-trained, the value ranges can\ngrow to around 0.03, making DARE impractical. We have also tried to remove\nfine-tuned instead of delta parameters and find that a 10% reduction can lead\nto drastically decreased performance (even to 0). This highlights that SFT\nmerely stimulates the abilities via delta parameters rather than injecting new\nabilities into LMs; (2) DARE can merge multiple task-specific LMs into one LM\nwith diverse abilities. For instance, the merger of WizardLM and WizardMath\nimproves the GSM8K zero-shot accuracy of WizardLM from 2.2 to 66.3, retaining\nits instruction-following ability while surpassing WizardMath's original 64.2\nperformance. Codes are available at https://github.com/yule-BUAA/MergeLM.",
            "author": [
                "Le Yu",
                "Bowen Yu",
                "Haiyang Yu",
                "Fei Huang",
                "Yongbin Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03099v1",
                "http://arxiv.org/pdf/2311.03099v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03096v1",
            "title": "Weight-Sharing Regularization",
            "updated": "2023-11-06T13:37:34Z",
            "published": "2023-11-06T13:37:34Z",
            "summary": "Weight-sharing is ubiquitous in deep learning. Motivated by this, we\nintroduce ''weight-sharing regularization'' for neural networks, defined as\n$R(w) = \\frac{1}{d - 1}\\sum_{i > j}^d |w_i - w_j|$. We study the proximal\nmapping of $R$ and provide an intuitive interpretation of it in terms of a\nphysical system of interacting particles. Using this interpretation, we design\na novel parallel algorithm for $\\operatorname{prox}_R$ which provides an\nexponential speedup over previous algorithms, with a depth of $O(\\log^3 d)$.\nOur algorithm makes it feasible to train weight-sharing regularized deep neural\nnetworks with proximal gradient descent. Experiments reveal that weight-sharing\nregularization enables fully-connected networks to learn convolution-like\nfilters.",
            "author": [
                "Mehran Shakerinava",
                "Motahareh Sohrabi",
                "Siamak Ravanbakhsh",
                "Simon Lacoste-Julien"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03096v1",
                "http://arxiv.org/pdf/2311.03096v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03094v1",
            "title": "Equivariance Is Not All You Need: Characterizing the Utility of\n  Equivariant Graph Neural Networks for Particle Physics Tasks",
            "updated": "2023-11-06T13:37:00Z",
            "published": "2023-11-06T13:37:00Z",
            "summary": "Incorporating inductive biases into ML models is an active area of ML\nresearch, especially when ML models are applied to data about the physical\nworld. Equivariant Graph Neural Networks (GNNs) have recently become a popular\nmethod for learning from physics data because they directly incorporate the\nsymmetries of the underlying physical system. Drawing from the relevant\nliterature around group equivariant networks, this paper presents a\ncomprehensive evaluation of the proposed benefits of equivariant GNNs by using\nreal-world particle physics reconstruction tasks as an evaluation test-bed. We\ndemonstrate that many of the theoretical benefits generally associated with\nequivariant networks may not hold for realistic systems and introduce\ncompelling directions for future research that will benefit both the scientific\ntheory of ML and physics applications.",
            "author": [
                "Savannah Thais",
                "Daniel Murnane"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03094v1",
                "http://arxiv.org/pdf/2311.03094v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03087v1",
            "title": "Persistent homology for high-dimensional data based on spectral methods",
            "updated": "2023-11-06T13:18:08Z",
            "published": "2023-11-06T13:18:08Z",
            "summary": "Persistent homology is a popular computational tool for detecting non-trivial\ntopology of point clouds, such as the presence of loops or voids. However, many\nreal-world datasets with low intrinsic dimensionality reside in an ambient\nspace of much higher dimensionality. We show that in this case vanilla\npersistent homology becomes very sensitive to noise and fails to detect the\ncorrect topology. The same holds true for most existing refinements of\npersistent homology. As a remedy, we find that spectral distances on the\n$k$-nearest-neighbor graph of the data, such as diffusion distance and\neffective resistance, allow persistent homology to detect the correct topology\neven in the presence of high-dimensional noise. Furthermore, we derive a novel\nclosed-form expression for effective resistance in terms of the\neigendecomposition of the graph Laplacian, and describe its relation to\ndiffusion distances. Finally, we apply these methods to several\nhigh-dimensional single-cell RNA-sequencing datasets and show that spectral\ndistances on the $k$-nearest-neighbor graph allow robust detection of cell\ncycle loops.",
            "author": [
                "Sebastian Damrich",
                "Philipp Berens",
                "Dmitry Kobak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03087v1",
                "http://arxiv.org/pdf/2311.03087v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.AT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03084v2",
            "title": "A Simple yet Efficient Ensemble Approach for AI-generated Text Detection",
            "updated": "2023-11-08T04:28:57Z",
            "published": "2023-11-06T13:11:02Z",
            "summary": "Recent Large Language Models (LLMs) have demonstrated remarkable capabilities\nin generating text that closely resembles human writing across wide range of\nstyles and genres. However, such capabilities are prone to potential abuse,\nsuch as fake news generation, spam email creation, and misuse in academic\nassignments. Hence, it is essential to build automated approaches capable of\ndistinguishing between artificially generated text and human-authored text. In\nthis paper, we propose a simple yet efficient solution to this problem by\nensembling predictions from multiple constituent LLMs. Compared to previous\nstate-of-the-art approaches, which are perplexity-based or uses ensembles with\na number of LLMs, our condensed ensembling approach uses only two constituent\nLLMs to achieve comparable performance. Experiments conducted on four benchmark\ndatasets for generative text classification show performance improvements in\nthe range of 0.5 to 100\\% compared to previous state-of-the-art approaches. We\nalso study the influence that the training data from individual LLMs have on\nmodel performance. We found that substituting commercially-restrictive\nGenerative Pre-trained Transformer (GPT) data with data generated from other\nopen language models such as Falcon, Large Language Model Meta AI (LLaMA2), and\nMosaic Pretrained Transformers (MPT) is a feasible alternative when developing\ngenerative text detectors. Furthermore, to demonstrate zero-shot\ngeneralization, we experimented with an English essays dataset, and results\nsuggest that our ensembling approach can handle new data effectively.",
            "author": [
                "Harika Abburi",
                "Kalyani Roy",
                "Michael Suesserman",
                "Nirmala Pudota",
                "Balaji Veeramani",
                "Edward Bowen",
                "Sanmitra Bhattacharya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03084v2",
                "http://arxiv.org/pdf/2311.03084v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03083v1",
            "title": "Quantifying the value of information transfer in population-based SHM",
            "updated": "2023-11-06T13:10:38Z",
            "published": "2023-11-06T13:10:38Z",
            "summary": "Population-based structural health monitoring (PBSHM), seeks to address some\nof the limitations associated with data scarcity that arise in traditional SHM.\nA tenet of the population-based approach to SHM is that information can be\nshared between sufficiently-similar structures in order to improve predictive\nmodels. Transfer learning techniques, such as domain adaptation, have been\nshown to be a highly-useful technology for sharing information between\nstructures when developing statistical classifiers for PBSHM. Nonetheless,\ntransfer-learning techniques are not without their pitfalls. In some\ncircumstances, for example if the data distributions associated with the\nstructures within a population are dissimilar, applying transfer-learning\nmethods can be detrimental to classification performance -- this phenomenon is\nknown as negative transfer. Given the potentially-severe consequences of\nnegative transfer, it is prudent for engineers to ask the question `when, what,\nand how should one transfer between structures?'.\n  The current paper aims to demonstrate a transfer-strategy decision process\nfor a classification task for a population of simulated structures in the\ncontext of a representative SHM maintenance problem, supported by domain\nadaptation. The transfer decision framework is based upon the concept of\nexpected value of information transfer. In order to compute the expected value\nof information transfer, predictions must be made regarding the classification\n(and decision performance) in the target domain following information transfer.\nIn order to forecast the outcome of transfers, a probabilistic regression is\nused here to predict classification performance from a proxy for structural\nsimilarity based on the modal assurance criterion.",
            "author": [
                "Aidan J. Hughes",
                "Jack Poole",
                "Nikolaos Dervilis",
                "Paul Gardner",
                "Keith Worden"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03083v1",
                "http://arxiv.org/pdf/2311.03083v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03082v1",
            "title": "A survey and classification of face alignment methods based on face\n  models",
            "updated": "2023-11-06T13:09:04Z",
            "published": "2023-11-06T13:09:04Z",
            "summary": "A face model is a mathematical representation of the distinct features of a\nhuman face. Traditionally, face models were built using a set of fiducial\npoints or landmarks, each point ideally located on a facial feature, i.e.,\ncorner of the eye, tip of the nose, etc. Face alignment is the process of\nfitting the landmarks in a face model to the respective ground truth positions\nin an input image containing a face. Despite significant research on face\nalignment in the past decades, no review analyses various face models used in\nthe literature. Catering to three types of readers - beginners, practitioners\nand researchers in face alignment, we provide a comprehensive analysis of\ndifferent face models used for face alignment. We include the interpretation\nand training of the face models along with the examples of fitting the face\nmodel to a new face image. We found that 3D-based face models are preferred in\ncases of extreme face pose, whereas deep learning-based methods often use\nheatmaps. Moreover, we discuss the possible future directions of face models in\nthe field of face alignment.",
            "author": [
                "Jagmohan Meher",
                "Hector Allende-Cid",
                "Torbj\u00f6rn E. M. Nordling"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03082v1",
                "http://arxiv.org/pdf/2311.03082v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03076v2",
            "title": "SugarViT -- Multi-objective Regression of UAV Images with Vision\n  Transformers and Deep Label Distribution Learning Demonstrated on Disease\n  Severity Prediction in Sugar Beet",
            "updated": "2023-11-07T08:43:19Z",
            "published": "2023-11-06T13:01:17Z",
            "summary": "Remote sensing and artificial intelligence are pivotal technologies of\nprecision agriculture nowadays. The efficient retrieval of large-scale field\nimagery combined with machine learning techniques shows success in various\ntasks like phenotyping, weeding, cropping, and disease control. This work will\nintroduce a machine learning framework for automatized large-scale\nplant-specific trait annotation for the use case disease severity scoring for\nCercospora Leaf Spot (CLS) in sugar beet. With concepts of Deep Label\nDistribution Learning (DLDL), special loss functions, and a tailored model\narchitecture, we develop an efficient Vision Transformer based model for\ndisease severity scoring called SugarViT. One novelty in this work is the\ncombination of remote sensing data with environmental parameters of the\nexperimental sites for disease severity prediction. Although the model is\nevaluated on this special use case, it is held as generic as possible to also\nbe applicable to various image-based classification and regression tasks. With\nour framework, it is even possible to learn models on multi-objective problems\nas we show by a pretraining on environmental metadata.",
            "author": [
                "Maurice G\u00fcnder",
                "Facundo Ram\u00f3n Ispizua Yamati",
                "Abel Andree Barreto Alc\u00e1ntara",
                "Anne-Katrin Mahlein",
                "Rafet Sifa",
                "Christian Bauckhage"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03076v2",
                "http://arxiv.org/pdf/2311.03076v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03075v1",
            "title": "SoK: Memorisation in machine learning",
            "updated": "2023-11-06T12:59:18Z",
            "published": "2023-11-06T12:59:18Z",
            "summary": "Quantifying the impact of individual data samples on machine learning models\nis an open research problem. This is particularly relevant when complex and\nhigh-dimensional relationships have to be learned from a limited sample of the\ndata generating distribution, such as in deep learning. It was previously shown\nthat, in these cases, models rely not only on extracting patterns which are\nhelpful for generalisation, but also seem to be required to incorporate some of\nthe training data more or less as is, in a process often termed memorisation.\nThis raises the question: if some memorisation is a requirement for effective\nlearning, what are its privacy implications? In this work we unify a broad\nrange of previous definitions and perspectives on memorisation in ML, discuss\ntheir interplay with model generalisation and their implications of these\nphenomena on data privacy. Moreover, we systematise methods allowing\npractitioners to detect the occurrence of memorisation or quantify it and\ncontextualise our findings in a broad range of ML learning settings. Finally,\nwe discuss memorisation in the context of privacy attacks, differential privacy\n(DP) and adversarial actors.",
            "author": [
                "Dmitrii Usynin",
                "Moritz Knolle",
                "Georgios Kaissis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03075v1",
                "http://arxiv.org/pdf/2311.03075v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03074v1",
            "title": "A Two-Stage Generative Model with CycleGAN and Joint Diffusion for\n  MRI-based Brain Tumor Detection",
            "updated": "2023-11-06T12:58:26Z",
            "published": "2023-11-06T12:58:26Z",
            "summary": "Accurate detection and segmentation of brain tumors is critical for medical\ndiagnosis. However, current supervised learning methods require extensively\nannotated images and the state-of-the-art generative models used in\nunsupervised methods often have limitations in covering the whole data\ndistribution. In this paper, we propose a novel framework Two-Stage Generative\nModel (TSGM) that combines Cycle Generative Adversarial Network (CycleGAN) and\nVariance Exploding stochastic differential equation using joint probability\n(VE-JP) to improve brain tumor detection and segmentation. The CycleGAN is\ntrained on unpaired data to generate abnormal images from healthy images as\ndata prior. Then VE-JP is implemented to reconstruct healthy images using\nsynthetic paired abnormal images as a guide, which alters only pathological\nregions but not regions of healthy. Notably, our method directly learned the\njoint probability distribution for conditional generation. The residual between\ninput and reconstructed images suggests the abnormalities and a thresholding\nmethod is subsequently applied to obtain segmentation results. Furthermore, the\nmultimodal results are weighted with different weights to improve the\nsegmentation accuracy further. We validated our method on three datasets, and\ncompared with other unsupervised methods for anomaly detection and\nsegmentation. The DSC score of 0.8590 in BraTs2020 dataset, 0.6226 in ITCS\ndataset and 0.7403 in In-house dataset show that our method achieves better\nsegmentation performance and has better generalization.",
            "author": [
                "Wenxin Wang",
                "Zhuo-Xu Cui",
                "Guanxun Cheng",
                "Chentao Cao",
                "Xi Xu",
                "Ziwei Liu",
                "Haifeng Wang",
                "Yulong Qi",
                "Dong Liang",
                "Yanjie Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03074v1",
                "http://arxiv.org/pdf/2311.03074v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03067v1",
            "title": "Forest aboveground biomass estimation using GEDI and earth observation\n  data through attention-based deep learning",
            "updated": "2023-11-06T12:51:01Z",
            "published": "2023-11-06T12:51:01Z",
            "summary": "Accurate quantification of forest aboveground biomass (AGB) is critical for\nunderstanding carbon accounting in the context of climate change. In this\nstudy, we presented a novel attention-based deep learning approach for forest\nAGB estimation, primarily utilizing openly accessible EO data, including: GEDI\nLiDAR data, C-band Sentinel-1 SAR data, ALOS-2 PALSAR-2 data, and Sentinel-2\nmultispectral data. The attention UNet (AU) model achieved markedly higher\naccuracy for biomass estimation compared to the conventional RF algorithm.\nSpecifically, the AU model attained an R2 of 0.66, RMSE of 43.66 Mg ha-1, and\nbias of 0.14 Mg ha-1, while RF resulted in lower scores of R2 0.62, RMSE 45.87\nMg ha-1, and bias 1.09 Mg ha-1. However, the superiority of the deep learning\napproach was not uniformly observed across all tested models. ResNet101 only\nachieved an R2 of 0.50, an RMSE of 52.93 Mg ha-1, and a bias of 0.99 Mg ha-1,\nwhile the UNet reported an R2 of 0.65, an RMSE of 44.28 Mg ha-1, and a\nsubstantial bias of 1.84 Mg ha-1. Moreover, to explore the performance of AU in\nthe absence of spatial information, fully connected (FC) layers were employed\nto eliminate spatial information from the remote sensing data. AU-FC achieved\nintermediate R2 of 0.64, RMSE of 44.92 Mgha-1, and bias of -0.56 Mg ha-1,\noutperforming RF but underperforming AU model using spatial information. We\nalso generated 10m forest AGB maps across Guangdong for the year 2019 using AU\nand compared it with that produced by RF. The AGB distributions from both\nmodels showed strong agreement with similar mean values; the mean forest AGB\nestimated by AU was 102.18 Mg ha-1 while that of RF was 104.84 Mg ha-1.\nAdditionally, it was observed that the AGB map generated by AU provided\nsuperior spatial information. Overall, this research substantiates the\nfeasibility of employing deep learning for biomass estimation based on\nsatellite data.",
            "author": [
                "Wenquan Dong",
                "Edward T. A. Mitchard",
                "Hao Yu",
                "Steven Hancock",
                "Casey M. Ryan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03067v1",
                "http://arxiv.org/pdf/2311.03067v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03062v2",
            "title": "Imaging through multimode fibres with physical prior",
            "updated": "2023-11-14T02:00:20Z",
            "published": "2023-11-06T12:46:29Z",
            "summary": "Imaging through perturbed multimode fibres based on deep learning has been\nwidely researched. However, existing methods mainly use target-speckle pairs in\ndifferent configurations. It is challenging to reconstruct targets without\ntrained networks. In this paper, we propose a physics-assisted, unsupervised,\nlearning-based fibre imaging scheme. The role of the physical prior is to\nsimplify the mapping relationship between the speckle pattern and the target\nimage, thereby reducing the computational complexity. The unsupervised network\nlearns target features according to the optimized direction provided by the\nphysical prior. Therefore, the reconstruction process of the online learning\nonly requires a few speckle patterns and unpaired targets. The proposed scheme\nalso increases the generalization ability of the learning-based method in\nperturbed multimode fibres. Our scheme has the potential to extend the\napplication of multimode fibre imaging.",
            "author": [
                "Chuncheng Zhang",
                "Yingjie Shi",
                "Zheyi Yao",
                "Xiubao Sui",
                "Qian Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03062v2",
                "http://arxiv.org/pdf/2311.03062v2"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04236v1",
            "title": "Distributed Agent-Based Collaborative Learning in Cross-Individual\n  Wearable Sensor-Based Human Activity Recognition",
            "updated": "2023-11-06T12:45:45Z",
            "published": "2023-11-06T12:45:45Z",
            "summary": "The rapid growth of wearable sensor technologies holds substantial promise\nfor the field of personalized and context-aware Human Activity Recognition.\nGiven the inherently decentralized nature of data sources within this domain,\nthe utilization of multi-agent systems with their inherent decentralization\ncapabilities presents an opportunity to facilitate the development of scalable,\nadaptable, and privacy-conscious methodologies. This paper introduces a\ncollaborative distributed learning approach rooted in multi-agent principles,\nwherein individual users of sensor-equipped devices function as agents within a\ndistributed network, collectively contributing to the comprehensive process of\nlearning and classifying human activities. In this proposed methodology, not\nonly is the privacy of activity monitoring data upheld for each individual,\neliminating the need for an external server to oversee the learning process,\nbut the system also exhibits the potential to surmount the limitations of\nconventional centralized models and adapt to the unique attributes of each\nuser. The proposed approach has been empirically tested on two publicly\naccessible human activity recognition datasets, specifically PAMAP2 and HARTH,\nacross varying settings. The provided empirical results conclusively highlight\nthe efficacy of inter-individual collaborative learning when contrasted with\ncentralized configurations, both in terms of local and global generalization.",
            "author": [
                "Ahmad Esmaeili",
                "Zahra Ghorrati",
                "Eric T. Matson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04236v1",
                "http://arxiv.org/pdf/2311.04236v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.AI",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03061v1",
            "title": "Learned layered coding for Successive Refinement in the Wyner-Ziv\n  Problem",
            "updated": "2023-11-06T12:45:32Z",
            "published": "2023-11-06T12:45:32Z",
            "summary": "We propose a data-driven approach to explicitly learn the progressive\nencoding of a continuous source, which is successively decoded with increasing\nlevels of quality and with the aid of correlated side information. This setup\nrefers to the successive refinement of the Wyner-Ziv coding problem. Assuming\nideal Slepian-Wolf coding, our approach employs recurrent neural networks\n(RNNs) to learn layered encoders and decoders for the quadratic Gaussian case.\nThe models are trained by minimizing a variational bound on the rate-distortion\nfunction of the successively refined Wyner-Ziv coding problem. We demonstrate\nthat RNNs can explicitly retrieve layered binning solutions akin to scalable\nnested quantization. Moreover, the rate-distortion performance of the scheme is\non par with the corresponding monolithic Wyner-Ziv coding approach and is close\nto the rate-distortion bound.",
            "author": [
                "Boris Joukovsky",
                "Brent De Weerdt",
                "Nikos Deligiannis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03061v1",
                "http://arxiv.org/pdf/2311.03061v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03057v1",
            "title": "GLEN: Generative Retrieval via Lexical Index Learning",
            "updated": "2023-11-06T12:35:06Z",
            "published": "2023-11-06T12:35:06Z",
            "summary": "Generative retrieval shed light on a new paradigm of document retrieval,\naiming to directly generate the identifier of a relevant document for a query.\nWhile it takes advantage of bypassing the construction of auxiliary index\nstructures, existing studies face two significant challenges: (i) the\ndiscrepancy between the knowledge of pre-trained language models and\nidentifiers and (ii) the gap between training and inference that poses\ndifficulty in learning to rank. To overcome these challenges, we propose a\nnovel generative retrieval method, namely Generative retrieval via LExical\niNdex learning (GLEN). For training, GLEN effectively exploits a dynamic\nlexical identifier using a two-phase index learning strategy, enabling it to\nlearn meaningful lexical identifiers and relevance signals between queries and\ndocuments. For inference, GLEN utilizes collision-free inference, using\nidentifier weights to rank documents without additional overhead. Experimental\nresults prove that GLEN achieves state-of-the-art or competitive performance\nagainst existing generative retrieval methods on various benchmark datasets,\ne.g., NQ320k, MS MARCO, and BEIR. The code is available at\nhttps://github.com/skleee/GLEN.",
            "author": [
                "Sunkyung Lee",
                "Minjin Choi",
                "Jongwuk Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03057v1",
                "http://arxiv.org/pdf/2311.03057v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03419v1",
            "title": "Personalizing Keyword Spotting with Speaker Information",
            "updated": "2023-11-06T12:16:06Z",
            "published": "2023-11-06T12:16:06Z",
            "summary": "Keyword spotting systems often struggle to generalize to a diverse population\nwith various accents and age groups. To address this challenge, we propose a\nnovel approach that integrates speaker information into keyword spotting using\nFeature-wise Linear Modulation (FiLM), a recent method for learning from\nmultiple sources of information. We explore both Text-Dependent and\nText-Independent speaker recognition systems to extract speaker information,\nand we experiment on extracting this information from both the input audio and\npre-enrolled user audio. We evaluate our systems on a diverse dataset and\nachieve a substantial improvement in keyword detection accuracy, particularly\namong underrepresented speaker groups. Moreover, our proposed approach only\nrequires a small 1% increase in the number of parameters, with a minimum impact\non latency and computational cost, which makes it a practical solution for\nreal-world applications.",
            "author": [
                "Beltr\u00e1n Labrador",
                "Pai Zhu",
                "Guanlong Zhao",
                "Angelo Scorza Scarpati",
                "Quan Wang",
                "Alicia Lozano-Diez",
                "Alex Park",
                "Ignacio L\u00f3pez Moreno"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03419v1",
                "http://arxiv.org/pdf/2311.03419v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.LG",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03055v1",
            "title": "DRAUC: An Instance-wise Distributionally Robust AUC Optimization\n  Framework",
            "updated": "2023-11-06T12:15:57Z",
            "published": "2023-11-06T12:15:57Z",
            "summary": "The Area Under the ROC Curve (AUC) is a widely employed metric in long-tailed\nclassification scenarios. Nevertheless, most existing methods primarily assume\nthat training and testing examples are drawn i.i.d. from the same distribution,\nwhich is often unachievable in practice. Distributionally Robust Optimization\n(DRO) enhances model performance by optimizing it for the local worst-case\nscenario, but directly integrating AUC optimization with DRO results in an\nintractable optimization problem. To tackle this challenge, methodically we\npropose an instance-wise surrogate loss of Distributionally Robust AUC (DRAUC)\nand build our optimization framework on top of it. Moreover, we highlight that\nconventional DRAUC may induce label bias, hence introducing distribution-aware\nDRAUC as a more suitable metric for robust AUC learning. Theoretically, we\naffirm that the generalization gap between the training loss and testing error\ndiminishes if the training set is sufficiently large. Empirically, experiments\non corrupted benchmark datasets demonstrate the effectiveness of our proposed\nmethod. Code is available at: https://github.com/EldercatSAM/DRAUC.",
            "author": [
                "Siran Dai",
                "Qianqian Xu",
                "Zhiyong Yang",
                "Xiaochun Cao",
                "Qingming Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03055v1",
                "http://arxiv.org/pdf/2311.03055v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03052v1",
            "title": "MixUp-MIL: A Study on Linear & Multilinear Interpolation-Based Data\n  Augmentation for Whole Slide Image Classification",
            "updated": "2023-11-06T12:00:53Z",
            "published": "2023-11-06T12:00:53Z",
            "summary": "For classifying digital whole slide images in the absence of pixel level\nannotation, typically multiple instance learning methods are applied. Due to\nthe generic applicability, such methods are currently of very high interest in\nthe research community, however, the issue of data augmentation in this context\nis rarely explored. Here we investigate linear and multilinear interpolation\nbetween feature vectors, a data augmentation technique, which proved to be\ncapable of improving the generalization performance classification networks and\nalso for multiple instance learning. Experiments, however, have been performed\non only two rather small data sets and one specific feature extraction approach\nso far and a strong dependence on the data set has been identified. Here we\nconduct a large study incorporating 10 different data set configurations, two\ndifferent feature extraction approaches (supervised and self-supervised), stain\nnormalization and two multiple instance learning architectures. The results\nshowed an extraordinarily high variability in the effect of the method. We\nidentified several interesting aspects to bring light into the darkness and\nidentified novel promising fields of research.",
            "author": [
                "Michael Gadermayr",
                "Lukas Koller",
                "Maximilian Tschuchnig",
                "Lea Maria Stangassinger",
                "Christina Kreutzer",
                "Sebastien Couillard-Despres",
                "Gertie Janneke Oostingh",
                "Anton Hittmair"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03052v1",
                "http://arxiv.org/pdf/2311.03052v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03044v1",
            "title": "Reinforcement Learning for Inverse Linear-quadratic Dynamic\n  Non-cooperative Games",
            "updated": "2023-11-06T11:40:07Z",
            "published": "2023-11-06T11:40:07Z",
            "summary": "In this paper, we address the inverse problem in the case of linear-quadratic\ndiscrete-time dynamic non-cooperative games. Given feedback laws of players\nthat are known to be a Nash equilibrium pair for a discrete-time linear system,\nwe want find cost function parameters for which the observed feedback laws are\noptimal and stabilizing. Using the given feedback laws, we introduce a\nmodel-based algorithm that generates cost function parameters solving the\nproblem. We provide theoretical results that guarantee the convergence and\nstability of the algorithm as well as the way to generate new games with\nnecessary properties without requiring to run the complete algorithm repeatedly\n. Then the algorithm is extended to a model-free version that uses data samples\ngenerated by unknown dynamics and has the same properties as the model-based\nversion. Simulation results validate the effectiveness of the proposed\nalgorithms.",
            "author": [
                "Emin Martirosyan",
                "Ming Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03044v1",
                "http://arxiv.org/pdf/2311.03044v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03040v1",
            "title": "Grouping Local Process Models",
            "updated": "2023-11-06T11:24:27Z",
            "published": "2023-11-06T11:24:27Z",
            "summary": "In recent years, process mining emerged as a proven technology to analyze and\nimprove operational processes. An expanding range of organizations using\nprocess mining in their daily operation brings a broader spectrum of processes\nto be analyzed. Some of these processes are highly unstructured, making it\ndifficult for traditional process discovery approaches to discover a\nstart-to-end model describing the entire process. Therefore, the subdiscipline\nof Local Process Model (LPM) discovery tries to build a set of LPMs, i.e.,\nsmaller models that explain sub-behaviors of the process. However, like other\npattern mining approaches, LPM discovery algorithms also face the problems of\nmodel explosion and model repetition, i.e., the algorithms may create hundreds\nif not thousands of models, and subsets of them are close in structure or\nbehavior. This work proposes a three-step pipeline for grouping similar LPMs\nusing various process model similarity measures. We demonstrate the usefulness\nof grouping through a real-life case study, and analyze the impact of different\nmeasures, the gravity of repetition in the discovered LPMs, and how it improves\nafter grouping on multiple real event logs.",
            "author": [
                "Viki Peeva",
                "Wil M. P. van der Aalst"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03040v1",
                "http://arxiv.org/pdf/2311.03040v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "I.5.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03037v1",
            "title": "Validity problems in clinical machine learning by indirect data labeling\n  using consensus definitions",
            "updated": "2023-11-06T11:14:48Z",
            "published": "2023-11-06T11:14:48Z",
            "summary": "We demonstrate a validity problem of machine learning in the vital\napplication area of disease diagnosis in medicine. It arises when target labels\nin training data are determined by an indirect measurement, and the fundamental\nmeasurements needed to determine this indirect measurement are included in the\ninput data representation. Machine learning models trained on this data will\nlearn nothing else but to exactly reconstruct the known target definition. Such\nmodels show perfect performance on similarly constructed test data but will\nfail catastrophically on real-world examples where the defining fundamental\nmeasurements are not or only incompletely available. We present a general\nprocedure allowing identification of problematic datasets and black-box machine\nlearning models trained on them, and exemplify our detection procedure on the\ntask of early prediction of sepsis.",
            "author": [
                "Michael Hagmann",
                "Shigehiko Schamoni",
                "Stefan Riezler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03037v1",
                "http://arxiv.org/pdf/2311.03037v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.QM",
                "stat.AP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03036v1",
            "title": "On regularized polynomial functional regression",
            "updated": "2023-11-06T11:14:36Z",
            "published": "2023-11-06T11:14:36Z",
            "summary": "This article offers a comprehensive treatment of polynomial functional\nregression, culminating in the establishment of a novel finite sample bound.\nThis bound encompasses various aspects, including general smoothness\nconditions, capacity conditions, and regularization techniques. In doing so, it\nextends and generalizes several findings from the context of linear functional\nregression as well. We also provide numerical evidence that using higher order\npolynomial terms can lead to an improved performance.",
            "author": [
                "Markus Holzleitner",
                "Sergei Pereverzyev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03036v1",
                "http://arxiv.org/pdf/2311.03036v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.LG",
                "cs.NA",
                "math.ST",
                "stat.TH",
                "65K10, 62G20, 62J05"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03033v1",
            "title": "Beyond Words: A Mathematical Framework for Interpreting Large Language\n  Models",
            "updated": "2023-11-06T11:13:17Z",
            "published": "2023-11-06T11:13:17Z",
            "summary": "Large language models (LLMs) are powerful AI tools that can generate and\ncomprehend natural language text and other complex information. However, the\nfield lacks a mathematical framework to systematically describe, compare and\nimprove LLMs. We propose Hex a framework that clarifies key terms and concepts\nin LLM research, such as hallucinations, alignment, self-verification and\nchain-of-thought reasoning. The Hex framework offers a precise and consistent\nway to characterize LLMs, identify their strengths and weaknesses, and\nintegrate new findings. Using Hex, we differentiate chain-of-thought reasoning\nfrom chain-of-thought prompting and establish the conditions under which they\nare equivalent. This distinction clarifies the basic assumptions behind\nchain-of-thought prompting and its implications for methods that use it, such\nas self-verification and prompt programming.\n  Our goal is to provide a formal framework for LLMs that can help both\nresearchers and practitioners explore new possibilities for generative AI. We\ndo not claim to have a definitive solution, but rather a tool for opening up\nnew research avenues. We argue that our formal definitions and results are\ncrucial for advancing the discussion on how to build generative AI systems that\nare safe, reliable, fair and robust, especially in domains like healthcare and\nsoftware engineering.",
            "author": [
                "Javier Gonz\u00e1lez",
                "Aditya V. Nori"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03033v1",
                "http://arxiv.org/pdf/2311.03033v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03024v1",
            "title": "Non Deterministic Pseudorandom Generator for Quantum Key Distribution",
            "updated": "2023-11-06T11:03:03Z",
            "published": "2023-11-06T11:03:03Z",
            "summary": "Quantum Key Distribution(QKD) thrives to achieve perfect secrecy of One time\nPad (OTP) through quantum processes. One of the crucial components of QKD are\nQuantum Random Number Generators(QRNG) for generation of keys. Unfortunately,\nthese QRNG does not immediately produce usable bits rather it produces raw bits\nwith high entropy but low uniformity which can be hardly used by any\ncryptographic system. A lot of pre-processing is required before the random\nnumbers generated by QRNG to be usable. This causes a bottle neck in random\nnumber generation rate as well as QKD system relying on it. To avoid this\nlacuna of post-processing methods employed as a central part of Quantum Random\nNumber Generators alternative approaches that satisfy the entropy(non\ndeterminism) and quantum security is explored. Pseudorandom generators based on\nquantum secure primitives could be an alternative to the post-processing\nproblem as PRNGs are way more faster than any random number generator employing\nphysical randomness (quantum mechanical process in QRNG) as well as it can\nprovide uniform bits required for cryptography application. In this work we\npropose a pseudorandom generator based on post quantum primitives. The central\ntheme of this random number generator is designing PRNG with non deterministic\nentropy generated through hard lattice problem - Learning with errors. We\nleverage the non determinism by Gaussian errors of LWE to construct\nnon-deterministic PRNG satisfying the entropy requirement of QKD. Further, the\npaper concludes by evaluating the PRNG through Die-Harder Test.",
            "author": [
                "Arun Mishra",
                "Kanaka Raju Pandiri",
                "Anupama Arjun Pandit",
                "Lucy Sharma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03024v1",
                "http://arxiv.org/pdf/2311.03024v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03002v1",
            "title": "Estimating treatment effects from single-arm trials via latent-variable\n  modeling",
            "updated": "2023-11-06T10:12:54Z",
            "published": "2023-11-06T10:12:54Z",
            "summary": "Randomized controlled trials (RCTs) are the accepted standard for treatment\neffect estimation but they can be infeasible due to ethical reasons and\nprohibitive costs. Single-arm trials, where all patients belong to the\ntreatment group, can be a viable alternative but require access to an external\ncontrol group. We propose an identifiable deep latent-variable model for this\nscenario that can also account for missing covariate observations by modeling\ntheir structured missingness patterns. Our method uses amortized variational\ninference to learn both group-specific and identifiable shared latent\nrepresentations, which can subsequently be used for (i) patient matching if\ntreatment outcomes are not available for the treatment group, or for (ii)\ndirect treatment effect estimation assuming outcomes are available for both\ngroups. We evaluate the model on a public benchmark as well as on a data set\nconsisting of a published RCT study and real-world electronic health records.\nCompared to previous methods, our results show improved performance both for\ndirect treatment effect estimation as well as for effect estimation via patient\nmatching.",
            "author": [
                "Manuel Haussmann",
                "Tran Minh Son Le",
                "Viivi Halla-aho",
                "Samu Kurki",
                "Jussi Leinonen",
                "Miika Koskinen",
                "Samuel Kaski",
                "Harri L\u00e4hdesm\u00e4ki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03002v1",
                "http://arxiv.org/pdf/2311.03002v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03001v1",
            "title": "Variational Weighting for Kernel Density Ratios",
            "updated": "2023-11-06T10:12:19Z",
            "published": "2023-11-06T10:12:19Z",
            "summary": "Kernel density estimation (KDE) is integral to a range of generative and\ndiscriminative tasks in machine learning. Drawing upon tools from the\nmultidimensional calculus of variations, we derive an optimal weight function\nthat reduces bias in standard kernel density estimates for density ratios,\nleading to improved estimates of prediction posteriors and\ninformation-theoretic measures. In the process, we shed light on some\nfundamental aspects of density estimation, particularly from the perspective of\nalgorithms that employ KDEs as their main building blocks.",
            "author": [
                "Sangwoong Yoon",
                "Frank C. Park",
                "Gunsu S Yun",
                "Iljung Kim",
                "Yung-Kyun Noh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03001v1",
                "http://arxiv.org/pdf/2311.03001v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03417v1",
            "title": "Federated Learning for Clinical Structured Data: A Benchmark Comparison\n  of Engineering and Statistical Approaches",
            "updated": "2023-11-06T10:11:59Z",
            "published": "2023-11-06T10:11:59Z",
            "summary": "Federated learning (FL) has shown promising potential in safeguarding data\nprivacy in healthcare collaborations. While the term \"FL\" was originally coined\nby the engineering community, the statistical field has also explored similar\nprivacy-preserving algorithms. Statistical FL algorithms, however, remain\nconsiderably less recognized than their engineering counterparts. Our goal was\nto bridge the gap by presenting the first comprehensive comparison of FL\nframeworks from both engineering and statistical domains. We evaluated five FL\nframeworks using both simulated and real-world data. The results indicate that\nstatistical FL algorithms yield less biased point estimates for model\ncoefficients and offer convenient confidence interval estimations. In contrast,\nengineering-based methods tend to generate more accurate predictions, sometimes\nsurpassing central pooled and statistical FL models. This study underscores the\nrelative strengths and weaknesses of both types of methods, emphasizing the\nneed for increased awareness and their integration in future FL applications.",
            "author": [
                "Siqi Li",
                "Di Miao",
                "Qiming Wu",
                "Chuan Hong",
                "Danny D'Agostino",
                "Xin Li",
                "Yilin Ning",
                "Yuqing Shang",
                "Huazhu Fu",
                "Marcus Eng Hock Ong",
                "Hamed Haddadi",
                "Nan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03417v1",
                "http://arxiv.org/pdf/2311.03417v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03000v1",
            "title": "Strong statistical parity through fair synthetic data",
            "updated": "2023-11-06T10:06:30Z",
            "published": "2023-11-06T10:06:30Z",
            "summary": "AI-generated synthetic data, in addition to protecting the privacy of\noriginal data sets, allows users and data consumers to tailor data to their\nneeds. This paper explores the creation of synthetic data that embodies\nFairness by Design, focusing on the statistical parity fairness definition. By\nequalizing the learned target probability distributions of the synthetic data\ngenerator across sensitive attributes, a downstream model trained on such\nsynthetic data provides fair predictions across all thresholds, that is, strong\nfair predictions even when inferring from biased, original data. This fairness\nadjustment can be either directly integrated into the sampling process of a\nsynthetic generator or added as a post-processing step. The flexibility allows\ndata consumers to create fair synthetic data and fine-tune the trade-off\nbetween accuracy and fairness without any previous assumptions on the data or\nre-training the synthetic data generator.",
            "author": [
                "Ivona Krchova",
                "Michael Platzer",
                "Paul Tiwald"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03000v1",
                "http://arxiv.org/pdf/2311.03000v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.05645v1",
            "title": "EControl: Fast Distributed Optimization with Compression and Error\n  Control",
            "updated": "2023-11-06T10:00:13Z",
            "published": "2023-11-06T10:00:13Z",
            "summary": "Modern distributed training relies heavily on communication compression to\nreduce the communication overhead. In this work, we study algorithms employing\na popular class of contractive compressors in order to reduce communication\noverhead. However, the naive implementation often leads to unstable convergence\nor even exponential divergence due to the compression bias. Error Compensation\n(EC) is an extremely popular mechanism to mitigate the aforementioned issues\nduring the training of models enhanced by contractive compression operators.\nCompared to the effectiveness of EC in the data homogeneous regime, the\nunderstanding of the practicality and theoretical foundations of EC in the data\nheterogeneous regime is limited. Existing convergence analyses typically rely\non strong assumptions such as bounded gradients, bounded data heterogeneity, or\nlarge batch accesses, which are often infeasible in modern machine learning\napplications. We resolve the majority of current issues by proposing EControl,\na novel mechanism that can regulate error compensation by controlling the\nstrength of the feedback signal. We prove fast convergence for EControl in\nstandard strongly convex, general convex, and nonconvex settings without any\nadditional assumptions on the problem or data heterogeneity. We conduct\nextensive numerical evaluations to illustrate the efficacy of our method and\nsupport our theoretical findings.",
            "author": [
                "Yuan Gao",
                "Rustem Islamov",
                "Sebastian Stich"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05645v1",
                "http://arxiv.org/pdf/2311.05645v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02996v1",
            "title": "Visual-information-driven model for crowd simulation using temporal\n  convolutional network",
            "updated": "2023-11-06T09:58:04Z",
            "published": "2023-11-06T09:58:04Z",
            "summary": "Crowd simulations play a pivotal role in building design, influencing both\nuser experience and public safety. While traditional knowledge-driven models\nhave their merits, data-driven crowd simulation models promise to bring a new\ndimension of realism to these simulations. However, most of the existing\ndata-driven models are designed for specific geometries, leading to poor\nadaptability and applicability. A promising strategy for enhancing the\nadaptability and realism of data-driven crowd simulation models is to\nincorporate visual information, including the scenario geometry and pedestrian\nlocomotion. Consequently, this paper proposes a novel visual-information-driven\n(VID) crowd simulation model. The VID model predicts the pedestrian velocity at\nthe next time step based on the prior social-visual information and motion data\nof an individual. A radar-geometry-locomotion method is established to extract\nthe visual information of pedestrians. Moreover, a temporal convolutional\nnetwork (TCN)-based deep learning model, named social-visual TCN, is developed\nfor velocity prediction. The VID model is tested on three public pedestrian\nmotion datasets with distinct geometries, i.e., corridor, corner, and\nT-junction. Both qualitative and quantitative metrics are employed to evaluate\nthe VID model, and the results highlight the improved adaptability of the model\nacross all three geometric scenarios. Overall, the proposed method demonstrates\neffectiveness in enhancing the adaptability of data-driven crowd models.",
            "author": [
                "Xuanwen Liang",
                "Eric Wai Ming Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02996v1",
                "http://arxiv.org/pdf/2311.02996v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02995v1",
            "title": "Zero-Shot Enhancement of Low-Light Image Based on Retinex Decomposition",
            "updated": "2023-11-06T09:57:48Z",
            "published": "2023-11-06T09:57:48Z",
            "summary": "Two difficulties here make low-light image enhancement a challenging task;\nfirstly, it needs to consider not only luminance restoration but also image\ncontrast, image denoising and color distortion issues simultaneously. Second,\nthe effectiveness of existing low-light enhancement methods depends on paired\nor unpaired training data with poor generalization performance.\n  To solve these difficult problems, we propose in this paper a new\nlearning-based Retinex decomposition of zero-shot low-light enhancement method,\ncalled ZERRINNet. To this end, we first designed the N-Net network, together\nwith the noise loss term, to be used for denoising the original low-light image\nby estimating the noise of the low-light image. Moreover, RI-Net is used to\nestimate the reflection component and illumination component, and in order to\nsolve the color distortion and contrast, we use the texture loss term and\nsegmented smoothing loss to constrain the reflection component and illumination\ncomponent. Finally, our method is a zero-reference enhancement method that is\nnot affected by the training data of paired and unpaired datasets, so our\ngeneralization performance is greatly improved, and in the paper, we have\neffectively validated it with a homemade real-life low-light dataset and\nadditionally with advanced vision tasks, such as face detection, target\nrecognition, and instance segmentation. We conducted comparative experiments on\na large number of public datasets and the results show that the performance of\nour method is competitive compared to the current state-of-the-art methods. The\ncode is available at:https://github.com/liwenchao0615/ZERRINNet",
            "author": [
                "Wenchao Li",
                "Bangshu Xiong",
                "Qiaofeng Ou",
                "Xiaoyun Long",
                "Jinhao Zhu",
                "Jiabao Chen",
                "Shuyuan Wen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02995v1",
                "http://arxiv.org/pdf/2311.02995v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02991v1",
            "title": "Diffusion-based Radiotherapy Dose Prediction Guided by Inter-slice Aware\n  Structure Encoding",
            "updated": "2023-11-06T09:54:47Z",
            "published": "2023-11-06T09:54:47Z",
            "summary": "Deep learning (DL) has successfully automated dose distribution prediction in\nradiotherapy planning, enhancing both efficiency and quality. However, existing\nmethods suffer from the over-smoothing problem for their commonly used L1 or L2\nloss with posterior average calculations. To alleviate this limitation, we\npropose a diffusion model-based method (DiffDose) for predicting the\nradiotherapy dose distribution of cancer patients. Specifically, the DiffDose\nmodel contains a forward process and a reverse process. In the forward process,\nDiffDose transforms dose distribution maps into pure Gaussian noise by\ngradually adding small noise and a noise predictor is simultaneously trained to\nestimate the noise added at each timestep. In the reverse process, it removes\nthe noise from the pure Gaussian noise in multiple steps with the well-trained\nnoise predictor and finally outputs the predicted dose distribution maps...",
            "author": [
                "Zhenghao Feng",
                "Lu Wen",
                "Jianghong Xiao",
                "Yuanyuan Xu",
                "Xi Wu",
                "Jiliu Zhou",
                "Xingchen Peng",
                "Yan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02991v1",
                "http://arxiv.org/pdf/2311.02991v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02986v1",
            "title": "Hacking Cryptographic Protocols with Advanced Variational Quantum\n  Attacks",
            "updated": "2023-11-06T09:46:16Z",
            "published": "2023-11-06T09:46:16Z",
            "summary": "Here we introduce an improved approach to Variational Quantum Attack\nAlgorithms (VQAA) on crytographic protocols. Our methods provide robust quantum\nattacks to well-known cryptographic algorithms, more efficiently and with\nremarkably fewer qubits than previous approaches. We implement simulations of\nour attacks for symmetric-key protocols such as S-DES, S-AES and Blowfish. For\ninstance, we show how our attack allows a classical simulation of a small\n8-qubit quantum computer to find the secret key of one 32-bit Blowfish instance\nwith 24 times fewer number of iterations than a brute-force attack. Our work\nalso shows improvements in attack success rates for lightweight ciphers such as\nS-DES and S-AES. Further applications beyond symmetric-key cryptography are\nalso discussed, including asymmetric-key protocols and hash functions. In\naddition, we also comment on potential future improvements of our methods. Our\nresults bring one step closer assessing the vulnerability of large-size\nclassical cryptographic protocols with Noisy Intermediate-Scale Quantum (NISQ)\ndevices, and set the stage for future research in quantum cybersecurity.",
            "author": [
                "Borja Aizpurua",
                "Pablo Bermejo",
                "Josu Etxezarreta Martinez",
                "Roman Orus"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02986v1",
                "http://arxiv.org/pdf/2311.02986v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03415v1",
            "title": "PowerFlowNet: Leveraging Message Passing GNNs for Improved Power Flow\n  Approximation",
            "updated": "2023-11-06T09:44:00Z",
            "published": "2023-11-06T09:44:00Z",
            "summary": "Accurate and efficient power flow (PF) analysis is crucial in modern\nelectrical networks' efficient operation and planning. Therefore, there is a\nneed for scalable algorithms capable of handling large-scale power networks\nthat can provide accurate and fast solutions. Graph Neural Networks (GNNs) have\nemerged as a promising approach for enhancing the speed of PF approximations by\nleveraging their ability to capture distinctive features from the underlying\npower network graph. In this study, we introduce PowerFlowNet, a novel GNN\narchitecture for PF approximation that showcases similar performance with the\ntraditional Newton-Raphson method but achieves it 4 times faster in the simple\nIEEE 14-bus system and 145 times faster in the realistic case of the French\nhigh voltage network (6470rte). Meanwhile, it significantly outperforms other\ntraditional approximation methods, such as the DC relaxation method, in terms\nof performance and execution time; therefore, making PowerFlowNet a highly\npromising solution for real-world PF analysis. Furthermore, we verify the\nefficacy of our approach by conducting an in-depth experimental evaluation,\nthoroughly examining the performance, scalability, interpretability, and\narchitectural dependability of PowerFlowNet. The evaluation provides insights\ninto the behavior and potential applications of GNNs in power system analysis.",
            "author": [
                "Nan Lin",
                "Stavros Orfanoudakis",
                "Nathan Ordonez Cardenas",
                "Juan S. Giraldo",
                "Pedro P. Vergara"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03415v1",
                "http://arxiv.org/pdf/2311.03415v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03414v1",
            "title": "A Generative Neural Network Approach for 3D Multi-Criteria Design\n  Generation and Optimization of an Engine Mount for an Unmanned Air Vehicle",
            "updated": "2023-11-06T09:33:56Z",
            "published": "2023-11-06T09:33:56Z",
            "summary": "One of the most promising developments in computer vision in recent years is\nthe use of generative neural networks for functionality condition-based 3D\ndesign reconstruction and generation. Here, neural networks learn dependencies\nbetween functionalities and a geometry in a very effective way. For a neural\nnetwork the functionalities are translated in conditions to a certain geometry.\nBut the more conditions the design generation needs to reflect, the more\ndifficult it is to learn clear dependencies. This leads to a multi criteria\ndesign problem due various conditions, which are not considered in the neural\nnetwork structure so far.\n  In this paper, we address this multi-criteria challenge for a 3D design use\ncase related to an unmanned aerial vehicle (UAV) motor mount. We generate\n10,000 abstract 3D designs and subject them all to simulations for three\nphysical disciplines: mechanics, thermodynamics, and aerodynamics. Then, we\ntrain a Conditional Variational Autoencoder (CVAE) using the geometry and\ncorresponding multicriteria functional constraints as input. We use our trained\nCVAE as well as the Marching cubes algorithm to generate meshes for simulation\nbased evaluation. The results are then evaluated with the generated UAV\ndesigns. Subsequently, we demonstrate the ability to generate optimized designs\nunder self-defined functionality conditions using the trained neural network.",
            "author": [
                "Christoph Petroll",
                "Sebastian Eilermann",
                "Philipp Hoefer",
                "Oliver Niggemann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03414v1",
                "http://arxiv.org/pdf/2311.03414v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03413v1",
            "title": "Discret2Di -- Deep Learning based Discretization for Model-based\n  Diagnosis",
            "updated": "2023-11-06T09:17:57Z",
            "published": "2023-11-06T09:17:57Z",
            "summary": "Consistency-based diagnosis is an established approach to diagnose technical\napplications, but suffers from significant modeling efforts, especially for\ndynamic multi-modal time series. Machine learning seems to be an obvious\nsolution, which becomes less obvious when looking at details: Which notion of\nconsistency can be used? If logical calculi are still to be used, how can\ndynamic time series be transferred into the discrete world?\n  This paper presents the methodology Discret2Di for automated learning of\nlogical expressions for consistency-based diagnosis. While these logical\ncalculi have advantages by providing a clear notion of consistency, they have\nthe key problem of relying on a discretization of the dynamic system. The\nsolution presented combines machine learning from both the time series and the\nsymbolic domain to automate the learning of logical rules for consistency-based\ndiagnosis.",
            "author": [
                "Lukas Moddemann",
                "Henrik Sebastian Steude",
                "Alexander Diedrich",
                "Oliver Niggemann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03413v1",
                "http://arxiv.org/pdf/2311.03413v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02971v1",
            "title": "TabRepo: A Large Scale Repository of Tabular Model Evaluations and its\n  AutoML Applications",
            "updated": "2023-11-06T09:17:18Z",
            "published": "2023-11-06T09:17:18Z",
            "summary": "We introduce TabRepo, a new dataset of tabular model evaluations and\npredictions. TabRepo contains the predictions and metrics of 1206 models\nevaluated on 200 regression and classification datasets. We illustrate the\nbenefit of our datasets in multiple ways. First, we show that it allows to\nperform analysis such as comparing Hyperparameter Optimization against current\nAutoML systems while also considering ensembling at no cost by using\nprecomputed model predictions. Second, we show that our dataset can be readily\nleveraged to perform transfer-learning. In particular, we show that applying\nstandard transfer-learning techniques allows to outperform current\nstate-of-the-art tabular systems in accuracy, runtime and latency.",
            "author": [
                "David Salinas",
                "Nick Erickson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02971v1",
                "http://arxiv.org/pdf/2311.02971v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02967v1",
            "title": "Non-intrusive model combination for learning dynamical systems",
            "updated": "2023-11-06T09:11:23Z",
            "published": "2023-11-06T09:11:23Z",
            "summary": "In data-driven modelling of complex dynamic processes, it is often desirable\nto combine different classes of models to enhance performance. Examples include\ncoupled models of different fidelities, or hybrid models based on physical\nknowledge and data-driven strategies. A key limitation of the broad adoption of\nmodel combination in applications is intrusiveness: training combined models\ntypically requires significant modifications to the learning algorithm\nimplementations, which may often be already well-developed and optimized for\nindividual model spaces. In this work, we propose an iterative, non-intrusive\nmethodology to combine two model spaces to learn dynamics from data. We show\nthat this can be understood, at least in the linear setting, as finding the\noptimal solution in the direct sum of the two hypothesis spaces, while\nleveraging only the projection operators in each individual space. Hence, the\nproposed algorithm can be viewed as iterative projections, for which we can\nobtain estimates on its convergence properties. To highlight the extensive\napplicability of our framework, we conduct numerical experiments in various\nproblem settings, with particular emphasis on various hybrid models based on\nthe Koopman operator approach.",
            "author": [
                "Shiqi Wu",
                "Ludovic Chamoin",
                "Qianxiao Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02967v1",
                "http://arxiv.org/pdf/2311.02967v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02962v1",
            "title": "Retrieval-Augmented Code Generation for Universal Information Extraction",
            "updated": "2023-11-06T09:03:21Z",
            "published": "2023-11-06T09:03:21Z",
            "summary": "Information Extraction (IE) aims to extract structural knowledge (e.g.,\nentities, relations, events) from natural language texts, which brings\nchallenges to existing methods due to task-specific schemas and complex text\nexpressions. Code, as a typical kind of formalized language, is capable of\ndescribing structural knowledge under various schemas in a universal way. On\nthe other hand, Large Language Models (LLMs) trained on both codes and texts\nhave demonstrated powerful capabilities of transforming texts into codes, which\nprovides a feasible solution to IE tasks. Therefore, in this paper, we propose\na universal retrieval-augmented code generation framework based on LLMs, called\nCode4UIE, for IE tasks. Specifically, Code4UIE adopts Python classes to define\ntask-specific schemas of various structural knowledge in a universal way. By so\ndoing, extracting knowledge under these schemas can be transformed into\ngenerating codes that instantiate the predefined Python classes with the\ninformation in texts. To generate these codes more precisely, Code4UIE adopts\nthe in-context learning mechanism to instruct LLMs with examples. In order to\nobtain appropriate examples for different tasks, Code4UIE explores several\nexample retrieval strategies, which can retrieve examples semantically similar\nto the given texts. Extensive experiments on five representative IE tasks\nacross nine datasets demonstrate the effectiveness of the Code4UIE framework.",
            "author": [
                "Yucan Guo",
                "Zixuan Li",
                "Xiaolong Jin",
                "Yantao Liu",
                "Yutao Zeng",
                "Wenxuan Liu",
                "Xiang Li",
                "Pan Yang",
                "Long Bai",
                "Jiafeng Guo",
                "Xueqi Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02962v1",
                "http://arxiv.org/pdf/2311.02962v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02960v1",
            "title": "Understanding Deep Representation Learning via Layerwise Feature\n  Compression and Discrimination",
            "updated": "2023-11-06T09:00:38Z",
            "published": "2023-11-06T09:00:38Z",
            "summary": "Over the past decade, deep learning has proven to be a highly effective tool\nfor learning meaningful features from raw data. However, it remains an open\nquestion how deep networks perform hierarchical feature learning across layers.\nIn this work, we attempt to unveil this mystery by investigating the structures\nof intermediate features. Motivated by our empirical findings that linear\nlayers mimic the roles of deep layers in nonlinear networks for feature\nlearning, we explore how deep linear networks transform input data into output\nby investigating the output (i.e., features) of each layer after training in\nthe context of multi-class classification problems. Toward this goal, we first\ndefine metrics to measure within-class compression and between-class\ndiscrimination of intermediate features, respectively. Through theoretical\nanalysis of these two metrics, we show that the evolution of features follows a\nsimple and quantitative pattern from shallow to deep layers when the input data\nis nearly orthogonal and the network weights are minimum-norm, balanced, and\napproximate low-rank: Each layer of the linear network progressively compresses\nwithin-class features at a geometric rate and discriminates between-class\nfeatures at a linear rate with respect to the number of layers that data have\npassed through. To the best of our knowledge, this is the first quantitative\ncharacterization of feature evolution in hierarchical representations of deep\nlinear networks. Empirically, our extensive experiments not only validate our\ntheoretical results numerically but also reveal a similar pattern in deep\nnonlinear networks which aligns well with recent empirical studies. Moreover,\nwe demonstrate the practical implications of our results in transfer learning.\nOur code is available at \\url{https://github.com/Heimine/PNC_DLN}.",
            "author": [
                "Peng Wang",
                "Xiao Li",
                "Can Yaras",
                "Zhihui Zhu",
                "Laura Balzano",
                "Wei Hu",
                "Qing Qu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02960v1",
                "http://arxiv.org/pdf/2311.02960v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02956v1",
            "title": "In-Context Learning for Knowledge Base Question Answering for Unmanned\n  Systems based on Large Language Models",
            "updated": "2023-11-06T08:52:11Z",
            "published": "2023-11-06T08:52:11Z",
            "summary": "Knowledge Base Question Answering (KBQA) aims to answer factoid questions\nbased on knowledge bases. However, generating the most appropriate knowledge\nbase query code based on Natural Language Questions (NLQ) poses a significant\nchallenge in KBQA. In this work, we focus on the CCKS2023 Competition of\nQuestion Answering with Knowledge Graph Inference for Unmanned Systems.\nInspired by the recent success of large language models (LLMs) like ChatGPT and\nGPT-3 in many QA tasks, we propose a ChatGPT-based Cypher Query Language (CQL)\ngeneration framework to generate the most appropriate CQL based on the given\nNLQ. Our generative framework contains six parts: an auxiliary model predicting\nthe syntax-related information of CQL based on the given NLQ, a proper noun\nmatcher extracting proper nouns from the given NLQ, a demonstration example\nselector retrieving similar examples of the input sample, a prompt constructor\ndesigning the input template of ChatGPT, a ChatGPT-based generation model\ngenerating the CQL, and an ensemble model to obtain the final answers from\ndiversified outputs. With our ChatGPT-based CQL generation framework, we\nachieved the second place in the CCKS 2023 Question Answering with Knowledge\nGraph Inference for Unmanned Systems competition, achieving an F1-score of\n0.92676.",
            "author": [
                "Yunlong Chen",
                "Yaming Zhang",
                "Jianfei Yu",
                "Li Yang",
                "Rui Xia"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-981-99-7224-1_26",
                "http://arxiv.org/abs/2311.02956v1",
                "http://arxiv.org/pdf/2311.02956v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04235v1",
            "title": "Can LLMs Follow Simple Rules?",
            "updated": "2023-11-06T08:50:29Z",
            "published": "2023-11-06T08:50:29Z",
            "summary": "As Large Language Models (LLMs) are deployed with increasing real-world\nresponsibilities, it is important to be able to specify and constrain the\nbehavior of these systems in a reliable manner. Model developers may wish to\nset explicit rules for the model, such as \"do not generate abusive content\",\nbut these may be circumvented by jailbreaking techniques. Evaluating how well\nLLMs follow developer-provided rules in the face of adversarial inputs\ntypically requires manual review, which slows down monitoring and methods\ndevelopment. To address this issue, we propose Rule-following Language\nEvaluation Scenarios (RuLES), a programmatic framework for measuring\nrule-following ability in LLMs. RuLES consists of 15 simple text scenarios in\nwhich the model is instructed to obey a set of rules in natural language while\ninteracting with the human user. Each scenario has a concise evaluation program\nto determine whether the model has broken any rules in a conversation. Through\nmanual exploration of model behavior in our scenarios, we identify 6 categories\nof attack strategies and collect two suites of test cases: one consisting of\nunique conversations from manual testing and one that systematically implements\nstrategies from the 6 categories. Across various popular proprietary and open\nmodels such as GPT-4 and Llama 2, we find that all models are susceptible to a\nwide variety of adversarial hand-crafted user inputs, though GPT-4 is the\nbest-performing model. Additionally, we evaluate open models under\ngradient-based attacks and find significant vulnerabilities. We propose RuLES\nas a challenging new setting for research into exploring and defending against\nboth manual and automatic attacks on LLMs.",
            "author": [
                "Norman Mu",
                "Sarah Chen",
                "Zifan Wang",
                "Sizhe Chen",
                "David Karamardian",
                "Lulwa Aljeraisy",
                "Dan Hendrycks",
                "David Wagner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04235v1",
                "http://arxiv.org/pdf/2311.04235v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02951v1",
            "title": "Machine learning-based photometric classification of galaxies, quasars,\n  emission-line galaxies, and stars",
            "updated": "2023-11-06T08:37:02Z",
            "published": "2023-11-06T08:37:02Z",
            "summary": "This paper explores the application of machine learning methods for\nclassifying astronomical sources using photometric data, including normal and\nemission line galaxies (ELGs; starforming, starburst, AGN, broad line),\nquasars, and stars. We utilized samples from Sloan Digital Sky Survey (SDSS)\nData Release 17 (DR17) and the ALLWISE catalog, which contain spectroscopically\nlabeled sources from SDSS. Our methodology comprises two parts. First, we\nconducted experiments, including three-class, four-class, and seven-class\nclassifications, employing the Random Forest (RF) algorithm. This phase aimed\nto achieve optimal performance with balanced datasets. In the second part, we\ntrained various machine learning methods, such as $k$-nearest neighbors (KNN),\nRF, XGBoost (XGB), voting, and artificial neural network (ANN), using all\navailable data based on promising results from the first phase. Our results\nhighlight the effectiveness of combining optical and infrared features,\nyielding the best performance across all classifiers. Specifically, in the\nthree-class experiment, RF and XGB algorithms achieved identical average F1\nscores of 98.93 per~cent on both balanced and unbalanced datasets. In the\nseven-class experiment, our average F1 score was 73.57 per~cent. Using the XGB\nmethod in the four-class experiment, we achieved F1 scores of 87.9 per~cent for\nnormal galaxies (NGs), 81.5 per~cent for ELGs, 99.1 per~cent for stars, and\n98.5 per~cent for quasars (QSOs). Unlike classical methods based on\ntime-consuming spectroscopy, our experiments demonstrate the feasibility of\nusing automated algorithms on carefully classified photometric data. With more\ndata and ample training samples, detailed photometric classification becomes\npossible, aiding in the selection of follow-up observation candidates.",
            "author": [
                "Fatemeh Zahra Zeraatgari",
                "Fatemeh Hafezianzade",
                "Yanxia Zhang",
                "Liquan Mei",
                "Ashraf Ayubinia",
                "Amin Mosallanezhad",
                "Jingyi Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02951v1",
                "http://arxiv.org/pdf/2311.02951v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02947v1",
            "title": "Multi-view learning for automatic classification of multi-wavelength\n  auroral images",
            "updated": "2023-11-06T08:30:24Z",
            "published": "2023-11-06T08:30:24Z",
            "summary": "Auroral classification plays a crucial role in polar research. However,\ncurrent auroral classification studies are predominantly based on images taken\nat a single wavelength, typically 557.7 nm. Images obtained at other\nwavelengths have been comparatively overlooked, and the integration of\ninformation from multiple wavelengths remains an underexplored area. This\nlimitation results in low classification rates for complex auroral patterns.\nFurthermore, these studies, whether employing traditional machine learning or\ndeep learning approaches, have not achieved a satisfactory trade-off between\naccuracy and speed. To address these challenges, this paper proposes a\nlightweight auroral multi-wavelength fusion classification network, MLCNet,\nbased on a multi-view approach. Firstly, we develop a lightweight feature\nextraction backbone, called LCTNet, to improve the classification rate and cope\nwith the increasing amount of auroral observation data. Secondly, considering\nthe existence of multi-scale spatial structures in auroras, we design a novel\nmulti-scale reconstructed feature module named MSRM. Finally, to highlight the\ndiscriminative information between auroral classes, we propose a lightweight\nattention feature enhancement module called LAFE. The proposed method is\nvalidated using observational data from the Arctic Yellow River Station during\n2003-2004. Experimental results demonstrate that the fusion of multi-wavelength\ninformation effectively improves the auroral classification performance. In\nparticular, our approach achieves state-of-the-art classification accuracy\ncompared to previous auroral classification studies, and superior results in\nterms of accuracy and computational efficiency compared to existing multi-view\nmethods.",
            "author": [
                "Qiuju Yang",
                "Hang Su",
                "Lili Liu",
                "Yixuan Wang",
                "Ze-Jun Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02947v1",
                "http://arxiv.org/pdf/2311.02947v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06297v1",
            "title": "STRIDE: Structure-guided Generation for Inverse Design of Molecules",
            "updated": "2023-11-06T08:22:35Z",
            "published": "2023-11-06T08:22:35Z",
            "summary": "Machine learning and especially deep learning has had an increasing impact on\nmolecule and materials design. In particular, given the growing access to an\nabundance of high-quality small molecule data for generative modeling for drug\ndesign, results for drug discovery have been promising. However, for many\nimportant classes of materials such as catalysts, antioxidants, and\nmetal-organic frameworks, such large datasets are not available. Such families\nof molecules with limited samples and structural similarities are especially\nprevalent for industrial applications. As is well-known, retraining and even\nfine-tuning are challenging on such small datasets. Novel, practically\napplicable molecules are most often derivatives of well-known molecules,\nsuggesting approaches to addressing data scarcity. To address this problem, we\nintroduce $\\textbf{STRIDE}$, a generative molecule workflow that generates\nnovel molecules with an unconditional generative model guided by known\nmolecules without any retraining. We generate molecules outside of the training\ndata from a highly specialized set of antioxidant molecules. Our generated\nmolecules have on average 21.7% lower synthetic accessibility scores and also\nreduce ionization potential by 5.9% of generated molecules via guiding.",
            "author": [
                "Shehtab Zaman",
                "Denis Akhiyarov",
                "Mauricio Araya-Polo",
                "Kenneth Chiu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06297v1",
                "http://arxiv.org/pdf/2311.06297v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02940v1",
            "title": "The Pursuit of Human Labeling: A New Perspective on Unsupervised\n  Learning",
            "updated": "2023-11-06T08:16:41Z",
            "published": "2023-11-06T08:16:41Z",
            "summary": "We present HUME, a simple model-agnostic framework for inferring human\nlabeling of a given dataset without any external supervision. The key insight\nbehind our approach is that classes defined by many human labelings are\nlinearly separable regardless of the representation space used to represent a\ndataset. HUME utilizes this insight to guide the search over all possible\nlabelings of a dataset to discover an underlying human labeling. We show that\nthe proposed optimization objective is strikingly well-correlated with the\nground truth labeling of the dataset. In effect, we only train linear\nclassifiers on top of pretrained representations that remain fixed during\ntraining, making our framework compatible with any large pretrained and\nself-supervised model. Despite its simplicity, HUME outperforms a supervised\nlinear classifier on top of self-supervised representations on the STL-10\ndataset by a large margin and achieves comparable performance on the CIFAR-10\ndataset. Compared to the existing unsupervised baselines, HUME achieves\nstate-of-the-art performance on four benchmark image classification datasets\nincluding the large-scale ImageNet-1000 dataset. Altogether, our work provides\na fundamentally new view to tackle unsupervised learning by searching for\nconsistent labelings between different representation spaces.",
            "author": [
                "Artyom Gadetsky",
                "Maria Brbic"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02940v1",
                "http://arxiv.org/pdf/2311.02940v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02938v1",
            "title": "Contrastive Multi-Level Graph Neural Networks for Session-based\n  Recommendation",
            "updated": "2023-11-06T08:11:32Z",
            "published": "2023-11-06T08:11:32Z",
            "summary": "Session-based recommendation (SBR) aims to predict the next item at a certain\ntime point based on anonymous user behavior sequences. Existing methods\ntypically model session representation based on simple item transition\ninformation. However, since session-based data consists of limited users'\nshort-term interactions, modeling session representation by capturing fixed\nitem transition information from a single dimension suffers from data sparsity.\nIn this paper, we propose a novel contrastive multi-level graph neural networks\n(CM-GNN) to better exploit complex and high-order item transition information.\nSpecifically, CM-GNN applies local-level graph convolutional network (L-GCN)\nand global-level network (G-GCN) on the current session and all the sessions\nrespectively, to effectively capture pairwise relations over all the sessions\nby aggregation strategy. Meanwhile, CM-GNN applies hyper-level graph\nconvolutional network (H-GCN) to capture high-order information among all the\nitem transitions. CM-GNN further introduces an attention-based fusion module to\nlearn pairwise relation-based session representation by fusing the item\nrepresentations generated by L-GCN and G-GCN. CM-GNN averages the item\nrepresentations obtained by H-GCN to obtain high-order relation-based session\nrepresentation. Moreover, to convert the high-order item transition information\ninto the pairwise relation-based session representation, CM-GNN maximizes the\nmutual information between the representations derived from the fusion module\nand the average pool layer by contrastive learning paradigm. We conduct\nextensive experiments on multiple widely used benchmark datasets to validate\nthe efficacy of the proposed method. The encouraging results demonstrate that\nour proposed method outperforms the state-of-the-art SBR techniques.",
            "author": [
                "Fuyun Wang",
                "Xingyu Gao",
                "Zhenyu Chen",
                "Lei Lyu"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TMM.2023.3250087",
                "http://arxiv.org/abs/2311.02938v1",
                "http://arxiv.org/pdf/2311.02938v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02927v1",
            "title": "Auto-ICell: An Accessible and Cost-Effective Integrative Droplet\n  Microfluidic System for Real-Time Single-Cell Morphological and Apoptotic\n  Analysis",
            "updated": "2023-11-06T07:45:34Z",
            "published": "2023-11-06T07:45:34Z",
            "summary": "The Auto-ICell system, a novel, and cost-effective integrated droplet\nmicrofluidic system, is introduced for real-time analysis of single-cell\nmorphology and apoptosis. This system integrates a 3D-printed microfluidic chip\nwith image analysis algorithms, enabling the generation of uniform droplet\nreactors and immediate image analysis. The system employs a color-based image\nanalysis algorithm in the bright field for droplet content analysis. Meanwhile,\nin the fluorescence field, cell apoptosis is quantitatively measured through a\ncombination of deep-learning-enabled multiple fluorescent channel analysis and\na live/dead cell stain kit. Breast cancer cells are encapsulated within uniform\ndroplets, with diameters ranging from 70 {\\mu}m to 240 {\\mu}m, generated at a\nhigh throughput of 1,500 droplets per minute. Real-time image analysis results\nare displayed within 2 seconds on a custom graphical user interface (GUI). The\nsystem provides an automatic calculation of the distribution and ratio of\nencapsulated dyes in the bright field, and in the fluorescent field, cell\nblebbing and cell circularity are observed and quantified respectively. The\nAuto-ICell system is non-invasive and provides online detection, offering a\nrobust, time-efficient, user-friendly, and cost-effective solution for\nsingle-cell analysis. It significantly enhances the detection throughput of\ndroplet single-cell analysis by reducing setup costs and improving operational\nperformance. This study highlights the potential of the Auto-ICell system in\nadvancing biological research and personalized disease treatment, with\npromising applications in cell culture, biochemical microreactors, drug\ncarriers, cell-based assays, synthetic biology, and point-of-care diagnostics.",
            "author": [
                "Yuanyuan Wei",
                "Meiai Lin",
                "Shanhang Luo",
                "Syed Muhammad Tariq Abbasi",
                "Liwei Tan",
                "Guangyao Cheng",
                "Bijie Bai",
                "Yi-Ping Ho",
                "Scott Wu Yuan",
                "Ho-Pui Ho"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02927v1",
                "http://arxiv.org/pdf/2311.02927v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "physics.bio-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02924v1",
            "title": "AttentioNet: Monitoring Student Attention Type in Learning with\n  EEG-Based Measurement System",
            "updated": "2023-11-06T07:43:15Z",
            "published": "2023-11-06T07:43:15Z",
            "summary": "Student attention is an indispensable input for uncovering their goals,\nintentions, and interests, which prove to be invaluable for a multitude of\nresearch areas, ranging from psychology to interactive systems. However, most\nexisting methods to classify attention fail to model its complex nature. To\nbridge this gap, we propose AttentioNet, a novel Convolutional Neural\nNetwork-based approach that utilizes Electroencephalography (EEG) data to\nclassify attention into five states: Selective, Sustained, Divided,\nAlternating, and relaxed state. We collected a dataset of 20 subjects through\nstandard neuropsychological tasks to elicit different attentional states. The\naverage across-student accuracy of our proposed model at this configuration is\n92.3% (SD=3.04), which is well-suited for end-user applications. Our transfer\nlearning-based approach for personalizing the model to individual subjects\neffectively addresses the issue of individual variability in EEG signals,\nresulting in improved performance and adaptability of the model for real-world\napplications. This represents a significant advancement in the field of\nEEG-based classification. Experimental results demonstrate that AttentioNet\noutperforms a popular EEGnet baseline (p-value < 0.05) in both\nsubject-independent and subject-dependent settings, confirming the\neffectiveness of our proposed approach despite the limitations of our dataset.\nThese results highlight the promising potential of AttentioNet for attention\nclassification using EEG data.",
            "author": [
                "Dhruv Verma",
                "Sejal Bhalla",
                "S. V. Sai Santosh",
                "Saumya Yadav",
                "Aman Parnami",
                "Jainendra Shukla"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02924v1",
                "http://arxiv.org/pdf/2311.02924v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "I.2.6; K.3.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02922v1",
            "title": "Truly Scale-Equivariant Deep Nets with Fourier Layers",
            "updated": "2023-11-06T07:32:27Z",
            "published": "2023-11-06T07:32:27Z",
            "summary": "In computer vision, models must be able to adapt to changes in image\nresolution to effectively carry out tasks such as image segmentation; This is\nknown as scale-equivariance. Recent works have made progress in developing\nscale-equivariant convolutional neural networks, e.g., through weight-sharing\nand kernel resizing. However, these networks are not truly scale-equivariant in\npractice. Specifically, they do not consider anti-aliasing as they formulate\nthe down-scaling operation in the continuous domain. To address this\nshortcoming, we directly formulate down-scaling in the discrete domain with\nconsideration of anti-aliasing. We then propose a novel architecture based on\nFourier layers to achieve truly scale-equivariant deep nets, i.e., absolute\nzero equivariance-error. Following prior works, we test this model on\nMNIST-scale and STL-10 datasets. Our proposed model achieves competitive\nclassification performance while maintaining zero equivariance-error.",
            "author": [
                "Md Ashiqur Rahman",
                "Raymond A. Yeh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02922v1",
                "http://arxiv.org/pdf/2311.02922v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02921v3",
            "title": "Edge2Node: Reducing Edge Prediction to Node Classification",
            "updated": "2023-11-22T17:26:08Z",
            "published": "2023-11-06T07:28:16Z",
            "summary": "Despite the success of graph neural network models in node classification,\nedge prediction (the task of predicting missing or potential links between\nnodes in a graph) remains a challenging problem for these models. A common\napproach for edge prediction is to first obtain the embeddings of two nodes,\nand then a predefined scoring function is used to predict the existence of an\nedge between the two nodes. Here, we introduce a preliminary idea called\nEdge2Node which suggests to directly obtain an embedding for each edge, without\nthe need for a scoring function. This idea wants to create a new graph H based\non the graph G given for the edge prediction task, and then suggests reducing\nthe edge prediction task on G to a node classification task on H. We anticipate\nthat this introductory method could stimulate further investigations for edge\nprediction task.",
            "author": [
                "Zahed Rahmati"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02921v3",
                "http://arxiv.org/pdf/2311.02921v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02916v1",
            "title": "Virtual Action Actor-Critic Framework for Exploration (Student Abstract)",
            "updated": "2023-11-06T07:08:51Z",
            "published": "2023-11-06T07:08:51Z",
            "summary": "Efficient exploration for an agent is challenging in reinforcement learning\n(RL). In this paper, a novel actor-critic framework namely virtual action\nactor-critic (VAAC), is proposed to address the challenge of efficient\nexploration in RL. This work is inspired by humans' ability to imagine the\npotential outcomes of their actions without actually taking them. In order to\nemulate this ability, VAAC introduces a new actor called virtual actor (VA),\nalongside the conventional actor-critic framework. Unlike the conventional\nactor, the VA takes the virtual action to anticipate the next state without\ninteracting with the environment. With the virtual policy following a Gaussian\ndistribution, the VA is trained to maximize the anticipated novelty of the\nsubsequent state resulting from a virtual action. If any next state resulting\nfrom available actions does not exhibit high anticipated novelty, training the\nVA leads to an increase in the virtual policy entropy. Hence, high virtual\npolicy entropy represents that there is no room for exploration. The proposed\nVAAC aims to maximize a modified Q function, which combines cumulative rewards\nand the negative sum of virtual policy entropy. Experimental results show that\nthe VAAC improves the exploration performance compared to existing algorithms.",
            "author": [
                "Bumgeun Park",
                "Taeyoung Kim",
                "Quoc-Vinh Lai-Dang",
                "Dongsoo Har"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02916v1",
                "http://arxiv.org/pdf/2311.02916v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02912v1",
            "title": "Imitation Learning based Alternative Multi-Agent Proximal Policy\n  Optimization for Well-Formed Swarm-Oriented Pursuit Avoidance",
            "updated": "2023-11-06T06:58:16Z",
            "published": "2023-11-06T06:58:16Z",
            "summary": "Multi-Robot System (MRS) has garnered widespread research interest and\nfostered tremendous interesting applications, especially in cooperative control\nfields. Yet little light has been shed on the compound ability of formation,\nmonitoring and defence in decentralized large-scale MRS for pursuit avoidance,\nwhich puts stringent requirements on the capability of coordination and\nadaptability. In this paper, we put forward a decentralized Imitation learning\nbased Alternative Multi-Agent Proximal Policy Optimization (IA-MAPPO) algorithm\nto provide a flexible and communication-economic solution to execute the\npursuit avoidance task in well-formed swarm. In particular, a\npolicy-distillation based MAPPO executor is firstly devised to capably\naccomplish and swiftly switch between multiple formations in a centralized\nmanner. Furthermore, we utilize imitation learning to decentralize the\nformation controller, so as to reduce the communication overheads and enhance\nthe scalability. Afterwards, alternative training is leveraged to compensate\nthe performance loss incurred by decentralization. The simulation results\nvalidate the effectiveness of IA-MAPPO and extensive ablation experiments\nfurther show the performance comparable to a centralized solution with\nsignificant decrease in communication overheads.",
            "author": [
                "Sizhao Li",
                "Yuming Xiang",
                "Rongpeng Li",
                "Zhifeng Zhao",
                "Honggang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02912v1",
                "http://arxiv.org/pdf/2311.02912v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02911v1",
            "title": "Goal-Oriented Wireless Communication Resource Allocation for\n  Cyber-Physical Systems",
            "updated": "2023-11-06T06:57:09Z",
            "published": "2023-11-06T06:57:09Z",
            "summary": "The proliferation of novel industrial applications at the wireless edge, such\nas smart grids and vehicle networks, demands the advancement of cyber-physical\nsystems. The performance of CPSs is closely linked to the last-mile wireless\ncommunication networks, which often become bottlenecks due to their inherent\nlimited resources. Current CPS operations often treat wireless communication\nnetworks as unpredictable and uncontrollable variables, ignoring the potential\nadaptability of wireless networks, which results in inefficient and overly\nconservative CPS operations. Meanwhile, current wireless communications often\nfocus more on throughput and other transmission-related metrics instead of CPS\ngoals. In this study, we introduce the framework of goal-oriented wireless\ncommunication resource allocations, accounting for the semantics and\nsignificance of data for CPS operation goals. This guarantees optimal CPS\nperformance from a cybernetic standpoint. We formulate a bandwidth allocation\nproblem aimed at maximizing the information utility gain of transmitted data\nbrought to CPS operation goals. Since the goal-oriented bandwidth allocation\nproblem is a large-scale combinational problem, we propose a divide-and-conquer\nand greedy solution algorithm. The information utility gain is first\napproximately decomposed into marginal utility information gains and computed\nin a parallel manner. Subsequently, the bandwidth allocation problem is\nreformulated as a knapsack problem, which can be further solved greedily with a\nguaranteed sub-optimality gap. We further demonstrate how our proposed\ngoal-oriented bandwidth allocation algorithm can be applied in four potential\nCPS applications, including data-driven decision-making, edge learning,\nfederated learning, and distributed optimization.",
            "author": [
                "Cheng Feng",
                "Kedi Zheng",
                "Yi Wang",
                "Kaibin Huang",
                "Qixin Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02911v1",
                "http://arxiv.org/pdf/2311.02911v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02909v1",
            "title": "Distributed Matrix-Based Sampling for Graph Neural Network Training",
            "updated": "2023-11-06T06:40:43Z",
            "published": "2023-11-06T06:40:43Z",
            "summary": "The primary contribution of this paper is new methods for reducing\ncommunication in the sampling step for distributed GNN training. Here, we\npropose a matrix-based bulk sampling approach that expresses sampling as a\nsparse matrix multiplication (SpGEMM) and samples multiple minibatches at once.\nWhen the input graph topology does not fit on a single device, our method\ndistributes the graph and use communication-avoiding SpGEMM algorithms to scale\nGNN minibatch sampling, enabling GNN training on much larger graphs than those\nthat can fit into a single device memory. When the input graph topology (but\nnot the embeddings) fits in the memory of one GPU, our approach (1) performs\nsampling without communication, (2) amortizes the overheads of sampling a\nminibatch, and (3) can represent multiple sampling algorithms by simply using\ndifferent matrix constructions. In addition to new methods for sampling, we\nshow that judiciously replicating feature data with a simple all-to-all\nexchange can outperform current methods for the feature extraction step in\ndistributed GNN training. We provide experimental results on the largest Open\nGraph Benchmark (OGB) datasets on $128$ GPUs, and show that our pipeline is\n$2.5\\times$ faster Quiver (a distributed extension to PyTorch-Geometric) on a\n$3$-layer GraphSAGE network. On datasets outside of OGB, we show a $8.46\\times$\nspeedup on $128$ GPUs in-per epoch time. Finally, we show scaling when the\ngraph is distributed across GPUs and scaling for both node-wise and layer-wise\nsampling algorithms",
            "author": [
                "Alok Tripathy",
                "Katherine Yelick",
                "Aydin Buluc"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02909v1",
                "http://arxiv.org/pdf/2311.02909v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02908v1",
            "title": "Monocular UAV Localisation with Deep Learning and Uncertainty\n  Propagation",
            "updated": "2023-11-06T06:39:39Z",
            "published": "2023-11-06T06:39:39Z",
            "summary": "In this paper, we propose a ground-based monocular UAV localisation system\nthat detects and localises an LED marker attached to the underside of a UAV.\nOur system removes the need for extensive infrastructure and calibration unlike\nexisting technologies such as UWB, radio frequency and multi-camera systems\noften used for localisation in GPS-denied environment. To improve deployablity\nfor real-world applications without the need to collect extensive real dataset,\nwe train a CNN on synthetic binary images as opposed to using real images in\nexisting monocular UAV localisation methods, and factor in the camera's zoom to\nallow tracking of UAVs flying at further distances. We propose NoisyCutout\nalgorithm for augmenting synthetic binary images to simulate binary images\nprocessed from real images and show that it improves localisation accuracy as\ncompared to using existing salt-and-pepper and Cutout augmentation methods. We\nalso leverage uncertainty propagation to modify the CNN's loss function and\nshow that this also improves localisation accuracy. Real-world experiments are\nconducted to evaluate our methods and we achieve an overall 3D RMSE of\napproximately 0.41m.",
            "author": [
                "Xueyan Oh",
                "Ryan Lim",
                "Leonard Loh",
                "Chee How Tan",
                "Shaohui Foong",
                "U-Xuan Tan"
            ],
            "link": [
                "http://dx.doi.org/10.1109/LRA.2022.3186750",
                "http://arxiv.org/abs/2311.02908v1",
                "http://arxiv.org/pdf/2311.02908v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02907v1",
            "title": "Reinforcement Learning for Safety Testing: Lessons from A Mobile Robot\n  Case Study",
            "updated": "2023-11-06T06:37:20Z",
            "published": "2023-11-06T06:37:20Z",
            "summary": "Safety-critical robot systems need thorough testing to expose design flaws\nand software bugs which could endanger humans. Testing in simulation is\nbecoming increasingly popular, as it can be applied early in the development\nprocess and does not endanger any real-world operators. However, not all\nsafety-critical flaws become immediately observable in simulation. Some may\nonly become observable under certain critical conditions. If these conditions\nare not covered, safety flaws may remain undetected. Creating critical tests is\ntherefore crucial. In recent years, there has been a trend towards using\nReinforcement Learning (RL) for this purpose. Guided by domain-specific reward\nfunctions, RL algorithms are used to learn critical test strategies. This paper\npresents a case study in which the collision avoidance behavior of a mobile\nrobot is subjected to RL-based testing. The study confirms prior research which\nshows that RL can be an effective testing tool. However, the study also\nhighlights certain challenges associated with RL-based testing, namely (i) a\npossible lack of diversity in test conditions and (ii) the phenomenon of reward\nhacking where the RL agent behaves in undesired ways due to a misalignment of\nreward and test specification. The challenges are illustrated with data and\nexamples from the experiments, and possible mitigation strategies are\ndiscussed.",
            "author": [
                "Tom P. Huck",
                "Martin Kaiser",
                "Constantin Cronrath",
                "Bengt Lennartson",
                "Torsten Kr\u00f6ger",
                "Tamim Asfour"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02907v1",
                "http://arxiv.org/pdf/2311.02907v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02903v1",
            "title": "HDGL: A hierarchical dynamic graph representation learning model for\n  brain disorder classification",
            "updated": "2023-11-06T06:29:23Z",
            "published": "2023-11-06T06:29:23Z",
            "summary": "The human brain can be considered as complex networks, composed of various\nregions that continuously exchange their information with each other, forming\nthe brain network graph, from which nodes and edges are extracted using\nresting-state functional magnetic resonance imaging (rs-fMRI). Therefore, this\ngraph can potentially depict abnormal patterns that have emerged under the\ninfluence of brain disorders. So far, numerous studies have attempted to find\nembeddings for brain network graphs and subsequently classify samples with\nbrain disorders from healthy ones, which include limitations such as: not\nconsidering the relationship between samples, not utilizing phenotype\ninformation, lack of temporal analysis, using static functional connectivity\n(FC) instead of dynamic ones and using a fixed graph structure. We propose a\nhierarchical dynamic graph representation learning (HDGL) model, which is the\nfirst model designed to address all the aforementioned challenges. HDGL\nconsists of two levels, where at the first level, it constructs brain network\ngraphs and learns their spatial and temporal embeddings, and at the second\nlevel, it forms population graphs and performs classification after embedding\nlearning. Furthermore, based on how these two levels are trained, four methods\nhave been introduced, some of which are suggested for reducing memory\ncomplexity. We evaluated the performance of the proposed model on the ABIDE and\nADHD-200 datasets, and the results indicate the improvement of this model\ncompared to several state-of-the-art models in terms of various evaluation\nmetrics.",
            "author": [
                "Parniyan Jalali",
                "Mehran Safayani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02903v1",
                "http://arxiv.org/pdf/2311.02903v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02899v2",
            "title": "Stochastic Pairwise Preference Convergence in Bayesian Agents",
            "updated": "2023-11-07T17:32:03Z",
            "published": "2023-11-06T06:21:11Z",
            "summary": "Beliefs inform the behavior of forward-thinking agents in complex\nenvironments. Recently, sequential Bayesian inference has emerged as a\nmechanism to study belief formation among agents adapting to dynamical\nconditions. However, we lack critical theory to explain how preferences evolve\nin cases of simple agent interactions. In this paper, we derive a Gaussian,\npairwise agent interaction model to study how preferences converge when driven\nby observation of each other's behaviors. We show that the dynamics of\nconvergence resemble an Ornstein-Uhlenbeck process, a common model in\nnonequilibrium stochastic dynamics. Using standard analytical and computational\ntechniques, we find that the hyperprior magnitudes, representing the learning\ntime, determine the convergence value and the asymptotic entropy of the\npreferences across pairs of agents. We also show that the dynamical variance in\npreferences is characterized by a relaxation time $t^\\star$, and compute its\nasymptotic upper bound. This formulation enhances the existing toolkit for\nmodeling stochastic, interactive agents by formalizing leading theories in\nlearning theory, and builds towards more comprehensive models of open problems\nin principal-agent and market theory.",
            "author": [
                "Jordan T Kemp",
                "Max-Olivier Hongler",
                "Olivier Gallay"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02899v2",
                "http://arxiv.org/pdf/2311.02899v2"
            ],
            "primary_category": "nlin.AO",
            "category": [
                "nlin.AO",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02898v2",
            "title": "Transduce and Speak: Neural Transducer for Text-to-Speech with Semantic\n  Token Prediction",
            "updated": "2023-11-08T05:52:39Z",
            "published": "2023-11-06T06:13:39Z",
            "summary": "We introduce a text-to-speech(TTS) framework based on a neural transducer. We\nuse discretized semantic tokens acquired from wav2vec2.0 embeddings, which\nmakes it easy to adopt a neural transducer for the TTS framework enjoying its\nmonotonic alignment constraints. The proposed model first generates aligned\nsemantic tokens using the neural transducer, then synthesizes a speech sample\nfrom the semantic tokens using a non-autoregressive(NAR) speech generator. This\ndecoupled framework alleviates the training complexity of TTS and allows each\nstage to focus on 1) linguistic and alignment modeling and 2) fine-grained\nacoustic modeling, respectively. Experimental results on the zero-shot adaptive\nTTS show that the proposed model exceeds the baselines in speech quality and\nspeaker similarity via objective and subjective measures. We also investigate\nthe inference speed and prosody controllability of our proposed model, showing\nthe potential of the neural transducer for TTS frameworks.",
            "author": [
                "Minchan Kim",
                "Myeonghun Jeong",
                "Byoung Jin Choi",
                "Dongjune Lee",
                "Nam Soo Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02898v2",
                "http://arxiv.org/pdf/2311.02898v2"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02892v1",
            "title": "Human as Points: Explicit Point-based 3D Human Reconstruction from\n  Single-view RGB Images",
            "updated": "2023-11-06T05:52:29Z",
            "published": "2023-11-06T05:52:29Z",
            "summary": "The latest trends in the research field of single-view human reconstruction\ndevote to learning deep implicit functions constrained by explicit body shape\npriors. Despite the remarkable performance improvements compared with\ntraditional processing pipelines, existing learning approaches still show\ndifferent aspects of limitations in terms of flexibility, generalizability,\nrobustness, and/or representation capability. To comprehensively address the\nabove issues, in this paper, we investigate an explicit point-based human\nreconstruction framework called HaP, which adopts point clouds as the\nintermediate representation of the target geometric structure. Technically, our\napproach is featured by fully-explicit point cloud estimation, manipulation,\ngeneration, and refinement in the 3D geometric space, instead of an implicit\nlearning process that can be ambiguous and less controllable. The overall\nworkflow is carefully organized with dedicated designs of the corresponding\nspecialized learning components as well as processing procedures. Extensive\nexperiments demonstrate that our framework achieves quantitative performance\nimprovements of 20% to 40% over current state-of-the-art methods, and better\nqualitative results. Our promising results may indicate a paradigm rollback to\nthe fully-explicit and geometry-centric algorithm design, which enables to\nexploit various powerful point cloud modeling architectures and processing\ntechniques. We will make our code and data publicly available at\nhttps://github.com/yztang4/HaP.",
            "author": [
                "Yingzhi Tang",
                "Qijian Zhang",
                "Junhui Hou",
                "Yebin Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02892v1",
                "http://arxiv.org/pdf/2311.02892v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02891v1",
            "title": "AdaFlood: Adaptive Flood Regularization",
            "updated": "2023-11-06T05:50:10Z",
            "published": "2023-11-06T05:50:10Z",
            "summary": "Although neural networks are conventionally optimized towards zero training\nloss, it has been recently learned that targeting a non-zero training loss\nthreshold, referred to as a flood level, often enables better test time\ngeneralization. Current approaches, however, apply the same constant flood\nlevel to all training samples, which inherently assumes all the samples have\nthe same difficulty. We present AdaFlood, a novel flood regularization method\nthat adapts the flood level of each training sample according to the difficulty\nof the sample. Intuitively, since training samples are not equal in difficulty,\nthe target training loss should be conditioned on the instance. Experiments on\ndatasets covering four diverse input modalities - text, images, asynchronous\nevent sequences, and tabular - demonstrate the versatility of AdaFlood across\ndata domains and noise levels.",
            "author": [
                "Wonho Bae",
                "Yi Ren",
                "Mohamad Osama Ahmed",
                "Frederick Tung",
                "Danica J. Sutherland",
                "Gabriel L. Oliveira"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02891v1",
                "http://arxiv.org/pdf/2311.02891v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02887v1",
            "title": "Stacked Autoencoder Based Feature Extraction and Superpixel Generation\n  for Multifrequency PolSAR Image Classification",
            "updated": "2023-11-06T05:37:03Z",
            "published": "2023-11-06T05:37:03Z",
            "summary": "In this paper we are proposing classification algorithm for multifrequency\nPolarimetric Synthetic Aperture Radar (PolSAR) image. Using PolSAR\ndecomposition algorithms 33 features are extracted from each frequency band of\nthe given image. Then, a two-layer autoencoder is used to reduce the\ndimensionality of input feature vector while retaining useful features of the\ninput. This reduced dimensional feature vector is then applied to generate\nsuperpixels using simple linear iterative clustering (SLIC) algorithm. Next, a\nrobust feature representation is constructed using both pixel as well as\nsuperpixel information. Finally, softmax classifier is used to perform\nclassification task. The advantage of using superpixels is that it preserves\nspatial information between neighbouring PolSAR pixels and therefore minimises\nthe effect of speckle noise during classification. Experiments have been\nconducted on Flevoland dataset and the proposed method was found to be superior\nto other methods available in the literature.",
            "author": [
                "Tushar Gadhiya",
                "Sumanth Tangirala",
                "Anil K. Roy"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-030-34872-4_37",
                "http://arxiv.org/abs/2311.02887v1",
                "http://arxiv.org/pdf/2311.02887v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03411v1",
            "title": "ViDa: Visualizing DNA hybridization trajectories with\n  biophysics-informed deep graph embeddings",
            "updated": "2023-11-06T05:27:29Z",
            "published": "2023-11-06T05:27:29Z",
            "summary": "Visualization tools can help synthetic biologists and molecular programmers\nunderstand the complex reactive pathways of nucleic acid reactions, which can\nbe designed for many potential applications and can be modelled using a\ncontinuous-time Markov chain (CTMC). Here we present ViDa, a new visualization\napproach for DNA reaction trajectories that uses a 2D embedding of the\nsecondary structure state space underlying the CTMC model. To this end, we\nintegrate a scattering transform of the secondary structure adjacency, a\nvariational autoencoder, and a nonlinear dimensionality reduction method. We\naugment the training loss with domain-specific supervised terms that capture\nboth thermodynamic and kinetic features. We assess ViDa on two well-studied DNA\nhybridization reactions. Our results demonstrate that the domain-specific\nfeatures lead to significant quality improvements over the state-of-the-art in\nDNA state space visualization, successfully separating different folding\npathways and thus providing useful insights into dominant reaction mechanisms.",
            "author": [
                "Chenwei Zhang",
                "Jordan Lovrod",
                "Boyan Beronov",
                "Khanh Dao Duc",
                "Anne Condon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03411v1",
                "http://arxiv.org/pdf/2311.03411v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.AI",
                "cs.HC",
                "cs.LG",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02884v1",
            "title": "Deep Learning-Empowered Semantic Communication Systems with a Shared\n  Knowledge Base",
            "updated": "2023-11-06T05:25:31Z",
            "published": "2023-11-06T05:25:31Z",
            "summary": "Deep learning-empowered semantic communication is regarded as a promising\ncandidate for future 6G networks. Although existing semantic communication\nsystems have achieved superior performance compared to traditional methods, the\nend-to-end architecture adopted by most semantic communication systems is\nregarded as a black box, leading to the lack of explainability. To tackle this\nissue, in this paper, a novel semantic communication system with a shared\nknowledge base is proposed for text transmissions. Specifically, a textual\nknowledge base constructed by inherently readable sentences is introduced into\nour system. With the aid of the shared knowledge base, the proposed system\nintegrates the message and corresponding knowledge from the shared knowledge\nbase to obtain the residual information, which enables the system to transmit\nfewer symbols without semantic performance degradation. In order to make the\nproposed system more reliable, the semantic self-information and the source\nentropy are mathematically defined based on the knowledge base. Furthermore,\nthe knowledge base construction algorithm is developed based on a\nsimilarity-comparison method, in which a pre-configured threshold can be\nleveraged to control the size of the knowledge base. Moreover, the simulation\nresults have demonstrated that the proposed approach outperforms existing\nbaseline methods in terms of transmitted data size and sentence similarity.",
            "author": [
                "Peng Yi",
                "Yang Cao",
                "Xin Kang",
                "Ying-Chang Liang"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TWC.2023.3330744",
                "http://arxiv.org/abs/2311.02884v1",
                "http://arxiv.org/pdf/2311.02884v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.IT",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02883v1",
            "title": "SQLPrompt: In-Context Text-to-SQL with Minimal Labeled Data",
            "updated": "2023-11-06T05:24:06Z",
            "published": "2023-11-06T05:24:06Z",
            "summary": "Text-to-SQL aims to automate the process of generating SQL queries on a\ndatabase from natural language text. In this work, we propose \"SQLPrompt\",\ntailored to improve the few-shot prompting capabilities of Text-to-SQL for\nLarge Language Models (LLMs). Our methods include innovative prompt design,\nexecution-based consistency decoding strategy which selects the SQL with the\nmost consistent execution outcome among other SQL proposals, and a method that\naims to improve performance by diversifying the SQL proposals during\nconsistency selection with different prompt designs (\"MixPrompt\") and\nfoundation models (\"MixLLMs\"). We show that \\emph{SQLPrompt} outperforms\nprevious approaches for in-context learning with few labeled data by a large\nmargin, closing the gap with finetuning state-of-the-art with thousands of\nlabeled data.",
            "author": [
                "Ruoxi Sun",
                "Sercan \u00d6. Arik",
                "Rajarishi Sinha",
                "Hootan Nakhost",
                "Hanjun Dai",
                "Pengcheng Yin",
                "Tomas Pfister"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02883v1",
                "http://arxiv.org/pdf/2311.02883v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02880v1",
            "title": "MultiSPANS: A Multi-range Spatial-Temporal Transformer Network for\n  Traffic Forecast via Structural Entropy Optimization",
            "updated": "2023-11-06T05:19:06Z",
            "published": "2023-11-06T05:19:06Z",
            "summary": "Traffic forecasting is a complex multivariate time-series regression task of\nparamount importance for traffic management and planning. However, existing\napproaches often struggle to model complex multi-range dependencies using local\nspatiotemporal features and road network hierarchical knowledge. To address\nthis, we propose MultiSPANS. First, considering that an individual recording\npoint cannot reflect critical spatiotemporal local patterns, we design\nmulti-filter convolution modules for generating informative ST-token embeddings\nto facilitate attention computation. Then, based on ST-token and\nspatial-temporal position encoding, we employ the Transformers to capture\nlong-range temporal and spatial dependencies. Furthermore, we introduce\nstructural entropy theory to optimize the spatial attention mechanism.\nSpecifically, The structural entropy minimization algorithm is used to generate\noptimal road network hierarchies, i.e., encoding trees. Based on this, we\npropose a relative structural entropy-based position encoding and a multi-head\nattention masking scheme based on multi-layer encoding trees. Extensive\nexperiments demonstrate the superiority of the presented framework over several\nstate-of-the-art methods in real-world traffic datasets, and the longer\nhistorical windows are effectively utilized. The code is available at\nhttps://github.com/SELGroup/MultiSPANS.",
            "author": [
                "Dongcheng Zou",
                "Senzhang Wang",
                "Xuefeng Li",
                "Hao Peng",
                "Yuandong Wang",
                "Chunyang Liu",
                "Kehua Sheng",
                "Bo Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02880v1",
                "http://arxiv.org/pdf/2311.02880v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02879v1",
            "title": "Exploring Active Learning in Meta-Learning: Enhancing Context Set\n  Labeling",
            "updated": "2023-11-06T05:18:01Z",
            "published": "2023-11-06T05:18:01Z",
            "summary": "Most meta-learning methods assume that the (very small) context set used to\nestablish a new task at test time is passively provided. In some settings,\nhowever, it is feasible to actively select which points to label; the potential\ngain from a careful choice is substantial, but the setting requires major\ndifferences from typical active learning setups. We clarify the ways in which\nactive meta-learning can be used to label a context set, depending on which\nparts of the meta-learning process use active learning. Within this framework,\nwe propose a natural algorithm based on fitting Gaussian mixtures for selecting\nwhich points to label; though simple, the algorithm also has theoretical\nmotivation. The proposed algorithm outperforms state-of-the-art active learning\nmethods when used with various meta-learning algorithms across several\nbenchmark datasets.",
            "author": [
                "Wonho Bae",
                "Jing Wang",
                "Danica J. Sutherland"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02879v1",
                "http://arxiv.org/pdf/2311.02879v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03410v1",
            "title": "DP-DCAN: Differentially Private Deep Contrastive Autoencoder Network for\n  Single-cell Clustering",
            "updated": "2023-11-06T05:13:29Z",
            "published": "2023-11-06T05:13:29Z",
            "summary": "Single-cell RNA sequencing (scRNA-seq) is important to transcriptomic\nanalysis of gene expression. Recently, deep learning has facilitated the\nanalysis of high-dimensional single-cell data. Unfortunately, deep learning\nmodels may leak sensitive information about users. As a result, Differential\nPrivacy (DP) is increasingly used to protect privacy. However, existing DP\nmethods usually perturb whole neural networks to achieve differential privacy,\nand hence result in great performance overheads. To address this challenge, in\nthis paper, we take advantage of the uniqueness of the autoencoder that it\noutputs only the dimension-reduced vector in the middle of the network, and\ndesign a Differentially Private Deep Contrastive Autoencoder Network (DP-DCAN)\nby partial network perturbation for single-cell clustering. Since only partial\nnetwork is added with noise, the performance improvement is obvious and\ntwofold: one part of network is trained with less noise due to a bigger privacy\nbudget, and the other part is trained without any noise. Experimental results\nof six datasets have verified that DP-DCAN is superior to the traditional DP\nscheme with whole network perturbation. Moreover, DP-DCAN demonstrates strong\nrobustness to adversarial attacks. The code is available at\nhttps://github.com/LFD-byte/DP-DCAN.",
            "author": [
                "Huifa Li",
                "Jie Fu",
                "Zhili Chen",
                "Xiaomin Yang",
                "Haitao Liu",
                "Xinpeng Ling"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03410v1",
                "http://arxiv.org/pdf/2311.03410v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.GN"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03409v1",
            "title": "Visualizing DNA reaction trajectories with deep graph embedding\n  approaches",
            "updated": "2023-11-06T05:06:35Z",
            "published": "2023-11-06T05:06:35Z",
            "summary": "Synthetic biologists and molecular programmers design novel nucleic acid\nreactions, with many potential applications. Good visualization tools are\nneeded to help domain experts make sense of the complex outputs of folding\npathway simulations of such reactions. Here we present ViDa, a new approach for\nvisualizing DNA reaction folding trajectories over the energy landscape of\nsecondary structures. We integrate a deep graph embedding model with common\ndimensionality reduction approaches, to map high-dimensional data onto 2D\nEuclidean space. We assess ViDa on two well-studied and contrasting DNA\nhybridization reactions. Our preliminary results suggest that ViDa's\nvisualization successfully separates trajectories with different folding\nmechanisms, thereby providing useful insight to users, and is a big improvement\nover the current state-of-the-art in DNA kinetics visualization.",
            "author": [
                "Chenwei Zhang",
                "Khanh Dao Duc",
                "Anne Condon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03409v1",
                "http://arxiv.org/pdf/2311.03409v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.AI",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02874v1",
            "title": "Dynamic Neural Fields for Learning Atlases of 4D Fetal MRI Time-series",
            "updated": "2023-11-06T05:01:58Z",
            "published": "2023-11-06T05:01:58Z",
            "summary": "We present a method for fast biomedical image atlas construction using neural\nfields. Atlases are key to biomedical image analysis tasks, yet conventional\nand deep network estimation methods remain time-intensive. In this preliminary\nwork, we frame subject-specific atlas building as learning a neural field of\ndeformable spatiotemporal observations. We apply our method to learning\nsubject-specific atlases and motion stabilization of dynamic BOLD MRI\ntime-series of fetuses in utero. Our method yields high-quality atlases of\nfetal BOLD time-series with $\\sim$5-7$\\times$ faster convergence compared to\nexisting work. While our method slightly underperforms well-tuned baselines in\nterms of anatomical overlap, it estimates templates significantly faster, thus\nenabling rapid processing and stabilization of large databases of 4D dynamic\nMRI acquisitions. Code is available at\nhttps://github.com/Kidrauh/neural-atlasing",
            "author": [
                "Zeen Chi",
                "Zhongxiao Cong",
                "Clinton J. Wang",
                "Yingcheng Liu",
                "Esra Abaci Turk",
                "P. Ellen Grant",
                "S. Mazdak Abulnaga",
                "Polina Golland",
                "Neel Dey"
            ],
            "link": [
                "http://dx.doi.org/10.48550/arXiv.2311.02874",
                "http://arxiv.org/abs/2311.02874v1",
                "http://arxiv.org/pdf/2311.02874v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02871v1",
            "title": "Channel Attention for Quantum Convolutional Neural Networks",
            "updated": "2023-11-06T04:54:05Z",
            "published": "2023-11-06T04:54:05Z",
            "summary": "Quantum convolutional neural networks (QCNNs) have gathered attention as one\nof the most promising algorithms for quantum machine learning. Reduction in the\ncost of training as well as improvement in performance is required for\npractical implementation of these models. In this study, we propose a channel\nattention mechanism for QCNNs and show the effectiveness of this approach for\nquantum phase classification problems. Our attention mechanism creates multiple\nchannels of output state based on measurement of quantum bits. This simple\napproach improves the performance of QCNNs and outperforms a conventional\napproach using feedforward neural networks as the additional post-processing.",
            "author": [
                "Gekko Budiutama",
                "Shunsuke Daimon",
                "Hirofumi Nishi",
                "Ryui Kaneko",
                "Tomi Ohtsuki",
                "Yu-ichiro Matsushita"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02871v1",
                "http://arxiv.org/pdf/2311.02871v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02869v4",
            "title": "Lightweight equivariant interaction graph neural network for accurate\n  and efficient interatomic potential and force predictions",
            "updated": "2023-11-17T15:36:42Z",
            "published": "2023-11-06T04:49:09Z",
            "summary": "In modern computational materials science, deep learning has shown the\ncapability to predict interatomic potentials, thereby supporting and\naccelerating conventional simulations. However, existing models typically\nsacrifice either accuracy or efficiency. Moreover, lightweight models are\nhighly demanded for offering simulating systems on a considerably larger scale\nat reduced computational costs. A century ago, Felix Bloch demonstrated how\nleveraging the equivariance of the translation operation on a crystal lattice\n(with geometric symmetry) could significantly reduce the computational cost of\ndetermining wavefunctions and accurately calculate material properties. Here,\nwe introduce a lightweight equivariant interaction graph neural network\n(LEIGNN) that can enable accurate and efficient interatomic potential and force\npredictions in crystals. Rather than relying on higher-order representations,\nLEIGNN employs a scalar-vector dual representation to encode equivariant\nfeatures. By extracting both local and global structures from vector\nrepresentations and learning geometric symmetry information, our model remains\nlightweight while ensuring prediction accuracy and robustness through the\nequivariance. Our results show that LEIGNN consistently outperforms the\nprediction performance of the representative baselines and achieves significant\nefficiency across diverse datasets, which include catalysts, molecules, and\norganic isomers. Finally, to further validate the predicted interatomic\npotentials from our model, we conduct classical molecular dynamics (MD) and ab\ninitio MD simulation across various systems, including solid, liquid, and gas.\nIt is found that LEIGNN can achieve the accuracy of ab initio MD and retain the\ncomputational efficiency of classical MD across all examined systems,\ndemonstrating its accuracy, efficiency, and universality.",
            "author": [
                "Ziduo Yang",
                "Xian Wang",
                "Yifan Li",
                "Qiujie Lv",
                "Calvin Yu-Chian Chen",
                "Lei Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02869v4",
                "http://arxiv.org/pdf/2311.02869v4"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02868v1",
            "title": "Sample Complexity Bounds for Estimating Probability Divergences under\n  Invariances",
            "updated": "2023-11-06T04:45:21Z",
            "published": "2023-11-06T04:45:21Z",
            "summary": "Group-invariant probability distributions appear in many data-generative\nmodels in machine learning, such as graphs, point clouds, and images. In\npractice, one often needs to estimate divergences between such distributions.\nIn this work, we study how the inherent invariances, with respect to any smooth\naction of a Lie group on a manifold, improve sample complexity when estimating\nthe Wasserstein distance, the Sobolev Integral Probability Metrics (Sobolev\nIPMs), the Maximum Mean Discrepancy (MMD), and also the complexity of the\ndensity estimation problem (in the $L^2$ and $L^\\infty$ distance). Our results\nindicate a two-fold gain: (1) reducing the sample complexity by a\nmultiplicative factor corresponding to the group size (for finite groups) or\nthe normalized volume of the quotient space (for groups of positive dimension);\n(2) improving the exponent in the convergence rate (for groups of positive\ndimension). These results are completely new for groups of positive dimension\nand extend recent bounds for finite group actions.",
            "author": [
                "Behrooz Tahmasebi",
                "Stefanie Jegelka"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02868v1",
                "http://arxiv.org/pdf/2311.02868v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03408v1",
            "title": "Training Multi-layer Neural Networks on Ising Machine",
            "updated": "2023-11-06T04:09:15Z",
            "published": "2023-11-06T04:09:15Z",
            "summary": "As a dedicated quantum device, Ising machines could solve large-scale binary\noptimization problems in milliseconds. There is emerging interest in utilizing\nIsing machines to train feedforward neural networks due to the prosperity of\ngenerative artificial intelligence. However, existing methods can only train\nsingle-layer feedforward networks because of the complex nonlinear network\ntopology. This paper proposes an Ising learning algorithm to train quantized\nneural network (QNN), by incorporating two essential techinques, namely binary\nrepresentation of topological network and order reduction of loss function. As\nfar as we know, this is the first algorithm to train multi-layer feedforward\nnetworks on Ising machines, providing an alternative to gradient-based\nbackpropagation. Firstly, training QNN is formulated as a quadratic constrained\nbinary optimization (QCBO) problem by representing neuron connection and\nactivation function as equality constraints. All quantized variables are\nencoded by binary bits based on binary encoding protocol. Secondly, QCBO is\nconverted to a quadratic unconstrained binary optimization (QUBO) problem, that\ncan be efficiently solved on Ising machines. The conversion leverages both\npenalty function and Rosenberg order reduction, who together eliminate equality\nconstraints and reduce high-order loss function into a quadratic one. With some\nassumptions, theoretical analysis shows the space complexity of our algorithm\nis $\\mathcal{O}(H^2L + HLN\\log H)$, quantifying the required number of Ising\nspins. Finally, the algorithm effectiveness is validated with a simulated Ising\nmachine on MNIST dataset. After annealing 700 ms, the classification accuracy\nachieves 98.3%. Among 100 runs, the success probability of finding the optimal\nsolution is 72%. Along with the increasing number of spins on Ising machine,\nour algorithm has the potential to train deeper neural networks.",
            "author": [
                "Xujie Song",
                "Tong Liu",
                "Shengbo Eben Li",
                "Jingliang Duan",
                "Wenxuan Wang",
                "Keqiang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03408v1",
                "http://arxiv.org/pdf/2311.03408v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NE",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02847v2",
            "title": "Kinematic-aware Prompting for Generalizable Articulated Object\n  Manipulation with LLMs",
            "updated": "2023-11-08T06:12:36Z",
            "published": "2023-11-06T03:26:41Z",
            "summary": "Generalizable articulated object manipulation is essential for home-assistant\nrobots. Recent efforts focus on imitation learning from demonstrations or\nreinforcement learning in simulation, however, due to the prohibitive costs of\nreal-world data collection and precise object simulation, it still remains\nchallenging for these works to achieve broad adaptability across diverse\narticulated objects. Recently, many works have tried to utilize the strong\nin-context learning ability of Large Language Models (LLMs) to achieve\ngeneralizable robotic manipulation, but most of these researches focus on\nhigh-level task planning, sidelining low-level robotic control. In this work,\nbuilding on the idea that the kinematic structure of the object determines how\nwe can manipulate it, we propose a kinematic-aware prompting framework that\nprompts LLMs with kinematic knowledge of objects to generate low-level motion\ntrajectory waypoints, supporting various object manipulation. To effectively\nprompt LLMs with the kinematic structure of different objects, we design a\nunified kinematic knowledge parser, which represents various articulated\nobjects as a unified textual description containing kinematic joints and\ncontact location. Building upon this unified description, a kinematic-aware\nplanner model is proposed to generate precise 3D manipulation waypoints via a\ndesigned kinematic-aware chain-of-thoughts prompting method. Our evaluation\nspanned 48 instances across 16 distinct categories, revealing that our\nframework not only outperforms traditional methods on 8 seen categories but\nalso shows a powerful zero-shot capability for 8 unseen articulated object\ncategories. Moreover, the real-world experiments on 7 different object\ncategories prove our framework's adaptability in practical scenarios. Code is\nreleased at\n\\href{https://github.com/GeWu-Lab/LLM_articulated_object_manipulation/tree/main}{here}.",
            "author": [
                "Wenke Xia",
                "Dong Wang",
                "Xincheng Pang",
                "Zhigang Wang",
                "Bin Zhao",
                "Di Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02847v2",
                "http://arxiv.org/pdf/2311.02847v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04234v1",
            "title": "Leveraging sinusoidal representation networks to predict fMRI signals\n  from EEG",
            "updated": "2023-11-06T03:16:18Z",
            "published": "2023-11-06T03:16:18Z",
            "summary": "In modern neuroscience, functional magnetic resonance imaging (fMRI) has been\na crucial and irreplaceable tool that provides a non-invasive window into the\ndynamics of whole-brain activity. Nevertheless, fMRI is limited by hemodynamic\nblurring as well as high cost, immobility, and incompatibility with metal\nimplants. Electroencephalography (EEG) is complementary to fMRI and can\ndirectly record the cortical electrical activity at high temporal resolution,\nbut has more limited spatial resolution and is unable to recover information\nabout deep subcortical brain structures. The ability to obtain fMRI information\nfrom EEG would enable cost-effective, imaging across a wider set of brain\nregions. Further, beyond augmenting the capabilities of EEG, cross-modality\nmodels would facilitate the interpretation of fMRI signals. However, as both\nEEG and fMRI are high-dimensional and prone to artifacts, it is currently\nchallenging to model fMRI from EEG. To address this challenge, we propose a\nnovel architecture that can predict fMRI signals directly from multi-channel\nEEG without explicit feature engineering. Our model achieves this by\nimplementing a Sinusoidal Representation Network (SIREN) to learn frequency\ninformation in brain dynamics from EEG, which serves as the input to a\nsubsequent encoder-decoder to effectively reconstruct the fMRI signal from a\nspecific brain region. We evaluate our model using a simultaneous EEG-fMRI\ndataset with 8 subjects and investigate its potential for predicting\nsubcortical fMRI signals. The present results reveal that our model outperforms\na recent state-of-the-art model, and indicates the potential of leveraging\nperiodic activation functions in deep neural networks to model functional\nneuroimaging data.",
            "author": [
                "Yamin Li",
                "Ange Lou",
                "Catie Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04234v1",
                "http://arxiv.org/pdf/2311.04234v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02840v1",
            "title": "Saturn: Efficient Multi-Large-Model Deep Learning",
            "updated": "2023-11-06T02:59:49Z",
            "published": "2023-11-06T02:59:49Z",
            "summary": "In this paper, we propose Saturn, a new data system to improve the efficiency\nof multi-large-model training (e.g., during model selection/hyperparameter\noptimization). We first identify three key interconnected systems challenges\nfor users building large models in this setting -- parallelism technique\nselection, distribution of GPUs over jobs, and scheduling. We then formalize\nthese as a joint problem, and build a new system architecture to tackle these\nchallenges simultaneously. Our evaluations show that our joint-optimization\napproach yields 39-49% lower model selection runtimes than typical current DL\npractice.",
            "author": [
                "Kabir Nagrecha",
                "Arun Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02840v1",
                "http://arxiv.org/pdf/2311.02840v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02838v1",
            "title": "Barron Space for Graph Convolution Neural Networks",
            "updated": "2023-11-06T02:58:05Z",
            "published": "2023-11-06T02:58:05Z",
            "summary": "Graph convolutional neural network (GCNN) operates on graph domain and it has\nachieved a superior performance to accomplish a wide range of tasks. In this\npaper, we introduce a Barron space of functions on a compact domain of graph\nsignals. We prove that the proposed Barron space is a reproducing kernel Banach\nspace, it can be decomposed into the union of a family of reproducing kernel\nHilbert spaces with neuron kernels, and it could be dense in the space of\ncontinuous functions on the domain. Approximation property is one of the main\nprinciples to design neural networks. In this paper, we show that outputs of\nGCNNs are contained in the Barron space and functions in the Barron space can\nbe well approximated by outputs of some GCNNs in the integrated square and\nuniform measurements. We also estimate the Rademacher complexity of functions\nwith bounded Barron norm and conclude that functions in the Barron space could\nbe learnt from their random samples efficiently.",
            "author": [
                "Seok-Young Chung",
                "Qiyu Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02838v1",
                "http://arxiv.org/pdf/2311.02838v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02835v1",
            "title": "Flexible Multi-Generator Model with Fused Spatiotemporal Graph for\n  Trajectory Prediction",
            "updated": "2023-11-06T02:46:05Z",
            "published": "2023-11-06T02:46:05Z",
            "summary": "Trajectory prediction plays a vital role in automotive radar systems,\nfacilitating precise tracking and decision-making in autonomous driving.\nGenerative adversarial networks with the ability to learn a distribution over\nfuture trajectories tend to predict out-of-distribution samples, which\ntypically occurs when the distribution of forthcoming paths comprises a blend\nof various manifolds that may be disconnected. To address this issue, we\npropose a trajectory prediction framework, which can capture the social\ninteraction variations and model disconnected manifolds of pedestrian\ntrajectories. Our framework is based on a fused spatiotemporal graph to better\nmodel the complex interactions of pedestrians in a scene, and a multi-generator\narchitecture that incorporates a flexible generator selector network on\ngenerated trajectories to learn a distribution over multiple generators. We\nshow that our framework achieves state-of-the-art performance compared with\nseveral baselines on different challenging datasets.",
            "author": [
                "Peiyuan Zhu",
                "Fengxia Han",
                "Hao Deng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02835v1",
                "http://arxiv.org/pdf/2311.02835v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02834v1",
            "title": "CAME: Competitively Learning a Mixture-of-Experts Model for First-stage\n  Retrieval",
            "updated": "2023-11-06T02:42:41Z",
            "published": "2023-11-06T02:42:41Z",
            "summary": "The first-stage retrieval aims to retrieve a subset of candidate documents\nfrom a huge collection both effectively and efficiently. Since various matching\npatterns can exist between queries and relevant documents, previous work tries\nto combine multiple retrieval models to find as many relevant results as\npossible. The constructed ensembles, whether learned independently or jointly,\ndo not care which component model is more suitable to an instance during\ntraining. Thus, they cannot fully exploit the capabilities of different types\nof retrieval models in identifying diverse relevance patterns. Motivated by\nthis observation, in this paper, we propose a Mixture-of-Experts (MoE) model\nconsisting of representative matching experts and a novel competitive learning\nmechanism to let the experts develop and enhance their expertise during\ntraining. Specifically, our MoE model shares the bottom layers to learn common\nsemantic representations and uses differently structured upper layers to\nrepresent various types of retrieval experts. Our competitive learning\nmechanism has two stages: (1) a standardized learning stage to train the\nexperts equally to develop their capabilities to conduct relevance matching;\n(2) a specialized learning stage where the experts compete with each other on\nevery training instance and get rewards and updates according to their\nperformance to enhance their expertise on certain types of samples.\nExperimental results on three retrieval benchmark datasets show that our method\nsignificantly outperforms the state-of-the-art baselines.",
            "author": [
                "Yinqiong Cai",
                "Yixing Fan",
                "Keping Bi",
                "Jiafeng Guo",
                "Wei Chen",
                "Ruqing Zhang",
                "Xueqi Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02834v1",
                "http://arxiv.org/pdf/2311.02834v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02832v1",
            "title": "Prioritized Propagation in Graph Neural Networks",
            "updated": "2023-11-06T02:38:35Z",
            "published": "2023-11-06T02:38:35Z",
            "summary": "Graph neural networks (GNNs) have recently received significant attention.\nLearning node-wise message propagation in GNNs aims to set personalized\npropagation steps for different nodes in the graph. Despite the success,\nexisting methods ignore node priority that can be reflected by node influence\nand heterophily. In this paper, we propose a versatile framework PPro, which\ncan be integrated with most existing GNN models and aim to learn prioritized\nnode-wise message propagation in GNNs. Specifically, the framework consists of\nthree components: a backbone GNN model, a propagation controller to determine\nthe optimal propagation steps for nodes, and a weight controller to compute the\npriority scores for nodes. We design a mutually enhanced mechanism to compute\nnode priority, optimal propagation step and label prediction. We also propose\nan alternative optimization strategy to learn the parameters in the backbone\nGNN model and two parametric controllers. We conduct extensive experiments to\ncompare our framework with other 11 state-of-the-art competitors on 8 benchmark\ndatasets. Experimental results show that our framework can lead to superior\nperformance in terms of propagation strategies and node representations.",
            "author": [
                "Yao Cheng",
                "Minjie Chen",
                "Xiang Li",
                "Caihua Shan",
                "Ming Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02832v1",
                "http://arxiv.org/pdf/2311.02832v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02827v1",
            "title": "On Subagging Boosted Probit Model Trees",
            "updated": "2023-11-06T02:22:16Z",
            "published": "2023-11-06T02:22:16Z",
            "summary": "With the insight of variance-bias decomposition, we design a new hybrid\nbagging-boosting algorithm named SBPMT for classification problems. For the\nboosting part of SBPMT, we propose a new tree model called Probit Model Tree\n(PMT) as base classifiers in AdaBoost procedure. For the bagging part, instead\nof subsampling from the dataset at each step of boosting, we perform boosted\nPMTs on each subagged dataset and combine them into a powerful \"committee\",\nwhich can be viewed an incomplete U-statistic. Our theoretical analysis shows\nthat (1) SBPMT is consistent under certain assumptions, (2) Increase the\nsubagging times can reduce the generalization error of SBPMT to some extent and\n(3) Large number of ProbitBoost iterations in PMT can benefit the performance\nof SBPMT with fewer steps in the AdaBoost part. Those three properties are\nverified by a famous simulation designed by Mease and Wyner (2008). The last\ntwo points also provide a useful guidance in model tuning. A comparison of\nperformance with other state-of-the-art classification methods illustrates that\nthe proposed SBPMT algorithm has competitive prediction power in general and\nperforms significantly better in some cases.",
            "author": [
                "Tian Qin",
                "Wei-Min Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02827v1",
                "http://arxiv.org/pdf/2311.02827v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02826v1",
            "title": "InstructPix2NeRF: Instructed 3D Portrait Editing from a Single Image",
            "updated": "2023-11-06T02:21:11Z",
            "published": "2023-11-06T02:21:11Z",
            "summary": "With the success of Neural Radiance Field (NeRF) in 3D-aware portrait\nediting, a variety of works have achieved promising results regarding both\nquality and 3D consistency. However, these methods heavily rely on per-prompt\noptimization when handling natural language as editing instructions. Due to the\nlack of labeled human face 3D datasets and effective architectures, the area of\nhuman-instructed 3D-aware editing for open-world portraits in an end-to-end\nmanner remains under-explored. To solve this problem, we propose an end-to-end\ndiffusion-based framework termed InstructPix2NeRF, which enables instructed\n3D-aware portrait editing from a single open-world image with human\ninstructions. At its core lies a conditional latent 3D diffusion process that\nlifts 2D editing to 3D space by learning the correlation between the paired\nimages' difference and the instructions via triplet data. With the help of our\nproposed token position randomization strategy, we could even achieve\nmulti-semantic editing through one single pass with the portrait identity\nwell-preserved. Besides, we further propose an identity consistency module that\ndirectly modulates the extracted identity signals into our diffusion process,\nwhich increases the multi-view 3D identity consistency. Extensive experiments\nverify the effectiveness of our method and show its superiority against strong\nbaselines quantitatively and qualitatively.",
            "author": [
                "Jianhui Li",
                "Shilong Liu",
                "Zidong Liu",
                "Yikai Wang",
                "Kaiwen Zheng",
                "Jinghui Xu",
                "Jianmin Li",
                "Jun Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02826v1",
                "http://arxiv.org/pdf/2311.02826v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02818v3",
            "title": "Signal Processing Meets SGD: From Momentum to Filter",
            "updated": "2023-11-24T06:36:55Z",
            "published": "2023-11-06T01:41:46Z",
            "summary": "In the field of deep learning, Stochastic Gradient Descent (SGD) and its\nmomentum-based variants are the predominant choices for optimization\nalgorithms. Despite all that, these momentum strategies, which accumulate\nhistorical gradients by using a fixed $\\beta$ hyperparameter to smooth the\noptimization processing, often neglect the potential impact of the variance of\nhistorical gradients on the current gradient estimation. In the gradient\nvariance during training, fluctuation indicates the objective function does not\nmeet the Lipschitz continuity condition at all time, which raises the\ntroublesome optimization problem. This paper aims to explore the potential\nbenefits of reducing the variance of historical gradients to make optimizer\nconverge to flat solutions. Moreover, we proposed a new optimization method\nbased on reducing the variance. We employed the Wiener filter theory to enhance\nthe first moment estimation of SGD, notably introducing an adaptive weight to\noptimizer. Specifically, the adaptive weight dynamically changes along with\ntemporal fluctuation of gradient variance during deep learning model training.\nExperimental results demonstrated our proposed adaptive weight optimizer, SGDF\n(Stochastic Gradient Descent With Filter), can achieve satisfactory performance\ncompared with state-of-the-art optimizers.",
            "author": [
                "Zhipeng Yao",
                "Guisong Chang",
                "Jiaqi Zhang",
                "Qi Zhang",
                "Yu Zhang",
                "Dazhou Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02818v3",
                "http://arxiv.org/pdf/2311.02818v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02816v1",
            "title": "APGL4SR: A Generic Framework with Adaptive and Personalized Global\n  Collaborative Information in Sequential Recommendation",
            "updated": "2023-11-06T01:33:24Z",
            "published": "2023-11-06T01:33:24Z",
            "summary": "The sequential recommendation system has been widely studied for its\npromising effectiveness in capturing dynamic preferences buried in users'\nsequential behaviors. Despite the considerable achievements, existing methods\nusually focus on intra-sequence modeling while overlooking exploiting global\ncollaborative information by inter-sequence modeling, resulting in inferior\nrecommendation performance. Therefore, previous works attempt to tackle this\nproblem with a global collaborative item graph constructed by pre-defined\nrules. However, these methods neglect two crucial properties when capturing\nglobal collaborative information, i.e., adaptiveness and personalization,\nyielding sub-optimal user representations. To this end, we propose a\ngraph-driven framework, named Adaptive and Personalized Graph Learning for\nSequential Recommendation (APGL4SR), that incorporates adaptive and\npersonalized global collaborative information into sequential recommendation\nsystems. Specifically, we first learn an adaptive global graph among all items\nand capture global collaborative information with it in a self-supervised\nfashion, whose computational burden can be further alleviated by the proposed\nSVD-based accelerator. Furthermore, based on the graph, we propose to extract\nand utilize personalized item correlations in the form of relative positional\nencoding, which is a highly compatible manner of personalizing the utilization\nof global collaborative information. Finally, the entire framework is optimized\nin a multi-task learning paradigm, thus each part of APGL4SR can be mutually\nreinforced. As a generic framework, APGL4SR can outperform other baselines with\nsignificant margins. The code is available at\nhttps://github.com/Graph-Team/APGL4SR.",
            "author": [
                "Mingjia Yin",
                "Hao Wang",
                "Xiang Xu",
                "Likang Wu",
                "Sirui Zhao",
                "Wei Guo",
                "Yong Liu",
                "Ruiming Tang",
                "Defu Lian",
                "Enhong Chen"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3583780.3614781",
                "http://arxiv.org/abs/2311.02816v1",
                "http://arxiv.org/pdf/2311.02816v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02815v1",
            "title": "Efficient, Self-Supervised Human Pose Estimation with Inductive Prior\n  Tuning",
            "updated": "2023-11-06T01:19:57Z",
            "published": "2023-11-06T01:19:57Z",
            "summary": "The goal of 2D human pose estimation (HPE) is to localize anatomical\nlandmarks, given an image of a person in a pose. SOTA techniques make use of\nthousands of labeled figures (finetuning transformers or training deep CNNs),\nacquired using labor-intensive crowdsourcing. On the other hand,\nself-supervised methods re-frame the HPE task as a reconstruction problem,\nenabling them to leverage the vast amount of unlabeled visual data, though at\nthe present cost of accuracy. In this work, we explore ways to improve\nself-supervised HPE. We (1) analyze the relationship between reconstruction\nquality and pose estimation accuracy, (2) develop a model pipeline that\noutperforms the baseline which inspired our work, using less than one-third the\namount of training data, and (3) offer a new metric suitable for\nself-supervised settings that measures the consistency of predicted body part\nlength proportions. We show that a combination of well-engineered\nreconstruction losses and inductive priors can help coordinate pose learning\nalongside reconstruction in a self-supervised paradigm.",
            "author": [
                "Nobline Yoo",
                "Olga Russakovsky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02815v1",
                "http://arxiv.org/pdf/2311.02815v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02807v1",
            "title": "QualEval: Qualitative Evaluation for Model Improvement",
            "updated": "2023-11-06T00:21:44Z",
            "published": "2023-11-06T00:21:44Z",
            "summary": "Quantitative evaluation metrics have traditionally been pivotal in gauging\nthe advancements of artificial intelligence systems, including large language\nmodels (LLMs). However, these metrics have inherent limitations. Given the\nintricate nature of real-world tasks, a single scalar to quantify and compare\nis insufficient to capture the fine-grained nuances of model behavior. Metrics\nserve only as a way to compare and benchmark models, and do not yield\nactionable diagnostics, thus making the model improvement process challenging.\nModel developers find themselves amid extensive manual efforts involving\nsifting through vast datasets and attempting hit-or-miss adjustments to\ntraining data or setups. In this work, we address the shortcomings of\nquantitative metrics by proposing QualEval, which augments quantitative scalar\nmetrics with automated qualitative evaluation as a vehicle for model\nimprovement. QualEval uses a powerful LLM reasoner and our novel flexible\nlinear programming solver to generate human-readable insights that when\napplied, accelerate model improvement. The insights are backed by a\ncomprehensive dashboard with fine-grained visualizations and\nhuman-interpretable analyses. We corroborate the faithfulness of QualEval by\ndemonstrating that leveraging its insights, for example, improves the absolute\nperformance of the Llama 2 model by up to 15% points relative on a challenging\ndialogue task (DialogSum) when compared to baselines. QualEval successfully\nincreases the pace of model development, thus in essence serving as a\ndata-scientist-in-a-box. Given the focus on critiquing and improving current\nevaluation metrics, our method serves as a refreshingly new technique for both\nmodel evaluation and improvement.",
            "author": [
                "Vishvak Murahari",
                "Ameet Deshpande",
                "Peter Clark",
                "Tanmay Rajpurohit",
                "Ashish Sabharwal",
                "Karthik Narasimhan",
                "Ashwin Kalyan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02807v1",
                "http://arxiv.org/pdf/2311.02807v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02801v1",
            "title": "On the Intersection of Self-Correction and Trust in Language Models",
            "updated": "2023-11-06T00:04:12Z",
            "published": "2023-11-06T00:04:12Z",
            "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nperforming complex cognitive tasks. However, their complexity and lack of\ntransparency have raised several trustworthiness concerns, including the\npropagation of misinformation and toxicity. Recent research has explored the\nself-correction capabilities of LLMs to enhance their performance. In this\nwork, we investigate whether these self-correction capabilities can be\nharnessed to improve the trustworthiness of LLMs. We conduct experiments\nfocusing on two key aspects of trustworthiness: truthfulness and toxicity. Our\nfindings reveal that self-correction can lead to improvements in toxicity and\ntruthfulness, but the extent of these improvements varies depending on the\nspecific aspect of trustworthiness and the nature of the task. Interestingly,\nour study also uncovers instances of \"self-doubt\" in LLMs during the\nself-correction process, introducing a new set of challenges that need to be\naddressed.",
            "author": [
                "Satyapriya Krishna"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02801v1",
                "http://arxiv.org/pdf/2311.02801v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02798v1",
            "title": "From molecules to scaffolds to functional groups: building\n  context-dependent molecular representation via multi-channel learning",
            "updated": "2023-11-05T23:47:52Z",
            "published": "2023-11-05T23:47:52Z",
            "summary": "Reliable molecular property prediction is essential for various scientific\nendeavors and industrial applications, such as drug discovery. However, the\nscarcity of data, combined with the highly non-linear causal relationships\nbetween physicochemical and biological properties and conventional molecular\nfeaturization schemes, complicates the development of robust molecular machine\nlearning models. Self-supervised learning (SSL) has emerged as a popular\nsolution, utilizing large-scale, unannotated molecular data to learn a\nfoundational representation of chemical space that might be advantageous for\ndownstream tasks. Yet, existing molecular SSL methods largely overlook\ndomain-specific knowledge, such as molecular similarity and scaffold\nimportance, as well as the context of the target application when operating\nover the large chemical space. This paper introduces a novel learning framework\nthat leverages the knowledge of structural hierarchies within molecular\nstructures, embeds them through separate pre-training tasks over distinct\nchannels, and employs a task-specific channel selection to compose a\ncontext-dependent representation. Our approach demonstrates competitive\nperformance across various molecular property benchmarks and establishes some\nstate-of-the-art results. It further offers unprecedented advantages in\nparticularly challenging yet ubiquitous scenarios like activity cliffs with\nenhanced robustness and generalizability compared to other baselines.",
            "author": [
                "Yue Wan",
                "Jialu Wu",
                "Tingjun Hou",
                "Chang-Yu Hsieh",
                "Xiaowei Jia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02798v1",
                "http://arxiv.org/pdf/2311.02798v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.chem-ph",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02794v1",
            "title": "Modelling Cellular Perturbations with the Sparse Additive Mechanism\n  Shift Variational Autoencoder",
            "updated": "2023-11-05T23:37:31Z",
            "published": "2023-11-05T23:37:31Z",
            "summary": "Generative models of observations under interventions have been a vibrant\ntopic of interest across machine learning and the sciences in recent years. For\nexample, in drug discovery, there is a need to model the effects of diverse\ninterventions on cells in order to characterize unknown biological mechanisms\nof action. We propose the Sparse Additive Mechanism Shift Variational\nAutoencoder, SAMS-VAE, to combine compositionality, disentanglement, and\ninterpretability for perturbation models. SAMS-VAE models the latent state of a\nperturbed sample as the sum of a local latent variable capturing\nsample-specific variation and sparse global variables of latent intervention\neffects. Crucially, SAMS-VAE sparsifies these global latent variables for\nindividual perturbations to identify disentangled, perturbation-specific latent\nsubspaces that are flexibly composable. We evaluate SAMS-VAE both\nquantitatively and qualitatively on a range of tasks using two popular single\ncell sequencing datasets. In order to measure perturbation-specific\nmodel-properties, we also introduce a framework for evaluation of perturbation\nmodels based on average treatment effects with links to posterior predictive\nchecks. SAMS-VAE outperforms comparable models in terms of generalization\nacross in-distribution and out-of-distribution tasks, including a combinatorial\nreasoning task under resource paucity, and yields interpretable latent\nstructures which correlate strongly to known biological mechanisms. Our results\nsuggest SAMS-VAE is an interesting addition to the modeling toolkit for machine\nlearning-driven scientific discovery.",
            "author": [
                "Michael Bereket",
                "Theofanis Karaletsos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02794v1",
                "http://arxiv.org/pdf/2311.02794v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02790v1",
            "title": "CausalCite: A Causal Formulation of Paper Citations",
            "updated": "2023-11-05T23:09:39Z",
            "published": "2023-11-05T23:09:39Z",
            "summary": "Evaluating the significance of a paper is pivotal yet challenging for the\nscientific community. While the citation count is the most commonly used proxy\nfor this purpose, they are widely criticized for failing to accurately reflect\na paper's true impact. In this work, we propose a causal inference method,\nTextMatch, which adapts the traditional matching framework to high-dimensional\ntext embeddings. Specifically, we encode each paper using the text embeddings\nby large language models (LLMs), extract similar samples by cosine similarity,\nand synthesize a counterfactual sample by the weighted average of similar\npapers according to their similarity values. We apply the resulting metric,\ncalled CausalCite, as a causal formulation of paper citations. We show its\neffectiveness on various criteria, such as high correlation with paper impact\nas reported by scientific experts on a previous dataset of 1K papers,\n(test-of-time) awards for past papers, and its stability across various\nsub-fields of AI. We also provide a set of findings that can serve as suggested\nways for future researchers to use our metric for a better understanding of a\npaper's quality. Our code and data are at\nhttps://github.com/causalNLP/causal-cite.",
            "author": [
                "Ishan Kumar",
                "Zhijing Jin",
                "Ehsan Mokhtarian",
                "Siyuan Guo",
                "Yuen Chen",
                "Negar Kiyavash",
                "Mrinmaya Sachan",
                "Bernhard Schoelkopf"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02790v1",
                "http://arxiv.org/pdf/2311.02790v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02788v1",
            "title": "Machine learning regression analyses of intensity modulation two-photon\n  spectroscopy (Mlim) in perovskite microcrystals",
            "updated": "2023-11-05T22:59:03Z",
            "published": "2023-11-05T22:59:03Z",
            "summary": "Perovskite thin films hold great promise for optoelectronic applications,\nsuch as solar cells and light emitting diodes. A challenge is that defects are\nunavoidably formed in the material. Thorough understanding of the defect\nformation and their dynamics has proven challenging based on traditional\nspectroscopy. Here we integrated the functional intensity modulation two-photon\nspectroscopy with artificial intelligence - enhance data analyses to obtain a\ndeep understanding of defect-related trap states within perovskite\nmicrocrystals. We introduce a novel charge carrier recombination dynamics model\nthat comprehensively includes exciton and electron-hole pair photoluminescence\n(PL) emissions, as well as the trapping and detrapping equilibrium dynamics. By\nvarying parameters in the dynamic model, a large pool of the temperature\ndependent intensity modulation PL spectra can be simulated by solving the\nordinary differential equations in the charge carrier dynamics model. Then,\ntree-based supervised machine learning methods and ensemble technique --\nregression chain have been used to optimize the Machine learning intensity\nmodulation spectroscopy (Mlim), which helps to determine the parameters of the\ncharge carrier dynamics model based on the temperature dependent intensity\nmodulated PL spectra in perovskite. And the reliability of the Mlim predicted\ntrap property parameters is confirmed by directly comparing the Mlim-retrieved\nintensity modulation spectra with experimental data. Besides, our approach\nunravels valuable insights into PL emissions, including those from excitons and\nfree electron-hole pairs, but also provides details of trapping, detrapping,\nand nonradiative depopulation processes, offering a comprehensive understanding\nof perovskite material photophysics. This study suggests that Mlim applications\nhold promise for studying various photoactive devices.",
            "author": [
                "Qi Shi",
                "T\u00f6nu Pullerits"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02788v1",
                "http://arxiv.org/pdf/2311.02788v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02787v1",
            "title": "Make a Donut: Language-Guided Hierarchical EMD-Space Planning for\n  Zero-shot Deformable Object Manipulation",
            "updated": "2023-11-05T22:43:29Z",
            "published": "2023-11-05T22:43:29Z",
            "summary": "Deformable object manipulation stands as one of the most captivating yet\nformidable challenges in robotics. While previous techniques have predominantly\nrelied on learning latent dynamics through demonstrations, typically\nrepresented as either particles or images, there exists a pertinent limitation:\nacquiring suitable demonstrations, especially for long-horizon tasks, can be\nelusive. Moreover, basing learning entirely on demonstrations can hamper the\nmodel's ability to generalize beyond the demonstrated tasks. In this work, we\nintroduce a demonstration-free hierarchical planning approach capable of\ntackling intricate long-horizon tasks without necessitating any training. We\nemploy large language models (LLMs) to articulate a high-level, stage-by-stage\nplan corresponding to a specified task. For every individual stage, the LLM\nprovides both the tool's name and the Python code to craft intermediate subgoal\npoint clouds. With the tool and subgoal for a particular stage at our disposal,\nwe present a granular closed-loop model predictive control strategy. This\nleverages Differentiable Physics with Point-to-Point correspondence\n(DiffPhysics-P2P) loss in the earth mover distance (EMD) space, applied\niteratively. Experimental findings affirm that our technique surpasses multiple\nbenchmarks in dough manipulation, spanning both short and long horizons.\nRemarkably, our model demonstrates robust generalization capabilities to novel\nand previously unencountered complex tasks without any preliminary\ndemonstrations. We further substantiate our approach with experimental trials\non real-world robotic platforms.",
            "author": [
                "Yang You",
                "Bokui Shen",
                "Congyue Deng",
                "Haoran Geng",
                "He Wang",
                "Leonidas Guibas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02787v1",
                "http://arxiv.org/pdf/2311.02787v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04930v1",
            "title": "Large language models implicitly learn to straighten neural sentence\n  trajectories to construct a predictive representation of natural language",
            "updated": "2023-11-05T22:16:21Z",
            "published": "2023-11-05T22:16:21Z",
            "summary": "Predicting upcoming events is critical to our ability to interact with our\nenvironment. Transformer models, trained on next-word prediction, appear to\nconstruct representations of linguistic input that can support diverse\ndownstream tasks. But how does a predictive objective shape such\nrepresentations? Inspired by recent work in vision (Henaff et al., 2019), we\ntest a hypothesis about predictive representations of autoregressive\ntransformers. In particular, we test whether the neural trajectory of a\nsentence becomes progressively straighter as it passes through the network\nlayers. The key insight is that straighter trajectories should facilitate\nprediction via linear extrapolation. We quantify straightness using a\n1-dimensional curvature metric, and present four findings in support of the\ntrajectory straightening hypothesis: i) In trained models, the curvature\ndecreases from the early to the deeper layers of the network. ii) Models that\nperform better on the next-word prediction objective exhibit greater decreases\nin curvature, suggesting that this improved ability to straighten sentence\ntrajectories may be the driver of better language modeling performance. iii)\nGiven the same linguistic context, the sequences that are generated by the\nmodel have lower curvature than the actual continuations observed in a language\ncorpus, suggesting that the model favors straighter trajectories for making\npredictions. iv) A consistent relationship holds between the average curvature\nand the average surprisal of sentences in the deep model layers, such that\nsentences with straighter trajectories also have lower surprisal. Importantly,\nuntrained models do not exhibit these behaviors. In tandem, these results\nsupport the trajectory straightening hypothesis and provide a possible\nmechanism for how the geometry of the internal representations of\nautoregressive models supports next word prediction.",
            "author": [
                "Eghbal A. Hosseini",
                "Evelina Fedorenko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04930v1",
                "http://arxiv.org/pdf/2311.04930v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02781v1",
            "title": "Architecting Intermediate Layers for Efficient Composition of Data\n  Management and Machine Learning Systems",
            "updated": "2023-11-05T22:04:23Z",
            "published": "2023-11-05T22:04:23Z",
            "summary": "Modern data analytics workloads combine relational data processing with\nmachine learning (ML). Most DBMS handle these workloads by offloading these ML\noperations to external specialized ML systems. While both DBMS and ML systems\ngo to great lengths to optimize performance for their specific workloads,\nsignificant performance is lost when used in combination, due to data movement\nacross system boundaries, conversions between incompatible internal data\nformats, and the lack of cross system optimizations.\n  A key idea to remove these bottlenecks is to integrate existing data\nmanipulation systems with ML systems by building a common intermediate layer\n(IR). Although this idea has been explored before (Weld, Delite), previous such\nattempts require significant re-engineering of prior systems and still fall\nshort in achieving best-of-breed performance for individual tasks (e.g., SQL,\nDeep Learning). Specifically, they rely on re-implementing existing systems\nusing a generic set of operators and fail to match best-of-breed individual\nperformance due to the inability to recover high-level optimizations from this\ngeneric IR through compiler analysis.\n  We present Flern, the first intermediate-layer integration between DB and ML\nsystems that are best-of-breed individually, competitive with the best compiled\nquery engines such as HyPer on comprehensive relational benchmarks (TPC-H) and\ncompetitive with TensorFlow and PyTorch in state-of-the-art ML models (e.g.,\nDeepSpeech, SqueezeNet, Transformers) and also represents a new\nstate-of-the-art for integration. A key realization is to architect\nintermediate layers based on generative programming capabilities, which\npreserves high-level contextual information for cross optimizations and enables\nthe construction of a variety of complex structures and cross system\noptimizations with minimal effort.",
            "author": [
                "Supun Abeysinghe",
                "Fei Wang",
                "Gregory Essertel",
                "Tiark Rompf"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02781v1",
                "http://arxiv.org/pdf/2311.02781v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02778v1",
            "title": "MuSHRoom: Multi-Sensor Hybrid Room Dataset for Joint 3D Reconstruction\n  and Novel View Synthesis",
            "updated": "2023-11-05T21:46:12Z",
            "published": "2023-11-05T21:46:12Z",
            "summary": "Metaverse technologies demand accurate, real-time, and immersive modeling on\nconsumer-grade hardware for both non-human perception (e.g.,\ndrone/robot/autonomous car navigation) and immersive technologies like AR/VR,\nrequiring both structural accuracy and photorealism. However, there exists a\nknowledge gap in how to apply geometric reconstruction and photorealism\nmodeling (novel view synthesis) in a unified framework.\n  To address this gap and promote the development of robust and immersive\nmodeling and rendering with consumer-grade devices, first, we propose a\nreal-world Multi-Sensor Hybrid Room Dataset (MuSHRoom). Our dataset presents\nexciting challenges and requires state-of-the-art methods to be cost-effective,\nrobust to noisy data and devices, and can jointly learn 3D reconstruction and\nnovel view synthesis, instead of treating them as separate tasks, making them\nideal for real-world applications. Second, we benchmark several famous\npipelines on our dataset for joint 3D mesh reconstruction and novel view\nsynthesis. Finally, in order to further improve the overall performance, we\npropose a new method that achieves a good trade-off between the two tasks. Our\ndataset and benchmark show great potential in promoting the improvements for\nfusing 3D reconstruction and high-quality rendering in a robust and\ncomputationally efficient end-to-end fashion.",
            "author": [
                "Xuqian Ren",
                "Wenjia Wang",
                "Dingding Cai",
                "Tuuli Tuominen",
                "Juho Kannala",
                "Esa Rahtu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02778v1",
                "http://arxiv.org/pdf/2311.02778v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02777v1",
            "title": "Robust Generalization Strategies for Morpheme Glossing in an Endangered\n  Language Documentation Context",
            "updated": "2023-11-05T21:45:57Z",
            "published": "2023-11-05T21:45:57Z",
            "summary": "Generalization is of particular importance in resource-constrained settings,\nwhere the available training data may represent only a small fraction of the\ndistribution of possible texts. We investigate the ability of morpheme labeling\nmodels to generalize by evaluating their performance on unseen genres of text,\nand we experiment with strategies for closing the gap between performance on\nin-distribution and out-of-distribution data. Specifically, we use weight decay\noptimization, output denoising, and iterative pseudo-labeling, and achieve a 2%\nimprovement on a test set containing texts from unseen genres. All experiments\nare performed using texts written in the Mayan language Uspanteko.",
            "author": [
                "Michael Ginn",
                "Alexis Palmer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02777v1",
                "http://arxiv.org/pdf/2311.02777v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02775v2",
            "title": "ChaTA: Towards an Intelligent Question-Answer Teaching Assistant using\n  Open-Source LLMs",
            "updated": "2023-11-13T16:03:15Z",
            "published": "2023-11-05T21:43:02Z",
            "summary": "Responding to the thousands of student questions on online QA platforms each\nsemester has a considerable human cost, particularly in computing courses with\nrapidly growing enrollments. To address the challenges of scalable and\nintelligent question-answering (QA), we introduce an innovative solution that\nleverages open-source Large Language Models (LLMs) from the LLaMA-2 family to\nensure data privacy. Our approach combines augmentation techniques such as\nretrieval augmented generation (RAG), supervised fine-tuning (SFT), and\nlearning from human preferences data using Direct Preference Optimization\n(DPO). Through extensive experimentation on a Piazza dataset from an\nintroductory CS course, comprising 10,000 QA pairs and 1,500 pairs of\npreference data, we demonstrate a significant 30% improvement in the quality of\nanswers, with RAG being a particularly impactful addition. Our contributions\ninclude the development of a novel architecture for educational QA, extensive\nevaluations of LLM performance utilizing both human assessments and LLM-based\nmetrics, and insights into the challenges and future directions of educational\ndata processing. This work paves the way for the development of CHATA, an\nintelligent QA assistant customizable for courses with an online QA platform",
            "author": [
                "Yann Hicke",
                "Anmol Agarwal",
                "Qianou Ma",
                "Paul Denny"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02775v2",
                "http://arxiv.org/pdf/2311.02775v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03405v2",
            "title": "Communication Efficient and Privacy-Preserving Federated Learning Based\n  on Evolution Strategies",
            "updated": "2023-11-09T01:41:36Z",
            "published": "2023-11-05T21:40:46Z",
            "summary": "Federated learning (FL) is an emerging paradigm for training deep neural\nnetworks (DNNs) in distributed manners. Current FL approaches all suffer from\nhigh communication overhead and information leakage. In this work, we present a\nfederated learning algorithm based on evolution strategies (FedES), a\nzeroth-order training method. Instead of transmitting model parameters, FedES\nonly communicates loss values, and thus has very low communication overhead.\nMoreover, a third party is unable to estimate gradients without knowing the\npre-shared seed, which protects data privacy. Experimental results demonstrate\nFedES can achieve the above benefits while keeping convergence performance the\nsame as that with back propagation methods.",
            "author": [
                "Guangchen Lan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03405v2",
                "http://arxiv.org/pdf/2311.03405v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02766v2",
            "title": "Riemannian Laplace Approximation with the Fisher Metric",
            "updated": "2023-11-08T00:31:22Z",
            "published": "2023-11-05T20:51:03Z",
            "summary": "The Laplace's method approximates a target density with a Gaussian\ndistribution at its mode. It is computationally efficient and asymptotically\nexact for Bayesian inference due to the Bernstein-von Mises theorem, but for\ncomplex targets and finite-data posteriors it is often too crude an\napproximation. A recent generalization of the Laplace Approximation transforms\nthe Gaussian approximation according to a chosen Riemannian geometry providing\na richer approximation family, while still retaining computational efficiency.\nHowever, as shown here, its properties heavily depend on the chosen metric,\nindeed the metric adopted in previous work results in approximations that are\noverly narrow as well as being biased even at the limit of infinite data. We\ncorrect this shortcoming by developing the approximation family further,\nderiving two alternative variants that are exact at the limit of infinite data,\nextending the theoretical analysis of the method, and demonstrating practical\nimprovements in a range of experiments.",
            "author": [
                "Hanlin Yu",
                "Marcelo Hartmann",
                "Bernardo Williams",
                "Mark Girolami",
                "Arto Klami"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02766v2",
                "http://arxiv.org/pdf/2311.02766v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02765v1",
            "title": "Rule Learning as Machine Translation using the Atomic Knowledge Bank",
            "updated": "2023-11-05T20:48:54Z",
            "published": "2023-11-05T20:48:54Z",
            "summary": "Machine learning models, and in particular language models, are being applied\nto various tasks that require reasoning. While such models are good at\ncapturing patterns their ability to reason in a trustable and controlled manner\nis frequently questioned. On the other hand, logic-based rule systems allow for\ncontrolled inspection and already established verification methods. However it\nis well-known that creating such systems manually is time-consuming and prone\nto errors. We explore the capability of transformers to translate sentences\nexpressing rules in natural language into logical rules. We see reasoners as\nthe most reliable tools for performing logical reasoning and focus on\ntranslating language into the format expected by such tools. We perform\nexperiments using the DKET dataset from the literature and create a dataset for\nlanguage to logic translation based on the Atomic knowledge bank.",
            "author": [
                "Kristoffer \u00c6s\u00f8y",
                "Ana Ozaki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02765v1",
                "http://arxiv.org/pdf/2311.02765v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02763v1",
            "title": "Log-Concavity of Multinomial Likelihood Functions Under Interval\n  Censoring Constraints on Frequencies or Their Partial Sums",
            "updated": "2023-11-05T20:44:08Z",
            "published": "2023-11-05T20:44:08Z",
            "summary": "We show that the likelihood function for a multinomial vector observed under\narbitrary interval censoring constraints on the frequencies or their partial\nsums is completely log-concave by proving that the constrained sample spaces\ncomprise M-convex subsets of the discrete simplex.",
            "author": [
                "Bruce Levin",
                "Erik Learned-Miller"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02763v1",
                "http://arxiv.org/pdf/2311.02763v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "cs.LG",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02762v2",
            "title": "Fast Sparse 3D Convolution Network with VDB",
            "updated": "2023-11-15T04:38:09Z",
            "published": "2023-11-05T20:43:46Z",
            "summary": "We proposed a new Convolution Neural Network implementation optimized for\nsparse 3D data inference. This implementation uses NanoVDB as the data\nstructure to store the sparse tensor. It leaves a relatively small memory\nfootprint while maintaining high performance. We demonstrate that this\narchitecture is around 20 times faster than the state-of-the-art dense CNN\nmodel on a high-resolution 3D object classification network.",
            "author": [
                "Fangjun Zhou",
                "Anyong Mao",
                "Eftychios Sifakis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02762v2",
                "http://arxiv.org/pdf/2311.02762v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02761v1",
            "title": "One-Shot Strategic Classification Under Unknown Costs",
            "updated": "2023-11-05T20:43:08Z",
            "published": "2023-11-05T20:43:08Z",
            "summary": "A primary goal in strategic classification is to learn decision rules which\nare robust to strategic input manipulation. Earlier works assume that strategic\nresponses are known; while some recent works address the important challenge of\nunknown responses, they exclusively study sequential settings which allow\nmultiple model deployments over time. But there are many\ndomains$\\unicode{x2014}$particularly in public policy, a common motivating\nuse-case$\\unicode{x2014}$where multiple deployments are unrealistic, or where\neven a single bad round is undesirable. To address this gap, we initiate the\nstudy of strategic classification under unknown responses in the one-shot\nsetting, which requires committing to a single classifier once. Focusing on the\nusers' cost function as the source of uncertainty, we begin by proving that for\na broad class of costs, even a small mis-estimation of the true cost can entail\narbitrarily low accuracy in the worst case. In light of this, we frame the\none-shot task as a minimax problem, with the goal of identifying the classifier\nwith the smallest worst-case risk over an uncertainty set of possible costs.\nOur main contribution is efficient algorithms for both the full-batch and\nstochastic settings, which we prove converge (offline) to the minimax optimal\nsolution at the dimension-independent rate of\n$\\tilde{\\mathcal{O}}(T^{-\\frac{1}{2}})$. Our analysis reveals important\nstructure stemming from the strategic nature of user responses, particularly\nthe importance of dual norm regularization with respect to the cost function.",
            "author": [
                "Elan Rosenfeld",
                "Nir Rosenfeld"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02761v1",
                "http://arxiv.org/pdf/2311.02761v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.GT",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02760v1",
            "title": "Causal Question Answering with Reinforcement Learning",
            "updated": "2023-11-05T20:33:18Z",
            "published": "2023-11-05T20:33:18Z",
            "summary": "Causal questions inquire about causal relationships between different events\nor phenomena. Specifically, they often aim to determine whether there is a\nrelationship between two phenomena, or to identify all causes/effects of a\nphenomenon. Causal questions are important for a variety of use cases,\nincluding virtual assistants and search engines. However, many current\napproaches to causal question answering cannot provide explanations or evidence\nfor their answers. Hence, in this paper, we aim to answer causal questions with\nCauseNet, a large-scale dataset of causal relations and their provenance data.\nInspired by recent, successful applications of reinforcement learning to\nknowledge graph tasks, such as link prediction and fact-checking, we explore\nthe application of reinforcement learning on CauseNet for causal question\nanswering. We introduce an Actor-Critic based agent which learns to search\nthrough the graph to answer causal questions. We bootstrap the agent with a\nsupervised learning procedure to deal with large action spaces and sparse\nrewards. Our evaluation shows that the agent successfully prunes the search\nspace to answer binary causal questions by visiting less than 30 nodes per\nquestion compared to over 3,000 nodes by a naive breadth-first search. Our\nablation study indicates that our supervised learning strategy provides a\nstrong foundation upon which our reinforcement learning agent improves. The\npaths returned by our agent explain the mechanisms by which a cause produces an\neffect. Moreover, for each edge on a path, CauseNet stores its original source\non the web allowing for easy verification of paths.",
            "author": [
                "Lukas Bl\u00fcbaum",
                "Stefan Heindorf"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02760v1",
                "http://arxiv.org/pdf/2311.02760v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02757v1",
            "title": "ELEGANT: Certified Defense on the Fairness of Graph Neural Networks",
            "updated": "2023-11-05T20:29:40Z",
            "published": "2023-11-05T20:29:40Z",
            "summary": "Graph Neural Networks (GNNs) have emerged as a prominent graph learning model\nin various graph-based tasks over the years. Nevertheless, due to the\nvulnerabilities of GNNs, it has been empirically proved that malicious\nattackers could easily corrupt the fairness level of their predictions by\nadding perturbations to the input graph data. In this paper, we take crucial\nsteps to study a novel problem of certifiable defense on the fairness level of\nGNNs. Specifically, we propose a principled framework named ELEGANT and present\na detailed theoretical certification analysis for the fairness of GNNs. ELEGANT\ntakes any GNNs as its backbone, and the fairness level of such a backbone is\ntheoretically impossible to be corrupted under certain perturbation budgets for\nattackers. Notably, ELEGANT does not have any assumption over the GNN structure\nor parameters, and does not require re-training the GNNs to realize\ncertification. Hence it can serve as a plug-and-play framework for any\noptimized GNNs ready to be deployed. We verify the satisfactory effectiveness\nof ELEGANT in practice through extensive experiments on real-world datasets\nacross different backbones of GNNs, where ELEGANT is also demonstrated to be\nbeneficial for GNN debiasing. Open-source code can be found at\nhttps://github.com/yushundong/ELEGANT.",
            "author": [
                "Yushun Dong",
                "Binchi Zhang",
                "Hanghang Tong",
                "Jundong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02757v1",
                "http://arxiv.org/pdf/2311.02757v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02749v1",
            "title": "Fast Point-cloud to Mesh Reconstruction for Deformable Object Tracking",
            "updated": "2023-11-05T19:59:36Z",
            "published": "2023-11-05T19:59:36Z",
            "summary": "The world around us is full of soft objects that we as humans learn to\nperceive and deform with dexterous hand movements from a young age. In order\nfor a Robotic hand to be able to control soft objects, it needs to acquire\nonline state feedback of the deforming object. While RGB-D cameras can collect\noccluded information at a rate of 30 Hz, the latter does not represent a\ncontinuously trackable object surface. Hence, in this work, we developed a\nmethod that can create deforming meshes of deforming point clouds at a speed of\nabove 50 Hz for different categories of objects. The reconstruction of meshes\nfrom point clouds has been long studied in the field of Computer graphics under\n3D reconstruction and 4D reconstruction, however both lack the speed and\ngeneralizability needed for robotics applications. Our model is designed using\na point cloud auto-encoder and a Real-NVP architecture. The latter is a\ncontinuous flow neural network with manifold-preservation properties. Our model\ntakes a template mesh which is the mesh of an object in its canonical state and\nthen deforms the template mesh to match a deformed point cloud of the object.\nOur method can perform mesh reconstruction and tracking at a rate of 58 Hz for\ndeformations of six different ycb categories. An instance of a downstream\napplication can be the control algorithm for a robotic hand that requires\nonline feedback from the state of a manipulated object which would allow online\ngrasp adaptation in a closed-loop manner. Furthermore, the tracking capacity\nthat our method provides can help in the system identification of deforming\nobjects in a marker-free approach. In future work, we will extend our method to\nmore categories of objects and real world deforming point clouds",
            "author": [
                "Elham Amin Mansour",
                "Hehui Zheng",
                "Robert K. Katzschmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02749v1",
                "http://arxiv.org/pdf/2311.02749v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02747v2",
            "title": "Attention Modules Improve Image-Level Anomaly Detection for Industrial\n  Inspection: A DifferNet Case Study",
            "updated": "2023-11-07T15:54:41Z",
            "published": "2023-11-05T19:48:50Z",
            "summary": "Within (semi-)automated visual industrial inspection, learning-based\napproaches for assessing visual defects, including deep neural networks, enable\nthe processing of otherwise small defect patterns in pixel size on\nhigh-resolution imagery. The emergence of these often rarely occurring defect\npatterns explains the general need for labeled data corpora. To alleviate this\nissue and advance the current state of the art in unsupervised visual\ninspection, this work proposes a DifferNet-based solution enhanced with\nattention modules: AttentDifferNet. It improves image-level detection and\nclassification capabilities on three visual anomaly detection datasets for\nindustrial inspection: InsPLAD-fault, MVTec AD, and Semiconductor Wafer. In\ncomparison to the state of the art, AttentDifferNet achieves improved results,\nwhich are, in turn, highlighted throughout our quali-quantitative study. Our\nquantitative evaluation shows an average improvement - compared to DifferNet -\nof 1.77 +/- 0.25 percentage points in overall AUROC considering all three\ndatasets, reaching SOTA results in InsPLAD-fault, an industrial inspection\nin-the-wild dataset. As our variants to AttentDifferNet show great prospects in\nthe context of currently investigated approaches, a baseline is formulated,\nemphasizing the importance of attention for industrial anomaly detection both\nin the wild and in controlled environments.",
            "author": [
                "Andr\u00e9 Luiz Buarque Vieira e Silva",
                "Francisco Sim\u00f5es",
                "Danny Kowerko",
                "Tobias Schlosser",
                "Felipe Battisti",
                "Veronica Teichrieb"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02747v2",
                "http://arxiv.org/pdf/2311.02747v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02746v1",
            "title": "Staged Reinforcement Learning for Complex Tasks through Decomposed\n  Environments",
            "updated": "2023-11-05T19:43:23Z",
            "published": "2023-11-05T19:43:23Z",
            "summary": "Reinforcement Learning (RL) is an area of growing interest in the field of\nartificial intelligence due to its many notable applications in diverse fields.\nParticularly within the context of intelligent vehicle control, RL has made\nimpressive progress. However, currently it is still in simulated controlled\nenvironments where RL can achieve its full super-human potential. Although how\nto apply simulation experience in real scenarios has been studied, how to\napproximate simulated problems to the real dynamic problems is still a\nchallenge. In this paper, we discuss two methods that approximate RL problems\nto real problems. In the context of traffic junction simulations, we\ndemonstrate that, if we can decompose a complex task into multiple sub-tasks,\nsolving these tasks first can be advantageous to help minimising possible\noccurrences of catastrophic events in the complex task. From a multi-agent\nperspective, we introduce a training structuring mechanism that exploits the\nuse of experience learned under the popular paradigm called Centralised\nTraining Decentralised Execution (CTDE). This experience can then be leveraged\nin fully decentralised settings that are conceptually closer to real settings,\nwhere agents often do not have access to a central oracle and must be treated\nas isolated independent units. The results show that the proposed approaches\nimprove agents performance in complex tasks related to traffic junctions,\nminimising potential safety-critical problems that might happen in these\nscenarios. Although still in simulation, the investigated situations are\nconceptually closer to real scenarios and thus, with these results, we intend\nto motivate further research in the subject.",
            "author": [
                "Rafael Pina",
                "Corentin Artaud",
                "Xiaolan Liu",
                "Varuna De Silva"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02746v1",
                "http://arxiv.org/pdf/2311.02746v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02745v1",
            "title": "The madness of people: rational learning in feedback-evolving games",
            "updated": "2023-11-05T19:33:25Z",
            "published": "2023-11-05T19:33:25Z",
            "summary": "The replicator equation in evolutionary game theory describes the change in a\npopulation's behaviors over time given suitable incentives. It arises when\nindividuals make decisions using a simple learning process - imitation. A\nrecent emerging framework builds upon this standard model by incorporating\ngame-environment feedback, in which the population's actions affect a shared\nenvironment, and in turn, the changing environment shapes incentives for future\nbehaviors. In this paper, we investigate game-environment feedback when\nindividuals instead use a boundedly rational learning rule known as logit\nlearning. We characterize the resulting system's complete set of fixed points\nand their local stability properties, and how the level of rationality\ndetermines overall environmental outcomes in comparison to imitative learning\nrules. We identify a large parameter space for which logit learning exhibits a\nwide range of dynamics as the rationality parameter is increased from low to\nhigh. Notably, we identify a bifurcation point at which the system exhibits\nstable limit cycles. When the population is highly rational, the limit cycle\ncollapses and a tragedy of the commons becomes stable.",
            "author": [
                "Keith Paarporn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02745v1",
                "http://arxiv.org/pdf/2311.02745v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.SY",
                "eess.SY",
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02741v1",
            "title": "Learning Independently from Causality in Multi-Agent Environments",
            "updated": "2023-11-05T19:12:08Z",
            "published": "2023-11-05T19:12:08Z",
            "summary": "Multi-Agent Reinforcement Learning (MARL) comprises an area of growing\ninterest in the field of machine learning. Despite notable advances, there are\nstill problems that require investigation. The lazy agent pathology is a famous\nproblem in MARL that denotes the event when some of the agents in a MARL team\ndo not contribute to the common goal, letting the teammates do all the work. In\nthis work, we aim to investigate this problem from a causality-based\nperspective. We intend to create the bridge between the fields of MARL and\ncausality and argue about the usefulness of this link. We study a fully\ndecentralised MARL setup where agents need to learn cooperation strategies and\nshow that there is a causal relation between individual observations and the\nteam reward. The experiments carried show how this relation can be used to\nimprove independent agents in MARL, resulting not only on better performances\nas a team but also on the rise of more intelligent behaviours on individual\nagents.",
            "author": [
                "Rafael Pina",
                "Varuna De Silva",
                "Corentin Artaud"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02741v1",
                "http://arxiv.org/pdf/2311.02741v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14688v1",
            "title": "Procedural Fairness Through Decoupling Objectionable Data Generating\n  Components",
            "updated": "2023-11-05T19:07:40Z",
            "published": "2023-11-05T19:07:40Z",
            "summary": "We reveal and address the frequently overlooked yet important issue of\ndisguised procedural unfairness, namely, the potentially inadvertent\nalterations on the behavior of neutral (i.e., not problematic) aspects of data\ngenerating process, and/or the lack of procedural assurance of the greatest\nbenefit of the least advantaged individuals. Inspired by John Rawls's advocacy\nfor pure procedural justice, we view automated decision-making as a microcosm\nof social institutions, and consider how the data generating process itself can\nsatisfy the requirements of procedural fairness. We propose a framework that\ndecouples the objectionable data generating components from the neutral ones by\nutilizing reference points and the associated value instantiation rule. Our\nfindings highlight the necessity of preventing disguised procedural unfairness,\ndrawing attention not only to the objectionable data generating components that\nwe aim to mitigate, but also more importantly, to the neutral components that\nwe intend to keep unaffected.",
            "author": [
                "Zeyu Tang",
                "Jialu Wang",
                "Yang Liu",
                "Peter Spirtes",
                "Kun Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14688v1",
                "http://arxiv.org/pdf/2311.14688v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02738v2",
            "title": "Scenario Diffusion: Controllable Driving Scenario Generation With\n  Diffusion",
            "updated": "2023-11-16T23:25:25Z",
            "published": "2023-11-05T19:04:25Z",
            "summary": "Automated creation of synthetic traffic scenarios is a key part of validating\nthe safety of autonomous vehicles (AVs). In this paper, we propose Scenario\nDiffusion, a novel diffusion-based architecture for generating traffic\nscenarios that enables controllable scenario generation. We combine latent\ndiffusion, object detection and trajectory regression to generate distributions\nof synthetic agent poses, orientations and trajectories simultaneously. To\nprovide additional control over the generated scenario, this distribution is\nconditioned on a map and sets of tokens describing the desired scenario. We\nshow that our approach has sufficient expressive capacity to model diverse\ntraffic patterns and generalizes to different geographical regions.",
            "author": [
                "Ethan Pronovost",
                "Meghana Reddy Ganesina",
                "Noureldin Hendy",
                "Zeyu Wang",
                "Andres Morales",
                "Kai Wang",
                "Nicholas Roy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02738v2",
                "http://arxiv.org/pdf/2311.02738v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02737v1",
            "title": "CIRCLE: Multi-Turn Query Clarifications with Reinforcement Learning",
            "updated": "2023-11-05T19:03:06Z",
            "published": "2023-11-05T19:03:06Z",
            "summary": "Users often have trouble formulating their information needs into words on\nthe first try when searching online. This can lead to frustration, as they may\nhave to reformulate their queries when retrieved information is not relevant.\nThis can be due to a lack of familiarity with the specific terminology related\nto their search topic, or because queries are ambiguous and related to multiple\ntopics. Most modern search engines have interactive features that suggest\nclarifications or similar queries based on what others have searched for.\nHowever, the proposed models are either based on a single interaction or\nevaluated on search logs, hindering the naturalness of the interactions. In\nthis paper, we introduce CIRCLE, a generative model for multi-turn query\nClarifications wIth ReinforCement LEarning that leverages multi-turn\ninteractions through a user simulation framework. Our model aims at generating\na diverse set of query clarifications using a pretrained language model\nfine-tuned using reinforcement learning. We evaluate it against well\nestablished google suggestions using a user simulation framework.",
            "author": [
                "Pierre Erbacher",
                "Laure Soulier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02737v1",
                "http://arxiv.org/pdf/2311.02737v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02734v1",
            "title": "ISAR: A Benchmark for Single- and Few-Shot Object Instance Segmentation\n  and Re-Identification",
            "updated": "2023-11-05T18:51:33Z",
            "published": "2023-11-05T18:51:33Z",
            "summary": "Most object-level mapping systems in use today make use of an upstream\nlearned object instance segmentation model. If we want to teach them about a\nnew object or segmentation class, we need to build a large dataset and retrain\nthe system. To build spatial AI systems that can quickly be taught about new\nobjects, we need to effectively solve the problem of single-shot object\ndetection, instance segmentation and re-identification. So far there is neither\na method fulfilling all of these requirements in unison nor a benchmark that\ncould be used to test such a method. Addressing this, we propose ISAR, a\nbenchmark and baseline method for single- and few-shot object Instance\nSegmentation And Re-identification, in an effort to accelerate the development\nof algorithms that can robustly detect, segment, and re-identify objects from a\nsingle or a few sparse training examples. We provide a semi-synthetic dataset\nof video sequences with ground-truth semantic annotations, a standardized\nevaluation pipeline, and a baseline method. Our benchmark aligns with the\nemerging research trend of unifying Multi-Object Tracking, Video Object\nSegmentation, and Re-identification.",
            "author": [
                "Nicolas Gorlo",
                "Kenneth Blomqvist",
                "Francesco Milano",
                "Roland Siegwart"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02734v1",
                "http://arxiv.org/pdf/2311.02734v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10753v1",
            "title": "Automating Source Code Refactoring in the Classroom",
            "updated": "2023-11-05T18:46:00Z",
            "published": "2023-11-05T18:46:00Z",
            "summary": "Refactoring is the practice of improving software quality without altering\nits external behavior. Developers intuitively refactor their code for multiple\npurposes, such as improving program comprehension, reducing code complexity,\ndealing with technical debt, and removing code smells. However, no prior\nstudies have exposed the students to an experience of the process of\nantipatterns detection and refactoring correction, and provided students with\ntoolset to practice it. To understand and increase the awareness of refactoring\nconcepts, in this paper, we aim to reflect on our experience with teaching\nrefactoring and how it helps students become more aware of bad programming\npractices and the importance of correcting them via refactoring. This paper\ndiscusses the results of an experiment in the classroom that involved carrying\nout various refactoring activities for the purpose of removing antipatterns\nusing JDeodorant, an Eclipse plugin that supports antipatterns detection and\nrefactoring. The results of the quantitative and qualitative analysis with 171\nstudents show that students tend to appreciate the idea of learning refactoring\nand are satisfied with various aspects of the JDeodorant plugin's operation.\nThrough this experiment, refactoring can turn into a vital part of the\ncomputing educational plan. We envision our findings enabling educators to\nsupport students with refactoring tools tuned towards safer and trustworthy\nrefactoring.",
            "author": [
                "Eman Abdullah AlOmar",
                "Mohamed Wiem Mkaouer",
                "Ali Ouni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10753v1",
                "http://arxiv.org/pdf/2311.10753v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02733v1",
            "title": "AV-Lip-Sync+: Leveraging AV-HuBERT to Exploit Multimodal Inconsistency\n  for Video Deepfake Detection",
            "updated": "2023-11-05T18:35:03Z",
            "published": "2023-11-05T18:35:03Z",
            "summary": "Multimodal manipulations (also known as audio-visual deepfakes) make it\ndifficult for unimodal deepfake detectors to detect forgeries in multimedia\ncontent. To avoid the spread of false propaganda and fake news, timely\ndetection is crucial. The damage to either modality (i.e., visual or audio) can\nonly be discovered through multi-modal models that can exploit both pieces of\ninformation simultaneously. Previous methods mainly adopt uni-modal video\nforensics and use supervised pre-training for forgery detection. This study\nproposes a new method based on a multi-modal self-supervised-learning (SSL)\nfeature extractor to exploit inconsistency between audio and visual modalities\nfor multi-modal video forgery detection. We use the transformer-based SSL\npre-trained Audio-Visual HuBERT (AV-HuBERT) model as a visual and acoustic\nfeature extractor and a multi-scale temporal convolutional neural network to\ncapture the temporal correlation between the audio and visual modalities. Since\nAV-HuBERT only extracts visual features from the lip region, we also adopt\nanother transformer-based video model to exploit facial features and capture\nspatial and temporal artifacts caused during the deepfake generation process.\nExperimental results show that our model outperforms all existing models and\nachieves new state-of-the-art performance on the FakeAVCeleb and DeepfakeTIMIT\ndatasets.",
            "author": [
                "Sahibzada Adil Shahzad",
                "Ammarah Hashmi",
                "Yan-Tsung Peng",
                "Yu Tsao",
                "Hsin-Min Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02733v1",
                "http://arxiv.org/pdf/2311.02733v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.MM",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02732v1",
            "title": "Solving High Dimensional Partial Differential Equations Using Tensor\n  Neural Network and A Posteriori Error Estimators",
            "updated": "2023-11-05T18:31:04Z",
            "published": "2023-11-05T18:31:04Z",
            "summary": "In this paper, we first propose a new type of tensor neural network and the\ncorresponding machine learning method to solve high-dimensional boundary value\nproblems with Dirichlet or Neumann type of boundary conditions and eigenvalue\nproblems of the second order elliptic operator. The most important advantage of\nthe proposed network is that when calculating the loss function, the high\ndimensional integration can be computed with high accuracy using fixed\nquadrature points within tolerable computational complexity. Based on the\ntheory of a posteriori error estimation, a machine learning method which use a\nposteriori error estimator as the loss function is designed to select optimal\nnetwork parameters adaptively. The theoretical analysis and numerical examples\nare provided to validate the proposed methods.",
            "author": [
                "Yifan Wang",
                "Zhongshuo Lin",
                "Yangfei Liao",
                "Haochen Liu",
                "Hehu Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02732v1",
                "http://arxiv.org/pdf/2311.02732v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "68T07, 65L70, 65N25, 65B99"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16143v1",
            "title": "Ransomware Detection and Classification using Machine Learning",
            "updated": "2023-11-05T18:16:53Z",
            "published": "2023-11-05T18:16:53Z",
            "summary": "Vicious assaults, malware, and various ransomware pose a cybersecurity\nthreat, causing considerable damage to computer structures, servers, and mobile\nand web apps across various industries and businesses. These safety concerns\nare important and must be addressed immediately. Ransomware detection and\nclassification are critical for guaranteeing rapid reaction and prevention.\nThis study uses the XGBoost classifier and Random Forest (RF) algorithms to\ndetect and classify ransomware attacks. This approach involves analyzing the\nbehaviour of ransomware and extracting relevant features that can help\ndistinguish between different ransomware families. The models are evaluated on\na dataset of ransomware attacks and demonstrate their effectiveness in\naccurately detecting and classifying ransomware. The results show that the\nXGBoost classifier, Random Forest Classifiers, can effectively detect and\nclassify different ransomware attacks with high accuracy, thereby providing a\nvaluable tool for enhancing cybersecurity.",
            "author": [
                "Kavitha Kunku",
                "ANK Zaman",
                "Kaushik Roy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16143v1",
                "http://arxiv.org/pdf/2311.16143v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02719v1",
            "title": "Uncertainty Estimation for Safety-critical Scene Segmentation via\n  Fine-grained Reward Maximization",
            "updated": "2023-11-05T17:43:37Z",
            "published": "2023-11-05T17:43:37Z",
            "summary": "Uncertainty estimation plays an important role for future reliable deployment\nof deep segmentation models in safety-critical scenarios such as medical\napplications. However, existing methods for uncertainty estimation have been\nlimited by the lack of explicit guidance for calibrating the prediction risk\nand model confidence. In this work, we propose a novel fine-grained reward\nmaximization (FGRM) framework, to address uncertainty estimation by directly\nutilizing an uncertainty metric related reward function with a reinforcement\nlearning based model tuning algorithm. This would benefit the model uncertainty\nestimation through direct optimization guidance for model calibration.\nSpecifically, our method designs a new uncertainty estimation reward function\nusing the calibration metric, which is maximized to fine-tune an evidential\nlearning pre-trained segmentation model for calibrating prediction risk.\nImportantly, we innovate an effective fine-grained parameter update scheme,\nwhich imposes fine-grained reward-weighting of each network parameter according\nto the parameter importance quantified by the fisher information matrix. To the\nbest of our knowledge, this is the first work exploring reward optimization for\nmodel uncertainty estimation in safety-critical vision tasks. The effectiveness\nof our method is demonstrated on two large safety-critical surgical scene\nsegmentation datasets under two different uncertainty estimation settings. With\nreal-time one forward pass at inference, our method outperforms\nstate-of-the-art methods by a clear margin on all the calibration metrics of\nuncertainty estimation, while maintaining a high task accuracy for the\nsegmentation results. Code is available at\n\\url{https://github.com/med-air/FGRM}.",
            "author": [
                "Hongzheng Yang",
                "Cheng Chen",
                "Yueyao Chen",
                "Markus Scheppach",
                "Hon Chi Yip",
                "Qi Dou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02719v1",
                "http://arxiv.org/pdf/2311.02719v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03402v2",
            "title": "CycleCL: Self-supervised Learning for Periodic Videos",
            "updated": "2023-11-13T13:09:49Z",
            "published": "2023-11-05T17:40:10Z",
            "summary": "Analyzing periodic video sequences is a key topic in applications such as\nautomatic production systems, remote sensing, medical applications, or physical\ntraining. An example is counting repetitions of a physical exercise. Due to the\ndistinct characteristics of periodic data, self-supervised methods designed for\nstandard image datasets do not capture changes relevant to the progression of\nthe cycle and fail to ignore unrelated noise. They thus do not work well on\nperiodic data. In this paper, we propose CycleCL, a self-supervised learning\nmethod specifically designed to work with periodic data. We start from the\ninsight that a good visual representation for periodic data should be sensitive\nto the phase of a cycle, but be invariant to the exact repetition, i.e. it\nshould generate identical representations for a specific phase throughout all\nrepetitions. We exploit the repetitions in videos to design a novel contrastive\nlearning method based on a triplet loss that optimizes for these desired\nproperties. Our method uses pre-trained features to sample pairs of frames from\napproximately the same phase and negative pairs of frames from different\nphases. Then, we iterate between optimizing a feature encoder and resampling\ntriplets, until convergence. By optimizing a model this way, we are able to\nlearn features that have the mentioned desired properties. We evaluate CycleCL\non an industrial and multiple human actions datasets, where it significantly\noutperforms previous video-based self-supervised learning methods on all tasks.",
            "author": [
                "Matteo Destro",
                "Michael Gygli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03402v2",
                "http://arxiv.org/pdf/2311.03402v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02715v1",
            "title": "Exploiting Correlated Auxiliary Feedback in Parameterized Bandits",
            "updated": "2023-11-05T17:27:06Z",
            "published": "2023-11-05T17:27:06Z",
            "summary": "We study a novel variant of the parameterized bandits problem in which the\nlearner can observe additional auxiliary feedback that is correlated with the\nobserved reward. The auxiliary feedback is readily available in many real-life\napplications, e.g., an online platform that wants to recommend the best-rated\nservices to its users can observe the user's rating of service (rewards) and\ncollect additional information like service delivery time (auxiliary feedback).\nIn this paper, we first develop a method that exploits auxiliary feedback to\nbuild a reward estimator with tight confidence bounds, leading to a smaller\nregret. We then characterize the regret reduction in terms of the correlation\ncoefficient between reward and its auxiliary feedback. Experimental results in\ndifferent settings also verify the performance gain achieved by our proposed\nmethod.",
            "author": [
                "Arun Verma",
                "Zhongxiang Dai",
                "Yao Shu",
                "Bryan Kian Hsiang Low"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02715v1",
                "http://arxiv.org/pdf/2311.02715v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02709v1",
            "title": "Benchmarking a Benchmark: How Reliable is MS-COCO?",
            "updated": "2023-11-05T16:55:40Z",
            "published": "2023-11-05T16:55:40Z",
            "summary": "Benchmark datasets are used to profile and compare algorithms across a\nvariety of tasks, ranging from image classification to segmentation, and also\nplay a large role in image pretraining algorithms. Emphasis is placed on\nresults with little regard to the actual content within the dataset. It is\nimportant to question what kind of information is being learned from these\ndatasets and what are the nuances and biases within them. In the following\nwork, Sama-COCO, a re-annotation of MS-COCO, is used to discover potential\nbiases by leveraging a shape analysis pipeline. A model is trained and\nevaluated on both datasets to examine the impact of different annotation\nconditions. Results demonstrate that annotation styles are important and that\nannotation pipelines should closely consider the task of interest. The dataset\nis made publicly available at https://www.sama.com/sama-coco-dataset/ .",
            "author": [
                "Eric Zimmermann",
                "Justin Szeto",
                "Jerome Pasquero",
                "Frederic Ratle"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02709v1",
                "http://arxiv.org/pdf/2311.02709v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02704v1",
            "title": "A Goal-Driven Approach to Systems Neuroscience",
            "updated": "2023-11-05T16:37:53Z",
            "published": "2023-11-05T16:37:53Z",
            "summary": "Humans and animals exhibit a range of interesting behaviors in dynamic\nenvironments, and it is unclear how our brains actively reformat this dense\nsensory information to enable these behaviors. Experimental neuroscience is\nundergoing a revolution in its ability to record and manipulate hundreds to\nthousands of neurons while an animal is performing a complex behavior. As these\nparadigms enable unprecedented access to the brain, a natural question that\narises is how to distill these data into interpretable insights about how\nneural circuits give rise to intelligent behaviors. The classical approach in\nsystems neuroscience has been to ascribe well-defined operations to individual\nneurons and provide a description of how these operations combine to produce a\ncircuit-level theory of neural computations. While this approach has had some\nsuccess for small-scale recordings with simple stimuli, designed to probe a\nparticular circuit computation, often times these ultimately lead to disparate\ndescriptions of the same system across stimuli. Perhaps more strikingly, many\nresponse profiles of neurons are difficult to succinctly describe in words,\nsuggesting that new approaches are needed in light of these experimental\nobservations. In this thesis, we offer a different definition of\ninterpretability that we show has promise in yielding unified structural and\nfunctional models of neural circuits, and describes the evolutionary\nconstraints that give rise to the response properties of the neural population,\nincluding those that have previously been difficult to describe individually.\nWe demonstrate the utility of this framework across multiple brain areas and\nspecies to study the roles of recurrent processing in the primate ventral\nvisual pathway; mouse visual processing; heterogeneity in rodent medial\nentorhinal cortex; and facilitating biological learning.",
            "author": [
                "Aran Nayebi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02704v1",
                "http://arxiv.org/pdf/2311.02704v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03401v1",
            "title": "Enhancing AI Research Paper Analysis: Methodology Component Extraction\n  using Factored Transformer-based Sequence Modeling Approach",
            "updated": "2023-11-05T16:33:35Z",
            "published": "2023-11-05T16:33:35Z",
            "summary": "Research in scientific disciplines evolves, often rapidly, over time with the\nemergence of novel methodologies and their associated terminologies. While\nmethodologies themselves being conceptual in nature and rather difficult to\nautomatically extract and characterise, in this paper, we seek to develop\nsupervised models for automatic extraction of the names of the various\nconstituents of a methodology, e.g., `R-CNN', `ELMo' etc. The main research\nchallenge for this task is effectively modeling the contexts around these\nmethodology component names in a few-shot or even a zero-shot setting. The main\ncontributions of this paper towards effectively identifying new evolving\nscientific methodology names are as follows: i) we propose a factored approach\nto sequence modeling, which leverages a broad-level category information of\nmethodology domains, e.g., `NLP', `RL' etc.; ii) to demonstrate the feasibility\nof our proposed approach of identifying methodology component names under a\npractical setting of fast evolving AI literature, we conduct experiments\nfollowing a simulated chronological setup (newer methodologies not seen during\nthe training process); iii) our experiments demonstrate that the factored\napproach outperforms state-of-the-art baselines by margins of up to 9.257\\% for\nthe methodology extraction task with the few-shot setup.",
            "author": [
                "Madhusudan Ghosh",
                "Debasis Ganguly",
                "Partha Basuchowdhuri",
                "Sudip Kumar Naskar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03401v1",
                "http://arxiv.org/pdf/2311.03401v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.DL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02703v1",
            "title": "Toward Trustworthy Identity Tracing via Multi-attribute Synergistic\n  Identification",
            "updated": "2023-11-05T16:31:21Z",
            "published": "2023-11-05T16:31:21Z",
            "summary": "Identity tracing is a technology that uses the selection and collection of\nidentity attributes of the object to be tested to discover its true identity,\nand it is one of the most important foundational issues in the field of social\nsecurity prevention. However, traditional identity recognition technologies\nbased on single attributes have difficulty achieving ultimate recognition\naccuracy, where deep learning-based model always lacks interpretability.\nMultivariate attribute collaborative identification is a possible key way to\novercome the mentioned recognition errors and low data quality problems. In\nthis paper, we propose the Trustworthy Identity Tracing (TIT) task and a\nMulti-attribute Synergistic Identification based TIT framework. We first\nestablished a novel identity model based on identity entropy theoretically. The\nindividual conditional identity entropy and core identification set are defined\nto reveal the intrinsic mechanism of multivariate attribute collaborative\nidentification. Based on the proposed identity model, we propose a trustworthy\nidentity tracing framework (TITF) with multi-attribute synergistic\nidentification to determine the identity of unknown objects, which can optimize\nthe core identification set and provide an interpretable identity tracing\nprocess. Actually, the essence of identity tracing is revealed to be the\nprocess of the identity entropy value converging to zero. To cope with the lack\nof test data, we construct a dataset of 1000 objects to simulate real-world\nscenarios, where 20 identity attributes are labeled to trace unknown object\nidentities. The experiment results conducted on the mentioned dataset show the\nproposed TITF algorithm can achieve satisfactory identification performance.",
            "author": [
                "Decheng Liu",
                "Jiahao Yu",
                "Ruimin Hu",
                "Wenbin Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02703v1",
                "http://arxiv.org/pdf/2311.02703v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02699v1",
            "title": "Nepali Video Captioning using CNN-RNN Architecture",
            "updated": "2023-11-05T16:09:40Z",
            "published": "2023-11-05T16:09:40Z",
            "summary": "This article presents a study on Nepali video captioning using deep neural\nnetworks. Through the integration of pre-trained CNNs and RNNs, the research\nfocuses on generating precise and contextually relevant captions for Nepali\nvideos. The approach involves dataset collection, data preprocessing, model\nimplementation, and evaluation. By enriching the MSVD dataset with Nepali\ncaptions via Google Translate, the study trains various CNN-RNN architectures.\nThe research explores the effectiveness of CNNs (e.g., EfficientNetB0,\nResNet101, VGG16) paired with different RNN decoders like LSTM, GRU, and\nBiLSTM. Evaluation involves BLEU and METEOR metrics, with the best model being\nEfficientNetB0 + BiLSTM with 1024 hidden dimensions, achieving a BLEU-4 score\nof 17 and METEOR score of 46. The article also outlines challenges and future\ndirections for advancing Nepali video captioning, offering a crucial resource\nfor further research in this area.",
            "author": [
                "Bipesh Subedi",
                "Saugat Singh",
                "Bal Krishna Bal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02699v1",
                "http://arxiv.org/pdf/2311.02699v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG",
                "I.2.7; I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02695v1",
            "title": "Identifying Linearly-Mixed Causal Representations from Multi-Node\n  Interventions",
            "updated": "2023-11-05T16:05:00Z",
            "published": "2023-11-05T16:05:00Z",
            "summary": "The task of inferring high-level causal variables from low-level\nobservations, commonly referred to as causal representation learning, is\nfundamentally underconstrained. As such, recent works to address this problem\nfocus on various assumptions that lead to identifiability of the underlying\nlatent causal variables. A large corpus of these preceding approaches consider\nmulti-environment data collected under different interventions on the causal\nmodel. What is common to virtually all of these works is the restrictive\nassumption that in each environment, only a single variable is intervened on.\nIn this work, we relax this assumption and provide the first identifiability\nresult for causal representation learning that allows for multiple variables to\nbe targeted by an intervention within one environment. Our approach hinges on a\ngeneral assumption on the coverage and diversity of interventions across\nenvironments, which also includes the shared assumption of single-node\ninterventions of previous works. The main idea behind our approach is to\nexploit the trace that interventions leave on the variance of the ground truth\ncausal variables and regularizing for a specific notion of sparsity with\nrespect to this trace. In addition to and inspired by our theoretical\ncontributions, we present a practical algorithm to learn causal representations\nfrom multi-node interventional data and provide empirical evidence that\nvalidates our identifiability results.",
            "author": [
                "Simon Bing",
                "Urmi Ninad",
                "Jonas Wahl",
                "Jakob Runge"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02695v1",
                "http://arxiv.org/pdf/2311.02695v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02692v1",
            "title": "ChEF: A Comprehensive Evaluation Framework for Standardized Assessment\n  of Multimodal Large Language Models",
            "updated": "2023-11-05T16:01:40Z",
            "published": "2023-11-05T16:01:40Z",
            "summary": "Multimodal Large Language Models (MLLMs) have shown impressive abilities in\ninteracting with visual content with myriad potential downstream tasks.\nHowever, even though a list of benchmarks has been proposed, the capabilities\nand limitations of MLLMs are still not comprehensively understood, due to a\nlack of a standardized and holistic evaluation framework. To this end, we\npresent the first Comprehensive Evaluation Framework (ChEF) that can\nholistically profile each MLLM and fairly compare different MLLMs. First, we\nstructure ChEF as four modular components, i.e., Scenario as scalable\nmultimodal datasets, Instruction as flexible instruction retrieving formulae,\nInferencer as reliable question answering strategies, and Metric as indicative\ntask-specific score functions. Based on them, ChEF facilitates versatile\nevaluations in a standardized framework, and new evaluations can be built by\ndesigning new Recipes (systematic selection of these four components). Notably,\ncurrent MLLM benchmarks can be readily summarized as recipes of ChEF. Second,\nwe introduce 6 new recipes to quantify competent MLLMs' desired capabilities\n(or called desiderata, i.e., calibration, in-context learning, instruction\nfollowing, language performance, hallucination, and robustness) as reliable\nagents that can perform real-world multimodal interactions. Third, we conduct a\nlarge-scale evaluation of 9 prominent MLLMs on 9 scenarios and 6 desiderata.\nOur evaluation summarized over 20 valuable observations concerning the\ngeneralizability of MLLMs across various scenarios and the composite capability\nof MLLMs required for multimodal interactions. We will publicly release all the\ndetailed implementations for further analysis, as well as an easy-to-use\nmodular toolkit for the integration of new recipes and models, so that ChEF can\nbe a growing evaluation framework for the MLLM community.",
            "author": [
                "Zhelun Shi",
                "Zhipin Wang",
                "Hongxing Fan",
                "Zhenfei Yin",
                "Lu Sheng",
                "Yu Qiao",
                "Jing Shao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02692v1",
                "http://arxiv.org/pdf/2311.02692v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14687v1",
            "title": "Does Explainable AI Have Moral Value?",
            "updated": "2023-11-05T15:59:27Z",
            "published": "2023-11-05T15:59:27Z",
            "summary": "Explainable AI (XAI) aims to bridge the gap between complex algorithmic\nsystems and human stakeholders. Current discourse often examines XAI in\nisolation as either a technological tool, user interface, or policy mechanism.\nThis paper proposes a unifying ethical framework grounded in moral duties and\nthe concept of reciprocity. We argue that XAI should be appreciated not merely\nas a right, but as part of our moral duties that helps sustain a reciprocal\nrelationship between humans affected by AI systems. This is because, we argue,\nexplanations help sustain constitutive symmetry and agency in AI-led\ndecision-making processes. We then assess leading XAI communities and reveal\ngaps between the ideal of reciprocity and practical feasibility. Machine\nlearning offers useful techniques but overlooks evaluation and adoption\nchallenges. Human-computer interaction provides preliminary insights but\noversimplifies organizational contexts. Policies espouse accountability but\nlack technical nuance. Synthesizing these views exposes barriers to\nimplementable, ethical XAI. Still, positioning XAI as a moral duty transcends\nrights-based discourse to capture a more robust and complete moral picture.\nThis paper provides an accessible, detailed analysis elucidating the moral\nvalue of explainability.",
            "author": [
                "Joshua L. M. Brand",
                "Luca Nannini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14687v1",
                "http://arxiv.org/pdf/2311.14687v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02687v1",
            "title": "Architecture Matters: Uncovering Implicit Mechanisms in Graph\n  Contrastive Learning",
            "updated": "2023-11-05T15:54:17Z",
            "published": "2023-11-05T15:54:17Z",
            "summary": "With the prosperity of contrastive learning for visual representation\nlearning (VCL), it is also adapted to the graph domain and yields promising\nperformance. However, through a systematic study of various graph contrastive\nlearning (GCL) methods, we observe that some common phenomena among existing\nGCL methods that are quite different from the original VCL methods, including\n1) positive samples are not a must for GCL; 2) negative samples are not\nnecessary for graph classification, neither for node classification when\nadopting specific normalization modules; 3) data augmentations have much less\ninfluence on GCL, as simple domain-agnostic augmentations (e.g., Gaussian\nnoise) can also attain fairly good performance. By uncovering how the implicit\ninductive bias of GNNs works in contrastive learning, we theoretically provide\ninsights into the above intriguing properties of GCL. Rather than directly\nporting existing VCL methods to GCL, we advocate for more attention toward the\nunique architecture of graph learning and consider its implicit influence when\ndesigning GCL methods. Code is available at https:\n//github.com/PKU-ML/ArchitectureMattersGCL.",
            "author": [
                "Xiaojun Guo",
                "Yifei Wang",
                "Zeming Wei",
                "Yisen Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02687v1",
                "http://arxiv.org/pdf/2311.02687v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02684v1",
            "title": "Octavius: Mitigating Task Interference in MLLMs via MoE",
            "updated": "2023-11-05T15:48:29Z",
            "published": "2023-11-05T15:48:29Z",
            "summary": "Recent studies have demonstrated Large Language Models (LLMs) can extend\ntheir zero-shot generalization capabilities to multimodal learning through\ninstruction tuning. As more modalities and downstream tasks are introduced,\nnegative conflicts and interference may have a worse impact on performance.\nWhile this phenomenon has been overlooked in previous work, we propose a novel\nand extensible framework, called \\mname, for comprehensive studies and\nexperimentation on multimodal learning with Multimodal Large Language Models\n(MLLMs). Specifically, we combine the well-known Mixture-of-Experts (MoE) and\none of the representative PEFT techniques, \\emph{i.e.,} LoRA, designing a novel\nLLM-based decoder, called LoRA-MoE, for multimodal learning. The experimental\nresults (about 20\\% improvement) have shown the effectiveness and versatility\nof our design in various 2D and 3D downstream tasks. Code and corresponding\ndataset will be available soon.",
            "author": [
                "Zeren Chen",
                "Ziqin Wang",
                "Zhen Wang",
                "Huayang Liu",
                "Zhenfei Yin",
                "Si Liu",
                "Lu Sheng",
                "Wanli Ouyang",
                "Yu Qiao",
                "Jing Shao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02684v1",
                "http://arxiv.org/pdf/2311.02684v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02679v2",
            "title": "Regret Analysis of Learning-Based Linear Quadratic Gaussian Control with\n  Additive Exploration",
            "updated": "2023-11-24T14:25:58Z",
            "published": "2023-11-05T15:32:37Z",
            "summary": "In this paper, we analyze the regret incurred by a computationally efficient\nexploration strategy, known as naive exploration, for controlling unknown\npartially observable systems within the Linear Quadratic Gaussian (LQG)\nframework. We introduce a two-phase control algorithm called LQG-NAIVE, which\ninvolves an initial phase of injecting Gaussian input signals to obtain a\nsystem model, followed by a second phase of an interplay between naive\nexploration and control in an episodic fashion. We show that LQG-NAIVE achieves\na regret growth rate of $\\tilde{\\mathcal{O}}(\\sqrt{T})$, i.e.,\n$\\mathcal{O}(\\sqrt{T})$ up to logarithmic factors after $T$ time steps, and we\nvalidate its performance through numerical simulations. Additionally, we\npropose LQG-IF2E, which extends the exploration signal to a `closed-loop'\nsetting by incorporating the Fisher Information Matrix (FIM). We provide\ncompelling numerical evidence of the competitive performance of LQG-IF2E\ncompared to LQG-NAIVE.",
            "author": [
                "Archith Athrey",
                "Othmane Mazhar",
                "Meichen Guo",
                "Bart De Schutter",
                "Shengling Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02679v2",
                "http://arxiv.org/pdf/2311.02679v2"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02665v1",
            "title": "Digital Typhoon: Long-term Satellite Image Dataset for the\n  Spatio-Temporal Modeling of Tropical Cyclones",
            "updated": "2023-11-05T14:22:13Z",
            "published": "2023-11-05T14:22:13Z",
            "summary": "This paper presents the official release of the Digital Typhoon dataset, the\nlongest typhoon satellite image dataset for 40+ years aimed at benchmarking\nmachine learning models for long-term spatio-temporal data. To build the\ndataset, we developed a workflow to create an infrared typhoon-centered image\nfor cropping using Lambert azimuthal equal-area projection referring to the\nbest track data. We also address data quality issues such as inter-satellite\ncalibration to create a homogeneous dataset. To take advantage of the dataset,\nwe organized machine learning tasks by the types and targets of inference, with\nother tasks for meteorological analysis, societal impact, and climate change.\nThe benchmarking results on the analysis, forecasting, and reanalysis for the\nintensity suggest that the dataset is challenging for recent deep learning\nmodels, due to many choices that affect the performance of various models. This\ndataset reduces the barrier for machine learning researchers to meet\nlarge-scale real-world events called tropical cyclones and develop machine\nlearning models that may contribute to advancing scientific knowledge on\ntropical cyclones as well as solving societal and sustainability issues such as\ndisaster reduction and climate change. The dataset is publicly available at\nhttp://agora.ex.nii.ac.jp/digital-typhoon/dataset/ and\nhttps://github.com/kitamoto-lab/digital-typhoon/.",
            "author": [
                "Asanobu Kitamoto",
                "Jared Hwang",
                "Bastien Vuillod",
                "Lucas Gautier",
                "Yingtao Tian",
                "Tarin Clanuwat"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02665v1",
                "http://arxiv.org/pdf/2311.02665v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02657v1",
            "title": "GSC: Generalizable Service Coordination",
            "updated": "2023-11-05T14:04:09Z",
            "published": "2023-11-05T14:04:09Z",
            "summary": "Services with distributed and interdependent components are becoming a\npopular option for harnessing dispersed resources available on cloud and edge\nnetworks. However, effective deployment and management of these services,\nnamely service coordination, is a challenging task. Service coordination\ncomprises the placement and scalability of components and scheduling incoming\ntraffic requesting for services between deployed instances. Due to the online\nnature of the problem and the success of Deep Reinforcement Learning (DRL)\nmethods, previous works considered DRL agents for solving service coordination\nproblems, yet these solutions have to be retrained for every unseen scenario.\nOther works have tried to tackle this shortcoming by incorporating Graph Neural\nNetworks (GNN) into their solutions, but they often focus on specific aspects\n(and disregard others) or cannot operate in dynamic and practical situations\nwhere there is no labeled dataset and feedback from the network might be\ndelayed. In response to these challenges, we present GSC, a generalizable\nservice coordinator that jointly considers service placement, scaling, and\ntraffic scheduling. GSC can operate in unseen situations without significant\nperformance degradation and outperforms existing state-of-the-art solutions by\n40%, as determined by simulating real-world network situations.",
            "author": [
                "Farzad Mohammadi",
                "Vahid Shah-Mansouri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02657v1",
                "http://arxiv.org/pdf/2311.02657v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02648v1",
            "title": "Drone-Enabled Load Management for Solar Small Cell Networks in Next-Gen\n  Communications Optimization for Solar Small Cells",
            "updated": "2023-11-05T13:21:38Z",
            "published": "2023-11-05T13:21:38Z",
            "summary": "In recent years, the cellular industry has witnessed a major evolution in\ncommunication technologies. It is evident that the Next Generation of cellular\nnetworks(NGN) will play a pivotal role in the acceptance of emerging IoT\napplications supporting high data rates, better Quality of Service(QoS), and\nreduced latency. However, the deployment of NGN will introduce a power overhead\non the communication infrastructure. Addressing the critical energy constraints\nin 5G and beyond, this study introduces an innovative load transfer method\nusing drone-carried airborne base stations (BSs) for stable and secure power\nreallocation within a green micro-grid network. This method effectively manages\nenergy deficit by transferring aerial BSs from high to low-energy cells,\ndepending on user density and the availability of aerial BSs, optimizing power\ndistribution in advanced cellular networks. The complexity of the proposed\nsystem is significantly lower as compared to existing power cable transmission\nsystems currently employed in powering the BSs. Furthermore, our proposed\nalgorithm has been shown to reduce BS power outages while requiring a minimum\nnumber of drone exchanges. We have conducted a thorough review on real-world\ndataset to prove the efficacy of our proposed approach to support BS during\nhigh load demand times",
            "author": [
                "Daksh Dave",
                "Dhruv Khut",
                "Sahil Nawale",
                "Pushkar Aggrawal",
                "Disha Rastogi",
                "Kailas Devadkar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02648v1",
                "http://arxiv.org/pdf/2311.02648v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02647v1",
            "title": "New Approach for an Affective Computing-Driven Quality of Experience\n  (QoE) Prediction",
            "updated": "2023-11-05T13:21:07Z",
            "published": "2023-11-05T13:21:07Z",
            "summary": "In human interactions, emotion recognition is crucial. For this reason, the\ntopic of computer-vision approaches for automatic emotion recognition is\ncurrently being extensively researched. Processing multi-channel\nelectroencephalogram (EEG) information is one of the most researched methods\nfor automatic emotion recognition. This paper presents a new model for an\naffective computing-driven Quality of Experience (QoE) prediction. In order to\nvalidate the proposed model, a publicly available dataset is used. The dataset\ncontains EEG, ECG, and respiratory data and is focused on a multimedia QoE\nassessment context. The EEG data are retained on which the differential entropy\nand the power spectral density are calculated with an observation window of\nthree seconds. These two features were extracted to train several deep-learning\nmodels to investigate the possibility of predicting QoE with five different\nfactors. The performance of these models is compared, and the best model is\noptimized to improve the results. The best results were obtained with an\nLSTM-based model, presenting an F1-score from 68% to 78%. An analysis of the\nmodel and its features shows that the Delta frequency band is the least\nnecessary, that two electrodes have a higher importance, and that two other\nelectrodes have a very low impact on the model's performances.",
            "author": [
                "Joshua B\u00e8gue",
                "Mohamed Aymen Labiod",
                "Abdelhamid Melloulk"
            ],
            "link": [
                "http://dx.doi.org/10.1109/MCOM.002.2200870.",
                "http://arxiv.org/abs/2311.02647v1",
                "http://arxiv.org/pdf/2311.02647v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.HC",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02641v1",
            "title": "PotholeGuard: A Pothole Detection Approach by Point Cloud Semantic\n  Segmentation",
            "updated": "2023-11-05T12:57:05Z",
            "published": "2023-11-05T12:57:05Z",
            "summary": "Pothole detection is crucial for road safety and maintenance, traditionally\nrelying on 2D image segmentation. However, existing 3D Semantic Pothole\nSegmentation research often overlooks point cloud sparsity, leading to\nsuboptimal local feature capture and segmentation accuracy. Our research\npresents an innovative point cloud-based pothole segmentation architecture. Our\nmodel efficiently identifies hidden features and uses a feedback mechanism to\nenhance local characteristics, improving feature presentation. We introduce a\nlocal relationship learning module to understand local shape relationships,\nenhancing structural insights. Additionally, we propose a lightweight adaptive\nstructure for refining local point features using the K nearest neighbor\nalgorithm, addressing point cloud density differences and domain selection.\nShared MLP Pooling is integrated to learn deep aggregation features,\nfacilitating semantic data exploration and segmentation guidance. Extensive\nexperiments on three public datasets confirm PotholeGuard's superior\nperformance over state-of-the-art methods. Our approach offers a promising\nsolution for robust and accurate 3D pothole segmentation, with applications in\nroad maintenance and safety.",
            "author": [
                "Sahil Nawale",
                "Dhruv Khut",
                "Daksh Dave",
                "Gauransh Sawhney",
                "Pushkar Aggrawal",
                "Dr. Kailas Devadakar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02641v1",
                "http://arxiv.org/pdf/2311.02641v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02640v1",
            "title": "Assessing the Promise and Pitfalls of ChatGPT for Automated Code\n  Generation",
            "updated": "2023-11-05T12:56:40Z",
            "published": "2023-11-05T12:56:40Z",
            "summary": "This paper presents a comprehensive evaluation of the code generation\ncapabilities of ChatGPT, a prominent large language model, compared to human\nprogrammers. A novel dataset of 131 code-generation prompts across 5 categories\nwas curated to enable robust analysis. Code solutions were generated by both\nChatGPT and humans for all prompts, resulting in 262 code samples. A meticulous\nmanual assessment methodology prioritized evaluating correctness,\ncomprehensibility, and security using 14 established code quality metrics. The\nkey findings reveal ChatGPT's strengths in crafting concise, efficient code\nwith advanced constructs, showcasing strengths in data analysis tasks (93.1%\naccuracy) but limitations in visual-graphical challenges. Comparative analysis\nwith human code highlights ChatGPT's inclination towards modular design and\nsuperior error handling. Additionally, machine learning models effectively\ndistinguished ChatGPT from human code with up to 88% accuracy, suggesting\ndetectable coding style disparities. By providing profound insights into\nChatGPT's code generation capabilities and limitations through quantitative\nmetrics and qualitative analysis, this study makes valuable contributions\ntoward advancing AI-based programming assistants. The curated dataset and\nmethodology offer a robust foundation for future research in this nascent\ndomain. All data and codes are available on\nhttps://github.com/DSAatUSU/ChatGPT-promises-and-pitfalls.",
            "author": [
                "Muhammad Fawad Akbar Khan",
                "Max Ramsdell",
                "Erik Falor",
                "Hamid Karimi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02640v1",
                "http://arxiv.org/pdf/2311.02640v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02633v1",
            "title": "The Background Also Matters: Background-Aware Motion-Guided Objects\n  Discovery",
            "updated": "2023-11-05T12:35:47Z",
            "published": "2023-11-05T12:35:47Z",
            "summary": "Recent works have shown that objects discovery can largely benefit from the\ninherent motion information in video data. However, these methods lack a proper\nbackground processing, resulting in an over-segmentation of the non-object\nregions into random segments. This is a critical limitation given the\nunsupervised setting, where object segments and noise are not distinguishable.\nTo address this limitation we propose BMOD, a Background-aware Motion-guided\nObjects Discovery method. Concretely, we leverage masks of moving objects\nextracted from optical flow and design a learning mechanism to extend them to\nthe true foreground composed of both moving and static objects. The background,\na complementary concept of the learned foreground class, is then isolated in\nthe object discovery process. This enables a joint learning of the objects\ndiscovery task and the object/non-object separation. The conducted experiments\non synthetic and real-world datasets show that integrating our background\nhandling with various cutting-edge methods brings each time a considerable\nimprovement. Specifically, we improve the objects discovery performance with a\nlarge margin, while establishing a strong baseline for object/non-object\nseparation.",
            "author": [
                "Sandra Kara",
                "Hejer Ammar",
                "Florian Chabot",
                "Quoc-Cuong Pham"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02633v1",
                "http://arxiv.org/pdf/2311.02633v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02631v1",
            "title": "A Critical Perceptual Pre-trained Model for Complex Trajectory Recovery",
            "updated": "2023-11-05T12:20:39Z",
            "published": "2023-11-05T12:20:39Z",
            "summary": "The trajectory on the road traffic is commonly collected at a low sampling\nrate, and trajectory recovery aims to recover a complete and continuous\ntrajectory from the sparse and discrete inputs. Recently, sequential language\nmodels have been innovatively adopted for trajectory recovery in a pre-trained\nmanner: it learns road segment representation vectors, which will be used in\nthe downstream tasks. However, existing methods are incapable of handling\ncomplex trajectories: when the trajectory crosses remote road segments or makes\nseveral turns, which we call critical nodes, the quality of learned\nrepresentations deteriorates, and the recovered trajectories skip the critical\nnodes. This work is dedicated to offering a more robust trajectory recovery for\ncomplex trajectories. Firstly, we define the trajectory complexity based on the\ndetour score and entropy score and construct the complexity-aware semantic\ngraphs correspondingly. Then, we propose a Multi-view Graph and Complexity\nAware Transformer (MGCAT) model to encode these semantics in trajectory\npre-training from two aspects: 1) adaptively aggregate the multi-view graph\nfeatures considering trajectory pattern, and 2) higher attention to critical\nnodes in a complex trajectory. Such that, our MGCAT is perceptual when handling\nthe critical scenario of complex trajectories. Extensive experiments are\nconducted on large-scale datasets. The results prove that our method learns\nbetter representations for trajectory recovery, with 5.22% higher F1-score\noverall and 8.16% higher F1-score for complex trajectories particularly. The\ncode is available at https://github.com/bonaldli/ComplexTraj.",
            "author": [
                "Dedong Li",
                "Ziyue Li",
                "Zhishuai Li",
                "Lei Bai",
                "Qingyuan Gong",
                "Lijun Sun",
                "Wolfgang Ketter",
                "Rui Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02631v1",
                "http://arxiv.org/pdf/2311.02631v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16141v1",
            "title": "Brain-Inspired Efficient Pruning: Exploiting Criticality in Spiking\n  Neural Networks",
            "updated": "2023-11-05T12:20:29Z",
            "published": "2023-11-05T12:20:29Z",
            "summary": "Spiking Neural Networks (SNNs) have been an attractive option for deployment\non devices with limited computing resources and lower power consumption because\nof the event-driven computing characteristic. As such devices have limited\ncomputing and storage resources, pruning for SNNs has been widely focused\nrecently. However, the binary and non-differentiable property of spike signals\nmake pruning deep SNNs challenging, so existing methods require high time\noverhead to make pruning decisions. In this paper, inspired by critical brain\nhypothesis in neuroscience, we design a regeneration mechanism based on\ncriticality to efficiently obtain the critical pruned networks. Firstly, we\npropose a low-cost metric for the criticality of pruning structures. Then we\nre-rank the pruned structures after pruning and regenerate those with higher\ncriticality. We evaluate our method using VGG-16 and ResNet-19 for both\nunstructured pruning and structured pruning. Our method achieves higher\nperformance compared to current state-of-the-art (SOTA) method with the same\ntime overhead. We also achieve comparable performances (even better on VGG-16)\ncompared to the SOTA method with 11.3x and 15.5x acceleration. Moreover, we\ninvestigate underlying mechanism of our method and find that it efficiently\nselects potential structures, learns the consistent feature representations and\nreduces the overfitting during the recovery phase.",
            "author": [
                "Shuo Chen",
                "Boxiao Liu",
                "Haihang You"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16141v1",
                "http://arxiv.org/pdf/2311.16141v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02630v1",
            "title": "The New Frontier of Cybersecurity: Emerging Threats and Innovations",
            "updated": "2023-11-05T12:08:20Z",
            "published": "2023-11-05T12:08:20Z",
            "summary": "In today's digitally interconnected world, cybersecurity threats have reached\nunprecedented levels, presenting a pressing concern for individuals,\norganizations, and governments. This study employs a qualitative research\napproach to comprehensively examine the diverse threats of cybersecurity and\ntheir impacts across various sectors. Four primary categories of threats are\nidentified and analyzed, encompassing malware attacks, social engineering\nattacks, network vulnerabilities, and data breaches. The research delves into\nthe consequences of these threats on individuals, organizations, and society at\nlarge. The findings reveal a range of key emerging threats in cybersecurity,\nincluding advanced persistent threats, ransomware attacks, Internet of Things\n(IoT) vulnerabilities, and social engineering exploits. Consequently, it is\nevident that emerging cybersecurity threats pose substantial risks to both\norganizations and individuals. The sophistication and diversity of these\nemerging threats necessitate a multi-layered approach to cybersecurity. This\napproach should include robust security measures, comprehensive employee\ntraining, and regular security audits. The implications of these emerging\nthreats are extensive, with potential consequences such as financial loss,\nreputational damage, and compromised personal information. This study\nemphasizes the importance of implementing effective measures to mitigate these\nthreats. It highlights the significance of using strong passwords, encryption\nmethods, and regularly updating software to bolster cyber defenses.",
            "author": [
                "Daksh Dave",
                "Gauransh Sawhney",
                "Pushkar Aggarwal",
                "Nitish Silswal",
                "Dhruv Khut"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02630v1",
                "http://arxiv.org/pdf/2311.02630v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02629v1",
            "title": "Pointer Networks with Q-Learning for OP Combinatorial Optimization",
            "updated": "2023-11-05T12:03:58Z",
            "published": "2023-11-05T12:03:58Z",
            "summary": "The Orienteering Problem (OP) presents a unique challenge in combinatorial\noptimization, emphasized by its widespread use in logistics, delivery, and\ntransportation planning. Given the NP-hard nature of OP, obtaining optimal\nsolutions is inherently complex. While Pointer Networks (Ptr-Nets) have\nexhibited prowess in various combinatorial tasks, their performance in the\ncontext of OP leaves room for improvement. Recognizing the potency of\nQ-learning, especially when paired with deep neural structures, this research\nunveils the Pointer Q-Network (PQN). This innovative method combines Ptr-Nets\nand Q-learning, effectively addressing the specific challenges presented by OP.\nWe deeply explore the architecture and efficiency of PQN, showcasing its\nsuperior capability in managing OP situations.",
            "author": [
                "Alessandro Barro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02629v1",
                "http://arxiv.org/pdf/2311.02629v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02628v1",
            "title": "SparseLock: Securing Neural Network Models in Deep Learning Accelerators",
            "updated": "2023-11-05T12:00:43Z",
            "published": "2023-11-05T12:00:43Z",
            "summary": "Securing neural networks (NNs) against model extraction and parameter\nexfiltration attacks is an important problem primarily because modern NNs take\na lot of time and resources to build and train. We observe that there are no\ncountermeasures (CMs) against recently proposed attacks on sparse NNs and there\nis no single CM that effectively protects against all types of known attacks\nfor both sparse as well as dense NNs. In this paper, we propose SparseLock, a\ncomprehensive CM that protects against all types of attacks including some of\nthe very recently proposed ones for which no CM exists as of today. We rely on\na novel compression algorithm and binning strategy. Our security guarantees are\nbased on the inherent hardness of bin packing and inverse bin packing problems.\nWe also perform a battery of statistical and information theory based tests to\nsuccessfully show that we leak very little information and side channels in our\narchitecture are akin to random sources. In addition, we show a performance\nbenefit of 47.13% over the nearest competing secure architecture.",
            "author": [
                "Nivedita Shrivastava",
                "Smruti R. Sarangi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02628v1",
                "http://arxiv.org/pdf/2311.02628v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06295v1",
            "title": "Gradual Optimization Learning for Conformational Energy Minimization",
            "updated": "2023-11-05T11:48:08Z",
            "published": "2023-11-05T11:48:08Z",
            "summary": "Molecular conformation optimization is crucial to computer-aided drug\ndiscovery and materials design. Traditional energy minimization techniques rely\non iterative optimization methods that use molecular forces calculated by a\nphysical simulator (oracle) as anti-gradients. However, this is a\ncomputationally expensive approach that requires many interactions with a\nphysical simulator. One way to accelerate this procedure is to replace the\nphysical simulator with a neural network. Despite recent progress in neural\nnetworks for molecular conformation energy prediction, such models are prone to\ndistribution shift, leading to inaccurate energy minimization. We find that the\nquality of energy minimization with neural networks can be improved by\nproviding optimization trajectories as additional training data. Still, it\ntakes around $5 \\times 10^5$ additional conformations to match the physical\nsimulator's optimization quality. In this work, we present the Gradual\nOptimization Learning Framework (GOLF) for energy minimization with neural\nnetworks that significantly reduces the required additional data. The framework\nconsists of an efficient data-collecting scheme and an external optimizer. The\nexternal optimizer utilizes gradients from the energy prediction model to\ngenerate optimization trajectories, and the data-collecting scheme selects\nadditional training data to be processed by the physical simulator. Our results\ndemonstrate that the neural network trained with GOLF performs on par with the\noracle on a benchmark of diverse drug-like molecules using $50$x less\nadditional data.",
            "author": [
                "Artem Tsypin",
                "Leonid Ugadiarov",
                "Kuzma Khrabrov",
                "Manvel Avetisian",
                "Alexander Telepov",
                "Egor Rumiantsev",
                "Alexey Skrynnik",
                "Aleksandr I. Panov",
                "Dmitry Vetrov",
                "Elena Tutubalina",
                "Artur Kadurin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06295v1",
                "http://arxiv.org/pdf/2311.06295v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02622v1",
            "title": "Neural Networks Are Implicit Decision Trees: The Hierarchical Simplicity\n  Bias",
            "updated": "2023-11-05T11:27:03Z",
            "published": "2023-11-05T11:27:03Z",
            "summary": "Neural networks exhibit simplicity bias; they rely on simpler features while\nignoring equally predictive but more complex features. In this work, we\nintroduce a novel approach termed imbalanced label coupling to investigate\nscenarios where simple and complex features exhibit different levels of\npredictive power. In these cases, complex features still contribute to\npredictions. The trained networks make predictions in alignment with the\nascending complexity of input features according to how they correlate with the\nlabel in the training set, irrespective of the underlying predictive power. For\ninstance, even when simple spurious features distort predictions in CIFAR-10,\nmost cats are predicted to be dogs, and most trucks are predicted to be\nautomobiles! This observation provides direct evidence that the neural network\nlearns core features in the presence of spurious features. We empirically show\nthat last-layer retraining with target data distribution is effective, yet\ninsufficient to fully recover core features when spurious features are\nperfectly correlated with the target labels in our synthetic dataset. We hope\nour research contributes to a deeper understanding of the implicit bias of\nneural networks.",
            "author": [
                "Zhehang Du"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02622v1",
                "http://arxiv.org/pdf/2311.02622v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02621v1",
            "title": "AIOps-Driven Enhancement of Log Anomaly Detection in Unsupervised\n  Scenarios",
            "updated": "2023-11-05T11:16:24Z",
            "published": "2023-11-05T11:16:24Z",
            "summary": "Artificial intelligence operations (AIOps) play a pivotal role in\nidentifying, mitigating, and analyzing anomalous system behaviors and alerts.\nHowever, the research landscape in this field remains limited, leaving\nsignificant gaps unexplored. This study introduces a novel hybrid framework\nthrough an innovative algorithm that incorporates an unsupervised strategy.\nThis strategy integrates Principal Component Analysis (PCA) and Artificial\nNeural Networks (ANNs) and uses a custom loss function to substantially enhance\nthe effectiveness of log anomaly detection. The proposed approach encompasses\nthe utilization of both simulated and real-world datasets, including logs from\nSockShop and Hadoop Distributed File System (HDFS). The experimental results\nare highly promising, demonstrating significant reductions in pseudo-positives.\nMoreover, this strategy offers notable advantages, such as the ability to\nprocess logs in their raw, unprocessed form, and the potential for further\nenhancements. The successful implementation of this approach showcases a\nremarkable reduction in anomalous logs, thus unequivocally establishing the\nefficacy of the proposed methodology. Ultimately, this study makes a\nsubstantial contribution to the advancement of log anomaly detection within\nAIOps platforms, addressing the critical need for effective and efficient log\nanalysis in modern and complex systems.",
            "author": [
                "Daksh Dave",
                "Gauransh Sawhney",
                "Dhruv Khut",
                "Sahil Nawale",
                "Pushkar Aggrawal",
                "Prasenjit Bhavathankar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02621v1",
                "http://arxiv.org/pdf/2311.02621v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.IR",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02617v1",
            "title": "TFNet: Tuning Fork Network with Neighborhood Pixel Aggregation for\n  Improved Building Footprint Extraction",
            "updated": "2023-11-05T10:52:16Z",
            "published": "2023-11-05T10:52:16Z",
            "summary": "This paper considers the problem of extracting building footprints from\nsatellite imagery -- a task that is critical for many urban planning and\ndecision-making applications. While recent advancements in deep learning have\nmade great strides in automated detection of building footprints,\nstate-of-the-art methods available in existing literature often generate\nerroneous results for areas with densely connected buildings. Moreover, these\nmethods do not incorporate the context of neighborhood images during training\nthus generally resulting in poor performance at image boundaries. In light of\nthese gaps, we propose a novel Tuning Fork Network (TFNet) design for deep\nsemantic segmentation that not only performs well for widely-spaced building\nbut also has good performance for buildings that are closely packed together.\nThe novelty of TFNet architecture lies in a a single encoder followed by two\nparallel decoders to separately reconstruct the building footprint and the\nbuilding edge. In addition, the TFNet design is coupled with a novel\nmethodology of incorporating neighborhood information at the tile boundaries\nduring the training process. This methodology further improves performance,\nespecially at the tile boundaries. For performance comparisons, we utilize the\nSpaceNet2 and WHU datasets, as well as a dataset from an area in Lahore,\nPakistan that captures closely connected buildings. For all three datasets, the\nproposed methodology is found to significantly outperform benchmark methods.",
            "author": [
                "Muhammad Ahmad Waseem",
                "Muhammad Tahir",
                "Zubair Khalid",
                "Momin Uppal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02617v1",
                "http://arxiv.org/pdf/2311.02617v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02610v1",
            "title": "An adaptive standardisation model for Day-Ahead electricity price\n  forecasting",
            "updated": "2023-11-05T09:40:19Z",
            "published": "2023-11-05T09:40:19Z",
            "summary": "The study of Day-Ahead prices in the electricity market is one of the most\npopular problems in time series forecasting. Previous research has focused on\nemploying increasingly complex learning algorithms to capture the sophisticated\ndynamics of the market. However, there is a threshold where increased\ncomplexity fails to yield substantial improvements. In this work, we propose an\nalternative approach by introducing an adaptive standardisation to mitigate the\neffects of dataset shifts that commonly occur in the market. By doing so,\nlearning algorithms can prioritize uncovering the true relationship between the\ntarget variable and the explanatory variables. We investigate four distinct\nmarkets, including two novel datasets, previously unexplored in the literature.\nThese datasets provide a more realistic representation of the current market\ncontext, that conventional datasets do not show. The results demonstrate a\nsignificant improvement across all four markets, using learning algorithms that\nare less complex yet widely accepted in the literature. This significant\nadvancement unveils opens up new lines of research in this field, highlighting\nthe potential of adaptive transformations in enhancing the performance of\nforecasting models.",
            "author": [
                "Carlos Sebasti\u00e1n",
                "Carlos E. Gonz\u00e1lez-Guill\u00e9n",
                "Jes\u00fas Juan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02610v1",
                "http://arxiv.org/pdf/2311.02610v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02608v1",
            "title": "Deep Learning-based 3D Point Cloud Classification: A Systematic Survey\n  and Outlook",
            "updated": "2023-11-05T09:28:43Z",
            "published": "2023-11-05T09:28:43Z",
            "summary": "In recent years, point cloud representation has become one of the research\nhotspots in the field of computer vision, and has been widely used in many\nfields, such as autonomous driving, virtual reality, robotics, etc. Although\ndeep learning techniques have achieved great success in processing regular\nstructured 2D grid image data, there are still great challenges in processing\nirregular, unstructured point cloud data. Point cloud classification is the\nbasis of point cloud analysis, and many deep learning-based methods have been\nwidely used in this task. Therefore, the purpose of this paper is to provide\nresearchers in this field with the latest research progress and future trends.\nFirst, we introduce point cloud acquisition, characteristics, and challenges.\nSecond, we review 3D data representations, storage formats, and commonly used\ndatasets for point cloud classification. We then summarize deep learning-based\nmethods for point cloud classification and complement recent research work.\nNext, we compare and analyze the performance of the main methods. Finally, we\ndiscuss some challenges and future directions for point cloud classification.",
            "author": [
                "Huang Zhang",
                "Changshuo Wang",
                "Shengwei Tian",
                "Baoli Lu",
                "Liping Zhang",
                "Xin Ning",
                "Xiao Bai"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.displa.2023.102456",
                "http://arxiv.org/abs/2311.02608v1",
                "http://arxiv.org/pdf/2311.02608v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02607v1",
            "title": "AI Techniques for Uncovering Resolved Planetary Nebula Candidates from\n  Wide-field VPHAS+ Survey Data",
            "updated": "2023-11-05T09:21:49Z",
            "published": "2023-11-05T09:21:49Z",
            "summary": "AI and deep learning techniques are beginning to play an increasing role in\nastronomy as a necessary tool to deal with the data avalanche. Here we describe\nan application for finding resolved Planetary Nebulae (PNe) in crowded,\nwide-field, narrow-band H-alpha survey imagery in the Galactic plane. PNe are\nimportant to study late stage of stellar evolution of low to intermediate-mass\nstars. However, the confirmed ~3800 Galactic PNe fall far short of the numbers\nexpected. Traditional visual searching for resolved PNe is time-consuming due\nto the large data size and areal coverage of modern astronomical surveys,\nespecially those taken in narrow-band filters highlighting emission nebulae. To\ntest and facilitate more objective, reproducible, efficient and reliable trawls\nfor PNe candidates we have developed a new, deep learning algorithm. In this\npaper, we applied the algorithm to several H-alpha digital surveys (e.g. IPHAS\nand VPHAS+). The training and validation dataset was built with true PNe from\nthe HASH database. After transfer learning, it was then applied to the VPHAS+\nsurvey. We examined 979 out of 2284 survey fields with each survey field\ncovering 1 * 1 deg^2. With a sample of 454 PNe from the IPHAS as our validation\nset, our algorithm correctly identified 444 of these objects (97.8%), with only\n16 explicable 'false' positives. Our model returned ~20,000 detections,\nincluding 2637 known PNe and many other kinds of catalogued non-PNe such as HII\nregions. A total of 815 new high-quality PNe candidates were found, 31 of which\nwere selected as top-quality targets for subsequent optical spectroscopic\nfollow-up. Representative preliminary confirmatory spectroscopy results are\npresented here to demonstrate the effectiveness of our techniques with full\ndetails to be given in paper-II.",
            "author": [
                "Ruiqi Sun",
                "Yushan Li",
                "Quentin Parker",
                "Jiaxin Li",
                "Xu Li",
                "Liang Cao",
                "Peng Jia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02607v1",
                "http://arxiv.org/pdf/2311.02607v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00018v2",
            "title": "Security Challenges in Autonomous Systems Design",
            "updated": "2023-12-04T03:45:38Z",
            "published": "2023-11-05T09:17:39Z",
            "summary": "Autonomous systems are emerging in many application domains. With the recent\nadvancements in artificial intelligence and machine learning, sensor\ntechnology, perception algorithms and robotics, scenarios previously requiring\nstrong human involvement can be handled by autonomous systems. With the\nindependence from human control, cybersecurity of such systems becomes even\nmore critical as no human intervention in case of undesired behavior is\npossible. In this context, this paper discusses emerging security challenges in\nautonomous systems design which arise in many domains such as autonomous\nincident response, risk assessment, data availability, systems interaction,\ntrustworthiness, updatability, access control, as well as the reliability and\nexplainability of machine learning methods. In all these areas, this paper\nthoroughly discusses the state of the art, identifies emerging security\nchallenges and proposes research directions to address these challenges for\ndeveloping secure autonomous systems.",
            "author": [
                "Mohammad Hamad",
                "Sebastian Steinhorst"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00018v2",
                "http://arxiv.org/pdf/2312.00018v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02602v1",
            "title": "Get the Ball Rolling: Alerting Autonomous Robots When to Help to Close\n  the Healthcare Loop",
            "updated": "2023-11-05T08:57:59Z",
            "published": "2023-11-05T08:57:59Z",
            "summary": "To facilitate the advancement of research in healthcare robots without human\nintervention or commands, we introduce the Autonomous Helping Challenge, along\nwith a crowd-sourcing large-scale dataset. The goal is to create healthcare\nrobots that possess the ability to determine when assistance is necessary,\ngenerate useful sub-tasks to aid in planning, carry out these plans through a\nphysical robot, and receive feedback from the environment in order to generate\nnew tasks and continue the process. Besides the general challenge in open-ended\nscenarios, Autonomous Helping focuses on three specific challenges: autonomous\ntask generation, the gap between the current scene and static commonsense, and\nthe gap between language instruction and the real world. Additionally, we\npropose Helpy, a potential approach to close the healthcare loop in the\nlearning-free setting.",
            "author": [
                "Jiaxin Shen",
                "Yanyao Liu",
                "Ziming Wang",
                "Ziyuan Jiao",
                "Yufeng Chen",
                "Wenjuan Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02602v1",
                "http://arxiv.org/pdf/2311.02602v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02601v1",
            "title": "Optimizing Implicit Neural Representations from Point Clouds via\n  Energy-Based Models",
            "updated": "2023-11-05T08:57:22Z",
            "published": "2023-11-05T08:57:22Z",
            "summary": "Reconstructing a continuous surface from an unoritented 3D point cloud is a\nfundamental task in 3D shape processing. In recent years, several methods have\nbeen proposed to address this problem using implicit neural representations\n(INRs). In this study, we propose a method to optimize INRs using energy-based\nmodels (EBMs). By employing the absolute value of the coordinate-based neural\nnetworks as the energy function, the INR can be optimized through the\nestimation of the point cloud distribution by the EBM. In addition, appropriate\nparameter settings of the EBM enable the model to consider the magnitude of\npoint cloud noise. Our experiments confirmed that the proposed method is more\nrobust against point cloud noise than conventional surface reconstruction\nmethods.",
            "author": [
                "Ryutaro Yamauchi",
                "Jinya Sakurai",
                "Ryo Furukawa",
                "Tatsushi Matsubayashi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02601v1",
                "http://arxiv.org/pdf/2311.02601v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02599v1",
            "title": "Learning Class and Domain Augmentations for Single-Source Open-Domain\n  Generalization",
            "updated": "2023-11-05T08:53:07Z",
            "published": "2023-11-05T08:53:07Z",
            "summary": "Single-source open-domain generalization (SS-ODG) addresses the challenge of\nlabeled source domains with supervision during training and unlabeled novel\ntarget domains during testing. The target domain includes both known classes\nfrom the source domain and samples from previously unseen classes. Existing\ntechniques for SS-ODG primarily focus on calibrating source-domain classifiers\nto identify open samples in the target domain. However, these methods struggle\nwith visually fine-grained open-closed data, often misclassifying open samples\nas closed-set classes. Moreover, relying solely on a single source domain\nrestricts the model's ability to generalize. To overcome these limitations, we\npropose a novel framework called SODG-Net that simultaneously synthesizes novel\ndomains and generates pseudo-open samples using a learning-based objective, in\ncontrast to the ad-hoc mixing strategies commonly found in the literature. Our\napproach enhances generalization by diversifying the styles of known class\nsamples using a novel metric criterion and generates diverse pseudo-open\nsamples to train a unified and confident multi-class classifier capable of\nhandling both open and closed-set data. Extensive experimental evaluations\nconducted on multiple benchmarks consistently demonstrate the superior\nperformance of SODG-Net compared to the literature.",
            "author": [
                "Prathmesh Bele",
                "Valay Bundele",
                "Avigyan Bhattacharya",
                "Ankit Jha",
                "Gemma Roig",
                "Biplab Banerjee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02599v1",
                "http://arxiv.org/pdf/2311.02599v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02598v1",
            "title": "Automated Camera Calibration via Homography Estimation with GNNs",
            "updated": "2023-11-05T08:45:26Z",
            "published": "2023-11-05T08:45:26Z",
            "summary": "Over the past few decades, a significant rise of camera-based applications\nfor traffic monitoring has occurred. Governments and local administrations are\nincreasingly relying on the data collected from these cameras to enhance road\nsafety and optimize traffic conditions. However, for effective data\nutilization, it is imperative to ensure accurate and automated calibration of\nthe involved cameras. This paper proposes a novel approach to address this\nchallenge by leveraging the topological structure of intersections. We propose\na framework involving the generation of a set of synthetic intersection\nviewpoint images from a bird's-eye-view image, framed as a graph of virtual\ncameras to model these images. Using the capabilities of Graph Neural Networks,\nwe effectively learn the relationships within this graph, thereby facilitating\nthe estimation of a homography matrix. This estimation leverages the\nneighbourhood representation for any real-world camera and is enhanced by\nexploiting multiple images instead of a single match. In turn, the homography\nmatrix allows the retrieval of extrinsic calibration parameters. As a result,\nthe proposed framework demonstrates superior performance on both synthetic\ndatasets and real-world cameras, setting a new state-of-the-art benchmark.",
            "author": [
                "Giacomo D'Amicantonio",
                "Egor Bondarev",
                "Peter H. N. De With"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02598v1",
                "http://arxiv.org/pdf/2311.02598v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02594v1",
            "title": "scBeacon: single-cell biomarker extraction via identifying paired cell\n  clusters across biological conditions with contrastive siamese networks",
            "updated": "2023-11-05T08:27:24Z",
            "published": "2023-11-05T08:27:24Z",
            "summary": "Despite the breakthroughs in biomarker discovery facilitated by differential\ngene analysis, challenges remain, particularly at the single-cell level.\nTraditional methodologies heavily rely on user-supplied cell annotations,\nfocusing on individually expressed data, often neglecting the critical\ninteractions between biological conditions, such as healthy versus diseased\nstates. In response, here we introduce scBeacon, an innovative framework built\nupon a deep contrastive siamese network. scBeacon pioneers an unsupervised\napproach, adeptly identifying matched cell populations across varied\nconditions, enabling a refined differential gene analysis. By utilizing a\nVQ-VAE framework, a contrastive siamese network, and a greedy iterative\nstrategy, scBeacon effectively pinpoints differential genes that hold potential\nas key biomarkers. Comprehensive evaluations on a diverse array of datasets\nvalidate scBeacon's superiority over existing single-cell differential gene\nanalysis tools. Its precision and adaptability underscore its significant role\nin enhancing diagnostic accuracy in biomarker discovery. With the emphasis on\nthe importance of biomarkers in diagnosis, scBeacon is positioned to be a\npivotal asset in the evolution of personalized medicine and targeted\ntreatments.",
            "author": [
                "Chenyu Liu",
                "Kweon Yong Jin",
                "Jun Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02594v1",
                "http://arxiv.org/pdf/2311.02594v1"
            ],
            "primary_category": "q-bio.GN",
            "category": [
                "q-bio.GN",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02586v1",
            "title": "Synthetic Tumor Manipulation: With Radiomics Features",
            "updated": "2023-11-05T08:07:50Z",
            "published": "2023-11-05T08:07:50Z",
            "summary": "We introduce RadiomicsFill, a synthetic tumor generator conditioned on\nradiomics features, enabling detailed control and individual manipulation of\ntumor subregions. This conditioning leverages conventional high-dimensional\nfeatures of the tumor (i.e., radiomics features) and thus is biologically\nwell-grounded. Our model combines generative adversarial networks,\nradiomics-feature conditioning, and multi-task learning. Through experiments\nwith glioma patients, RadiomicsFill demonstrated its capability to generate\ndiverse, realistic tumors and its fine-tuning ability for specific radiomics\nfeatures like 'Pixel Surface' and 'Shape Sphericity'. The ability of\nRadiomicsFill to generate an unlimited number of realistic synthetic tumors\noffers notable prospects for both advancing medical imaging research and\npotential clinical applications.",
            "author": [
                "Inye Na",
                "Jonghun Kim",
                "Hyunjin Park"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02586v1",
                "http://arxiv.org/pdf/2311.02586v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03396v1",
            "title": "Differentially Private Pre-Trained Model Fusion using Decentralized\n  Federated Graph Matching",
            "updated": "2023-11-05T07:56:00Z",
            "published": "2023-11-05T07:56:00Z",
            "summary": "Model fusion is becoming a crucial component in the context of\nmodel-as-a-service scenarios, enabling the delivery of high-quality model\nservices to local users. However, this approach introduces privacy risks and\nimposes certain limitations on its applications. Ensuring secure model exchange\nand knowledge fusion among users becomes a significant challenge in this\nsetting. To tackle this issue, we propose PrivFusion, a novel architecture that\npreserves privacy while facilitating model fusion under the constraints of\nlocal differential privacy. PrivFusion leverages a graph-based structure,\nenabling the fusion of models from multiple parties without necessitating\nretraining. By employing randomized mechanisms, PrivFusion ensures privacy\nguarantees throughout the fusion process. To enhance model privacy, our\napproach incorporates a hybrid local differentially private mechanism and\ndecentralized federated graph matching, effectively protecting both activation\nvalues and weights. Additionally, we introduce a perturbation filter adapter to\nalleviate the impact of randomized noise, thereby preserving the utility of the\nfused model. Through extensive experiments conducted on diverse image datasets\nand real-world healthcare applications, we provide empirical evidence\nshowcasing the effectiveness of PrivFusion in maintaining model performance\nwhile preserving privacy. Our contributions offer valuable insights and\npractical solutions for secure and collaborative data analysis within the\ndomain of privacy-preserving model fusion.",
            "author": [
                "Qian Chen",
                "Yiqiang Chen",
                "Xinlong Jiang",
                "Teng Zhang",
                "Weiwei Dai",
                "Wuliang Huang",
                "Zhen Yan",
                "Bo Ye"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03396v1",
                "http://arxiv.org/pdf/2311.03396v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02583v1",
            "title": "SSL-DG: Rethinking and Fusing Semi-supervised Learning and Domain\n  Generalization in Medical Image Segmentation",
            "updated": "2023-11-05T07:44:40Z",
            "published": "2023-11-05T07:44:40Z",
            "summary": "Deep learning-based medical image segmentation is an essential yet\nchallenging task in clinical practice, which arises from restricted access to\nannotated data coupled with the occurrence of domain shifts. Previous attempts\nhave focused on isolated solutions, while disregarding their\ninter-connectedness. In this paper, we rethink the relationship between\nsemi-supervised learning (SSL) and domain generalization (DG), which are the\ncutting-edge approaches to address the annotated data-driven constraints and\nthe domain shift issues. Inspired by class-level representation, we show that\nunseen target data can be represented by a linear combination of source data,\nwhich can be achieved by simple data augmentation. The augmented data enrich\ndomain distributions while having semantic consistency, aligning with the\nprinciples of consistency-based SSL. Accordingly, we propose SSL-DG, fusing DG\nand SSL, to achieve cross-domain generalization with limited annotations.\nSpecifically, the global and focal region augmentation, together with an\naugmentation scale-balancing mechanism, are used to construct a mask-based\ndomain diffusion augmentation module to significantly enrich domain diversity.\nIn order to obtain consistent predictions for the same source data in different\nnetworks, we use uncertainty estimation and a deep mutual learning strategy to\nenforce the consistent constraint. Extensive experiments including ablation\nstudies are designed to validate the proposed SSL-DG. The results demonstrate\nthat our SSL-DG significantly outperforms state-of-the-art solutions in two\nchallenging DG tasks with limited annotations. Code is available at\nhttps://github.com/yezanting/SSL-DG.",
            "author": [
                "Zanting Ye"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02583v1",
                "http://arxiv.org/pdf/2311.02583v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02581v1",
            "title": "Yet Another Generative Model For Room Impulse Response Estimation",
            "updated": "2023-11-05T07:25:39Z",
            "published": "2023-11-05T07:25:39Z",
            "summary": "Recent neural room impulse response (RIR) estimators typically comprise an\nencoder for reference audio analysis and a generator for RIR synthesis.\nEspecially, it is the performance of the generator that directly influences the\noverall estimation quality. In this context, we explore an alternate generator\narchitecture for improved performance. We first train an autoencoder with\nresidual quantization to learn a discrete latent token space, where each token\nrepresents a small time-frequency patch of the RIR. Then, we cast the RIR\nestimation problem as a reference-conditioned autoregressive token generation\ntask, employing transformer variants that operate across frequency, time, and\nquantization depth axes. This way, we address the standard blind estimation\ntask and additional acoustic matching problem, which aims to find an RIR that\nmatches the source signal to the target signal's reverberation characteristics.\nExperimental results show that our system is preferable to other baselines\nacross various evaluation metrics.",
            "author": [
                "Sungho Lee",
                "Hyeong-Seok Choi",
                "Kyogu Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02581v1",
                "http://arxiv.org/pdf/2311.02581v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02579v1",
            "title": "mahaNLP: A Marathi Natural Language Processing Library",
            "updated": "2023-11-05T06:59:59Z",
            "published": "2023-11-05T06:59:59Z",
            "summary": "We present mahaNLP, an open-source natural language processing (NLP) library\nspecifically built for the Marathi language. It aims to enhance the support for\nthe low-resource Indian language Marathi in the field of NLP. It is an\neasy-to-use, extensible, and modular toolkit for Marathi text analysis built on\nstate-of-the-art MahaBERT-based transformer models. Our work holds significant\nimportance as other existing Indic NLP libraries provide basic Marathi\nprocessing support and rely on older models with restricted performance. Our\ntoolkit stands out by offering a comprehensive array of NLP tasks, encompassing\nboth fundamental preprocessing tasks and advanced NLP tasks like sentiment\nanalysis, NER, hate speech detection, and sentence completion. This paper\nfocuses on an overview of the mahaNLP framework, its features, and its usage.\nThis work is a part of the L3Cube MahaNLP initiative, more information about it\ncan be found at https://github.com/l3cube-pune/MarathiNLP .",
            "author": [
                "Vidula Magdum",
                "Omkar Dhekane",
                "Sharayu Hiwarkhedkar",
                "Saloni Mittal",
                "Raviraj Joshi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02579v1",
                "http://arxiv.org/pdf/2311.02579v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02577v2",
            "title": "Steady-State Analysis and Online Learning for Queues with Hawkes\n  Arrivals",
            "updated": "2023-11-13T07:16:00Z",
            "published": "2023-11-05T06:46:26Z",
            "summary": "We investigate the long-run behavior of single-server queues with Hawkes\narrivals and general service distributions and related optimization problems.\nIn detail, utilizing novel coupling techniques, we establish finite moment\nbounds for the stationary distribution of the workload and busy period\nprocesses. In addition, we are able to show that, those queueing processes\nconverge exponentially fast to their stationary distribution. Based on these\ntheoretic results, we develop an efficient numerical algorithm to solve the\noptimal staffing problem for the Hawkes queues in a data-driven manner.\nNumerical results indicate a sharp difference in staffing for Hawkes queues,\ncompared to the classic GI/GI/1 model, especially in the heavy-traffic regime.",
            "author": [
                "Xinyun Chen",
                "Guiyu Hong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02577v2",
                "http://arxiv.org/pdf/2311.02577v2"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03395v1",
            "title": "Newvision: application for helping blind people using deep learning",
            "updated": "2023-11-05T06:23:10Z",
            "published": "2023-11-05T06:23:10Z",
            "summary": "As able-bodied people, we often take our vision for granted. For people who\nare visually impaired, however, their disability can have a significant impact\non their daily lives. We are developing proprietary headgear that will help\nvisually impaired people navigate their surroundings, identify objects and\npeople, read text, and avoid obstacles. The headgear will use a combination of\ncomputer vision, distance estimation with ultrasonic sensors, voice\nrecognition, and voice assistants to provide users with real-time information\nabout their environment. Users will be able to interact with the headgear\nthrough voice commands, such as ''What is that?'' to identify an object or\n''Navigate to the front door'' to find their way around. The headgear will then\nprovide the user with a verbal description of the object or spoken navigation\ninstructions. We believe that this headgear has the potential to make a\nsignificant difference in the lives of visually impaired people, allowing them\nto live more independently and participate more fully in society.",
            "author": [
                "Kumar Srinivas Bobba",
                "Kartheeban K",
                "Vamsi Krishna Sai Boddu",
                "Vijaya Mani Surendra Bolla",
                "Dinesh Bugga"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03395v1",
                "http://arxiv.org/pdf/2311.03395v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "I.2; I.4; I.7; C.3; J.7; J.0"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02572v1",
            "title": "Multiple Object Tracking based on Occlusion-Aware Embedding Consistency\n  Learning",
            "updated": "2023-11-05T06:08:58Z",
            "published": "2023-11-05T06:08:58Z",
            "summary": "The Joint Detection and Embedding (JDE) framework has achieved remarkable\nprogress for multiple object tracking. Existing methods often employ extracted\nembeddings to re-establish associations between new detections and previously\ndisrupted tracks. However, the reliability of embeddings diminishes when the\nregion of the occluded object frequently contains adjacent objects or clutters,\nespecially in scenarios with severe occlusion. To alleviate this problem, we\npropose a novel multiple object tracking method based on visual embedding\nconsistency, mainly including: 1) Occlusion Prediction Module (OPM) and 2)\nOcclusion-Aware Association Module (OAAM). The OPM predicts occlusion\ninformation for each true detection, facilitating the selection of valid\nsamples for consistency learning of the track's visual embedding. The OAAM\nleverages occlusion cues and visual embeddings to generate two separate\nembeddings for each track, guaranteeing consistency in both unoccluded and\noccluded detections. By integrating these two modules, our method is capable of\naddressing track interruptions caused by occlusion in online tracking\nscenarios. Extensive experimental results demonstrate that our approach\nachieves promising performance levels in both unoccluded and occluded tracking\nscenarios.",
            "author": [
                "Yaoqi Hu",
                "Axi Niu",
                "Yu Zhu",
                "Qingsen Yan",
                "Jinqiu Sun",
                "Yanning Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02572v1",
                "http://arxiv.org/pdf/2311.02572v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02565v1",
            "title": "KITS: Inductive Spatio-Temporal Kriging with Increment Training Strategy",
            "updated": "2023-11-05T04:43:48Z",
            "published": "2023-11-05T04:43:48Z",
            "summary": "Sensors are commonly deployed to perceive the environment. However, due to\nthe high cost, sensors are usually sparsely deployed. Kriging is the tailored\ntask to infer the unobserved nodes (without sensors) using the observed source\nnodes (with sensors). The essence of kriging task is transferability. Recently,\nseveral inductive spatio-temporal kriging methods have been proposed based on\ngraph neural networks, being trained based on a graph built on top of observed\nnodes via pretext tasks such as masking nodes out and reconstructing them.\nHowever, the graph in training is inevitably much sparser than the graph in\ninference that includes all the observed and unobserved nodes. The learned\npattern cannot be well generalized for inference, denoted as graph gap. To\naddress this issue, we first present a novel Increment training strategy:\ninstead of masking nodes (and reconstructing them), we add virtual nodes into\nthe training graph so as to mitigate the graph gap issue naturally.\nNevertheless, the empty-shell virtual nodes without labels could have\nbad-learned features and lack supervision signals. To solve these issues, we\npair each virtual node with its most similar observed node and fuse their\nfeatures together; to enhance the supervision signal, we construct reliable\npseudo labels for virtual nodes. As a result, the learned pattern of virtual\nnodes could be safely transferred to real unobserved nodes for reliable\nkriging. We name our new Kriging model with Increment Training Strategy as\nKITS. Extensive experiments demonstrate that KITS consistently outperforms\nexisting kriging methods by large margins, e.g., the improvement over MAE score\ncould be as high as 18.33%.",
            "author": [
                "Qianxiong Xu",
                "Cheng Long",
                "Ziyue Li",
                "Sijie Ruan",
                "Rui Zhao",
                "Zhishuai Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02565v1",
                "http://arxiv.org/pdf/2311.02565v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02563v1",
            "title": "Time Series Synthesis Using the Matrix Profile for Anonymization",
            "updated": "2023-11-05T04:27:24Z",
            "published": "2023-11-05T04:27:24Z",
            "summary": "Publishing and sharing data is crucial for the data mining community,\nallowing collaboration and driving open innovation. However, many researchers\ncannot release their data due to privacy regulations or fear of leaking\nconfidential business information. To alleviate such issues, we propose the\nTime Series Synthesis Using the Matrix Profile (TSSUMP) method, where\nsynthesized time series can be released in lieu of the original data. The\nTSSUMP method synthesizes time series by preserving similarity join information\n(i.e., Matrix Profile) while reducing the correlation between the synthesized\nand the original time series. As a result, neither the values for the\nindividual time steps nor the local patterns (or shapes) from the original data\ncan be recovered, yet the resulting data can be used for downstream tasks that\ndata analysts are interested in. We concentrate on similarity joins because\nthey are one of the most widely applied time series data mining routines across\ndifferent data mining tasks. We test our method on a case study of ECG and\ngender masking prediction. In this case study, the gender information is not\nonly removed from the synthesized time series, but the synthesized time series\nalso preserves enough information from the original time series. As a result,\nunmodified data mining tools can obtain near-identical performance on the\nsynthesized time series as on the original time series.",
            "author": [
                "Audrey Der",
                "Chin-Chia Michael Yeh",
                "Yan Zheng",
                "Junpeng Wang",
                "Huiyuan Chen",
                "Zhongfang Zhuang",
                "Liang Wang",
                "Wei Zhang",
                "Eamonn Keogh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02563v1",
                "http://arxiv.org/pdf/2311.02563v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "cs.AI",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02561v1",
            "title": "Ego-Network Transformer for Subsequence Classification in Time Series\n  Data",
            "updated": "2023-11-05T04:21:42Z",
            "published": "2023-11-05T04:21:42Z",
            "summary": "Time series classification is a widely studied problem in the field of time\nseries data mining. Previous research has predominantly focused on scenarios\nwhere relevant or foreground subsequences have already been extracted, with\neach subsequence corresponding to a single label. However, real-world time\nseries data often contain foreground subsequences that are intertwined with\nbackground subsequences. Successfully classifying these relevant subsequences\nrequires not only distinguishing between different classes but also accurately\nidentifying the foreground subsequences amidst the background. To address this\nchallenge, we propose a novel subsequence classification method that represents\neach subsequence as an ego-network, providing crucial nearest neighbor\ninformation to the model. The ego-networks of all subsequences collectively\nform a time series subsequence graph, and we introduce an algorithm to\nefficiently construct this graph. Furthermore, we have demonstrated the\nsignificance of enforcing temporal consistency in the prediction of adjacent\nsubsequences for the subsequence classification problem. To evaluate the\neffectiveness of our approach, we conducted experiments using 128 univariate\nand 30 multivariate time series datasets. The experimental results demonstrate\nthe superior performance of our method compared to alternative approaches.\nSpecifically, our method outperforms the baseline on 104 out of 158 datasets.",
            "author": [
                "Chin-Chia Michael Yeh",
                "Huiyuan Chen",
                "Yujie Fan",
                "Xin Dai",
                "Yan Zheng",
                "Vivian Lai",
                "Junpeng Wang",
                "Zhongfang Zhuang",
                "Liang Wang",
                "Wei Zhang",
                "Eamonn Keogh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02561v1",
                "http://arxiv.org/pdf/2311.02561v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02560v1",
            "title": "Temporal Treasure Hunt: Content-based Time Series Retrieval System for\n  Discovering Insights",
            "updated": "2023-11-05T04:12:13Z",
            "published": "2023-11-05T04:12:13Z",
            "summary": "Time series data is ubiquitous across various domains such as finance,\nhealthcare, and manufacturing, but their properties can vary significantly\ndepending on the domain they originate from. The ability to perform\nContent-based Time Series Retrieval (CTSR) is crucial for identifying unknown\ntime series examples. However, existing CTSR works typically focus on\nretrieving time series from a single domain database, which can be inadequate\nif the user does not know the source of the query time series. This limitation\nmotivates us to investigate the CTSR problem in a scenario where the database\ncontains time series from multiple domains. To facilitate this investigation,\nwe introduce a CTSR benchmark dataset that comprises time series data from a\nvariety of domains, such as motion, power demand, and traffic. This dataset is\nsourced from a publicly available time series classification dataset archive,\nmaking it easily accessible to researchers in the field. We compare several\npopular methods for modeling and retrieving time series data using this\nbenchmark dataset. Additionally, we propose a novel distance learning model\nthat outperforms the existing methods. Overall, our study highlights the\nimportance of addressing the CTSR problem across multiple domains and provides\na useful benchmark dataset for future research.",
            "author": [
                "Chin-Chia Michael Yeh",
                "Huiyuan Chen",
                "Xin Dai",
                "Yan Zheng",
                "Yujie Fan",
                "Vivian Lai",
                "Junpeng Wang",
                "Audrey Der",
                "Zhongfang Zhuang",
                "Liang Wang",
                "Wei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02560v1",
                "http://arxiv.org/pdf/2311.02560v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02557v1",
            "title": "Fast Minimization of Expected Logarithmic Loss via Stochastic Dual\n  Averaging",
            "updated": "2023-11-05T03:33:44Z",
            "published": "2023-11-05T03:33:44Z",
            "summary": "Consider the problem of minimizing an expected logarithmic loss over either\nthe probability simplex or the set of quantum density matrices. This problem\nencompasses tasks such as solving the Poisson inverse problem, computing the\nmaximum-likelihood estimate for quantum state tomography, and approximating\npositive semi-definite matrix permanents with the currently tightest\napproximation ratio. Although the optimization problem is convex, standard\niteration complexity guarantees for first-order methods do not directly apply\ndue to the absence of Lipschitz continuity and smoothness in the loss function.\n  In this work, we propose a stochastic first-order algorithm named $B$-sample\nstochastic dual averaging with the logarithmic barrier. For the Poisson inverse\nproblem, our algorithm attains an $\\varepsilon$-optimal solution in $\\tilde{O}\n(d^2/\\varepsilon^2)$ time, matching the state of the art. When computing the\nmaximum-likelihood estimate for quantum state tomography, our algorithm yields\nan $\\varepsilon$-optimal solution in $\\tilde{O} (d^3/\\varepsilon^2)$ time,\nwhere $d$ denotes the dimension. This improves on the time complexities of\nexisting stochastic first-order methods by a factor of $d^{\\omega-2}$ and those\nof batch methods by a factor of $d^2$, where $\\omega$ denotes the matrix\nmultiplication exponent. Numerical experiments demonstrate that empirically,\nour algorithm outperforms existing methods with explicit complexity guarantees.",
            "author": [
                "Chung-En Tsai",
                "Hao-Chung Cheng",
                "Yen-Huan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02557v1",
                "http://arxiv.org/pdf/2311.02557v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02552v1",
            "title": "IPVNet: Learning Implicit Point-Voxel Features for Open-Surface 3D\n  Reconstruction",
            "updated": "2023-11-05T03:01:36Z",
            "published": "2023-11-05T03:01:36Z",
            "summary": "Reconstruction of 3D open surfaces (e.g., non-watertight meshes) is an\nunderexplored area of computer vision. Recent learning-based implicit\ntechniques have removed previous barriers by enabling reconstruction in\narbitrary resolutions. Yet, such approaches often rely on distinguishing\nbetween the inside and outside of a surface in order to extract a zero level\nset when reconstructing the target. In the case of open surfaces, this\ndistinction often leads to artifacts such as the artificial closing of surface\ngaps. However, real-world data may contain intricate details defined by salient\nsurface gaps. Implicit functions that regress an unsigned distance field have\nshown promise in reconstructing such open surfaces. Nonetheless, current\nunsigned implicit methods rely on a discretized representation of the raw data.\nThis not only bounds the learning process to the representation's resolution,\nbut it also introduces outliers in the reconstruction. To enable accurate\nreconstruction of open surfaces without introducing outliers, we propose a\nlearning-based implicit point-voxel model (IPVNet). IPVNet predicts the\nunsigned distance between a surface and a query point in 3D space by leveraging\nboth raw point cloud data and its discretized voxel counterpart. Experiments on\nsynthetic and real-world public datasets demonstrates that IPVNet outperforms\nthe state of the art while producing far fewer outliers in the resulting\nreconstruction.",
            "author": [
                "Mohammad Samiul Arshad",
                "William J. Beksi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02552v1",
                "http://arxiv.org/pdf/2311.02552v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02551v1",
            "title": "High-dimensional Bid Learning for Energy Storage Bidding in Energy\n  Markets",
            "updated": "2023-11-05T02:59:53Z",
            "published": "2023-11-05T02:59:53Z",
            "summary": "With the growing penetration of renewable energy resource, electricity market\nprices have exhibited greater volatility. Therefore, it is important for Energy\nStorage Systems(ESSs) to leverage the multidimensional nature of energy market\nbids to maximize profitability. However, current learning methods cannot fully\nutilize the high-dimensional price-quantity bids in the energy markets. To\naddress this challenge, we modify the common reinforcement learning(RL) process\nby proposing a new bid representation method called Neural Network Embedded\nBids (NNEBs). NNEBs refer to market bids that are represented by monotonic\nneural networks with discrete outputs. To achieve effective learning of NNEBs,\nwe first learn a neural network as a strategic mapping from the market price to\nESS power output with RL. Then, we re-train the network with two training\nmodifications to make the network output monotonic and discrete. Finally, the\nneural network is equivalently converted into a high-dimensional bid for\nbidding. We conducted experiments over real-world market datasets. Our studies\nshow that the proposed method achieves 18% higher profit than the baseline and\nup to 78% profit of the optimal market bidder.",
            "author": [
                "Jinyu Liu",
                "Hongye Guo",
                "Qinghu Tang",
                "En Lu",
                "Qiuna Cai",
                "Qixin Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02551v1",
                "http://arxiv.org/pdf/2311.02551v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.GT",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02549v1",
            "title": "3D-Aware Talking-Head Video Motion Transfer",
            "updated": "2023-11-05T02:50:45Z",
            "published": "2023-11-05T02:50:45Z",
            "summary": "Motion transfer of talking-head videos involves generating a new video with\nthe appearance of a subject video and the motion pattern of a driving video.\nCurrent methodologies primarily depend on a limited number of subject images\nand 2D representations, thereby neglecting to fully utilize the multi-view\nappearance features inherent in the subject video. In this paper, we propose a\nnovel 3D-aware talking-head video motion transfer network, Head3D, which fully\nexploits the subject appearance information by generating a\nvisually-interpretable 3D canonical head from the 2D subject frames with a\nrecurrent network. A key component of our approach is a self-supervised 3D head\ngeometry learning module, designed to predict head poses and depth maps from 2D\nsubject video frames. This module facilitates the estimation of a 3D head in\ncanonical space, which can then be transformed to align with driving video\nframes. Additionally, we employ an attention-based fusion network to combine\nthe background and other details from subject frames with the 3D subject head\nto produce the synthetic target video. Our extensive experiments on two public\ntalking-head video datasets demonstrate that Head3D outperforms both 2D and 3D\nprior arts in the practical cross-identity setting, with evidence showing it\ncan be readily adapted to the pose-controllable novel view synthesis task.",
            "author": [
                "Haomiao Ni",
                "Jiachen Liu",
                "Yuan Xue",
                "Sharon X. Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02549v1",
                "http://arxiv.org/pdf/2311.02549v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02546v1",
            "title": "Preliminary Analysis on Second-Order Convergence for Biased Policy\n  Gradient Methods",
            "updated": "2023-11-05T02:33:30Z",
            "published": "2023-11-05T02:33:30Z",
            "summary": "Although the convergence of policy gradient algorithms to first-order\nstationary points is well-established, the objective functions of reinforcement\nlearning problems are typically highly nonconvex. Therefore, recent work has\nfocused on two extensions: ``global\" convergence guarantees under regularity\nassumptions on the function structure, and second-order guarantees for escaping\nsaddle points and convergence to true local minima. Our work expands on the\nlatter approach, avoiding the restrictive assumptions of the former that may\nnot apply to general objective functions. Existing results on vanilla policy\ngradient only consider an unbiased gradient estimator, but practical\nimplementations under the infinite-horizon discounted setting, including both\nMonte-Carlo methods and actor-critic methods, involve gradient descent updates\nwith a biased gradient estimator. We present preliminary results on the\nconvergence of biased policy gradient algorithms to second-order stationary\npoints, leveraging proof techniques from nonconvex optimization. In our next\nsteps we aim to provide the first finite-time second-order convergence analysis\nfor actor-critic algorithms.",
            "author": [
                "Siqiao Mu",
                "Diego Klabjan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02546v1",
                "http://arxiv.org/pdf/2311.02546v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02544v1",
            "title": "Nonlinear Multi-objective Reinforcement Learning with Provable\n  Guarantees",
            "updated": "2023-11-05T02:11:07Z",
            "published": "2023-11-05T02:11:07Z",
            "summary": "We describe RA-E3 (Reward-Aware Explicit Explore or Exploit), an algorithm\nwith provable guarantees for solving a single or multi-objective Markov\nDecision Process (MDP) where we want to maximize the expected value of a\nnonlinear function over accumulated rewards. This allows us to model\nfairness-aware welfare optimization for multi-objective reinforcement learning\nas well as risk-aware reinforcement learning with nonlinear Von\nNeumann-Morgenstern utility functions in the single objective setting. RA-E3\nextends the classic E3 algorithm that solves MDPs with scalar rewards and\nlinear preferences. We first state a distinct reward-aware version of value\niteration that calculates a non-stationary policy that is approximately optimal\nfor a given model of the environment. This sub-procedure is based on an\nextended form of Bellman optimality for nonlinear optimization that explicitly\nconsiders time and current accumulated reward. We then describe how to use this\noptimization procedure in a larger algorithm that must simultaneously learn a\nmodel of the environment. The algorithm learns an approximately optimal policy\nin time that depends polynomially on the MDP size, desired approximation, and\nsmoothness of the nonlinear function, and exponentially on the number of\nobjectives.",
            "author": [
                "Nianli Peng",
                "Brandon Fain"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02544v1",
                "http://arxiv.org/pdf/2311.02544v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02542v1",
            "title": "VR-NeRF: High-Fidelity Virtualized Walkable Spaces",
            "updated": "2023-11-05T02:03:14Z",
            "published": "2023-11-05T02:03:14Z",
            "summary": "We present an end-to-end system for the high-fidelity capture, model\nreconstruction, and real-time rendering of walkable spaces in virtual reality\nusing neural radiance fields. To this end, we designed and built a custom\nmulti-camera rig to densely capture walkable spaces in high fidelity and with\nmulti-view high dynamic range images in unprecedented quality and density. We\nextend instant neural graphics primitives with a novel perceptual color space\nfor learning accurate HDR appearance, and an efficient mip-mapping mechanism\nfor level-of-detail rendering with anti-aliasing, while carefully optimizing\nthe trade-off between quality and speed. Our multi-GPU renderer enables\nhigh-fidelity volume rendering of our neural radiance field model at the full\nVR resolution of dual 2K$\\times$2K at 36 Hz on our custom demo machine. We\ndemonstrate the quality of our results on our challenging high-fidelity\ndatasets, and compare our method and datasets to existing baselines. We release\nour dataset on our project website.",
            "author": [
                "Linning Xu",
                "Vasu Agrawal",
                "William Laney",
                "Tony Garcia",
                "Aayush Bansal",
                "Changil Kim",
                "Samuel Rota Bul\u00f2",
                "Lorenzo Porzi",
                "Peter Kontschieder",
                "Alja\u017e Bo\u017ei\u010d",
                "Dahua Lin",
                "Michael Zollh\u00f6fer",
                "Christian Richardt"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3610548.3618139",
                "http://arxiv.org/abs/2311.02542v1",
                "http://arxiv.org/pdf/2311.02542v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02536v1",
            "title": "Augment the Pairs: Semantics-Preserving Image-Caption Pair Augmentation\n  for Grounding-Based Vision and Language Models",
            "updated": "2023-11-05T01:14:02Z",
            "published": "2023-11-05T01:14:02Z",
            "summary": "Grounding-based vision and language models have been successfully applied to\nlow-level vision tasks, aiming to precisely locate objects referred in\ncaptions. The effectiveness of grounding representation learning heavily relies\non the scale of the training dataset. Despite being a useful data enrichment\nstrategy, data augmentation has received minimal attention in existing vision\nand language tasks as augmentation for image-caption pairs is non-trivial. In\nthis study, we propose a robust phrase grounding model trained with\ntext-conditioned and text-unconditioned data augmentations. Specifically, we\napply text-conditioned color jittering and horizontal flipping to ensure\nsemantic consistency between images and captions. To guarantee image-caption\ncorrespondence in the training samples, we modify the captions according to\npre-defined keywords when applying horizontal flipping. Additionally, inspired\nby recent masked signal reconstruction, we propose to use pixel-level masking\nas a novel form of data augmentation. While we demonstrate our data\naugmentation method with MDETR framework, the proposed approach is applicable\nto common grounding-based vision and language tasks with other frameworks.\nFinally, we show that image encoder pretrained on large-scale image and\nlanguage datasets (such as CLIP) can further improve the results. Through\nextensive experiments on three commonly applied datasets: Flickr30k, referring\nexpressions and GQA, our method demonstrates advanced performance over the\nstate-of-the-arts with various metrics. Code can be found in\nhttps://github.com/amzn/augment-the-pairs-wacv2024.",
            "author": [
                "Jingru Yi",
                "Burak Uzkent",
                "Oana Ignat",
                "Zili Li",
                "Amanmeet Garg",
                "Xiang Yu",
                "Linda Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02536v1",
                "http://arxiv.org/pdf/2311.02536v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02525v1",
            "title": "QOCO: A QoE-Oriented Computation Offloading Algorithm based on Deep\n  Reinforcement Learning for Mobile Edge Computing",
            "updated": "2023-11-04T23:22:42Z",
            "published": "2023-11-04T23:22:42Z",
            "summary": "In the realm of mobile edge computing (MEC), efficient computation task\noffloading plays a pivotal role in ensuring a seamless quality of experience\n(QoE) for users. Maintaining a high QoE is paramount in today's interconnected\nworld, where users demand responsive and reliable services. This challenge\nstands as one of the most primary key factors contributing to handling dynamic\nand uncertain mobile environment. In this study, we delve into computation\noffloading in MEC systems, where strict task processing deadlines and energy\nconstraints can adversely affect the system performance. We formulate the\ncomputation task offloading problem as a Markov decision process (MDP) to\nmaximize the long-term QoE of each user individually. We propose a\ndecentralized QoE-oriented computation offloading (QOCO) algorithm based on\ndeep reinforcement learning (DRL) that empowers mobile devices to make their\noffloading decisions without requiring knowledge of decisions made by other\ndevices. Through numerical studies, we evaluate the performance of QOCO.\nSimulation results validate that the QOCO algorithm efficiently exploits the\ncomputational resources of edge nodes. Consequently, it can complete 14% more\ntasks and reduce task delay and energy consumption by 9% and 6%, respectively.\nThese together contribute to a significant improvement of at least 37% in\naverage QoE compared to an existing algorithm.",
            "author": [
                "Iman Rahmati",
                "Hamed Shah-Mansouri",
                "Ali Movaghar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02525v1",
                "http://arxiv.org/pdf/2311.02525v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10752v1",
            "title": "Differentiating patients with obstructive sleep apnea from healthy\n  controls based on heart rate - blood pressure coupling quantified by\n  entropy-based indices",
            "updated": "2023-11-04T23:05:32Z",
            "published": "2023-11-04T23:05:32Z",
            "summary": "We introduce an entropy-based classification method for pairs of sequences\n(ECPS) for quantifying mutual dependencies in heart rate and beat-to-beat blood\npressure recordings. The purpose of the method is to build a classifier for\ndata in which each item consists of the two intertwined data series taken for\neach subject. The method is based on ordinal patterns, and uses entropy-like\nindices. Machine learning is used to select a subset of indices most suitable\nfor our classification problem in order to build an optimal yet simple model\nfor distinguishing between patients suffering from obstructive sleep apnea and\na control group.",
            "author": [
                "Pawe\u0142 Pilarczyk",
                "Grzegorz Graff",
                "Jos\u00e9 M. Amig\u00f3",
                "Katarzyna Tessmer",
                "Krzysztof Narkiewicz",
                "Beata Graff"
            ],
            "link": [
                "http://dx.doi.org/10.1063/5.0158923",
                "http://arxiv.org/abs/2311.10752v1",
                "http://arxiv.org/pdf/2311.10752v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02522v1",
            "title": "Comparison of Different Machine Learning Approaches to Predict Viscosity\n  of Tri-n-Butyl Phosphate Mixtures Using Experimental Data",
            "updated": "2023-11-04T22:46:50Z",
            "published": "2023-11-04T22:46:50Z",
            "summary": "Tri-n-butyl phosphate (TBP) is a solvent that is commonly used in a variety\nof industries, including the nuclear and chemical industries, for its ability\nto dissolve and purify various inorganic acids and metals. It is often used in\nhydrometallurgical processes to separate and purify these substances. Machine\nlearning models offer a promising alternative to traditional methods for\npredicting the viscosity of TBP mixtures. By training machine learning models\non a dataset of viscosity measurements, it is possible to accurately predict\nthe viscosity of TBP mixtures at different compositions, densities, and\ntemperatures, which can save time and resources and reduce the risk of exposure\nto toxic solvents. This paper aimed at proposing Machine Learning (ML)\ntechniques to automatically predict the viscosity of TBP mixtures using\nexperimental data. For comparison peruses, we trained five different ML\nalgorithms including Support Vector Regressor (SVR), Random Forest (RF),\nLogistic Regression (LR), Gradient Boosted Decision Trees (XGBoost), and Neural\nNetwork (NN). We collected a total of 511 measurements for TBP mixtures with\ntemperature-based density, at different compositions, containing hexane,\ndodecane, cyclohexane, n-heptane, toluene, and ethylbenzene measured at\ntemperatures of T= (288.15, 293.15, 298.15, 303.15, 308.15, 313.15, 318.15,\n323.15, and 328.15) K. The results revealed that the NN model with 25 and 50\nneurons in the hidden layers could achieve the best viscosity predictions for a\nsystem of TBP mixtures. The NN model outperformed other regular ML models in\nterms of Mean Square Error (MSE) of 0.157 % and adjusted R2 of 99.72 % on the\ntest data set. This paper demonstrated that the NN model can be an appropriate\noption to accurately predict the viscosity of TBP + Ethylbenzene with a margin\nof deviation as low as 0.049 %.",
            "author": [
                "Faranak Hatami",
                "Mousa Moradi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02522v1",
                "http://arxiv.org/pdf/2311.02522v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02517v1",
            "title": "Implementation of a data-driven equation-discovery mesoscale\n  parameterization into an ocean model",
            "updated": "2023-11-04T22:01:04Z",
            "published": "2023-11-04T22:01:04Z",
            "summary": "Mesoscale eddies are poorly represented in climate ocean models, and\ntherefore their effects on the large scale circulation must be parameterized.\nClassical parameterizations, which represent the bulk effect of the unresolved\neddies, can be improved with new subgrid models learned directly from data.\nZanna and Bolton (2020) (ZB20) applied an equation-discovery algorithm to\nreveal an interpretable expression parameterizing the subgrid mesoscale fluxes\nthrough the components of the velocity-gradient tensor. In this work, we\nimplement the ZB20 parameterization into the primitive-equation GFDL MOM6 ocean\nmodel and test it in two idealized configurations with significantly different\nstratification and topography. In addition, we propose an approach based on\nspatial filtering to improve the representation of large-scale energy\nbackscatter and numerical properties of the parameterization. The ZB20\nparameterization led to improved climatological mean flow and energy\ndistributions, compared to the current state-of-the-art energy backscatter\nparameterizations. The ZB20 is scale-aware and can be used with a single value\nof the non-dimensional scaling coefficient for a range of resolutions. The\nsuccessful application of the ZB20 to parameterize mesoscale eddies in two\nidealized configurations offers a promising opportunity to reduce long-standing\nbiases in global ocean simulations in future studies.",
            "author": [
                "Pavel Perezhogin",
                "Cheng Zhang",
                "Alistair Adcroft",
                "Carlos Fernandez-Granda",
                "Laure Zanna"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02517v1",
                "http://arxiv.org/pdf/2311.02517v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02516v1",
            "title": "Forward $\u03c7^2$ Divergence Based Variational Importance Sampling",
            "updated": "2023-11-04T21:46:28Z",
            "published": "2023-11-04T21:46:28Z",
            "summary": "Maximizing the log-likelihood is a crucial aspect of learning latent variable\nmodels, and variational inference (VI) stands as the commonly adopted method.\nHowever, VI can encounter challenges in achieving a high log-likelihood when\ndealing with complicated posterior distributions. In response to this\nlimitation, we introduce a novel variational importance sampling (VIS) approach\nthat directly estimates and maximizes the log-likelihood. VIS leverages the\noptimal proposal distribution, achieved by minimizing the forward $\\chi^2$\ndivergence, to enhance log-likelihood estimation. We apply VIS to various\npopular latent variable models, including mixture models, variational\nauto-encoders, and partially observable generalized linear models. Results\ndemonstrate that our approach consistently outperforms state-of-the-art\nbaselines, both in terms of log-likelihood and model parameter estimation.",
            "author": [
                "Chengrui Li",
                "Yule Wang",
                "Weihan Li",
                "Anqi Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02516v1",
                "http://arxiv.org/pdf/2311.02516v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.CO",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.05641v1",
            "title": "Mobile Internet Quality Estimation using Self-Tuning Kernel Regression",
            "updated": "2023-11-04T21:09:46Z",
            "published": "2023-11-04T21:09:46Z",
            "summary": "Modeling and estimation for spatial data are ubiquitous in real life,\nfrequently appearing in weather forecasting, pollution detection, and\nagriculture. Spatial data analysis often involves processing datasets of\nenormous scale. In this work, we focus on large-scale internet-quality open\ndatasets from Ookla. We look into estimating mobile (cellular) internet quality\nat the scale of a state in the United States. In particular, we aim to conduct\nestimation based on highly {\\it imbalanced} data: Most of the samples are\nconcentrated in limited areas, while very few are available in the rest, posing\nsignificant challenges to modeling efforts. We propose a new adaptive kernel\nregression approach that employs self-tuning kernels to alleviate the adverse\neffects of data imbalance in this problem. Through comparative experimentation\non two distinct mobile network measurement datasets, we demonstrate that the\nproposed self-tuning kernel regression method produces more accurate\npredictions, with the potential to be applied in other applications.",
            "author": [
                "Hanyang Jiang",
                "Henry Shaowu Yuchi",
                "Elizabeth Belding",
                "Ellen Zegura",
                "Yao Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.05641v1",
                "http://arxiv.org/pdf/2311.05641v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02502v1",
            "title": "MAAIP: Multi-Agent Adversarial Interaction Priors for imitation from\n  fighting demonstrations for physics-based characters",
            "updated": "2023-11-04T20:40:39Z",
            "published": "2023-11-04T20:40:39Z",
            "summary": "Simulating realistic interaction and motions for physics-based characters is\nof great interest for interactive applications, and automatic secondary\ncharacter animation in the movie and video game industries. Recent works in\nreinforcement learning have proposed impressive results for single character\nsimulation, especially the ones that use imitation learning based techniques.\nHowever, imitating multiple characters interactions and motions requires to\nalso model their interactions. In this paper, we propose a novel Multi-Agent\nGenerative Adversarial Imitation Learning based approach that generalizes the\nidea of motion imitation for one character to deal with both the interaction\nand the motions of the multiple physics-based characters. Two unstructured\ndatasets are given as inputs: 1) a single-actor dataset containing motions of a\nsingle actor performing a set of motions linked to a specific application, and\n2) an interaction dataset containing a few examples of interactions between\nmultiple actors. Based on these datasets, our system trains control policies\nallowing each character to imitate the interactive skills associated with each\nactor, while preserving the intrinsic style. This approach has been tested on\ntwo different fighting styles, boxing and full-body martial art, to demonstrate\nthe ability of the method to imitate different styles.",
            "author": [
                "Mohamed Younes",
                "Ewa Kijak",
                "Richard Kulpa",
                "Simon Malinowski",
                "Franck Multon"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3606926",
                "http://arxiv.org/abs/2311.02502v1",
                "http://arxiv.org/pdf/2311.02502v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR",
                "cs.LG",
                "cs.RO",
                "68U99",
                "I.3.8; I.3.m"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02496v2",
            "title": "LocoMuJoCo: A Comprehensive Imitation Learning Benchmark for Locomotion",
            "updated": "2023-11-30T17:47:04Z",
            "published": "2023-11-04T19:41:50Z",
            "summary": "Imitation Learning (IL) holds great promise for enabling agile locomotion in\nembodied agents. However, many existing locomotion benchmarks primarily focus\non simplified toy tasks, often failing to capture the complexity of real-world\nscenarios and steering research toward unrealistic domains. To advance research\nin IL for locomotion, we present a novel benchmark designed to facilitate\nrigorous evaluation and comparison of IL algorithms. This benchmark encompasses\na diverse set of environments, including quadrupeds, bipeds, and\nmusculoskeletal human models, each accompanied by comprehensive datasets, such\nas real noisy motion capture data, ground truth expert data, and ground truth\nsub-optimal data, enabling evaluation across a spectrum of difficulty levels.\nTo increase the robustness of learned agents, we provide an easy interface for\ndynamics randomization and offer a wide range of partially observable tasks to\ntrain agents across different embodiments. Finally, we provide handcrafted\nmetrics for each task and ship our benchmark with state-of-the-art baseline\nalgorithms to ease evaluation and enable fast benchmarking.",
            "author": [
                "Firas Al-Hafez",
                "Guoping Zhao",
                "Jan Peters",
                "Davide Tateo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02496v2",
                "http://arxiv.org/pdf/2311.02496v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02495v2",
            "title": "Uncertainty Quantification in Multivariable Regression for Material\n  Property Prediction with Bayesian Neural Networks",
            "updated": "2023-12-05T18:00:59Z",
            "published": "2023-11-04T19:40:16Z",
            "summary": "With the increased use of data-driven approaches and machine learning-based\nmethods in material science, the importance of reliable uncertainty\nquantification (UQ) of the predicted variables for informed decision-making\ncannot be overstated. UQ in material property prediction poses unique\nchallenges, including the multi-scale and multi-physics nature of advanced\nmaterials, intricate interactions between numerous factors, limited\navailability of large curated datasets for model training, etc. Recently,\nBayesian Neural Networks (BNNs) have emerged as a promising approach for UQ,\noffering a probabilistic framework for capturing uncertainties within neural\nnetworks. In this work, we introduce an approach for UQ within physics-informed\nBNNs, which integrates knowledge from governing laws in material modeling to\nguide the models toward physically consistent predictions. To evaluate the\neffectiveness of this approach, we present case studies for predicting the\ncreep rupture life of steel alloys. Experimental validation with three datasets\nof collected measurements from creep tests demonstrates the ability of BNNs to\nproduce accurate point and uncertainty estimates that are competitive or exceed\nthe performance of the conventional method of Gaussian Process Regression.\nSimilarly, we evaluated the suitability of BNNs for UQ in an active learning\napplication and reported competitive performance. The most promising framework\nfor creep life prediction is BNNs based on Markov Chain Monte Carlo\napproximation of the posterior distribution of network parameters, as it\nprovided more reliable results in comparison to BNNs based on variational\ninference approximation or related NNs with probabilistic outputs. The codes\nare available at:\nhttps://github.com/avakanski/Creep-uncertainty-quantification.",
            "author": [
                "Longze Li",
                "Jiang Chang",
                "Aleksandar Vakanski",
                "Yachun Wang",
                "Tiankai Yao",
                "Min Xian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02495v2",
                "http://arxiv.org/pdf/2311.02495v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cond-mat.mtrl-sci",
                "I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02492v1",
            "title": "Forecasting Post-Wildfire Vegetation Recovery in California using a\n  Convolutional Long Short-Term Memory Tensor Regression Network",
            "updated": "2023-11-04T19:32:08Z",
            "published": "2023-11-04T19:32:08Z",
            "summary": "The study of post-wildfire plant regrowth is essential for developing\nsuccessful ecosystem recovery strategies. Prior research mainly examines key\necological and biogeographical factors influencing post-fire succession. This\nresearch proposes a novel approach for predicting and analyzing post-fire plant\nrecovery. We develop a Convolutional Long Short-Term Memory Tensor Regression\n(ConvLSTMTR) network that predicts future Normalized Difference Vegetation\nIndex (NDVI) based on short-term plant growth data after fire containment. The\nmodel is trained and tested on 104 major California wildfires occurring between\n2013 and 2020, each with burn areas exceeding 3000 acres. The integration of\nConvLSTM with tensor regression enables the calculation of an overall logistic\ngrowth rate k using predicted NDVI. Overall, our k-value predictions\ndemonstrate impressive performance, with 50% of predictions exhibiting an\nabsolute error of 0.12 or less, and 75% having an error of 0.24 or less.\nFinally, we employ Uniform Manifold Approximation and Projection (UMAP) and KNN\nclustering to identify recovery trends, offering insights into regions with\nvarying rates of recovery. This study pioneers the combined use of tensor\nregression and ConvLSTM, and introduces the application of UMAP for clustering\nsimilar wildfires. This advances predictive ecological modeling and could\ninform future post-fire vegetation management strategies.",
            "author": [
                "Jiahe Liu",
                "Xiaodi Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02492v1",
                "http://arxiv.org/pdf/2311.02492v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02490v1",
            "title": "Improved Convergence Rates of Anderson Acceleration for a Large Class of\n  Fixed-Point Iterations",
            "updated": "2023-11-04T19:23:21Z",
            "published": "2023-11-04T19:23:21Z",
            "summary": "This paper studies Anderson acceleration (AA) for fixed-point methods\n${x}^{(k+1)}=q({x}^{(k)})$. It provides the first proof that when the operator\n$q$ is linear and symmetric, AA improves the root-linear convergence factor\nover the fixed-point iterations. When $q$ is nonlinear, yet has a symmetric\nJacobian at the solution, a slightly modified AA algorithm is proved to have an\nanalogous root-linear convergence factor improvement over fixed-point\niterations. Simulations verify our observations. Furthermore, experiments with\ndifferent data models demonstrate AA is significantly superior to the standard\nfixed-point methods for Tyler's M-estimation.",
            "author": [
                "Casey Garner",
                "Gilad Lerman",
                "Teng Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02490v1",
                "http://arxiv.org/pdf/2311.02490v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "math.OC",
                "stat.ML",
                "65F10, 65H10, 68W40"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03392v1",
            "title": "ANAIS-112: updated results on annual modulation with three-year exposure",
            "updated": "2023-11-04T19:18:51Z",
            "published": "2023-11-04T19:18:51Z",
            "summary": "The ANAIS experiment is intended to search for dark matter annual modulation\nwith ultrapure NaI(Tl) scintillators in order to provide a model independent\nconfirmation or refutation of the long-standing DAMA/LIBRA positive annual\nmodulation signal in the low energy detection rate, using the same target and\ntechnique. Other experiments exclude the region of parameters singled out by\nDAMA/LIBRA. However, these experiments use different target materials, so the\ncomparison of their results depends on the models assumed for the dark matter\nparticle and its distribution in the galactic halo. ANAIS-112, consisting of\nnine 12.5 kg NaI(Tl) modules produced by Alpha Spectra Inc., disposed in a\n3$\\times$3 matrix configuration, is taking data smoothly with excellent\nperformance at the Canfranc Underground Laboratory, Spain, since August, 2017.\nLast published results corresponding to three-year exposure were compatible\nwith the absence of modulation and incompatible with DAMA/LIBRA for a\nsensitivity above 2.5$\\sigma$ C.L. Present status of the experiment and a\nreanalysis of the first 3 years data using new filtering protocols based on\nmachine-learning techniques are reported. This reanalysis allows to improve the\nsensitivity previously achieved for the DAMA/LIBRA signal. Updated sensitivity\nprospects are also presented: with the improved filtering, testing the\nDAMA/LIBRA signal at 5$\\sigma$ will be within reach in 2025.",
            "author": [
                "Iv\u00e1n Coarasa",
                "Julio Amar\u00e9",
                "Jaime Apilluelo",
                "Susana Cebri\u00e1n",
                "David Cintas",
                "Eduardo Garc\u00eda",
                "Mar\u00eda Mart\u00ednez",
                "Miguel \u00c1ngel Oliv\u00e1n",
                "Ysrael Ortigoza",
                "Alfonso Ortiz de Sol\u00f3rzano",
                "Tamara Pardo",
                "Jorge Puimed\u00f3n",
                "Ana Salinas",
                "Mar\u00eda Luisa Sarsa",
                "Patricia Villar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03392v1",
                "http://arxiv.org/pdf/2311.03392v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02485v1",
            "title": "Uncertainty Quantification of Deep Learning for Spatiotemporal Data:\n  Challenges and Opportunities",
            "updated": "2023-11-04T19:11:25Z",
            "published": "2023-11-04T19:11:25Z",
            "summary": "With the advancement of GPS, remote sensing, and computational simulations,\nlarge amounts of geospatial and spatiotemporal data are being collected at an\nincreasing speed. Such emerging spatiotemporal big data assets, together with\nthe recent progress of deep learning technologies, provide unique opportunities\nto transform society. However, it is widely recognized that deep learning\nsometimes makes unexpected and incorrect predictions with unwarranted\nconfidence, causing severe consequences in high-stake decision-making\napplications (e.g., disaster management, medical diagnosis, autonomous\ndriving). Uncertainty quantification (UQ) aims to estimate a deep learning\nmodel's confidence. This paper provides a brief overview of UQ of deep learning\nfor spatiotemporal data, including its unique challenges and existing methods.\nWe particularly focus on the importance of uncertainty sources. We identify\nseveral future research directions for spatiotemporal data.",
            "author": [
                "Wenchong He",
                "Zhe Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02485v1",
                "http://arxiv.org/pdf/2311.02485v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02482v1",
            "title": "Generalized zero-shot audio-to-intent classification",
            "updated": "2023-11-04T18:55:08Z",
            "published": "2023-11-04T18:55:08Z",
            "summary": "Spoken language understanding systems using audio-only data are gaining\npopularity, yet their ability to handle unseen intents remains limited. In this\nstudy, we propose a generalized zero-shot audio-to-intent classification\nframework with only a few sample text sentences per intent. To achieve this, we\nfirst train a supervised audio-to-intent classifier by making use of a\nself-supervised pre-trained model. We then leverage a neural audio synthesizer\nto create audio embeddings for sample text utterances and perform generalized\nzero-shot classification on unseen intents using cosine similarity. We also\npropose a multimodal training strategy that incorporates lexical information\ninto the audio representation to improve zero-shot performance. Our multimodal\ntraining approach improves the accuracy of zero-shot intent classification on\nunseen intents of SLURP by 2.75% and 18.2% for the SLURP and internal\ngoal-oriented dialog datasets, respectively, compared to audio-only training.",
            "author": [
                "Veera Raghavendra Elluru",
                "Devang Kulshreshtha",
                "Rohit Paturi",
                "Sravan Bodapati",
                "Srikanth Ronanki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02482v1",
                "http://arxiv.org/pdf/2311.02482v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.AI",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02480v1",
            "title": "A Strictly Bounded Deep Network for Unpaired Cyclic Translation of\n  Medical Images",
            "updated": "2023-11-04T18:43:31Z",
            "published": "2023-11-04T18:43:31Z",
            "summary": "Medical image translation is an ill-posed problem. Unlike existing paired\nunbounded unidirectional translation networks, in this paper, we consider\nunpaired medical images and provide a strictly bounded network that yields a\nstable bidirectional translation. We propose a patch-level concatenated cyclic\nconditional generative adversarial network (pCCGAN) embedded with adaptive\ndictionary learning. It consists of two cyclically connected CGANs of 47 layers\neach; where both generators (each of 32 layers) are conditioned with\nconcatenation of alternate unpaired patches from input and target modality\nimages (not ground truth) of the same organ. The key idea is to exploit\ncross-neighborhood contextual feature information that bounds the translation\nspace and boosts generalization. The generators are further equipped with\nadaptive dictionaries learned from the contextual patches to reduce possible\ndegradation. Discriminators are 15-layer deep networks that employ minimax\nfunction to validate the translated imagery. A combined loss function is\nformulated with adversarial, non-adversarial, forward-backward cyclic, and\nidentity losses that further minimize the variance of the proposed learning\nmachine. Qualitative, quantitative, and ablation analysis show superior results\non real CT and MRI.",
            "author": [
                "Swati Rai",
                "Jignesh S. Bhatt",
                "Sarat Kumar Patra"
            ],
            "link": [
                "http://dx.doi.org/10.1109/SSP53291.2023.10207960",
                "http://arxiv.org/abs/2311.02480v1",
                "http://arxiv.org/pdf/2311.02480v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02476v2",
            "title": "Forecasting Success of Computer Science Professors and Students Based on\n  Their Academic and Personal Backgrounds",
            "updated": "2023-11-22T07:12:36Z",
            "published": "2023-11-04T18:30:24Z",
            "summary": "After completing their undergraduate studies, many computer science (CS)\nstudents apply for competitive graduate programs in North America. Their\nlong-term goal is often to be hired by one of the big five tech companies or to\nbecome a faculty member. Therefore, being aware of the role of admission\ncriteria may help them choose the best path towards their goals. In this paper,\nwe analyze the influence of students' previous universities on their chances of\nbeing accepted to prestigious North American universities and returning to\nacademia as professors in the future. Our findings demonstrate that the ranking\nof their prior universities is a significant factor in achieving their goals.\nWe then illustrate that there is a bias in the undergraduate institutions of\nstudents admitted to the top 25 computer science programs. Finally, we employ\nmachine learning models to forecast the success of professors at these\nuniversities. We achieved an RMSE of 7.85 for this prediction task.",
            "author": [
                "Ghazal Kalhor",
                "Behnam Bahrak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02476v2",
                "http://arxiv.org/pdf/2311.02476v2"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02475v1",
            "title": "Constrained Equation Learner Networks for Precision-Preserving\n  Extrapolation of Robotic Skills",
            "updated": "2023-11-04T18:16:18Z",
            "published": "2023-11-04T18:16:18Z",
            "summary": "In Programming by Demonstration, the robot learns novel skills from human\ndemonstrations. After learning, the robot should be able not only to reproduce\nthe skill, but also to generalize it to shifted domains without collecting new\ntraining data. Adaptation to similar domains has been investigated in the\nliterature; however, an open problem is how to adapt learned skills to\ndifferent conditions that are outside of the data distribution, and, more\nimportant, how to preserve the precision of the desired adaptations. This paper\npresents a novel supervised learning framework called Constrained Equation\nLearner Networks that addresses the trajectory adaptation problem in\nProgramming by Demonstrations from a constrained regression perspective. While\nconventional approaches for constrained regression use one kind of basis\nfunction, e.g., Gaussian, we exploit Equation Learner Networks to learn a set\nof analytical expressions and use them as basis functions. These basis\nfunctions are learned from demonstration with the objective to minimize\ndeviations from the training data while imposing constraints that represent the\ndesired adaptations, like new initial or final points or maintaining the\ntrajectory within given bounds. Our approach addresses three main difficulties\nin adapting robotic trajectories: 1) minimizing the distortion of the\ntrajectory for new adaptations; 2) preserving the precision of the adaptations;\nand 3) dealing with the lack of intuition about the structure of basis\nfunctions. We validate our approach both in simulation and in real experiments\nin a set of robotic tasks that require adaptation due to changes in the\nenvironment, and we compare obtained results with two existing approaches.\nPerformed experiments show that Constrained Equation Learner Networks\noutperform state of the art approaches by increasing generalization and\nadaptability of robotic skills.",
            "author": [
                "Hector Perez-Villeda",
                "Justus Piater",
                "Matteo Saveriano"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02475v1",
                "http://arxiv.org/pdf/2311.02475v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02471v1",
            "title": "Efficient Large-Scale Simulation of Fish Schooling Behavior Using\n  Voronoi Tessellations and Fuzzy Clustering",
            "updated": "2023-11-04T18:11:09Z",
            "published": "2023-11-04T18:11:09Z",
            "summary": "This paper introduces an efficient approach to reduce the computational cost\nof simulating collective behaviors, such as fish schooling, using\nIndividual-Based Models (IBMs). The proposed technique employs adaptive and\ndynamic load-balancing domain partitioning, which utilizes unsupervised\nmachine-learning models to cluster a large number of simulated individuals into\nsub-schools based on their spatial-temporal locations. It also utilizes Voronoi\ntessellations to construct non-overlapping simulation subdomains. This approach\nminimizes agent-to-agent communication and balances the load both spatially and\ntemporally, ultimately resulting in reduced computational complexity.\n  Experimental simulations demonstrate that this partitioning approach\noutperforms the standard regular grid-based domain decomposition, achieving a\nreduction in computational cost while maintaining spatial and temporal load\nbalance. The approach presented in this paper has the potential to be applied\nto other collective behavior simulations requiring large-scale simulations with\na substantial number of individuals.",
            "author": [
                "Salah Alrabeei",
                "Talal Rahman",
                "Sam Subbey"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02471v1",
                "http://arxiv.org/pdf/2311.02471v1"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE",
                "68T05, 92D50, 65M50, 90B10",
                "I.3.7; I.6.5; I.6.8; I.3.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02469v1",
            "title": "The Three Hundred Project: Mapping The Matter Distribution in Galaxy\n  Clusters Via Deep Learning from Multiview Mock Observations",
            "updated": "2023-11-04T18:07:38Z",
            "published": "2023-11-04T18:07:38Z",
            "summary": "A galaxy cluster as the most massive gravitationally-bound object in the\nUniverse, is dominated by Dark Matter, which unfortunately can only be\ninvestigated through its interaction with the luminous baryons with some\nsimplified assumptions that introduce an un-preferred bias. In this work, we,\nfor the first time, propose a deep learning method based on the U-Net\narchitecture, to directly infer the projected total mass density map from mock\nobservations of simulated galaxy clusters at multi-wavelengths. The model is\ntrained with a large dataset of idealised mock images from simulated clusters\nof The Three Hundred Project. Through different metrics to assess the fidelity\nof the inferred density map, we show that the predicted total mass distribution\nis in very good agreement with the true simulated cluster. Therefore, it is not\nsurprising to see the integrated halo mass is almost unbiased, around 1 per\ncent for the best result from multiview, and the scatter is also very small,\nbasically within 3 per cent. This result suggests that this ML method provides\nan alternative and easier way to reconstruct the overall matter distribution in\ngalaxy clusters than the traditional lensing method.",
            "author": [
                "Daniel de Andres",
                "Weiguang Cui",
                "Gustavo Yepes",
                "Marco De Petris",
                "Antonio Ferragamo",
                "Federico De Luca",
                "Gianmarco Aversano",
                "Douglas Rennehan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02469v1",
                "http://arxiv.org/pdf/2311.02469v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.GA",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02467v1",
            "title": "Individualized Policy Evaluation and Learning under Clustered Network\n  Interference",
            "updated": "2023-11-04T17:58:24Z",
            "published": "2023-11-04T17:58:24Z",
            "summary": "While there now exists a large literature on policy evaluation and learning,\nmuch of prior work assumes that the treatment assignment of one unit does not\naffect the outcome of another unit. Unfortunately, ignoring interference may\nlead to biased policy evaluation and yield ineffective learned policies. For\nexample, treating influential individuals who have many friends can generate\npositive spillover effects, thereby improving the overall performance of an\nindividualized treatment rule (ITR). We consider the problem of evaluating and\nlearning an optimal ITR under clustered network (or partial) interference where\nclusters of units are sampled from a population and units may influence one\nanother within each cluster. Under this model, we propose an estimator that can\nbe used to evaluate the empirical performance of an ITR. We show that this\nestimator is substantially more efficient than the standard inverse probability\nweighting estimator, which does not impose any assumption about spillover\neffects. We derive the finite-sample regret bound for a learned ITR, showing\nthat the use of our efficient evaluation estimator leads to the improved\nperformance of learned policies. Finally, we conduct simulation and empirical\nstudies to illustrate the advantages of the proposed methodology.",
            "author": [
                "Yi Zhang",
                "Kosuke Imai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02467v1",
                "http://arxiv.org/pdf/2311.02467v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG",
                "econ.EM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02466v1",
            "title": "Multi-State Brain Network Discovery",
            "updated": "2023-11-04T17:54:15Z",
            "published": "2023-11-04T17:54:15Z",
            "summary": "Brain network discovery aims to find nodes and edges from the spatio-temporal\nsignals obtained by neuroimaging data, such as fMRI scans of human brains.\nExisting methods tend to derive representative or average brain networks,\nassuming observed signals are generated by only a single brain activity state.\nHowever, the human brain usually involves multiple activity states, which\njointly determine the brain activities. The brain regions and their\nconnectivity usually exhibit intricate patterns that are difficult to capture\nwith only a single-state network. Recent studies find that brain parcellation\nand connectivity change according to the brain activity state. We refer to such\nbrain networks as multi-state, and this mixture can help us understand human\nbehavior. Thus, compared to a single-state network, a multi-state network can\nprevent us from losing crucial information of cognitive brain network. To\nachieve this, we propose a new model called MNGL (Multi-state Network Graphical\nLasso), which successfully models multi-state brain networks by combining CGL\n(coherent graphical lasso) with GMM (Gaussian Mixture Model). Using both\nsynthetic and real world ADHD 200 fMRI datasets, we demonstrate that MNGL\noutperforms recent state-of-the-art alternatives by discovering more\nexplanatory and realistic results.",
            "author": [
                "Hang Yin",
                "Yao Su",
                "Xinyue Liu",
                "Thomas Hartvigsen",
                "Yanhua Li",
                "Xiangnan Kong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02466v1",
                "http://arxiv.org/pdf/2311.02466v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02464v1",
            "title": "On Learning the Distribution of a Random Spatial Field in a\n  Location-Unaware Mobile Sensing Setup",
            "updated": "2023-11-04T17:52:33Z",
            "published": "2023-11-04T17:52:33Z",
            "summary": "In applications like environment monitoring and pollution control, physical\nquantities are modeled by spatio-temporal fields. It is of interest to learn\nthe statistical distribution of such fields as a function of space, time or\nboth. In this work, our aim is to learn the statistical distribution of a\nspatio-temporal field along a fixed one dimensional path, as a function of\nspatial location, in the absence of location information. Spatial field\nanalysis, commonly done using static sensor networks is a well studied problem\nin literature. Recently, due to flexibility in setting the spatial sampling\ndensity and low hardware cost, owing to larger spatial coverage, mobile sensors\nare used for this purpose. The main challenge in using mobile sensors is their\nlocation uncertainty. Obtaining location information of samples requires\nadditional hardware and cost. So, we consider the case when the spatio-temporal\nfield along the fixed length path is sampled using a simple mobile sensing\ndevice that records field values while traversing the path without any location\ninformation. We ask whether it is possible to learn the statistical\ndistribution of the field, as a function of spatial location, using samples\nfrom the location-unaware mobile sensor under some simple assumptions on the\nfield. We answer this question in affirmative and provide a series of\nanalytical and experimental results to support our claim.",
            "author": [
                "Meera Pai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02464v1",
                "http://arxiv.org/pdf/2311.02464v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "eess.SP",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02455v1",
            "title": "Attention-based Multi-instance Mixed Models",
            "updated": "2023-11-04T16:42:42Z",
            "published": "2023-11-04T16:42:42Z",
            "summary": "Predicting patient features from single-cell data can unveil cellular states\nimplicated in health and disease. Linear models and average cell type\nexpressions are typically favored for this task for their efficiency and\nrobustness, but they overlook the rich cell heterogeneity inherent in\nsingle-cell data. To address this gap, we introduce GMIL, a framework\nintegrating Generalized Linear Mixed Models (GLMM) and Multiple Instance\nLearning (MIL), upholding the advantages of linear models while modeling\ncell-state heterogeneity. By leveraging predefined cell embeddings, GMIL\nenhances computational efficiency and aligns with recent advancements in\nsingle-cell representation learning. Our empirical results reveal that GMIL\noutperforms existing MIL models in single-cell datasets, uncovering new\nassociations and elucidating biological mechanisms across different domains.",
            "author": [
                "Jan P. Engelmann",
                "Alessandro Palma",
                "Jakub M. Tomczak",
                "Fabian J Theis",
                "Francesco Paolo Casale"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02455v1",
                "http://arxiv.org/pdf/2311.02455v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.GN",
                "q-bio.QM",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02446v1",
            "title": "Learning Robust Sequential Recommenders through Confident Soft Labels",
            "updated": "2023-11-04T16:14:23Z",
            "published": "2023-11-04T16:14:23Z",
            "summary": "Sequential recommenders that are trained on implicit feedback are usually\nlearned as a multi-class classification task through softmax-based loss\nfunctions on one-hot class labels. However, one-hot training labels are sparse\nand may lead to biased training and sub-optimal performance. Dense, soft labels\nhave been shown to help improve recommendation performance. But how to generate\nhigh-quality and confident soft labels from noisy sequential interactions\nbetween users and items is still an open question.\n  We propose a new learning framework for sequential recommenders, CSRec, which\nintroduces confident soft labels to provide robust guidance when learning from\nuser-item interactions. CSRec contains a teacher module that generates\nhigh-quality and confident soft labels and a student module that acts as the\ntarget recommender and is trained on the combination of dense, soft labels and\nsparse, one-hot labels.\n  We propose and compare three approaches to constructing the teacher module:\n(i) model-level, (ii) data-level, and (iii) training-level. To evaluate the\neffectiveness and generalization ability of CSRec, we conduct experiments using\nvarious state-of-the-art sequential recommendation models as the target student\nmodule on four benchmark datasets. Our experimental results demonstrate that\nCSRec is effective in training better performing sequential recommenders.",
            "author": [
                "Shiguang Wu",
                "Xin Xin",
                "Pengjie Ren",
                "Zhumin Chen",
                "Jun Ma",
                "Maarten de Rijke",
                "Zhaochun Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02446v1",
                "http://arxiv.org/pdf/2311.02446v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02442v1",
            "title": "Quantum transport on networks for supervised classification",
            "updated": "2023-11-04T15:57:43Z",
            "published": "2023-11-04T15:57:43Z",
            "summary": "Classification, the computational process of categorizing an input into\npre-existing classes, is now a cornerstone in modern computation in the era of\nmachine learning. Here we propose a new type of quantum classifier, based on\nquantum transport of particles in a trained quantum network. The classifier is\nbased on sending a quantum particle into a network and measuring the particle's\nexit point, which serves as a \"class\" and can be determined by changing the\nnetwork parameters. Using this scheme, we demonstrate three examples of\nclassification; in the first, wave functions are classified according to their\noverlap with predetermined (random) groups. In the second, we classify\nwave-functions according to their level of localization. Both examples use\nsmall training sets and achieve over 90\\% precision and recall. The third\nclassification scheme is a \"real-world problem\", concerning classification of\ncatalytic aromatic-aldehyde substrates according to their reactivity. Using\nexperimental data, the quantum classifier reaches an average 86\\%\nclassification accuracy. We show that the quantum classifier outperforms its\nclassical counterpart for these examples, thus demonstrating quantum advantage,\nespecially in the regime of \"small data\". These results pave the way for a\nnovel classification scheme, which can be implemented as an algorithm, and\npotentially realized experimentally on quantum hardware such as photonic\nnetworks.",
            "author": [
                "Shmuel Lorber",
                "Oded Zimron",
                "Inbal Lorena Zak",
                "Anat Milo",
                "Yonatan Dubi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02442v1",
                "http://arxiv.org/pdf/2311.02442v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02433v1",
            "title": "Can ChatGPT support software verification?",
            "updated": "2023-11-04T15:25:18Z",
            "published": "2023-11-04T15:25:18Z",
            "summary": "Large language models have become increasingly effective in software\nengineering tasks such as code generation, debugging and repair. Language\nmodels like ChatGPT can not only generate code, but also explain its inner\nworkings and in particular its correctness. This raises the question whether we\ncan utilize ChatGPT to support formal software verification.\n  In this paper, we take some first steps towards answering this question. More\nspecifically, we investigate whether ChatGPT can generate loop invariants. Loop\ninvariant generation is a core task in software verification, and the\ngeneration of valid and useful invariants would likely help formal verifiers.\nTo provide some first evidence on this hypothesis, we ask ChatGPT to annotate\n106 C programs with loop invariants. We check validity and usefulness of the\ngenerated invariants by passing them to two verifiers, Frama-C and CPAchecker.\nOur evaluation shows that ChatGPT is able to produce valid and useful\ninvariants allowing Frama-C to verify tasks that it could not solve before.\nBased on our initial insights, we propose ways of combining ChatGPT (or large\nlanguage models in general) and software verifiers, and discuss current\nlimitations and open issues.",
            "author": [
                "Christian Jan\u00dfen",
                "Cedric Richter",
                "Heike Wehrheim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02433v1",
                "http://arxiv.org/pdf/2311.02433v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI",
                "cs.FL",
                "cs.LG",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02428v1",
            "title": "Task Arithmetic with LoRA for Continual Learning",
            "updated": "2023-11-04T15:12:24Z",
            "published": "2023-11-04T15:12:24Z",
            "summary": "Continual learning refers to the problem where the training data is available\nin sequential chunks, termed \"tasks\". The majority of progress in continual\nlearning has been stunted by the problem of catastrophic forgetting, which is\ncaused by sequential training of the model on streams of data. Moreover, it\nbecomes computationally expensive to sequentially train large models multiple\ntimes. To mitigate both of these problems at once, we propose a novel method to\ncontinually train transformer-based vision models using low-rank adaptation and\ntask arithmetic. Our method completely bypasses the problem of catastrophic\nforgetting, as well as reducing the computational requirement for training\nmodels on each task. When aided with a small memory of 10 samples per class,\nour method achieves performance close to full-set finetuning. We present\nrigorous ablations to support the prowess of our method.",
            "author": [
                "Rajas Chitale",
                "Ankit Vaidya",
                "Aditya Kane",
                "Archana Ghotkar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02428v1",
                "http://arxiv.org/pdf/2311.02428v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02426v1",
            "title": "Online Long-run Constrained Optimization",
            "updated": "2023-11-04T15:08:36Z",
            "published": "2023-11-04T15:08:36Z",
            "summary": "In this paper, a novel Follow-the-Perturbed-Leader type algorithm is proposed\nand analyzed for solving general long-term constrained optimization problems in\nonline manner, where the objective and constraints are not necessarily convex.\nIn each period, random linear perturbation and strongly concave perturbation\nare incorporated in primal and dual directions, respectively, to the offline\noracle, and a global minimax point is searched as solution. Based on two\nparticular definitions of expected static cumulative regret, we derive the\nfirst sublinear $O(T^{8/9})$ regret complexity for this class of problems. The\nproposed algorithm is applied to tackle a long-term (risk) constrained river\npollutant source identification problem, demonstrating the validity of the\ntheoretical results and exhibiting superior performance compared to existing\nmethod.",
            "author": [
                "Shijie Pan",
                "Wenjie Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02426v1",
                "http://arxiv.org/pdf/2311.02426v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02423v1",
            "title": "Payoff-based learning with matrix multiplicative weights in quantum\n  games",
            "updated": "2023-11-04T14:56:17Z",
            "published": "2023-11-04T14:56:17Z",
            "summary": "In this paper, we study the problem of learning in quantum games - and other\nclasses of semidefinite games - with scalar, payoff-based feedback. For\nconcreteness, we focus on the widely used matrix multiplicative weights (MMW)\nalgorithm and, instead of requiring players to have full knowledge of the game\n(and/or each other's chosen states), we introduce a suite of\nminimal-information matrix multiplicative weights (3MW) methods tailored to\ndifferent information frameworks. The main difficulty to attaining convergence\nin this setting is that, in contrast to classical finite games, quantum games\nhave an infinite continuum of pure states (the quantum equivalent of pure\nstrategies), so standard importance-weighting techniques for estimating payoff\nvectors cannot be employed. Instead, we borrow ideas from bandit convex\noptimization and we design a zeroth-order gradient sampler adapted to the\nsemidefinite geometry of the problem at hand. As a first result, we show that\nthe 3MW method with deterministic payoff feedback retains the\n$\\mathcal{O}(1/\\sqrt{T})$ convergence rate of the vanilla, full information MMW\nalgorithm in quantum min-max games, even though the players only observe a\nsingle scalar. Subsequently, we relax the algorithm's information requirements\neven further and we provide a 3MW method that only requires players to observe\na random realization of their payoff observable, and converges to equilibrium\nat an $\\mathcal{O}(T^{-1/4})$ rate. Finally, going beyond zero-sum games, we\nshow that a regularized variant of the proposed 3MW method guarantees local\nconvergence with high probability to all equilibria that satisfy a certain\nfirst-order stability condition.",
            "author": [
                "Kyriakos Lotidis",
                "Panayotis Mertikopoulos",
                "Nicholas Bambos",
                "Jose Blanchet"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02423v1",
                "http://arxiv.org/pdf/2311.02423v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.LG",
                "math.OC",
                "quant-ph",
                "Primary 91A10, 91A26, 37N40, secondary 68Q32, 81Q93"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16140v1",
            "title": "Adapting Segment Anything Model (SAM) through Prompt-based Learning for\n  Enhanced Protein Identification in Cryo-EM Micrographs",
            "updated": "2023-11-04T14:20:08Z",
            "published": "2023-11-04T14:20:08Z",
            "summary": "Cryo-electron microscopy (cryo-EM) remains pivotal in structural biology, yet\nthe task of protein particle picking, integral for 3D protein structure\nconstruction, is laden with manual inefficiencies. While recent AI tools such\nas Topaz and crYOLO are advancing the field, they do not fully address the\nchallenges of cryo-EM images, including low contrast, complex shapes, and\nheterogeneous conformations. This study explored prompt-based learning to adapt\nthe state-of-the-art image segmentation foundation model Segment Anything Model\n(SAM) for cryo-EM. This focus was driven by the desire to optimize model\nperformance with a small number of labeled data without altering pre-trained\nparameters, aiming for a balance between adaptability and foundational\nknowledge retention. Through trials with three prompt-based learning\nstrategies, namely head prompt, prefix prompt, and encoder prompt, we observed\nenhanced performance and reduced computational requirements compared to the\nfine-tuning approach. This work not only highlights the potential of prompting\nSAM in protein identification from cryo-EM micrographs but also suggests its\nbroader promise in biomedical image segmentation and object detection.",
            "author": [
                "Fei He",
                "Zhiyuan Yang",
                "Mingyue Gao",
                "Biplab Poudel",
                "Newgin Sam Ebin Sam Dhas",
                "Rajan Gyawali",
                "Ashwin Dhakal",
                "Jianlin Cheng",
                "Dong Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16140v1",
                "http://arxiv.org/pdf/2311.16140v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02407v1",
            "title": "The equivalence of dynamic and strategic stability under regularized\n  learning in games",
            "updated": "2023-11-04T14:07:33Z",
            "published": "2023-11-04T14:07:33Z",
            "summary": "In this paper, we examine the long-run behavior of regularized, no-regret\nlearning in finite games. A well-known result in the field states that the\nempirical frequencies of no-regret play converge to the game's set of coarse\ncorrelated equilibria; however, our understanding of how the players' actual\nstrategies evolve over time is much more limited - and, in many cases,\nnon-existent. This issue is exacerbated further by a series of recent results\nshowing that only strict Nash equilibria are stable and attracting under\nregularized learning, thus making the relation between learning and pointwise\nsolution concepts particularly elusive. In lieu of this, we take a more general\napproach and instead seek to characterize the \\emph{setwise} rationality\nproperties of the players' day-to-day play. To that end, we focus on one of the\nmost stringent criteria of setwise strategic stability, namely that any\nunilateral deviation from the set in question incurs a cost to the deviator - a\nproperty known as closedness under better replies (club). In so doing, we\nobtain a far-reaching equivalence between strategic and dynamic stability: a\nproduct of pure strategies is closed under better replies if and only if its\nspan is stable and attracting under regularized learning. In addition, we\nestimate the rate of convergence to such sets, and we show that methods based\non entropic regularization (like the exponential weights algorithm) converge at\na geometric rate, while projection-based methods converge within a finite\nnumber of iterations, even with bandit, payoff-based feedback.",
            "author": [
                "Victor Boone",
                "Panayotis Mertikopoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02407v1",
                "http://arxiv.org/pdf/2311.02407v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.LG",
                "math.OC",
                "Primary 91A10, 91A26, secondary 68Q32, 62L20"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02405v1",
            "title": "SplitMAC: Wireless Split Learning over Multiple Access Channels",
            "updated": "2023-11-04T13:59:26Z",
            "published": "2023-11-04T13:59:26Z",
            "summary": "This paper presents a novel split learning (SL) framework, referred to as\nSplitMAC, which reduces the latency of SL by leveraging simultaneous uplink\ntransmission over multiple access channels. The key strategy is to divide\ndevices into multiple groups and allow the devices within the same group to\nsimultaneously transmit their smashed data and device-side models over the\nmultiple access channels. The optimization problem of device grouping to\nminimize SL latency is formulated, and the benefit of device grouping in\nreducing the uplink latency of SL is theoretically derived. By examining a\ntwo-device grouping case, two asymptotically-optimal algorithms are devised for\ndevice grouping in low and high signal-to-noise ratio (SNR) scenarios,\nrespectively, while providing proofs of their optimality. By merging these\nalgorithms, a near-optimal device grouping algorithm is proposed to cover a\nwide range of SNR. Simulation results demonstrate that our SL framework with\nthe proposed device grouping algorithm is superior to existing SL frameworks in\nreducing SL latency.",
            "author": [
                "Seonjung Kim",
                "Yongjeong Oh",
                "Yo-Seb Jeon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02405v1",
                "http://arxiv.org/pdf/2311.02405v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02402v1",
            "title": "Hybrid quantum image classification and federated learning for hepatic\n  steatosis diagnosis",
            "updated": "2023-11-04T13:28:06Z",
            "published": "2023-11-04T13:28:06Z",
            "summary": "With the maturity achieved by deep learning techniques, intelligent systems\nthat can assist physicians in the daily interpretation of clinical images can\nplay a very important role. In addition, quantum techniques applied to deep\nlearning can enhance this performance, and federated learning techniques can\nrealize privacy-friendly collaborative learning among different participants,\nsolving privacy issues due to the use of sensitive data and reducing the number\nof data to be collected for each individual participant. We present in this\nstudy a hybrid quantum neural network that can be used to quantify\nnon-alcoholic liver steatosis and could be useful in the diagnostic process to\ndetermine a liver's suitability for transplantation; at the same time, we\npropose a federated learning approach based on a classical deep learning\nsolution to solve the same problem, but using a reduced data set in each part.\nThe liver steatosis image classification accuracy of the hybrid quantum neural\nnetwork, the hybrid quantum ResNet model, consisted of 5 qubits and more than\n100 variational gates, reaches 97%, which is 1.8% higher than its classical\ncounterpart, ResNet. Crucially, that even with a reduced dataset, our hybrid\napproach consistently outperformed its classical counterpart, indicating\nsuperior generalization and less potential for overfitting in medical\napplications. In addition, a federated approach with multiple clients, up to\n32, despite the lower accuracy, but still higher than 90%, would allow using,\nfor each participant, a very small dataset, i.e., up to one-thirtieth. Our\nwork, based over real-word clinical data can be regarded as a scalable and\ncollaborative starting point, could thus fulfill the need for an effective and\nreliable computer-assisted system that facilitates the daily diagnostic work of\nthe clinical pathologist.",
            "author": [
                "Luca Lusnig",
                "Asel Sagingalieva",
                "Mikhail Surmach",
                "Tatjana Protasevich",
                "Ovidiu Michiu",
                "Joseph McLoughlin",
                "Christopher Mansell",
                "Graziano de' Petris",
                "Deborah Bonazza",
                "Fabrizio Zanconati",
                "Alexey Melnikov",
                "Fabio Cavalli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02402v1",
                "http://arxiv.org/pdf/2311.02402v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02401v1",
            "title": "BarcodeBERT: Transformers for Biodiversity Analysis",
            "updated": "2023-11-04T13:25:49Z",
            "published": "2023-11-04T13:25:49Z",
            "summary": "Understanding biodiversity is a global challenge, in which DNA barcodes -\nshort snippets of DNA that cluster by species - play a pivotal role. In\nparticular, invertebrates, a highly diverse and under-explored group, pose\nunique taxonomic complexities. We explore machine learning approaches,\ncomparing supervised CNNs, fine-tuned foundation models, and a DNA\nbarcode-specific masking strategy across datasets of varying complexity. While\nsimpler datasets and tasks favor supervised CNNs or fine-tuned transformers,\nchallenging species-level identification demands a paradigm shift towards\nself-supervised pretraining. We propose BarcodeBERT, the first self-supervised\nmethod for general biodiversity analysis, leveraging a 1.5 M invertebrate DNA\nbarcode reference library. This work highlights how dataset specifics and\ncoverage impact model selection, and underscores the role of self-supervised\npretraining in achieving high-accuracy DNA barcode-based identification at the\nspecies and genus level. Indeed, without the fine-tuning step, BarcodeBERT\npretrained on a large DNA barcode dataset outperforms DNABERT and DNABERT-2 on\nmultiple downstream classification tasks. The code repository is available at\nhttps://github.com/Kari-Genomics-Lab/BarcodeBERT",
            "author": [
                "Pablo Millan Arias",
                "Niousha Sadjadi",
                "Monireh Safari",
                "ZeMing Gong",
                "Austin T. Wang",
                "Scott C. Lowe",
                "Joakim Bruslund Haurum",
                "Iuliia Zarubiieva",
                "Dirk Steinke",
                "Lila Kari",
                "Angel X. Chang",
                "Graham W. Taylor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02401v1",
                "http://arxiv.org/pdf/2311.02401v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02400v1",
            "title": "From Plate to Production: Artificial Intelligence in Modern\n  Consumer-Driven Food Systems",
            "updated": "2023-11-04T13:13:44Z",
            "published": "2023-11-04T13:13:44Z",
            "summary": "Global food systems confront the urgent challenge of supplying sustainable,\nnutritious diets in the face of escalating demands. The advent of Artificial\nIntelligence (AI) is bringing in a personal choice revolution, wherein\nAI-driven individual decisions transform food systems from dinner tables, to\nthe farms, and back to our plates. In this context, AI algorithms refine\npersonal dietary choices, subsequently shaping agricultural outputs, and\npromoting an optimized feedback loop from consumption to cultivation.\nInitially, we delve into AI tools and techniques spanning the food supply\nchain, and subsequently assess how AI subfields$\\unicode{x2013}$encompassing\nmachine learning, computer vision, and speech recognition$\\unicode{x2013}$are\nharnessed within the AI-enabled Food System (AIFS) framework, which\nincreasingly leverages Internet of Things, multimodal sensors and real-time\ndata exchange. We spotlight the AIFS framework, emphasizing its fusion of AI\nwith technologies such as digitalization, big data analytics, biotechnology,\nand IoT extensively used in modern food systems in every component. This\nparadigm shifts the conventional \"farm to fork\" narrative to a cyclical\n\"consumer-driven farm to fork\" model for better achieving sustainable,\nnutritious diets. This paper explores AI's promise and the intrinsic challenges\nit poses within the food domain. By championing stringent AI governance,\nuniform data architectures, and cross-disciplinary partnerships, we argue that\nAI, when synergized with consumer-centric strategies, holds the potential to\nsteer food systems toward a sustainable trajectory. We furnish a comprehensive\nsurvey for the state-of-the-art in diverse facets of food systems, subsequently\npinpointing gaps and advocating for the judicious and efficacious deployment of\nemergent AI methodologies.",
            "author": [
                "Weiqing Min",
                "Pengfei Zhou",
                "Leyi Xu",
                "Tao Liu",
                "Tianhao Li",
                "Mingyu Huang",
                "Ying Jin",
                "Yifan Yi",
                "Min Wen",
                "Shuqiang Jiang",
                "Ramesh Jain"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02400v1",
                "http://arxiv.org/pdf/2311.02400v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02399v1",
            "title": "Entropy Aware Training for Fast and Accurate Distributed GNN",
            "updated": "2023-11-04T13:11:49Z",
            "published": "2023-11-04T13:11:49Z",
            "summary": "Several distributed frameworks have been developed to scale Graph Neural\nNetworks (GNNs) on billion-size graphs. On several benchmarks, we observe that\nthe graph partitions generated by these frameworks have heterogeneous data\ndistributions and class imbalance, affecting convergence, and resulting in\nlower performance than centralized implementations. We holistically address\nthese challenges and develop techniques that reduce training time and improve\naccuracy. We develop an Edge-Weighted partitioning technique to improve the\nmicro average F1 score (accuracy) by minimizing the total entropy. Furthermore,\nwe add an asynchronous personalization phase that adapts each compute-host's\nmodel to its local data distribution. We design a class-balanced sampler that\nconsiderably speeds up convergence. We implemented our algorithms on the\nDistDGL framework and observed that our training techniques scale much better\nthan the existing training approach. We achieved a (2-3x) speedup in training\ntime and 4\\% improvement on average in micro-F1 scores on 5 large graph\nbenchmarks compared to the standard baselines.",
            "author": [
                "Dhruv Deshmukh",
                "Gagan Raj Gupta",
                "Manisha Chawla",
                "Vishwesh Jatala",
                "Anirban Haldar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02399v1",
                "http://arxiv.org/pdf/2311.02399v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "I.5.1; I.5.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02398v1",
            "title": "CDR-Adapter: Learning Adapters to Dig Out More Transferring Ability for\n  Cross-Domain Recommendation Models",
            "updated": "2023-11-04T13:03:24Z",
            "published": "2023-11-04T13:03:24Z",
            "summary": "Data sparsity and cold-start problems are persistent challenges in\nrecommendation systems. Cross-domain recommendation (CDR) is a promising\nsolution that utilizes knowledge from the source domain to improve the\nrecommendation performance in the target domain. Previous CDR approaches have\nmainly followed the Embedding and Mapping (EMCDR) framework, which involves\nlearning a mapping function to facilitate knowledge transfer. However, these\napproaches necessitate re-engineering and re-training the network structure to\nincorporate transferrable knowledge, which can be computationally expensive and\nmay result in catastrophic forgetting of the original knowledge. In this paper,\nwe present a scalable and efficient paradigm to address data sparsity and\ncold-start issues in CDR, named CDR-Adapter, by decoupling the original\nrecommendation model from the mapping function, without requiring\nre-engineering the network structure. Specifically, CDR-Adapter is a novel\nplug-and-play module that employs adapter modules to align feature\nrepresentations, allowing for flexible knowledge transfer across different\ndomains and efficient fine-tuning with minimal training costs. We conducted\nextensive experiments on the benchmark dataset, which demonstrated the\neffectiveness of our approach over several state-of-the-art CDR approaches.",
            "author": [
                "Yanyu Chen",
                "Yao Yao",
                "Wai Kin Victor Chan",
                "Li Xiao",
                "Kai Zhang",
                "Liang Zhang",
                "Yun Ye"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02398v1",
                "http://arxiv.org/pdf/2311.02398v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02396v1",
            "title": "Precise Robotic Needle-Threading with Tactile Perception and\n  Reinforcement Learning",
            "updated": "2023-11-04T12:45:08Z",
            "published": "2023-11-04T12:45:08Z",
            "summary": "This work presents a novel tactile perception-based method, named T-NT, for\nperforming the needle-threading task, an application of deformable linear\nobject (DLO) manipulation. This task is divided into two main stages: Tail-end\nFinding and Tail-end Insertion. In the first stage, the agent traces the\ncontour of the thread twice using vision-based tactile sensors mounted on the\ngripper fingers. The two-run tracing is to locate the tail-end of the thread.\n  In the second stage, it employs a tactile-guided reinforcement learning (RL)\nmodel to drive the robot to insert the thread into the target needle eyelet.\nThe RL model is trained in a Unity-based simulated environment. The simulation\nenvironment supports tactile rendering which can produce realistic tactile\nimages and thread modeling. During insertion, the position of the poke point\nand the center of the eyelet are obtained through a pre-trained segmentation\nmodel, Grounded-SAM, which predicts the masks for both the needle eye and\nthread imprints. These positions are then fed into the reinforcement learning\nmodel, aiding in a smoother transition to real-world applications. Extensive\nexperiments on real robots are conducted to demonstrate the efficacy of our\nmethod. More experiments and videos can be found in the supplementary materials\nand on the website: https://sites.google.com/view/tac-needlethreading.",
            "author": [
                "Zhenjun Yu",
                "Wenqiang Xu",
                "Siqiong Yao",
                "Jieji Ren",
                "Tutian Tang",
                "Yutong Li",
                "Guoying Gu",
                "Cewu Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02396v1",
                "http://arxiv.org/pdf/2311.02396v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02394v1",
            "title": "NeuroEvoBench: Benchmarking Evolutionary Optimizers for Deep Learning\n  Applications",
            "updated": "2023-11-04T12:42:38Z",
            "published": "2023-11-04T12:42:38Z",
            "summary": "Recently, the Deep Learning community has become interested in evolutionary\noptimization (EO) as a means to address hard optimization problems, e.g.\nmeta-learning through long inner loop unrolls or optimizing non-differentiable\noperators. One core reason for this trend has been the recent innovation in\nhardware acceleration and compatible software - making distributed population\nevaluations much easier than before. Unlike for gradient descent-based methods\nthough, there is a lack of hyperparameter understanding and best practices for\nEO - arguably due to severely less 'graduate student descent' and benchmarking\nbeing performed for EO methods. Additionally, classical benchmarks from the\nevolutionary community provide few practical insights for Deep Learning\napplications. This poses challenges for newcomers to hardware-accelerated EO\nand hinders significant adoption. Hence, we establish a new benchmark of EO\nmethods (NeuroEvoBench) tailored toward Deep Learning applications and\nexhaustively evaluate traditional and meta-learned EO. We investigate core\nscientific questions including resource allocation, fitness shaping,\nnormalization, regularization & scalability of EO. The benchmark is\nopen-sourced at https://github.com/neuroevobench/neuroevobench under Apache-2.0\nlicense.",
            "author": [
                "Robert Tjarko Lange",
                "Yujin Tang",
                "Yingtao Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02394v1",
                "http://arxiv.org/pdf/2311.02394v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02393v1",
            "title": "Continual Learning of Unsupervised Monocular Depth from Videos",
            "updated": "2023-11-04T12:36:07Z",
            "published": "2023-11-04T12:36:07Z",
            "summary": "Spatial scene understanding, including monocular depth estimation, is an\nimportant problem in various applications, such as robotics and autonomous\ndriving. While improvements in unsupervised monocular depth estimation have\npotentially allowed models to be trained on diverse crowdsourced videos, this\nremains underexplored as most methods utilize the standard training protocol,\nwherein the models are trained from scratch on all data after new data is\ncollected. Instead, continual training of models on sequentially collected data\nwould significantly reduce computational and memory costs. Nevertheless, naive\ncontinual training leads to catastrophic forgetting, where the model\nperformance deteriorates on older domains as it learns on newer domains,\nhighlighting the trade-off between model stability and plasticity. While\nseveral techniques have been proposed to address this issue in image\nclassification, the high-dimensional and spatiotemporally correlated outputs of\ndepth estimation make it a distinct challenge. To the best of our knowledge, no\nframework or method currently exists focusing on the problem of continual\nlearning in depth estimation. Thus, we introduce a framework that captures the\nchallenges of continual unsupervised depth estimation (CUDE), and define the\nnecessary metrics to evaluate model performance. We propose a rehearsal-based\ndual-memory method, MonoDepthCL, which utilizes spatiotemporal consistency for\ncontinual learning in depth estimation, even when the camera intrinsics are\nunknown.",
            "author": [
                "Hemang Chawla",
                "Arnav Varma",
                "Elahe Arani",
                "Bahram Zonooz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02393v1",
                "http://arxiv.org/pdf/2311.02393v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02392v1",
            "title": "Cross-Level Distillation and Feature Denoising for Cross-Domain Few-Shot\n  Classification",
            "updated": "2023-11-04T12:28:04Z",
            "published": "2023-11-04T12:28:04Z",
            "summary": "The conventional few-shot classification aims at learning a model on a large\nlabeled base dataset and rapidly adapting to a target dataset that is from the\nsame distribution as the base dataset. However, in practice, the base and the\ntarget datasets of few-shot classification are usually from different domains,\nwhich is the problem of cross-domain few-shot classification. We tackle this\nproblem by making a small proportion of unlabeled images in the target domain\naccessible in the training stage. In this setup, even though the base data are\nsufficient and labeled, the large domain shift still makes transferring the\nknowledge from the base dataset difficult. We meticulously design a cross-level\nknowledge distillation method, which can strengthen the ability of the model to\nextract more discriminative features in the target dataset by guiding the\nnetwork's shallow layers to learn higher-level information. Furthermore, in\norder to alleviate the overfitting in the evaluation stage, we propose a\nfeature denoising operation which can reduce the feature redundancy and\nmitigate overfitting. Our approach can surpass the previous state-of-the-art\nmethod, Dynamic-Distillation, by 5.44% on 1-shot and 1.37% on 5-shot\nclassification tasks on average in the BSCD-FSL benchmark. The implementation\ncode will be available at https://github.com/jarucezh/cldfd.",
            "author": [
                "Hao Zheng",
                "Runqi Wang",
                "Jianzhuang Liu",
                "Asako Kanezaki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02392v1",
                "http://arxiv.org/pdf/2311.02392v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02390v1",
            "title": "AI-based Self-healing Solutions Applied to Cellular Networks: An\n  Overview",
            "updated": "2023-11-04T12:18:47Z",
            "published": "2023-11-04T12:18:47Z",
            "summary": "In this article, we provide an overview of machine learning (ML) methods,\nboth classical and deep variants, that are used to implement self-healing for\ncell outages in cellular networks. Self-healing is a promising approach to\nnetwork management, which aims to detect and compensate for cell outages in an\nautonomous way. This technology aims to decrease the expenses associated with\nthe installation and maintenance of existing 4G and 5G, i.e. emerging 6G\nnetworks by simplifying operational tasks through its ability to heal itself.\nWe provide an overview of the basic concepts and taxonomy for SON,\nself-healing, and ML techniques, in network management. Moreover, we review the\nstate-of-the-art in literature for cell outages, with a particular emphasis on\nML-based approaches.",
            "author": [
                "Jaleh Farmani",
                "Amirreza Khalil Zadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02390v1",
                "http://arxiv.org/pdf/2311.02390v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04231v1",
            "title": "A Practical Large-Scale Roadside Multi-View Multi-Sensor Spatial\n  Synchronization Framework for Intelligent Transportation Systems",
            "updated": "2023-11-04T11:43:31Z",
            "published": "2023-11-04T11:43:31Z",
            "summary": "Spatial synchronization in roadside scenarios is essential for integrating\ndata from multiple sensors at different locations. Current methods using\ncascading spatial transformation (CST) often lead to cumulative errors in\nlarge-scale deployments. Manual camera calibration is insufficient and requires\nextensive manual work, and existing methods are limited to controlled or\nsingle-view scenarios. To address these challenges, our research introduces a\nparallel spatial transformation (PST)-based framework for large-scale,\nmulti-view, multi-sensor scenarios. PST parallelizes sensor coordinate system\ntransformation, reducing cumulative errors. We incorporate deep learning for\nprecise roadside monocular global localization, reducing manual work.\nAdditionally, we use geolocation cues and an optimization algorithm for\nimproved synchronization accuracy. Our framework has been tested in real-world\nscenarios, outperforming CST-based methods. It significantly enhances\nlarge-scale roadside multi-perspective, multi-sensor spatial synchronization,\nreducing deployment costs.",
            "author": [
                "Yong Li",
                "Zhiguo Zhao",
                "Yunli Chen",
                "Rui Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04231v1",
                "http://arxiv.org/pdf/2311.04231v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06293v1",
            "title": "Quantum Neural Networks for Power Flow Analysis",
            "updated": "2023-11-04T11:25:31Z",
            "published": "2023-11-04T11:25:31Z",
            "summary": "This paper explores the potential application of quantum and hybrid\nquantum-classical neural networks in power flow analysis. Experiments are\nconducted using two small-size datasets based on the IEEE 4-bus and 33-bus test\nsystems. A systematic performance comparison is also conducted among quantum,\nhybrid quantum-classical, and classical neural networks. The comparison is\nbased on (i) generalization ability, (ii) robustness, (iii) training dataset\nsize needed, (iv) training error. (v) training computational time, and (vi)\ntraining process stability. The results show that the developed\nquantum-classical neural network outperforms both quantum and classical neural\nnetworks, and hence can improve deep learning-based power flow analysis in the\nnoisy-intermediate-scale quantum (NISQ) era.",
            "author": [
                "Zeynab Kaseb",
                "Matthias Moller",
                "Giorgio Tosti Balducci",
                "Peter Palensky",
                "Pedro P. Vergara"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06293v1",
                "http://arxiv.org/pdf/2311.06293v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02379v1",
            "title": "Accelerating Reinforcement Learning of Robotic Manipulations via\n  Feedback from Large Language Models",
            "updated": "2023-11-04T11:21:38Z",
            "published": "2023-11-04T11:21:38Z",
            "summary": "Reinforcement Learning (RL) plays an important role in the robotic\nmanipulation domain since it allows self-learning from trial-and-error\ninteractions with the environment. Still, sample efficiency and reward\nspecification seriously limit its potential. One possible solution involves\nlearning from expert guidance. However, obtaining a human expert is impractical\ndue to the high cost of supervising an RL agent, and developing an automatic\nsupervisor is a challenging endeavor. Large Language Models (LLMs) demonstrate\nremarkable abilities to provide human-like feedback on user inputs in natural\nlanguage. Nevertheless, they are not designed to directly control low-level\nrobotic motions, as their pretraining is based on vast internet data rather\nthan specific robotics data. In this paper, we introduce the Lafite-RL\n(Language agent feedback interactive Reinforcement Learning) framework, which\nenables RL agents to learn robotic tasks efficiently by taking advantage of\nLLMs' timely feedback. Our experiments conducted on RLBench tasks illustrate\nthat, with simple prompt design in natural language, the Lafite-RL agent\nexhibits improved learning capabilities when guided by an LLM. It outperforms\nthe baseline in terms of both learning efficiency and success rate,\nunderscoring the efficacy of the rewards provided by an LLM.",
            "author": [
                "Kun Chu",
                "Xufeng Zhao",
                "Cornelius Weber",
                "Mengdi Li",
                "Stefan Wermter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02379v1",
                "http://arxiv.org/pdf/2311.02379v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02374v1",
            "title": "Riemannian stochastic optimization methods avoid strict saddle points",
            "updated": "2023-11-04T11:12:24Z",
            "published": "2023-11-04T11:12:24Z",
            "summary": "Many modern machine learning applications - from online principal component\nanalysis to covariance matrix identification and dictionary learning - can be\nformulated as minimization problems on Riemannian manifolds, and are typically\nsolved with a Riemannian stochastic gradient method (or some variant thereof).\nHowever, in many cases of interest, the resulting minimization problem is not\ngeodesically convex, so the convergence of the chosen solver to a desirable\nsolution - i.e., a local minimizer - is by no means guaranteed. In this paper,\nwe study precisely this question, that is, whether stochastic Riemannian\noptimization algorithms are guaranteed to avoid saddle points with probability\n1. For generality, we study a family of retraction-based methods which, in\naddition to having a potentially much lower per-iteration cost relative to\nRiemannian gradient descent, include other widely used algorithms, such as\nnatural policy gradient methods and mirror descent in ordinary convex spaces.\nIn this general setting, we show that, under mild assumptions for the ambient\nmanifold and the oracle providing gradient information, the policies under\nstudy avoid strict saddle points / submanifolds with probability 1, from any\ninitial condition. This result provides an important sanity check for the use\nof gradient methods on manifolds as it shows that, almost always, the limit\nstate of a stochastic Riemannian algorithm can only be a local minimizer.",
            "author": [
                "Ya-Ping Hsieh",
                "Mohammad Reza Karimi",
                "Andreas Krause",
                "Panayotis Mertikopoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02374v1",
                "http://arxiv.org/pdf/2311.02374v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "Primary 62L20, 37N40, secondary 90C15, 90C48"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02373v1",
            "title": "From Trojan Horses to Castle Walls: Unveiling Bilateral Backdoor Effects\n  in Diffusion Models",
            "updated": "2023-11-04T11:00:31Z",
            "published": "2023-11-04T11:00:31Z",
            "summary": "While state-of-the-art diffusion models (DMs) excel in image generation,\nconcerns regarding their security persist. Earlier research highlighted DMs'\nvulnerability to backdoor attacks, but these studies placed stricter\nrequirements than conventional methods like 'BadNets' in image classification.\nThis is because the former necessitates modifications to the diffusion sampling\nand training procedures. Unlike the prior work, we investigate whether\ngenerating backdoor attacks in DMs can be as simple as BadNets, i.e., by only\ncontaminating the training dataset without tampering the original diffusion\nprocess. In this more realistic backdoor setting, we uncover bilateral backdoor\neffects that not only serve an adversarial purpose (compromising the\nfunctionality of DMs) but also offer a defensive advantage (which can be\nleveraged for backdoor defense). Specifically, we find that a BadNets-like\nbackdoor attack remains effective in DMs for producing incorrect images\n(misaligned with the intended text conditions), and thereby yielding incorrect\npredictions when DMs are used as classifiers. Meanwhile, backdoored DMs exhibit\nan increased ratio of backdoor triggers, a phenomenon we refer to as `trigger\namplification', among the generated images. We show that this latter insight\ncan be used to enhance the detection of backdoor-poisoned training data. Even\nunder a low backdoor poisoning ratio, studying the backdoor effects of DMs is\nalso valuable for designing anti-backdoor image classifiers. Last but not\nleast, we establish a meaningful linkage between backdoor attacks and the\nphenomenon of data replications by exploring DMs' inherent data memorization\ntendencies. The codes of our work are available at\nhttps://github.com/OPTML-Group/BiBadDiff.",
            "author": [
                "Zhuoshi Pan",
                "Yuguang Yao",
                "Gaowen Liu",
                "Bingquan Shen",
                "H. Vicky Zhao",
                "Ramana Rao Kompella",
                "Sijia Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02373v1",
                "http://arxiv.org/pdf/2311.02373v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02369v1",
            "title": "TACNET: Temporal Audio Source Counting Network",
            "updated": "2023-11-04T10:48:14Z",
            "published": "2023-11-04T10:48:14Z",
            "summary": "In this paper, we introduce the Temporal Audio Source Counting Network\n(TaCNet), an innovative architecture that addresses limitations in audio source\ncounting tasks. TaCNet operates directly on raw audio inputs, eliminating\ncomplex preprocessing steps and simplifying the workflow. Notably, it excels in\nreal-time speaker counting, even with truncated input windows. Our extensive\nevaluation, conducted using the LibriCount dataset, underscores TaCNet's\nexceptional performance, positioning it as a state-of-the-art solution for\naudio source counting tasks. With an average accuracy of 74.18 percentage over\n11 classes, TaCNet demonstrates its effectiveness across diverse scenarios,\nincluding applications involving Chinese and Persian languages. This\ncross-lingual adaptability highlights its versatility and potential impact.",
            "author": [
                "Amirreza Ahmadnejad",
                "Ahmad Mahmmodian Darviishani",
                "Mohmmad Mehrdad Asadi",
                "Sajjad Saffariyeh",
                "Pedram Yousef",
                "Emad Fatemizadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02369v1",
                "http://arxiv.org/pdf/2311.02369v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02365v1",
            "title": "Evolution of reciprocity with limited payoff memory",
            "updated": "2023-11-04T10:26:06Z",
            "published": "2023-11-04T10:26:06Z",
            "summary": "Direct reciprocity is a mechanism for the evolution of cooperation in\nrepeated social interactions. According to this literature, individuals\nnaturally learn to adopt conditionally cooperative strategies if they have\nmultiple encounters with their partner. Corresponding models have greatly\nfacilitated our understanding of cooperation, yet they often make strong\nassumptions on how individuals remember and process payoff information. For\nexample, when strategies are updated through social learning, it is commonly\nassumed that individuals compare their average payoffs. This would require them\nto compute (or remember) their payoffs against everyone else in the population.\nTo understand how more realistic constraints influence direct reciprocity, we\nconsider the evolution of conditional behaviors when individuals learn based on\nmore recent experiences. Even in the most extreme case that they only take into\naccount their very last interaction, we find that cooperation can still evolve.\nHowever, such individuals adopt less generous strategies, and they tend to\ncooperate less often than in the classical setup with average payoffs.\nInterestingly, once individuals remember the payoffs of two or three recent\ninteractions, cooperation rates quickly approach the classical limit. These\nfindings contribute to a literature that explores which kind of cognitive\ncapabilities are required for reciprocal cooperation. While our results suggest\nthat some rudimentary form of payoff memory is necessary, it already suffices\nto remember a few interactions.",
            "author": [
                "Nikoleta E. Glynatsi",
                "Alex McAvoy",
                "Christian Hilbe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02365v1",
                "http://arxiv.org/pdf/2311.02365v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02358v3",
            "title": "Domain Transfer in Latent Space (DTLS) Wins on Image Super-Resolution --\n  a Non-Denoising Model",
            "updated": "2023-11-20T08:15:57Z",
            "published": "2023-11-04T09:57:50Z",
            "summary": "Large scale image super-resolution is a challenging computer vision task,\nsince vast information is missing in a highly degraded image, say for example\nforscale x16 super-resolution. Diffusion models are used successfully in recent\nyears in extreme super-resolution applications, in which Gaussian noise is used\nas a means to form a latent photo-realistic space, and acts as a link between\nthe space of latent vectors and the latent photo-realistic space. There are\nquite a few sophisticated mathematical derivations on mapping the statistics of\nGaussian noises making Diffusion Models successful. In this paper we propose a\nsimple approach which gets away from using Gaussian noise but adopts some basic\nstructures of diffusion models for efficient image super-resolution.\nEssentially, we propose a DNN to perform domain transfer between neighbor\ndomains, which can learn the differences in statistical properties to\nfacilitate gradual interpolation with results of reasonable quality. Further\nquality improvement is achieved by conditioning the domain transfer with\nreference to the input LR image. Experimental results show that our method\noutperforms not only state-of-the-art large scale super resolution models, but\nalso the current diffusion models for image super-resolution. The approach can\nreadily be extended to other image-to-image tasks, such as image enlightening,\ninpainting, denoising, etc.",
            "author": [
                "Chun-Chuen Hui",
                "Wan-Chi Siu",
                "Ngai-Fong Law"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02358v3",
                "http://arxiv.org/pdf/2311.02358v3"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02357v1",
            "title": "Contrastive Deep Nonnegative Matrix Factorization for Community\n  Detection",
            "updated": "2023-11-04T09:50:37Z",
            "published": "2023-11-04T09:50:37Z",
            "summary": "Recently, nonnegative matrix factorization (NMF) has been widely adopted for\ncommunity detection, because of its better interpretability. However, the\nexisting NMF-based methods have the following three problems: 1) they directly\ntransform the original network into community membership space, so it is\ndifficult for them to capture the hierarchical information; 2) they often only\npay attention to the topology of the network and ignore its node attributes; 3)\nit is hard for them to learn the global structure information necessary for\ncommunity detection. Therefore, we propose a new community detection algorithm,\nnamed Contrastive Deep Nonnegative Matrix Factorization (CDNMF). Firstly, we\ndeepen NMF to strengthen its capacity for information extraction. Subsequently,\ninspired by contrastive learning, our algorithm creatively constructs network\ntopology and node attributes as two contrasting views. Furthermore, we utilize\na debiased negative sampling layer and learn node similarity at the community\nlevel, thereby enhancing the suitability of our model for community detection.\nWe conduct experiments on three public real graph datasets and the proposed\nmodel has achieved better results than state-of-the-art methods. Code available\nat https://github.com/6lyc/CDNMF.git.",
            "author": [
                "Yuecheng Li",
                "Jialong Chen",
                "Chuan Chen",
                "Lei Yang",
                "Zibin Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02357v1",
                "http://arxiv.org/pdf/2311.02357v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02356v1",
            "title": "MATA*: Combining Learnable Node Matching with A* Algorithm for\n  Approximate Graph Edit Distance Computation",
            "updated": "2023-11-04T09:33:08Z",
            "published": "2023-11-04T09:33:08Z",
            "summary": "Graph Edit Distance (GED) is a general and domain-agnostic metric to measure\ngraph similarity, widely used in graph search or retrieving tasks. However, the\nexact GED computation is known to be NP-complete. For instance, the widely used\nA* algorithms explore the entire search space to find the optimal solution\nwhich inevitably suffers scalability issues. Learning-based methods apply graph\nrepresentation techniques to learn the GED by formulating a regression task,\nwhich can not recover the edit path and lead to inaccurate GED approximation\n(i.e., the predicted GED is smaller than the exact). To this end, in this work,\nwe present a data-driven hybrid approach MATA* for approximate GED computation\nbased on Graph Neural Networks (GNNs) and A* algorithms, which models from the\nperspective of learning to match nodes instead of directly regressing GED.\nSpecifically, aware of the structure-dominant operations (i.e.,node and edge\ninsertion/deletion) property in GED computation, a structure-enhanced GNN is\nfirstly designed to jointly learn local and high-order structural information\nfor node embeddings for node matchings. Second, top-k candidate nodes are\nproduced via a differentiable top-k operation to enable the training for node\nmatchings, which is adhering to another property of GED, i.e., multiple optimal\nnode matchings. Third, benefiting from the candidate nodes, MATA* only performs\non the promising search directions, reaching the solution efficiently. Finally,\nextensive experiments show the superiority of MATA* as it significantly\noutperforms the combinatorial search-based, learning-based and hybrid methods\nand scales well to large-size graphs.",
            "author": [
                "Junfeng Liu",
                "Min Zhou",
                "Shuai Ma",
                "Lujia Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02356v1",
                "http://arxiv.org/pdf/2311.02356v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02349v1",
            "title": "Sample Complexity of Opinion Formation on Networks",
            "updated": "2023-11-04T08:28:33Z",
            "published": "2023-11-04T08:28:33Z",
            "summary": "Consider public health officials aiming to spread awareness about a new\nvaccine in a community interconnected by a social network. How can they\ndistribute information with minimal resources, ensuring community-wide\nunderstanding that aligns with the actual facts? This concern mirrors numerous\nreal-world situations. In this paper, we initialize the study of sample\ncomplexity in opinion formation to solve this problem. Our model is built on\nthe recognized opinion formation game, where we regard each agent's opinion as\na data-derived model parameter, not just a real number as in prior studies.\nSuch an extension offers a wider understanding of opinion formation and ties\nclosely with federated learning. Through this formulation, we characterize the\nsample complexity bounds for any network and also show asymptotically tight\nbounds for specific network structures. Intriguingly, we discover optimal\nstrategies often allocate samples inversely to the degree, hinting at vital\npolicy implications. Our findings are empirically validated on both synthesized\nand real-world networks.",
            "author": [
                "Haolin Liu",
                "Rajmohan Rajaraman",
                "Ravi Sundaram",
                "Anil Vullikanti",
                "Omer Wasim",
                "Haifeng Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02349v1",
                "http://arxiv.org/pdf/2311.02349v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02345v1",
            "title": "Perturbation-based Active Learning for Question Answering",
            "updated": "2023-11-04T08:07:23Z",
            "published": "2023-11-04T08:07:23Z",
            "summary": "Building a question answering (QA) model with less annotation costs can be\nachieved by utilizing active learning (AL) training strategy. It selects the\nmost informative unlabeled training data to update the model effectively.\nAcquisition functions for AL are used to determine how informative each\ntraining example is, such as uncertainty or diversity based sampling. In this\nwork, we propose a perturbation-based active learning acquisition strategy and\ndemonstrate it is more effective than existing commonly used strategies.",
            "author": [
                "Fan Luo",
                "Mihai Surdeanu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02345v1",
                "http://arxiv.org/pdf/2311.02345v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02342v1",
            "title": "Proposal-Level Unsupervised Domain Adaptation for Open World Unbiased\n  Detector",
            "updated": "2023-11-04T07:46:45Z",
            "published": "2023-11-04T07:46:45Z",
            "summary": "Open World Object Detection (OWOD) combines open-set object detection with\nincremental learning capabilities to handle the challenge of the open and\ndynamic visual world. Existing works assume that a foreground predictor trained\non the seen categories can be directly transferred to identify the unseen\ncategories' locations by selecting the top-k most confident foreground\npredictions. However, the assumption is hardly valid in practice. This is\nbecause the predictor is inevitably biased to the known categories, and fails\nunder the shift in the appearance of the unseen categories. In this work, we\naim to build an unbiased foreground predictor by re-formulating the task under\nUnsupervised Domain Adaptation, where the current biased predictor helps form\nthe domains: the seen object locations and confident background locations as\nthe source domain, and the rest ambiguous ones as the target domain. Then, we\nadopt the simple and effective self-training method to learn a predictor based\non the domain-invariant foreground features, hence achieving unbiased\nprediction robust to the shift in appearance between the seen and unseen\ncategories. Our approach's pipeline can adapt to various detection frameworks\nand UDA methods, empirically validated by OWOD evaluation, where we achieve\nstate-of-the-art performance.",
            "author": [
                "Xuanyi Liu",
                "Zhongqi Yue",
                "Xian-Sheng Hua"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02342v1",
                "http://arxiv.org/pdf/2311.02342v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02341v1",
            "title": "Enhancing English Writing Proficiency in China's Polytechnic Students An\n  In-Depth Literature Review on the Application of the Input Hypothesis",
            "updated": "2023-11-04T07:41:12Z",
            "published": "2023-11-04T07:41:12Z",
            "summary": "Having good English writing skills is extremely important for students in\npolytechnic institutions. However, a lot of students in technical schools have\ndifficulties in reaching high levels of skill. The Input Hypothesis, created by\nStephen Krashen, suggests that people learn languages well when they receive\ninformation that's a little harder than what they already know but still\nunderstandable. This research paper wants to study how the Input Hypothesis can\nhelp polytechnic students improve their English writing skills. The study will\ninclude real-life observations and experiments from the previous research. We\nwill look at data from polytechnic students who are receiving special writing\ninstruction to see if the Input Hypothesis actually helps improve their writing\nskills. The paper can better inform polytechnic students, faculty members, and\nsupport staff and even members of the larger community about the attributions,\nthe processes, and the possible outcomes of second language development for\npolytechnic students.\n  Keywords: English writing skills, Polytechnic students, Input hypothesis,\nComprehensible input",
            "author": [
                "Wei Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02341v1",
                "http://arxiv.org/pdf/2311.02341v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02340v1",
            "title": "MC-Stereo: Multi-peak Lookup and Cascade Search Range for Stereo\n  Matching",
            "updated": "2023-11-04T07:26:27Z",
            "published": "2023-11-04T07:26:27Z",
            "summary": "Stereo matching is a fundamental task in scene comprehension. In recent\nyears, the method based on iterative optimization has shown promise in stereo\nmatching. However, the current iteration framework employs a single-peak\nlookup, which struggles to handle the multi-peak problem effectively.\nAdditionally, the fixed search range used during the iteration process limits\nthe final convergence effects. To address these issues, we present a novel\niterative optimization architecture called MC-Stereo. This architecture\nmitigates the multi-peak distribution problem in matching through the\nmulti-peak lookup strategy, and integrates the coarse-to-fine concept into the\niterative framework via the cascade search range. Furthermore, given that\nfeature representation learning is crucial for successful learnbased stereo\nmatching, we introduce a pre-trained network to serve as the feature extractor,\nenhancing the front end of the stereo matching pipeline. Based on these\nimprovements, MC-Stereo ranks first among all publicly available methods on the\nKITTI-2012 and KITTI-2015 benchmarks, and also achieves state-of-the-art\nperformance on ETH3D. The code will be open sourced after the publication of\nthis paper.",
            "author": [
                "Miaojie Feng",
                "Junda Cheng",
                "Hao Jia",
                "Longliang Liu",
                "Gangwei Xu",
                "Xin Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02340v1",
                "http://arxiv.org/pdf/2311.02340v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02338v1",
            "title": "Potato Leaf Disease Classification using Deep Learning: A Convolutional\n  Neural Network Approach",
            "updated": "2023-11-04T07:16:37Z",
            "published": "2023-11-04T07:16:37Z",
            "summary": "In this study, a Convolutional Neural Network (CNN) is used to classify\npotato leaf illnesses using Deep Learning. The suggested approach entails\npreprocessing the leaf image data, training a CNN model on that data, and\nassessing the model's success on a test set. The experimental findings show\nthat the CNN model, with an overall accuracy of 99.1%, is highly accurate in\nidentifying two kinds of potato leaf diseases, including Early Blight, Late\nBlight, and Healthy. The suggested method may offer a trustworthy and effective\nremedy for identifying potato diseases, which is essential for maintaining food\nsecurity and minimizing financial losses in agriculture. The model can\naccurately recognize the various disease types even when there are severe\ninfections present. This work highlights the potential of deep learning methods\nfor categorizing potato diseases, which can help with effective and automated\ndisease management in potato farming.",
            "author": [
                "Utkarsh Yashwant Tambe",
                "A. Shobanadevi",
                "A. Shanthini",
                "Hsiu-Chun Hsu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02338v1",
                "http://arxiv.org/pdf/2311.02338v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02337v1",
            "title": "STOW: Discrete-Frame Segmentation and Tracking of Unseen Objects for\n  Warehouse Picking Robots",
            "updated": "2023-11-04T06:52:38Z",
            "published": "2023-11-04T06:52:38Z",
            "summary": "Segmentation and tracking of unseen object instances in discrete frames pose\na significant challenge in dynamic industrial robotic contexts, such as\ndistribution warehouses. Here, robots must handle object rearrangement,\nincluding shifting, removal, and partial occlusion by new items, and track\nthese items after substantial temporal gaps. The task is further complicated\nwhen robots encounter objects not learned in their training sets, which\nrequires the ability to segment and track previously unseen items. Considering\nthat continuous observation is often inaccessible in such settings, our task\ninvolves working with a discrete set of frames separated by indefinite periods\nduring which substantial changes to the scene may occur. This task also\ntranslates to domestic robotic applications, such as rearrangement of objects\non a table. To address these demanding challenges, we introduce new synthetic\nand real-world datasets that replicate these industrial and household\nscenarios. We also propose a novel paradigm for joint segmentation and tracking\nin discrete frames along with a transformer module that facilitates efficient\ninter-frame communication. The experiments we conduct show that our approach\nsignificantly outperforms recent methods. For additional results and videos,\nplease visit \\href{https://sites.google.com/view/stow-corl23}{website}. Code\nand dataset will be released.",
            "author": [
                "Yi Li",
                "Muru Zhang",
                "Markus Grotz",
                "Kaichun Mo",
                "Dieter Fox"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02337v1",
                "http://arxiv.org/pdf/2311.02337v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02336v1",
            "title": "Green light GaN p-n junction luminescent particles enhance the\n  superconducting properties of B(P)SCCO Smart Meta-Superconductors (SMSCs)",
            "updated": "2023-11-04T06:46:20Z",
            "published": "2023-11-04T06:46:20Z",
            "summary": "Superconducting materials exhibit unique physical properties and hold great\nscientific value and vast industrial application prospects. However, due to\nlimitations such as critical temperature (TC) and critical current density\n(JC), the large-scale application of superconducting materials remains\nchallenging. Chemical doping has been a commonly used method to enhance the\nsuperconductivity of B(P)SCCO. However, satisfactory enhancement results have\nbeen difficult to achieve. In this study, we introduced green light GaN p-n\njunction particles as inhomogeneous phases into B(P)SCCO polycrystalline\nparticles to form a smart meta-superconductors (SMSCs) structure. Based on the\nelectroluminescence properties of the p-n junction, the Cooper pairs were\nstimulated and strengthened to enhance the superconductivity of B(P)SCCO.\nExperimental results demonstrate that the introduction of inhomogeneous phases\ncan indeed enhance the critical temperature TC, critical current density JC,\nand complete diamagnetism (Meissner effect) of B(P)SCCO superconductors.\nMoreover, When the particle size of raw material of B(P)SCCO is reduced from\n30{\\mu}m to 5{\\mu}m, the grain size of the sintered samples also decreases, and\nthe optimal doping concentration of the inhomogeneous phases increases from\n0.15 wt.% to 0.2 wt.%, further improving the enhancement of superconductivity.",
            "author": [
                "Qingyu Hai",
                "Honggang Chen",
                "Chao Sun",
                "Duo Chen",
                "Yao Qi",
                "Miao Shi",
                "Xiaopeng Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02336v1",
                "http://arxiv.org/pdf/2311.02336v1"
            ],
            "primary_category": "cond-mat.supr-con",
            "category": [
                "cond-mat.supr-con"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02335v2",
            "title": "Machine learning approach to analyze heavy quark diffusion coefficient\n  in relativistic heavy-ion collisions",
            "updated": "2023-11-21T01:06:58Z",
            "published": "2023-11-04T06:39:59Z",
            "summary": "The diffusion coefficient of heavy quarks in the deconfined medium is\nexamined in this research using a deep convolutional neural network (CNN)\ntrained with data from relativistic heavy ion collisions involving heavy flavor\nhadrons. The CNN is trained using observables such as the nuclear modification\nfactor $R_{AA}$ and the elliptic flow $v_2$ of non-prompt $J/\\psi$ from\nB-hadron decay in different centralities, where B meson evolutions are\ncalculated using the Langevin equation and the Instantaneous Coalescence Model.\nThe CNN outputs the parameters characterizing the temperature and momentum\ndependence of the heavy quark diffusion coefficient. By inputting the\nexperimental data of non-prompt $J/\\psi$ $(R_{AA}, v_2)$ from various collision\ncentralities into multiple channels of the well-trained network, we derive the\nvalues of the diffusion coefficient parameters. Additionally, We evaluate the\nuncertainty in determining the diffusion coefficient by taking into account the\nuncertainties present in the experimental data $(R_{AA}, v_2)$, which serve as\ninputs to the deep neural network.",
            "author": [
                "Rui Guo",
                "Yonghui Li",
                "Baoyi Chen"
            ],
            "link": [
                "http://dx.doi.org/10.3390/e25111563",
                "http://arxiv.org/abs/2311.02335v2",
                "http://arxiv.org/pdf/2311.02335v2"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02333v1",
            "title": "Understanding the Natural Language of DNA using Encoder-Decoder\n  Foundation Models with Byte-level Precision",
            "updated": "2023-11-04T06:00:56Z",
            "published": "2023-11-04T06:00:56Z",
            "summary": "This paper presents the Ensemble Nucleotide Byte-level Encoder-Decoder\n(ENBED) foundation model, analyzing DNA sequences at byte-level precision with\nan encoder-decoder Transformer architecture. ENBED uses a sub-quadratic\nimplementation of attention to develop an efficient model capable of\nsequence-to-sequence transformations, generalizing previous genomic models with\nencoder-only or decoder-only architectures. We use Masked Language Modeling to\npre-train the foundation model using reference genome sequences and apply it in\nthe following downstream tasks: (1) identification of enhancers, promotors and\nsplice sites, (2) identification of biological function annotations of genomic\nsequences, (3) recognition of sequences containing base call mismatches and\ninsertion/deletion errors, an advantage over tokenization schemes involving\nmultiple base pairs, which lose the ability to analyze with byte-level\nprecision, and (4) generating mutations of the Influenza virus using the\nencoder-decoder architecture and validating them against real-world\nobservations. In each of these tasks, we demonstrate significant improvement as\ncompared to the existing state-of-the-art results.",
            "author": [
                "Aditya Malusare",
                "Harish Kothandaraman",
                "Dipesh Tamboli",
                "Nadia A. Lanman",
                "Vaneet Aggarwal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02333v1",
                "http://arxiv.org/pdf/2311.02333v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.GN"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02332v3",
            "title": "Multimodal Machine Learning in Image-Based and Clinical Biomedicine:\n  Survey and Prospects",
            "updated": "2023-11-20T20:55:29Z",
            "published": "2023-11-04T05:42:51Z",
            "summary": "Machine learning (ML) applications in medical artificial intelligence (AI)\nsystems have shifted from traditional and statistical methods to increasing\napplication of deep learning models. This survey navigates the current\nlandscape of multimodal ML, focusing on its profound impact on medical image\nanalysis and clinical decision support systems. Emphasizing challenges and\ninnovations in addressing multimodal representation, fusion, translation,\nalignment, and co-learning, the paper explores the transformative potential of\nmultimodal models for clinical predictions. It also questions practical\nimplementation of such models, bringing attention to the dynamics between\ndecision support systems and healthcare providers. Despite advancements,\nchallenges such as data biases and the scarcity of \"big data\" in many\nbiomedical domains persist. We conclude with a discussion on effective\ninnovation and collaborative efforts to further the miss",
            "author": [
                "Elisa Warner",
                "Joonsang Lee",
                "William Hsu",
                "Tanveer Syeda-Mahmood",
                "Charles Kahn",
                "Olivier Gevaert",
                "Arvind Rao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02332v3",
                "http://arxiv.org/pdf/2311.02332v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02330v1",
            "title": "Jet mixing enhancement with Bayesian optimization, deep learning, and\n  persistent data topology",
            "updated": "2023-11-04T05:34:50Z",
            "published": "2023-11-04T05:34:50Z",
            "summary": "We optimize the jet mixing using large eddy simulations (LES) at a Reynolds\nnumber of 3000. Key methodological enablers consist of Bayesian optimization, a\nsurrogate model enhanced by deep learning, and persistent data topology for\nphysical interpretation. The mixing performance is characterized by an\nequivalent jet radius ($R_{\\rm eq}$) derived from the streamwise velocity in a\nplane located 8 diameters downstream. The optimization is performed in a\n22-dimensional actuation space that comprises most known excitations. This\nsearch space parameterizes distributed actuation imposed on the bulk flow and\nat the periphery of the nozzle in the streamwise and radial directions. The\nmomentum flux measures the energy input of the actuation. The optimization\nquadruples the jet radius $R_{\\rm eq}$ with a $7$-armed blooming jet after\naround $570$ evaluations. The control input requires $2\\%$ momentum flux of the\nmain flow, which is one order of magnitude lower than most ad hoc dual-mode\nexcitations. Intriguingly, a pronounced suboptimum in the search space is\nassociated with a double-helix jet, a new flow pattern. This jet pattern\nresults in a mixing improvement comparable to the blooming jet. A\nstate-of-the-art Bayesian optimization converges towards this double helix\nsolution. The learning is accelerated and converges to another better optimum\nby including surrogate model trained along the optimization. Persistent data\ntopology extracts the global and many local minima in the actuation space and\ncan be identified with flow patterns beneficial to the mixing.",
            "author": [
                "Bernd R. Noack",
                "Yiqing Li",
                "Tianyu Wang",
                "Guy Y. Cornejo Maceda",
                "Ethan Pickering",
                "Artur Tyliszczak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02330v1",
                "http://arxiv.org/pdf/2311.02330v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "nlin.CD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02328v1",
            "title": "An Operator Learning Framework for Spatiotemporal Super-resolution of\n  Scientific Simulations",
            "updated": "2023-11-04T05:33:23Z",
            "published": "2023-11-04T05:33:23Z",
            "summary": "In numerous contexts, high-resolution solutions to partial differential\nequations are required to capture faithfully essential dynamics which occur at\nsmall spatiotemporal scales, but these solutions can be very difficult and slow\nto obtain using traditional methods due to limited computational resources. A\nrecent direction to circumvent these computational limitations is to use\nmachine learning techniques for super-resolution, to reconstruct\nhigh-resolution numerical solutions from low-resolution simulations which can\nbe obtained more efficiently. The proposed approach, the Super Resolution\nOperator Network (SROpNet), frames super-resolution as an operator learning\nproblem and draws inspiration from existing architectures to learn continuous\nrepresentations of solutions to parametric differential equations from\nlow-resolution approximations, which can then be evaluated at any desired\nlocation. In addition, no restrictions are imposed on the locations of (the\nfixed number of) spatiotemporal sensors at which the low-resolution\napproximations are provided, thereby enabling the consideration of a broader\nspectrum of problems arising in practice, for which many existing\nsuper-resolution approaches are not well-suited.",
            "author": [
                "Valentin Duruisseaux",
                "Amit Chakraborty"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02328v1",
                "http://arxiv.org/pdf/2311.02328v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02326v1",
            "title": "FragXsiteDTI: Revealing Responsible Segments in Drug-Target Interaction\n  with Transformer-Driven Interpretation",
            "updated": "2023-11-04T04:57:13Z",
            "published": "2023-11-04T04:57:13Z",
            "summary": "Drug-Target Interaction (DTI) prediction is vital for drug discovery, yet\nchallenges persist in achieving model interpretability and optimizing\nperformance. We propose a novel transformer-based model, FragXsiteDTI, that\naims to address these challenges in DTI prediction. Notably, FragXsiteDTI is\nthe first DTI model to simultaneously leverage drug molecule fragments and\nprotein pockets. Our information-rich representations for both proteins and\ndrugs offer a detailed perspective on their interaction. Inspired by the\nPerceiver IO framework, our model features a learnable latent array, initially\ninteracting with protein binding site embeddings using cross-attention and\nlater refined through self-attention and used as a query to the drug fragments\nin the drug's cross-attention transformer block. This learnable query array\nserves as a mediator and enables seamless information translation, preserving\ncritical nuances in drug-protein interactions. Our computational results on\nthree benchmarking datasets demonstrate the superior predictive power of our\nmodel over several state-of-the-art models. We also show the interpretability\nof our model in terms of the critical components of both target proteins and\ndrug molecules within drug-target pairs.",
            "author": [
                "Ali Khodabandeh Yalabadi",
                "Mehdi Yazdani-Jahromi",
                "Niloofar Yousefi",
                "Aida Tayebi",
                "Sina Abdidizaji",
                "Ozlem Ozmen Garibay"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02326v1",
                "http://arxiv.org/pdf/2311.02326v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03389v1",
            "title": "Learning Disentangled Speech Representations",
            "updated": "2023-11-04T04:54:17Z",
            "published": "2023-11-04T04:54:17Z",
            "summary": "Disentangled representation learning from speech remains limited despite its\nimportance in many application domains. A key challenge is the lack of speech\ndatasets with known generative factors to evaluate methods. This paper proposes\nSynSpeech: a novel synthetic speech dataset with ground truth factors enabling\nresearch on disentangling speech representations. We plan to present a\ncomprehensive study evaluating supervised techniques using established\nsupervised disentanglement metrics. This benchmark dataset and framework\naddress the gap in the rigorous evaluation of state-of-the-art disentangled\nspeech representation learning methods. Our findings will provide insights to\nadvance this underexplored area and enable more robust speech representations.",
            "author": [
                "Yusuf Brima",
                "Ulf Krumnack",
                "Simone Pika",
                "Gunther Heidemann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03389v1",
                "http://arxiv.org/pdf/2311.03389v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.LG",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02319v1",
            "title": "On the Robustness, Connectivity and Giant Component Size of Random K-out\n  Graphs",
            "updated": "2023-11-04T04:07:49Z",
            "published": "2023-11-04T04:07:49Z",
            "summary": "Random K-out graphs are garnering interest in designing distributed systems\nincluding secure sensor networks, anonymous crypto-currency networks, and\ndifferentially-private decentralized learning. In these security-critical\napplications, it is important to model and analyze the resilience of the\nnetwork to node failures and adversarial captures. Motivated by this, we\nanalyze how the connectivity properties of random K-out graphs vary with the\nnetwork parameters $K$, the number of nodes ($n$), and the number of nodes that\nget failed or compromised ($\\gamma_n$). In particular, we study the conditions\nfor achieving \\emph{connectivity} {with high probability} and for the existence\nof a \\emph{giant component} with formal guarantees on the size of the largest\nconnected component in terms of the parameters $n,~K$, and $\\gamma_n$. Next, we\nanalyze the property of \\emph{$r$-robustness} which is a stronger property than\nconnectivity and leads to resilient consensus in the presence of malicious\nnodes. We derive conditions on $K$ and $n$ under which the random K-out graph\nachieves r-robustness with high probability. We also provide extensive\nnumerical simulations and compare our results on random K-out graphs with known\nresults on Erd\\H{o}s-R\\'enyi (ER) graphs.",
            "author": [
                "Eray Can Elumar",
                "Mansi Sood",
                "Osman Ya\u011fan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02319v1",
                "http://arxiv.org/pdf/2311.02319v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02317v1",
            "title": "Evaluating Machine Learning Classifier Approaches, and their Accuracy\n  for the Detection of Cyberattacks on 5G IoT Systems",
            "updated": "2023-11-04T04:00:35Z",
            "published": "2023-11-04T04:00:35Z",
            "summary": "As 5G continues to expand its coverage and use. Innovative ideas/technologies\ncontinue to be implemented within. New vulnerabilities appear, thus resulting\nin new methods of mitigation and detection to occur. With the architecture that\n5G can implement, DDoS (Distributed Denial of Service) is at a higher risk.\nThere are many methods and approaches to help combat this challenge, most of\nwhich are implemented in networks containing Wi-Fi (Wireless Fidelity). This\narticle aims to discuss the possible approaches that could be included in 5G\ntechnology. The method we will discuss involves Machine Learning. We have used\nthree classifiers to test on datasets (Na\\\"ive Bayes, UltraBoost, LogitBoost)\nwith multiple cross-folds, verifying which would have the highest accuracy with\nmultiple factors (such as the cross-folds, verifying whether the number of\nfolds affects accuracy), expanding upon [25] by using feature selection to\nobtain more accurate results.",
            "author": [
                "Adem Rosic"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02317v1",
                "http://arxiv.org/pdf/2311.02317v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02316v1",
            "title": "Self-Supervised Learning of Representations for Space Generates\n  Multi-Modular Grid Cells",
            "updated": "2023-11-04T03:59:37Z",
            "published": "2023-11-04T03:59:37Z",
            "summary": "To solve the spatial problems of mapping, localization and navigation, the\nmammalian lineage has developed striking spatial representations. One important\nspatial representation is the Nobel-prize winning grid cells: neurons that\nrepresent self-location, a local and aperiodic quantity, with seemingly bizarre\nnon-local and spatially periodic activity patterns of a few discrete periods.\nWhy has the mammalian lineage learnt this peculiar grid representation?\nMathematical analysis suggests that this multi-periodic representation has\nexcellent properties as an algebraic code with high capacity and intrinsic\nerror-correction, but to date, there is no satisfactory synthesis of core\nprinciples that lead to multi-modular grid cells in deep recurrent neural\nnetworks. In this work, we begin by identifying key insights from four families\nof approaches to answering the grid cell question: coding theory, dynamical\nsystems, function optimization and supervised deep learning. We then leverage\nour insights to propose a new approach that combines the strengths of all four\napproaches. Our approach is a self-supervised learning (SSL) framework -\nincluding data, data augmentations, loss functions and a network architecture -\nmotivated from a normative perspective, without access to supervised position\ninformation or engineering of particular readout representations as needed in\nprevious approaches. We show that multiple grid cell modules can emerge in\nnetworks trained on our SSL framework and that the networks and emergent\nrepresentations generalize well outside their training distribution. This work\ncontains insights for neuroscientists interested in the origins of grid cells\nas well as machine learning researchers interested in novel SSL frameworks.",
            "author": [
                "Rylan Schaeffer",
                "Mikail Khona",
                "Tzuhsuan Ma",
                "Crist\u00f3bal Eyzaguirre",
                "Sanmi Koyejo",
                "Ila Rani Fiete"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02316v1",
                "http://arxiv.org/pdf/2311.02316v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02315v1",
            "title": "Counting Manatee Aggregations using Deep Neural Networks and Anisotropic\n  Gaussian Kernel",
            "updated": "2023-11-04T03:58:24Z",
            "published": "2023-11-04T03:58:24Z",
            "summary": "Manatees are aquatic mammals with voracious appetites. They rely on sea grass\nas the main food source, and often spend up to eight hours a day grazing. They\nmove slow and frequently stay in group (i.e. aggregations) in shallow water to\nsearch for food, making them vulnerable to environment change and other risks.\nAccurate counting manatee aggregations within a region is not only biologically\nmeaningful in observing their habit, but also crucial for designing safety\nrules for human boaters, divers, etc., as well as scheduling nursing,\nintervention, and other plans. In this paper, we propose a deep learning based\ncrowd counting approach to automatically count number of manatees within a\nregion, by using low quality images as input. Because manatees have unique\nshape and they often stay in shallow water in groups, water surface reflection,\nocclusion, camouflage etc. making it difficult to accurately count manatee\nnumbers. To address the challenges, we propose to use Anisotropic Gaussian\nKernel (AGK), with tunable rotation and variances, to ensure that density\nfunctions can maximally capture shapes of individual manatees in different\naggregations. After that, we apply AGK kernel to different types of deep neural\nnetworks primarily designed for crowd counting, including VGG, SANet, Congested\nScene Recognition network (CSRNet), MARUNet etc. to learn manatee densities and\ncalculate number of manatees in the scene. By using generic low quality images\nextracted from surveillance videos, our experiment results and comparison show\nthat AGK kernel based manatee counting achieves minimum Mean Absolute Error\n(MAE) and Root Mean Square Error (RMSE). The proposed method works particularly\nwell for counting manatee aggregations in environments with complex background.",
            "author": [
                "Zhiqiang Wang",
                "Yiran Pang",
                "Cihan Ulus",
                "Xingquan Zhu"
            ],
            "link": [
                "http://dx.doi.org/10.1038/s41598-023-45507-3",
                "http://arxiv.org/abs/2311.02315v1",
                "http://arxiv.org/pdf/2311.02315v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02314v1",
            "title": "Thermal Face Image Classification using Deep Learning Techniques",
            "updated": "2023-11-04T03:56:40Z",
            "published": "2023-11-04T03:56:40Z",
            "summary": "Thermal images have various applications in security, medical and industrial\ndomains. This paper proposes a practical deep-learning approach for thermal\nimage classification. Accurate and efficient classification of thermal images\nposes a significant challenge across various fields due to the complex image\ncontent and the scarcity of annotated datasets. This work uses a convolutional\nneural network (CNN) architecture, specifically ResNet-50 and VGGNet-19, to\nextract features from thermal images. This work also applied Kalman filter on\nthermal input images for image denoising. The experimental results demonstrate\nthe effectiveness of the proposed approach in terms of accuracy and efficiency.",
            "author": [
                "Prosenjit Chatterjee",
                "ANK Zaman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02314v1",
                "http://arxiv.org/pdf/2311.02314v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02311v1",
            "title": "A Brief Survey of Open Radio Access Network (O-RAN) Security",
            "updated": "2023-11-04T03:29:03Z",
            "published": "2023-11-04T03:29:03Z",
            "summary": "Open Radio Access Network (O-RAN), a novel architecture that separates the\ntraditional radio access network (RAN) into multiple disaggregated components,\nleads a revolution in the telecommunication ecosystems. Compared to the\ntraditional RAN, the proposed O-RAN paradigm is more flexible and more\ncost-effective for the operators, vendors, and the public. The key design\nconsiderations of O-RAN include virtualization and intelligent capabilities in\norder to meet the new requirements of 5G. However, because of the open nature\nand the newly imported techniques in O-RAN architecture, the assessment of the\nsecurity in O-RAN architecture during its early development stage is crucial.\nThis project aims to present an investigation of the current ORAN architecture\nfrom several attack surfaces, including (1) Architectural openness, (2) Cloud\nand Virtualization, (3) Network slicing, and (4) Machine Learning. The existing\nattack surfaces and corresponding mitigation methods of these attacks are also\nsurveyed and provided in this report, serving as a guiding principle and\nvaluable recommendation for the O-RAN implementers and framework designers.",
            "author": [
                "Yi-Zih Chen",
                "Terrance Yu-Hao Chen",
                "Po-Jung Su",
                "Chi-Ting Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02311v1",
                "http://arxiv.org/pdf/2311.02311v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02310v1",
            "title": "Narrowing the Gap between Zero- and Few-shot Machine Translation by\n  Matching Styles",
            "updated": "2023-11-04T03:18:45Z",
            "published": "2023-11-04T03:18:45Z",
            "summary": "Large language models trained primarily in a monolingual setting have\ndemonstrated their ability to generalize to machine translation using zero- and\nfew-shot examples with in-context learning. However, even though zero-shot\ntranslations are relatively good, there remains a discernible gap comparing\ntheir performance with the few-shot setting. In this paper, we investigate the\nfactors contributing to this gap and find that this gap can largely be closed\n(for about 70%) by matching the writing styles of the target corpus.\nAdditionally, we explore potential approaches to enhance zero-shot baselines\nwithout the need for parallel demonstration examples, providing valuable\ninsights into how these methods contribute to improving translation metrics.",
            "author": [
                "Weiting Tan",
                "Haoran Xu",
                "Lingfeng Shen",
                "Shuyue Stella Li",
                "Kenton Murray",
                "Philipp Koehn",
                "Benjamin Van Durme",
                "Yunmo Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02310v1",
                "http://arxiv.org/pdf/2311.02310v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02306v1",
            "title": "Heteroskedastic Tensor Clustering",
            "updated": "2023-11-04T02:50:40Z",
            "published": "2023-11-04T02:50:40Z",
            "summary": "Tensor clustering, which seeks to extract underlying cluster structures from\nnoisy tensor observations, has gained increasing attention. One extensively\nstudied model for tensor clustering is the tensor block model, which postulates\nthe existence of clustering structures along each mode and has found broad\napplications in areas like multi-tissue gene expression analysis and multilayer\nnetwork analysis. However, currently available computationally feasible methods\nfor tensor clustering either are limited to handling i.i.d. sub-Gaussian noise\nor suffer from suboptimal statistical performance, which restrains their\nutility in applications that have to deal with heteroskedastic data and/or low\nsignal-to-noise-ratio (SNR).\n  To overcome these challenges, we propose a two-stage method, named\n$\\mathsf{High\\text{-}order~HeteroClustering}$ ($\\mathsf{HHC}$), which starts by\nperforming tensor subspace estimation via a novel spectral algorithm called\n$\\mathsf{Thresholded~Deflated\\text{-}HeteroPCA}$, followed by approximate\n$k$-means to obtain cluster nodes. Encouragingly, our algorithm provably\nachieves exact clustering as long as the SNR exceeds the computational limit\n(ignoring logarithmic factors); here, the SNR refers to the ratio of the\npairwise disparity between nodes to the noise level, and the computational\nlimit indicates the lowest SNR that enables exact clustering with polynomial\nruntime. Comprehensive simulation and real-data experiments suggest that our\nalgorithm outperforms existing algorithms across various settings, delivering\nmore reliable clustering performance.",
            "author": [
                "Yuchen Zhou",
                "Yuxin Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02306v1",
                "http://arxiv.org/pdf/2311.02306v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "cs.IT",
                "cs.LG",
                "math.IT",
                "stat.ME",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02304v1",
            "title": "Imitating and Finetuning Model Predictive Control for Robust and\n  Symmetric Quadrupedal Locomotion",
            "updated": "2023-11-04T02:36:24Z",
            "published": "2023-11-04T02:36:24Z",
            "summary": "Control of legged robots is a challenging problem that has been investigated\nby different approaches, such as model-based control and learning algorithms.\nThis work proposes a novel Imitating and Finetuning Model Predictive Control\n(IFM) framework to take the strengths of both approaches. Our framework first\ndevelops a conventional model predictive controller (MPC) using Differential\nDynamic Programming and Raibert heuristic, which serves as an expert policy.\nThen we train a clone of the MPC using imitation learning to make the\ncontroller learnable. Finally, we leverage deep reinforcement learning with\nlimited exploration for further finetuning the policy on more challenging\nterrains. By conducting comprehensive simulation and hardware experiments, we\ndemonstrate that the proposed IFM framework can significantly improve the\nperformance of the given MPC controller on rough, slippery, and conveyor\nterrains that require careful coordination of footsteps. We also showcase that\nIFM can efficiently produce more symmetric, periodic, and energy-efficient\ngaits compared to Vanilla RL with a minimal burden of reward shaping.",
            "author": [
                "Donghoon Youm",
                "Hyunyoung Jung",
                "Hyeongjun Kim",
                "Jemin Hwangbo",
                "Hae-Won Park",
                "Sehoon Ha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02304v1",
                "http://arxiv.org/pdf/2311.02304v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02303v1",
            "title": "MFTCoder: Boosting Code LLMs with Multitask Fine-Tuning",
            "updated": "2023-11-04T02:22:40Z",
            "published": "2023-11-04T02:22:40Z",
            "summary": "Code LLMs have emerged as a specialized research field, with remarkable\nstudies dedicated to enhancing model's coding capabilities through fine-tuning\non pre-trained models. Previous fine-tuning approaches were typically tailored\nto specific downstream tasks or scenarios, which meant separate fine-tuning for\neach task, requiring extensive training resources and posing challenges in\nterms of deployment and maintenance. Furthermore, these approaches failed to\nleverage the inherent interconnectedness among different code-related tasks. To\novercome these limitations, we present a multi-task fine-tuning framework,\nMFTcoder, that enables simultaneous and parallel fine-tuning on multiple tasks.\nBy incorporating various loss functions, we effectively address common\nchallenges in multi-task learning, such as data imbalance, varying difficulty\nlevels, and inconsistent convergence speeds. Extensive experiments have\nconclusively demonstrated that our multi-task fine-tuning approach outperforms\nboth individual fine-tuning on single tasks and fine-tuning on a mixed ensemble\nof tasks. Moreover, MFTcoder offers efficient training capabilities, including\nefficient data tokenization modes and PEFT fine-tuning, resulting in\nsignificantly improved speed compared to traditional fine-tuning methods.\nMFTcoder seamlessly integrates with several mainstream open-source LLMs, such\nas CodeLLama and Qwen. Leveraging the CodeLLama foundation, our MFTcoder\nfine-tuned model, \\textsc{CodeFuse-CodeLLama-34B}, achieves an impressive\npass@1 score of 74.4\\% on the HumaneEval benchmark, surpassing GPT-4\nperformance (67\\%, zero-shot). MFTCoder is open-sourced at\n\\url{https://github.com/codefuse-ai/MFTCOder}",
            "author": [
                "Bingchang Liu",
                "Chaoyu Chen",
                "Cong Liao",
                "Zi Gong",
                "Huan Wang",
                "Zhichao Lei",
                "Ming Liang",
                "Dajun Chen",
                "Min Shen",
                "Hailian Zhou",
                "Hang Yu",
                "Jianguo Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02303v1",
                "http://arxiv.org/pdf/2311.02303v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02302v1",
            "title": "Proactively incremental-learning QAOA",
            "updated": "2023-11-04T02:15:26Z",
            "published": "2023-11-04T02:15:26Z",
            "summary": "Solving optimization problems with high performance is the target of existing\nworks of Quantum Approximate Optimization Algorithm (QAOA). With this\nintention, we propose an advanced QAOA based on incremental learning, where the\ntraining trajectory is proactively segmented into incremental phases. Taking\nthe MaxCut problem as our example, we randomly select a small subgraph from the\nwhole graph and train the quantum circuit to get optimized parameters for the\nMaxCut of the subgraph in the first phase. Then in each subsequent incremental\nphase, a portion of the remaining nodes and edges are added to the current\nsubgraph, and the circuit is retrained to get new optimized parameters. The\nabove operation is repeated until the MaxCut problem on the whole graph is\nsolved. The key point is that the optimized parameters of the previous phase\nwill be reused in the initial parameters of the current phase. Numerous\nsimulation experiments show our method has superior performance on\nApproximation Ratio (AR) and training time compared to prevalent works of QAOA.\nSpecifically, the AR is higher than standard QAOA by 13.17% on weighted random\ngraphs.",
            "author": [
                "Lingxiao Li",
                "Jing Li",
                "Yanqi Song",
                "Sujuan Qin",
                "Qiaoyan Wen",
                "Fei Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02302v1",
                "http://arxiv.org/pdf/2311.02302v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02300v1",
            "title": "Successive Model-Agnostic Meta-Learning for Few-Shot Fault Time Series\n  Prognosis",
            "updated": "2023-11-04T02:07:47Z",
            "published": "2023-11-04T02:07:47Z",
            "summary": "Meta learning is a promising technique for solving few-shot fault prediction\nproblems, which have attracted the attention of many researchers in recent\nyears. Existing meta-learning methods for time series prediction, which\npredominantly rely on random and similarity matching-based task partitioning,\nface three major limitations: (1) feature exploitation inefficiency; (2)\nsuboptimal task data allocation; and (3) limited robustness with small samples.\nTo overcome these limitations, we introduce a novel 'pseudo meta-task'\npartitioning scheme that treats a continuous time period of a time series as a\nmeta-task, composed of multiple successive short time periods. Employing\ncontinuous time series as pseudo meta-tasks allows our method to extract more\ncomprehensive features and relationships from the data, resulting in more\naccurate predictions. Moreover, we introduce a differential algorithm to\nenhance the robustness of our method across different datasets. Through\nextensive experiments on several fault and time series prediction datasets, we\ndemonstrate that our approach substantially enhances prediction performance and\ngeneralization capability under both few-shot and general conditions.",
            "author": [
                "Hai Su",
                "Jiajun Hu",
                "Songsen Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02300v1",
                "http://arxiv.org/pdf/2311.02300v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02290v1",
            "title": "A Physics based Machine Learning Model to characterize Room Temperature\n  Semiconductor Detectors in 3D",
            "updated": "2023-11-04T01:15:00Z",
            "published": "2023-11-04T01:15:00Z",
            "summary": "Room temperature semiconductor radiation detectors (RTSD) for X-ray and\ngamma-ray detection are vital tools for medical imaging, astrophysics and other\napplications. CdZnTe (CZT) has been the main RTSD for more than three decades\nwith desired detection properties. In a typical pixelated configuration, CZT\nhave electrodes on opposite ends. For advanced event reconstruction algorithms\nat sub-pixel level, detailed characterization of the RTSD is required in three\ndimensional (3D) space. However, 3D characterization of the material defects\nand charge transport properties in the sub-pixel regime is a labor-intensive\nprocess with skilled manpower and novel experimental setups. Presently,\nstate-of-art characterization is done over the bulk of the RTSD considering\nhomogenous properties. In this paper, we propose a novel physics based machine\nlearning (PBML) model to characterize the RTSD over a discretized sub-pixelated\n3D volume which is assumed. Our novel approach is the first to characterize a\nfull 3D charge transport model of the RTSD. In this work, we first discretize\nthe RTSD between a pixelated electrodes spatially in 3D - x, y, and z. The\nresulting discretizations are termed as voxels in 3D space. In each voxel, the\ndifferent physics based charge transport properties such as drift, trapping,\ndetrapping and recombination of charges are modeled as trainable model weights.\nThe drift of the charges considers second order non-linear motion which is\nobserved in practice with the RTSDs. Based on the electron-hole pair injections\nas input to the PBML model, and signals at the electrodes, free and trapped\ncharges (electrons and holes) as outputs of the model, the PBML model\ndetermines the trainable weights by backpropagating the loss function. The\ntrained weights of the model represents one-to-one relation to that of the\nactual physical charge transport properties in a voxelized detector.",
            "author": [
                "Srutarshi Banerjee",
                "Miesher Rodrigues",
                "Manuel Ballester",
                "Alexander H. Vija",
                "Aggelos K. Katsaggelos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02290v1",
                "http://arxiv.org/pdf/2311.02290v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02288v1",
            "title": "OverHear: Headphone based Multi-sensor Keystroke Inference",
            "updated": "2023-11-04T00:48:20Z",
            "published": "2023-11-04T00:48:20Z",
            "summary": "Headphones, traditionally limited to audio playback, have evolved to\nintegrate sensors like high-definition microphones and accelerometers. While\nthese advancements enhance user experience, they also introduce potential\neavesdropping vulnerabilities, with keystroke inference being our concern in\nthis work. To validate this threat, we developed OverHear, a keystroke\ninference framework that leverages both acoustic and accelerometer data from\nheadphones. The accelerometer data, while not sufficiently detailed for\nindividual keystroke identification, aids in clustering key presses by hand\nposition. Concurrently, the acoustic data undergoes analysis to extract Mel\nFrequency Cepstral Coefficients (MFCC), aiding in distinguishing between\ndifferent keystrokes. These features feed into machine learning models for\nkeystroke prediction, with results further refined via dictionary-based word\nprediction methods. In our experimental setup, we tested various keyboard types\nunder different environmental conditions. We were able to achieve top-5 key\nprediction accuracy of around 80% for mechanical keyboards and around 60% for\nmembrane keyboards with top-100 word prediction accuracies over 70% for all\nkeyboard types. The results highlight the effectiveness and limitations of our\napproach in the context of real-world scenarios.",
            "author": [
                "Raveen Wijewickrama",
                "Maryam Abbasihafshejani",
                "Anindya Maiti",
                "Murtuza Jadliwala"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02288v1",
                "http://arxiv.org/pdf/2311.02288v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.HC",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02287v1",
            "title": "Predicting Ground Reaction Force from Inertial Sensors",
            "updated": "2023-11-04T00:44:40Z",
            "published": "2023-11-04T00:44:40Z",
            "summary": "The study of ground reaction forces (GRF) is used to characterize the\nmechanical loading experienced by individuals in movements such as running,\nwhich is clinically applicable to identify athletes at risk for stress-related\ninjuries. Our aim in this paper is to determine if data collected with inertial\nmeasurement units (IMUs), that can be worn by athletes during outdoor runs, can\nbe used to predict GRF with sufficient accuracy to allow the analysis of its\nderived biomechanical variables (e.g., contact time and loading rate).\n  In this paper, we consider lightweight approaches in contrast to\nstate-of-the-art prediction using LSTM neural networks. Specifically, we\ncompare use of LSTMs to k-Nearest Neighbors (KNN) regression as well as propose\na novel solution, SVD Embedding Regression (SER), using linear regression\nbetween singular value decomposition embeddings of IMUs data (input) and GRF\ndata (output). We evaluate the accuracy of these techniques when using training\ndata collected from different athletes, from the same athlete, or both, and we\nexplore the use of acceleration and angular velocity data from sensors at\ndifferent locations (sacrum and shanks). Our results illustrate that simple\nmachine learning methods such as SER and KNN can be similarly accurate or more\naccurate than LSTM neural networks, with much faster training times and\nhyperparameter optimization; in particular, SER and KNN are more accurate when\npersonal training data are available, and KNN comes with benefit of providing\nprovenance of prediction. Notably, the use of personal data reduces prediction\nerrors of all methods for most biomechanical variables.",
            "author": [
                "Bowen Song",
                "Marco Paolieri",
                "Harper E. Stewart",
                "Leana Golubchik",
                "Jill L. McNitt-Gray",
                "Vishal Misra",
                "Devavrat Shah"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02287v1",
                "http://arxiv.org/pdf/2311.02287v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02283v1",
            "title": "Objectives Are All You Need: Solving Deceptive Problems Without Explicit\n  Diversity Maintenance",
            "updated": "2023-11-04T00:09:48Z",
            "published": "2023-11-04T00:09:48Z",
            "summary": "Navigating deceptive domains has often been a challenge in machine learning\ndue to search algorithms getting stuck at sub-optimal local optima. Many\nalgorithms have been proposed to navigate these domains by explicitly\nmaintaining diversity or equivalently promoting exploration, such as Novelty\nSearch or other so-called Quality Diversity algorithms. In this paper, we\npresent an approach with promise to solve deceptive domains without explicit\ndiversity maintenance by optimizing a potentially large set of defined\nobjectives. These objectives can be extracted directly from the environment by\nsub-aggregating the raw performance of individuals in a variety of ways. We use\nlexicase selection to optimize for these objectives as it has been shown to\nimplicitly maintain population diversity. We compare this technique with a\nvarying number of objectives to a commonly used quality diversity algorithm,\nMAP-Elites, on a set of discrete optimization as well as reinforcement learning\ndomains with varying degrees of deception. We find that decomposing objectives\ninto many objectives and optimizing them outperforms MAP-Elites on the\ndeceptive domains that we explore. Furthermore, we find that this technique\nresults in competitive performance on the diversity-focused metrics of QD-Score\nand Coverage, without explicitly optimizing for these things. Our ablation\nstudy shows that this technique is robust to different subaggregation\ntechniques. However, when it comes to non-deceptive, or ``illumination\"\ndomains, quality diversity techniques generally outperform our objective-based\nframework with respect to exploration (but not exploitation), hinting at\npotential directions for future work.",
            "author": [
                "Ryan Boldi",
                "Li Ding",
                "Lee Spector"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02283v1",
                "http://arxiv.org/pdf/2311.02283v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02282v1",
            "title": "Contrastive Multi-Modal Representation Learning for Spark Plug Fault\n  Diagnosis",
            "updated": "2023-11-04T00:04:09Z",
            "published": "2023-11-04T00:04:09Z",
            "summary": "Due to the incapability of one sensory measurement to provide enough\ninformation for condition monitoring of some complex engineered industrial\nmechanisms and also for overcoming the misleading noise of a single sensor,\nmultiple sensors are installed to improve the condition monitoring of some\nindustrial equipment. Therefore, an efficient data fusion strategy is demanded.\nIn this research, we presented a Denoising Multi-Modal Autoencoder with a\nunique training strategy based on contrastive learning paradigm, both being\nutilized for the first time in the machine health monitoring realm. The\npresented approach, which leverages the merits of both supervised and\nunsupervised learning, not only achieves excellent performance in fusing\nmultiple modalities (or views) of data into an enriched common representation\nbut also takes data fusion to the next level wherein one of the views can be\nomitted during inference time with very slight performance reduction, or even\nwithout any reduction at all. The presented methodology enables multi-modal\nfault diagnosis systems to perform more robustly in case of sensor failure\noccurrence, and one can also intentionally omit one of the sensors (the more\nexpensive one) in order to build a more cost-effective condition monitoring\nsystem without sacrificing performance for practical purposes. The\neffectiveness of the presented methodology is examined on a real-world private\nmulti-modal dataset gathered under non-laboratory conditions from a complex\nengineered mechanism, an inline four-stroke spark-ignition engine, aiming for\nspark plug fault diagnosis. This dataset, which contains the accelerometer and\nacoustic signals as two modalities, has a very slight amount of fault, and\nachieving good performance on such a dataset promises that the presented method\ncan perform well on other equipment as well.",
            "author": [
                "Ardavan Modarres",
                "Vahid Mohammad-Zadeh Eivaghi",
                "Mahdi Aliyari Shoorehdeli",
                "Ashkan Moosavian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02282v1",
                "http://arxiv.org/pdf/2311.02282v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02278v1",
            "title": "Machine learning's own Industrial Revolution",
            "updated": "2023-11-04T00:00:13Z",
            "published": "2023-11-04T00:00:13Z",
            "summary": "Machine learning is expected to enable the next Industrial Revolution.\nHowever, lacking standardized and automated assembly networks, ML faces\nsignificant challenges to meet ever-growing enterprise demands and empower\nbroad industries. In the Perspective, we argue that ML needs to first complete\nits own Industrial Revolution, elaborate on how to best achieve its goals, and\ndiscuss new opportunities to enable rapid translation from ML's innovation\nfrontier to mass production and utilization.",
            "author": [
                "Yuan Luo",
                "Song Han",
                "Jingjing Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02278v1",
                "http://arxiv.org/pdf/2311.02278v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02273v1",
            "title": "A Sequential Learning Procedure with Applications to Online Sales\n  Examination",
            "updated": "2023-11-03T23:38:52Z",
            "published": "2023-11-03T23:38:52Z",
            "summary": "In this paper, we consider the problem of estimating parameters in a linear\nregression model. We propose a sequential learning procedure to determine the\nsample size for achieving a given small estimation risk, under the widely used\nGauss-Markov setup with independent normal errors. The procedure is proven to\nenjoy the second-order efficiency and risk-efficiency properties, which are\nvalidated through Monte Carlo simulation studies. Using e-commerce data, we\nimplement the procedure to examine the influential factors of online sales.",
            "author": [
                "Jun Hu",
                "Yan Zhuang",
                "Shunan Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02273v1",
                "http://arxiv.org/pdf/2311.02273v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "62L12, 62L05, 62L10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03388v1",
            "title": "Attention-based Models for Snow-Water Equivalent Prediction",
            "updated": "2023-11-03T23:33:35Z",
            "published": "2023-11-03T23:33:35Z",
            "summary": "Snow Water-Equivalent (SWE) -- the amount of water available if snowpack is\nmelted -- is a key decision variable used by water management agencies to make\nirrigation, flood control, power generation and drought management decisions.\nSWE values vary spatiotemporally -- affected by weather, topography and other\nenvironmental factors. While daily SWE can be measured by Snow Telemetry\n(SNOTEL) stations with requisite instrumentation, such stations are spatially\nsparse requiring interpolation techniques to create spatiotemporally complete\ndata. While recent efforts have explored machine learning (ML) for SWE\nprediction, a number of recent ML advances have yet to be considered. The main\ncontribution of this paper is to explore one such ML advance, attention\nmechanisms, for SWE prediction. Our hypothesis is that attention has a unique\nability to capture and exploit correlations that may exist across locations or\nthe temporal spectrum (or both). We present a generic attention-based modeling\nframework for SWE prediction and adapt it to capture spatial attention and\ntemporal attention. Our experimental results on 323 SNOTEL stations in the\nWestern U.S. demonstrate that our attention-based models outperform other\nmachine learning approaches. We also provide key results highlighting the\ndifferences between spatial and temporal attention in this context and a\nroadmap toward deployment for generating spatially-complete SWE maps.",
            "author": [
                "Krishu K. Thapa",
                "Bhupinderjeet Singh",
                "Supriya Savalkar",
                "Alan Fern",
                "Kirti Rajagopalan",
                "Ananth Kalyanaraman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03388v1",
                "http://arxiv.org/pdf/2311.03388v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "physics.ao-ph",
                "I.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02271v2",
            "title": "FaMeSumm: Investigating and Improving Faithfulness of Medical\n  Summarization",
            "updated": "2023-11-08T22:54:33Z",
            "published": "2023-11-03T23:25:53Z",
            "summary": "Summaries of medical text shall be faithful by being consistent and factual\nwith source inputs, which is an important but understudied topic for safety and\nefficiency in healthcare. In this paper, we investigate and improve\nfaithfulness in summarization on a broad range of medical summarization tasks.\nOur investigation reveals that current summarization models often produce\nunfaithful outputs for medical input text. We then introduce FaMeSumm, a\nframework to improve faithfulness by fine-tuning pre-trained language models\nbased on medical knowledge. FaMeSumm performs contrastive learning on designed\nsets of faithful and unfaithful summaries, and it incorporates medical terms\nand their contexts to encourage faithful generation of medical terms. We\nconduct comprehensive experiments on three datasets in two languages: health\nquestion and radiology report summarization datasets in English, and a\npatient-doctor dialogue dataset in Chinese. Results demonstrate that FaMeSumm\nis flexible and effective by delivering consistent improvements over mainstream\nlanguage models such as BART, T5, mT5, and PEGASUS, yielding state-of-the-art\nperformances on metrics for faithfulness and general quality. Human evaluation\nby doctors also shows that FaMeSumm generates more faithful outputs. Our code\nis available at https://github.com/psunlpgroup/FaMeSumm .",
            "author": [
                "Nan Zhang",
                "Yusen Zhang",
                "Wu Guo",
                "Prasenjit Mitra",
                "Rui Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02271v2",
                "http://arxiv.org/pdf/2311.02271v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02270v1",
            "title": "Regularized Linear Regression for Binary Classification",
            "updated": "2023-11-03T23:18:21Z",
            "published": "2023-11-03T23:18:21Z",
            "summary": "Regularized linear regression is a promising approach for binary\nclassification problems in which the training set has noisy labels since the\nregularization term can help to avoid interpolating the mislabeled data points.\nIn this paper we provide a systematic study of the effects of the\nregularization strength on the performance of linear classifiers that are\ntrained to solve binary classification problems by minimizing a regularized\nleast-squares objective. We consider the over-parametrized regime and assume\nthat the classes are generated from a Gaussian Mixture Model (GMM) where a\nfraction $c<\\frac{1}{2}$ of the training data is mislabeled. Under these\nassumptions, we rigorously analyze the classification errors resulting from the\napplication of ridge, $\\ell_1$, and $\\ell_\\infty$ regression. In particular, we\ndemonstrate that ridge regression invariably improves the classification error.\nWe prove that $\\ell_1$ regularization induces sparsity and observe that in many\ncases one can sparsify the solution by up to two orders of magnitude without\nany considerable loss of performance, even though the GMM has no underlying\nsparsity structure. For $\\ell_\\infty$ regularization we show that, for large\nenough regularization strength, the optimal weights concentrate around two\nvalues of opposite sign. We observe that in many cases the corresponding\n\"compression\" of each weight to a single bit leads to very little loss in\nperformance. These latter observations can have significant practical\nramifications.",
            "author": [
                "Danil Akhtiamov",
                "Reza Ghane",
                "Babak Hassibi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02270v1",
                "http://arxiv.org/pdf/2311.02270v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02268v1",
            "title": "LLMs-augmented Contextual Bandit",
            "updated": "2023-11-03T23:12:57Z",
            "published": "2023-11-03T23:12:57Z",
            "summary": "Contextual bandits have emerged as a cornerstone in reinforcement learning,\nenabling systems to make decisions with partial feedback. However, as contexts\ngrow in complexity, traditional bandit algorithms can face challenges in\nadequately capturing and utilizing such contexts. In this paper, we propose a\nnovel integration of large language models (LLMs) with the contextual bandit\nframework. By leveraging LLMs as an encoder, we enrich the representation of\nthe context, providing the bandit with a denser and more informative view.\nPreliminary results on synthetic datasets demonstrate the potential of this\napproach, showing notable improvements in cumulative rewards and reductions in\nregret compared to traditional bandit algorithms. This integration not only\nshowcases the capabilities of LLMs in reinforcement learning but also opens the\ndoor to a new era of contextually-aware decision systems.",
            "author": [
                "Ali Baheri",
                "Cecilia O. Alm"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02268v1",
                "http://arxiv.org/pdf/2311.02268v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02266v1",
            "title": "Multi-task Learning for Optical Coherence Tomography Angiography (OCTA)\n  Vessel Segmentation",
            "updated": "2023-11-03T23:10:56Z",
            "published": "2023-11-03T23:10:56Z",
            "summary": "Optical Coherence Tomography Angiography (OCTA) is a non-invasive imaging\ntechnique that provides high-resolution cross-sectional images of the retina,\nwhich are useful for diagnosing and monitoring various retinal diseases.\nHowever, manual segmentation of OCTA images is a time-consuming and\nlabor-intensive task, which motivates the development of automated segmentation\nmethods. In this paper, we propose a novel multi-task learning method for OCTA\nsegmentation, called OCTA-MTL, that leverages an image-to-DT (Distance\nTransform) branch and an adaptive loss combination strategy. The image-to-DT\nbranch predicts the distance from each vessel voxel to the vessel surface,\nwhich can provide useful shape prior and boundary information for the\nsegmentation task. The adaptive loss combination strategy dynamically adjusts\nthe loss weights according to the inverse of the average loss values of each\ntask, to balance the learning process and avoid the dominance of one task over\nthe other. We evaluate our method on the ROSE-2 dataset its superiority in\nterms of segmentation performance against two baseline methods: a single-task\nsegmentation method and a multi-task segmentation method with a fixed loss\ncombination.",
            "author": [
                "Can Koz",
                "Onat Dalmaz",
                "Mertay Dayanc"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02266v1",
                "http://arxiv.org/pdf/2311.02266v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02262v1",
            "title": "Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs",
            "updated": "2023-11-03T22:56:43Z",
            "published": "2023-11-03T22:56:43Z",
            "summary": "In human-written articles, we often leverage the subtleties of text style,\nsuch as bold and italics, to guide the attention of readers. These textual\nemphases are vital for the readers to grasp the conveyed information. When\ninteracting with large language models (LLMs), we have a similar need -\nsteering the model to pay closer attention to user-specified information, e.g.,\nan instruction. Existing methods, however, are constrained to process plain\ntext and do not support such a mechanism. This motivates us to introduce PASTA\n- Post-hoc Attention STeering Approach, a method that allows LLMs to read text\nwith user-specified emphasis marks. To this end, PASTA identifies a small\nsubset of attention heads and applies precise attention reweighting on them,\ndirecting the model attention to user-specified parts. Like prompting, PASTA is\napplied at inference time and does not require changing any model parameters.\nExperiments demonstrate that PASTA can substantially enhance an LLM's ability\nto follow user instructions or integrate new knowledge from user inputs,\nleading to a significant performance improvement on a variety of tasks, e.g.,\nan average accuracy improvement of 22% for LLAMA-7B. Our code is publicly\navailable at https://github.com/QingruZhang/PASTA .",
            "author": [
                "Qingru Zhang",
                "Chandan Singh",
                "Liyuan Liu",
                "Xiaodong Liu",
                "Bin Yu",
                "Jianfeng Gao",
                "Tuo Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02262v1",
                "http://arxiv.org/pdf/2311.02262v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02258v1",
            "title": "Learning Time-Invariant Representations for Individual Neurons from\n  Population Dynamics",
            "updated": "2023-11-03T22:30:12Z",
            "published": "2023-11-03T22:30:12Z",
            "summary": "Neurons can display highly variable dynamics. While such variability\npresumably supports the wide range of behaviors generated by the organism,\ntheir gene expressions are relatively stable in the adult brain. This suggests\nthat neuronal activity is a combination of its time-invariant identity and the\ninputs the neuron receives from the rest of the circuit. Here, we propose a\nself-supervised learning based method to assign time-invariant representations\nto individual neurons based on permutation-, and population size-invariant\nsummary of population recordings. We fit dynamical models to neuronal activity\nto learn a representation by considering the activity of both the individual\nand the neighboring population. Our self-supervised approach and use of\nimplicit representations enable robust inference against imperfections such as\npartial overlap of neurons across sessions, trial-to-trial variability, and\nlimited availability of molecular (transcriptomic) labels for downstream\nsupervised tasks. We demonstrate our method on a public multimodal dataset of\nmouse cortical neuronal activity and transcriptomic labels. We report > 35%\nimprovement in predicting the transcriptomic subclass identity and > 20%\nimprovement in predicting class identity with respect to the state-of-the-art.",
            "author": [
                "Lu Mi",
                "Trung Le",
                "Tianxing He",
                "Eli Shlizerman",
                "Uygar S\u00fcmb\u00fcl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02258v1",
                "http://arxiv.org/pdf/2311.02258v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02254v1",
            "title": "Learning-Based and Quality Preserving Super-Resolution of Noisy Images",
            "updated": "2023-11-03T22:00:50Z",
            "published": "2023-11-03T22:00:50Z",
            "summary": "Several applications require the super-resolution of noisy images and the\npreservation of geometrical and texture features. State-of-the-art\nsuper-resolution methods do not account for noise and generally enhance the\noutput image's artefacts (e.g., aliasing, blurring). We propose a\nlearning-based method that accounts for the presence of noise and preserves the\nproperties of the input image, as measured by quantitative metrics (e.g.,\nnormalised crossed correlation, normalised mean squared error,\npeak-signal-to-noise-ration, structural similarity feature-based similarity,\nuniversal image quality). We train our network to up-sample a low-resolution\nnoisy image while preserving its properties. We perform our tests on the Cineca\nMarconi100 cluster, at the 26th position in the top500 list. The experimental\nresults show that our method outperforms learning-based methods, has comparable\nresults with standard methods, preserves the properties of the input image as\ncontours, brightness, and textures, and reduces the artefacts. As average\nquantitative metrics, our method has a PSNR value of 23.81 on the\nsuper-resolution of Gaussian noise images with a 2X up-sampling factor. In\ncontrast, previous work has a PSNR value of 23.09 (standard method) and 21.78\n(learning-based method). Our learning-based and quality-preserving\nsuper-resolution improves the high-resolution prediction of noisy images with\nrespect to state-of-the-art methods with different noise types and up-sampling\nfactors.",
            "author": [
                "Simone Cammarasana",
                "Giuseppe Patan\u00e8"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02254v1",
                "http://arxiv.org/pdf/2311.02254v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02253v1",
            "title": "Comparative Knowledge Distillation",
            "updated": "2023-11-03T21:55:33Z",
            "published": "2023-11-03T21:55:33Z",
            "summary": "In the era of large scale pretrained models, Knowledge Distillation (KD)\nserves an important role in transferring the wisdom of computationally heavy\nteacher models to lightweight, efficient student models while preserving\nperformance. Traditional KD paradigms, however, assume readily available access\nto teacher models for frequent inference -- a notion increasingly at odds with\nthe realities of costly, often proprietary, large scale models. Addressing this\ngap, our paper considers how to minimize the dependency on teacher model\ninferences in KD in a setting we term Few Teacher Inference Knowledge\nDistillation (FTI KD). We observe that prevalent KD techniques and state of the\nart data augmentation strategies fall short in this constrained setting.\nDrawing inspiration from educational principles that emphasize learning through\ncomparison, we propose Comparative Knowledge Distillation (CKD), which\nencourages student models to understand the nuanced differences in a teacher\nmodel's interpretations of samples. Critically, CKD provides additional\nlearning signals to the student without making additional teacher calls. We\nalso extend the principle of CKD to groups of samples, enabling even more\nefficient learning from limited teacher calls. Empirical evaluation across\nvaried experimental settings indicates that CKD consistently outperforms state\nof the art data augmentation and KD techniques.",
            "author": [
                "Alex Wilf",
                "Alex Tianyi Xu",
                "Paul Pu Liang",
                "Alexander Obolenskiy",
                "Daniel Fried",
                "Louis-Philippe Morency"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02253v1",
                "http://arxiv.org/pdf/2311.02253v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02251v1",
            "title": "The Potential of Wearable Sensors for Assessing Patient Acuity in\n  Intensive Care Unit (ICU)",
            "updated": "2023-11-03T21:52:05Z",
            "published": "2023-11-03T21:52:05Z",
            "summary": "Acuity assessments are vital in critical care settings to provide timely\ninterventions and fair resource allocation. Traditional acuity scores rely on\nmanual assessments and documentation of physiological states, which can be\ntime-consuming, intermittent, and difficult to use for healthcare providers.\nFurthermore, such scores do not incorporate granular information such as\npatients' mobility level, which can indicate recovery or deterioration in the\nICU. We hypothesized that existing acuity scores could be potentially improved\nby employing Artificial Intelligence (AI) techniques in conjunction with\nElectronic Health Records (EHR) and wearable sensor data. In this study, we\nevaluated the impact of integrating mobility data collected from wrist-worn\naccelerometers with clinical data obtained from EHR for developing an AI-driven\nacuity assessment score. Accelerometry data were collected from 86 patients\nwearing accelerometers on their wrists in an academic hospital setting. The\ndata was analyzed using five deep neural network models: VGG, ResNet,\nMobileNet, SqueezeNet, and a custom Transformer network. These models\noutperformed a rule-based clinical score (SOFA= Sequential Organ Failure\nAssessment) used as a baseline, particularly regarding the precision,\nsensitivity, and F1 score. The results showed that while a model relying solely\non accelerometer data achieved limited performance (AUC 0.50, Precision 0.61,\nand F1-score 0.68), including demographic information with the accelerometer\ndata led to a notable enhancement in performance (AUC 0.69, Precision 0.75, and\nF1-score 0.67). This work shows that the combination of mobility and patient\ninformation can successfully differentiate between stable and unstable states\nin critically ill patients.",
            "author": [
                "Jessica Sena",
                "Mohammad Tahsin Mostafiz",
                "Jiaqing Zhang",
                "Andrea Davidson",
                "Sabyasachi Bandyopadhyay",
                "Ren Yuanfang",
                "Tezcan Ozrazgat-Baslanti",
                "Benjamin Shickel",
                "Tyler Loftus",
                "William Robson Schwartz",
                "Azra Bihorac",
                "Parisa Rashidi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02251v1",
                "http://arxiv.org/pdf/2311.02251v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02248v1",
            "title": "COSMIC: Data Efficient Instruction-tuning For Speech In-Context Learning",
            "updated": "2023-11-03T21:47:03Z",
            "published": "2023-11-03T21:47:03Z",
            "summary": "We present a data and cost efficient way of incorporating the speech modality\ninto a large language model (LLM). The resulting multi-modal LLM is a\nCOntextual Speech Model with Instruction-following/in-context-learning\nCapabilities - COSMIC. Speech comprehension test question-answer (SQA) pairs\nare generated using GPT-3.5 based on the speech transcriptions as a part of the\nsupervision for the instruction tuning. With fewer than 20M trainable\nparameters and as little as 450 hours of English speech data for SQA\ngeneration, COSMIC exhibits emergent instruction-following and in-context\nlearning capabilities in speech-to-text tasks. The model is able to follow the\ngiven text instructions to generate text response even on the unseen EN$\\to$X\nspeech-to-text translation (S2TT) task with zero-shot setting. We evaluate the\nmodel's in-context learning via various tasks such as EN$\\to$X S2TT and\nfew-shot domain adaptation. And instruction-following capabilities are\nevaluated through a contextual biasing benchmark. Our results demonstrate the\nefficacy of the proposed low cost recipe for building a speech LLM and that\nwith the new instruction-tuning data.",
            "author": [
                "Jing Pan",
                "Jian Wu",
                "Yashesh Gaur",
                "Sunit Sivasankaran",
                "Zhuo Chen",
                "Shujie Liu",
                "Jinyu Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02248v1",
                "http://arxiv.org/pdf/2311.02248v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02247v1",
            "title": "PRISM: Progressive Restoration for Scene Graph-based Image Manipulation",
            "updated": "2023-11-03T21:30:34Z",
            "published": "2023-11-03T21:30:34Z",
            "summary": "Scene graphs have emerged as accurate descriptive priors for image generation\nand manipulation tasks, however, their complexity and diversity of the shapes\nand relations of objects in data make it challenging to incorporate them into\nthe models and generate high-quality results. To address these challenges, we\npropose PRISM, a novel progressive multi-head image manipulation approach to\nimprove the accuracy and quality of the manipulated regions in the scene. Our\nimage manipulation framework is trained using an end-to-end denoising masked\nreconstruction proxy task, where the masked regions are progressively unmasked\nfrom the outer regions to the inner part. We take advantage of the outer part\nof the masked area as they have a direct correlation with the context of the\nscene. Moreover, our multi-head architecture simultaneously generates detailed\nobject-specific regions in addition to the entire image to produce\nhigher-quality images. Our model outperforms the state-of-the-art methods in\nthe semantic image manipulation task on the CLEVR and Visual Genome datasets.\nOur results demonstrate the potential of our approach for enhancing the quality\nand precision of scene graph-based image manipulation.",
            "author": [
                "Pavel Jahoda",
                "Azade Farshad",
                "Yousef Yeganeh",
                "Ehsan Adeli",
                "Nassir Navab"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02247v1",
                "http://arxiv.org/pdf/2311.02247v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02243v1",
            "title": "Equal Opportunity of Coverage in Fair Regression",
            "updated": "2023-11-03T21:19:59Z",
            "published": "2023-11-03T21:19:59Z",
            "summary": "We study fair machine learning (ML) under predictive uncertainty to enable\nreliable and trustworthy decision-making. The seminal work of ``equalized\ncoverage'' proposed an uncertainty-aware fairness notion. However, it does not\nguarantee equal coverage rates across more fine-grained groups (e.g.,\nlow-income females) conditioning on the true label and is biased in the\nassessment of uncertainty. To tackle these limitations, we propose a new\nuncertainty-aware fairness -- Equal Opportunity of Coverage (EOC) -- that aims\nto achieve two properties: (1) coverage rates for different groups with similar\noutcomes are close, and (2) the coverage rate for the entire population remains\nat a predetermined level. Further, the prediction intervals should be narrow to\nbe informative. We propose Binned Fair Quantile Regression (BFQR), a\ndistribution-free post-processing method to improve EOC with reasonable width\nfor any trained ML models. It first calibrates a hold-out set to bound\ndeviation from EOC, then leverages conformal prediction to maintain EOC on a\ntest set, meanwhile optimizing prediction interval width. Experimental results\ndemonstrate the effectiveness of our method in improving EOC. Our code is\npublicly available at https://github.com/fangxin-wang/bfqr .",
            "author": [
                "Fangxin Wang",
                "Lu Cheng",
                "Ruocheng Guo",
                "Kay Liu",
                "Philip S. Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02243v1",
                "http://arxiv.org/pdf/2311.02243v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02239v1",
            "title": "Using DUCK-Net for Polyp Image Segmentation",
            "updated": "2023-11-03T20:58:44Z",
            "published": "2023-11-03T20:58:44Z",
            "summary": "This paper presents a novel supervised convolutional neural network\narchitecture, \"DUCK-Net\", capable of effectively learning and generalizing from\nsmall amounts of medical images to perform accurate segmentation tasks. Our\nmodel utilizes an encoder-decoder structure with a residual downsampling\nmechanism and a custom convolutional block to capture and process image\ninformation at multiple resolutions in the encoder segment. We employ data\naugmentation techniques to enrich the training set, thus increasing our model's\nperformance. While our architecture is versatile and applicable to various\nsegmentation tasks, in this study, we demonstrate its capabilities specifically\nfor polyp segmentation in colonoscopy images. We evaluate the performance of\nour method on several popular benchmark datasets for polyp segmentation,\nKvasir-SEG, CVC-ClinicDB, CVC-ColonDB, and ETIS-LARIBPOLYPDB showing that it\nachieves state-of-the-art results in terms of mean Dice coefficient, Jaccard\nindex, Precision, Recall, and Accuracy. Our approach demonstrates strong\ngeneralization capabilities, achieving excellent performance even with limited\ntraining data. The code is publicly available on GitHub:\nhttps://github.com/RazvanDu/DUCK-Net",
            "author": [
                "Razvan-Gabriel Dumitru",
                "Darius Peteleaza",
                "Catalin Craciun"
            ],
            "link": [
                "http://dx.doi.org/10.1038/s41598-023-36940-5",
                "http://arxiv.org/abs/2311.02239v1",
                "http://arxiv.org/pdf/2311.02239v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "I.2; I.4; I.5"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02237v1",
            "title": "Explainable Authorship Identification in Cultural Heritage Applications:\n  Analysis of a New Perspective",
            "updated": "2023-11-03T20:51:15Z",
            "published": "2023-11-03T20:51:15Z",
            "summary": "While a substantial amount of work has recently been devoted to enhance the\nperformance of computational Authorship Identification (AId) systems, little to\nno attention has been paid to endowing AId systems with the ability to explain\nthe reasons behind their predictions. This lacking substantially hinders the\npractical employment of AId methodologies, since the predictions returned by\nsuch systems are hardly useful unless they are supported with suitable\nexplanations. In this paper, we explore the applicability of existing\ngeneral-purpose eXplainable Artificial Intelligence (XAI) techniques to AId,\nwith a special focus on explanations addressed to scholars working in cultural\nheritage. In particular, we assess the relative merits of three different types\nof XAI techniques (feature ranking, probing, factuals and counterfactual\nselection) on three different AId tasks (authorship attribution, authorship\nverification, same-authorship verification) by running experiments on real AId\ndata. Our analysis shows that, while these techniques make important first\nsteps towards explainable Authorship Identification, more work remains to be\ndone in order to provide tools that can be profitably integrated in the\nworkflows of scholars.",
            "author": [
                "Mattia Setzu",
                "Silvia Corbara",
                "Anna Monreale",
                "Alejandro Moreo",
                "Fabrizio Sebastiani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02237v1",
                "http://arxiv.org/pdf/2311.02237v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02236v1",
            "title": "Robust Fine-Tuning of Vision-Language Models for Domain Generalization",
            "updated": "2023-11-03T20:50:40Z",
            "published": "2023-11-03T20:50:40Z",
            "summary": "Transfer learning enables the sharing of common knowledge among models for a\nvariety of downstream tasks, but traditional methods suffer in limited training\ndata settings and produce narrow models incapable of effectively generalizing\nunder distribution shifts. Foundation models have recently demonstrated\nimpressive zero-shot inference capabilities and robustness under distribution\nshifts. However, zero-shot evaluation for these models has been predominantly\nconfined to benchmarks with simple distribution shifts, limiting our\nunderstanding of their effectiveness under the more realistic shifts found in\npractice. Moreover, common fine-tuning methods for these models have yet to be\nevaluated against vision models in few-shot scenarios where training data is\nlimited. To address these gaps, we present a new recipe for few-shot\nfine-tuning of the popular vision-language foundation model CLIP and evaluate\nits performance on challenging benchmark datasets with realistic distribution\nshifts from the WILDS collection. Our experimentation demonstrates that, while\nzero-shot CLIP fails to match performance of trained vision models on more\ncomplex benchmarks, few-shot CLIP fine-tuning outperforms its vision-only\ncounterparts in terms of in-distribution and out-of-distribution accuracy at\nall levels of training data availability. This provides a strong incentive for\nadoption of foundation models within few-shot learning applications operating\nwith real-world data. Code is available at\nhttps://github.com/mit-ll/robust-vision-language-finetuning",
            "author": [
                "Kevin Vogt-Lowell",
                "Noah Lee",
                "Theodoros Tsiligkaridis",
                "Marc Vaillant"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02236v1",
                "http://arxiv.org/pdf/2311.02236v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02227v1",
            "title": "State-wise Safe Reinforcement Learning With Pixel Observations",
            "updated": "2023-11-03T20:32:30Z",
            "published": "2023-11-03T20:32:30Z",
            "summary": "Reinforcement Learning(RL) in the context of safe exploration has long\ngrappled with the challenges of the delicate balance between maximizing rewards\nand minimizing safety violations, the complexities arising from contact-rich or\nnon-smooth environments, and high-dimensional pixel observations. Furthermore,\nincorporating state-wise safety constraints in the exploration and learning\nprocess, where the agent is prohibited from accessing unsafe regions without\nprior knowledge, adds an additional layer of complexity. In this paper, we\npropose a novel pixel-observation safe RL algorithm that efficiently encodes\nstate-wise safety constraints with unknown hazard regions through the\nintroduction of a latent barrier function learning mechanism. As a joint\nlearning framework, our approach first involves constructing a latent dynamics\nmodel with low-dimensional latent spaces derived from pixel observations.\nSubsequently, we build and learn a latent barrier function on top of the latent\ndynamics and conduct policy optimization simultaneously, thereby improving both\nsafety and the total expected return. Experimental evaluations on the\nsafety-gym benchmark suite demonstrate that our proposed method significantly\nreduces safety violations throughout the training process and demonstrates\nfaster safety convergence compared to existing methods while achieving\ncompetitive results in reward return.",
            "author": [
                "Simon Sinong Zhan",
                "Yixuan Wang",
                "Qingyuan Wu",
                "Ruochen Jiao",
                "Chao Huang",
                "Qi Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02227v1",
                "http://arxiv.org/pdf/2311.02227v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02225v1",
            "title": "Multi-scale Time-stepping of Partial Differential Equations with\n  Transformers",
            "updated": "2023-11-03T20:26:43Z",
            "published": "2023-11-03T20:26:43Z",
            "summary": "Developing fast surrogates for Partial Differential Equations (PDEs) will\naccelerate design and optimization in almost all scientific and engineering\napplications. Neural networks have been receiving ever-increasing attention and\ndemonstrated remarkable success in computational modeling of PDEs, however;\ntheir prediction accuracy is not at the level of full deployment. In this work,\nwe utilize the transformer architecture, the backbone of numerous\nstate-of-the-art AI models, to learn the dynamics of physical systems as the\nmixing of spatial patterns learned by a convolutional autoencoder. Moreover, we\nincorporate the idea of multi-scale hierarchical time-stepping to increase the\nprediction speed and decrease accumulated error over time. Our model achieves\nsimilar or better results in predicting the time-evolution of Navier-Stokes\nequations compared to the powerful Fourier Neural Operator (FNO) and two\ntransformer-based neural operators OFormer and Galerkin Transformer.",
            "author": [
                "AmirPouya Hemmasian",
                "Amir Barati Farimani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02225v1",
                "http://arxiv.org/pdf/2311.02225v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16139v1",
            "title": "GNNBleed: Inference Attacks to Unveil Private Edges in Graphs with\n  Realistic Access to GNN Models",
            "updated": "2023-11-03T20:26:03Z",
            "published": "2023-11-03T20:26:03Z",
            "summary": "Graph Neural Networks (GNNs) have increasingly become an indispensable tool\nin learning from graph-structured data, catering to various applications\nincluding social network analysis, recommendation systems, etc. At the heart of\nthese networks are the edges which are crucial in guiding GNN models'\npredictions. In many scenarios, these edges represent sensitive information,\nsuch as personal associations or financial dealings -- thus requiring privacy\nassurance. However, their contributions to GNN model predictions may in turn be\nexploited by the adversary to compromise their privacy. Motivated by these\nconflicting requirements, this paper investigates edge privacy in contexts\nwhere adversaries possess black-box GNN model access, restricted further by\naccess controls, preventing direct insights into arbitrary node outputs. In\nthis context, we introduce a series of privacy attacks grounded on the\nmessage-passing mechanism of GNNs. These strategies allow adversaries to deduce\nconnections between two nodes not by directly analyzing the model's output for\nthese pairs but by analyzing the output for nodes linked to them. Our\nevaluation with seven real-life datasets and four GNN architectures underlines\na significant vulnerability: even in systems fortified with access control\nmechanisms, an adaptive adversary can decipher private connections between\nnodes, thereby revealing potentially sensitive relationships and compromising\nthe confidentiality of the graph.",
            "author": [
                "Zeyu Song",
                "Ehsanul Kabir",
                "Shagufta Mehnaz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16139v1",
                "http://arxiv.org/pdf/2311.16139v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02222v1",
            "title": "Lessons learned while developing the Serenity-S1 ATCA card",
            "updated": "2023-11-03T20:16:53Z",
            "published": "2023-11-03T20:16:53Z",
            "summary": "The Serenity-S1 is a Xilinx Virtex Ultrascale+ based Advanced\nTelecommunications Computing Architecture (ATCA) processing blade that has been\noptimised for production. It incorporates many developments from the Serenity-A\nand Serenity-Z prototype cards and, where possible, adopts solutions being used\nacross CERN. It also uses many new parts because commonly used parts have\ndisappeared from the market during the semiconductor crisis, with only some\nreturning.\n  Improvements to simplify manufacture, the performance of new components, some\nof the more difficult aspects of procurement, the performance of\nproduction-grade Samtec 25\\,Gb/s optical firefly parts, and issues with the\nrack cooling infrastructure are discussed.",
            "author": [
                "T. Mehner",
                "L. E. Ardila-Perez",
                "M. Balzer",
                "G. Fedi",
                "M. Fuchs",
                "A. Howard",
                "G. Iles",
                "M. Loutit",
                "S. Mansbridge",
                "F. Palla",
                "D. Parker",
                "M. Pesaresi",
                "A. Rose",
                "M. Saleh",
                "O. Sander",
                "M. Schleicher",
                "C. Strohman",
                "D. Tcherniakhovski",
                "T. Williams",
                "J. Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02222v1",
                "http://arxiv.org/pdf/2311.02222v1"
            ],
            "primary_category": "physics.ins-det",
            "category": [
                "physics.ins-det"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02221v1",
            "title": "Structured Neural Networks for Density Estimation and Causal Inference",
            "updated": "2023-11-03T20:15:05Z",
            "published": "2023-11-03T20:15:05Z",
            "summary": "Injecting structure into neural networks enables learning functions that\nsatisfy invariances with respect to subsets of inputs. For instance, when\nlearning generative models using neural networks, it is advantageous to encode\nthe conditional independence structure of observed variables, often in the form\nof Bayesian networks. We propose the Structured Neural Network (StrNN), which\ninjects structure through masking pathways in a neural network. The masks are\ndesigned via a novel relationship we explore between neural network\narchitectures and binary matrix factorization, to ensure that the desired\nindependencies are respected. We devise and study practical algorithms for this\notherwise NP-hard design problem based on novel objectives that control the\nmodel architecture. We demonstrate the utility of StrNN in three applications:\n(1) binary and Gaussian density estimation with StrNN, (2) real-valued density\nestimation with Structured Autoregressive Flows (StrAFs) and Structured\nContinuous Normalizing Flows (StrCNF), and (3) interventional and\ncounterfactual analysis with StrAFs for causal inference. Our work opens up new\navenues for learning neural networks that enable data-efficient generative\nmodeling and the use of normalizing flows for causal effect estimation.",
            "author": [
                "Asic Q. Chen",
                "Ruian Shi",
                "Xiang Gao",
                "Ricardo Baptista",
                "Rahul G. Krishnan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02221v1",
                "http://arxiv.org/pdf/2311.02221v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02216v1",
            "title": "Exploring the Numerical Reasoning Capabilities of Language Models: A\n  Comprehensive Analysis on Tabular Data",
            "updated": "2023-11-03T20:05:30Z",
            "published": "2023-11-03T20:05:30Z",
            "summary": "Numbers are crucial for various real-world domains such as finance,\neconomics, and science. Thus, understanding and reasoning with numbers are\nessential skills for language models to solve different tasks. While different\nnumerical benchmarks have been introduced in recent years, they are limited to\nspecific numerical aspects mostly. In this paper, we propose a hierarchical\ntaxonomy for numerical reasoning skills with more than ten reasoning types\nacross four levels: representation, number sense, manipulation, and complex\nreasoning. We conduct a comprehensive evaluation of state-of-the-art models to\nidentify reasoning challenges specific to them. Henceforth, we develop a\ndiverse set of numerical probes employing a semi-automated approach. We focus\non the tabular Natural Language Inference (TNLI) task as a case study and\nmeasure models' performance shifts. Our results show that no model consistently\nexcels across all numerical reasoning types. Among the probed models, FlanT5\n(few-/zero-shot) and GPT-3.5 (few-shot) demonstrate strong overall numerical\nreasoning skills compared to other models. Label-flipping probes indicate that\nmodels often exploit dataset artifacts to predict the correct labels.",
            "author": [
                "Mubashara Akhtar",
                "Abhilash Shankarampeta",
                "Vivek Gupta",
                "Arpit Patil",
                "Oana Cocarascu",
                "Elena Simperl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02216v1",
                "http://arxiv.org/pdf/2311.02216v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02215v1",
            "title": "Towards model-free RL algorithms that scale well with unstructured data",
            "updated": "2023-11-03T20:03:54Z",
            "published": "2023-11-03T20:03:54Z",
            "summary": "Conventional reinforcement learning (RL) algorithms exhibit broad generality\nin their theoretical formulation and high performance on several challenging\ndomains when combined with powerful function approximation. However, developing\nRL algorithms that perform well across problems with unstructured observations\nat scale remains challenging because most function approximation methods rely\non externally provisioned knowledge about the structure of the input for good\nperformance (e.g. convolutional networks, graph neural networks, tile-coding).\nA common practice in RL is to evaluate algorithms on a single problem, or on\nproblems with limited variation in the observation scale. RL practitioners lack\na systematic way to study how well a single RL algorithm performs when\ninstantiated across a range of problem scales, and they lack function\napproximation techniques that scale well with unstructured observations.\n  We address these limitations by providing environments and algorithms to\nstudy scaling for unstructured observation vectors and flat action spaces. We\nintroduce a family of combinatorial RL problems with an exponentially large\nstate space and high-dimensional dynamics but where linear computation is\nsufficient to learn a (nonlinear) value function estimate for performant\ncontrol. We provide an algorithm that constructs reward-relevant general value\nfunction (GVF) questions to find and exploit predictive structure directly from\nthe experience stream. In an empirical evaluation of the approach on synthetic\nproblems, we observe a sample complexity that scales linearly with the\nobservation size. The proposed algorithm reliably outperforms a conventional\ndeep RL algorithm on these scaling problems, and they exhibit several desirable\nauxiliary properties. These results suggest new algorithmic mechanisms by which\nalgorithms can learn at scale from unstructured data.",
            "author": [
                "Joseph Modayil",
                "Zaheer Abbas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02215v1",
                "http://arxiv.org/pdf/2311.02215v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02213v1",
            "title": "Joint Composite Latent Space Bayesian Optimization",
            "updated": "2023-11-03T19:53:37Z",
            "published": "2023-11-03T19:53:37Z",
            "summary": "Bayesian Optimization (BO) is a technique for sample-efficient black-box\noptimization that employs probabilistic models to identify promising input\nlocations for evaluation. When dealing with composite-structured functions,\nsuch as f=g o h, evaluating a specific location x yields observations of both\nthe final outcome f(x) = g(h(x)) as well as the intermediate output(s) h(x).\nPrevious research has shown that integrating information from these\nintermediate outputs can enhance BO performance substantially. However,\nexisting methods struggle if the outputs h(x) are high-dimensional. Many\nrelevant problems fall into this setting, including in the context of\ngenerative AI, molecular design, or robotics. To effectively tackle these\nchallenges, we introduce Joint Composite Latent Space Bayesian Optimization\n(JoCo), a novel framework that jointly trains neural network encoders and\nprobabilistic models to adaptively compress high-dimensional input and output\nspaces into manageable latent representations. This enables viable BO on these\ncompressed representations, allowing JoCo to outperform other state-of-the-art\nmethods in high-dimensional BO on a wide variety of simulated and real-world\nproblems.",
            "author": [
                "Natalie Maus",
                "Zhiyuan Jerry Lin",
                "Maximilian Balandat",
                "Eytan Bakshy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02213v1",
                "http://arxiv.org/pdf/2311.02213v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04929v1",
            "title": "An Interdisciplinary Outlook on Large Language Models for Scientific\n  Research",
            "updated": "2023-11-03T19:41:09Z",
            "published": "2023-11-03T19:41:09Z",
            "summary": "In this paper, we describe the capabilities and constraints of Large Language\nModels (LLMs) within disparate academic disciplines, aiming to delineate their\nstrengths and limitations with precision. We examine how LLMs augment\nscientific inquiry, offering concrete examples such as accelerating literature\nreview by summarizing vast numbers of publications, enhancing code development\nthrough automated syntax correction, and refining the scientific writing\nprocess. Simultaneously, we articulate the challenges LLMs face, including\ntheir reliance on extensive and sometimes biased datasets, and the potential\nethical dilemmas stemming from their use. Our critical discussion extends to\nthe varying impacts of LLMs across fields, from the natural sciences, where\nthey help model complex biological sequences, to the social sciences, where\nthey can parse large-scale qualitative data. We conclude by offering a nuanced\nperspective on how LLMs can be both a boon and a boundary to scientific\nprogress.",
            "author": [
                "James Boyko",
                "Joseph Cohen",
                "Nathan Fox",
                "Maria Han Veiga",
                "Jennifer I-Hsiu Li",
                "Jing Liu",
                "Bernardo Modenesi",
                "Andreas H. Rauch",
                "Kenneth N. Reid",
                "Soumi Tribedi",
                "Anastasia Visheratina",
                "Xin Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04929v1",
                "http://arxiv.org/pdf/2311.04929v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.DL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02202v1",
            "title": "Neural Collage Transfer: Artistic Reconstruction via Material\n  Manipulation",
            "updated": "2023-11-03T19:10:37Z",
            "published": "2023-11-03T19:10:37Z",
            "summary": "Collage is a creative art form that uses diverse material scraps as a base\nunit to compose a single image. Although pixel-wise generation techniques can\nreproduce a target image in collage style, it is not a suitable method due to\nthe solid stroke-by-stroke nature of the collage form. While some previous\nworks for stroke-based rendering produced decent sketches and paintings,\ncollages have received much less attention in research despite their popularity\nas a style. In this paper, we propose a method for learning to make collages\nvia reinforcement learning without the need for demonstrations or collage\nartwork data. We design the collage Markov Decision Process (MDP), which allows\nthe agent to handle various materials and propose a model-based soft\nactor-critic to mitigate the agent's training burden derived from the\nsophisticated dynamics of collage. Moreover, we devise additional techniques\nsuch as active material selection and complexity-based multi-scale collage to\nhandle target images at any size and enhance the results' aesthetics by placing\nrelatively more scraps in areas of high complexity. Experimental results show\nthat the trained agent appropriately selected and pasted materials to\nregenerate the target image into a collage and obtained a higher evaluation\nscore on content and style than pixel-wise generation methods. Code is\navailable at https://github.com/northadventure/CollageRL.",
            "author": [
                "Ganghun Lee",
                "Minji Kim",
                "Yunsu Lee",
                "Minsu Lee",
                "Byoung-Tak Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02202v1",
                "http://arxiv.org/pdf/2311.02202v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02198v3",
            "title": "Imitation Bootstrapped Reinforcement Learning",
            "updated": "2023-11-24T06:08:20Z",
            "published": "2023-11-03T19:03:20Z",
            "summary": "Despite the considerable potential of reinforcement learning (RL), robotics\ncontrol tasks predominantly rely on imitation learning (IL) owing to its better\nsample efficiency. However, given the high cost of collecting extensive\ndemonstrations, RL is still appealing if it can utilize limited imitation data\nfor efficient autonomous self-improvement. Existing RL methods that utilize\ndemonstrations either initialize the replay buffer with demonstrations and\noversample them during RL training, which does not benefit from the\ngeneralization potential of modern IL methods, or pretrain the RL policy with\nIL on the demonstrations, which requires additional mechanisms to prevent\ncatastrophic forgetting during RL fine-tuning. We propose imitation\nbootstrapped reinforcement learning (IBRL), a novel framework that first trains\nan IL policy on a limited number of demonstrations and then uses it to propose\nalternative actions for both online exploration and target value bootstrapping.\nIBRL achieves SoTA performance and sample efficiency on 7 challenging sparse\nreward continuous control tasks in simulation while learning directly from\npixels. As a highlight of our method, IBRL achieves $6.4\\times$ higher success\nrate than RLPD, a strong method that combines the idea of oversampling\ndemonstrations with modern RL improvements, under the budget of 10 demos and\n100K interactions in the challenging PickPlaceCan task in the Robomimic\nbenchmark.",
            "author": [
                "Hengyuan Hu",
                "Suvir Mirchandani",
                "Dorsa Sadigh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02198v3",
                "http://arxiv.org/pdf/2311.02198v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02194v1",
            "title": "AlberDICE: Addressing Out-Of-Distribution Joint Actions in Offline\n  Multi-Agent RL via Alternating Stationary Distribution Correction Estimation",
            "updated": "2023-11-03T18:56:48Z",
            "published": "2023-11-03T18:56:48Z",
            "summary": "One of the main challenges in offline Reinforcement Learning (RL) is the\ndistribution shift that arises from the learned policy deviating from the data\ncollection policy. This is often addressed by avoiding out-of-distribution\n(OOD) actions during policy improvement as their presence can lead to\nsubstantial performance degradation. This challenge is amplified in the offline\nMulti-Agent RL (MARL) setting since the joint action space grows exponentially\nwith the number of agents. To avoid this curse of dimensionality, existing MARL\nmethods adopt either value decomposition methods or fully decentralized\ntraining of individual agents. However, even when combined with standard\nconservatism principles, these methods can still result in the selection of OOD\njoint actions in offline MARL. To this end, we introduce AlberDICE, an offline\nMARL algorithm that alternatively performs centralized training of individual\nagents based on stationary distribution optimization. AlberDICE circumvents the\nexponential complexity of MARL by computing the best response of one agent at a\ntime while effectively avoiding OOD joint action selection. Theoretically, we\nshow that the alternating optimization procedure converges to Nash policies. In\nthe experiments, we demonstrate that AlberDICE significantly outperforms\nbaseline algorithms on a standard suite of MARL benchmarks.",
            "author": [
                "Daiki E. Matsunaga",
                "Jongmin Lee",
                "Jaeseok Yoon",
                "Stefanos Leonardos",
                "Pieter Abbeel",
                "Kee-Eung Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02194v1",
                "http://arxiv.org/pdf/2311.02194v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02193v1",
            "title": "An effective self-supervised learning method for various seismic noise\n  attenuation",
            "updated": "2023-11-03T18:51:50Z",
            "published": "2023-11-03T18:51:50Z",
            "summary": "Faced with the scarcity of clean label data in real scenarios, seismic\ndenoising methods based on supervised learning (SL) often encounter performance\nlimitations. Specifically, when a model trained on synthetic data is directly\napplied to field data, its performance would drastically decline due to\nsignificant differences in feature distributions between the two. To address\nthis challenge, we develop an effective self-supervised strategy. This\nstrategy, while relying on a single denoising network model, adeptly attenuates\nvarious types of seismic noise. The strategy comprises two main phases: 1. The\nwarm-up phase. By using prior knowledge or extracting information from real\ndata, we introduce additional noise to the original noisy data, constructing a\nnoisier data with intensified noise. This data serves as the input, with the\noriginal noisy data acting as pseudo-labels. This facilitates rapid\npre-training of the network to capture a certain noise characteristics and\nboosts network stability, setting the stage for the subsequent phase. 2.\nIterative data refinement (IDR) phase. During this phase, we use the\npredictions of the original noisy data from the network trained in the previous\nepoch as the pseudo-labels. We continue to add noise to the predictions,\ncreating a new noisier-noisy dataset for the current epoch of network training.\nThrough this iterative process, we progressively reduce the discrepancy between\nthe original noisy data and the desired clean data. Ultimately, the network's\npredictions on the original noisy data become our denoised results. Validations\nunder scenarios with random noise, backscattered noise, and blending noise\nreveal that our method not only matches the traditional SL techniques on\nsynthetic data but significantly outperforms them on field data.",
            "author": [
                "Shijun Cheng",
                "Zhiyao Cheng",
                "Chao Jiang",
                "Weijian Mao",
                "Qingchen Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02193v1",
                "http://arxiv.org/pdf/2311.02193v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02192v1",
            "title": "Automating Governing Knowledge Commons and Contextual Integrity (GKC-CI)\n  Privacy Policy Annotations with Large Language Models",
            "updated": "2023-11-03T18:49:05Z",
            "published": "2023-11-03T18:49:05Z",
            "summary": "Identifying contextual integrity (CI) and governing knowledge commons (GKC)\nparameters in privacy policy texts can facilitate normative privacy analysis.\nHowever, GKC-CI annotation has heretofore required manual or crowdsourced\neffort. This paper demonstrates that high-accuracy GKC-CI parameter annotation\nof privacy policies can be performed automatically using large language models.\nWe fine-tune 18 open-source and proprietary models on 21,588 GKC-CI annotations\nfrom 16 ground truth privacy policies. Our best-performing model (fine-tuned\nGPT-3.5 Turbo with prompt engineering) has an accuracy of 86%, exceeding the\nperformance of prior crowdsourcing approaches despite the complexity of privacy\npolicy texts and the nuance of the GKC-CI annotation task. We apply our\nbest-performing model to privacy policies from 164 popular online services,\ndemonstrating the effectiveness of scaling GKC-CI annotation for data\nexploration. We make all annotated policies as well as the training data and\nscripts needed to fine-tune our best-performing model publicly available for\nfuture research.",
            "author": [
                "Jake Chanenson",
                "Madison Pickering",
                "Noah Apthorpe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02192v1",
                "http://arxiv.org/pdf/2311.02192v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02191v1",
            "title": "SparsePoser: Real-time Full-body Motion Reconstruction from Sparse Data",
            "updated": "2023-11-03T18:48:01Z",
            "published": "2023-11-03T18:48:01Z",
            "summary": "Accurate and reliable human motion reconstruction is crucial for creating\nnatural interactions of full-body avatars in Virtual Reality (VR) and\nentertainment applications. As the Metaverse and social applications gain\npopularity, users are seeking cost-effective solutions to create full-body\nanimations that are comparable in quality to those produced by commercial\nmotion capture systems. In order to provide affordable solutions, though, it is\nimportant to minimize the number of sensors attached to the subject's body.\nUnfortunately, reconstructing the full-body pose from sparse data is a heavily\nunder-determined problem. Some studies that use IMU sensors face challenges in\nreconstructing the pose due to positional drift and ambiguity of the poses. In\nrecent years, some mainstream VR systems have released 6-degree-of-freedom\n(6-DoF) tracking devices providing positional and rotational information.\nNevertheless, most solutions for reconstructing full-body poses rely on\ntraditional inverse kinematics (IK) solutions, which often produce\nnon-continuous and unnatural poses. In this article, we introduce SparsePoser,\na novel deep learning-based solution for reconstructing a full-body pose from a\nreduced set of six tracking devices. Our system incorporates a\nconvolutional-based autoencoder that synthesizes high-quality continuous human\nposes by learning the human motion manifold from motion capture data. Then, we\nemploy a learned IK component, made of multiple lightweight feed-forward neural\nnetworks, to adjust the hands and feet toward the corresponding trackers. We\nextensively evaluate our method on publicly available motion capture datasets\nand with real-time live demos. We show that our method outperforms\nstate-of-the-art techniques using IMU sensors or 6-DoF tracking devices, and\ncan be used for users with different body dimensions and proportions.",
            "author": [
                "Jose Luis Ponton",
                "Haoran Yun",
                "Andreas Aristidou",
                "Carlos Andujar",
                "Nuria Pelechano"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3625264",
                "http://arxiv.org/abs/2311.02191v1",
                "http://arxiv.org/pdf/2311.02191v1"
            ],
            "primary_category": "cs.GR",
            "category": [
                "cs.GR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02189v1",
            "title": "FairSeg: A Large-scale Medical Image Segmentation Dataset for Fairness\n  Learning with Fair Error-Bound Scaling",
            "updated": "2023-11-03T18:44:21Z",
            "published": "2023-11-03T18:44:21Z",
            "summary": "Fairness in artificial intelligence models has gained significantly more\nattention in recent years, especially in the area of medicine, as fairness in\nmedical models is critical to people's well-being and lives. High-quality\nmedical fairness datasets are needed to promote fairness learning research.\nExisting medical fairness datasets are all for classification tasks, and no\nfairness datasets are available for medical segmentation, while medical\nsegmentation is an equally important clinical task as classifications, which\ncan provide detailed spatial information on organ abnormalities ready to be\nassessed by clinicians. In this paper, we propose the first fairness dataset\nfor medical segmentation named FairSeg with 10,000 subject samples. In\naddition, we propose a fair error-bound scaling approach to reweight the loss\nfunction with the upper error-bound in each identity group. We anticipate that\nthe segmentation performance equity can be improved by explicitly tackling the\nhard cases with high training errors in each identity group. To facilitate fair\ncomparisons, we propose new equity-scaled segmentation performance metrics,\nsuch as the equity-scaled Dice coefficient, which is calculated as the overall\nDice coefficient divided by one plus the standard deviation of group Dice\ncoefficients. Through comprehensive experiments, we demonstrate that our fair\nerror-bound scaling approach either has superior or comparable fairness\nperformance to the state-of-the-art fairness learning models. The dataset and\ncode are publicly accessible via\n\\url{https://github.com/Harvard-Ophthalmology-AI-Lab/FairSeg}.",
            "author": [
                "Yu Tian",
                "Min Shi",
                "Yan Luo",
                "Ava Kouhana",
                "Tobias Elze",
                "Mengyu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02189v1",
                "http://arxiv.org/pdf/2311.02189v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02181v1",
            "title": "Joint Problems in Learning Multiple Dynamical Systems",
            "updated": "2023-11-03T18:16:00Z",
            "published": "2023-11-03T18:16:00Z",
            "summary": "Clustering of time series is a well-studied problem, with applications\nranging from quantitative, personalized models of metabolism obtained from\nmetabolite concentrations to state discrimination in quantum information\ntheory. We consider a variant, where given a set of trajectories and a number\nof parts, we jointly partition the set of trajectories and learn linear\ndynamical system (LDS) models for each part, so as to minimize the maximum\nerror across all the models. We present globally convergent methods and EM\nheuristics, accompanied by promising computational results.",
            "author": [
                "Mengjia Niu",
                "Xiaoyu He",
                "Petr Rysavy",
                "Quan Zhou",
                "Jakub Marecek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02181v1",
                "http://arxiv.org/pdf/2311.02181v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03387v1",
            "title": "Determination of droplet size from wide-angle light scattering image\n  data using convolutional neural networks",
            "updated": "2023-11-03T18:05:47Z",
            "published": "2023-11-03T18:05:47Z",
            "summary": "Wide-angle light scattering (WALS) offers the possibility of a highly\ntemporally and spatially resolved measurement of droplets in spray-based\nmethods for nanoparticle synthesis. The size of these droplets is a critical\nvariable affecting the final properties of synthesized materials such as\nhetero-aggregates. However, conventional methods for determining droplet sizes\nfrom WALS image data are labor-intensive and may introduce biases, particularly\nwhen applied to complex systems like spray flame synthesis (SFS). To address\nthese challenges, we introduce a fully automatic machine learning-based\napproach that employs convolutional neural networks (CNNs) in order to\nstreamline the droplet sizing process. This CNN-based methodology offers\nfurther advantages: it requires few manual labels and can utilize transfer\nlearning, making it a promising alternative to conventional methods,\nspecifically with respect to efficiency. To evaluate the performance of our\nmachine learning models, we consider WALS data from an ethanol spray flame\nprocess at various heights above the burner surface (HABs), where the models\nare trained and cross-validated on a large dataset comprising nearly 35000 WALS\nimages.",
            "author": [
                "Tom Kirstein",
                "Simon A\u00dfmann",
                "Orkun Furat",
                "Stefan Will",
                "Volker Schmidt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03387v1",
                "http://arxiv.org/pdf/2311.03387v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02171v2",
            "title": "Emergence of Abstract State Representations in Embodied Sequence\n  Modeling",
            "updated": "2023-11-07T05:03:08Z",
            "published": "2023-11-03T18:00:59Z",
            "summary": "Decision making via sequence modeling aims to mimic the success of language\nmodels, where actions taken by an embodied agent are modeled as tokens to\npredict. Despite their promising performance, it remains unclear if embodied\nsequence modeling leads to the emergence of internal representations that\nrepresent the environmental state information. A model that lacks abstract\nstate representations would be liable to make decisions based on surface\nstatistics which fail to generalize. We take the BabyAI environment, a grid\nworld in which language-conditioned navigation tasks are performed, and build a\nsequence modeling Transformer, which takes a language instruction, a sequence\nof actions, and environmental observations as its inputs. In order to\ninvestigate the emergence of abstract state representations, we design a\n\"blindfolded\" navigation task, where only the initial environmental layout, the\nlanguage instruction, and the action sequence to complete the task are\navailable for training. Our probing results show that intermediate\nenvironmental layouts can be reasonably reconstructed from the internal\nactivations of a trained model, and that language instructions play a role in\nthe reconstruction accuracy. Our results suggest that many key features of\nstate representations can emerge via embodied sequence modeling, supporting an\noptimistic outlook for applications of sequence modeling objectives to more\ncomplex embodied decision-making domains.",
            "author": [
                "Tian Yun",
                "Zilai Zeng",
                "Kunal Handa",
                "Ashish V. Thapliyal",
                "Bo Pang",
                "Ellie Pavlick",
                "Chen Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02171v2",
                "http://arxiv.org/pdf/2311.02171v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02167v1",
            "title": "Ly$\u03b1$NNA: A Deep Learning Field-level Inference Machine for the\n  Lyman-$\u03b1$ Forest",
            "updated": "2023-11-03T18:00:03Z",
            "published": "2023-11-03T18:00:03Z",
            "summary": "The inference of astrophysical and cosmological properties from the\nLyman-$\\alpha$ forest conventionally relies on summary statistics of the\ntransmission field that carry useful but limited information. We present a deep\nlearning framework for inference from the Lyman-$\\alpha$ forest at field-level.\nThis framework consists of a 1D residual convolutional neural network (ResNet)\nthat extracts spectral features and performs regression on thermal parameters\nof the IGM that characterize the power-law temperature-density relation. We\ntrain this supervised machinery using a large set of mock absorption spectra\nfrom Nyx hydrodynamic simulations at $z=2.2$ with a range of thermal parameter\ncombinations (labels). We employ Bayesian optimization to find an optimal set\nof hyperparameters for our network, and then employ a committee of ten neural\nnetworks for increased statistical robustness of the network inference. In\naddition to the parameter point predictions, our machine also provides a\nself-consistent estimate of their covariance matrix with which we construct a\npipeline for inferring the posterior distribution of the parameters. We compare\nthe results of our framework with the traditional summary (PDF and power\nspectrum of transmission) based approach in terms of the area of the 68%\ncredibility regions as our figure of merit (FoM). In our study of the\ninformation content of perfect (noise- and systematics-free) Ly$\\alpha$ forest\nspectral data-sets, we find a significant tightening of the posterior\nconstraints -- factors of 5.65 and 1.71 in FoM over power spectrum only and\njointly with PDF, respectively -- that is the consequence of recovering the\nrelevant parts of information that are not carried by the classical summary\nstatistics.",
            "author": [
                "Parth Nayak",
                "Michael Walther",
                "Daniel Gruen",
                "Sreyas Adiraju"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02167v1",
                "http://arxiv.org/pdf/2311.02167v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02077v1",
            "title": "EmerNeRF: Emergent Spatial-Temporal Scene Decomposition via\n  Self-Supervision",
            "updated": "2023-11-03T17:59:55Z",
            "published": "2023-11-03T17:59:55Z",
            "summary": "We present EmerNeRF, a simple yet powerful approach for learning\nspatial-temporal representations of dynamic driving scenes. Grounded in neural\nfields, EmerNeRF simultaneously captures scene geometry, appearance, motion,\nand semantics via self-bootstrapping. EmerNeRF hinges upon two core components:\nFirst, it stratifies scenes into static and dynamic fields. This decomposition\nemerges purely from self-supervision, enabling our model to learn from general,\nin-the-wild data sources. Second, EmerNeRF parameterizes an induced flow field\nfrom the dynamic field and uses this flow field to further aggregate\nmulti-frame features, amplifying the rendering precision of dynamic objects.\nCoupling these three fields (static, dynamic, and flow) enables EmerNeRF to\nrepresent highly-dynamic scenes self-sufficiently, without relying on ground\ntruth object annotations or pre-trained models for dynamic object segmentation\nor optical flow estimation. Our method achieves state-of-the-art performance in\nsensor simulation, significantly outperforming previous methods when\nreconstructing static (+2.93 PSNR) and dynamic (+3.70 PSNR) scenes. In\naddition, to bolster EmerNeRF's semantic generalization, we lift 2D visual\nfoundation model features into 4D space-time and address a general positional\nbias in modern Transformers, significantly boosting 3D perception performance\n(e.g., 37.50% relative improvement in occupancy prediction accuracy on\naverage). Finally, we construct a diverse and challenging 120-sequence dataset\nto benchmark neural fields under extreme and highly-dynamic settings.",
            "author": [
                "Jiawei Yang",
                "Boris Ivanovic",
                "Or Litany",
                "Xinshuo Weng",
                "Seung Wook Kim",
                "Boyi Li",
                "Tong Che",
                "Danfei Xu",
                "Sanja Fidler",
                "Marco Pavone",
                "Yue Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02077v1",
                "http://arxiv.org/pdf/2311.02077v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02076v1",
            "title": "Universal Sharpness Dynamics in Neural Network Training: Fixed Point\n  Analysis, Edge of Stability, and Route to Chaos",
            "updated": "2023-11-03T17:59:40Z",
            "published": "2023-11-03T17:59:40Z",
            "summary": "In gradient descent dynamics of neural networks, the top eigenvalue of the\nHessian of the loss (sharpness) displays a variety of robust phenomena\nthroughout training. This includes early time regimes where the sharpness may\ndecrease during early periods of training (sharpness reduction), and later time\nbehavior such as progressive sharpening and edge of stability. We demonstrate\nthat a simple $2$-layer linear network (UV model) trained on a single training\nexample exhibits all of the essential sharpness phenomenology observed in\nreal-world scenarios. By analyzing the structure of dynamical fixed points in\nfunction space and the vector field of function updates, we uncover the\nunderlying mechanisms behind these sharpness trends. Our analysis reveals (i)\nthe mechanism behind early sharpness reduction and progressive sharpening, (ii)\nthe required conditions for edge of stability, and (iii) a period-doubling\nroute to chaos on the edge of stability manifold as learning rate is increased.\nFinally, we demonstrate that various predictions from this simplified model\ngeneralize to real-world scenarios and discuss its limitations.",
            "author": [
                "Dayal Singh Kalra",
                "Tianyu He",
                "Maissam Barkeshli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02076v1",
                "http://arxiv.org/pdf/2311.02076v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cond-mat.dis-nn",
                "nlin.CD",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02147v1",
            "title": "The Alignment Problem in Context",
            "updated": "2023-11-03T17:57:55Z",
            "published": "2023-11-03T17:57:55Z",
            "summary": "A core challenge in the development of increasingly capable AI systems is to\nmake them safe and reliable by ensuring their behaviour is consistent with\nhuman values. This challenge, known as the alignment problem, does not merely\napply to hypothetical future AI systems that may pose catastrophic risks; it\nalready applies to current systems, such as large language models, whose\npotential for harm is rapidly increasing. In this paper, I assess whether we\nare on track to solve the alignment problem for large language models, and what\nthat means for the safety of future AI systems. I argue that existing\nstrategies for alignment are insufficient, because large language models remain\nvulnerable to adversarial attacks that can reliably elicit unsafe behaviour. I\noffer an explanation of this lingering vulnerability on which it is not simply\na contingent limitation of current language models, but has deep technical ties\nto a crucial aspect of what makes these models useful and versatile in the\nfirst place -- namely, their remarkable aptitude to learn \"in context\" directly\nfrom user instructions. It follows that the alignment problem is not only\nunsolved for current AI systems, but may be intrinsically difficult to solve\nwithout severely undermining their capabilities. Furthermore, this assessment\nraises concerns about the prospect of ensuring the safety of future and more\ncapable AI systems.",
            "author": [
                "Rapha\u00ebl Milli\u00e8re"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02147v1",
                "http://arxiv.org/pdf/2311.02147v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02146v1",
            "title": "Bayesian Optimization of Function Networks with Partial Evaluations",
            "updated": "2023-11-03T17:55:08Z",
            "published": "2023-11-03T17:55:08Z",
            "summary": "Bayesian optimization is a framework for optimizing functions that are costly\nor time-consuming to evaluate. Recent work has considered Bayesian optimization\nof function networks (BOFN), where the objective function is computed via a\nnetwork of functions, each taking as input the output of previous nodes in the\nnetwork and additional parameters. Exploiting this network structure has been\nshown to yield significant performance improvements. Existing BOFN algorithms\nfor general-purpose networks are required to evaluate the full network at each\niteration. However, many real-world applications allow evaluating nodes\nindividually. To take advantage of this opportunity, we propose a novel\nknowledge gradient acquisition function for BOFN that chooses which node to\nevaluate as well as the inputs for that node in a cost-aware fashion. This\napproach can dramatically reduce query costs by allowing the evaluation of part\nof the network at a lower cost relative to evaluating the entire network. We\nprovide an efficient approach to optimizing our acquisition function and show\nit outperforms existing BOFN methods and other benchmarks across several\nsynthetic and real-world problems. Our acquisition function is the first to\nenable cost-aware optimization of a broad class of function networks.",
            "author": [
                "Poompol Buathong",
                "Jiayue Wan",
                "Samuel Daulton",
                "Raul Astudillo",
                "Maximilian Balandat",
                "Peter I. Frazier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02146v1",
                "http://arxiv.org/pdf/2311.02146v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02072v1",
            "title": "Learning Historical Status Prompt for Accurate and Robust Visual\n  Tracking",
            "updated": "2023-11-03T17:54:59Z",
            "published": "2023-11-03T17:54:59Z",
            "summary": "Most trackers perform template and search region similarity matching to find\nthe most similar object to the template during tracking. However, they struggle\nto make prediction when the target appearance changes due to the limited\nhistorical information introduced by roughly cropping the current search region\nbased on the predicted result of previous frame. In this paper, we identify\nthat the central impediment to improving the performance of existing trackers\nis the incapacity to integrate abundant and effective historical information.\nTo address this issue, we propose a Historical Information Prompter (HIP) to\nenhance the provision of historical information. We also build HIPTrack upon\nHIP module. HIP is a plug-and-play module that make full use of search region\nfeatures to introduce historical appearance information. It also incorporates\nhistorical position information by constructing refined mask of the target. HIP\nis a lightweight module to generate historical information prompts. By\nintegrating historical information prompts, HIPTrack significantly enhances the\ntracking performance without the need to retrain the backbone. Experimental\nresults demonstrate that our method outperforms all state-of-the-art approaches\non LaSOT, LaSOT ext, GOT10k and NfS. Futhermore, HIP module exhibits strong\ngenerality and can be seamlessly integrated into trackers to improve tracking\nperformance. The source code and models will be released for further research.",
            "author": [
                "Wenrui Cai",
                "Qingjie Liu",
                "Yunhong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02072v1",
                "http://arxiv.org/pdf/2311.02072v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02061v1",
            "title": "Active Learning-Based Species Range Estimation",
            "updated": "2023-11-03T17:45:18Z",
            "published": "2023-11-03T17:45:18Z",
            "summary": "We propose a new active learning approach for efficiently estimating the\ngeographic range of a species from a limited number of on the ground\nobservations. We model the range of an unmapped species of interest as the\nweighted combination of estimated ranges obtained from a set of different\nspecies. We show that it is possible to generate this candidate set of ranges\nby using models that have been trained on large weakly supervised community\ncollected observation data. From this, we develop a new active querying\napproach that sequentially selects geographic locations to visit that best\nreduce our uncertainty over an unmapped species' range. We conduct a detailed\nevaluation of our approach and compare it to existing active learning methods\nusing an evaluation dataset containing expert-derived ranges for one thousand\nspecies. Our results demonstrate that our method outperforms alternative active\nlearning methods and approaches the performance of end-to-end trained models,\neven when only using a fraction of the data. This highlights the utility of\nactive learning via transfer learned spatial representations for species range\nestimation. It also emphasizes the value of leveraging emerging large-scale\ncrowdsourced datasets, not only for modeling a species' range, but also for\nactively discovering them.",
            "author": [
                "Christian Lange",
                "Elijah Cole",
                "Grant Van Horn",
                "Oisin Mac Aodha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02061v1",
                "http://arxiv.org/pdf/2311.02061v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02058v2",
            "title": "LOTUS: Continual Imitation Learning for Robot Manipulation Through\n  Unsupervised Skill Discovery",
            "updated": "2023-11-17T08:26:16Z",
            "published": "2023-11-03T17:38:35Z",
            "summary": "We introduce LOTUS, a continual imitation learning algorithm that empowers a\nphysical robot to continuously and efficiently learn to solve new manipulation\ntasks throughout its lifespan. The core idea behind LOTUS is constructing an\never-growing skill library from a sequence of new tasks with a small number of\nhuman demonstrations. LOTUS starts with a continual skill discovery process\nusing an open-vocabulary vision model, which extracts skills as recurring\npatterns presented in unsegmented demonstrations. Continual skill discovery\nupdates existing skills to avoid catastrophic forgetting of previous tasks and\nadds new skills to solve novel tasks. LOTUS trains a meta-controller that\nflexibly composes various skills to tackle vision-based manipulation tasks in\nthe lifelong learning process. Our comprehensive experiments show that LOTUS\noutperforms state-of-the-art baselines by over 11% in success rate, showing its\nsuperior knowledge transfer ability compared to prior methods. More results and\nvideos can be found on the project website:\nhttps://ut-austin-rpl.github.io/Lotus/.",
            "author": [
                "Weikang Wan",
                "Yifeng Zhu",
                "Rutav Shah",
                "Yuke Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02058v2",
                "http://arxiv.org/pdf/2311.02058v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02057v2",
            "title": "Neural ODEs as a discovery tool to characterize the structure of the hot\n  galactic wind of M82",
            "updated": "2023-11-28T16:50:54Z",
            "published": "2023-11-03T17:34:50Z",
            "summary": "Dynamic astrophysical phenomena are predominantly described by differential\nequations, yet our understanding of these systems is constrained by our\nincomplete grasp of non-linear physics and scarcity of comprehensive datasets.\nAs such, advancing techniques in solving non-linear inverse problems becomes\npivotal to addressing numerous outstanding questions in the field. In\nparticular, modeling hot galactic winds is difficult because of unknown\nstructure for various physical terms, and the lack of \\textit{any} kinematic\nobservational data. Additionally, the flow equations contain singularities that\nlead to numerical instability, making parameter sweeps non-trivial. We leverage\ndifferentiable programming, which enables neural networks to be embedded as\nindividual terms within the governing coupled ordinary differential equations\n(ODEs), and show that this method can adeptly learn hidden physics. We robustly\ndiscern the structure of a mass-loading function which captures the physical\neffects of cloud destruction and entrainment into the hot superwind. Within a\nsupervised learning framework, we formulate our loss function anchored on the\nastrophysical entropy ($K \\propto P/\\rho^{5/3}$). Our results demonstrate the\nefficacy of this approach, even in the absence of kinematic data $v$. We then\napply these models to real Chandra X-Ray observations of starburst galaxy M82,\nproviding the first systematic description of mass-loading within the\nsuperwind. This work further highlights neural ODEs as a useful discovery tool\nwith mechanistic interpretability in non-linear inverse problems. We make our\ncode public at this GitHub repository\n(https://github.com/dustindnguyen/2023_NeurIPS_NeuralODEs_M82).",
            "author": [
                "Dustin D. Nguyen",
                "Yuan-Sen Ting",
                "Todd A. Thompson",
                "Sebastian Lopez",
                "Laura A. Lopez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02057v2",
                "http://arxiv.org/pdf/2311.02057v2"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03386v1",
            "title": "A Simple and Efficient Baseline for Data Attribution on Images",
            "updated": "2023-11-03T17:29:46Z",
            "published": "2023-11-03T17:29:46Z",
            "summary": "Data attribution methods play a crucial role in understanding machine\nlearning models, providing insight into which training data points are most\nresponsible for model outputs during deployment. However, current\nstate-of-the-art approaches require a large ensemble of as many as 300,000\nmodels to accurately attribute model predictions. These approaches therefore\ncome at a high computational cost, are memory intensive, and are hard to scale\nto large models or datasets. In this work, we focus on a minimalist baseline,\nutilizing the feature space of a backbone pretrained via self-supervised\nlearning to perform data attribution. Our method is model-agnostic and scales\neasily to large datasets. We show results on CIFAR-10 and ImageNet, achieving\nstrong performance that rivals or outperforms state-of-the-art approaches at a\nfraction of the compute or memory cost. Contrary to prior work, our results\nreinforce the intuition that a model's prediction on one image is most impacted\nby visually similar training samples. Our approach serves as a simple and\nefficient baseline for data attribution on images.",
            "author": [
                "Vasu Singla",
                "Pedro Sandoval-Segura",
                "Micah Goldblum",
                "Jonas Geiping",
                "Tom Goldstein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03386v1",
                "http://arxiv.org/pdf/2311.03386v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02043v1",
            "title": "Bayesian Quantile Regression with Subset Selection: A Posterior\n  Summarization Perspective",
            "updated": "2023-11-03T17:19:31Z",
            "published": "2023-11-03T17:19:31Z",
            "summary": "Quantile regression is a powerful tool for inferring how covariates affect\nspecific percentiles of the response distribution. Existing methods either\nestimate conditional quantiles separately for each quantile of interest or\nestimate the entire conditional distribution using semi- or non-parametric\nmodels. The former often produce inadequate models for real data and do not\nshare information across quantiles, while the latter are characterized by\ncomplex and constrained models that can be difficult to interpret and\ncomputationally inefficient. Further, neither approach is well-suited for\nquantile-specific subset selection. Instead, we pose the fundamental problems\nof linear quantile estimation, uncertainty quantification, and subset selection\nfrom a Bayesian decision analysis perspective. For any Bayesian regression\nmodel, we derive optimal and interpretable linear estimates and uncertainty\nquantification for each model-based conditional quantile. Our approach\nintroduces a quantile-focused squared error loss, which enables efficient,\nclosed-form computing and maintains a close relationship with Wasserstein-based\ndensity estimation. In an extensive simulation study, our methods demonstrate\nsubstantial gains in quantile estimation accuracy, variable selection, and\ninference over frequentist and Bayesian competitors. We apply these tools to\nidentify the quantile-specific impacts of social and environmental stressors on\neducational outcomes for a large cohort of children in North Carolina.",
            "author": [
                "Joseph Feldman",
                "Daniel Kowal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02043v1",
                "http://arxiv.org/pdf/2311.02043v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "math.ST",
                "stat.AP",
                "stat.CO",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02042v1",
            "title": "A Data-Driven Approach to Coarse-Graining Simple Liquids in Confinement",
            "updated": "2023-11-03T17:19:14Z",
            "published": "2023-11-03T17:19:14Z",
            "summary": "We propose a data-driven framework for identifying coarse-grained (CG)\nLennard-Jones (LJ) potential parameters in confined systems for simple liquids.\nOur approach involves the use of a Deep Neural Network (DNN) that is trained to\napproximate the solution of the Inverse Liquid State (ILST) problem for\nconfined systems. The DNN model inherently incorporates essential physical\ncharacteristics specific to confined fluids, enabling accurate prediction of\ninhomogeneity effects. By utilizing transfer learning, we predict single-site\nLJ potentials of simple multiatomic liquids confined in a slit-like channel,\nwhich effectively replicate both the fluid structure and molecular force of the\ntarget All-Atom (AA) system when the electrostatic interactions are not\ndominant. In addition, we showcase the synergy between the data-driven approach\nand the well-known Bottom-Up coarse-graining method utilizing Relative-Entropy\n(RE) Minimization. Through sequential utilization of these two methods, the\nrobustness of the iterative RE method is significantly augmented, leading to a\nremarkable enhancement in convergence.",
            "author": [
                "Ishan Nadkarni",
                "Haiyi Wu",
                "Narayana. R. Aluru"
            ],
            "link": [
                "http://dx.doi.org/10.1021/acs.jctc.3c00633",
                "http://arxiv.org/abs/2311.02042v1",
                "http://arxiv.org/pdf/2311.02042v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02041v1",
            "title": "Quantum circuit synthesis with diffusion models",
            "updated": "2023-11-03T17:17:08Z",
            "published": "2023-11-03T17:17:08Z",
            "summary": "Quantum computing has recently emerged as a transformative technology. Yet,\nits promised advantages rely on efficiently translating quantum operations into\nviable physical realizations. In this work, we use generative machine learning\nmodels, specifically denoising diffusion models (DMs), to facilitate this\ntransformation. Leveraging text-conditioning, we steer the model to produce\ndesired quantum operations within gate-based quantum circuits. Notably, DMs\nallow to sidestep during training the exponential overhead inherent in the\nclassical simulation of quantum dynamics -- a consistent bottleneck in\npreceding ML techniques. We demonstrate the model's capabilities across two\ntasks: entanglement generation and unitary compilation. The model excels at\ngenerating new circuits and supports typical DM extensions such as masking and\nediting to, for instance, align the circuit generation to the constraints of\nthe targeted quantum device. Given their flexibility and generalization\nabilities, we envision DMs as pivotal in quantum circuit synthesis, enhancing\nboth practical applications but also insights into theoretical quantum\ncomputation.",
            "author": [
                "Florian F\u00fcrrutter",
                "Gorka Mu\u00f1oz-Gil",
                "Hans J. Briegel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02041v1",
                "http://arxiv.org/pdf/2311.02041v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02038v1",
            "title": "Triggerless data acquisition pipeline for Machine Learning based\n  statistical anomaly detection",
            "updated": "2023-11-03T17:13:28Z",
            "published": "2023-11-03T17:13:28Z",
            "summary": "This work describes an online processing pipeline designed to identify\nanomalies in a continuous stream of data collected without external triggers\nfrom a particle detector. The processing pipeline begins with a local\nreconstruction algorithm, employing neural networks on an FPGA as its first\nstage. Subsequent data preparation and anomaly detection stages are accelerated\nusing GPGPUs. As a practical demonstration of anomaly detection, we have\ndeveloped a data quality monitoring application using a cosmic muon detector.\nIts primary objective is to detect deviations from the expected operational\nconditions of the detector. This serves as a proof-of-concept for a system that\ncan be adapted for use in large particle physics experiments, enabling anomaly\ndetection on datasets with reduced bias.",
            "author": [
                "Gaia Grosso",
                "Nicol\u00f2 Lai",
                "Matteo Migliorini",
                "Jacopo Pazzini",
                "Andrea Triossi",
                "Marco Zanetti",
                "Alberto Zucchetta"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02038v1",
                "http://arxiv.org/pdf/2311.02038v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02143v2",
            "title": "Pairing-based graph neural network for simulating quantum materials",
            "updated": "2023-11-21T15:54:28Z",
            "published": "2023-11-03T17:12:29Z",
            "summary": "We develop a pairing-based graph neural network for simulating quantum\nmany-body systems. Our architecture augments a BCS-type geminal wavefunction\nwith a generalized pair amplitude parameterized by a graph neural network.\nVariational Monte Carlo with our neural network simultaneously provides an\naccurate, flexible, and scalable method for simulating many-electron systems.\nWe apply this method to two-dimensional semiconductor electron-hole bilayers\nand obtain accurate results on a variety of interaction-induced phases,\nincluding the exciton Bose-Einstein condensate, electron-hole superconductor,\nand bilayer Wigner crystal. Our study demonstrates the potential of\nphysically-motivated neural network wavefunctions for quantum materials\nsimulations.",
            "author": [
                "Di Luo",
                "David D. Dai",
                "Liang Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02143v2",
                "http://arxiv.org/pdf/2311.02143v2"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el",
                "cond-mat.dis-nn",
                "cs.LG",
                "physics.comp-ph",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04927v1",
            "title": "Contextualizing the Limits of Model & Evaluation Dataset Curation on\n  Semantic Similarity Classification Tasks",
            "updated": "2023-11-03T17:12:07Z",
            "published": "2023-11-03T17:12:07Z",
            "summary": "This paper demonstrates how the limitations of pre-trained models and open\nevaluation datasets factor into assessing the performance of binary semantic\nsimilarity classification tasks. As (1) end-user-facing documentation around\nthe curation of these datasets and pre-trained model training regimes is often\nnot easily accessible and (2) given the lower friction and higher demand to\nquickly deploy such systems in real-world contexts, our study reinforces prior\nwork showing performance disparities across datasets, embedding techniques and\ndistance metrics, while highlighting the importance of understanding how data\nis collected, curated and analyzed in semantic similarity classification.",
            "author": [
                "Daniel Theron"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04927v1",
                "http://arxiv.org/pdf/2311.04927v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01623v1",
            "title": "VQPy: An Object-Oriented Approach to Modern Video Analytics",
            "updated": "2023-11-03T16:58:10Z",
            "published": "2023-11-03T16:58:10Z",
            "summary": "Video analytics is widely used in contemporary systems and services. At the\nforefront of video analytics are video queries that users develop to find\nobjects of particular interest. Building upon the insight that video objects\n(e.g., human, animals, cars, etc.), the center of video analytics, are similar\nin spirit to objects modeled by traditional object-oriented languages, we\npropose to develop an object-oriented approach to video analytics. This\napproach, named VQPy, consists of a frontend$\\unicode{x2015}$a Python variant\nwith constructs that make it easy for users to express video objects and their\ninteractions$\\unicode{x2015}$as well as an extensible backend that can\nautomatically construct and optimize pipelines based on video objects. We have\nimplemented and open-sourced VQPy, which has been productized in Cisco as part\nof its DeepVision framework.",
            "author": [
                "Shan Yu",
                "Zhenting Zhu",
                "Yu Chen",
                "Hanchen Xu",
                "Pengzhan Zhao",
                "Yang Wang",
                "Arthi Padmanabhan",
                "Hugo Latapie",
                "Harry Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01623v1",
                "http://arxiv.org/pdf/2311.01623v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16138v1",
            "title": "After-Stroke Arm Paresis Detection using Kinematic Data",
            "updated": "2023-11-03T16:56:02Z",
            "published": "2023-11-03T16:56:02Z",
            "summary": "This paper presents an approach for detecting unilateral arm\nparalysis/weakness using kinematic data. Our method employs temporal\nconvolution networks and recurrent neural networks, guided by knowledge\ndistillation, where we use inertial measurement units attached to the body to\ncapture kinematic information such as acceleration, rotation, and flexion of\nbody joints during an action. This information is then analyzed to recognize\nbody actions and patterns. Our proposed network achieves a high paretic\ndetection accuracy of 97.99\\%, with an action classification accuracy of\n77.69\\%, through knowledge sharing. Furthermore, by incorporating causal\nreasoning, we can gain additional insights into the patient's condition, such\nas their Fugl-Meyer assessment score or impairment level based on the machine\nlearning result. Overall, our approach demonstrates the potential of using\nkinematic data and machine learning for detecting arm paralysis/weakness. The\nresults suggest that our method could be a useful tool for clinicians and\nhealthcare professionals working with patients with this condition.",
            "author": [
                "Kenneth Lai",
                "Mohammed Almekhlafi",
                "Svetlana Yanushkevich"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16138v1",
                "http://arxiv.org/pdf/2311.16138v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14686v1",
            "title": "Causal Models Applied to the Patterns of Human Migration due to Climate\n  Change",
            "updated": "2023-11-03T16:54:16Z",
            "published": "2023-11-03T16:54:16Z",
            "summary": "The impacts of mass migration, such as crisis induced by climate change,\nextend beyond environmental concerns and can greatly affect social\ninfrastructure and public services, such as education, healthcare, and\nsecurity. These crises exacerbate certain elements like cultural barriers, and\ndiscrimination by amplifying the challenges faced by these affected\ncommunities. This paper proposes an innovative approach to address migration\ncrises in the context of crisis management through a combination of modeling\nand imbalance assessment tools. By employing deep learning for forecasting and\nintegrating causal reasoning via Bayesian networks, this methodology enables\nthe evaluation of imbalances and risks in the socio-technological landscape,\nproviding crucial insights for informed decision-making. Through this\nframework, critical systems can be analyzed to understand how fluctuations in\nmigration levels may impact them, facilitating effective crisis governance\nstrategies.",
            "author": [
                "Kenneth Lai",
                "Svetlana Yanushkevich"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14686v1",
                "http://arxiv.org/pdf/2311.14686v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03385v1",
            "title": "Intelligent Stress Assessment for e-Coaching",
            "updated": "2023-11-03T16:51:44Z",
            "published": "2023-11-03T16:51:44Z",
            "summary": "This paper considers the adaptation of the e-coaching concept at times of\nemergencies and disasters, through aiding the e-coaching with intelligent tools\nfor monitoring humans' affective state. The states such as anxiety, panic,\navoidance, and stress, if properly detected, can be mitigated using the\ne-coaching tactic and strategy. In this work, we focus on a stress monitoring\nassistant tool developed on machine learning techniques. We provide the results\nof an experimental study using the proposed method.",
            "author": [
                "Kenneth Lai",
                "Svetlana Yanushkevich",
                "Vlad Shmerko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03385v1",
                "http://arxiv.org/pdf/2311.03385v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02025v1",
            "title": "Vicinal Risk Minimization for Few-Shot Cross-lingual Transfer in Abusive\n  Language Detection",
            "updated": "2023-11-03T16:51:07Z",
            "published": "2023-11-03T16:51:07Z",
            "summary": "Cross-lingual transfer learning from high-resource to medium and low-resource\nlanguages has shown encouraging results. However, the scarcity of resources in\ntarget languages remains a challenge. In this work, we resort to data\naugmentation and continual pre-training for domain adaptation to improve\ncross-lingual abusive language detection. For data augmentation, we analyze two\nexisting techniques based on vicinal risk minimization and propose MIXAG, a\nnovel data augmentation method which interpolates pairs of instances based on\nthe angle of their representations. Our experiments involve seven languages\ntypologically distinct from English and three different domains. The results\nreveal that the data augmentation strategies can enhance few-shot cross-lingual\nabusive language detection. Specifically, we observe that consistently in all\ntarget languages, MIXAG improves significantly in multidomain and multilingual\nenvironments. Finally, we show through an error analysis how the domain\nadaptation can favour the class of abusive texts (reducing false negatives),\nbut at the same time, declines the precision of the abusive language detection\nmodel.",
            "author": [
                "Gretel Liz De la Pe\u00f1a Sarrac\u00e9n",
                "Paolo Rosso",
                "Robert Litschko",
                "Goran Glava\u0161",
                "Simone Paolo Ponzetto"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02025v1",
                "http://arxiv.org/pdf/2311.02025v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02142v1",
            "title": "Sparse Training of Discrete Diffusion Models for Graph Generation",
            "updated": "2023-11-03T16:50:26Z",
            "published": "2023-11-03T16:50:26Z",
            "summary": "Generative models for graphs often encounter scalability challenges due to\nthe inherent need to predict interactions for every node pair. Despite the\nsparsity often exhibited by real-world graphs, the unpredictable sparsity\npatterns of their adjacency matrices, stemming from their unordered nature,\nleads to quadratic computational complexity. In this work, we introduce\nSparseDiff, a denoising diffusion model for graph generation that is able to\nexploit sparsity during its training phase. At the core of SparseDiff is a\nmessage-passing neural network tailored to predict only a subset of edges\nduring each forward pass. When combined with a sparsity-preserving noise model,\nthis model can efficiently work with edge lists representations of graphs,\npaving the way for scalability to much larger structures. During the sampling\nphase, SparseDiff iteratively populates the adjacency matrix from its prior\nstate, ensuring prediction of the full graph while controlling memory\nutilization. Experimental results show that SparseDiff simultaneously matches\nstate-of-the-art in generation performance on both small and large graphs,\nhighlighting the versatility of our method.",
            "author": [
                "Yiming Qin",
                "Clement Vignac",
                "Pascal Frossard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02142v1",
                "http://arxiv.org/pdf/2311.02142v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02019v1",
            "title": "Reproducible Parameter Inference Using Bagged Posteriors",
            "updated": "2023-11-03T16:28:16Z",
            "published": "2023-11-03T16:28:16Z",
            "summary": "Under model misspecification, it is known that Bayesian posteriors often do\nnot properly quantify uncertainty about true or pseudo-true parameters. Even\nmore fundamentally, misspecification leads to a lack of reproducibility in the\nsense that the same model will yield contradictory posteriors on independent\ndata sets from the true distribution. To define a criterion for reproducible\nuncertainty quantification under misspecification, we consider the probability\nthat two confidence sets constructed from independent data sets have nonempty\noverlap, and we establish a lower bound on this overlap probability that holds\nfor any valid confidence sets. We prove that credible sets from the standard\nposterior can strongly violate this bound, particularly in high-dimensional\nsettings (i.e., with dimension increasing with sample size), indicating that it\nis not internally coherent under misspecification. To improve reproducibility\nin an easy-to-use and widely applicable way, we propose to apply bagging to the\nBayesian posterior (\"BayesBag\"'); that is, to use the average of posterior\ndistributions conditioned on bootstrapped datasets. We motivate BayesBag from\nfirst principles based on Jeffrey conditionalization and show that the bagged\nposterior typically satisfies the overlap lower bound. Further, we prove a\nBernstein--Von Mises theorem for the bagged posterior, establishing its\nasymptotic normal distribution. We demonstrate the benefits of BayesBag via\nsimulation experiments and an application to crime rate prediction.",
            "author": [
                "Jonathan H. Huggins",
                "Jeffrey W. Miller"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02019v1",
                "http://arxiv.org/pdf/2311.02019v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02018v1",
            "title": "Active Reasoning in an Open-World Environment",
            "updated": "2023-11-03T16:24:34Z",
            "published": "2023-11-03T16:24:34Z",
            "summary": "Recent advances in vision-language learning have achieved notable success on\ncomplete-information question-answering datasets through the integration of\nextensive world knowledge. Yet, most models operate passively, responding to\nquestions based on pre-stored knowledge. In stark contrast, humans possess the\nability to actively explore, accumulate, and reason using both newfound and\nexisting information to tackle incomplete-information questions. In response to\nthis gap, we introduce $Conan$, an interactive open-world environment devised\nfor the assessment of active reasoning. $Conan$ facilitates active exploration\nand promotes multi-round abductive inference, reminiscent of rich, open-world\nsettings like Minecraft. Diverging from previous works that lean primarily on\nsingle-round deduction via instruction following, $Conan$ compels agents to\nactively interact with their surroundings, amalgamating new evidence with prior\nknowledge to elucidate events from incomplete observations. Our analysis on\n$Conan$ underscores the shortcomings of contemporary state-of-the-art models in\nactive exploration and understanding complex scenarios. Additionally, we\nexplore Abduction from Deduction, where agents harness Bayesian rules to recast\nthe challenge of abduction as a deductive process. Through $Conan$, we aim to\ngalvanize advancements in active reasoning and set the stage for the next\ngeneration of artificial intelligence agents adept at dynamically engaging in\nenvironments.",
            "author": [
                "Manjie Xu",
                "Guangyuan Jiang",
                "Wei Liang",
                "Chi Zhang",
                "Yixin Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02018v1",
                "http://arxiv.org/pdf/2311.02018v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02017v1",
            "title": "DeliverAI: Reinforcement Learning Based Distributed Path-Sharing Network\n  for Food Deliveries",
            "updated": "2023-11-03T16:23:22Z",
            "published": "2023-11-03T16:23:22Z",
            "summary": "Delivery of items from the producer to the consumer has experienced\nsignificant growth over the past decade and has been greatly fueled by the\nrecent pandemic. Amazon Fresh, Shopify, UberEats, InstaCart, and DoorDash are\nrapidly growing and are sharing the same business model of consumer items or\nfood delivery. Existing food delivery methods are sub-optimal because each\ndelivery is individually optimized to go directly from the producer to the\nconsumer via the shortest time path. We observe a significant scope for\nreducing the costs associated with completing deliveries under the current\nmodel. We model our food delivery problem as a multi-objective optimization,\nwhere consumer satisfaction and delivery costs, both, need to be optimized.\nTaking inspiration from the success of ride-sharing in the taxi industry, we\npropose DeliverAI - a reinforcement learning-based path-sharing algorithm.\nUnlike previous attempts for path-sharing, DeliverAI can provide real-time,\ntime-efficient decision-making using a Reinforcement learning-enabled agent\nsystem. Our novel agent interaction scheme leverages path-sharing among\ndeliveries to reduce the total distance traveled while keeping the delivery\ncompletion time under check. We generate and test our methodology vigorously on\na simulation setup using real data from the city of Chicago. Our results show\nthat DeliverAI can reduce the delivery fleet size by 12\\%, the distance\ntraveled by 13%, and achieve 50% higher fleet utilization compared to the\nbaselines.",
            "author": [
                "Ashman Mehra",
                "Snehanshu Saha",
                "Vaskar Raychoudhury",
                "Archana Mathur"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02017v1",
                "http://arxiv.org/pdf/2311.02017v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02013v1",
            "title": "Score Models for Offline Goal-Conditioned Reinforcement Learning",
            "updated": "2023-11-03T16:19:33Z",
            "published": "2023-11-03T16:19:33Z",
            "summary": "Offline Goal-Conditioned Reinforcement Learning (GCRL) is tasked with\nlearning to achieve multiple goals in an environment purely from offline\ndatasets using sparse reward functions. Offline GCRL is pivotal for developing\ngeneralist agents capable of leveraging pre-existing datasets to learn diverse\nand reusable skills without hand-engineering reward functions. However,\ncontemporary approaches to GCRL based on supervised learning and contrastive\nlearning are often suboptimal in the offline setting. An alternative\nperspective on GCRL optimizes for occupancy matching, but necessitates learning\na discriminator, which subsequently serves as a pseudo-reward for downstream\nRL. Inaccuracies in the learned discriminator can cascade, negatively\ninfluencing the resulting policy. We present a novel approach to GCRL under a\nnew lens of mixture-distribution matching, leading to our discriminator-free\nmethod: SMORe. The key insight is combining the occupancy matching perspective\nof GCRL with a convex dual formulation to derive a learning objective that can\nbetter leverage suboptimal offline data. SMORe learns scores or unnormalized\ndensities representing the importance of taking an action at a state for\nreaching a particular goal. SMORe is principled and our extensive experiments\non the fully offline GCRL benchmark composed of robot manipulation and\nlocomotion tasks, including high-dimensional observations, show that SMORe can\noutperform state-of-the-art baselines by a significant margin.",
            "author": [
                "Harshit Sikchi",
                "Rohan Chitnis",
                "Ahmed Touati",
                "Alborz Geramifard",
                "Amy Zhang",
                "Scott Niekum"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02013v1",
                "http://arxiv.org/pdf/2311.02013v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02009v1",
            "title": "Trust-Preserved Human-Robot Shared Autonomy enabled by Bayesian\n  Relational Event Modeling",
            "updated": "2023-11-03T16:13:33Z",
            "published": "2023-11-03T16:13:33Z",
            "summary": "Shared autonomy functions as a flexible framework that empowers robots to\noperate across a spectrum of autonomy levels, allowing for efficient task\nexecution with minimal human oversight. However, humans might be intimidated by\nthe autonomous decision-making capabilities of robots due to perceived risks\nand a lack of trust. This paper proposed a trust-preserved shared autonomy\nstrategy that grants robots to seamlessly adjust their autonomy level, striving\nto optimize team performance and enhance their acceptance among human\ncollaborators. By enhancing the Relational Event Modeling framework with\nBayesian learning techniques, this paper enables dynamic inference of human\ntrust based solely on time-stamped relational events within human-robot teams.\nAdopting a longitudinal perspective on trust development and calibration in\nhuman-robot teams, the proposed shared autonomy strategy warrants robots to\npreserve human trust by not only passively adapting to it but also actively\nparticipating in trust repair when violations occur. We validate the\neffectiveness of the proposed approach through a user study on human-robot\ncollaborative search and rescue scenarios. The objective and subjective\nevaluations demonstrate its merits over teleoperation on both task execution\nand user acceptability.",
            "author": [
                "Yingke Li",
                "Fumin Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02009v1",
                "http://arxiv.org/pdf/2311.02009v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02004v1",
            "title": "Investigation of Random Laser in the Machine Learning Approach",
            "updated": "2023-11-03T16:07:24Z",
            "published": "2023-11-03T16:07:24Z",
            "summary": "Machine Learning and Deep Learning are computational tools that fall within\nthe domain of artificial intelligence. In recent years, numerous research works\nhave advanced the application of machine and deep learning in various fields,\nincluding optics and photonics. In this article, we employ machine learning\nalgorithms to investigate the feasibility of predicting a stochastic phenomena:\nrandom laser emissions. Our results indicate that machine and deep learning\nhave the capacity to accurately reproduce fluctuations characteristic of random\nlasers. By employing simple supervised learning algorithms, we demonstrate that\nthe random laser intensity fluctuations can be predicted using spontaneous\nemission and pump intensity as input parameters in the models. Applications\nbased on the demonstrated results are discussed.\n  Keywords: Machine Learning, Deep Learning, Random Laser.",
            "author": [
                "Emanuel P. Santos",
                "Rodrigo F. Silva",
                "C\u00e9lio V. T. Maciel",
                "Daniel F. Luz",
                "Pedro F. A. Silva"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02004v1",
                "http://arxiv.org/pdf/2311.02004v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02003v1",
            "title": "A Structured Pruning Algorithm for Model-based Deep Learning",
            "updated": "2023-11-03T16:05:51Z",
            "published": "2023-11-03T16:05:51Z",
            "summary": "There is a growing interest in model-based deep learning (MBDL) for solving\nimaging inverse problems. MBDL networks can be seen as iterative algorithms\nthat estimate the desired image using a physical measurement model and a\nlearned image prior specified using a convolutional neural net (CNNs). The\niterative nature of MBDL networks increases the test-time computational\ncomplexity, which limits their applicability in certain large-scale\napplications. We address this issue by presenting structured pruning algorithm\nfor model-based deep learning (SPADE) as the first structured pruning algorithm\nfor MBDL networks. SPADE reduces the computational complexity of CNNs used\nwithin MBDL networks by pruning its non-essential weights. We propose three\ndistinct strategies to fine-tune the pruned MBDL networks to minimize the\nperformance loss. Each fine-tuning strategy has a unique benefit that depends\non the presence of a pre-trained model and a high-quality ground truth. We\nvalidate SPADE on two distinct inverse problems, namely compressed sensing MRI\nand image super-resolution. Our results highlight that MBDL models pruned by\nSPADE can achieve substantial speed up in testing time while maintaining\ncompetitive performance.",
            "author": [
                "Chicago Park",
                "Weijie Gan",
                "Zihao Zou",
                "Yuyang Hu",
                "Zhixin Sun",
                "Ulugbek S. Kamilov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02003v1",
                "http://arxiv.org/pdf/2311.02003v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06292v1",
            "title": "Towards a data-driven debt collection strategy based on an advanced\n  machine learning framework",
            "updated": "2023-11-03T16:01:30Z",
            "published": "2023-11-03T16:01:30Z",
            "summary": "The European debt purchase market as measured by the total book value of\npurchased debt approached 25bn euros in 2020 and it was growing at double-digit\nrates. This is an example of how big the debt collection and debt purchase\nindustry has grown and the important impact it has in the financial sector.\nHowever, in order to ensure an adequate return during the debt collection\nprocess, a good estimation of the propensity to pay and/or the expected\ncashflow is crucial. These estimations can be employed, for instance, to create\ndifferent strategies during the amicable collection to maximize quality\nstandards and revenues. And not only that, but also to prioritize the cases in\nwhich a legal process is necessary when debtors are unreachable for an amicable\nnegotiation. This work offers a solution for these estimations. Specifically, a\nnew machine learning modelling pipeline is presented showing how outperforms\ncurrent strategies employed in the sector. The solution contains a\npre-processing pipeline and a model selector based on the best model\ncalibration. Performance is validated with real historical data of the debt\nindustry.",
            "author": [
                "Abel Sancarlos",
                "Edgar Bahilo",
                "Pablo Mozo",
                "Lukas Norman",
                "Obaid Ur Rehma",
                "Mihails Anufrijevs"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06292v1",
                "http://arxiv.org/pdf/2311.06292v1"
            ],
            "primary_category": "q-fin.ST",
            "category": [
                "q-fin.ST",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02002v1",
            "title": "A Variational Perspective on High-Resolution ODEs",
            "updated": "2023-11-03T16:00:40Z",
            "published": "2023-11-03T16:00:40Z",
            "summary": "We consider unconstrained minimization of smooth convex functions. We propose\na novel variational perspective using forced Euler-Lagrange equation that\nallows for studying high-resolution ODEs. Through this, we obtain a faster\nconvergence rate for gradient norm minimization using Nesterov's accelerated\ngradient method. Additionally, we show that Nesterov's method can be\ninterpreted as a rate-matching discretization of an appropriately chosen\nhigh-resolution ODE. Finally, using the results from the new variational\nperspective, we propose a stochastic method for noisy gradients. Several\nnumerical experiments compare and illustrate our stochastic algorithm with\nstate of the art methods.",
            "author": [
                "Hoomaan Maskan",
                "Konstantinos C. Zygalakis",
                "Alp Yurtsever"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02002v1",
                "http://arxiv.org/pdf/2311.02002v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02000v1",
            "title": "High Probability Convergence of Adam Under Unbounded Gradients and\n  Affine Variance Noise",
            "updated": "2023-11-03T15:55:53Z",
            "published": "2023-11-03T15:55:53Z",
            "summary": "In this paper, we study the convergence of the Adaptive Moment Estimation\n(Adam) algorithm under unconstrained non-convex smooth stochastic\noptimizations. Despite the widespread usage in machine learning areas, its\ntheoretical properties remain limited. Prior researches primarily investigated\nAdam's convergence from an expectation view, often necessitating strong\nassumptions like uniformly stochastic bounded gradients or problem-dependent\nknowledge in prior. As a result, the applicability of these findings in\npractical real-world scenarios has been constrained. To overcome these\nlimitations, we provide a deep analysis and show that Adam could converge to\nthe stationary point in high probability with a rate of $\\mathcal{O}\\left({\\rm\npoly}(\\log T)/\\sqrt{T}\\right)$ under coordinate-wise \"affine\" variance noise,\nnot requiring any bounded gradient assumption and any problem-dependent\nknowledge in prior to tune hyper-parameters. Additionally, it is revealed that\nAdam confines its gradients' magnitudes within an order of\n$\\mathcal{O}\\left({\\rm poly}(\\log T)\\right)$. Finally, we also investigate a\nsimplified version of Adam without one of the corrective terms and obtain a\nconvergence rate that is adaptive to the noise level.",
            "author": [
                "Yusu Hong",
                "Junhong Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02000v1",
                "http://arxiv.org/pdf/2311.02000v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01996v1",
            "title": "Detection of keratoconus Diseases using deep Learning",
            "updated": "2023-11-03T15:49:06Z",
            "published": "2023-11-03T15:49:06Z",
            "summary": "One of the most serious corneal disorders, keratoconus is difficult to\ndiagnose in its early stages and can result in blindness. This illness, which\noften appears in the second decade of life, affects people of all sexes and\nraces. Convolutional neural networks (CNNs), one of the deep learning\napproaches, have recently come to light as particularly promising tools for the\naccurate and timely diagnosis of keratoconus. The purpose of this study was to\nevaluate how well different D-CNN models identified keratoconus-related\ndiseases. To be more precise, we compared five different CNN-based deep\nlearning architectures (DenseNet201, InceptionV3, MobileNetV2, VGG19,\nXception). In our comprehensive experimental analysis, the DenseNet201-based\nmodel performed very well in keratoconus disease identification in our\nextensive experimental research. This model outperformed its D-CNN equivalents,\nwith an astounding accuracy rate of 89.14% in three crucial classes:\nKeratoconus, Normal, and Suspect. The results demonstrate not only the\nstability and robustness of the model but also its practical usefulness in\nreal-world applications for accurate and dependable keratoconus identification.\nIn addition, D-CNN DenseNet201 performs extraordinarily well in terms of\nprecision, recall rates, and F1 scores in addition to accuracy. These measures\nvalidate the model's usefulness as an effective diagnostic tool by highlighting\nits capacity to reliably detect instances of keratoconus and to reduce false\npositives and negatives.",
            "author": [
                "AKM Enzam-Ul Haque",
                "Golam Rabbany",
                "Md. Siam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01996v1",
                "http://arxiv.org/pdf/2311.01996v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01994v1",
            "title": "Obtaining Explainable Classification Models using Distributionally\n  Robust Optimization",
            "updated": "2023-11-03T15:45:34Z",
            "published": "2023-11-03T15:45:34Z",
            "summary": "Model explainability is crucial for human users to be able to interpret how a\nproposed classifier assigns labels to data based on its feature values. We\nstudy generalized linear models constructed using sets of feature value rules,\nwhich can capture nonlinear dependencies and interactions. An inherent\ntrade-off exists between rule set sparsity and its prediction accuracy. It is\ncomputationally expensive to find the right choice of sparsity -- e.g., via\ncross-validation -- with existing methods. We propose a new formulation to\nlearn an ensemble of rule sets that simultaneously addresses these competing\nfactors. Good generalization is ensured while keeping computational costs low\nby utilizing distributionally robust optimization. The formulation utilizes\ncolumn generation to efficiently search the space of rule sets and constructs a\nsparse ensemble of rule sets, in contrast with techniques like random forests\nor boosting and their variants. We present theoretical results that motivate\nand justify the use of our distributionally robust formulation. Extensive\nnumerical experiments establish that our method improves over competing methods\n-- on a large set of publicly available binary classification problem instances\n-- with respect to one or more of the following metrics: generalization\nquality, computational cost, and explainability.",
            "author": [
                "Sanjeeb Dash",
                "Soumyadip Ghosh",
                "Joao Goncalves",
                "Mark S. Squillante"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01994v1",
                "http://arxiv.org/pdf/2311.01994v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01990v1",
            "title": "Conditions on Preference Relations that Guarantee the Existence of\n  Optimal Policies",
            "updated": "2023-11-03T15:42:12Z",
            "published": "2023-11-03T15:42:12Z",
            "summary": "Learning from Preferential Feedback (LfPF) plays an essential role in\ntraining Large Language Models, as well as certain types of interactive\nlearning agents. However, a substantial gap exists between the theory and\napplication of LfPF algorithms. Current results guaranteeing the existence of\noptimal policies in LfPF problems assume that both the preferences and\ntransition dynamics are determined by a Markov Decision Process. We introduce\nthe Direct Preference Process, a new framework for analyzing LfPF problems in\npartially-observable, non-Markovian environments. Within this framework, we\nestablish conditions that guarantee the existence of optimal policies by\nconsidering the ordinal structure of the preferences. Using the von\nNeumann-Morgenstern Expected Utility Theorem, we show that the Direct\nPreference Process generalizes the standard reinforcement learning problem. Our\nfindings narrow the gap between the empirical success and theoretical\nunderstanding of LfPF algorithms and provide future practitioners with the\ntools necessary for a more principled design of LfPF agents.",
            "author": [
                "Jonathan Colaco Carr",
                "Prakash Panangaden",
                "Doina Precup"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01990v1",
                "http://arxiv.org/pdf/2311.01990v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01989v2",
            "title": "Leveraging Large-Scale Pretrained Vision Foundation Models for\n  Label-Efficient 3D Point Cloud Segmentation",
            "updated": "2023-11-06T08:18:26Z",
            "published": "2023-11-03T15:41:15Z",
            "summary": "Recently, large-scale pre-trained models such as Segment-Anything Model (SAM)\nand Contrastive Language-Image Pre-training (CLIP) have demonstrated remarkable\nsuccess and revolutionized the field of computer vision. These foundation\nvision models effectively capture knowledge from a large-scale broad data with\ntheir vast model parameters, enabling them to perform zero-shot segmentation on\npreviously unseen data without additional training. While they showcase\ncompetence in 2D tasks, their potential for enhancing 3D scene understanding\nremains relatively unexplored. To this end, we present a novel framework that\nadapts various foundational models for the 3D point cloud segmentation task.\nOur approach involves making initial predictions of 2D semantic masks using\ndifferent large vision models. We then project these mask predictions from\nvarious frames of RGB-D video sequences into 3D space. To generate robust 3D\nsemantic pseudo labels, we introduce a semantic label fusion strategy that\neffectively combines all the results via voting. We examine diverse scenarios,\nlike zero-shot learning and limited guidance from sparse 2D point labels, to\nassess the pros and cons of different vision foundation models. Our approach is\nexperimented on ScanNet dataset for 3D indoor scenes, and the results\ndemonstrate the effectiveness of adopting general 2D foundation models on\nsolving 3D point cloud segmentation tasks.",
            "author": [
                "Shichao Dong",
                "Fayao Liu",
                "Guosheng Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01989v2",
                "http://arxiv.org/pdf/2311.01989v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01987v1",
            "title": "Generalization of Graph-Based Active Learning Relaxation Strategies\n  Across Materials",
            "updated": "2023-11-03T15:40:20Z",
            "published": "2023-11-03T15:40:20Z",
            "summary": "Although density functional theory (DFT) has aided in accelerating the\ndiscovery of new materials, such calculations are computationally expensive,\nespecially for high-throughput efforts. This has prompted an explosion in\nexploration of machine learning assisted techniques to improve the\ncomputational efficiency of DFT. In this study, we present a comprehensive\ninvestigation of the broader application of Finetuna, an active learning\nframework to accelerate structural relaxation in DFT with prior information\nfrom Open Catalyst Project pretrained graph neural networks. We explore the\nchallenges associated with out-of-domain systems: alcohol ($C_{>2}$) on metal\nsurfaces as larger adsorbates, metal-oxides with spin polarization, and\nthree-dimensional (3D) structures like zeolites and metal-organic-frameworks.\nBy pre-training machine learning models on large datasets and fine-tuning the\nmodel along the simulation, we demonstrate the framework's ability to conduct\nrelaxations with fewer DFT calculations. Depending on the similarity of the\ntest systems to the training systems, a more conservative querying strategy is\napplied. Our best-performing Finetuna strategy reduces the number of DFT\nsingle-point calculations by 80% for alcohols and 3D structures, and 42% for\noxide systems.",
            "author": [
                "Xiaoxiao Wang",
                "Joseph Musielewicz",
                "Richard Tran",
                "Sudheesh Kumar Ethirajan",
                "Xiaoyan Fu",
                "Hilda Mera",
                "John R. Kitchin",
                "Rachel C. Kurchin",
                "Zachary W. Ulissi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01987v1",
                "http://arxiv.org/pdf/2311.01987v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01985v1",
            "title": "Maximizing Portfolio Predictability with Machine Learning",
            "updated": "2023-11-03T15:38:10Z",
            "published": "2023-11-03T15:38:10Z",
            "summary": "We construct the maximally predictable portfolio (MPP) of stocks using\nmachine learning. Solving for the optimal constrained weights in the\nmulti-asset MPP gives portfolios with a high monthly coefficient of\ndetermination, given the sample covariance matrix of predicted return errors\nfrom a machine learning model. Various models for the covariance matrix are\ntested. The MPPs of S&P 500 index constituents with estimated returns from\nElastic Net, Random Forest, and Support Vector Regression models can outperform\nor underperform the index depending on the time period. Portfolios that take\nadvantage of the high predictability of the MPP's returns and employ a Kelly\ncriterion style strategy consistently outperform the benchmark.",
            "author": [
                "Michael Pinelis",
                "David Ruppert"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01985v1",
                "http://arxiv.org/pdf/2311.01985v1"
            ],
            "primary_category": "q-fin.CP",
            "category": [
                "q-fin.CP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01984v1",
            "title": "Optimal Image Transport on Sparse Dictionaries",
            "updated": "2023-11-03T15:37:01Z",
            "published": "2023-11-03T15:37:01Z",
            "summary": "In this paper, we derive a novel optimal image transport algorithm over\nsparse dictionaries by taking advantage of Sparse Representation (SR) and\nOptimal Transport (OT). Concisely, we design a unified optimization framework\nin which the individual image features (color, textures, styles, etc.) are\nencoded using sparse representation compactly, and an optimal transport plan is\nthen inferred between two learned dictionaries in accordance with the encoding\nprocess. This paradigm gives rise to a simple but effective way for\nsimultaneous image representation and transformation, which is also empirically\nsolvable because of the moderate size of sparse coding and optimal transport\nsub-problems. We demonstrate its versatility and many benefits to different\nimage-to-image translation tasks, in particular image color transform and\nartistic style transfer, and show the plausible results for photo-realistic\ntransferred effects.",
            "author": [
                "Junqing Huang",
                "Haihui Wang",
                "Andreas Weiermann",
                "Michael Ruzhansky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01984v1",
                "http://arxiv.org/pdf/2311.01984v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01977v2",
            "title": "RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory\n  Sketches",
            "updated": "2023-11-06T05:53:08Z",
            "published": "2023-11-03T15:31:51Z",
            "summary": "Generalization remains one of the most important desiderata for robust robot\nlearning systems. While recently proposed approaches show promise in\ngeneralization to novel objects, semantic concepts, or visual distribution\nshifts, generalization to new tasks remains challenging. For example, a\nlanguage-conditioned policy trained on pick-and-place tasks will not be able to\ngeneralize to a folding task, even if the arm trajectory of folding is similar\nto pick-and-place. Our key insight is that this kind of generalization becomes\nfeasible if we represent the task through rough trajectory sketches. We propose\na policy conditioning method using such rough trajectory sketches, which we\ncall RT-Trajectory, that is practical, easy to specify, and allows the policy\nto effectively perform new tasks that would otherwise be challenging to\nperform. We find that trajectory sketches strike a balance between being\ndetailed enough to express low-level motion-centric guidance while being coarse\nenough to allow the learned policy to interpret the trajectory sketch in the\ncontext of situational visual observations. In addition, we show how trajectory\nsketches can provide a useful interface to communicate with robotic policies:\nthey can be specified through simple human inputs like drawings or videos, or\nthrough automated methods such as modern image-generating or\nwaypoint-generating methods. We evaluate RT-Trajectory at scale on a variety of\nreal-world robotic tasks, and find that RT-Trajectory is able to perform a\nwider range of tasks compared to language-conditioned and goal-conditioned\npolicies, when provided the same training data.",
            "author": [
                "Jiayuan Gu",
                "Sean Kirmani",
                "Paul Wohlhart",
                "Yao Lu",
                "Montserrat Gonzalez Arenas",
                "Kanishka Rao",
                "Wenhao Yu",
                "Chuyuan Fu",
                "Keerthana Gopalakrishnan",
                "Zhuo Xu",
                "Priya Sundaresan",
                "Peng Xu",
                "Hao Su",
                "Karol Hausman",
                "Chelsea Finn",
                "Quan Vuong",
                "Ted Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01977v2",
                "http://arxiv.org/pdf/2311.01977v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01973v1",
            "title": "Emergence of odd elasticity in a microswimmer using deep reinforcement\n  learning",
            "updated": "2023-11-03T15:22:26Z",
            "published": "2023-11-03T15:22:26Z",
            "summary": "We investigate the emergence of odd elasticity in an elastic microswimmer\nmodel by using Deep Q-Network with a reinforcement learning method. Although\nthe swimming velocity decreases for an elastic microswimmer with prescribed\ndynamics in the large-frequency regime, the fully trained elastic microswimmer\nadapts a waiting strategy to avoid the velocity decrease. For the trained\nmicroswimmers, we evaluate the performance of the cycles by the product of the\nloop area (called non-reciprocality) and the loop frequency, and show that the\naverage swimming velocity is proportional to the performance. By calculating\nthe force-displacement correlations, we obtain the effective odd elasticity of\nthe microswimmer to characterize its non-reciprocal dynamics. The emergent odd\nelasticity is closely related to the loop frequency of the cyclic deformation.\nThe present work provides us with a clue to reveal the emergence of various\nnon-reciprocal phenomena in active systems by using machine learning.",
            "author": [
                "Li-Shing Lin",
                "Kento Yasuda",
                "Kenta Ishimoto",
                "Shigeyuki Komura"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01973v1",
                "http://arxiv.org/pdf/2311.01973v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01968v1",
            "title": "Latent Diffusion Model for Conditional Reservoir Facies Generation",
            "updated": "2023-11-03T15:10:05Z",
            "published": "2023-11-03T15:10:05Z",
            "summary": "Creating accurate and geologically realistic reservoir facies based on\nlimited measurements is crucial for field development and reservoir management,\nespecially in the oil and gas sector. Traditional two-point geostatistics,\nwhile foundational, often struggle to capture complex geological patterns.\nMulti-point statistics offers more flexibility, but comes with its own\nchallenges. With the rise of Generative Adversarial Networks (GANs) and their\nsuccess in various fields, there has been a shift towards using them for facies\ngeneration. However, recent advances in the computer vision domain have shown\nthe superiority of diffusion models over GANs. Motivated by this, a novel\nLatent Diffusion Model is proposed, which is specifically designed for\nconditional generation of reservoir facies. The proposed model produces\nhigh-fidelity facies realizations that rigorously preserve conditioning data.\nIt significantly outperforms a GAN-based alternative.",
            "author": [
                "Daesoo Lee",
                "Oscar Ovanger",
                "Jo Eidsvik",
                "Erlend Aune",
                "Jacob Skauvold",
                "Ragnar Hauge"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01968v1",
                "http://arxiv.org/pdf/2311.01968v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01967v1",
            "title": "The language of prompting: What linguistic properties make a prompt\n  successful?",
            "updated": "2023-11-03T15:03:36Z",
            "published": "2023-11-03T15:03:36Z",
            "summary": "The latest generation of LLMs can be prompted to achieve impressive zero-shot\nor few-shot performance in many NLP tasks. However, since performance is highly\nsensitive to the choice of prompts, considerable effort has been devoted to\ncrowd-sourcing prompts or designing methods for prompt optimisation. Yet, we\nstill lack a systematic understanding of how linguistic properties of prompts\ncorrelate with task performance. In this work, we investigate how LLMs of\ndifferent sizes, pre-trained and instruction-tuned, perform on prompts that are\nsemantically equivalent, but vary in linguistic structure. We investigate both\ngrammatical properties such as mood, tense, aspect and modality, as well as\nlexico-semantic variation through the use of synonyms. Our findings contradict\nthe common assumption that LLMs achieve optimal performance on lower perplexity\nprompts that reflect language use in pretraining or instruction-tuning data.\nPrompts transfer poorly between datasets or models, and performance cannot\ngenerally be explained by perplexity, word frequency, ambiguity or prompt\nlength. Based on our results, we put forward a proposal for a more robust and\ncomprehensive evaluation standard for prompting research.",
            "author": [
                "Alina Leidinger",
                "Robert van Rooij",
                "Ekaterina Shutova"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01967v1",
                "http://arxiv.org/pdf/2311.01967v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01960v1",
            "title": "Hardness of Low Rank Approximation of Entrywise Transformed Matrix\n  Products",
            "updated": "2023-11-03T14:56:24Z",
            "published": "2023-11-03T14:56:24Z",
            "summary": "Inspired by fast algorithms in natural language processing, we study low rank\napproximation in the entrywise transformed setting where we want to find a good\nrank $k$ approximation to $f(U \\cdot V)$, where $U, V^\\top \\in \\mathbb{R}^{n\n\\times r}$ are given, $r = O(\\log(n))$, and $f(x)$ is a general scalar\nfunction. Previous work in sublinear low rank approximation has shown that if\nboth (1) $U = V^\\top$ and (2) $f(x)$ is a PSD kernel function, then there is an\n$O(nk^{\\omega-1})$ time constant relative error approximation algorithm, where\n$\\omega \\approx 2.376$ is the exponent of matrix multiplication. We give the\nfirst conditional time hardness results for this problem, demonstrating that\nboth conditions (1) and (2) are in fact necessary for getting better than\n$n^{2-o(1)}$ time for a relative error low rank approximation for a wide class\nof functions. We give novel reductions from the Strong Exponential Time\nHypothesis (SETH) that rely on lower bounding the leverage scores of flat\nsparse vectors and hold even when the rank of the transformed matrix $f(UV)$\nand the target rank are $n^{o(1)}$, and when $U = V^\\top$. Furthermore, even\nwhen $f(x) = x^p$ is a simple polynomial, we give runtime lower bounds in the\ncase when $U \\neq V^\\top$ of the form $\\Omega(\\min(n^{2-o(1)}, \\Omega(2^p)))$.\nLastly, we demonstrate that our lower bounds are tight by giving an $O(n \\cdot\n\\text{poly}(k, 2^p, 1/\\epsilon))$ time relative error approximation algorithm\nand a fast $O(n \\cdot \\text{poly}(k, p, 1/\\epsilon))$ additive error\napproximation using fast tensor-based sketching. Additionally, since our low\nrank algorithms rely on matrix-vector product subroutines, our lower bounds\nextend to show that computing $f(UV)W$, for even a small matrix $W$, requires\n$\\Omega(n^{2-o(1)})$ time.",
            "author": [
                "Tamas Sarlos",
                "Xingyou Song",
                "David Woodruff",
                "Qiuyi",
                "Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01960v1",
                "http://arxiv.org/pdf/2311.01960v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01953v1",
            "title": "Optimistic Multi-Agent Policy Gradient for Cooperative Tasks",
            "updated": "2023-11-03T14:47:54Z",
            "published": "2023-11-03T14:47:54Z",
            "summary": "\\textit{Relative overgeneralization} (RO) occurs in cooperative multi-agent\nlearning tasks when agents converge towards a suboptimal joint policy due to\noverfitting to suboptimal behavior of other agents. In early work, optimism has\nbeen shown to mitigate the \\textit{RO} problem when using tabular Q-learning.\nHowever, with function approximation optimism can amplify overestimation and\nthus fail on complex tasks. On the other hand, recent deep multi-agent policy\ngradient (MAPG) methods have succeeded in many complex tasks but may fail with\nsevere \\textit{RO}. We propose a general, yet simple, framework to enable\noptimistic updates in MAPG methods and alleviate the RO problem. Specifically,\nwe employ a \\textit{Leaky ReLU} function where a single hyperparameter selects\nthe degree of optimism to reshape the advantages when updating the policy.\nIntuitively, our method remains optimistic toward individual actions with lower\nreturns which are potentially caused by other agents' sub-optimal behavior\nduring learning. The optimism prevents the individual agents from quickly\nconverging to a local optimum. We also provide a formal analysis from an\noperator view to understand the proposed advantage transformation. In extensive\nevaluations on diverse sets of tasks, including illustrative matrix games,\ncomplex \\textit{Multi-agent MuJoCo} and \\textit{Overcooked} benchmarks, the\nproposed method\\footnote{Code can be found at\n\\url{https://github.com/wenshuaizhao/optimappo}.} outperforms strong baselines\non 13 out of 19 tested tasks and matches the performance on the rest.",
            "author": [
                "Wenshuai Zhao",
                "Yi Zhao",
                "Zhiyuan Li",
                "Juho Kannala",
                "Joni Pajarinen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01953v1",
                "http://arxiv.org/pdf/2311.01953v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04926v1",
            "title": "More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve\n  Visually Diverse Images of Parsons Problems",
            "updated": "2023-11-03T14:47:17Z",
            "published": "2023-11-03T14:47:17Z",
            "summary": "The advent of large language models is reshaping computing education. Recent\nresearch has demonstrated that these models can produce better explanations\nthan students, answer multiple-choice questions at or above the class average,\nand generate code that can pass automated tests in introductory courses. These\ncapabilities have prompted instructors to rapidly adapt their courses and\nassessment methods to accommodate changes in learning objectives and the\npotential for academic integrity violations. While some scholars have advocated\nfor the integration of visual problems as a safeguard against the capabilities\nof language models, new multimodal language models now have vision and language\ncapabilities that may allow them to analyze and solve visual problems. In this\npaper, we evaluate the performance of two large multimodal models on visual\nassignments, with a specific focus on Parsons problems presented across diverse\nvisual representations. Our results show that GPT-4V solved 96.7\\% of these\nvisual problems, struggling minimally with a single Parsons problem.\nConversely, Bard performed poorly by only solving 69.2\\% of problems,\nstruggling with common issues like hallucinations and refusals. These findings\nsuggest that merely transitioning to visual programming problems might not be a\npanacea to issues of academic integrity in the generative AI era.",
            "author": [
                "Irene Hou",
                "Owen Man",
                "Sophie Mettille",
                "Sebastian Gutierrez",
                "Kenneth Angelikas",
                "Stephen MacNeil"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04926v1",
                "http://arxiv.org/pdf/2311.04926v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01949v1",
            "title": "Hint-enhanced In-Context Learning wakes Large Language Models up for\n  knowledge-intensive tasks",
            "updated": "2023-11-03T14:39:20Z",
            "published": "2023-11-03T14:39:20Z",
            "summary": "In-context learning (ICL) ability has emerged with the increasing scale of\nlarge language models (LLMs), enabling them to learn input-label mappings from\ndemonstrations and perform well on downstream tasks. However, under the\nstandard ICL setting, LLMs may sometimes neglect query-related information in\ndemonstrations, leading to incorrect predictions. To address this limitation,\nwe propose a new paradigm called Hint-enhanced In-Context Learning (HICL) to\nexplore the power of ICL in open-domain question answering, an important form\nin knowledge-intensive tasks. HICL leverages LLMs' reasoning ability to extract\nquery-related knowledge from demonstrations, then concatenates the knowledge to\nprompt LLMs in a more explicit way. Furthermore, we track the source of this\nknowledge to identify specific examples, and introduce a Hint-related Example\nRetriever (HER) to select informative examples for enhanced demonstrations. We\nevaluate HICL with HER on 3 open-domain QA benchmarks, and observe average\nperformance gains of 2.89 EM score and 2.52 F1 score on gpt-3.5-turbo, 7.62 EM\nscore and 7.27 F1 score on LLaMA-2-Chat-7B compared with standard setting.",
            "author": [
                "Yifan Wang",
                "Qingyan Guo",
                "Xinzhe Ni",
                "Chufan Shi",
                "Lemao Liu",
                "Haiyun Jiang",
                "Yujiu Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01949v1",
                "http://arxiv.org/pdf/2311.01949v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14685v1",
            "title": "Comprehensive Assessment of Toxicity in ChatGPT",
            "updated": "2023-11-03T14:37:53Z",
            "published": "2023-11-03T14:37:53Z",
            "summary": "Moderating offensive, hateful, and toxic language has always been an\nimportant but challenging topic in the domain of safe use in NLP. The emerging\nlarge language models (LLMs), such as ChatGPT, can potentially further\naccentuate this threat. Previous works have discovered that ChatGPT can\ngenerate toxic responses using carefully crafted inputs. However, limited\nresearch has been done to systematically examine when ChatGPT generates toxic\nresponses. In this paper, we comprehensively evaluate the toxicity in ChatGPT\nby utilizing instruction-tuning datasets that closely align with real-world\nscenarios. Our results show that ChatGPT's toxicity varies based on different\nproperties and settings of the prompts, including tasks, domains, length, and\nlanguages. Notably, prompts in creative writing tasks can be 2x more likely\nthan others to elicit toxic responses. Prompting in German and Portuguese can\nalso double the response toxicity. Additionally, we discover that certain\ndeliberately toxic prompts, designed in earlier studies, no longer yield\nharmful responses. We hope our discoveries can guide model developers to better\nregulate these AI systems and the users to avoid undesirable outputs.",
            "author": [
                "Boyang Zhang",
                "Xinyue Shen",
                "Wai Man Si",
                "Zeyang Sha",
                "Zeyuan Chen",
                "Ahmed Salem",
                "Yun Shen",
                "Michael Backes",
                "Yang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14685v1",
                "http://arxiv.org/pdf/2311.14685v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CL",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02133v1",
            "title": "Safe Online Dynamics Learning with Initially Unknown Models and\n  Infeasible Safety Certificates",
            "updated": "2023-11-03T14:23:57Z",
            "published": "2023-11-03T14:23:57Z",
            "summary": "Safety-critical control tasks with high levels of uncertainty are becoming\nincreasingly common. Typically, techniques that guarantee safety during\nlearning and control utilize constraint-based safety certificates, which can be\nleveraged to compute safe control inputs. However, excessive model uncertainty\ncan render robust safety certification methods or infeasible, meaning no\ncontrol input satisfies the constraints imposed by the safety certificate. This\npaper considers a learning-based setting with a robust safety certificate based\non a control barrier function (CBF) second-order cone program. If the control\nbarrier function certificate is feasible, our approach leverages it to\nguarantee safety. Otherwise, our method explores the system dynamics to collect\ndata and recover the feasibility of the control barrier function constraint. To\nthis end, we employ a method inspired by well-established tools from Bayesian\noptimization. We show that if the sampling frequency is high enough, we recover\nthe feasibility of the robust CBF certificate, guaranteeing safety. Our\napproach requires no prior model and corresponds, to the best of our knowledge,\nto the first algorithm that guarantees safety in settings with occasionally\ninfeasible safety certificates without requiring a backup non-learning-based\ncontroller.",
            "author": [
                "Alexandre Capone",
                "Ryan Cosner",
                "Aaron Ames",
                "Sandra Hirche"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02133v1",
                "http://arxiv.org/pdf/2311.02133v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.AI",
                "cs.RO",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01934v1",
            "title": "Does Difficulty even Matter? Investigating Difficulty Adjustment and\n  Practice Behavior in an Open-Ended Learning Task",
            "updated": "2023-11-03T14:18:52Z",
            "published": "2023-11-03T14:18:52Z",
            "summary": "Difficulty adjustment in practice exercises has been shown to be beneficial\nfor learning. However, previous research has mostly investigated close-ended\ntasks, which do not offer the students multiple ways to reach a valid solution.\nContrary to this, in order to learn in an open-ended learning task, students\nneed to effectively explore the solution space as there are multiple ways to\nreach a solution. For this reason, the effects of difficulty adjustment could\nbe different for open-ended tasks. To investigate this, as our first\ncontribution, we compare different methods of difficulty adjustment in a user\nstudy conducted with 86 participants. Furthermore, as the practice behavior of\nthe students is expected to influence how well the students learn, we\nadditionally look at their practice behavior as a post-hoc analysis. Therefore,\nas a second contribution, we identify different types of practice behavior and\nhow they link to students' learning outcomes and subjective evaluation measures\nas well as explore the influence the difficulty adjustment methods have on the\npractice behaviors. Our results suggest the usefulness of taking into account\nthe practice behavior in addition to only using the practice performance to\ninform adaptive intervention and difficulty adjustment methods.",
            "author": [
                "Anan Sch\u00fctt",
                "Tobias Huber",
                "Jauwairia Nasir",
                "Cristina Conati",
                "Elisabeth Andr\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01934v1",
                "http://arxiv.org/pdf/2311.01934v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01933v1",
            "title": "ForecastPFN: Synthetically-Trained Zero-Shot Forecasting",
            "updated": "2023-11-03T14:17:11Z",
            "published": "2023-11-03T14:17:11Z",
            "summary": "The vast majority of time-series forecasting approaches require a substantial\ntraining dataset. However, many real-life forecasting applications have very\nlittle initial observations, sometimes just 40 or fewer. Thus, the\napplicability of most forecasting methods is restricted in data-sparse\ncommercial applications. While there is recent work in the setting of very\nlimited initial data (so-called `zero-shot' forecasting), its performance is\ninconsistent depending on the data used for pretraining. In this work, we take\na different approach and devise ForecastPFN, the first zero-shot forecasting\nmodel trained purely on a novel synthetic data distribution. ForecastPFN is a\nprior-data fitted network, trained to approximate Bayesian inference, which can\nmake predictions on a new time series dataset in a single forward pass. Through\nextensive experiments, we show that zero-shot predictions made by ForecastPFN\nare more accurate and faster compared to state-of-the-art forecasting methods,\neven when the other methods are allowed to train on hundreds of additional\nin-distribution data points.",
            "author": [
                "Samuel Dooley",
                "Gurnoor Singh Khurana",
                "Chirag Mohapatra",
                "Siddartha Naidu",
                "Colin White"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01933v1",
                "http://arxiv.org/pdf/2311.01933v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01929v2",
            "title": "ProS: Facial Omni-Representation Learning via Prototype-based\n  Self-Distillation",
            "updated": "2023-11-07T15:34:42Z",
            "published": "2023-11-03T14:10:06Z",
            "summary": "This paper presents a novel approach, called Prototype-based\nSelf-Distillation (ProS), for unsupervised face representation learning. The\nexisting supervised methods heavily rely on a large amount of annotated\ntraining facial data, which poses challenges in terms of data collection and\nprivacy concerns. To address these issues, we propose ProS, which leverages a\nvast collection of unlabeled face images to learn a comprehensive facial\nomni-representation. In particular, ProS consists of two vision-transformers\n(teacher and student models) that are trained with different augmented images\n(cropping, blurring, coloring, etc.). Besides, we build a face-aware retrieval\nsystem along with augmentations to obtain the curated images comprising\npredominantly facial areas. To enhance the discrimination of learned features,\nwe introduce a prototype-based matching loss that aligns the similarity\ndistributions between features (teacher or student) and a set of learnable\nprototypes. After pre-training, the teacher vision transformer serves as a\nbackbone for downstream tasks, including attribute estimation, expression\nrecognition, and landmark alignment, achieved through simple fine-tuning with\nadditional layers. Extensive experiments demonstrate that our method achieves\nstate-of-the-art performance on various tasks, both in full and few-shot\nsettings. Furthermore, we investigate pre-training with synthetic face images,\nand ProS exhibits promising performance in this scenario as well.",
            "author": [
                "Xing Di",
                "Yiyu Zheng",
                "Xiaoming Liu",
                "Yu Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01929v2",
                "http://arxiv.org/pdf/2311.01929v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01927v1",
            "title": "GateLoop: Fully Data-Controlled Linear Recurrence for Sequence Modeling",
            "updated": "2023-11-03T14:08:39Z",
            "published": "2023-11-03T14:08:39Z",
            "summary": "Linear Recurrence has proven to be a powerful tool for modeling long\nsequences efficiently. In this work, we show that existing models fail to take\nfull advantage of its potential. Motivated by this finding, we develop\nGateLoop, a foundational sequence model that generalizes linear recurrent\nmodels such as S4, S5, LRU and RetNet, by employing data-controlled state\ntransitions. Utilizing this theoretical advance, GateLoop empirically\noutperforms existing models for auto-regressive language modeling. Our method\ncomes with a low-cost $O(l)$ recurrent mode and an efficient $O(l \\log_{2} l)$\nparallel mode making use of highly optimized associative scan implementations.\nFurthermore, we derive an $O(l^2)$ surrogate attention mode, revealing\nremarkable implications for Transformer and recently proposed architectures.\nSpecifically, we prove that our approach can be interpreted as providing\ndata-controlled relative-positional information to Attention. While many\nexisting models solely rely on data-controlled cumulative sums for context\naggregation, our findings suggest that incorporating data-controlled complex\ncumulative products may be a crucial step towards more powerful sequence\nmodels.",
            "author": [
                "Tobias Katsch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01927v1",
                "http://arxiv.org/pdf/2311.01927v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08417v1",
            "title": "Image complexity based fMRI-BOLD visual network categorization across\n  visual datasets using topological descriptors and deep-hybrid learning",
            "updated": "2023-11-03T14:05:57Z",
            "published": "2023-11-03T14:05:57Z",
            "summary": "This study proposes a new approach that investigates differences in\ntopological characteristics of visual networks, which are constructed using\nfMRI BOLD time-series corresponding to visual datasets of COCO, ImageNet, and\nSUN. A publicly available BOLD5000 dataset is utilized that contains fMRI scans\nwhile viewing 5254 images of diverse complexities. The objective of this study\nis to examine how network topology differs in response to distinct visual\nstimuli from these visual datasets. To achieve this, 0- and 1-dimensional\npersistence diagrams are computed for each visual network representing COCO,\nImageNet, and SUN. For extracting suitable features from topological\npersistence diagrams, K-means clustering is executed. The extracted K-means\ncluster features are fed to a novel deep-hybrid model that yields accuracy in\nthe range of 90%-95% in classifying these visual networks. To understand\nvision, this type of visual network categorization across visual datasets is\nimportant as it captures differences in BOLD signals while perceiving images\nwith different contexts and complexities. Furthermore, distinctive topological\npatterns of visual network associated with each dataset, as revealed from this\nstudy, could potentially lead to the development of future neuroimaging\nbiomarkers for diagnosing visual processing disorders like visual agnosia or\nprosopagnosia, and tracking changes in visual cognition over time.",
            "author": [
                "Debanjali Bhattacharya",
                "Neelam Sinha",
                "Yashwanth R.",
                "Amit Chattopadhyay"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08417v1",
                "http://arxiv.org/pdf/2311.08417v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "eess.SP",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04925v1",
            "title": "Investigating Deep-Learning NLP for Automating the Extraction of\n  Oncology Efficacy Endpoints from Scientific Literature",
            "updated": "2023-11-03T14:01:54Z",
            "published": "2023-11-03T14:01:54Z",
            "summary": "Benchmarking drug efficacy is a critical step in clinical trial design and\nplanning. The challenge is that much of the data on efficacy endpoints is\nstored in scientific papers in free text form, so extraction of such data is\ncurrently a largely manual task. Our objective is to automate this task as much\nas possible. In this study we have developed and optimised a framework to\nextract efficacy endpoints from text in scientific papers, using a machine\nlearning approach. Our machine learning model predicts 25 classes associated\nwith efficacy endpoints and leads to high F1 scores (harmonic mean of precision\nand recall) of 96.4% on the test set, and 93.9% and 93.7% on two case studies.\nThese methods were evaluated against - and showed strong agreement with -\nsubject matter experts and show significant promise in the future of automating\nthe extraction of clinical endpoints from free text. Clinical information\nextraction from text data is currently a laborious manual task which scales\npoorly and is prone to human error. Demonstrating the ability to extract\nefficacy endpoints automatically shows great promise for accelerating clinical\ntrial design moving forwards.",
            "author": [
                "Aline Gendrin-Brokmann",
                "Eden Harrison",
                "Julianne Noveras",
                "Leonidas Souliotis",
                "Harris Vince",
                "Ines Smit",
                "Francisco Costa",
                "David Milward",
                "Sashka Dimitrievska",
                "Paul Metcalfe",
                "Emilie Louvet"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04925v1",
                "http://arxiv.org/pdf/2311.04925v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01918v1",
            "title": "Large Language Models Illuminate a Progressive Pathway to Artificial\n  Healthcare Assistant: A Review",
            "updated": "2023-11-03T13:51:36Z",
            "published": "2023-11-03T13:51:36Z",
            "summary": "With the rapid development of artificial intelligence, large language models\n(LLMs) have shown promising capabilities in mimicking human-level language\ncomprehension and reasoning. This has sparked significant interest in applying\nLLMs to enhance various aspects of healthcare, ranging from medical education\nto clinical decision support. However, medicine involves multifaceted data\nmodalities and nuanced reasoning skills, presenting challenges for integrating\nLLMs. This paper provides a comprehensive review on the applications and\nimplications of LLMs in medicine. It begins by examining the fundamental\napplications of general-purpose and specialized LLMs, demonstrating their\nutilities in knowledge retrieval, research support, clinical workflow\nautomation, and diagnostic assistance. Recognizing the inherent multimodality\nof medicine, the review then focuses on multimodal LLMs, investigating their\nability to process diverse data types like medical imaging and EHRs to augment\ndiagnostic accuracy. To address LLMs' limitations regarding personalization and\ncomplex clinical reasoning, the paper explores the emerging development of\nLLM-powered autonomous agents for healthcare. Furthermore, it summarizes the\nevaluation methodologies for assessing LLMs' reliability and safety in medical\ncontexts. Overall, this review offers an extensive analysis on the\ntransformative potential of LLMs in modern medicine. It also highlights the\npivotal need for continuous optimizations and ethical oversight before these\nmodels can be effectively integrated into clinical practice. Visit\nhttps://github.com/mingze-yuan/Awesome-LLM-Healthcare for an accompanying\nGitHub repository containing latest papers.",
            "author": [
                "Mingze Yuan",
                "Peng Bao",
                "Jiajia Yuan",
                "Yunhao Shen",
                "Zifan Chen",
                "Yi Xie",
                "Jie Zhao",
                "Yang Chen",
                "Li Zhang",
                "Lin Shen",
                "Bin Dong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01918v1",
                "http://arxiv.org/pdf/2311.01918v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02130v1",
            "title": "Client Orchestration and Cost-Efficient Joint Optimization for\n  NOMA-Enabled Hierarchical Federated Learning",
            "updated": "2023-11-03T13:34:44Z",
            "published": "2023-11-03T13:34:44Z",
            "summary": "Hierarchical federated learning (HFL) shows great advantages over\nconventional two-layer federated learning (FL) in reducing network overhead and\ninteraction latency while still retaining the data privacy of distributed FL\nclients. However, the communication and energy overhead still pose a bottleneck\nfor HFL performance, especially as the number of clients raises dramatically.\nTo tackle this issue, we propose a non-orthogonal multiple access (NOMA)\nenabled HFL system under semi-synchronous cloud model aggregation in this\npaper, aiming to minimize the total cost of time and energy at each HFL global\nround. Specifically, we first propose a novel fuzzy logic based client\norchestration policy considering client heterogenerity in multiple aspects,\nincluding channel quality, data quantity and model staleness. Subsequently,\ngiven the fuzzy based client-edge association, a joint edge server scheduling\nand resource allocation problem is formulated. Utilizing problem decomposition,\nwe firstly derive the closed-form solution for the edge server scheduling\nsubproblem via the penalty dual decomposition (PDD) method. Next, a deep\ndeterministic policy gradient (DDPG) based algorithm is proposed to tackle the\nresource allocation subproblem considering time-varying environments. Finally,\nextensive simulations demonstrate that the proposed scheme outperforms the\nconsidered benchmarks regarding HFL performance improvement and total cost\nreduction.",
            "author": [
                "Bibo Wu",
                "Fang Fang",
                "Xianbin Wang",
                "Donghong Cai",
                "Shu Fu",
                "Zhiguo Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02130v1",
                "http://arxiv.org/pdf/2311.02130v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01906v1",
            "title": "Simplifying Transformer Blocks",
            "updated": "2023-11-03T13:30:52Z",
            "published": "2023-11-03T13:30:52Z",
            "summary": "A simple design recipe for deep Transformers is to compose identical building\nblocks. But standard transformer blocks are far from simple, interweaving\nattention and MLP sub-blocks with skip connections & normalisation layers in\nprecise arrangements. This complexity leads to brittle architectures, where\nseemingly minor changes can significantly reduce training speed, or render\nmodels untrainable.\n  In this work, we ask to what extent the standard transformer block can be\nsimplified? Combining signal propagation theory and empirical observations, we\nmotivate modifications that allow many block components to be removed with no\nloss of training speed, including skip connections, projection or value\nparameters, sequential sub-blocks and normalisation layers. In experiments on\nboth autoregressive decoder-only and BERT encoder-only models, our simplified\ntransformers emulate the per-update training speed and performance of standard\ntransformers, while enjoying 15% faster training throughput, and using 15%\nfewer parameters.",
            "author": [
                "Bobby He",
                "Thomas Hofmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01906v1",
                "http://arxiv.org/pdf/2311.01906v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01902v1",
            "title": "High Precision Causal Model Evaluation with Conditional Randomization",
            "updated": "2023-11-03T13:22:27Z",
            "published": "2023-11-03T13:22:27Z",
            "summary": "The gold standard for causal model evaluation involves comparing model\npredictions with true effects estimated from randomized controlled trials\n(RCT). However, RCTs are not always feasible or ethical to perform. In\ncontrast, conditionally randomized experiments based on inverse probability\nweighting (IPW) offer a more realistic approach but may suffer from high\nestimation variance. To tackle this challenge and enhance causal model\nevaluation in real-world conditional randomization settings, we introduce a\nnovel low-variance estimator for causal error, dubbed as the pairs estimator.\nBy applying the same IPW estimator to both the model and true experimental\neffects, our estimator effectively cancels out the variance due to IPW and\nachieves a smaller asymptotic variance. Empirical studies demonstrate the\nimproved of our estimator, highlighting its potential on achieving near-RCT\nperformance. Our method offers a simple yet powerful solution to evaluate\ncausal inference models in conditional randomization settings without\ncomplicated modification of the IPW estimator itself, paving the way for more\nrobust and reliable model assessments.",
            "author": [
                "Chao Ma",
                "Cheng Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01902v1",
                "http://arxiv.org/pdf/2311.01902v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01900v1",
            "title": "Online non-parametric likelihood-ratio estimation by Pearson-divergence\n  functional minimization",
            "updated": "2023-11-03T13:20:11Z",
            "published": "2023-11-03T13:20:11Z",
            "summary": "Quantifying the difference between two probability density functions, $p$ and\n$q$, using available data, is a fundamental problem in Statistics and Machine\nLearning. A usual approach for addressing this problem is the likelihood-ratio\nestimation (LRE) between $p$ and $q$, which -- to our best knowledge -- has\nbeen investigated mainly for the offline case. This paper contributes by\nintroducing a new framework for online non-parametric LRE (OLRE) for the\nsetting where pairs of iid observations $(x_t \\sim p, x'_t \\sim q)$ are\nobserved over time. The non-parametric nature of our approach has the advantage\nof being agnostic to the forms of $p$ and $q$. Moreover, we capitalize on the\nrecent advances in Kernel Methods and functional minimization to develop an\nestimator that can be efficiently updated online. We provide theoretical\nguarantees for the performance of the OLRE method along with empirical\nvalidation in synthetic experiments.",
            "author": [
                "Alejandro de la Concha",
                "Nicolas Vayatis",
                "Argyris Kalogeratos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01900v1",
                "http://arxiv.org/pdf/2311.01900v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01888v1",
            "title": "Learning Sparse Codes with Entropy-Based ELBOs",
            "updated": "2023-11-03T13:03:41Z",
            "published": "2023-11-03T13:03:41Z",
            "summary": "Standard probabilistic sparse coding assumes a Laplace prior, a linear\nmapping from latents to observables, and Gaussian observable distributions. We\nhere derive a solely entropy-based learning objective for the parameters of\nstandard sparse coding. The novel variational objective has the following\nfeatures: (A) unlike MAP approximations, it uses non-trivial posterior\napproximations for probabilistic inference; (B) unlike for previous non-trivial\napproximations, the novel objective is fully analytical; and (C) the objective\nallows for a novel principled form of annealing. The objective is derived by\nfirst showing that the standard ELBO objective converges to a sum of entropies,\nwhich matches similar recent results for generative models with Gaussian\npriors. The conditions under which the ELBO becomes equal to entropies are then\nshown to have analytical solutions, which leads to the fully analytical\nobjective. Numerical experiments are used to demonstrate the feasibility of\nlearning with such entropy-based ELBOs. We investigate different posterior\napproximations including Gaussians with correlated latents and deep amortized\napproximations. Furthermore, we numerically investigate entropy-based annealing\nwhich results in improved learning. Our main contributions are theoretical,\nhowever, and they are twofold: (1) for non-trivial posterior approximations, we\nprovide the (to the knowledge of the authors) first analytical ELBO objective\nfor standard probabilistic sparse coding; and (2) we provide the first\ndemonstration on how a recently shown convergence of the ELBO to entropy sums\ncan be used for learning.",
            "author": [
                "Dmytro Velychko",
                "Simon Damm",
                "Asja Fischer",
                "J\u00f6rg L\u00fccke"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01888v1",
                "http://arxiv.org/pdf/2311.01888v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01885v1",
            "title": "Domain Randomization via Entropy Maximization",
            "updated": "2023-11-03T12:54:05Z",
            "published": "2023-11-03T12:54:05Z",
            "summary": "Varying dynamics parameters in simulation is a popular Domain Randomization\n(DR) approach for overcoming the reality gap in Reinforcement Learning (RL).\nNevertheless, DR heavily hinges on the choice of the sampling distribution of\nthe dynamics parameters, since high variability is crucial to regularize the\nagent's behavior but notoriously leads to overly conservative policies when\nrandomizing excessively. In this paper, we propose a novel approach to address\nsim-to-real transfer, which automatically shapes dynamics distributions during\ntraining in simulation without requiring real-world data. We introduce DOmain\nRAndomization via Entropy MaximizatiON (DORAEMON), a constrained optimization\nproblem that directly maximizes the entropy of the training distribution while\nretaining generalization capabilities. In achieving this, DORAEMON gradually\nincreases the diversity of sampled dynamics parameters as long as the\nprobability of success of the current policy is sufficiently high. We\nempirically validate the consistent benefits of DORAEMON in obtaining highly\nadaptive and generalizable policies, i.e. solving the task at hand across the\nwidest range of dynamics parameters, as opposed to representative baselines\nfrom the DR literature. Notably, we also demonstrate the Sim2Real applicability\nof DORAEMON through its successful zero-shot transfer in a robotic manipulation\nsetup under unknown real-world parameters.",
            "author": [
                "Gabriele Tiboni",
                "Pascal Klink",
                "Jan Peters",
                "Tatiana Tommasi",
                "Carlo D'Eramo",
                "Georgia Chalvatzaki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01885v1",
                "http://arxiv.org/pdf/2311.01885v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01876v1",
            "title": "Sentiment Analysis through LLM Negotiations",
            "updated": "2023-11-03T12:35:29Z",
            "published": "2023-11-03T12:35:29Z",
            "summary": "A standard paradigm for sentiment analysis is to rely on a singular LLM and\nmakes the decision in a single round under the framework of in-context\nlearning. This framework suffers the key disadvantage that the single-turn\noutput generated by a single LLM might not deliver the perfect decision, just\nas humans sometimes need multiple attempts to get things right. This is\nespecially true for the task of sentiment analysis where deep reasoning is\nrequired to address the complex linguistic phenomenon (e.g., clause\ncomposition, irony, etc) in the input.\n  To address this issue, this paper introduces a multi-LLM negotiation\nframework for sentiment analysis. The framework consists of a reasoning-infused\ngenerator to provide decision along with rationale, a explanation-deriving\ndiscriminator to evaluate the credibility of the generator. The generator and\nthe discriminator iterate until a consensus is reached. The proposed framework\nnaturally addressed the aforementioned challenge, as we are able to take the\ncomplementary abilities of two LLMs, have them use rationale to persuade each\nother for correction.\n  Experiments on a wide range of sentiment analysis benchmarks (SST-2, Movie\nReview, Twitter, yelp, amazon, IMDB) demonstrate the effectiveness of proposed\napproach: it consistently yields better performances than the ICL baseline\nacross all benchmarks, and even superior performances to supervised baselines\non the Twitter and movie review datasets.",
            "author": [
                "Xiaofei Sun",
                "Xiaoya Li",
                "Shengyu Zhang",
                "Shuhe Wang",
                "Fei Wu",
                "Jiwei Li",
                "Tianwei Zhang",
                "Guoyin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01876v1",
                "http://arxiv.org/pdf/2311.01876v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01875v1",
            "title": "Enhancing Functional Data Analysis with Sequential Neural Networks:\n  Advantages and Comparative Study",
            "updated": "2023-11-03T12:33:18Z",
            "published": "2023-11-03T12:33:18Z",
            "summary": "Functional Data Analysis (FDA) is a statistical domain developed to handle\nfunctional data characterized by high dimensionality and complex data\nstructures. Sequential Neural Networks (SNNs) are specialized neural networks\ncapable of processing sequence data, a fundamental aspect of functional data.\nDespite their great flexibility in modeling functional data, SNNs have been\ninadequately employed in the FDA community. One notable advantage of SNNs is\nthe ease of implementation, making them accessible to a broad audience beyond\nacademia. Conversely, FDA-based methodologies present challenges, particularly\nfor practitioners outside the field, due to their intricate complexity. In\nlight of this, we propose utilizing SNNs in FDA applications and demonstrate\ntheir effectiveness through comparative analyses against popular FDA regression\nmodels based on numerical experiments and real-world data analysis. SNN\narchitectures allow us to surpass the limitations of traditional FDA methods,\noffering scalability, flexibility, and improved analytical performance. Our\nfindings highlight the potential of SNN-based methodologies as powerful tools\nfor data applications involving functional data.",
            "author": [
                "J. Zhao",
                "J. Li",
                "M. Chen",
                "S. Jadhav"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01875v1",
                "http://arxiv.org/pdf/2311.01875v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02129v1",
            "title": "Hierarchical Reinforcement Learning for Power Network Topology Control",
            "updated": "2023-11-03T12:33:00Z",
            "published": "2023-11-03T12:33:00Z",
            "summary": "Learning in high-dimensional action spaces is a key challenge in applying\nreinforcement learning (RL) to real-world systems. In this paper, we study the\npossibility of controlling power networks using RL methods. Power networks are\ncritical infrastructures that are complex to control. In particular, the\ncombinatorial nature of the action space poses a challenge to both conventional\noptimizers and learned controllers. Hierarchical reinforcement learning (HRL)\nrepresents one approach to address this challenge. More precisely, a HRL\nframework for power network topology control is proposed. The HRL framework\nconsists of three levels of action abstraction. At the highest level, there is\nthe overall long-term task of power network operation, namely, keeping the\npower grid state within security constraints at all times, which is decomposed\ninto two temporally extended actions: 'do nothing' versus 'propose a topology\nchange'. At the intermediate level, the action space consists of all\ncontrollable substations. Finally, at the lowest level, the action space\nconsists of all configurations of the chosen substation. By employing this HRL\nframework, several hierarchical power network agents are trained for the IEEE\n14-bus network. Whereas at the highest level a purely rule-based policy is\nstill chosen for all agents in this study, at the intermediate level the policy\nis trained using different state-of-the-art RL algorithms. At the lowest level,\neither an RL algorithm or a greedy algorithm is used. The performance of the\ndifferent 3-level agents is compared with standard baseline (RL or greedy)\napproaches. A key finding is that the 3-level agent that employs RL both at the\nintermediate and the lowest level outperforms all other agents on the most\ndifficult task. Our code is publicly available.",
            "author": [
                "Blazej Manczak",
                "Jan Viebahn",
                "Herke van Hoof"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02129v1",
                "http://arxiv.org/pdf/2311.02129v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01870v1",
            "title": "Multi-EuP: The Multilingual European Parliament Dataset for Analysis of\n  Bias in Information Retrieval",
            "updated": "2023-11-03T12:29:11Z",
            "published": "2023-11-03T12:29:11Z",
            "summary": "We present Multi-EuP, a new multilingual benchmark dataset, comprising 22K\nmulti-lingual documents collected from the European Parliament, spanning 24\nlanguages. This dataset is designed to investigate fairness in a multilingual\ninformation retrieval (IR) context to analyze both language and demographic\nbias in a ranking context. It boasts an authentic multilingual corpus,\nfeaturing topics translated into all 24 languages, as well as cross-lingual\nrelevance judgments. Furthermore, it offers rich demographic information\nassociated with its documents, facilitating the study of demographic bias. We\nreport the effectiveness of Multi-EuP for benchmarking both monolingual and\nmultilingual IR. We also conduct a preliminary experiment on language bias\ncaused by the choice of tokenization strategy.",
            "author": [
                "Jinrui Yang",
                "Timothy Baldwin",
                "Trevor Cohn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01870v1",
                "http://arxiv.org/pdf/2311.01870v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01867v1",
            "title": "3-Dimensional residual neural architecture search for ultrasonic defect\n  detection",
            "updated": "2023-11-03T12:21:01Z",
            "published": "2023-11-03T12:21:01Z",
            "summary": "This study presents a deep learning methodology using 3-dimensional (3D)\nconvolutional neural networks to detect defects in carbon fiber reinforced\npolymer composites through volumetric ultrasonic testing data. Acquiring large\namounts of ultrasonic training data experimentally is expensive and\ntime-consuming. To address this issue, a synthetic data generation method was\nextended to incorporate volumetric data. By preserving the complete volumetric\ndata, complex preprocessing is reduced, and the model can utilize spatial and\ntemporal information that is lost during imaging. This enables the model to\nutilise important features that might be overlooked otherwise. The performance\nof three architectures were compared. The first two architectures were\nhand-designed to address the high aspect ratios between the spatial and\ntemporal dimensions. The first architecture reduced dimensionality in the time\ndomain and used cubed kernels for feature extraction. The second architecture\nused cuboidal kernels to account for the large aspect ratios. The evaluation\nincluded comparing the use of max pooling and convolutional layers for\ndimensionality reduction, with the fully convolutional layers consistently\noutperforming the models using max pooling. The third architecture was\ngenerated through neural architecture search from a modified 3D Residual Neural\nNetwork (ResNet) search space. Additionally, domain-specific augmentation\nmethods were incorporated during training, resulting in significant\nimprovements in model performance for all architectures. The mean accuracy\nimprovements ranged from 8.2% to 22.4%. The best performing models achieved\nmean accuracies of 91.8%, 92.2%, and 100% for the reduction, constant, and\ndiscovered architectures, respectively. Whilst maintaining a model size smaller\nthan most 2-dimensional (2D) ResNets.",
            "author": [
                "Shaun McKnight",
                "Christopher MacKinnon",
                "S. Gareth Pierce",
                "Ehsan Mohseni",
                "Vedran Tunukovic",
                "Charles N. MacLeod",
                "Randika K. W. Vithanage",
                "Tom OHare"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01867v1",
                "http://arxiv.org/pdf/2311.01867v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16136v1",
            "title": "ERASER: Machine Unlearning in MLaaS via an Inference Serving-Aware\n  Approach",
            "updated": "2023-11-03T12:20:13Z",
            "published": "2023-11-03T12:20:13Z",
            "summary": "Over the past few years, Machine Learning-as-a-Service (MLaaS) has received a\nsurging demand for supporting Machine Learning-driven services to offer\nrevolutionized user experience across diverse application areas. MLaaS provides\ninference service with low inference latency to application users based on an\nML model trained using a dataset collected from numerous individual data\nowners. Recently, for the sake of data owners' privacy and to comply with the\n\"right to be forgotten (RTBF)\" as enacted by data protection legislation, many\nmachine unlearning methods have been proposed to remove data owners' data from\ntrained models upon their unlearning requests. However, despite their promising\nefficiency, almost all existing machine unlearning methods handle unlearning\nrequests in a manner that is independent of inference requests, which\nunfortunately introduces new security and privacy vulnerabilities for machine\nunlearning in MLaaS. In this paper, we propose the ERASER framework for machinE\nunleaRning in MLaAS via an inferencE seRving-aware approach. ERASER proposes a\nnovel certified inference consistency mechanism that reduces inference latency\nby selectively postponing unlearning execution incurred by unlearning requests\nfrom data owners, while strictly adhering to the RTBF principle. ERASER offers\nthree groups of design choices to allow for tailor-made variants that best suit\nthe specific environments and preferences of different MLaaS systems. Extensive\nempirical evaluations across various settings confirm ERASER's effectiveness,\ne.g., it can effectively save up to 99% of inference latency and 31% of\ncomputation overhead over the inference-oblivion baseline.",
            "author": [
                "Yuke Hu",
                "Jian Lou",
                "Jiaqi Liu",
                "Feng Lin",
                "Zhan Qin",
                "Kui Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16136v1",
                "http://arxiv.org/pdf/2311.16136v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01866v1",
            "title": "Towards Concept-Aware Large Language Models",
            "updated": "2023-11-03T12:19:22Z",
            "published": "2023-11-03T12:19:22Z",
            "summary": "Concepts play a pivotal role in various human cognitive functions, including\nlearning, reasoning and communication. However, there is very little work on\nendowing machines with the ability to form and reason with concepts. In\nparticular, state-of-the-art large language models (LLMs) work at the level of\ntokens, not concepts.\n  In this work, we analyze how well contemporary LLMs capture human concepts\nand their structure. We then discuss ways to develop concept-aware LLMs, taking\nplace at different stages of the pipeline. We sketch a method for pretraining\nLLMs using concepts, and also explore the simpler approach that uses the output\nof existing LLMs. Despite its simplicity, our proof-of-concept is shown to\nbetter match human intuition, as well as improve the robustness of predictions.\nThese preliminary results underscore the promise of concept-aware LLMs.",
            "author": [
                "Chen Shani",
                "Jilles Vreeken",
                "Dafna Shahaf"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01866v1",
                "http://arxiv.org/pdf/2311.01866v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01864v1",
            "title": "SortNet: Learning To Rank By a Neural-Based Sorting Algorithm",
            "updated": "2023-11-03T12:14:26Z",
            "published": "2023-11-03T12:14:26Z",
            "summary": "The problem of relevance ranking consists of sorting a set of objects with\nrespect to a given criterion. Since users may prefer different relevance\ncriteria, the ranking algorithms should be adaptable to the user needs. Two\nmain approaches exist in literature for the task of learning to rank: 1) a\nscore function, learned by examples, which evaluates the properties of each\nobject yielding an absolute relevance value that can be used to order the\nobjects or 2) a pairwise approach, where a \"preference function\" is learned\nusing pairs of objects to define which one has to be ranked first. In this\npaper, we present SortNet, an adaptive ranking algorithm which orders objects\nusing a neural network as a comparator. The neural network training set\nprovides examples of the desired ordering between pairs of items and it is\nconstructed by an iterative procedure which, at each iteration, adds the most\ninformative training examples. Moreover, the comparator adopts a connectionist\narchitecture that is particularly suited for implementing a preference\nfunction. We also prove that such an architecture has the universal\napproximation property and can implement a wide class of functions. Finally,\nthe proposed algorithm is evaluated on the LETOR dataset showing promising\nperformances in comparison with other state of the art algorithms.",
            "author": [
                "Leonardo Rigutini",
                "Tiziano Papini",
                "Marco Maggini",
                "Franco Scarselli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01864v1",
                "http://arxiv.org/pdf/2311.01864v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01854v1",
            "title": "An Ensemble Machine Learning Approach for Screening Covid-19 based on\n  Urine Parameters",
            "updated": "2023-11-03T11:45:10Z",
            "published": "2023-11-03T11:45:10Z",
            "summary": "The rapid spread of COVID-19 and the emergence of new variants underscore the\nimportance of effective screening measures. Rapid diagnosis and subsequent\nquarantine of infected individuals can prevent further spread of the virus in\nsociety. While PCR tests are the gold standard for COVID-19 diagnosis, they are\ncostly and time-consuming. In contrast, urine test strips are an inexpensive,\nnon-invasive, and rapidly obtainable screening method that can provide\nimportant information about a patient's health status. In this study, we\ncollected a new dataset and used the RGB (Red Green Blue) color space of urine\ntest strips parameters to detect the health status of individuals. To improve\nthe accuracy of our model, we converted the RGB space to 10 additional color\nspaces. After evaluating four different machine learning models, we proposed a\nnew ensemble model based on a multi-layer perceptron neural network. Although\nthe initial results were not strong, we were able to improve the model's\nscreening performance for COVID-19 by removing uncertain regions of the model\nspace. Ultimately, our model achieved a screening accuracy of 80% based on\nurine parameters. Our results suggest that urine test strips can be a useful\ntool for COVID-19 screening, particularly in resource-constrained settings\nwhere PCR testing may not be feasible. Further research is needed to validate\nour findings and explore the potential role of urine test strips in COVID-19\ndiagnosis and management.",
            "author": [
                "Behzad Moayedi",
                "Abdalsamad Keramatfar",
                "Mohammad Hadi Goldani",
                "Mohammad Javad Fallahi",
                "Alborz Jahangirisisakht",
                "Mohammad Saboori",
                "Leyla badiei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01854v1",
                "http://arxiv.org/pdf/2311.01854v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01851v1",
            "title": "Holistic Representation Learning for Multitask Trajectory Anomaly\n  Detection",
            "updated": "2023-11-03T11:32:53Z",
            "published": "2023-11-03T11:32:53Z",
            "summary": "Video anomaly detection deals with the recognition of abnormal events in\nvideos. Apart from the visual signal, video anomaly detection has also been\naddressed with the use of skeleton sequences. We propose a holistic\nrepresentation of skeleton trajectories to learn expected motions across\nsegments at different times. Our approach uses multitask learning to\nreconstruct any continuous unobserved temporal segment of the trajectory\nallowing the extrapolation of past or future segments and the interpolation of\nin-between segments. We use an end-to-end attention-based encoder-decoder. We\nencode temporally occluded trajectories, jointly learn latent representations\nof the occluded segments, and reconstruct trajectories based on expected\nmotions across different temporal segments. Extensive experiments on three\ntrajectory-based video anomaly detection datasets show the advantages and\neffectiveness of our approach with state-of-the-art results on anomaly\ndetection in skeleton trajectories.",
            "author": [
                "Alexandros Stergiou",
                "Brent De Weerdt",
                "Nikos Deligiannis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01851v1",
                "http://arxiv.org/pdf/2311.01851v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01850v1",
            "title": "Leveraging Mobile Learning Platforms for Flexible Education Delivery:\n  Bridging Educational Gaps in Afghanistan",
            "updated": "2023-11-03T11:26:55Z",
            "published": "2023-11-03T11:26:55Z",
            "summary": "The educational landscape of Afghanistan, besieged by infrastructural\ninadequacies and socio-political tribulations, presents a compelling case for\nthe integration of mobile learning platforms. This article embarks on an\nexploratory voyage into the realms of mobile learning as a potential harbinger\nof educational transformation in Afghanistan. It delineates the pervasive\neducational challenges, underscores the technological innovations powering\nmobile learning platforms, and illuminates the pathways through which mobile\nlearning can transcend the extant barriers to education. Enriched by real-world\ncase studies, the narrative unravels the pragmatic lessons that can be\nharnessed to tailor mobile learning solutions to Afghanistan's unique context.\nThe discussion further traverses the collaborative horizon, elucidating the\nsynergistic interplay among academia, government, the private sector, and\ninternational bodies essential for the successful implementation of mobile\nlearning platforms. The article also furnishes pragmatic recommendations,\nemphasizing the triad of policy formulation, infrastructure enhancement, and\ncapacity building as cornerstone imperatives. The envisioned integration of\nmobile learning platforms augurs a paradigmatic shift towards a more\naccessible, inclusive, and resilient educational framework in Afghanistan, with\nfar-reaching implications for socio-economic development. Through a meticulous\namalgamation of technology, policy, and collaborative endeavors, this article\nposits that Afghanistan stands on the cusp of an educational renaissance, with\nmobile learning platforms serving as a pivotal conduit toward this envisioned\nhorizon.",
            "author": [
                "Mursal Dawodi",
                "Jawid Ahmad Baktash",
                "Sayed Mohammad Reza Dawodi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01850v1",
                "http://arxiv.org/pdf/2311.01850v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01840v1",
            "title": "Spectral Clustering of Attributed Multi-relational Graphs",
            "updated": "2023-11-03T11:05:29Z",
            "published": "2023-11-03T11:05:29Z",
            "summary": "Graph clustering aims at discovering a natural grouping of the nodes such\nthat similar nodes are assigned to a common cluster. Many different algorithms\nhave been proposed in the literature: for simple graphs, for graphs with\nattributes associated to nodes, and for graphs where edges represent different\ntypes of relations among nodes. However, complex data in many domains can be\nrepresented as both attributed and multi-relational networks.\n  In this paper, we propose SpectralMix, a joint dimensionality reduction\ntechnique for multi-relational graphs with categorical node attributes.\nSpectralMix integrates all information available from the attributes, the\ndifferent types of relations, and the graph structure to enable a sound\ninterpretation of the clustering results. Moreover, it generalizes existing\ntechniques: it reduces to spectral embedding and clustering when only applied\nto a single graph and to homogeneity analysis when applied to categorical data.\nExperiments conducted on several real-world datasets enable us to detect\ndependencies between graph structure and categorical attributes, moreover, they\nexhibit the superiority of SpectralMix over existing methods.",
            "author": [
                "Ylli Sadikaj",
                "Yllka Velaj",
                "Sahar Behzadi",
                "Claudia Plant"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3447548.3467381",
                "http://arxiv.org/abs/2311.01840v1",
                "http://arxiv.org/pdf/2311.01840v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01832v1",
            "title": "On Hand-Held Grippers and the Morphological Gap in Human Manipulation\n  Demonstration",
            "updated": "2023-11-03T10:39:48Z",
            "published": "2023-11-03T10:39:48Z",
            "summary": "Collecting manipulation demonstrations with robotic hardware is tedious - and\nthus difficult to scale. Recording data on robot hardware ensures that it is in\nthe appropriate format for Learning from Demonstrations (LfD) methods. By\ncontrast, humans are proficient manipulators, and recording their actions would\nbe easy to scale, but it is challenging to use that data format with LfD\nmethods. The question we explore is whether there is a method to collect data\nin a format that can be used with LfD while retaining some of the attractive\nfeatures of recording human manipulation. We propose equipping humans with\nhand-held, hand-actuated parallel grippers and a head-mounted camera to record\ndemonstrations of manipulation tasks. Using customised and reproducible\ngrippers, we collect an initial dataset of common manipulation tasks. We show\nthat there are tasks that, against our initial intuition, can be performed\nusing parallel grippers. Qualitative insights are obtained regarding the impact\nof the difference in morphology on LfD by comparing the strategies used to\ncomplete tasks with human hands and grippers. Our data collection method\nbridges the gap between robot- and human-native manipulation demonstration. By\nmaking the design of our gripper prototype available, we hope to reduce other\nresearchers effort to collect manipulation data.",
            "author": [
                "Kiran Doshi",
                "Yijiang Huang",
                "Stelian Coros"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01832v1",
                "http://arxiv.org/pdf/2311.01832v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01831v1",
            "title": "Universal Multi-modal Multi-domain Pre-trained Recommendation",
            "updated": "2023-11-03T10:39:42Z",
            "published": "2023-11-03T10:39:42Z",
            "summary": "There is a rapidly-growing research interest in modeling user preferences via\npre-training multi-domain interactions for recommender systems. However,\nExisting pre-trained multi-domain recommendations mostly select the item texts\nto be bridges across domains, and simply explore the user behaviors in target\ndomains. Hence, they ignore other informative multi-modal item contents (e.g.,\nvisual information), and also lack of thorough consideration of user behaviors\nfrom all interactive domains. To address these issues, in this paper, we\npropose to pre-train universal multi-modal item content presentation for\nmulti-domain recommendation, called UniM^2Rec, which could smoothly learn the\nmulti-modal item content presentations and the multi-modal user preferences\nfrom all domains. With the pre-trained multi-domain recommendation model,\nUniM^2Rec could be efficiently and effectively transferred to new target\ndomains in practice. Extensive experiments conducted on five real-world\ndatasets in target domains demonstrate the superiority of the proposed method\nover existing competitive methods, especially for the real-world recommendation\nscenarios that usually struggle with seriously missing or noisy item contents.",
            "author": [
                "Wenqi Sun",
                "Ruobing Xie",
                "Shuqing Bian",
                "Wayne Xin Zhao",
                "Jie Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01831v1",
                "http://arxiv.org/pdf/2311.01831v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01830v1",
            "title": "Automated ab initio-accurate atomistic simulations of dissociated\n  dislocations",
            "updated": "2023-11-03T10:37:39Z",
            "published": "2023-11-03T10:37:39Z",
            "summary": "In (M Hodapp and A Shapeev 2020 Mach. Learn.: Sci. Technol. 1 045005), we\nhave proposed an algorithm that fully automatically trains machine-learning\ninteratomic potentials (MLIPs) during large-scale simulations, and successfully\napplied it to simulate screw dislocation motion in body-centered cubic\ntungsten. The algorithm identifies local subregions of the large-scale\nsimulation region where the potential extrapolates, and then constructs\nperiodic configurations of 100--200 atoms out of these non-periodic subregions\nthat can be efficiently computed with plane-wave Density Functional Theory\n(DFT) codes.\n  In this work, we extend this algorithm to dissociated dislocations with\narbitrary character angles and apply it to partial dislocations in\nface-centered cubic aluminum. Given the excellent agreement with available DFT\nreference results, we argue that our algorithm has the potential to become a\nuniversal way of simulating dissociated dislocations in face-centered cubic and\npossibly also other materials, such as hexagonal closed-packed magnesium, and\ntheir alloys. Moreover, it can be used to construct reliable training sets for\nMLIPs to be used in large-scale simulations of curved dislocations.",
            "author": [
                "Laura Mismetti",
                "Max Hodapp"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01830v1",
                "http://arxiv.org/pdf/2311.01830v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01829v1",
            "title": "Mix-ME: Quality-Diversity for Multi-Agent Learning",
            "updated": "2023-11-03T10:36:54Z",
            "published": "2023-11-03T10:36:54Z",
            "summary": "In many real-world systems, such as adaptive robotics, achieving a single,\noptimised solution may be insufficient. Instead, a diverse set of\nhigh-performing solutions is often required to adapt to varying contexts and\nrequirements. This is the realm of Quality-Diversity (QD), which aims to\ndiscover a collection of high-performing solutions, each with their own unique\ncharacteristics. QD methods have recently seen success in many domains,\nincluding robotics, where they have been used to discover damage-adaptive\nlocomotion controllers. However, most existing work has focused on single-agent\nsettings, despite many tasks of interest being multi-agent. To this end, we\nintroduce Mix-ME, a novel multi-agent variant of the popular MAP-Elites\nalgorithm that forms new solutions using a crossover-like operator by mixing\ntogether agents from different teams. We evaluate the proposed methods on a\nvariety of partially observable continuous control tasks. Our evaluation shows\nthat these multi-agent variants obtained by Mix-ME not only compete with\nsingle-agent baselines but also often outperform them in multi-agent settings\nunder partial observability.",
            "author": [
                "Gar\u00f0ar Ingvarsson",
                "Mikayel Samvelyan",
                "Bryan Lim",
                "Manon Flageat",
                "Antoine Cully",
                "Tim Rockt\u00e4schel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01829v1",
                "http://arxiv.org/pdf/2311.01829v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.MA",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01828v1",
            "title": "Unbiased Offline Evaluation for Learning to Rank with Business Rules",
            "updated": "2023-11-03T10:34:06Z",
            "published": "2023-11-03T10:34:06Z",
            "summary": "For industrial learning-to-rank (LTR) systems, it is common that the output\nof a ranking model is modified, either as a results of post-processing logic\nthat enforces business requirements, or as a result of unforeseen design flaws\nor bugs present in real-world production systems. This poses a challenge for\ndeploying off-policy learning and evaluation methods, as these often rely on\nthe assumption that rankings implied by the model's scores coincide with\ndisplayed items to the users. Further requirements for reliable offline\nevaluation are proper randomization and correct estimation of the propensities\nof displaying each item in any given position of the ranking, which are also\nimpacted by the aforementioned post-processing. We investigate empirically how\nthese scenarios impair off-policy evaluation for learning-to-rank models. We\nthen propose a novel correction method based on the Birkhoff-von-Neumann\ndecomposition that is robust to this type of post-processing. We obtain more\naccurate off-policy estimates in offline experiments, overcoming the problem of\npost-processed rankings. To the best of our knowledge this is the first study\non the impact of real-world business rules on offline evaluation of LTR models.",
            "author": [
                "Matej Jakimov",
                "Alexander Buchholz",
                "Yannik Stein",
                "Thorsten Joachims"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01828v1",
                "http://arxiv.org/pdf/2311.01828v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02127v1",
            "title": "A Systematic Review of Deep Graph Neural Networks: Challenges,\n  Classification, Architectures, Applications & Potential Utility in\n  Bioinformatics",
            "updated": "2023-11-03T10:25:47Z",
            "published": "2023-11-03T10:25:47Z",
            "summary": "In recent years, tasks of machine learning ranging from image processing &\naudio/video analysis to natural language understanding have been transformed by\ndeep learning. The data content in all these scenarios are expressed via\nEuclidean space. However, a considerable amount of application data is\nstructured in non-Euclidean space and is expressed as graphs, e.g. dealing with\ncomplicated interactions & object interdependencies. Modelling physical\nsystems, learning molecular signatures, identifying protein interactions and\npredicting diseases involve utilising a model that can adapt from graph data.\nGraph neural networks (GNNs), specified as artificial-neural models, employ\nmessage transmission between graph nodes to represent graph dependencies and\nare primarily used in the non-Euclidean domain. Variants of GNN like Graph\nRecurrent Networks (GRN), Graph Auto Encoder (GAE), Graph Convolution Networks\n(GCN), Graph Adversarial Methods & Graph Reinforcement learning have exhibited\nbreakthrough productivity on a wide range of tasks, especially in the field of\nbioinformatics, in recent years as a result of the rapid collection of\nbiological network data. Apart from presenting all existing GNN models,\nmathematical analysis and comparison of the variants of all types of GNN have\nbeen highlighted in this survey. Graph neural networks are investigated for\ntheir potential real-world applications in various fields, focusing on\nBioinformatics. Furthermore, resources for evaluating graph neural network\nmodels and accessing open-source code & benchmark data sets are included.\nUltimately, we provide some (seven) proposals for future research in this\nrapidly evolving domain. GNNs have the potential to be an excellent tool for\nsolving a wide range of biological challenges in bioinformatics research, as\nthey are best represented as connected complex graphs.",
            "author": [
                "Adil Mudasir Malla",
                "Asif Ali Banka"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02127v1",
                "http://arxiv.org/pdf/2311.02127v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01815v2",
            "title": "Estimating 3D Uncertainty Field: Quantifying Uncertainty for Neural\n  Radiance Fields",
            "updated": "2023-11-26T03:44:36Z",
            "published": "2023-11-03T09:47:53Z",
            "summary": "Current methods based on Neural Radiance Fields (NeRF) significantly lack the\ncapacity to quantify uncertainty in their predictions, particularly on the\nunseen space including the occluded and outside scene content. This limitation\nhinders their extensive applications in robotics, where the reliability of\nmodel predictions has to be considered for tasks such as robotic exploration\nand planning in unknown environments. To address this, we propose a novel\napproach to estimate a 3D Uncertainty Field based on the learned incomplete\nscene geometry, which explicitly identifies these unseen regions. By\nconsidering the accumulated transmittance along each camera ray, our\nUncertainty Field infers 2D pixel-wise uncertainty, exhibiting high values for\nrays directly casting towards occluded or outside the scene content. To\nquantify the uncertainty on the learned surface, we model a stochastic radiance\nfield. Our experiments demonstrate that our approach is the only one that can\nexplicitly reason about high uncertainty both on 3D unseen regions and its\ninvolved 2D rendered pixels, compared with recent methods. Furthermore, we\nillustrate that our designed uncertainty field is ideally suited for real-world\nrobotics tasks, such as next-best-view selection.",
            "author": [
                "Jianxiong Shen",
                "Ruijie Ren",
                "Adria Ruiz",
                "Francesc Moreno-Noguer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01815v2",
                "http://arxiv.org/pdf/2311.01815v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01811v1",
            "title": "DiffDub: Person-generic Visual Dubbing Using Inpainting Renderer with\n  Diffusion Auto-encoder",
            "updated": "2023-11-03T09:41:51Z",
            "published": "2023-11-03T09:41:51Z",
            "summary": "Generating high-quality and person-generic visual dubbing remains a\nchallenge. Recent innovation has seen the advent of a two-stage paradigm,\ndecoupling the rendering and lip synchronization process facilitated by\nintermediate representation as a conduit. Still, previous methodologies rely on\nrough landmarks or are confined to a single speaker, thus limiting their\nperformance. In this paper, we propose DiffDub: Diffusion-based dubbing. We\nfirst craft the Diffusion auto-encoder by an inpainting renderer incorporating\na mask to delineate editable zones and unaltered regions. This allows for\nseamless filling of the lower-face region while preserving the remaining parts.\nThroughout our experiments, we encountered several challenges. Primarily, the\nsemantic encoder lacks robustness, constricting its ability to capture\nhigh-level features. Besides, the modeling ignored facial positioning, causing\nmouth or nose jitters across frames. To tackle these issues, we employ\nversatile strategies, including data augmentation and supplementary eye\nguidance. Moreover, we encapsulated a conformer-based reference encoder and\nmotion generator fortified by a cross-attention mechanism. This enables our\nmodel to learn person-specific textures with varying references and reduces\nreliance on paired audio-visual data. Our rigorous experiments comprehensively\nhighlight that our ground-breaking approach outpaces existing methods with\nconsiderable margins and delivers seamless, intelligible videos in\nperson-generic and multilingual scenarios.",
            "author": [
                "Tao Liu",
                "Chenpeng Du",
                "Shuai Fan",
                "Feilong Chen",
                "Kai Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01811v1",
                "http://arxiv.org/pdf/2311.01811v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01807v1",
            "title": "Cross-modal Consistency Learning with Fine-grained Fusion Network for\n  Multimodal Fake News Detection",
            "updated": "2023-11-03T09:35:20Z",
            "published": "2023-11-03T09:35:20Z",
            "summary": "Previous studies on multimodal fake news detection have observed the mismatch\nbetween text and images in the fake news and attempted to explore the\nconsistency of multimodal news based on global features of different\nmodalities. However, they fail to investigate this relationship between\nfine-grained fragments in multimodal content. To gain public trust, fake news\noften includes relevant parts in the text and the image, making such multimodal\ncontent appear consistent. Using global features may suppress potential\ninconsistencies in irrelevant parts. Therefore, in this paper, we propose a\nnovel Consistency-learning Fine-grained Fusion Network (CFFN) that separately\nexplores the consistency and inconsistency from high-relevant and low-relevant\nword-region pairs. Specifically, for a multimodal post, we divide word-region\npairs into high-relevant and low-relevant parts based on their relevance\nscores. For the high-relevant part, we follow the cross-modal attention\nmechanism to explore the consistency. For low-relevant part, we calculate\ninconsistency scores to capture inconsistent points. Finally, a selection\nmodule is used to choose the primary clue (consistency or inconsistency) for\nidentifying the credibility of multimodal news. Extensive experiments on two\npublic datasets demonstrate that our CFFN substantially outperforms all the\nbaselines.",
            "author": [
                "Jun Li",
                "Yi Bin",
                "Jie Zou",
                "Jie Zou",
                "Guoqing Wang",
                "Yang Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01807v1",
                "http://arxiv.org/pdf/2311.01807v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01806v1",
            "title": "Sketching for Convex and Nonconvex Regularized Least Squares with Sharp\n  Guarantees",
            "updated": "2023-11-03T09:35:01Z",
            "published": "2023-11-03T09:35:01Z",
            "summary": "Randomized algorithms are important for solving large-scale optimization\nproblems. In this paper, we propose a fast sketching algorithm for least square\nproblems regularized by convex or nonconvex regularization functions, Sketching\nfor Regularized Optimization (SRO). Our SRO algorithm first generates a sketch\nof the original data matrix, then solves the sketched problem. Different from\nexisting randomized algorithms, our algorithm handles general Frechet\nsubdifferentiable regularization functions in an unified framework. We present\ngeneral theoretical result for the approximation error between the optimization\nresults of the original problem and the sketched problem for regularized least\nsquare problems which can be convex or nonconvex. For arbitrary convex\nregularizer, relative-error bound is proved for the approximation error.\nImportantly, minimax rates for sparse signal estimation by solving the sketched\nsparse convex or nonconvex learning problems are also obtained using our\ngeneral theoretical result under mild conditions. To the best of our knowledge,\nour results are among the first to demonstrate minimax rates for convex or\nnonconvex sparse learning problem by sketching under a unified theoretical\nframework. We further propose an iterative sketching algorithm which reduces\nthe approximation error exponentially by iteratively invoking the sketching\nalgorithm. Experimental results demonstrate the effectiveness of the proposed\nSRO and Iterative SRO algorithms.",
            "author": [
                "Yingzhen Yang",
                "Ping Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01806v1",
                "http://arxiv.org/pdf/2311.01806v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02126v1",
            "title": "PILL: Plug Into LLM with Adapter Expert and Attention Gate",
            "updated": "2023-11-03T09:31:10Z",
            "published": "2023-11-03T09:31:10Z",
            "summary": "Due to the remarkable capabilities of powerful Large Language Models (LLMs)\nin effectively following instructions, there has been a growing number of\nassistants in the community to assist humans. Recently, significant progress\nhas been made in the development of Vision Language Models (VLMs), expanding\nthe capabilities of LLMs and enabling them to execute more diverse\ninstructions. However, it is foreseeable that models will likely need to handle\ntasks involving additional modalities such as speech, video, and others. This\nposes a particularly prominent challenge of dealing with the complexity of\nmixed modalities. To address this, we introduce a novel architecture called\nPILL: Plug Into LLM with adapter expert and attention gate to better decouple\nthese complex modalities and leverage efficient fine-tuning. We introduce two\nmodules: Firstly, utilizing Mixture-of-Modality-Adapter-Expert to independently\nhandle different modalities, enabling better adaptation to downstream tasks\nwhile preserving the expressive capability of the original model. Secondly, by\nintroducing Modality-Attention-Gating, which enables adaptive control of the\ncontribution of modality tokens to the overall representation. In addition, we\nhave made improvements to the Adapter to enhance its learning and expressive\ncapabilities. Experimental results demonstrate that our approach exhibits\ncompetitive performance compared to other mainstream methods for modality\nfusion. For researchers interested in our work, we provide free access to the\ncode and models at https://github.com/DsaltYfish/PILL.",
            "author": [
                "Fangyuan Zhang",
                "Tingting Liang",
                "Zhengyuan Wu",
                "Yuyu Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02126v1",
                "http://arxiv.org/pdf/2311.02126v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01797v2",
            "title": "On the Generalization Properties of Diffusion Models",
            "updated": "2023-11-14T00:09:58Z",
            "published": "2023-11-03T09:20:20Z",
            "summary": "Diffusion models are a class of generative models that serve to establish a\nstochastic transport map between an empirically observed, yet unknown, target\ndistribution and a known prior. Despite their remarkable success in real-world\napplications, a theoretical understanding of their generalization capabilities\nremains underdeveloped. This work embarks on a comprehensive theoretical\nexploration of the generalization attributes of diffusion models. We establish\ntheoretical estimates of the generalization gap that evolves in tandem with the\ntraining dynamics of score-based diffusion models, suggesting a polynomially\nsmall generalization error ($O(n^{-2/5}+m^{-4/5})$) on both the sample size $n$\nand the model capacity $m$, evading the curse of dimensionality (i.e., not\nexponentially large in the data dimension) when early-stopped. Furthermore, we\nextend our quantitative analysis to a data-dependent scenario, wherein target\ndistributions are portrayed as a succession of densities with progressively\nincreasing distances between modes. This precisely elucidates the adverse\neffect of \"modes shift\" in ground truths on the model generalization. Moreover,\nthese estimates are not solely theoretical constructs but have also been\nconfirmed through numerical simulations. Our findings contribute to the\nrigorous understanding of diffusion models' generalization properties and\nprovide insights that may guide practical applications.",
            "author": [
                "Puheng Li",
                "Zhong Li",
                "Huishuai Zhang",
                "Jiang Bian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01797v2",
                "http://arxiv.org/pdf/2311.01797v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01796v1",
            "title": "Learning to Augment Distributions for Out-of-Distribution Detection",
            "updated": "2023-11-03T09:19:33Z",
            "published": "2023-11-03T09:19:33Z",
            "summary": "Open-world classification systems should discern out-of-distribution (OOD)\ndata whose labels deviate from those of in-distribution (ID) cases, motivating\nrecent studies in OOD detection. Advanced works, despite their promising\nprogress, may still fail in the open world, owing to the lack of knowledge\nabout unseen OOD data in advance. Although one can access auxiliary OOD data\n(distinct from unseen ones) for model training, it remains to analyze how such\nauxiliary data will work in the open world. To this end, we delve into such a\nproblem from a learning theory perspective, finding that the distribution\ndiscrepancy between the auxiliary and the unseen real OOD data is the key to\naffecting the open-world detection performance. Accordingly, we propose\nDistributional-Augmented OOD Learning (DAL), alleviating the OOD distribution\ndiscrepancy by crafting an OOD distribution set that contains all distributions\nin a Wasserstein ball centered on the auxiliary OOD distribution. We justify\nthat the predictor trained over the worst OOD data in the ball can shrink the\nOOD distribution discrepancy, thus improving the open-world detection\nperformance given only the auxiliary OOD data. We conduct extensive evaluations\nacross representative OOD detection setups, demonstrating the superiority of\nour DAL over its advanced counterparts.",
            "author": [
                "Qizhou Wang",
                "Zhen Fang",
                "Yonggang Zhang",
                "Feng Liu",
                "Yixuan Li",
                "Bo Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01796v1",
                "http://arxiv.org/pdf/2311.01796v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03384v1",
            "title": "Serious Games in Digital Gaming: A Comprehensive Review of Applications,\n  Game Engines and Advancements",
            "updated": "2023-11-03T09:17:09Z",
            "published": "2023-11-03T09:17:09Z",
            "summary": "Serious games are defined as applied games that focus on the gamification of\nan experience (e.g., learning and training activities) and are not strictly for\nentertainment purposes. In recent years, serious games have become increasingly\npopular due to their ability to simultaneously educate and entertain users. In\nthis review, we provide a comprehensive overview of the different types of\ndigital games and expand on the serious games genre while focusing on its\nvarious applications. Furthermore, we present the most widely used game engines\nused in the game development industry and extend the Unity game machine\nadvantages. Lastly, we conclude our research with a detailed comparison of the\ntwo most popular choices (Unreal and Unity engines) and their respective\nadvantages and disadvantages while providing future suggestions for serious\ndigital game development.",
            "author": [
                "Alexandros Gazis",
                "Eleftheria Katsiri"
            ],
            "link": [
                "http://dx.doi.org/10.37394/232018.2023.11.2",
                "http://arxiv.org/abs/2311.03384v1",
                "http://arxiv.org/pdf/2311.03384v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "K.6.3; C.5.2; C.5.3; C.5.5; C.5.m; C.5.0"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04924v1",
            "title": "Tuning-less Object Naming with a Foundation Model",
            "updated": "2023-11-03T09:11:49Z",
            "published": "2023-11-03T09:11:49Z",
            "summary": "We implement a real-time object naming system that enables learning a set of\nnamed entities never seen. Our approach employs an existing foundation model\nthat we consider ready to see anything before starting. It turns seen images\ninto relatively small feature vectors that we associate with index to a\ngradually built vocabulary without any training of fine-tuning of the model.\nOur contribution is using the association mechanism known from transformers as\nattention. It has features that support generalization from irrelevant\ninformation for distinguishing the entities and potentially enable associating\nwith much more than indices to vocabulary. As a result, the system can work in\na one-shot manner and correctly name objects named in different contents. We\nalso outline implementation details of the system modules integrated by a\nblackboard architecture. Finally, we investigate the system's quality, mainly\nhow many objects it can handle in this way.",
            "author": [
                "Andrej Lucny",
                "Pavel Petrovic"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04924v1",
                "http://arxiv.org/pdf/2311.04924v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01783v1",
            "title": "Neural SPDE solver for uncertainty quantification in high-dimensional\n  space-time dynamics",
            "updated": "2023-11-03T08:40:15Z",
            "published": "2023-11-03T08:40:15Z",
            "summary": "Historically, the interpolation of large geophysical datasets has been\ntackled using methods like Optimal Interpolation (OI) or model-based data\nassimilation schemes. However, the recent connection between Stochastic Partial\nDifferential Equations (SPDE) and Gaussian Markov Random Fields (GMRF)\nintroduced a novel approach to handle large datasets making use of sparse\nprecision matrices in OI. Recent advancements in deep learning also addressed\nthis issue by incorporating data assimilation into neural architectures: it\ntreats the reconstruction task as a joint learning problem involving both prior\nmodel and solver as neural networks. Though, it requires further developments\nto quantify the associated uncertainties. In our work, we leverage SPDEbased\nGaussian Processes to estimate complex prior models capable of handling\nnonstationary covariances in space and time. We develop a specific architecture\nable to learn both state and SPDE parameters as a neural SPDE solver, while\nproviding the precisionbased analytical form of the SPDE sampling. The latter\nis used as a surrogate model along the data assimilation window. Because the\nprior is stochastic, we can easily draw samples from it and condition the\nmembers by our neural solver, allowing flexible estimation of the posterior\ndistribution based on large ensemble. We demonstrate this framework on\nrealistic Sea Surface Height datasets. Our solution improves the OI baseline,\naligns with neural prior while enabling uncertainty quantification and online\nparameter estimation.",
            "author": [
                "Maxime Beauchamp",
                "Ronan Fablet",
                "Hugo Georgenthum"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01783v1",
                "http://arxiv.org/pdf/2311.01783v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02125v1",
            "title": "Using General Value Functions to Learn Domain-Backed Inventory\n  Management Policies",
            "updated": "2023-11-03T08:35:54Z",
            "published": "2023-11-03T08:35:54Z",
            "summary": "We consider the inventory management problem, where the goal is to balance\nconflicting objectives such as availability and wastage of a large range of\nproducts in a store. We propose a reinforcement learning (RL) approach that\nutilises General Value Functions (GVFs) to derive domain-backed inventory\nreplenishment policies. The inventory replenishment decisions are modelled as a\nsequential decision making problem, which is challenging due to uncertain\ndemand and the existence of aggregate (cross-product) constraints. In existing\nliterature, GVFs have primarily been used for auxiliary task learning. We use\nthis capability to train GVFs on domain-critical characteristics such as\nprediction of stock-out probability and wastage quantity. Using this domain\nexpertise for more effective exploration, we train an RL agent to compute the\ninventory replenishment quantities for a large range of products (up to 6000 in\nthe reported experiments), which share aggregate constraints such as the total\nweight/volume per delivery. Additionally, we show that the GVF predictions can\nbe used to provide additional domain-backed insights into the decisions\nproposed by the RL agent. Finally, since the environment dynamics are fully\ntransferred, the trained GVFs can be used for faster adaptation to vastly\ndifferent business objectives (for example, due to the start of a promotional\nperiod or due to deployment in a new customer environment).",
            "author": [
                "Durgesh Kalwar",
                "Omkar Shelke",
                "Harshad Khadilkar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02125v1",
                "http://arxiv.org/pdf/2311.02125v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01777v1",
            "title": "CheX-Nomaly: Segmenting Lung Abnormalities from Chest Radiographs using\n  Machine Learning",
            "updated": "2023-11-03T08:27:57Z",
            "published": "2023-11-03T08:27:57Z",
            "summary": "The global challenge in chest radiograph X-ray (CXR) abnormalities often\nbeing misdiagnosed is primarily associated with perceptual errors, where\nhealthcare providers struggle to accurately identify the location of\nabnormalities, rather than misclassification errors. We currently address this\nproblem through disease-specific segmentation models. Unfortunately, these\nmodels cannot be released in the field due to their lack of generalizability\nacross all thoracic diseases. A binary model tends to perform poorly when it\nencounters a disease that isn't represented in the dataset. We present\nCheX-nomaly: a binary localization U-net model that leverages transfer learning\ntechniques with the incorporation of an innovative contrastive learning\napproach. Trained on the VinDr-CXR dataset, which encompasses 14 distinct\ndiseases in addition to 'no finding' cases, my model achieves generalizability\nacross these 14 diseases and others it has not seen before. We show that we can\nsignificantly improve the generalizability of an abnormality localization model\nby incorporating a contrastive learning method and dissociating the bounding\nboxes with its disease class. We also introduce a new loss technique to apply\nto enhance the U-nets performance on bounding box segmentation. By introducing\nCheX-nomaly, we offer a promising solution to enhance the precision of chest\ndisease diagnosis, with a specific focus on reducing the significant number of\nperceptual errors in healthcare.",
            "author": [
                "Sanskriti Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01777v1",
                "http://arxiv.org/pdf/2311.01777v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01775v1",
            "title": "UP4LS: User Profile Constructed by Multiple Attributes for Enhancing\n  Linguistic Steganalysis",
            "updated": "2023-11-03T08:20:48Z",
            "published": "2023-11-03T08:20:48Z",
            "summary": "Linguistic steganalysis (LS) tasks aim to effectively detect stegos generated\nby linguistic steganography. Existing LS methods overlook the distinctive user\ncharacteristics, leading to weak performance in social networks. The limited\noccurrence of stegos further complicates detection. In this paper, we propose\nthe UP4LS, a novel framework with the User Profile for enhancing LS\nperformance. Specifically, by delving into post content, we explore user\nattributes like writing habits, psychological states, and focal areas, thereby\nbuilding the user profile for LS. For each attribute, we design the identified\nfeature extraction module. The extracted features are mapped to\nhigh-dimensional user features via deep-learning networks from existing\nmethods. Then the language model is employed to extract content features. The\nuser and content features are integrated to optimize feature representation.\nDuring the training phase, we prioritize the distribution of stegos.\nExperiments demonstrate that UP4LS can significantly enhance the performance of\nexisting methods, and an overall accuracy improvement of nearly 25%. In\nparticular, the improvement is especially pronounced with fewer stego samples.\nAdditionally, UP4LS also sets the stage for studies on related tasks,\nencouraging extensive applications on LS tasks.",
            "author": [
                "Yihao Wang",
                "Ruiqi Song",
                "Ru Zhang",
                "Jianyi Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01775v1",
                "http://arxiv.org/pdf/2311.01775v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01773v1",
            "title": "PDF: Point Diffusion Implicit Function for Large-scale Scene Neural\n  Representation",
            "updated": "2023-11-03T08:19:47Z",
            "published": "2023-11-03T08:19:47Z",
            "summary": "Recent advances in implicit neural representations have achieved impressive\nresults by sampling and fusing individual points along sampling rays in the\nsampling space. However, due to the explosively growing sampling space, finely\nrepresenting and synthesizing detailed textures remains a challenge for\nunbounded large-scale outdoor scenes. To alleviate the dilemma of using\nindividual points to perceive the entire colossal space, we explore learning\nthe surface distribution of the scene to provide structural priors and reduce\nthe samplable space and propose a Point Diffusion implicit Function, PDF, for\nlarge-scale scene neural representation. The core of our method is a\nlarge-scale point cloud super-resolution diffusion module that enhances the\nsparse point cloud reconstructed from several training images into a dense\npoint cloud as an explicit prior. Then in the rendering stage, only sampling\npoints with prior points within the sampling radius are retained. That is, the\nsampling space is reduced from the unbounded space to the scene surface.\nMeanwhile, to fill in the background of the scene that cannot be provided by\npoint clouds, the region sampling based on Mip-NeRF 360 is employed to model\nthe background representation. Expensive experiments have demonstrated the\neffectiveness of our method for large-scale scene novel view synthesis, which\noutperforms relevant state-of-the-art baselines.",
            "author": [
                "Yuhan Ding",
                "Fukun Yin",
                "Jiayuan Fan",
                "Hui Li",
                "Xin Chen",
                "Wen Liu",
                "Chongshan Lu",
                "Gang YU",
                "Tao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01773v1",
                "http://arxiv.org/pdf/2311.01773v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01771v2",
            "title": "Efficient Generalized Low-Rank Tensor Contextual Bandits",
            "updated": "2023-11-09T13:55:16Z",
            "published": "2023-11-03T08:12:05Z",
            "summary": "In this paper, we aim to build a novel bandits algorithm that is capable of\nfully harnessing the power of multi-dimensional data and the inherent\nnon-linearity of reward functions to provide high-usable and accountable\ndecision-making services. To this end, we introduce a generalized low-rank\ntensor contextual bandits model in which an action is formed from three feature\nvectors, and thus can be represented by a tensor. In this formulation, the\nreward is determined through a generalized linear function applied to the inner\nproduct of the action's feature tensor and a fixed but unknown parameter tensor\nwith a low tubal rank. To effectively achieve the trade-off between exploration\nand exploitation, we introduce a novel algorithm called \"Generalized Low-Rank\nTensor Exploration Subspace then Refine\" (G-LowTESTR). This algorithm first\ncollects raw data to explore the intrinsic low-rank tensor subspace information\nembedded in the decision-making scenario, and then converts the original\nproblem into an almost lower-dimensional generalized linear contextual bandits\nproblem. Rigorous theoretical analysis shows that the regret bound of\nG-LowTESTR is superior to those in vectorization and matricization cases. We\nconduct a series of simulations and real data experiments to further highlight\nthe effectiveness of G-LowTESTR, leveraging its ability to capitalize on the\nlow-rank tensor structure for enhanced learning.",
            "author": [
                "Qianxin Yi",
                "Yiyang Yang",
                "Shaojie Tang",
                "Yao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01771v2",
                "http://arxiv.org/pdf/2311.01771v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02124v1",
            "title": "Sliced Denoising: A Physics-Informed Molecular Pre-Training Method",
            "updated": "2023-11-03T07:58:05Z",
            "published": "2023-11-03T07:58:05Z",
            "summary": "While molecular pre-training has shown great potential in enhancing drug\ndiscovery, the lack of a solid physical interpretation in current methods\nraises concerns about whether the learned representation truly captures the\nunderlying explanatory factors in observed data, ultimately resulting in\nlimited generalization and robustness. Although denoising methods offer a\nphysical interpretation, their accuracy is often compromised by ad-hoc noise\ndesign, leading to inaccurate learned force fields. To address this limitation,\nthis paper proposes a new method for molecular pre-training, called sliced\ndenoising (SliDe), which is based on the classical mechanical intramolecular\npotential theory. SliDe utilizes a novel noise strategy that perturbs bond\nlengths, angles, and torsion angles to achieve better sampling over\nconformations. Additionally, it introduces a random slicing approach that\ncircumvents the computationally expensive calculation of the Jacobian matrix,\nwhich is otherwise essential for estimating the force field. By aligning with\nphysical principles, SliDe shows a 42\\% improvement in the accuracy of\nestimated force fields compared to current state-of-the-art denoising methods,\nand thus outperforms traditional baselines on various molecular property\nprediction tasks.",
            "author": [
                "Yuyan Ni",
                "Shikun Feng",
                "Wei-Ying Ma",
                "Zhi-Ming Ma",
                "Yanyan Lan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02124v1",
                "http://arxiv.org/pdf/2311.02124v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01762v1",
            "title": "Solving Kernel Ridge Regression with Gradient Descent for a Non-Constant\n  Kernel",
            "updated": "2023-11-03T07:43:53Z",
            "published": "2023-11-03T07:43:53Z",
            "summary": "Kernel ridge regression, KRR, is a generalization of linear ridge regression\nthat is non-linear in the data, but linear in the parameters. The solution can\nbe obtained either as a closed-form solution, which includes a matrix\ninversion, or iteratively through gradient descent. Using the iterative\napproach opens up for changing the kernel during training, something that is\ninvestigated in this paper. We theoretically address the effects this has on\nmodel complexity and generalization. Based on our findings, we propose an\nupdate scheme for the bandwidth of translational-invariant kernels, where we\nlet the bandwidth decrease to zero during training, thus circumventing the need\nfor hyper-parameter selection. We demonstrate on real and synthetic data how\ndecreasing the bandwidth during training outperforms using a constant\nbandwidth, selected by cross-validation and marginal likelihood maximization.\nWe also show theoretically and empirically that using a decreasing bandwidth,\nwe are able to achieve both zero training error in combination with good\ngeneralization, and a double descent behavior, phenomena that do not occur for\nKRR with constant bandwidth but are known to appear for neural networks.",
            "author": [
                "Oskar Allerbo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01762v1",
                "http://arxiv.org/pdf/2311.01762v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.OC",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.02173v1",
            "title": "TailorMe: Self-Supervised Learning of an Anatomically Constrained\n  Volumetric Human Shape Model",
            "updated": "2023-11-03T07:42:19Z",
            "published": "2023-11-03T07:42:19Z",
            "summary": "Human shape spaces have been extensively studied, as they are a core element\nof human shape and pose inference tasks. Classic methods for creating a human\nshape model register a surface template mesh to a database of 3D scans and use\ndimensionality reduction techniques, such as Principal Component Analysis, to\nlearn a compact representation. While these shape models enable global shape\nmodifications by correlating anthropometric measurements with the learned\nsubspace, they only provide limited localized shape control. We instead\nregister a volumetric anatomical template, consisting of skeleton bones and\nsoft tissue, to the surface scans of the CAESAR database. We further enlarge\nour training data to the full Cartesian product of all skeletons and all soft\ntissues using physically plausible volumetric deformation transfer. This data\nis then used to learn an anatomically constrained volumetric human shape model\nin a self-supervised fashion. The resulting TailorMe model enables shape\nsampling, localized shape manipulation, and fast inference from given surface\nscans.",
            "author": [
                "Stephan Wenninger",
                "Fabian Kemper",
                "Ulrich Schwanecke",
                "Mario Botsch"
            ],
            "link": [
                "http://arxiv.org/abs/2312.02173v1",
                "http://arxiv.org/pdf/2312.02173v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "I.3.0; I.5.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02123v1",
            "title": "RigLSTM: Recurrent Independent Grid LSTM for Generalizable Sequence\n  Learning",
            "updated": "2023-11-03T07:40:06Z",
            "published": "2023-11-03T07:40:06Z",
            "summary": "Sequential processes in real-world often carry a combination of simple\nsubsystems that interact with each other in certain forms. Learning such a\nmodular structure can often improve the robustness against environmental\nchanges. In this paper, we propose recurrent independent Grid LSTM (RigLSTM),\ncomposed of a group of independent LSTM cells that cooperate with each other,\nfor exploiting the underlying modular structure of the target task. Our model\nadopts cell selection, input feature selection, hidden state selection, and\nsoft state updating to achieve a better generalization ability on the basis of\nthe recent Grid LSTM for the tasks where some factors differ between training\nand evaluation. Specifically, at each time step, only a fraction of cells are\nactivated, and the activated cells select relevant inputs and cells to\ncommunicate with. At the end of one time step, the hidden states of the\nactivated cells are updated by considering the relevance between the inputs and\nthe hidden states from the last and current time steps. Extensive experiments\non diversified sequential modeling tasks are conducted to show the superior\ngeneralization ability when there exist changes in the testing environment.\nSource code is available at \\url{https://github.com/ziyuwwang/rig-lstm}.",
            "author": [
                "Ziyu Wang",
                "Wenhao Jiang",
                "Zixuan Zhang",
                "Wei Tang",
                "Junchi Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02123v1",
                "http://arxiv.org/pdf/2311.02123v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01759v1",
            "title": "TinyFormer: Efficient Transformer Design and Deployment on Tiny Devices",
            "updated": "2023-11-03T07:34:47Z",
            "published": "2023-11-03T07:34:47Z",
            "summary": "Developing deep learning models on tiny devices (e.g. Microcontroller units,\nMCUs) has attracted much attention in various embedded IoT applications.\nHowever, it is challenging to efficiently design and deploy recent advanced\nmodels (e.g. transformers) on tiny devices due to their severe hardware\nresource constraints. In this work, we propose TinyFormer, a framework\nspecifically designed to develop and deploy resource-efficient transformers on\nMCUs. TinyFormer mainly consists of SuperNAS, SparseNAS and SparseEngine.\nSeparately, SuperNAS aims to search for an appropriate supernet from a vast\nsearch space. SparseNAS evaluates the best sparse single-path model including\ntransformer architecture from the identified supernet. Finally, SparseEngine\nefficiently deploys the searched sparse models onto MCUs. To the best of our\nknowledge, SparseEngine is the first deployment framework capable of performing\ninference of sparse models with transformer on MCUs. Evaluation results on the\nCIFAR-10 dataset demonstrate that TinyFormer can develop efficient transformers\nwith an accuracy of $96.1\\%$ while adhering to hardware constraints of $1$MB\nstorage and $320$KB memory. Additionally, TinyFormer achieves significant\nspeedups in sparse inference, up to $12.2\\times$, when compared to the CMSIS-NN\nlibrary. TinyFormer is believed to bring powerful transformers into TinyML\nscenarios and greatly expand the scope of deep learning applications.",
            "author": [
                "Jianlei Yang",
                "Jiacheng Liao",
                "Fanding Lei",
                "Meichen Liu",
                "Junyi Chen",
                "Lingkun Long",
                "Han Wan",
                "Bei Yu",
                "Weisheng Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01759v1",
                "http://arxiv.org/pdf/2311.01759v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01757v1",
            "title": "Indo LEGO-ABSA: A Multitask Generative Aspect Based Sentiment Analysis\n  for Indonesian Language",
            "updated": "2023-11-03T07:28:12Z",
            "published": "2023-11-03T07:28:12Z",
            "summary": "Aspect-based sentiment analysis is a method in natural language processing\naimed at identifying and understanding sentiments related to specific aspects\nof an entity. Aspects are words or phrases that represent an aspect or\nattribute of a particular entity. Previous research has utilized generative\npre-trained language models to perform aspect-based sentiment analysis.\nLEGO-ABSA is one framework that has successfully employed generative\npre-trained language models in aspect-based sentiment analysis, particularly in\nEnglish. LEGO-ABSA uses a multitask learning and prompting approach to enhance\nmodel performance. However, the application of this approach has not been done\nin the context of Bahasa Indonesia. Therefore, this research aims to implement\nthe multitask learning and prompting approach in aspect-based sentiment\nanalysis for Bahasa Indonesia using generative pre-trained language models. In\nthis study, the Indo LEGO-ABSA model is developed, which is an aspect-based\nsentiment analysis model utilizing generative pre-trained language models and\ntrained with multitask learning and prompting. Indo LEGO-ABSA is trained with a\nhotel domain dataset in the Indonesian language. The obtained results include\nan f1-score of 79.55% for the Aspect Sentiment Triplet Extraction task, 86.09%\nfor Unified Aspect-based Sentiment Analysis, 79.85% for Aspect Opinion Pair\nExtraction, 87.45% for Aspect Term Extraction, and 88.09% for Opinion Term\nExtraction. Indo LEGO-ABSA adopts the LEGO-ABSA framework that employs the T5\nmodel, specifically mT5, by applying multitask learning to train all tasks\nwithin aspect-based sentiment analysis.",
            "author": [
                "Randy Zakya Suchrady",
                "Ayu Purwarianti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01757v1",
                "http://arxiv.org/pdf/2311.01757v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01753v1",
            "title": "RiskQ: Risk-sensitive Multi-Agent Reinforcement Learning Value\n  Factorization",
            "updated": "2023-11-03T07:18:36Z",
            "published": "2023-11-03T07:18:36Z",
            "summary": "Multi-agent systems are characterized by environmental uncertainty, varying\npolicies of agents, and partial observability, which result in significant\nrisks. In the context of Multi-Agent Reinforcement Learning (MARL), learning\ncoordinated and decentralized policies that are sensitive to risk is\nchallenging. To formulate the coordination requirements in risk-sensitive MARL,\nwe introduce the Risk-sensitive Individual-Global-Max (RIGM) principle as a\ngeneralization of the Individual-Global-Max (IGM) and Distributional IGM (DIGM)\nprinciples. This principle requires that the collection of risk-sensitive\naction selections of each agent should be equivalent to the risk-sensitive\naction selection of the central policy. Current MARL value factorization\nmethods do not satisfy the RIGM principle for common risk metrics such as the\nValue at Risk (VaR) metric or distorted risk measurements. Therefore, we\npropose RiskQ to address this limitation, which models the joint return\ndistribution by modeling quantiles of it as weighted quantile mixtures of\nper-agent return distribution utilities. RiskQ satisfies the RIGM principle for\nthe VaR and distorted risk metrics. We show that RiskQ can obtain promising\nperformance through extensive experiments. The source code of RiskQ is\navailable in https://github.com/xmu-rl-3dv/RiskQ.",
            "author": [
                "Siqi Shen",
                "Chennan Ma",
                "Chao Li",
                "Weiquan Liu",
                "Yongquan Fu",
                "Songzhu Mei",
                "Xinwang Liu",
                "Cheng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01753v1",
                "http://arxiv.org/pdf/2311.01753v1"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01749v1",
            "title": "Epidemic Decision-making System Based Federated Reinforcement Learning",
            "updated": "2023-11-03T06:57:41Z",
            "published": "2023-11-03T06:57:41Z",
            "summary": "Epidemic decision-making can effectively help the government to\ncomprehensively consider public security and economic development to respond to\npublic health and safety emergencies. Epidemic decision-making can effectively\nhelp the government to comprehensively consider public security and economic\ndevelopment to respond to public health and safety emergencies. Some studies\nhave shown that intensive learning can effectively help the government to make\nepidemic decision, thus achieving the balance between health security and\neconomic development. Some studies have shown that intensive learning can\neffectively help the government to make epidemic decision, thus achieving the\nbalance between health security and economic development. However, epidemic\ndata often has the characteristics of limited samples and high privacy.\nHowever, epidemic data often has the characteristics of limited samples and\nhigh privacy. This model can combine the epidemic situation data of various\nprovinces for cooperative training to use as an enhanced learning model for\nepidemic situation decision, while protecting the privacy of data. The\nexperiment shows that the enhanced federated learning can obtain more optimized\nperformance and return than the enhanced learning, and the enhanced federated\nlearning can also accelerate the training convergence speed of the training\nmodel. accelerate the training convergence speed of the client. At the same\ntime, through the experimental comparison, A2C is the most suitable\nreinforcement learning model for the epidemic situation decision-making.\nlearning model for the epidemic situation decision-making scenario, followed by\nthe PPO model, and the performance of DDPG is unsatisfactory.",
            "author": [
                "Yangxi Zhou",
                "Junping Du",
                "Zhe Xue",
                "Zhenhui Pan",
                "Weikang Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01749v1",
                "http://arxiv.org/pdf/2311.01749v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01744v1",
            "title": "Data-Centric Long-Tailed Image Recognition",
            "updated": "2023-11-03T06:34:37Z",
            "published": "2023-11-03T06:34:37Z",
            "summary": "In the context of the long-tail scenario, models exhibit a strong demand for\nhigh-quality data. Data-centric approaches aim to enhance both the quantity and\nquality of data to improve model performance. Among these approaches,\ninformation augmentation has been progressively introduced as a crucial\ncategory. It achieves a balance in model performance by augmenting the richness\nand quantity of samples in the tail classes. However, there is currently a lack\nof research into the underlying mechanisms explaining the effectiveness of\ninformation augmentation methods. Consequently, the utilization of information\naugmentation in long-tail recognition tasks relies heavily on empirical and\nintricate fine-tuning. This work makes two primary contributions. Firstly, we\napproach the problem from the perspectives of feature diversity and\ndistribution shift, introducing the concept of Feature Diversity Gain (FDG) to\nelucidate why information augmentation is effective. We find that the\nperformance of information augmentation can be explained by FDG, and its\nperformance peaks when FDG achieves an appropriate balance. Experimental\nresults demonstrate that by using FDG to select augmented data, we can further\nenhance model performance without the need for any modifications to the model's\narchitecture. Thus, data-centric approaches hold significant potential in the\nfield of long-tail recognition, beyond the development of new model structures.\nFurthermore, we systematically introduce the core components and fundamental\ntasks of a data-centric long-tail learning framework for the first time. These\ncore components guide the implementation and deployment of the system, while\nthe corresponding fundamental tasks refine and expand the research area.",
            "author": [
                "Yanbiao Ma",
                "Licheng Jiao",
                "Fang Liu",
                "Shuyuan Yang",
                "Xu Liu",
                "Puhua Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01744v1",
                "http://arxiv.org/pdf/2311.01744v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01743v1",
            "title": "Energy Efficiency Optimization for Subterranean LoRaWAN Using A\n  Reinforcement Learning Approach: A Direct-to-Satellite Scenario",
            "updated": "2023-11-03T06:33:56Z",
            "published": "2023-11-03T06:33:56Z",
            "summary": "The integration of subterranean LoRaWAN and non-terrestrial networks (NTN)\ndelivers substantial economic and societal benefits in remote agriculture and\ndisaster rescue operations. The LoRa modulation leverages quasi-orthogonal\nspreading factors (SFs) to optimize data rates, airtime, coverage and energy\nconsumption. However, it is still challenging to effectively assign SFs to end\ndevices for minimizing co-SF interference in massive subterranean LoRaWAN NTN.\nTo address this, we investigate a reinforcement learning (RL)-based SFs\nallocation scheme to optimize the system's energy efficiency (EE). To\nefficiently capture the device-to-environment interactions in dense networks,\nwe proposed an SFs allocation technique using the multi-agent dueling double\ndeep Q-network (MAD3QN) and the multi-agent advantage actor-critic (MAA2C)\nalgorithms based on an analytical reward mechanism. Our proposed RL-based SFs\nallocation approach evinces better performance compared to four benchmarks in\nthe extreme underground direct-to-satellite scenario. Remarkably, MAD3QN shows\npromising potentials in surpassing MAA2C in terms of convergence rate and EE.",
            "author": [
                "Kaiqiang Lin",
                "Muhammad Asad Ullah",
                "Hirley Alves",
                "Konstantin Mikhaylov",
                "Tong Hao"
            ],
            "link": [
                "http://dx.doi.org/10.1109/LWC.2023.3327833",
                "http://arxiv.org/abs/2311.01743v1",
                "http://arxiv.org/pdf/2311.01743v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.AI",
                "cs.LG",
                "cs.NI",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01742v1",
            "title": "Global Optimization: A Machine Learning Approach",
            "updated": "2023-11-03T06:33:38Z",
            "published": "2023-11-03T06:33:38Z",
            "summary": "Many approaches for addressing Global Optimization problems typically rely on\nrelaxations of nonlinear constraints over specific mathematical primitives.\nThis is restricting in applications with constraints that are black-box,\nimplicit or consist of more general primitives. Trying to address such\nlimitations, Bertsimas and Ozturk (2023) proposed OCTHaGOn as a way of solving\nblack-box global optimization problems by approximating the nonlinear\nconstraints using hyperplane-based Decision-Trees and then using those trees to\nconstruct a unified mixed integer optimization (MIO) approximation of the\noriginal problem. We provide extensions to this approach, by (i) approximating\nthe original problem using other MIO-representable ML models besides Decision\nTrees, such as Gradient Boosted Trees, Multi Layer Perceptrons and Suport\nVector Machines, (ii) proposing adaptive sampling procedures for more accurate\nmachine learning-based constraint approximations, (iii) utilizing robust\noptimization to account for the uncertainty of the sample-dependent training of\nthe ML models, and (iv) leveraging a family of relaxations to address the\ninfeasibilities of the final MIO approximation. We then test the enhanced\nframework in 81 Global Optimization instances. We show improvements in solution\nfeasibility and optimality in the majority of instances. We also compare\nagainst BARON, showing improved optimality gaps or solution times in 11\ninstances.",
            "author": [
                "Dimitris Bertsimas",
                "Georgios Margaritis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01742v1",
                "http://arxiv.org/pdf/2311.01742v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01739v2",
            "title": "Efficient Algorithms for Monte Carlo Particle Transport on AI\n  Accelerator Hardware",
            "updated": "2023-11-07T03:22:56Z",
            "published": "2023-11-03T06:27:36Z",
            "summary": "The recent trend toward deep learning has led to the development of a variety\nof highly innovative AI accelerator architectures. One such architecture, the\nCerebras Wafer-Scale Engine 2 (WSE-2), features 40 GB of on-chip SRAM, making\nit a potentially attractive platform for latency- or bandwidth-bound HPC\nsimulation workloads. In this study, we examine the feasibility of performing\ncontinuous energy Monte Carlo (MC) particle transport on the WSE-2 by porting a\nkey kernel from the MC transport algorithm to Cerebras's CSL programming model.\nNew algorithms for minimizing communication costs and for handling load\nbalancing are developed and tested. The WSE-2 is found to run 130 times faster\nthan a highly optimized CUDA version of the kernel run on an NVIDIA A100 GPU --\nsignificantly outpacing the expected performance increase given the difference\nin transistor counts between the architectures.",
            "author": [
                "John Tramm",
                "Bryce Allen",
                "Kazutomo Yoshii",
                "Andrew Siegel",
                "Leighton Wilson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01739v2",
                "http://arxiv.org/pdf/2311.01739v2"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.PF",
                "D.1.3; J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01734v1",
            "title": "MixCon3D: Synergizing Multi-View and Cross-Modal Contrastive Learning\n  for Enhancing 3D Representation",
            "updated": "2023-11-03T06:05:36Z",
            "published": "2023-11-03T06:05:36Z",
            "summary": "Contrastive learning has emerged as a promising paradigm for 3D open-world\nunderstanding, jointly with text, image, and point cloud. In this paper, we\nintroduce MixCon3D, which combines the complementary information between 2D\nimages and 3D point clouds to enhance contrastive learning. With the further\nintegration of multi-view 2D images, MixCon3D enhances the traditional\ntri-modal representation by offering a more accurate and comprehensive\ndepiction of real-world 3D objects and bolstering text alignment. Additionally,\nwe pioneer the first thorough investigation of various training recipes for the\n3D contrastive learning paradigm, building a solid baseline with improved\nperformance. Extensive experiments conducted on three representative benchmarks\nreveal that our method renders significant improvement over the baseline,\nsurpassing the previous state-of-the-art performance on the challenging\n1,156-category Objaverse-LVIS dataset by 5.7%. We further showcase the\neffectiveness of our approach in more applications, including text-to-3D\nretrieval and point cloud captioning. The code is available at\nhttps://github.com/UCSC-VLAA/MixCon3D.",
            "author": [
                "Yipeng Gao",
                "Zeyu Wang",
                "Wei-Shi Zheng",
                "Cihang Xie",
                "Yuyin Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01734v1",
                "http://arxiv.org/pdf/2311.01734v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01732v2",
            "title": "Proto-lm: A Prototypical Network-Based Framework for Built-in\n  Interpretability in Large Language Models",
            "updated": "2023-11-12T04:28:43Z",
            "published": "2023-11-03T05:55:32Z",
            "summary": "Large Language Models (LLMs) have significantly advanced the field of Natural\nLanguage Processing (NLP), but their lack of interpretability has been a major\nconcern. Current methods for interpreting LLMs are post hoc, applied after\ninference time, and have limitations such as their focus on low-level features\nand lack of explainability at higher level text units. In this work, we\nintroduce proto-lm, a prototypical network-based white-box framework that\nallows LLMs to learn immediately interpretable embeddings during the\nfine-tuning stage while maintaining competitive performance. Our method's\napplicability and interpretability are demonstrated through experiments on a\nwide range of NLP tasks, and our results indicate a new possibility of creating\ninterpretable models without sacrificing performance. This novel approach to\ninterpretability in LLMs can pave the way for more interpretable models without\nthe need to sacrifice performance.",
            "author": [
                "Sean Xie",
                "Soroush Vosoughi",
                "Saeed Hassanpour"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01732v2",
                "http://arxiv.org/pdf/2311.01732v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01731v1",
            "title": "Capturing Local and Global Features in Medical Images by Using Ensemble\n  CNN-Transformer",
            "updated": "2023-11-03T05:55:28Z",
            "published": "2023-11-03T05:55:28Z",
            "summary": "This paper introduces a groundbreaking classification model called the\nControllable Ensemble Transformer and CNN (CETC) for the analysis of medical\nimages. The CETC model combines the powerful capabilities of convolutional\nneural networks (CNNs) and transformers to effectively capture both local and\nglobal features present in medical images. The model architecture comprises\nthree main components: a convolutional encoder block (CEB), a\ntransposed-convolutional decoder block (TDB), and a transformer classification\nblock (TCB). The CEB is responsible for capturing multi-local features at\ndifferent scales and draws upon components from VGGNet, ResNet, and MobileNet\nas backbones. By leveraging this combination, the CEB is able to effectively\ndetect and encode local features. The TDB, on the other hand, consists of\nsub-decoders that decode and sum the captured features using ensemble\ncoefficients. This enables the model to efficiently integrate the information\nfrom multiple scales. Finally, the TCB utilizes the SwT backbone and a\nspecially designed prediction head to capture global features, ensuring a\ncomprehensive understanding of the entire image. The paper provides detailed\ninformation on the experimental setup and implementation, including the use of\ntransfer learning, data preprocessing techniques, and training settings. The\nCETC model is trained and evaluated using two publicly available COVID-19\ndatasets. Remarkably, the model outperforms existing state-of-the-art models\nacross various evaluation metrics. The experimental results clearly demonstrate\nthe superiority of the CETC model, emphasizing its potential for accurately and\nefficiently analyzing medical images.",
            "author": [
                "Javad Mirzapour Kaleybar",
                "Hooman Saadat",
                "Hooman Khaloo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01731v1",
                "http://arxiv.org/pdf/2311.01731v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01729v2",
            "title": "CDGraph: Dual Conditional Social Graph Synthesizing via Diffusion Model",
            "updated": "2023-11-06T02:19:09Z",
            "published": "2023-11-03T05:54:07Z",
            "summary": "The social graphs synthesized by the generative models are increasingly in\ndemand due to data scarcity and concerns over user privacy. One of the key\nperformance criteria for generating social networks is the fidelity to\nspecified conditionals, such as users with certain membership and financial\nstatus. While recent diffusion models have shown remarkable performance in\ngenerating images, their effectiveness in synthesizing graphs has not yet been\nexplored in the context of conditional social graphs. In this paper, we propose\nthe first kind of conditional diffusion model for social networks, CDGraph,\nwhich trains and synthesizes graphs based on two specified conditions. We\npropose the co-evolution dependency in the denoising process of CDGraph to\ncapture the mutual dependencies between the dual conditions and further\nincorporate social homophily and social contagion to preserve the connectivity\nbetween nodes while satisfying the specified conditions. Moreover, we introduce\na novel classifier loss, which guides the training of the diffusion process\nthrough the mutual dependency of dual conditions. We evaluate CDGraph against\nfour existing graph generative methods, i.e., SPECTRE, GSM, EDGE, and DiGress,\non four datasets. Our results show that the generated graphs from CDGraph\nachieve much higher dual-conditional validity and lower discrepancy in various\nsocial network metrics than the baselines, thus demonstrating its proficiency\nin generating dual-conditional social graphs.",
            "author": [
                "Jui-Yi Tsai",
                "Ya-Wen Teng",
                "Ho Chiok Yew",
                "De-Nian Yang",
                "Lydia Y. Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01729v2",
                "http://arxiv.org/pdf/2311.01729v2"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01728v1",
            "title": "RDE: A Hybrid Policy Framework for Multi-Agent Path Finding Problem",
            "updated": "2023-11-03T05:52:40Z",
            "published": "2023-11-03T05:52:40Z",
            "summary": "Multi-agent path finding (MAPF) is an abstract model for the navigation of\nmultiple robots in warehouse automation, where multiple robots plan\ncollision-free paths from the start to goal positions. Reinforcement learning\n(RL) has been employed to develop partially observable distributed MAPF\npolicies that can be scaled to any number of agents. However, RL-based MAPF\npolicies often get agents stuck in deadlock due to warehouse automation's dense\nand structured obstacles. This paper proposes a novel hybrid MAPF policy, RDE,\nbased on switching among the RL-based MAPF policy, the Distance heat map\n(DHM)-based policy and the Escape policy. The RL-based policy is used for\ncoordination among agents. In contrast, when no other agents are in the agent's\nfield of view, it can get the next action by querying the DHM. The escape\npolicy that randomly selects valid actions can help agents escape the deadlock.\nWe conduct simulations on warehouse-like structured grid maps using\nstate-of-the-art RL-based MAPF policies (DHC and DCC), which show that RDE can\nsignificantly improve their performance.",
            "author": [
                "Jianqi Gao",
                "Yanjie Li",
                "Xiaoqing Yang",
                "Mingshan Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01728v1",
                "http://arxiv.org/pdf/2311.01728v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01727v1",
            "title": "Flexible Error Mitigation of Quantum Processes with Data Augmentation\n  Empowered Neural Model",
            "updated": "2023-11-03T05:52:14Z",
            "published": "2023-11-03T05:52:14Z",
            "summary": "Neural networks have shown their effectiveness in various tasks in the realm\nof quantum computing. However, their application in quantum error mitigation, a\ncrucial step towards realizing practical quantum advancements, has been\nrestricted by reliance on noise-free statistics. To tackle this critical\nchallenge, we propose a data augmentation empowered neural model for error\nmitigation (DAEM). Our model does not require any prior knowledge about the\nspecific noise type and measurement settings and can estimate noise-free\nstatistics solely from the noisy measurement results of the target quantum\nprocess, rendering it highly suitable for practical implementation. In\nnumerical experiments, we show the model's superior performance in mitigating\nvarious types of noise, including Markovian noise and Non-Markovian noise,\ncompared with previous error mitigation methods. We further demonstrate its\nversatility by employing the model to mitigate errors in diverse types of\nquantum processes, including those involving large-scale quantum systems and\ncontinuous-variable quantum states. This powerful data augmentation-empowered\nneural model for error mitigation establishes a solid foundation for realizing\nmore reliable and robust quantum technologies in practical applications.",
            "author": [
                "Manwen Liao",
                "Yan Zhu",
                "Giulio Chiribella",
                "Yuxiang Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01727v1",
                "http://arxiv.org/pdf/2311.01727v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02120v1",
            "title": "Static Virus Spread Algorithm for DNA Sequence Design",
            "updated": "2023-11-03T05:47:00Z",
            "published": "2023-11-03T05:47:00Z",
            "summary": "DNA is not only the genetic material of life, but also a favorable material\nfor a new computing model. Various research works based on DNA computing have\nbeen carried out in recent years. DNA sequence design is the foundation of such\nresearch. The sequence quality directly affects the universality, robustness,\nand stability of DNA computing. How to design DNA sequences depends on the\nbiological properties and target requirements, which is a typical combinatorial\noptimization problem. In this paper, in order to design DNA sequences with\nhigh-quality, we propose a novel meta-heuristic evolutionary algorithm, termed\nthe static virus spread algorithm (SVS). Through this algorithm, we focus on\nthe constraints of universal DNA sequence design and produce a large number of\nDNA sequences with non-complementarity and small difference in melting\ntemperature as the objectives, and fully considering the balanced proportion of\nthe four bases. The computer simulation and polyacrylamide gel electrophoresis\nexperiments show that the high-quality DNA sequences designed by this algorithm\nare effective, which is expected to provide a convenient tool for sequence\npreparation before DNA biochemical operations.",
            "author": [
                "Yao Yao",
                "Xun Zhang",
                "Xin Liu",
                "Yuan Liu",
                "Xiaokang Zhang",
                "Qiang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02120v1",
                "http://arxiv.org/pdf/2311.02120v1"
            ],
            "primary_category": "cs.ET",
            "category": [
                "cs.ET",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01723v3",
            "title": "Towards Calibrated Robust Fine-Tuning of Vision-Language Models",
            "updated": "2023-11-30T00:07:54Z",
            "published": "2023-11-03T05:41:25Z",
            "summary": "While fine-tuning unlocks the potential of a pre-trained model for a specific\ntask, it compromises the model's ability to generalize to out-of-distribution\n(OOD) datasets. To mitigate this, robust fine-tuning aims to ensure performance\non OOD datasets as well as on an in-distribution (ID) dataset for which the\nmodel is being tuned. However, another criterion for reliable machine learning\n(ML), confidence calibration, has been overlooked despite its increasing demand\nfor real-world high-stakes ML applications (e.g., autonomous driving and\nmedical diagnosis). For the first time, we raise concerns about the calibration\nof fine-tuned vision-language models (VLMs) under distribution shift by showing\nthat naive fine-tuning and even state-of-the-art robust fine-tuning methods\nhurt the calibration of pre-trained VLMs, especially on OOD datasets. To\naddress this issue, we provide a simple approach, called calibrated robust\nfine-tuning (CaRot), that incentivizes calibration and robustness on both ID\nand OOD datasets. Empirical results on ImageNet-1K distribution shift\nevaluation verify the effectiveness of our method.",
            "author": [
                "Changdae Oh",
                "Mijoo Kim",
                "Hyesu Lim",
                "Junhyeok Park",
                "Euiseog Jeong",
                "Zhi-Qi Cheng",
                "Kyungwoo Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01723v3",
                "http://arxiv.org/pdf/2311.01723v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01722v1",
            "title": "Heterogeneous federated collaborative filtering using FAIR: Federated\n  Averaging in Random Subspaces",
            "updated": "2023-11-03T05:39:45Z",
            "published": "2023-11-03T05:39:45Z",
            "summary": "Recommendation systems (RS) for items (e.g., movies, books) and ads are\nwidely used to tailor content to users on various internet platforms.\nTraditionally, recommendation models are trained on a central server. However,\ndue to rising concerns for data privacy and regulations like the GDPR,\nfederated learning is an increasingly popular paradigm in which data never\nleaves the client device. Applying federated learning to recommendation models\nis non-trivial due to large embedding tables, which often exceed the memory\nconstraints of most user devices. To include data from all devices in federated\nlearning, we must enable collective training of embedding tables on devices\nwith heterogeneous memory capacities. Current solutions to heterogeneous\nfederated learning can only accommodate a small range of capacities and thus\nlimit the number of devices that can participate in training. We present\nFederated Averaging in Random subspaces (FAIR), which allows arbitrary\ncompression of embedding tables based on device capacity and ensures the\nparticipation of all devices in training. FAIR uses what we call consistent and\ncollapsible subspaces defined by hashing-based random projections to jointly\ntrain large embedding tables while using varying amounts of compression on user\ndevices. We evaluate FAIR on Neural Collaborative Filtering tasks with multiple\ndatasets and verify that FAIR can gather and share information from a wide\nrange of devices with varying capacities, allowing for seamless collaboration.\nWe prove the convergence of FAIR in the homogeneous setting with non-i.i.d data\ndistribution. Our code is open source at {https://github.com/apd10/FLCF}",
            "author": [
                "Aditya Desai",
                "Benjamin Meisburger",
                "Zichang Liu",
                "Anshumali Shrivastava"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01722v1",
                "http://arxiv.org/pdf/2311.01722v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10099v1",
            "title": "Smart Traffic Management of Vehicles using Faster R-CNN based Deep\n  Learning Method",
            "updated": "2023-11-03T05:30:13Z",
            "published": "2023-11-03T05:30:13Z",
            "summary": "With constant growth of civilization and modernization of cities all across\nthe world since past few centuries smart traffic management of vehicles is one\nof the most sorted after problem by research community. It is a challenging\nproblem in computer vision and artificial intelligence domain. Smart traffic\nmanagement basically involves segmentation of vehicles, estimation of traffic\ndensity and tracking of vehicles. The vehicle segmentation from traffic videos\nhelps realization of niche applications such as monitoring of speed and\nestimation of traffic. When occlusions, background with clutters and traffic\nwith density variations are present, this problem becomes more intractable in\nnature. Keeping this motivation in this research work, we investigate Faster\nR-CNN based deep learning method towards segmentation of vehicles. This problem\nis addressed in four steps viz minimization with adaptive background model,\nFaster R-CNN based subnet operation, Faster R-CNN initial refinement and result\noptimization with extended topological active nets. The computational framework\nuses ideas of adaptive background modeling. It also addresses shadow and\nillumination related issues. Higher segmentation accuracy is achieved through\ntopological active net deformable models. The topological and extended\ntopological active nets help to achieve stated deformations. Mesh deformation\nis achieved with minimization of energy. The segmentation accuracy is improved\nwith modified version of extended topological active net. The experimental\nresults demonstrate superiority of this computational framework",
            "author": [
                "Arindam Chaudhuri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10099v1",
                "http://arxiv.org/pdf/2311.10099v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01720v1",
            "title": "Learning Reduced-Order Soft Robot Controller",
            "updated": "2023-11-03T05:24:19Z",
            "published": "2023-11-03T05:24:19Z",
            "summary": "Deformable robots are notoriously difficult to model or control due to its\nhigh-dimensional configuration spaces. Direct trajectory optimization suffers\nfrom the curse-of-dimensionality and incurs a high computational cost, while\nlearning-based controller optimization methods are sensitive to hyper-parameter\ntuning. To overcome these limitations, we hypothesize that high fidelity soft\nrobots can be both simulated and controlled by restricting to low-dimensional\nspaces. Under such assumption, we propose a two-stage algorithm to identify\nsuch simulation- and control-spaces. Our method first identifies the so-called\nsimulation-space that captures the salient deformation modes, to which the\nrobot's governing equation is restricted. We then identify the control-space,\nto which control signals are restricted. We propose a multi-fidelity Riemannian\nBayesian bilevel optimization to identify task-specific control spaces. We show\nthat the dimension of control-space can be less than $10$ for a high-DOF soft\nrobot to accomplish walking and swimming tasks, allowing low-dimensional MPC\ncontrollers to be applied to soft robots with tractable computational\ncomplexity.",
            "author": [
                "Chen Liang",
                "Xifeng Gao",
                "Kui Wu",
                "Zherong Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01720v1",
                "http://arxiv.org/pdf/2311.01720v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01712v1",
            "title": "A New Korean Text Classification Benchmark for Recognizing the Political\n  Intents in Online Newspapers",
            "updated": "2023-11-03T04:59:55Z",
            "published": "2023-11-03T04:59:55Z",
            "summary": "Many users reading online articles in various magazines may suffer\nconsiderable difficulty in distinguishing the implicit intents in texts. In\nthis work, we focus on automatically recognizing the political intents of a\ngiven online newspaper by understanding the context of the text. To solve this\ntask, we present a novel Korean text classification dataset that contains\nvarious articles. We also provide deep-learning-based text classification\nbaseline models trained on the proposed dataset. Our dataset contains 12,000\nnews articles that may contain political intentions, from the politics section\nof six of the most representative newspaper organizations in South Korea. All\nthe text samples are labeled simultaneously in two aspects (1) the level of\npolitical orientation and (2) the level of pro-government. To the best of our\nknowledge, our paper is the most large-scale Korean news dataset that contains\nlong text and addresses multi-task classification problems. We also train\nrecent state-of-the-art (SOTA) language models that are based on transformer\narchitectures and demonstrate that the trained models show decent text\nclassification performance. All the codes, datasets, and trained models are\navailable at https://github.com/Kdavid2355/KoPolitic-Benchmark-Dataset.",
            "author": [
                "Beomjune Kim",
                "Eunsun Lee",
                "Dongbin Na"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01712v1",
                "http://arxiv.org/pdf/2311.01712v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01709v1",
            "title": "Causal inference with Machine Learning-Based Covariate Representation",
            "updated": "2023-11-03T04:36:36Z",
            "published": "2023-11-03T04:36:36Z",
            "summary": "Utilizing covariate information has been a powerful approach to improve the\nefficiency and accuracy for causal inference, which support massive amount of\nrandomized experiments run on data-driven enterprises. However, state-of-art\napproaches can become practically unreliable when the dimension of covariate\nincreases to just 50, whereas experiments on large platforms can observe even\nhigher dimension of covariate. We propose a machine-learning-assisted covariate\nrepresentation approach that can effectively make use of historical experiment\nor observational data that are run on the same platform to understand which\nlower dimensions can effectively represent the higher-dimensional covariate. We\nthen propose design and estimation methods with the covariate representation.\nWe prove statistically reliability and performance guarantees for the proposed\nmethods. The empirical performance is demonstrated using numerical experiments.",
            "author": [
                "Yuhang Wu",
                "Jinghai He",
                "Zeyu Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01709v1",
                "http://arxiv.org/pdf/2311.01709v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01708v1",
            "title": "Physics-Informed Generator-Encoder Adversarial Networks with Latent\n  Space Matching for Stochastic Differential Equations",
            "updated": "2023-11-03T04:29:49Z",
            "published": "2023-11-03T04:29:49Z",
            "summary": "We propose a new class of physics-informed neural networks, called\nPhysics-Informed Generator-Encoder Adversarial Networks, to effectively address\nthe challenges posed by forward, inverse, and mixed problems in stochastic\ndifferential equations. In these scenarios, while the governing equations are\nknown, the available data consist of only a limited set of snapshots for system\nparameters. Our model consists of two key components: the generator and the\nencoder, both updated alternately by gradient descent. In contrast to previous\napproaches of directly matching the approximated solutions with real snapshots,\nwe employ an indirect matching that operates within the lower-dimensional\nlatent feature space. This method circumvents challenges associated with\nhigh-dimensional inputs and complex data distributions, while yielding more\naccurate solutions compared to existing neural network solvers. In addition,\nthe approach also mitigates the training instability issues encountered in\nprevious adversarial frameworks in an efficient manner. Numerical results\nprovide compelling evidence of the effectiveness of the proposed method in\nsolving different types of stochastic differential equations.",
            "author": [
                "Ruisong Gao",
                "Min Yang",
                "Jin Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01708v1",
                "http://arxiv.org/pdf/2311.01708v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01702v1",
            "title": "Medical Image Segmentation with Domain Adaptation: A Survey",
            "updated": "2023-11-03T04:17:06Z",
            "published": "2023-11-03T04:17:06Z",
            "summary": "Deep learning (DL) has shown remarkable success in various medical imaging\ndata analysis applications. However, it remains challenging for DL models to\nachieve good generalization, especially when the training and testing datasets\nare collected at sites with different scanners, due to domain shift caused by\ndifferences in data distributions. Domain adaptation has emerged as an\neffective means to address this challenge by mitigating domain gaps in medical\nimaging applications. In this review, we specifically focus on domain\nadaptation approaches for DL-based medical image segmentation. We first present\nthe motivation and background knowledge underlying domain adaptations, then\nprovide a comprehensive review of domain adaptation applications in medical\nimage segmentations, and finally discuss the challenges, limitations, and\nfuture research trends in the field to promote the methodology development of\ndomain adaptation in the context of medical image segmentation. Our goal was to\nprovide researchers with up-to-date references on the applications of domain\nadaptation in medical image segmentation studies.",
            "author": [
                "Yuemeng Li",
                "Yong Fan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01702v1",
                "http://arxiv.org/pdf/2311.01702v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01698v1",
            "title": "Adversarial Attacks on Cooperative Multi-agent Bandits",
            "updated": "2023-11-03T04:03:19Z",
            "published": "2023-11-03T04:03:19Z",
            "summary": "Cooperative multi-agent multi-armed bandits (CMA2B) consider the\ncollaborative efforts of multiple agents in a shared multi-armed bandit game.\nWe study latent vulnerabilities exposed by this collaboration and consider\nadversarial attacks on a few agents with the goal of influencing the decisions\nof the rest. More specifically, we study adversarial attacks on CMA2B in both\nhomogeneous settings, where agents operate with the same arm set, and\nheterogeneous settings, where agents have distinct arm sets. In the homogeneous\nsetting, we propose attack strategies that, by targeting just one agent,\nconvince all agents to select a particular target arm $T-o(T)$ times while\nincurring $o(T)$ attack costs in $T$ rounds. In the heterogeneous setting, we\nprove that a target arm attack requires linear attack costs and propose attack\nstrategies that can force a maximum number of agents to suffer linear regrets\nwhile incurring sublinear costs and only manipulating the observations of a few\ntarget agents. Numerical experiments validate the effectiveness of our proposed\nattack strategies.",
            "author": [
                "Jinhang Zuo",
                "Zhiyao Zhang",
                "Xuchuang Wang",
                "Cheng Chen",
                "Shuai Li",
                "John C. S. Lui",
                "Mohammad Hajiesmaili",
                "Adam Wierman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01698v1",
                "http://arxiv.org/pdf/2311.01698v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01695v1",
            "title": "Communication-Efficient Federated Non-Linear Bandit Optimization",
            "updated": "2023-11-03T03:50:31Z",
            "published": "2023-11-03T03:50:31Z",
            "summary": "Federated optimization studies the problem of collaborative function\noptimization among multiple clients (e.g. mobile devices or organizations)\nunder the coordination of a central server. Since the data is collected\nseparately by each client and always remains decentralized, federated\noptimization preserves data privacy and allows for large-scale computing, which\nmakes it a promising decentralized machine learning paradigm. Though it is\noften deployed for tasks that are online in nature, e.g., next-word prediction\non keyboard apps, most works formulate it as an offline problem. The few\nexceptions that consider federated bandit optimization are limited to very\nsimplistic function classes, e.g., linear, generalized linear, or\nnon-parametric function class with bounded RKHS norm, which severely hinders\nits practical usage. In this paper, we propose a new algorithm, named\nFed-GO-UCB, for federated bandit optimization with generic non-linear objective\nfunction. Under some mild conditions, we rigorously prove that Fed-GO-UCB is\nable to achieve sub-linear rate for both cumulative regret and communication\ncost. At the heart of our theoretical analysis are distributed regression\noracle and individual confidence set construction, which can be of independent\ninterests. Empirical evaluations also demonstrate the effectiveness of the\nproposed algorithm.",
            "author": [
                "Chuanhao Li",
                "Chong Liu",
                "Yu-Xiang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01695v1",
                "http://arxiv.org/pdf/2311.01695v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01693v1",
            "title": "Enhancing Computer Science Education with Pair Programming and Problem\n  Solving Studios",
            "updated": "2023-11-03T03:40:55Z",
            "published": "2023-11-03T03:40:55Z",
            "summary": "This study examines the adaptation of the problem-solving studio to computer\nscience education by combining it with pair programming. Pair programming is a\nsoftware engineering practice in industry, but has seen mixed results in the\nclassroom. Recent research suggests that pair programming has promise and\npotential to be an effective pedagogical tool, however what constitutes good\ninstructional design and implementation for pair programming in the classroom\nis not clear. We developed a framework for instructional design for pair\nprogramming by adapting the problem-solving studio (PSS), a pedagogy originally\nfrom biomedical engineering. PSS involves teams of students solving open-ended\nproblems with real-time feedback given by the instructor. Notably, PSS uses\nproblems of adjustable difficulty to keep students of all levels engaged and\nfunctioning within the zone of proximal development. The course structure has\nthree stages, first starting with demonstration, followed by a PSS session,\nthen finishing with a debrief. We studied the combination of PSS and pair\nprogramming in a CS1 class over three years. Surveys of the students report a\nhigh level of engagement, learning, and motivation.",
            "author": [
                "J. Walker Orr"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01693v1",
                "http://arxiv.org/pdf/2311.01693v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01686v1",
            "title": "Disentangled Representation Learning with Transmitted Information\n  Bottleneck",
            "updated": "2023-11-03T03:18:40Z",
            "published": "2023-11-03T03:18:40Z",
            "summary": "Encoding only the task-related information from the raw data, \\ie,\ndisentangled representation learning, can greatly contribute to the robustness\nand generalizability of models. Although significant advances have been made by\nregularizing the information in representations with information theory, two\nmajor challenges remain: 1) the representation compression inevitably leads to\nperformance drop; 2) the disentanglement constraints on representations are in\ncomplicated optimization. To these issues, we introduce Bayesian networks with\ntransmitted information to formulate the interaction among input and\nrepresentations during disentanglement. Building upon this framework, we\npropose \\textbf{DisTIB} (\\textbf{T}ransmitted \\textbf{I}nformation\n\\textbf{B}ottleneck for \\textbf{Dis}entangled representation learning), a novel\nobjective that navigates the balance between information compression and\npreservation. We employ variational inference to derive a tractable estimation\nfor DisTIB. This estimation can be simply optimized via standard gradient\ndescent with a reparameterization trick. Moreover, we theoretically prove that\nDisTIB can achieve optimal disentanglement, underscoring its superior efficacy.\nTo solidify our claims, we conduct extensive experiments on various downstream\ntasks to demonstrate the appealing efficacy of DisTIB and validate our\ntheoretical analyses.",
            "author": [
                "Zhuohang Dang",
                "Minnan Luo",
                "Chengyou Jia",
                "Guang Dai",
                "Jihong Wang",
                "Xiaojun Chang",
                "Jingdong Wang",
                "Qinghua Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01686v1",
                "http://arxiv.org/pdf/2311.01686v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01683v1",
            "title": "Amide Proton Transfer (APT) imaging in tumor with a machine learning\n  approach using partially synthetic data",
            "updated": "2023-11-03T03:12:21Z",
            "published": "2023-11-03T03:12:21Z",
            "summary": "Machine learning (ML) has been increasingly used to quantify chemical\nexchange saturation transfer (CEST) effect. ML models are typically trained\nusing either measured data or fully simulated data. However, training with\nmeasured data often lacks sufficient training data, while training with fully\nsimulated data may introduce bias due to limited simulations pools. This study\nintroduces a new platform that combines simulated and measured components to\ngenerate partially synthetic CEST data, and to evaluate its feasibility for\ntraining ML models to predict amide proton transfer (APT) effect. Partially\nsynthetic CEST signals were created using an inverse summation of APT effects\nfrom simulations and the other components from measurements. Training data were\ngenerated by varying APT simulation parameters and applying scaling factors to\nadjust the measured components, achieving a balance between simulation\nflexibility and fidelity. First, tissue-mimicking CEST signals along with\nground truth information were created using multiple-pool model simulations to\nvalidate this method. Second, an ML model was trained individually on partially\nsynthetic data, in vivo data, and fully simulated data, to predict APT effect\nin rat brains bearing 9L tumors. Experiments on tissue-mimicking data suggest\nthat the ML method using the partially synthetic data is accurate in predicting\nAPT. In vivo experiments suggest that our method provides more accurate and\nrobust prediction than the training using in vivo data and fully synthetic\ndata. Partially synthetic CEST data can address the challenges in conventional\nML methods.",
            "author": [
                "Malvika Viswanathan",
                "Leqi Yin",
                "Yashwant Kurmi",
                "Zhongliang Zu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01683v1",
                "http://arxiv.org/pdf/2311.01683v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01679v1",
            "title": "SE Territory: Monaural Speech Enhancement Meets the Fixed Virtual\n  Perceptual Space Mapping",
            "updated": "2023-11-03T03:03:47Z",
            "published": "2023-11-03T03:03:47Z",
            "summary": "Monaural speech enhancement has achieved remarkable progress recently.\nHowever, its performance has been constrained by the limited spatial cues\navailable at a single microphone. To overcome this limitation, we introduce a\nstrategy to map monaural speech into a fixed simulation space for better\ndifferentiation between target speech and noise. Concretely, we propose\nSE-TerrNet, a novel monaural speech enhancement model featuring a virtual\nbinaural speech mapping network via a two-stage multi-task learning framework.\nIn the first stage, monaural noisy input is projected into a virtual space\nusing supervised speech mapping blocks, creating binaural representations.\nThese blocks synthesize binaural noisy speech from monaural input via an ideal\nbinaural room impulse response. The synthesized output assigns speech and noise\nsources to fixed directions within the perceptual space. In the second stage,\nthe obtained binaural features from the first stage are aggregated. This\naggregation aims to decrease pattern discrepancies between the mapped binaural\nand original monaural features, achieved by implementing an intermediate fusion\nmodule. Furthermore, this stage incorporates the utilization of cross-attention\nto capture the injected virtual spatial information to improve the extraction\nof the target speech. Empirical studies highlight the effectiveness of virtual\nspatial cues in enhancing monaural speech enhancement. As a result, the\nproposed SE-TerrNet significantly surpasses the recent monaural speech\nenhancement methods in terms of both speech quality and intelligibility.",
            "author": [
                "Xinmeng Xu",
                "Jibin Wu",
                "Xiaoyong Wei",
                "Yan Liu",
                "Richard So",
                "Yuhong Yang",
                "Weiping Tu",
                "Kay Chen Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01679v1",
                "http://arxiv.org/pdf/2311.01679v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01678v1",
            "title": "Reduce, Reuse, Recycle: Building Greener Sustainable Software",
            "updated": "2023-11-03T03:03:13Z",
            "published": "2023-11-03T03:03:13Z",
            "summary": "Technology use has grown rapidly in recent years. It is infused in virtually\nevery aspect of organizational and individual life. This technology runs on\nservers, typically in data centers. As workloads grow, more serves are\nrequired. Each server incrementally adds to the energy consumption footprint of\na data center. Currently, data centers account for more than one percent of all\npower usage worldwide. Clearly, energy efficiency is a significant concern for\ndata centers. While many aspects of data center energy efficiency have received\nattention, energy consumption is rarely considered in software development\norganizations. In this work, we consider the energy consumption impacts of\nfundamental software operations, and demonstrate that non-trivial energy\nsavings can be achieved in software by making energy-conscious decisions\nregarding basic aspects of programming. This work has significant potential for\npractical impact; applying the lessons learned in this study can lead to\ngreener sustainable software.",
            "author": [
                "Kaushik Dutta",
                "Debra Vandermeer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01678v1",
                "http://arxiv.org/pdf/2311.01678v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.PF",
                "D.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02117v2",
            "title": "Cooperative Network Learning for Large-Scale and Decentralized Graphs",
            "updated": "2023-11-07T08:50:24Z",
            "published": "2023-11-03T02:56:01Z",
            "summary": "Graph research, the systematic study of interconnected data points\nrepresented as graphs, plays a vital role in capturing intricate relationships\nwithin networked systems. However, in the real world, as graphs scale up,\nconcerns about data security among different data-owning agencies arise,\nhindering information sharing and, ultimately, the utilization of graph data.\nTherefore, establishing a mutual trust mechanism among graph agencies is\ncrucial for unlocking the full potential of graphs. Here, we introduce a\nCooperative Network Learning (CNL) framework to ensure secure graph computing\nfor various graph tasks. Essentially, this CNL framework unifies the local and\nglobal perspectives of GNN computing with distributed data for an agency by\nvirtually connecting all participating agencies as a global graph without a\nfixed central coordinator. Inter-agency computing is protected by various\ntechnologies inherent in our framework, including homomorphic encryption and\nsecure transmission. Moreover, each agency has a fair right to design or employ\nvarious graph learning models from its local or global perspective. Thus, CNL\ncan collaboratively train GNN models based on decentralized graphs inferred\nfrom local and global graphs. Experiments on contagion dynamics prediction and\ntraditional graph tasks (i.e., node classification and link prediction)\ndemonstrate that our CNL architecture outperforms state-of-the-art GNNs\ndeveloped at individual sites, revealing that CNL can provide a reliable, fair,\nsecure, privacy-preserving, and global perspective to build effective and\npersonalized models for network applications. We hope this framework will\naddress privacy concerns in graph-related research and integrate decentralized\ngraph data structures to benefit the network research community in cooperation\nand innovation.",
            "author": [
                "Qiang Wu",
                "Yiming Huang",
                "Yujie Zeng",
                "Yijie Teng",
                "Fang Zhou",
                "Linyuan L\u00fc"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02117v2",
                "http://arxiv.org/pdf/2311.02117v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01676v1",
            "title": "MineSegSAT: An automated system to evaluate mining disturbed area\n  extents from Sentinel-2 imagery",
            "updated": "2023-11-03T02:52:01Z",
            "published": "2023-11-03T02:52:01Z",
            "summary": "Assessing the environmental impact of the mineral extraction industry plays a\ncritical role in understanding and mitigating the ecological consequences of\nextractive activities. This paper presents MineSegSAT, a model that presents a\nnovel approach to predicting environmentally impacted areas of mineral\nextraction sites using the SegFormer deep learning segmentation architecture\ntrained on Sentinel-2 data. The data was collected from non-overlapping regions\nover Western Canada in 2021 containing areas of land that have been\nenvironmentally impacted by mining activities that were identified from\nhigh-resolution satellite imagery in 2021. The SegFormer architecture, a\nstate-of-the-art semantic segmentation framework, is employed to leverage its\nadvanced spatial understanding capabilities for accurate land cover\nclassification. We investigate the efficacy of loss functions including Dice,\nTversky, and Lovasz loss respectively. The trained model was utilized for\ninference over the test region in the ensuing year to identify potential areas\nof expansion or contraction over these same periods. The Sentinel-2 data is\nmade available on Amazon Web Services through a collaboration with Earth Daily\nAnalytics which provides corrected and tiled analytics-ready data on the AWS\nplatform. The model and ongoing API to access the data on AWS allow the\ncreation of an automated tool to monitor the extent of disturbed areas\nsurrounding known mining sites to ensure compliance with their environmental\nimpact goals.",
            "author": [
                "Ezra MacDonald",
                "Derek Jacoby",
                "Yvonne Coady"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01676v1",
                "http://arxiv.org/pdf/2311.01676v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02116v1",
            "title": "Resist Label Noise with PGM for Graph Neural Networks",
            "updated": "2023-11-03T02:47:06Z",
            "published": "2023-11-03T02:47:06Z",
            "summary": "While robust graph neural networks (GNNs) have been widely studied for graph\nperturbation and attack, those for label noise have received significantly less\nattention. Most existing methods heavily rely on the label smoothness\nassumption to correct noisy labels, which adversely affects their performance\non heterophilous graphs. Further, they generally perform poorly in high\nnoise-rate scenarios. To address these problems, in this paper, we propose a\nnovel probabilistic graphical model (PGM) based framework LNP. Given a noisy\nlabel set and a clean label set, our goal is to maximize the likelihood of\nlabels in the clean set. We first present LNP-v1, which generates clean labels\nbased on graphs only in the Bayesian network. To further leverage the\ninformation of clean labels in the noisy label set, we put forward LNP-v2,\nwhich incorporates the noisy label set into the Bayesian network to generate\nclean labels. The generative process can then be used to predict labels for\nunlabeled nodes. We conduct extensive experiments to show the robustness of LNP\non varying noise types and rates, and also on graphs with different\nheterophilies. In particular, we show that LNP can lead to inspiring\nperformance in high noise-rate situations.",
            "author": [
                "Qingqing Ge",
                "Jianxiang Yu",
                "Zeyuan Zhao",
                "Xiang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02116v1",
                "http://arxiv.org/pdf/2311.02116v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01664v1",
            "title": "A Theoretical Case Study of the Generalisation of Machine-learned\n  Potentials",
            "updated": "2023-11-03T01:55:14Z",
            "published": "2023-11-03T01:55:14Z",
            "summary": "Machine-learned interatomic potentials (MLIPs) are typically trained on\ndatasets that encompass a restricted subset of possible input structures, which\npresents a potential challenge for their generalization to a broader range of\nsystems outside the training set. Nevertheless, MLIPs have demonstrated\nimpressive accuracy in predicting forces and energies in simulations involving\nintricate and complex structures. In this paper we aim to take steps towards\nrigorously explaining the excellent observed generalisation properties of\nMLIPs. Specifically, we offer a comprehensive theoretical and numerical\ninvestigation of the generalization of MLIPs in the context of dislocation\nsimulations. We quantify precisely how the accuracy of such simulations is\ndirectly determined by a few key factors: the size of the training structures,\nthe choice of training observations (e.g., energies, forces, virials), and the\nlevel of accuracy achieved in the fitting process. Notably, our study reveals\nthe crucial role of fitting virials in ensuring the consistency of MLIPs for\ndislocation simulations. Our series of careful numerical experiments\nencompassing screw, edge, and mixed dislocations, supports existing best\npractices in the MLIPs literature but also provides new insights into the\ndesign of data sets and loss functions.",
            "author": [
                "Yangshuai Wang",
                "Shashwat Patel",
                "Christoph Ortner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01664v1",
                "http://arxiv.org/pdf/2311.01664v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01661v1",
            "title": "Deep Learning-driven Community Resilience Rating based on Intertwined\n  Socio-Technical Systems Features",
            "updated": "2023-11-03T01:50:36Z",
            "published": "2023-11-03T01:50:36Z",
            "summary": "Community resilience is a complex and muti-faceted phenomenon that emerges\nfrom complex and nonlinear interactions among different socio-technical systems\nand their resilience properties. However, present studies on community\nresilience focus primarily on vulnerability assessment and utilize index-based\napproaches, with limited ability to capture heterogeneous features within\ncommunity socio-technical systems and their nonlinear interactions in shaping\nrobustness, redundancy, and resourcefulness components of resilience. To\naddress this gap, this paper presents an integrated three-layer deep learning\nmodel for community resilience rating (called Resili-Net). Twelve measurable\nresilience features are specified and computed within community socio-technical\nsystems (i.e., facilities, infrastructures, and society) related to three\nresilience components of robustness, redundancy, and resourcefulness. Using\npublicly accessible data from multiple metropolitan statistical areas in the\nUnited States, Resili-Net characterizes the resilience levels of spatial areas\ninto five distinct levels. The interpretability of the model outcomes enables\nfeature analysis for specifying the determinants of resilience in areas within\neach resilience level, allowing for the identification of specific resilience\nenhancement strategies. Changes in community resilience profiles under urban\ndevelopment patterns are further examined by changing the value of related\nsocio-technical systems features. Accordingly, the outcomes provide novel\nperspectives for community resilience assessment by harnessing machine\nintelligence and heterogeneous urban big data.",
            "author": [
                "Kai Yin",
                "Ali Mostafavi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01661v1",
                "http://arxiv.org/pdf/2311.01661v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.AI",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01660v1",
            "title": "Maximum Likelihood Estimation of Flexible Survival Densities with\n  Importance Sampling",
            "updated": "2023-11-03T01:46:48Z",
            "published": "2023-11-03T01:46:48Z",
            "summary": "Survival analysis is a widely-used technique for analyzing time-to-event data\nin the presence of censoring. In recent years, numerous survival analysis\nmethods have emerged which scale to large datasets and relax traditional\nassumptions such as proportional hazards. These models, while being performant,\nare very sensitive to model hyperparameters including: (1) number of bins and\nbin size for discrete models and (2) number of cluster assignments for\nmixture-based models. Each of these choices requires extensive tuning by\npractitioners to achieve optimal performance. In addition, we demonstrate in\nempirical studies that: (1) optimal bin size may drastically differ based on\nthe metric of interest (e.g., concordance vs brier score), and (2) mixture\nmodels may suffer from mode collapse and numerical instability. We propose a\nsurvival analysis approach which eliminates the need to tune hyperparameters\nsuch as mixture assignments and bin sizes, reducing the burden on\npractitioners. We show that the proposed approach matches or outperforms\nbaselines on several real-world datasets.",
            "author": [
                "Mert Ketenci",
                "Shreyas Bhave",
                "No\u00e9mie Elhadad",
                "Adler Perotte"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01660v1",
                "http://arxiv.org/pdf/2311.01660v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02115v1",
            "title": "Towards objective and systematic evaluation of bias in medical imaging\n  AI",
            "updated": "2023-11-03T01:37:28Z",
            "published": "2023-11-03T01:37:28Z",
            "summary": "Artificial intelligence (AI) models trained using medical images for clinical\ntasks often exhibit bias in the form of disparities in performance between\nsubgroups. Since not all sources of biases in real-world medical imaging data\nare easily identifiable, it is challenging to comprehensively assess how those\nbiases are encoded in models, and how capable bias mitigation methods are at\nameliorating performance disparities. In this article, we introduce a novel\nanalysis framework for systematically and objectively investigating the impact\nof biases in medical images on AI models. We developed and tested this\nframework for conducting controlled in silico trials to assess bias in medical\nimaging AI using a tool for generating synthetic magnetic resonance images with\nknown disease effects and sources of bias. The feasibility is showcased by\nusing three counterfactual bias scenarios to measure the impact of simulated\nbias effects on a convolutional neural network (CNN) classifier and the\nefficacy of three bias mitigation strategies. The analysis revealed that the\nsimulated biases resulted in expected subgroup performance disparities when the\nCNN was trained on the synthetic datasets. Moreover, reweighing was identified\nas the most successful bias mitigation strategy for this setup, and we\ndemonstrated how explainable AI methods can aid in investigating the\nmanifestation of bias in the model using this framework. Developing fair AI\nmodels is a considerable challenge given that many and often unknown sources of\nbiases can be present in medical imaging datasets. In this work, we present a\nnovel methodology to objectively study the impact of biases and mitigation\nstrategies on deep learning pipelines, which can support the development of\nclinical AI that is robust and responsible.",
            "author": [
                "Emma A. M. Stanley",
                "Raissa Souza",
                "Anthony Winder",
                "Vedant Gulve",
                "Kimberly Amador",
                "Matthias Wilms",
                "Nils D. Forkert"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02115v1",
                "http://arxiv.org/pdf/2311.02115v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01658v1",
            "title": "The AGN fraction in high-redshift protocluster candidates selected by\n  Planck and Herschel",
            "updated": "2023-11-03T01:36:58Z",
            "published": "2023-11-03T01:36:58Z",
            "summary": "A complete understanding of the mass assembly history of structures in the\nuniverse requires the study of the growth of galaxies and their supermassive\nblack holes (SMBHs) as a function of their local environment over cosmic time.\nIn this context, it is important to quantify the effects that the early stages\nof galaxy cluster development have on the growth of SMBHs. We used a sample of\nHerschel/SPIRE sources of $\\sim$ 228 red and compact Planck-selected\nprotocluster (PC) candidates to estimate the active galactic nuclei (AGN)\nfraction from a large sample of galaxies within these candidates. We estimate\nthe AGN fraction by using the mid-infrared (mid-IR) photometry provided by the\nWISE/AllWISE data of $\\sim650$ counterparts at high redshifts. We created an\nAllWISE mid-IR colour-colour selection using a clustering machine learning\nalgorithm and two {\\it WISE} colour cuts using the 3.4 $\\mu m$ (W1), 4.6 $\\mu\nm$ (W2) and 12 $\\mu m$ (W3) passbands, to classify sources as AGN. We also\ncompare the AGN fraction in PCs with that in the field to better understand the\ninfluence of the environment on galaxy development. We found an AGN fraction of\n$f_{AGN} = 0.113 \\pm 0.03$ in PC candidates and an AGN fraction of $f_{AGN} =\n0.095 \\pm 0.013$ in the field. We also selected a subsample of `red' SPIRE\nsubsample with a higher overdensity significance, obtaining $f_{AGN} = 0.186\n\\pm 0.044$, versus $f_{AGN} = 0.037 \\pm 0.010$ of `non-red sources', consistent\nwith higher AGN fractions for denser environments. We conclude that our results\npoint towards a higher AGN fraction in PCs, similar to other studies.",
            "author": [
                "Caleb Gatica",
                "Ricardo Demarco",
                "Herv\u00e9 Dole",
                "Maria Polletta",
                "Brenda Frye",
                "Clement Martinache",
                "Alessandro Rettura"
            ],
            "link": [
                "http://dx.doi.org/10.1093/mnras/stad3404",
                "http://arxiv.org/abs/2311.01658v1",
                "http://arxiv.org/pdf/2311.01658v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01655v2",
            "title": "Detecting Spurious Correlations via Robust Visual Concepts in Real and\n  AI-Generated Image Classification",
            "updated": "2023-11-16T00:22:27Z",
            "published": "2023-11-03T01:12:35Z",
            "summary": "Often machine learning models tend to automatically learn associations\npresent in the training data without questioning their validity or\nappropriateness. This undesirable property is the root cause of the\nmanifestation of spurious correlations, which render models unreliable and\nprone to failure in the presence of distribution shifts. Research shows that\nmost methods attempting to remedy spurious correlations are only effective for\na model's known spurious associations. Current spurious correlation detection\nalgorithms either rely on extensive human annotations or are too restrictive in\ntheir formulation. Moreover, they rely on strict definitions of visual\nartifacts that may not apply to data produced by generative models, as they are\nknown to hallucinate contents that do not conform to standard specifications.\nIn this work, we introduce a general-purpose method that efficiently detects\npotential spurious correlations, and requires significantly less human\ninterference in comparison to the prior art. Additionally, the proposed method\nprovides intuitive explanations while eliminating the need for pixel-level\nannotations. We demonstrate the proposed method's tolerance to the peculiarity\nof AI-generated images, which is a considerably challenging task, one where\nmost of the existing methods fall short. Consequently, our method is also\nsuitable for detecting spurious correlations that may propagate to downstream\napplications originating from generative models.",
            "author": [
                "Preetam Prabhu Srikar Dammu",
                "Chirag Shah"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01655v2",
                "http://arxiv.org/pdf/2311.01655v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01650v1",
            "title": "MARRS: Multimodal Reference Resolution System",
            "updated": "2023-11-03T00:48:42Z",
            "published": "2023-11-03T00:48:42Z",
            "summary": "Successfully handling context is essential for any dialog understanding task.\nThis context maybe be conversational (relying on previous user queries or\nsystem responses), visual (relying on what the user sees, for example, on their\nscreen), or background (based on signals such as a ringing alarm or playing\nmusic). In this work, we present an overview of MARRS, or Multimodal Reference\nResolution System, an on-device framework within a Natural Language\nUnderstanding system, responsible for handling conversational, visual and\nbackground context. In particular, we present different machine learning models\nto enable handing contextual queries; specifically, one to enable reference\nresolution, and one to handle context via query rewriting. We also describe how\nthese models complement each other to form a unified, coherent, lightweight\nsystem that can understand context while preserving user privacy.",
            "author": [
                "Halim Cagri Ates",
                "Shruti Bhargava",
                "Site Li",
                "Jiarui Lu",
                "Siddhardha Maddula",
                "Joel Ruben Antony Moniz",
                "Anil Kumar Nalamalapu",
                "Roman Hoang Nguyen",
                "Melis Ozyildirim",
                "Alkesh Patel",
                "Dhivya Piraviperumal",
                "Vincent Renkens",
                "Ankit Samal",
                "Thy Tran",
                "Bo-Hsiang Tseng",
                "Hong Yu",
                "Yuan Zhang",
                "Rong Zou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01650v1",
                "http://arxiv.org/pdf/2311.01650v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01647v1",
            "title": "Calibrate and Boost Logical Expressiveness of GNN Over Multi-Relational\n  and Temporal Graphs",
            "updated": "2023-11-03T00:33:24Z",
            "published": "2023-11-03T00:33:24Z",
            "summary": "As a powerful framework for graph representation learning, Graph Neural\nNetworks (GNNs) have garnered significant attention in recent years. However,\nto the best of our knowledge, there has been no formal analysis of the logical\nexpressiveness of GNNs as Boolean node classifiers over multi-relational\ngraphs, where each edge carries a specific relation type. In this paper, we\ninvestigate $\\mathcal{FOC}_2$, a fragment of first-order logic with two\nvariables and counting quantifiers. On the negative side, we demonstrate that\nthe R$^2$-GNN architecture, which extends the local message passing GNN by\nincorporating global readout, fails to capture $\\mathcal{FOC}_2$ classifiers in\nthe general case. Nevertheless, on the positive side, we establish that\nR$^2$-GNNs models are equivalent to $\\mathcal{FOC}_2$ classifiers under certain\nrestricted yet reasonable scenarios. To address the limitations of R$^2$-GNNs\nregarding expressiveness, we propose a simple graph transformation technique,\nakin to a preprocessing step, which can be executed in linear time. This\ntransformation enables R$^2$-GNNs to effectively capture any $\\mathcal{FOC}_2$\nclassifiers when applied to the \"transformed\" input graph. Moreover, we extend\nour analysis of expressiveness and graph transformation to temporal graphs,\nexploring several temporal GNN architectures and providing an expressiveness\nhierarchy for them. To validate our findings, we implement R$^2$-GNNs and the\ngraph transformation technique and conduct empirical tests in node\nclassification tasks against various well-known GNN architectures that support\nmulti-relational or temporal graphs. Our experimental results consistently\ndemonstrate that R$^2$-GNN with the graph transformation outperforms the\nbaseline methods on both synthetic and real-world datasets",
            "author": [
                "Yeyuan Chen",
                "Dingmin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01647v1",
                "http://arxiv.org/pdf/2311.01647v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01646v1",
            "title": "SemiGPC: Distribution-Aware Label Refinement for Imbalanced\n  Semi-Supervised Learning Using Gaussian Processes",
            "updated": "2023-11-03T00:25:58Z",
            "published": "2023-11-03T00:25:58Z",
            "summary": "In this paper we introduce SemiGPC, a distribution-aware label refinement\nstrategy based on Gaussian Processes where the predictions of the model are\nderived from the labels posterior distribution. Differently from other\nbuffer-based semi-supervised methods such as CoMatch and SimMatch, our SemiGPC\nincludes a normalization term that addresses imbalances in the global data\ndistribution while maintaining local sensitivity. This explicit control allows\nSemiGPC to be more robust to confirmation bias especially under class\nimbalance. We show that SemiGPC improves performance when paired with different\nSemi-Supervised methods such as FixMatch, ReMixMatch, SimMatch and FreeMatch\nand different pre-training strategies including MSN and Dino. We also show that\nSemiGPC achieves state of the art results under different degrees of class\nimbalance on standard CIFAR10-LT/CIFAR100-LT especially in the low data-regime.\nUsing SemiGPC also results in about 2% avg.accuracy increase compared to a new\ncompetitive baseline on the more challenging benchmarks SemiAves, SemiCUB,\nSemiFungi and Semi-iNat.",
            "author": [
                "Abdelhak Lemkhenter",
                "Manchen Wang",
                "Luca Zancato",
                "Gurumurthy Swaminathan",
                "Paolo Favaro",
                "Davide Modolo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01646v1",
                "http://arxiv.org/pdf/2311.01646v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01644v1",
            "title": "Should Under-parameterized Student Networks Copy or Average Teacher\n  Weights?",
            "updated": "2023-11-03T00:21:36Z",
            "published": "2023-11-03T00:21:36Z",
            "summary": "Any continuous function $f^*$ can be approximated arbitrarily well by a\nneural network with sufficiently many neurons $k$. We consider the case when\n$f^*$ itself is a neural network with one hidden layer and $k$ neurons.\nApproximating $f^*$ with a neural network with $n< k$ neurons can thus be seen\nas fitting an under-parameterized \"student\" network with $n$ neurons to a\n\"teacher\" network with $k$ neurons. As the student has fewer neurons than the\nteacher, it is unclear, whether each of the $n$ student neurons should copy one\nof the teacher neurons or rather average a group of teacher neurons. For\nshallow neural networks with erf activation function and for the standard\nGaussian input distribution, we prove that \"copy-average\" configurations are\ncritical points if the teacher's incoming vectors are orthonormal and its\noutgoing weights are unitary. Moreover, the optimum among such configurations\nis reached when $n-1$ student neurons each copy one teacher neuron and the\n$n$-th student neuron averages the remaining $k-n+1$ teacher neurons. For the\nstudent network with $n=1$ neuron, we provide additionally a closed-form\nsolution of the non-trivial critical point(s) for commonly used activation\nfunctions through solving an equivalent constrained optimization problem.\nEmpirically, we find for the erf activation function that gradient flow\nconverges either to the optimal copy-average critical point or to another point\nwhere each student neuron approximately copies a different teacher neuron.\nFinally, we find similar results for the ReLU activation function, suggesting\nthat the optimal solution of underparameterized networks has a universal\nstructure.",
            "author": [
                "Berfin \u015eim\u015fek",
                "Amire Bendjeddou",
                "Wulfram Gerstner",
                "Johanni Brea"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01644v1",
                "http://arxiv.org/pdf/2311.01644v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16135v1",
            "title": "Use of Deep Neural Networks for Uncertain Stress Functions with\n  Extensions to Impact Mechanics",
            "updated": "2023-11-03T00:12:24Z",
            "published": "2023-11-03T00:12:24Z",
            "summary": "Stress-strain curves, or more generally, stress functions, are an extremely\nimportant characterization of a material's mechanical properties. However,\nstress functions are often difficult to derive and are narrowly tailored to a\nspecific material. Further, large deformations, high strain-rates, temperature\nsensitivity, and effect of material parameters compound modeling challenges. We\npropose a generalized deep neural network approach to model stress as a state\nfunction with quantile regression to capture uncertainty. We extend these\nmodels to uniaxial impact mechanics using stochastic differential equations to\ndemonstrate a use case and provide a framework for implementing this\nuncertainty-aware stress function. We provide experiments benchmarking our\napproach against leading constitutive, machine learning, and transfer learning\napproaches to stress and impact mechanics modeling on publicly available and\nnewly presented data sets. We also provide a framework to optimize material\nparameters given multiple competing impact scenarios.",
            "author": [
                "Garrett Blum",
                "Ryan Doris",
                "Diego Klabjan",
                "Horacio Espinosa",
                "Ron Szalkowski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16135v1",
                "http://arxiv.org/pdf/2311.16135v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03383v1",
            "title": "Toward Reinforcement Learning-based Rectilinear Macro Placement Under\n  Human Constraints",
            "updated": "2023-11-03T00:09:52Z",
            "published": "2023-11-03T00:09:52Z",
            "summary": "Macro placement is a critical phase in chip design, which becomes more\nintricate when involving general rectilinear macros and layout areas.\nFurthermore, macro placement that incorporates human-like constraints, such as\ndesign hierarchy and peripheral bias, has the potential to significantly reduce\nthe amount of additional manual labor required from designers. This study\nproposes a methodology that leverages an approach suggested by Google's Circuit\nTraining (G-CT) to provide a learning-based macro placer that not only supports\nplacing rectilinear cases, but also adheres to crucial human-like design\nprinciples. Our experimental results demonstrate the effectiveness of our\nframework in achieving power-performance-area (PPA) metrics and in obtaining\nplacements of high quality, comparable to those produced with human\nintervention. Additionally, our methodology shows potential as a generalized\nmodel to address diverse macro shapes and layout areas.",
            "author": [
                "Tuyen P. Le",
                "Hieu T. Nguyen",
                "Seungyeol Baek",
                "Taeyoun Kim",
                "Jungwoo Lee",
                "Seongjung Kim",
                "Hyunjin Kim",
                "Misu Jung",
                "Daehoon Kim",
                "Seokyong Lee",
                "Daewoo Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03383v1",
                "http://arxiv.org/pdf/2311.03383v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.AR",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01642v1",
            "title": "Robust Adversarial Reinforcement Learning via Bounded Rationality\n  Curricula",
            "updated": "2023-11-03T00:00:32Z",
            "published": "2023-11-03T00:00:32Z",
            "summary": "Robustness against adversarial attacks and distribution shifts is a\nlong-standing goal of Reinforcement Learning (RL). To this end, Robust\nAdversarial Reinforcement Learning (RARL) trains a protagonist against\ndestabilizing forces exercised by an adversary in a competitive zero-sum Markov\ngame, whose optimal solution, i.e., rational strategy, corresponds to a Nash\nequilibrium. However, finding Nash equilibria requires facing complex saddle\npoint optimization problems, which can be prohibitive to solve, especially for\nhigh-dimensional control. In this paper, we propose a novel approach for\nadversarial RL based on entropy regularization to ease the complexity of the\nsaddle point optimization problem. We show that the solution of this\nentropy-regularized problem corresponds to a Quantal Response Equilibrium\n(QRE), a generalization of Nash equilibria that accounts for bounded\nrationality, i.e., agents sometimes play random actions instead of optimal\nones. Crucially, the connection between the entropy-regularized objective and\nQRE enables free modulation of the rationality of the agents by simply tuning\nthe temperature coefficient. We leverage this insight to propose our novel\nalgorithm, Quantal Adversarial RL (QARL), which gradually increases the\nrationality of the adversary in a curriculum fashion until it is fully\nrational, easing the complexity of the optimization problem while retaining\nrobustness. We provide extensive evidence of QARL outperforming RARL and recent\nbaselines across several MuJoCo locomotion and navigation problems in overall\nperformance and robustness.",
            "author": [
                "Aryaman Reddi",
                "Maximilian T\u00f6lle",
                "Jan Peters",
                "Georgia Chalvatzaki",
                "Carlo D'Eramo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01642v1",
                "http://arxiv.org/pdf/2311.01642v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01638v1",
            "title": "Inference on summaries of a model-agnostic longitudinal variable\n  importance trajectory",
            "updated": "2023-11-02T23:21:57Z",
            "published": "2023-11-02T23:21:57Z",
            "summary": "In prediction settings where data are collected over time, it is often of\ninterest to understand both the importance of variables for predicting the\nresponse at each time point and the importance summarized over the time series.\nBuilding on recent advances in estimation and inference for variable importance\nmeasures, we define summaries of variable importance trajectories. These\nmeasures can be estimated and the same approaches for inference can be applied\nregardless of the choice of the algorithm(s) used to estimate the prediction\nfunction. We propose a nonparametric efficient estimation and inference\nprocedure as well as a null hypothesis testing procedure that are valid even\nwhen complex machine learning tools are used for prediction. Through\nsimulations, we demonstrate that our proposed procedures have good operating\ncharacteristics, and we illustrate their use by investigating the longitudinal\nimportance of risk factors for suicide attempt.",
            "author": [
                "Brian D. Williamson",
                "Erica E. M. Moodie",
                "Susan M. Shortreed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01638v1",
                "http://arxiv.org/pdf/2311.01638v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01634v1",
            "title": "\"Close...but not as good as an educator.\" -- Using ChatGPT to provide\n  formative feedback in large-class collaborative learning",
            "updated": "2023-11-02T23:00:38Z",
            "published": "2023-11-02T23:00:38Z",
            "summary": "Delivering personalised, formative feedback to multiple problem-based\nlearning groups in a short time period can be almost impossible. We employed\nChatGPT to provide personalised formative feedback in a one-hour Zoom break-out\nroom activity that taught practicing health professionals how to formulate\nevaluation plans for digital health initiatives. Learners completed an\nevaluation survey that included Likert scales and open-ended questions that\nwere analysed. Half of the 44 survey respondents had never used ChatGPT before.\nOverall, respondents found the feedback favourable, described a wide range of\ngroup dynamics, and had adaptive responses to the feedback, yet only three\ngroups used the feedback loop to improve their evaluation plans. Future\neducators can learn from our experience including engineering prompts,\nproviding instructions on how to use ChatGPT, and scaffolding optimal group\ninteractions with ChatGPT. Future researchers should explore the influence of\nChatGPT on group dynamics and derive design principles for the use of ChatGPT\nin collaborative learning.",
            "author": [
                "Cory Dal Ponte",
                "Sathana Dushyanthen",
                "Kayley Lyons"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01634v1",
                "http://arxiv.org/pdf/2311.01634v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01630v1",
            "title": "Generalizations of Matrix Multiplication can solve the Light Bulb\n  Problem",
            "updated": "2023-11-02T22:49:41Z",
            "published": "2023-11-02T22:49:41Z",
            "summary": "In the light bulb problem, one is given uniformly random vectors $x_1,\n\\ldots, x_n, y_1, \\ldots, y_n \\in \\{-1,1\\}^d$. They are all chosen\nindependently except a planted pair $(x_{i^*}, y_{j^*})$ is chosen with\ncorrelation $\\rho>0$. The goal is to find the planted pair. This problem was\nintroduced over 30 years ago by L.~Valiant, and is known to have many\napplications in data analysis, statistics, and learning theory.\n  The naive algorithm runs in $\\Omega(n^2)$ time, and algorithms based on\nLocality-Sensitive Hashing approach quadratic time as $\\rho \\to 0$. In 2012,\nG.~Valiant gave a breakthrough algorithm using fast matrix multiplication that\nruns in time $O(n^{(5-\\omega)/(4-\\omega)}) < O(n^{1.615})$, no matter how small\n$\\rho>0$ is. This was subsequently refined by Karppa, Kaski, and Kohonen in\n2016 to $O(n^{2 \\omega / 3}) < O(n^{1.582})$.\n  In this paper, we propose a new approach which can replace matrix\nmultiplication tensor with other tensors. Those tensors can omit some terms one\nis supposed to compute, and include additional error terms. Our new approach\ncan make use of any tensors which previously had no known algorithmic\napplications, including tensors which arise naturally as intermediate steps in\nborder rank methods and in the Laser method.\n  We further show that our approach can be combined with locality-sensitive\nhashing to design an algorithm whose running time improves as $\\rho$ gets\nlarger. To our knowledge, this is the first algorithm which combines fast\nmatrix multiplication with hashing for the light bulb problem or any closest\npair problem, and it leads to faster algorithms for small $\\rho>0$.\n  We also introduce a new tensor $T_{2112}$, which has the same size of $2\n\\times 2$ matrix multiplication tensor, but runs faster than the Strassen's\nalgorithm for light bulb problem.",
            "author": [
                "Josh Alman",
                "Hengjie Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01630v1",
                "http://arxiv.org/pdf/2311.01630v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01620v1",
            "title": "ACQUIRED: A Dataset for Answering Counterfactual Questions In Real-Life\n  Videos",
            "updated": "2023-11-02T22:17:03Z",
            "published": "2023-11-02T22:17:03Z",
            "summary": "Multimodal counterfactual reasoning is a vital yet challenging ability for AI\nsystems. It involves predicting the outcomes of hypothetical circumstances\nbased on vision and language inputs, which enables AI models to learn from\nfailures and explore hypothetical scenarios. Despite its importance, there are\nonly a few datasets targeting the counterfactual reasoning abilities of\nmultimodal models. Among them, they only cover reasoning over synthetic\nenvironments or specific types of events (e.g. traffic collisions), making them\nhard to reliably benchmark the model generalization ability in diverse\nreal-world scenarios and reasoning dimensions. To overcome these limitations,\nwe develop a video question answering dataset, ACQUIRED: it consists of 3.9K\nannotated videos, encompassing a wide range of event types and incorporating\nboth first and third-person viewpoints, which ensures a focus on real-world\ndiversity. In addition, each video is annotated with questions that span three\ndistinct dimensions of reasoning, including physical, social, and temporal,\nwhich can comprehensively evaluate the model counterfactual abilities along\nmultiple aspects. We benchmark our dataset against several state-of-the-art\nlanguage-only and multimodal models and experimental results demonstrate a\nsignificant performance gap (>13%) between models and humans. The findings\nsuggest that multimodal counterfactual reasoning remains an open challenge and\nACQUIRED is a comprehensive and reliable benchmark for inspiring future\nresearch in this direction.",
            "author": [
                "Te-Lin Wu",
                "Zi-Yi Dou",
                "Qingyuan Hu",
                "Yu Hou",
                "Nischal Reddy Chandra",
                "Marjorie Freedman",
                "Ralph M. Weischedel",
                "Nanyun Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01620v1",
                "http://arxiv.org/pdf/2311.01620v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01617v1",
            "title": "Look-Ahead Selective Plasticity for Continual Learning of Visual Tasks",
            "updated": "2023-11-02T22:00:23Z",
            "published": "2023-11-02T22:00:23Z",
            "summary": "Contrastive representation learning has emerged as a promising technique for\ncontinual learning as it can learn representations that are robust to\ncatastrophic forgetting and generalize well to unseen future tasks. Previous\nwork in continual learning has addressed forgetting by using previous task data\nand trained models. Inspired by event models created and updated in the brain,\nwe propose a new mechanism that takes place during task boundaries, i.e., when\none task finishes and another starts. By observing the redundancy-inducing\nability of contrastive loss on the output of a neural network, our method\nleverages the first few samples of the new task to identify and retain\nparameters contributing most to the transfer ability of the neural network,\nfreeing up the remaining parts of the network to learn new features. We\nevaluate the proposed methods on benchmark computer vision datasets including\nCIFAR10 and TinyImagenet and demonstrate state-of-the-art performance in the\ntask-incremental, class-incremental, and domain-incremental continual learning\nscenarios.",
            "author": [
                "Rouzbeh Meshkinnejad",
                "Jie Mei",
                "Daniel Lizotte",
                "Yalda Mohsenzadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01617v1",
                "http://arxiv.org/pdf/2311.01617v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01615v1",
            "title": "FLAP: Fast Language-Audio Pre-training",
            "updated": "2023-11-02T21:58:50Z",
            "published": "2023-11-02T21:58:50Z",
            "summary": "We propose Fast Language-Audio Pre-training (FLAP), a self-supervised\napproach that efficiently and effectively learns aligned audio and language\nrepresentations through masking, contrastive learning and reconstruction. For\nefficiency, FLAP randomly drops audio spectrogram tokens, focusing solely on\nthe remaining ones for self-supervision. Through inter-modal contrastive\nlearning, FLAP learns to align paired audio and text representations in a\nshared latent space. Notably, FLAP leverages multiple augmented views via\nmasking for inter-modal contrast and learns to reconstruct the masked portion\nof audio tokens. Moreover, FLAP leverages large language models (LLMs) to\naugment the text inputs, contributing to improved performance. These approaches\nlead to more robust and informative audio-text representations, enabling FLAP\nto achieve state-of-the-art (SoTA) performance on audio-text retrieval tasks on\nAudioCaps (achieving 53.0% R@1) and Clotho (achieving 25.5% R@1).",
            "author": [
                "Ching-Feng Yeh",
                "Po-Yao Huang",
                "Vasu Sharma",
                "Shang-Wen Li",
                "Gargi Gosh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01615v1",
                "http://arxiv.org/pdf/2311.01615v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01609v1",
            "title": "Responsible Emergent Multi-Agent Behavior",
            "updated": "2023-11-02T21:37:32Z",
            "published": "2023-11-02T21:37:32Z",
            "summary": "Responsible AI has risen to the forefront of the AI research community. As\nneural network-based learning algorithms continue to permeate real-world\napplications, the field of Responsible AI has played a large role in ensuring\nthat such systems maintain a high-level of human-compatibility. Despite this\nprogress, the state of the art in Responsible AI has ignored one crucial point:\nhuman problems are multi-agent problems. Predominant approaches largely\nconsider the performance of a single AI system in isolation, but human problems\nare, by their very nature, multi-agent. From driving in traffic to negotiating\neconomic policy, human problem-solving involves interaction and the interplay\nof the actions and motives of multiple individuals.\n  This dissertation develops the study of responsible emergent multi-agent\nbehavior, illustrating how researchers and practitioners can better understand\nand shape multi-agent learning with respect to three pillars of Responsible AI:\ninterpretability, fairness, and robustness. First, I investigate multi-agent\ninterpretability, presenting novel techniques for understanding emergent\nmulti-agent behavior at multiple levels of granularity. With respect to\nlow-level interpretability, I examine the extent to which implicit\ncommunication emerges as an aid to coordination in multi-agent populations. I\nintroduce a novel curriculum-driven method for learning high-performing\npolicies in difficult, sparse reward environments and show through a measure of\nposition-based social influence that multi-agent teams that learn sophisticated\ncoordination strategies exchange significantly more information through\nimplicit signals than lesser-coordinated agents. Then, at a high-level, I study\nconcept-based interpretability in the context of multi-agent learning. I\npropose a novel method for learning intrinsically interpretable, concept-based\npolicies and show that it enables...",
            "author": [
                "Niko A. Grupen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01609v1",
                "http://arxiv.org/pdf/2311.01609v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02110v1",
            "title": "Feature Attribution Explanations for Spiking Neural Networks",
            "updated": "2023-11-02T21:30:56Z",
            "published": "2023-11-02T21:30:56Z",
            "summary": "Third-generation artificial neural networks, Spiking Neural Networks (SNNs),\ncan be efficiently implemented on hardware. Their implementation on\nneuromorphic chips opens a broad range of applications, such as machine\nlearning-based autonomous control and intelligent biomedical devices. In\ncritical applications, however, insight into the reasoning of SNNs is\nimportant, thus SNNs need to be equipped with the ability to explain how\ndecisions are reached. We present \\textit{Temporal Spike Attribution} (TSA), a\nlocal explanation method for SNNs. To compute the explanation, we aggregate all\ninformation available in model-internal variables: spike times and model\nweights. We evaluate TSA on artificial and real-world time series data and\nmeasure explanation quality w.r.t. multiple quantitative criteria. We find that\nTSA correctly identifies a small subset of input features relevant to the\ndecision (i.e., is output-complete and compact) and generates similar\nexplanations for similar inputs (i.e., is continuous). Further, our experiments\nshow that incorporating the notion of \\emph{absent} spikes improves explanation\nquality. Our work can serve as a starting point for explainable SNNs, with\nfuture implementations on hardware yielding not only predictions but also\nexplanations in a broad range of application scenarios. Source code is\navailable at https://github.com/ElisaNguyen/tsa-explanations.",
            "author": [
                "Elisa Nguyen",
                "Meike Nauta",
                "Gwenn Englebienne",
                "Christin Seifert"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02110v1",
                "http://arxiv.org/pdf/2311.02110v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01602v1",
            "title": "DRNet: A Decision-Making Method for Autonomous Lane Changingwith Deep\n  Reinforcement Learning",
            "updated": "2023-11-02T21:17:52Z",
            "published": "2023-11-02T21:17:52Z",
            "summary": "Machine learning techniques have outperformed numerous rule-based methods for\ndecision-making in autonomous vehicles. Despite recent efforts, lane changing\nremains a major challenge, due to the complex driving scenarios and changeable\nsocial behaviors of surrounding vehicles. To help improve the state of the art,\nwe propose to leveraging the emerging \\underline{D}eep\n\\underline{R}einforcement learning (DRL) approach for la\\underline{NE} changing\nat the \\underline{T}actical level. To this end, we present \"DRNet\", a novel and\nhighly efficient DRL-based framework that enables a DRL agent to learn to drive\nby executing reasonable lane changing on simulated highways with an arbitrary\nnumber of lanes, and considering driving style of surrounding vehicles to make\nbetter decisions. Furthermore, to achieve a safe policy for decision-making,\nDRNet incorporates ideas from safety verification, the most important component\nof autonomous driving, to ensure that only safe actions are chosen at any time.\nThe setting of our state representation and reward function enables the trained\nagent to take appropriate actions in a real-world-like simulator. Our DRL agent\nhas the ability to learn the desired task without causing collisions and\noutperforms DDQN and other baseline models.",
            "author": [
                "Kunpeng Xu",
                "Lifei Chen",
                "Shengrui Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01602v1",
                "http://arxiv.org/pdf/2311.01602v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01599v1",
            "title": "Local Borsuk-Ulam, Stability, and Replicability",
            "updated": "2023-11-02T21:10:16Z",
            "published": "2023-11-02T21:10:16Z",
            "summary": "We use and adapt the Borsuk-Ulam Theorem from topology to derive limitations\non list-replicable and globally stable learning algorithms. We further\ndemonstrate the applicability of our methods in combinatorics and topology.\n  We show that, besides trivial cases, both list-replicable and globally stable\nlearning are impossible in the agnostic PAC setting. This is in contrast with\nthe realizable case where it is known that any class with a finite Littlestone\ndimension can be learned by such algorithms. In the realizable PAC setting, we\nsharpen previous impossibility results and broaden their scope. Specifically,\nwe establish optimal bounds for list replicability and global stability numbers\nin finite classes. This provides an exponential improvement over previous works\nand implies an exponential separation from the Littlestone dimension. We\nfurther introduce lower bounds for weak learners, i.e., learners that are only\nmarginally better than random guessing. Lower bounds from previous works apply\nonly to stronger learners.\n  To offer a broader and more comprehensive view of our topological approach,\nwe prove a local variant of the Borsuk-Ulam theorem in topology and a result in\ncombinatorics concerning Kneser colorings. In combinatorics, we prove that if\n$c$ is a coloring of all non-empty subsets of $[n]$ such that disjoint sets\nhave different colors, then there is a chain of subsets that receives at least\n$1+ \\lfloor n/2\\rfloor$ colors (this bound is sharp). In topology, we prove\ne.g. that for any open antipodal-free cover of the $d$-dimensional sphere,\nthere is a point $x$ that belongs to at least $t=\\lceil\\frac{d+3}{2}\\rceil$\nsets.",
            "author": [
                "Zachary Chase",
                "Bogdan Chornomaz",
                "Shay Moran",
                "Amir Yehudayoff"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01599v1",
                "http://arxiv.org/pdf/2311.01599v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS",
                "I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01596v1",
            "title": "Local Bayesian Dirichlet mixing of imperfect models",
            "updated": "2023-11-02T21:02:40Z",
            "published": "2023-11-02T21:02:40Z",
            "summary": "To improve the predictability of complex computational models in the\nexperimentally-unknown domains, we propose a Bayesian statistical machine\nlearning framework utilizing the Dirichlet distribution that combines results\nof several imperfect models. This framework can be viewed as an extension of\nBayesian stacking. To illustrate the method, we study the ability of Bayesian\nmodel averaging and mixing techniques to mine nuclear masses. We show that the\nglobal and local mixtures of models reach excellent performance on both\nprediction accuracy and uncertainty quantification and are preferable to\nclassical Bayesian model averaging. Additionally, our statistical analysis\nindicates that improving model predictions through mixing rather than mixing of\ncorrected models leads to more robust extrapolations.",
            "author": [
                "Vojtech Kejzlar",
                "L\u00e9o Neufcourt",
                "Witold Nazarewicz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01596v1",
                "http://arxiv.org/pdf/2311.01596v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "nucl-th",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01594v1",
            "title": "Intelligent QoS aware slice resource allocation with user association\n  parameterization for beyond 5G ORAN based architecture using DRL",
            "updated": "2023-11-02T21:00:16Z",
            "published": "2023-11-02T21:00:16Z",
            "summary": "The diverse requirements of beyond 5G services increase design complexity and\ndemand dynamic adjustments to the network parameters. This can be achieved with\nslicing and programmable network architectures such as the open radio access\nnetwork (ORAN). It facilitates the tuning of the network components exactly to\nthe demands of future-envisioned applications as well as intelligence at the\nedge of the network. Artificial intelligence (AI) has recently drawn a lot of\ninterest for its potential to solve challenging issues in wireless\ncommunication. Due to the non-deterministic, random, and complex behavior of\nmodels and parameters involved in the process, radio resource management is one\nof the topics that needs to be addressed with such techniques. The study\npresented in this paper proposes quality of service (QoS)-aware intra-slice\nresource allocation that provides superior performance compared to baseline and\nstate of the art strategies. The slice-dedicated intelligent agents learn how\nto handle resources at near-RT RIC level time granularities while optimizing\nvarious key performance indicators (KPIs) and meeting QoS requirements for each\nend user. In order to improve KPIs and system performance with various reward\nfunctions, the study discusses Markov's decision process (MDP) and deep\nreinforcement learning (DRL) techniques, notably the deep Q network (DQN). The\nsimulation evaluates the efficacy of the algorithm under dynamic conditions and\nvarious network characteristics. Results and analysis demonstrate the\nimprovement in the performance of the network for enhanced mobile broadband\n(eMBB) and ultra-reliable low latency (URLLC) slice categories.",
            "author": [
                "Suvidha Mhatre",
                "Ferran Adelantado",
                "Kostas Ramantas",
                "Christos Verikoukis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01594v1",
                "http://arxiv.org/pdf/2311.01594v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01591v1",
            "title": "Better Fair than Sorry: Adversarial Missing Data Imputation for Fair\n  GNNs",
            "updated": "2023-11-02T20:57:44Z",
            "published": "2023-11-02T20:57:44Z",
            "summary": "This paper addresses the problem of learning fair Graph Neural Networks\n(GNNs) under missing protected attributes. GNNs have achieved state-of-the-art\nresults in many relevant tasks where decisions might disproportionately impact\nspecific communities. However, existing work on fair GNNs assumes that either\nprotected attributes are fully-observed or that the missing data imputation is\nfair. In practice, biases in the imputation will be propagated to the model\noutcomes, leading them to overestimate the fairness of their predictions. We\naddress this challenge by proposing Better Fair than Sorry (BFtS), a fair\nmissing data imputation model for protected attributes used by fair GNNs. The\nkey design principle behind BFtS is that imputations should approximate the\nworst-case scenario for the fair GNN -- i.e. when optimizing fairness is the\nhardest. We implement this idea using a 3-player adversarial scheme where two\nadversaries collaborate against the fair GNN. Experiments using synthetic and\nreal datasets show that BFtS often achieves a better fairness $\\times$ accuracy\ntrade-off than existing alternatives.",
            "author": [
                "Debolina Halder Lina",
                "Arlei Silva"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01591v1",
                "http://arxiv.org/pdf/2311.01591v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01589v1",
            "title": "A Statistical Guarantee for Representation Transfer in Multitask\n  Imitation Learning",
            "updated": "2023-11-02T20:45:29Z",
            "published": "2023-11-02T20:45:29Z",
            "summary": "Transferring representation for multitask imitation learning has the\npotential to provide improved sample efficiency on learning new tasks, when\ncompared to learning from scratch. In this work, we provide a statistical\nguarantee indicating that we can indeed achieve improved sample efficiency on\nthe target task when a representation is trained using sufficiently diverse\nsource tasks. Our theoretical results can be readily extended to account for\ncommonly used neural network architectures with realistic assumptions. We\nconduct empirical analyses that align with our theoretical findings on four\nsimulated environments$\\unicode{x2014}$in particular leveraging more data from\nsource tasks can improve sample efficiency on learning in the new task.",
            "author": [
                "Bryan Chan",
                "Karime Pereida",
                "James Bergstra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01589v1",
                "http://arxiv.org/pdf/2311.01589v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01588v2",
            "title": "Domain Adaptive Graph Neural Networks for Constraining Cosmological\n  Parameters Across Multiple Data Sets",
            "updated": "2023-11-21T19:16:51Z",
            "published": "2023-11-02T20:40:21Z",
            "summary": "Deep learning models have been shown to outperform methods that rely on\nsummary statistics, like the power spectrum, in extracting information from\ncomplex cosmological data sets. However, due to differences in the subgrid\nphysics implementation and numerical approximations across different simulation\nsuites, models trained on data from one cosmological simulation show a drop in\nperformance when tested on another. Similarly, models trained on any of the\nsimulations would also likely experience a drop in performance when applied to\nobservational data. Training on data from two different suites of the CAMELS\nhydrodynamic cosmological simulations, we examine the generalization\ncapabilities of Domain Adaptive Graph Neural Networks (DA-GNNs). By utilizing\nGNNs, we capitalize on their capacity to capture structured scale-free\ncosmological information from galaxy distributions. Moreover, by including\nunsupervised domain adaptation via Maximum Mean Discrepancy (MMD), we enable\nour models to extract domain-invariant features. We demonstrate that DA-GNN\nachieves higher accuracy and robustness on cross-dataset tasks (up to $28\\%$\nbetter relative error and up to almost an order of magnitude better $\\chi^2$).\nUsing data visualizations, we show the effects of domain adaptation on proper\nlatent space data alignment. This shows that DA-GNNs are a promising method for\nextracting domain-independent cosmological information, a vital step toward\nrobust deep learning for real cosmic survey data.",
            "author": [
                "Andrea Roncoli",
                "Aleksandra \u0106iprijanovi\u0107",
                "Maggie Voetberg",
                "Francisco Villaescusa-Navarro",
                "Brian Nord"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01588v2",
                "http://arxiv.org/pdf/2311.01588v2"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04229v1",
            "title": "Exploring Best Practices for ECG Signal Processing in Machine Learning",
            "updated": "2023-11-02T20:29:15Z",
            "published": "2023-11-02T20:29:15Z",
            "summary": "In this work we search for best practices in pre-processing of\nElectrocardiogram (ECG) signals in order to train better classifiers for the\ndiagnosis of heart conditions. State of the art machine learning algorithms\nhave achieved remarkable results in classification of some heart conditions\nusing ECG data, yet there appears to be no consensus on pre-processing best\npractices. Is this lack of consensus due to different conditions and\narchitectures requiring different processing steps for optimal performance? Is\nit possible that state of the art deep-learning models have rendered\npre-processing unnecessary? In this work we apply down-sampling, normalization,\nand filtering functions to 3 different multi-label ECG datasets and measure\ntheir effects on 3 different high-performing time-series classifiers. We find\nthat sampling rates as low as 50Hz can yield comparable results to the commonly\nused 500Hz. This is significant as smaller sampling rates will result in\nsmaller datasets and models, which require less time and resources to train.\nAdditionally, despite their common usage, we found min-max normalization to be\nslightly detrimental overall, and band-passing to make no measurable\ndifference. We found the blind approach to pre-processing of ECGs for\nmulti-label classification to be ineffective, with the exception of sample rate\nreduction which reliably reduces computational resources, but does not increase\naccuracy.",
            "author": [
                "Amir Salimi",
                "Sunil Vasu Kalmady",
                "Abram Hindle",
                "Osmar Zaiane",
                "Padma Kaul"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04229v1",
                "http://arxiv.org/pdf/2311.04229v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01580v1",
            "title": "MetaReVision: Meta-Learning with Retrieval for Visually Grounded\n  Compositional Concept Acquisition",
            "updated": "2023-11-02T20:19:58Z",
            "published": "2023-11-02T20:19:58Z",
            "summary": "Humans have the ability to learn novel compositional concepts by recalling\nand generalizing primitive concepts acquired from past experiences. Inspired by\nthis observation, in this paper, we propose MetaReVision, a retrieval-enhanced\nmeta-learning model to address the visually grounded compositional concept\nlearning problem. The proposed MetaReVision consists of a retrieval module and\na meta-learning module which are designed to incorporate retrieved primitive\nconcepts as a supporting set to meta-train vision-anguage models for grounded\ncompositional concept recognition. Through meta-learning from episodes\nconstructed by the retriever, MetaReVision learns a generic compositional\nrepresentation that can be fast updated to recognize novel compositional\nconcepts. We create CompCOCO and CompFlickr to benchmark the grounded\ncompositional concept learning. Our experimental results show that MetaReVision\noutperforms other competitive baselines and the retrieval module plays an\nimportant role in this compositional learning process.",
            "author": [
                "Guangyue Xu",
                "Parisa Kordjamshidi",
                "Joyce Chai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01580v1",
                "http://arxiv.org/pdf/2311.01580v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01575v1",
            "title": "On the Convergence of Encoder-only Shallow Transformers",
            "updated": "2023-11-02T20:03:05Z",
            "published": "2023-11-02T20:03:05Z",
            "summary": "In this paper, we aim to build the global convergence theory of encoder-only\nshallow Transformers under a realistic setting from the perspective of\narchitectures, initialization, and scaling under a finite width regime. The\ndifficulty lies in how to tackle the softmax in self-attention mechanism, the\ncore ingredient of Transformer. In particular, we diagnose the scaling scheme,\ncarefully tackle the input/output of softmax, and prove that quadratic\noverparameterization is sufficient for global convergence of our shallow\nTransformers under commonly-used He/LeCun initialization in practice. Besides,\nneural tangent kernel (NTK) based analysis is also given, which facilitates a\ncomprehensive comparison. Our theory demonstrates the separation on the\nimportance of different scaling schemes and initialization. We believe our\nresults can pave the way for a better understanding of modern Transformers,\nparticularly on training dynamics.",
            "author": [
                "Yongtao Wu",
                "Fanghui Liu",
                "Grigorios G Chrysos",
                "Volkan Cevher"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01575v1",
                "http://arxiv.org/pdf/2311.01575v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01574v1",
            "title": "Improving Lesion Segmentation in FDG-18 Whole-Body PET/CT scans using\n  Multilabel approach: AutoPET II challenge",
            "updated": "2023-11-02T19:51:54Z",
            "published": "2023-11-02T19:51:54Z",
            "summary": "Automatic segmentation of lesions in FDG-18 Whole Body (WB) PET/CT scans\nusing deep learning models is instrumental for determining treatment response,\noptimizing dosimetry, and advancing theranostic applications in oncology.\nHowever, the presence of organs with elevated radiotracer uptake, such as the\nliver, spleen, brain, and bladder, often leads to challenges, as these regions\nare often misidentified as lesions by deep learning models. To address this\nissue, we propose a novel approach of segmenting both organs and lesions,\naiming to enhance the performance of automatic lesion segmentation methods. In\nthis study, we assessed the effectiveness of our proposed method using the\nAutoPET II challenge dataset, which comprises 1014 subjects. We evaluated the\nimpact of inclusion of additional labels and data in the segmentation\nperformance of the model. In addition to the expert-annotated lesion labels, we\nintroduced eight additional labels for organs, including the liver, kidneys,\nurinary bladder, spleen, lung, brain, heart, and stomach. These labels were\nintegrated into the dataset, and a 3D UNET model was trained within the nnUNet\nframework. Our results demonstrate that our method achieved the top ranking in\nthe held-out test dataset, underscoring the potential of this approach to\nsignificantly improve lesion segmentation accuracy in FDG-18 Whole-Body PET/CT\nscans, ultimately benefiting cancer patients and advancing clinical practice.",
            "author": [
                "Gowtham Krishnan Murugesan",
                "Diana McCrumb",
                "Eric Brunner",
                "Jithendra Kumar",
                "Rahul Soni",
                "Vasily Grigorash",
                "Stephen Moore",
                "Jeff Van Oss"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01574v1",
                "http://arxiv.org/pdf/2311.01574v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01573v1",
            "title": "Improving Fairness using Vision-Language Driven Image Augmentation",
            "updated": "2023-11-02T19:51:10Z",
            "published": "2023-11-02T19:51:10Z",
            "summary": "Fairness is crucial when training a deep-learning discriminative model,\nespecially in the facial domain. Models tend to correlate specific\ncharacteristics (such as age and skin color) with unrelated attributes\n(downstream tasks), resulting in biases which do not correspond to reality. It\nis common knowledge that these correlations are present in the data and are\nthen transferred to the models during training. This paper proposes a method to\nmitigate these correlations to improve fairness. To do so, we learn\ninterpretable and meaningful paths lying in the semantic space of a pre-trained\ndiffusion model (DiffAE) -- such paths being supervised by contrastive text\ndipoles. That is, we learn to edit protected characteristics (age and skin\ncolor). These paths are then applied to augment images to improve the fairness\nof a given dataset. We test the proposed method on CelebA-HQ and UTKFace on\nseveral downstream tasks with age and skin color as protected characteristics.\nAs a proxy for fairness, we compute the difference in accuracy with respect to\nthe protected characteristics. Quantitative results show how the augmented\nimages help the model improve the overall accuracy, the aforementioned metric,\nand the disparity of equal opportunity. Code is available at:\nhttps://github.com/Moreno98/Vision-Language-Bias-Control.",
            "author": [
                "Moreno D'Inc\u00e0",
                "Christos Tzelepis",
                "Ioannis Patras",
                "Nicu Sebe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01573v1",
                "http://arxiv.org/pdf/2311.01573v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01571v1",
            "title": "Preserving the knowledge of long clinical texts using aggregated\n  ensembles of large language models",
            "updated": "2023-11-02T19:50:02Z",
            "published": "2023-11-02T19:50:02Z",
            "summary": "Clinical texts, such as admission notes, discharge summaries, and progress\nnotes, contain rich and valuable information that can be used for various\nclinical outcome prediction tasks. However, applying large language models,\nsuch as BERT-based models, to clinical texts poses two major challenges: the\nlimitation of input length and the diversity of data sources. This paper\nproposes a novel method to preserve the knowledge of long clinical texts using\naggregated ensembles of large language models. Unlike previous studies which\nuse model ensembling or text aggregation methods separately, we combine\nensemble learning with text aggregation and train multiple large language\nmodels on two clinical outcome tasks: mortality prediction and length of stay\nprediction. We show that our method can achieve better results than baselines,\nensembling, and aggregation individually, and can improve the performance of\nlarge language models while handling long inputs and diverse datasets. We\nconduct extensive experiments on the admission notes from the MIMIC-III\nclinical database by combining multiple unstructured and high-dimensional\ndatasets, demonstrating our method's effectiveness and superiority over\nexisting approaches. We also provide a comprehensive analysis and discussion of\nour results, highlighting our method's applications and limitations for future\nresearch in the domain of clinical healthcare. The results and analysis of this\nstudy is supportive of our method assisting in clinical healthcare systems by\nenabling clinical decision-making with robust performance overcoming the\nchallenges of long text inputs and varied datasets.",
            "author": [
                "Mohammad Junayed Hasan",
                "Suhra Noor",
                "Mohammad Ashrafuzzaman Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01571v1",
                "http://arxiv.org/pdf/2311.01571v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01570v1",
            "title": "Sequential Subset Matching for Dataset Distillation",
            "updated": "2023-11-02T19:49:11Z",
            "published": "2023-11-02T19:49:11Z",
            "summary": "Dataset distillation is a newly emerging task that synthesizes a small-size\ndataset used in training deep neural networks (DNNs) for reducing data storage\nand model training costs. The synthetic datasets are expected to capture the\nessence of the knowledge contained in real-world datasets such that the former\nyields a similar performance as the latter. Recent advancements in distillation\nmethods have produced notable improvements in generating synthetic datasets.\nHowever, current state-of-the-art methods treat the entire synthetic dataset as\na unified entity and optimize each synthetic instance equally. This static\noptimization approach may lead to performance degradation in dataset\ndistillation. Specifically, we argue that static optimization can give rise to\na coupling issue within the synthetic data, particularly when a larger amount\nof synthetic data is being optimized. This coupling issue, in turn, leads to\nthe failure of the distilled dataset to extract the high-level features learned\nby the deep neural network (DNN) in the latter epochs.\n  In this study, we propose a new dataset distillation strategy called\nSequential Subset Matching (SeqMatch), which tackles this problem by adaptively\noptimizing the synthetic data to encourage sequential acquisition of knowledge\nduring dataset distillation. Our analysis indicates that SeqMatch effectively\naddresses the coupling issue by sequentially generating the synthetic\ninstances, thereby enhancing its performance significantly. Our proposed\nSeqMatch outperforms state-of-the-art methods in various datasets, including\nSVNH, CIFAR-10, CIFAR-100, and Tiny ImageNet. Our code is available at\nhttps://github.com/shqii1j/seqmatch.",
            "author": [
                "Jiawei Du",
                "Qin Shi",
                "Joey Tianyi Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01570v1",
                "http://arxiv.org/pdf/2311.01570v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01568v2",
            "title": "Anytime-Competitive Reinforcement Learning with Policy Prior",
            "updated": "2023-11-13T08:15:37Z",
            "published": "2023-11-02T19:44:59Z",
            "summary": "This paper studies the problem of Anytime-Competitive Markov Decision Process\n(A-CMDP). Existing works on Constrained Markov Decision Processes (CMDPs) aim\nto optimize the expected reward while constraining the expected cost over\nrandom dynamics, but the cost in a specific episode can still be\nunsatisfactorily high. In contrast, the goal of A-CMDP is to optimize the\nexpected reward while guaranteeing a bounded cost in each round of any episode\nagainst a policy prior. We propose a new algorithm, called Anytime-Competitive\nReinforcement Learning (ACRL), which provably guarantees the anytime cost\nconstraints. The regret analysis shows the policy asymptotically matches the\noptimal reward achievable under the anytime competitive constraints.\nExperiments on the application of carbon-intelligent computing verify the\nreward performance and cost constraint guarantee of ACRL.",
            "author": [
                "Jianyi Yang",
                "Pengfei Li",
                "Tongxin Li",
                "Adam Wierman",
                "Shaolei Ren"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01568v2",
                "http://arxiv.org/pdf/2311.01568v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01548v2",
            "title": "The MadNIS Reloaded",
            "updated": "2023-11-16T09:33:11Z",
            "published": "2023-11-02T19:00:01Z",
            "summary": "In pursuit of precise and fast theory predictions for the LHC, we present an\nimplementation of the MadNIS method in the MadGraph event generator. A series\nof improvements in MadNIS further enhance its efficiency and speed. We validate\nthis implementation for realistic partonic processes and find significant gains\nfrom using modern machine learning in event generators.",
            "author": [
                "Theo Heimel",
                "Nathan Huetsch",
                "Fabio Maltoni",
                "Olivier Mattelaer",
                "Tilman Plehn",
                "Ramon Winterhalder"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01548v2",
                "http://arxiv.org/pdf/2311.01548v2"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01545v2",
            "title": "Quantifying chemical short-range order in metallic alloys",
            "updated": "2023-11-22T01:22:06Z",
            "published": "2023-11-02T18:57:01Z",
            "summary": "Metallic alloys often form phases - known as solid solutions - in which\nchemical elements are spread out on the same crystal lattice in an almost\nrandom manner. The tendency of certain chemical motifs to be more common than\nothers is known as chemical short-range order (SRO) and it has received\nsubstantial consideration in alloys with multiple chemical elements present in\nlarge concentrations due to their extreme configurational complexity (e.g.,\nhigh-entropy alloys). Short-range order renders solid solutions \"slightly less\nrandom than completely random\", which is a physically intuitive picture, but\nnot easily quantifiable due to the sheer number of possible chemical motifs and\ntheir subtle spatial distribution on the lattice. Here we present a multiscale\nmethod to predict and quantify the SRO state of an alloy with atomic\nresolution, incorporating machine learning techniques to bridge the gap between\nelectronic-structure calculations and the characteristic length scale of SRO.\nThe result is an approach capable of predicting SRO length scale in agreement\nwith experimental measurements while comprehensively correlating SRO with\nfundamental quantities such as local lattice distortions. This work advances\nthe quantitative understanding of solid-solution phases, paving the way for SRO\nrigorous incorporation into predictive mechanical and thermodynamic models.",
            "author": [
                "Killian Sheriff",
                "Yifan Cao",
                "Tess Smidt",
                "Rodrigo Freitas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01545v2",
                "http://arxiv.org/pdf/2311.01545v2"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01544v2",
            "title": "Divergent Token Metrics: Measuring degradation to prune away LLM\n  components -- and optimize quantization",
            "updated": "2023-11-13T15:33:35Z",
            "published": "2023-11-02T18:55:53Z",
            "summary": "Large Language Models (LLMs) have reshaped natural language processing with\ntheir impressive capabilities. Their ever-increasing size, however, raised\nconcerns about their effective deployment and the need for LLM compressions.\nThis study introduces the Divergent Token metrics (DTMs), a novel approach for\nassessing compressed LLMs, addressing the limitations of traditional perplexity\nor accuracy measures that fail to accurately reflect text generation quality.\nDTMs focus on token divergence, that allow deeper insights into the subtleties\nof model compression, i.p. when evaluating component's impacts individually.\nUtilizing the First Divergent Token metric (FDTM) in model sparsification\nreveals that a quarter of all attention components can be pruned beyond 90% on\nthe Llama-2 model family, still keeping SOTA performance. For quantization FDTM\nsuggests that over 80% of parameters can naively be transformed to int8 without\nspecial outlier management. These evaluations indicate the necessity of\nchoosing appropriate compressions for parameters individually-and that FDTM can\nidentify those-while standard metrics result in deteriorated outcomes.",
            "author": [
                "Bj\u00f6rn Deiseroth",
                "Max Meuer",
                "Nikolas Gritsch",
                "Constantin Eichenberg",
                "Patrick Schramowski",
                "Matthias A\u00dfenmacher",
                "Kristian Kersting"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01544v2",
                "http://arxiv.org/pdf/2311.01544v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01538v1",
            "title": "A reluctant additive model framework for interpretable nonlinear\n  individualized treatment rules",
            "updated": "2023-11-02T18:44:02Z",
            "published": "2023-11-02T18:44:02Z",
            "summary": "Individualized treatment rules (ITRs) for treatment recommendation is an\nimportant topic for precision medicine as not all beneficial treatments work\nwell for all individuals. Interpretability is a desirable property of ITRs, as\nit helps practitioners make sense of treatment decisions, yet there is a need\nfor ITRs to be flexible to effectively model complex biomedical data for\ntreatment decision making. Many ITR approaches either focus on linear ITRs,\nwhich may perform poorly when true optimal ITRs are nonlinear, or black-box\nnonlinear ITRs, which may be hard to interpret and can be overly complex. This\ndilemma indicates a tension between interpretability and accuracy of treatment\ndecisions. Here we propose an additive model-based nonlinear ITR learning\nmethod that balances interpretability and flexibility of the ITR. Our approach\naims to strike this balance by allowing both linear and nonlinear terms of the\ncovariates in the final ITR. Our approach is parsimonious in that the nonlinear\nterm is included in the final ITR only when it substantially improves the ITR\nperformance. To prevent overfitting, we combine cross-fitting and a specialized\ninformation criterion for model selection. Through extensive simulations, we\nshow that our methods are data-adaptive to the degree of nonlinearity and can\nfavorably balance ITR interpretability and flexibility. We further demonstrate\nthe robust performance of our methods with an application to a cancer drug\nsensitive study.",
            "author": [
                "Jacob M. Maronge",
                "Jared D. Huling",
                "Guanhua Chen"
            ],
            "link": [
                "http://dx.doi.org/10.1214/23-AOAS1767",
                "http://arxiv.org/abs/2311.01538v1",
                "http://arxiv.org/pdf/2311.01538v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01537v1",
            "title": "Variable Selection in Maximum Mean Discrepancy for Interpretable\n  Distribution Comparison",
            "updated": "2023-11-02T18:38:39Z",
            "published": "2023-11-02T18:38:39Z",
            "summary": "Two-sample testing decides whether two datasets are generated from the same\ndistribution. This paper studies variable selection for two-sample testing, the\ntask being to identify the variables (or dimensions) responsible for the\ndiscrepancies between the two distributions. This task is relevant to many\nproblems of pattern analysis and machine learning, such as dataset shift\nadaptation, causal inference and model validation. Our approach is based on a\ntwo-sample test based on the Maximum Mean Discrepancy (MMD). We optimise the\nAutomatic Relevance Detection (ARD) weights defined for individual variables to\nmaximise the power of the MMD-based test. For this optimisation, we introduce\nsparse regularisation and propose two methods for dealing with the issue of\nselecting an appropriate regularisation parameter. One method determines the\nregularisation parameter in a data-driven way, and the other aggregates the\nresults of different regularisation parameters. We confirm the validity of the\nproposed methods by systematic comparisons with baseline methods, and\ndemonstrate their usefulness in exploratory analysis of high-dimensional\ntraffic simulation data. Preliminary theoretical analyses are also provided,\nincluding a rigorous definition of variable selection for two-sample testing.",
            "author": [
                "Kensuke Mitsuzawa",
                "Motonobu Kanagawa",
                "Stefano Bortoli",
                "Margherita Grossi",
                "Paolo Papotti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01537v1",
                "http://arxiv.org/pdf/2311.01537v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01534v1",
            "title": "Approximate Multiagent Reinforcement Learning for On-Demand Urban\n  Mobility Problem on a Large Map (extended version)",
            "updated": "2023-11-02T18:33:32Z",
            "published": "2023-11-02T18:33:32Z",
            "summary": "In this paper, we focus on the autonomous multiagent taxi routing problem for\na large urban environment where the location and number of future ride requests\nare unknown a-priori, but follow an estimated empirical distribution. Recent\ntheory has shown that if a base policy is stable then a rollout-based algorithm\nwith such a base policy produces a near-optimal stable policy. Although,\nrollout-based approaches are well-suited for learning cooperative multiagent\npolicies with considerations for future demand, applying such methods to a\nlarge urban environment can be computationally expensive. Large environments\ntend to have a large volume of requests, and hence require a large fleet of\ntaxis to guarantee stability. In this paper, we aim to address the\ncomputational bottleneck of multiagent (one-at-a-time) rollout, where the\ncomputational complexity grows linearly in the number of agents. We propose an\napproximate one-at-a-time rollout-based two-phase algorithm that reduces the\ncomputational cost, while still achieving a stable near-optimal policy. Our\napproach partitions the graph into sectors based on the predicted demand and an\nuser-defined maximum number of agents that can be planned for using the\none-at-a-time rollout approach. The algorithm then applies instantaneous\nassignment (IA) for re-balancing taxis across sectors and a sector-wide\none-at-a-time rollout algorithm that is executed in parallel for each sector.\nWe characterize the number of taxis $m$ that is sufficient for IA base policy\nto be stable, and derive a necessary condition on $m$ as time goes to infinity.\nOur numerical results show that our approach achieves stability for an $m$ that\nsatisfies the theoretical conditions. We also empirically demonstrate that our\nproposed two-phase algorithm has comparable performance to the one-at-a-time\nrollout over the entire map, but with significantly lower runtimes.",
            "author": [
                "Daniel Garces",
                "Sushmita Bhattacharya",
                "Dimitri Bertsekas",
                "Stephanie Gil"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01534v1",
                "http://arxiv.org/pdf/2311.01534v1"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01527v1",
            "title": "To pair or not to pair? Machine-learned explicitly-correlated electronic\n  structure for NaCl in water",
            "updated": "2023-11-02T18:23:19Z",
            "published": "2023-11-02T18:23:19Z",
            "summary": "The extent of ion pairing in solution is an important phenomenon to\nrationalise transport and thermodynamic properties of electrolytes. A\nfundamental measure of this pairing is the potential of mean force (PMF)\nbetween the solvated ions. The relative stabilities of the paired and solvent\nseparated states in the PMF are highly sensitive to the underlying potential\nenergy surface. However direct application of accurate electronic structure\nmethods to resolve this property is challenging, since long simulations are\nrequired. Leveraging developments in machine learning potentials and electronic\nstructure methods, we obtain wavefunction based models with RPA and MP2 for the\nprototypical system of Na and Cl ions in water. We show that even among these\nmethods, discrepancies in the PMF still remain, and also highlight shortcomings\nof density functional theory and classical force-field predictions. These\nmodels are primed for application to computationally intensive electrolyte\nproperties including transport coefficients and even confined systems, all of\nwhich are highly sensitive to their chosen reference electronic structure\nmethod.",
            "author": [
                "Niamh O'Neill",
                "Benjamin X. Shi",
                "Kara Fong",
                "Angelos Michaelides",
                "Christoph Schran"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01527v1",
                "http://arxiv.org/pdf/2311.01527v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01526v1",
            "title": "ATGNN: Audio Tagging Graph Neural Network",
            "updated": "2023-11-02T18:19:26Z",
            "published": "2023-11-02T18:19:26Z",
            "summary": "Deep learning models such as CNNs and Transformers have achieved impressive\nperformance for end-to-end audio tagging. Recent works have shown that despite\nstacking multiple layers, the receptive field of CNNs remains severely limited.\nTransformers on the other hand are able to map global context through\nself-attention, but treat the spectrogram as a sequence of patches which is not\nflexible enough to capture irregular audio objects. In this work, we treat the\nspectrogram in a more flexible way by considering it as graph structure and\nprocess it with a novel graph neural architecture called ATGNN. ATGNN not only\ncombines the capability of CNNs with the global information sharing ability of\nGraph Neural Networks, but also maps semantic relationships between learnable\nclass embeddings and corresponding spectrogram regions. We evaluate ATGNN on\ntwo audio tagging tasks, where it achieves 0.585 mAP on the FSD50K dataset and\n0.335 mAP on the AudioSet-balanced dataset, achieving comparable results to\nTransformer based models with significantly lower number of learnable\nparameters.",
            "author": [
                "Shubhr Singh",
                "Christian J. Steinmetz",
                "Emmanouil Benetos",
                "Huy Phan",
                "Dan Stowell"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01526v1",
                "http://arxiv.org/pdf/2311.01526v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01522v2",
            "title": "An Efficient Detection and Control System for Underwater Docking using\n  Machine Learning and Realistic Simulation: A Comprehensive Approach",
            "updated": "2023-11-06T19:34:05Z",
            "published": "2023-11-02T18:10:20Z",
            "summary": "Underwater docking is critical to enable the persistent operation of\nAutonomous Underwater Vehicles (AUVs). For this, the AUV must be capable of\ndetecting and localizing the docking station, which is complex due to the\nhighly dynamic undersea environment. Image-based solutions offer a high\nacquisition rate and versatile alternative to adapt to this environment;\nhowever, the underwater environment presents challenges such as low visibility,\nhigh turbidity, and distortion. In addition to this, field experiments to\nvalidate underwater docking capabilities can be costly and dangerous due to the\nspecialized equipment and safety considerations required to conduct the\nexperiments. This work compares different deep-learning architectures to\nperform underwater docking detection and classification. The architecture with\nthe best performance is then compressed using knowledge distillation under the\nteacher-student paradigm to reduce the network's memory footprint, allowing\nreal-time implementation. To reduce the simulation-to-reality gap, a Generative\nAdversarial Network (GAN) is used to do image-to-image translation, converting\nthe Gazebo simulation image into a realistic underwater-looking image. The\nobtained image is then processed using an underwater image formation model to\nsimulate image attenuation over distance under different water types. The\nproposed method is finally evaluated according to the AUV docking success rate\nand compared with classical vision methods. The simulation results show an\nimprovement of 20% in the high turbidity scenarios regardless of the underwater\ncurrents. Furthermore, we show the performance of the proposed approach by\nshowing experimental results on the off-the-shelf AUV Iver3.",
            "author": [
                "Jalil Chavez-Galaviz",
                "Jianwen Li",
                "Matthew Bergman",
                "Miras Mengdibayev",
                "Nina Mahmoudian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01522v2",
                "http://arxiv.org/pdf/2311.01522v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01520v2",
            "title": "4D-Former: Multimodal 4D Panoptic Segmentation",
            "updated": "2023-11-17T21:58:35Z",
            "published": "2023-11-02T18:09:35Z",
            "summary": "4D panoptic segmentation is a challenging but practically useful task that\nrequires every point in a LiDAR point-cloud sequence to be assigned a semantic\nclass label, and individual objects to be segmented and tracked over time.\nExisting approaches utilize only LiDAR inputs which convey limited information\nin regions with point sparsity. This problem can, however, be mitigated by\nutilizing RGB camera images which offer appearance-based information that can\nreinforce the geometry-based LiDAR features. Motivated by this, we propose\n4D-Former: a novel method for 4D panoptic segmentation which leverages both\nLiDAR and image modalities, and predicts semantic masks as well as temporally\nconsistent object masks for the input point-cloud sequence. We encode semantic\nclasses and objects using a set of concise queries which absorb feature\ninformation from both data modalities. Additionally, we propose a learned\nmechanism to associate object tracks over time which reasons over both\nappearance and spatial location. We apply 4D-Former to the nuScenes and\nSemanticKITTI datasets where it achieves state-of-the-art results.",
            "author": [
                "Ali Athar",
                "Enxu Li",
                "Sergio Casas",
                "Raquel Urtasun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01520v2",
                "http://arxiv.org/pdf/2311.01520v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01508v1",
            "title": "$\\texttt{slick}$: Modeling a Universe of Molecular Line Luminosities in\n  Hydrodynamical Simulations",
            "updated": "2023-11-02T18:00:08Z",
            "published": "2023-11-02T18:00:08Z",
            "summary": "We present {\\sc slick} (the Scalable Line Intensity Computation Kit), a\nsoftware package that calculates realistic CO, [\\ion{C}{1}], and [\\ion{C}{2}]\nluminosities for clouds and galaxies formed in hydrodynamic simulations. Built\non the radiative transfer code {\\sc despotic}, {\\sc slick} computes the\nthermal, radiative, and statistical equilibrium in concentric zones of model\nclouds, based on their physical properties and individual environments. We\nvalidate our results applying {\\sc slick} to the high-resolution run of the\n{\\sc Simba} simulations, testing the derived luminosities against empirical and\ntheoretical/analytic relations. To simulate the line emission from a universe\nof emitting clouds, we have incorporated random forest machine learning (ML)\nmethods into our approach, allowing us to predict cosmologically evolving\nproperties of CO, [\\ion{C}{1}] and [\\ion{C}{2}] emission from galaxies such as\nluminosity functions. We tested this model in 100,000 gas particles, and 2,500\ngalaxies, reaching an average accuracy of $\\sim$99.8\\% for all lines. Finally,\nwe present the first model light cones created with realistic and ML-predicted\nCO, [\\ion{C}{1}], and [\\ion{C}{2}] luminosities in cosmological hydrodynamical\nsimulations, from $z=0$ to $z=10$.",
            "author": [
                "Karolina Garcia",
                "Desika Narayanan",
                "Gerg\u00f6 Popping",
                "R. Anirudh",
                "Sagan Sutherland",
                "Melanie Kaasinen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01508v1",
                "http://arxiv.org/pdf/2311.01508v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.CO",
                "astro-ph.IM",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01500v1",
            "title": "E(2) Equivariant Neural Networks for Robust Galaxy Morphology\n  Classification",
            "updated": "2023-11-02T18:00:02Z",
            "published": "2023-11-02T18:00:02Z",
            "summary": "We propose the use of group convolutional neural network architectures\n(GCNNs) equivariant to the 2D Euclidean group, $E(2)$, for the task of galaxy\nmorphology classification by utilizing symmetries of the data present in galaxy\nimages as an inductive bias in the architecture. We conduct robustness studies\nby introducing artificial perturbations via Poisson noise insertion and\none-pixel adversarial attacks to simulate the effects of limited observational\ncapabilities. We train, validate, and test GCNNs equivariant to discrete\nsubgroups of $E(2)$ - the cyclic and dihedral groups of order $N$ - on the\nGalaxy10 DECals dataset and find that GCNNs achieve higher classification\naccuracy and are consistently more robust than their non-equivariant\ncounterparts, with an architecture equivariant to the group $D_{16}$ achieving\na $95.52 \\pm 0.18\\%$ test-set accuracy. We also find that the model loses\n$<6\\%$ accuracy on a $50\\%$-noise dataset and all GCNNs are less susceptible to\none-pixel perturbations than an identically constructed CNN. Our code is\npublicly available at https://github.com/snehjp2/GCNNMorphology.",
            "author": [
                "Sneh Pandya",
                "Purvik Patel",
                "Franc O",
                "Jonathan Blazek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01500v1",
                "http://arxiv.org/pdf/2311.01500v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01497v1",
            "title": "Efficient micromirror confinement of sub-TeV cosmic rays in galaxy\n  clusters",
            "updated": "2023-11-02T18:00:01Z",
            "published": "2023-11-02T18:00:01Z",
            "summary": "Recent observations suggest a stronger confinement of cosmic rays (CRs) in\ncertain astrophysical systems than predicted by current CR-transport theories.\nWe posit that the incorporation of microscale physics into CR-transport models\ncan account for this enhanced CR confinement. We develop a theoretical\ndescription of the effect of magnetic microscale fluctuations originating from\nthe mirror instability on macroscopic CR diffusion. We confirm our theory with\nlarge-dynamical-range simulations of CR transport in the intracluster medium\n(ICM) of galaxy clusters and kinetic simulations of CR transport in micromirror\nfields. We conclude that sub-TeV CR confinement in the ICM is far more\neffective than previously anticipated on the basis of Galactic-transport\nextrapolations.",
            "author": [
                "Patrick Reichherzer",
                "Archie F. A. Bott",
                "Robert J. Ewart",
                "Gianluca Gregori",
                "Philipp Kempski",
                "Matthew W. Kunz",
                "Alexander A. Schekochihin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01497v1",
                "http://arxiv.org/pdf/2311.01497v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "physics.plasm-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01462v1",
            "title": "Idempotent Generative Network",
            "updated": "2023-11-02T17:59:55Z",
            "published": "2023-11-02T17:59:55Z",
            "summary": "We propose a new approach for generative modeling based on training a neural\nnetwork to be idempotent. An idempotent operator is one that can be applied\nsequentially without changing the result beyond the initial application, namely\n$f(f(z))=f(z)$. The proposed model $f$ is trained to map a source distribution\n(e.g, Gaussian noise) to a target distribution (e.g. realistic images) using\nthe following objectives: (1) Instances from the target distribution should map\nto themselves, namely $f(x)=x$. We define the target manifold as the set of all\ninstances that $f$ maps to themselves. (2) Instances that form the source\ndistribution should map onto the defined target manifold. This is achieved by\noptimizing the idempotence term, $f(f(z))=f(z)$ which encourages the range of\n$f(z)$ to be on the target manifold. Under ideal assumptions such a process\nprovably converges to the target distribution. This strategy results in a model\ncapable of generating an output in one step, maintaining a consistent latent\nspace, while also allowing sequential applications for refinement.\nAdditionally, we find that by processing inputs from both target and source\ndistributions, the model adeptly projects corrupted or modified data back to\nthe target manifold. This work is a first step towards a ``global projector''\nthat enables projecting any input into a target data distribution.",
            "author": [
                "Assaf Shocher",
                "Amil Dravid",
                "Yossi Gandelsman",
                "Inbar Mosseri",
                "Michael Rubinstein",
                "Alexei A. Efros"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01462v1",
                "http://arxiv.org/pdf/2311.01462v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01460v1",
            "title": "Implicit Chain of Thought Reasoning via Knowledge Distillation",
            "updated": "2023-11-02T17:59:49Z",
            "published": "2023-11-02T17:59:49Z",
            "summary": "To augment language models with the ability to reason, researchers usually\nprompt or finetune them to produce chain of thought reasoning steps before\nproducing the final answer. However, although people use natural language to\nreason effectively, it may be that LMs could reason more effectively with some\nintermediate computation that is not in natural language. In this work, we\nexplore an alternative reasoning approach: instead of explicitly producing the\nchain of thought reasoning steps, we use the language model's internal hidden\nstates to perform implicit reasoning. The implicit reasoning steps are\ndistilled from a teacher model trained on explicit chain-of-thought reasoning,\nand instead of doing reasoning \"horizontally\" by producing intermediate words\none-by-one, we distill it such that the reasoning happens \"vertically\" among\nthe hidden states in different layers. We conduct experiments on a multi-digit\nmultiplication task and a grade school math problem dataset and find that this\napproach enables solving tasks previously not solvable without explicit\nchain-of-thought, at a speed comparable to no chain-of-thought.",
            "author": [
                "Yuntian Deng",
                "Kiran Prasad",
                "Roland Fernandez",
                "Paul Smolensky",
                "Vishrav Chaudhary",
                "Stuart Shieber"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01460v1",
                "http://arxiv.org/pdf/2311.01460v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01459v1",
            "title": "Align Your Prompts: Test-Time Prompting with Distribution Alignment for\n  Zero-Shot Generalization",
            "updated": "2023-11-02T17:59:32Z",
            "published": "2023-11-02T17:59:32Z",
            "summary": "The promising zero-shot generalization of vision-language models such as CLIP\nhas led to their adoption using prompt learning for numerous downstream tasks.\nPrevious works have shown test-time prompt tuning using entropy minimization to\nadapt text prompts for unseen domains. While effective, this overlooks the key\ncause for performance degradation to unseen domains -- distribution shift. In\nthis work, we explicitly handle this problem by aligning the\nout-of-distribution (OOD) test sample statistics to those of the source data\nusing prompt tuning. We use a single test sample to adapt multi-modal prompts\nat test time by minimizing the feature distribution shift to bridge the gap in\nthe test domain. Evaluating against the domain generalization benchmark, our\nmethod improves zero-shot top- 1 accuracy beyond existing prompt-learning\ntechniques, with a 3.08% improvement over the baseline MaPLe. In cross-dataset\ngeneralization with unseen categories across 10 datasets, our method improves\nconsistently across all datasets compared to the existing state-of-the-art. Our\nsource code and models are available at\nhttps://jameelhassan.github.io/promptalign.",
            "author": [
                "Jameel Hassan",
                "Hanan Gani",
                "Noor Hussein",
                "Muhammad Uzair Khattak",
                "Muzammal Naseer",
                "Fahad Shahbaz Khan",
                "Salman Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01459v1",
                "http://arxiv.org/pdf/2311.01459v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01458v1",
            "title": "Detecting Deepfakes Without Seeing Any",
            "updated": "2023-11-02T17:59:31Z",
            "published": "2023-11-02T17:59:31Z",
            "summary": "Deepfake attacks, malicious manipulation of media containing people, are a\nserious concern for society. Conventional deepfake detection methods train\nsupervised classifiers to distinguish real media from previously encountered\ndeepfakes. Such techniques can only detect deepfakes similar to those\npreviously seen, but not zero-day (previously unseen) attack types. As current\ndeepfake generation techniques are changing at a breathtaking pace, new attack\ntypes are proposed frequently, making this a major issue. Our main observations\nare that: i) in many effective deepfake attacks, the fake media must be\naccompanied by false facts i.e. claims about the identity, speech, motion, or\nappearance of the person. For instance, when impersonating Obama, the attacker\nexplicitly or implicitly claims that the fake media show Obama; ii) current\ngenerative techniques cannot perfectly synthesize the false facts claimed by\nthe attacker. We therefore introduce the concept of \"fact checking\", adapted\nfrom fake news detection, for detecting zero-day deepfake attacks. Fact\nchecking verifies that the claimed facts (e.g. identity is Obama), agree with\nthe observed media (e.g. is the face really Obama's?), and thus can\ndifferentiate between real and fake media. Consequently, we introduce FACTOR, a\npractical recipe for deepfake fact checking and demonstrate its power in\ncritical attack settings: face swapping and audio-visual synthesis. Although it\nis training-free, relies exclusively on off-the-shelf features, is very easy to\nimplement, and does not see any deepfakes, it achieves better than\nstate-of-the-art accuracy.",
            "author": [
                "Tal Reiss",
                "Bar Cavia",
                "Yedid Hoshen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01458v1",
                "http://arxiv.org/pdf/2311.01458v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01457v1",
            "title": "Conformal Policy Learning for Sensorimotor Control Under Distribution\n  Shifts",
            "updated": "2023-11-02T17:59:30Z",
            "published": "2023-11-02T17:59:30Z",
            "summary": "This paper focuses on the problem of detecting and reacting to changes in the\ndistribution of a sensorimotor controller's observables. The key idea is the\ndesign of switching policies that can take conformal quantiles as input, which\nwe define as conformal policy learning, that allows robots to detect\ndistribution shifts with formal statistical guarantees. We show how to design\nsuch policies by using conformal quantiles to switch between base policies with\ndifferent characteristics, e.g. safety or speed, or directly augmenting a\npolicy observation with a quantile and training it with reinforcement learning.\nTheoretically, we show that such policies achieve the formal convergence\nguarantees in finite time. In addition, we thoroughly evaluate their advantages\nand limitations on two compelling use cases: simulated autonomous driving and\nactive perception with a physical quadruped. Empirical results demonstrate that\nour approach outperforms five baselines. It is also the simplest of the\nbaseline strategies besides one ablation. Being easy to use, flexible, and with\nformal guarantees, our work demonstrates how conformal prediction can be an\neffective tool for sensorimotor learning under uncertainty.",
            "author": [
                "Huang Huang",
                "Satvik Sharma",
                "Antonio Loquercio",
                "Anastasios Angelopoulos",
                "Ken Goldberg",
                "Jitendra Malik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01457v1",
                "http://arxiv.org/pdf/2311.01457v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01455v2",
            "title": "RoboGen: Towards Unleashing Infinite Data for Automated Robot Learning\n  via Generative Simulation",
            "updated": "2023-11-13T18:40:10Z",
            "published": "2023-11-02T17:59:21Z",
            "summary": "We present RoboGen, a generative robotic agent that automatically learns\ndiverse robotic skills at scale via generative simulation. RoboGen leverages\nthe latest advancements in foundation and generative models. Instead of\ndirectly using or adapting these models to produce policies or low-level\nactions, we advocate for a generative scheme, which uses these models to\nautomatically generate diversified tasks, scenes, and training supervisions,\nthereby scaling up robotic skill learning with minimal human supervision. Our\napproach equips a robotic agent with a self-guided propose-generate-learn\ncycle: the agent first proposes interesting tasks and skills to develop, and\nthen generates corresponding simulation environments by populating pertinent\nobjects and assets with proper spatial configurations. Afterwards, the agent\ndecomposes the proposed high-level task into sub-tasks, selects the optimal\nlearning approach (reinforcement learning, motion planning, or trajectory\noptimization), generates required training supervision, and then learns\npolicies to acquire the proposed skill. Our work attempts to extract the\nextensive and versatile knowledge embedded in large-scale models and transfer\nthem to the field of robotics. Our fully generative pipeline can be queried\nrepeatedly, producing an endless stream of skill demonstrations associated with\ndiverse tasks and environments.",
            "author": [
                "Yufei Wang",
                "Zhou Xian",
                "Feng Chen",
                "Tsun-Hsuan Wang",
                "Yian Wang",
                "Zackory Erickson",
                "David Held",
                "Chuang Gan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01455v2",
                "http://arxiv.org/pdf/2311.01455v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01454v1",
            "title": "NOIR: Neural Signal Operated Intelligent Robots for Everyday Activities",
            "updated": "2023-11-02T17:59:06Z",
            "published": "2023-11-02T17:59:06Z",
            "summary": "We present Neural Signal Operated Intelligent Robots (NOIR), a\ngeneral-purpose, intelligent brain-robot interface system that enables humans\nto command robots to perform everyday activities through brain signals. Through\nthis interface, humans communicate their intended objects of interest and\nactions to the robots using electroencephalography (EEG). Our novel system\ndemonstrates success in an expansive array of 20 challenging, everyday\nhousehold activities, including cooking, cleaning, personal care, and\nentertainment. The effectiveness of the system is improved by its synergistic\nintegration of robot learning algorithms, allowing for NOIR to adapt to\nindividual users and predict their intentions. Our work enhances the way humans\ninteract with robots, replacing traditional channels of interaction with\ndirect, neural communication. Project website: https://noir-corl.github.io/.",
            "author": [
                "Ruohan Zhang",
                "Sharon Lee",
                "Minjune Hwang",
                "Ayano Hiranaka",
                "Chen Wang",
                "Wensi Ai",
                "Jin Jie Ryan Tan",
                "Shreya Gupta",
                "Yilun Hao",
                "Gabrael Levine",
                "Ruohan Gao",
                "Anthony Norcia",
                "Li Fei-Fei",
                "Jiajun Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01454v1",
                "http://arxiv.org/pdf/2311.01454v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01453v1",
            "title": "PPI++: Efficient Prediction-Powered Inference",
            "updated": "2023-11-02T17:59:04Z",
            "published": "2023-11-02T17:59:04Z",
            "summary": "We present PPI++: a computationally lightweight methodology for estimation\nand inference based on a small labeled dataset and a typically much larger\ndataset of machine-learning predictions. The methods automatically adapt to the\nquality of available predictions, yielding easy-to-compute confidence sets --\nfor parameters of any dimensionality -- that always improve on classical\nintervals using only the labeled data. PPI++ builds on prediction-powered\ninference (PPI), which targets the same problem setting, improving its\ncomputational and statistical efficiency. Real and synthetic experiments\ndemonstrate the benefits of the proposed adaptations.",
            "author": [
                "Anastasios N. Angelopoulos",
                "John C. Duchi",
                "Tijana Zrnic"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01453v1",
                "http://arxiv.org/pdf/2311.01453v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01491v1",
            "title": "Investigating the Behavior of Diffusion Models for Accelerating\n  Electronic Structure Calculations",
            "updated": "2023-11-02T17:58:37Z",
            "published": "2023-11-02T17:58:37Z",
            "summary": "We present an investigation into diffusion models for molecular generation,\nwith the aim of better understanding how their predictions compare to the\nresults of physics-based calculations. The investigation into these models is\ndriven by their potential to significantly accelerate electronic structure\ncalculations using machine learning, without requiring expensive\nfirst-principles datasets for training interatomic potentials. We find that the\ninference process of a popular diffusion model for de novo molecular generation\nis divided into an exploration phase, where the model chooses the atomic\nspecies, and a relaxation phase, where it adjusts the atomic coordinates to\nfind a low-energy geometry. As training proceeds, we show that the model\ninitially learns about the first-order structure of the potential energy\nsurface, and then later learns about higher-order structure. We also find that\nthe relaxation phase of the diffusion model can be re-purposed to sample the\nBoltzmann distribution over conformations and to carry out structure\nrelaxations. For structure relaxations, the model finds geometries with ~10x\nlower energy than those produced by a classical force field for small organic\nmolecules. Initializing a density functional theory (DFT) relaxation at the\ndiffusion-produced structures yields a >2x speedup to the DFT relaxation when\ncompared to initializing at structures relaxed with a classical force field.",
            "author": [
                "Daniel Rothchild",
                "Andrew S. Rosen",
                "Eric Taw",
                "Connie Robinson",
                "Joseph E. Gonzalez",
                "Aditi S. Krishnapriyan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01491v1",
                "http://arxiv.org/pdf/2311.01491v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cond-mat.mtrl-sci",
                "cs.LG",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01452v1",
            "title": "Time Series Anomaly Detection using Diffusion-based Models",
            "updated": "2023-11-02T17:58:09Z",
            "published": "2023-11-02T17:58:09Z",
            "summary": "Diffusion models have been recently used for anomaly detection (AD) in\nimages. In this paper we investigate whether they can also be leveraged for AD\non multivariate time series (MTS). We test two diffusion-based models and\ncompare them to several strong neural baselines. We also extend the PA%K\nprotocol, by computing a ROCK-AUC metric, which is agnostic to both the\ndetection threshold and the ratio K of correctly detected points. Our models\noutperform the baselines on synthetic datasets and are competitive on\nreal-world datasets, illustrating the potential of diffusion-based methods for\nAD in multivariate time series.",
            "author": [
                "Ioana Pintilie",
                "Andrei Manolache",
                "Florin Brad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01452v1",
                "http://arxiv.org/pdf/2311.01452v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01450v1",
            "title": "DreamSmooth: Improving Model-based Reinforcement Learning via Reward\n  Smoothing",
            "updated": "2023-11-02T17:57:38Z",
            "published": "2023-11-02T17:57:38Z",
            "summary": "Model-based reinforcement learning (MBRL) has gained much attention for its\nability to learn complex behaviors in a sample-efficient way: planning actions\nby generating imaginary trajectories with predicted rewards. Despite its\nsuccess, we found that surprisingly, reward prediction is often a bottleneck of\nMBRL, especially for sparse rewards that are challenging (or even ambiguous) to\npredict. Motivated by the intuition that humans can learn from rough reward\nestimates, we propose a simple yet effective reward smoothing approach,\nDreamSmooth, which learns to predict a temporally-smoothed reward, instead of\nthe exact reward at the given timestep. We empirically show that DreamSmooth\nachieves state-of-the-art performance on long-horizon sparse-reward tasks both\nin sample efficiency and final performance without losing performance on common\nbenchmarks, such as Deepmind Control Suite and Atari benchmarks.",
            "author": [
                "Vint Lee",
                "Pieter Abbeel",
                "Youngwoon Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01450v1",
                "http://arxiv.org/pdf/2311.01450v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01448v1",
            "title": "UltraLiDAR: Learning Compact Representations for LiDAR Completion and\n  Generation",
            "updated": "2023-11-02T17:57:03Z",
            "published": "2023-11-02T17:57:03Z",
            "summary": "LiDAR provides accurate geometric measurements of the 3D world.\nUnfortunately, dense LiDARs are very expensive and the point clouds captured by\nlow-beam LiDAR are often sparse. To address these issues, we present\nUltraLiDAR, a data-driven framework for scene-level LiDAR completion, LiDAR\ngeneration, and LiDAR manipulation. The crux of UltraLiDAR is a compact,\ndiscrete representation that encodes the point cloud's geometric structure, is\nrobust to noise, and is easy to manipulate. We show that by aligning the\nrepresentation of a sparse point cloud to that of a dense point cloud, we can\ndensify the sparse point clouds as if they were captured by a real high-density\nLiDAR, drastically reducing the cost. Furthermore, by learning a prior over the\ndiscrete codebook, we can generate diverse, realistic LiDAR point clouds for\nself-driving. We evaluate the effectiveness of UltraLiDAR on sparse-to-dense\nLiDAR completion and LiDAR generation. Experiments show that densifying\nreal-world point clouds with our approach can significantly improve the\nperformance of downstream perception systems. Compared to prior art on LiDAR\ngeneration, our approach generates much more realistic point clouds. According\nto A/B test, over 98.5\\% of the time human participants prefer our results over\nthose of previous methods.",
            "author": [
                "Yuwen Xiong",
                "Wei-Chiu Ma",
                "Jingkang Wang",
                "Raquel Urtasun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01448v1",
                "http://arxiv.org/pdf/2311.01448v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01447v1",
            "title": "CADSim: Robust and Scalable in-the-wild 3D Reconstruction for\n  Controllable Sensor Simulation",
            "updated": "2023-11-02T17:56:59Z",
            "published": "2023-11-02T17:56:59Z",
            "summary": "Realistic simulation is key to enabling safe and scalable development of %\nself-driving vehicles. A core component is simulating the sensors so that the\nentire autonomy system can be tested in simulation. Sensor simulation involves\nmodeling traffic participants, such as vehicles, with high quality appearance\nand articulated geometry, and rendering them in real time. The self-driving\nindustry has typically employed artists to build these assets. However, this is\nexpensive, slow, and may not reflect reality. Instead, reconstructing assets\nautomatically from sensor data collected in the wild would provide a better\npath to generating a diverse and large set with good real-world coverage.\nNevertheless, current reconstruction approaches struggle on in-the-wild sensor\ndata, due to its sparsity and noise. To tackle these issues, we present CADSim,\nwhich combines part-aware object-class priors via a small set of CAD models\nwith differentiable rendering to automatically reconstruct vehicle geometry,\nincluding articulated wheels, with high-quality appearance. Our experiments\nshow our method recovers more accurate shapes from sparse data compared to\nexisting approaches. Importantly, it also trains and renders efficiently. We\ndemonstrate our reconstructed vehicles in several applications, including\naccurate testing of autonomy perception systems.",
            "author": [
                "Jingkang Wang",
                "Sivabalan Manivasagam",
                "Yun Chen",
                "Ze Yang",
                "Ioan Andrei B\u00e2rsan",
                "Anqi Joyce Yang",
                "Wei-Chiu Ma",
                "Raquel Urtasun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01447v1",
                "http://arxiv.org/pdf/2311.01447v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01446v1",
            "title": "Adv3D: Generating Safety-Critical 3D Objects through Closed-Loop\n  Simulation",
            "updated": "2023-11-02T17:56:44Z",
            "published": "2023-11-02T17:56:44Z",
            "summary": "Self-driving vehicles (SDVs) must be rigorously tested on a wide range of\nscenarios to ensure safe deployment. The industry typically relies on\nclosed-loop simulation to evaluate how the SDV interacts on a corpus of\nsynthetic and real scenarios and verify it performs properly. However, they\nprimarily only test the system's motion planning module, and only consider\nbehavior variations. It is key to evaluate the full autonomy system in\nclosed-loop, and to understand how variations in sensor data based on scene\nappearance, such as the shape of actors, affect system performance. In this\npaper, we propose a framework, Adv3D, that takes real world scenarios and\nperforms closed-loop sensor simulation to evaluate autonomy performance, and\nfinds vehicle shapes that make the scenario more challenging, resulting in\nautonomy failures and uncomfortable SDV maneuvers. Unlike prior works that add\ncontrived adversarial shapes to vehicle roof-tops or roadside to harm\nperception only, we optimize a low-dimensional shape representation to modify\nthe vehicle shape itself in a realistic manner to degrade autonomy performance\n(e.g., perception, prediction, and motion planning). Moreover, we find that the\nshape variations found with Adv3D optimized in closed-loop are much more\neffective than those in open-loop, demonstrating the importance of finding\nscene appearance variations that affect autonomy in the interactive setting.",
            "author": [
                "Jay Sarva",
                "Jingkang Wang",
                "James Tu",
                "Yuwen Xiong",
                "Sivabalan Manivasagam",
                "Raquel Urtasun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01446v1",
                "http://arxiv.org/pdf/2311.01446v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01444v1",
            "title": "LabelFormer: Object Trajectory Refinement for Offboard Perception from\n  LiDAR Point Clouds",
            "updated": "2023-11-02T17:56:06Z",
            "published": "2023-11-02T17:56:06Z",
            "summary": "A major bottleneck to scaling-up training of self-driving perception systems\nare the human annotations required for supervision. A promising alternative is\nto leverage \"auto-labelling\" offboard perception models that are trained to\nautomatically generate annotations from raw LiDAR point clouds at a fraction of\nthe cost. Auto-labels are most commonly generated via a two-stage approach --\nfirst objects are detected and tracked over time, and then each object\ntrajectory is passed to a learned refinement model to improve accuracy. Since\nexisting refinement models are overly complex and lack advanced temporal\nreasoning capabilities, in this work we propose LabelFormer, a simple,\nefficient, and effective trajectory-level refinement approach. Our approach\nfirst encodes each frame's observations separately, then exploits\nself-attention to reason about the trajectory with full temporal context, and\nfinally decodes the refined object size and per-frame poses. Evaluation on both\nurban and highway datasets demonstrates that LabelFormer outperforms existing\nworks by a large margin. Finally, we show that training on a dataset augmented\nwith auto-labels generated by our method leads to improved downstream detection\nperformance compared to existing methods. Please visit the project website for\ndetails https://waabi.ai/labelformer",
            "author": [
                "Anqi Joyce Yang",
                "Sergio Casas",
                "Nikita Dvornik",
                "Sean Segal",
                "Yuwen Xiong",
                "Jordan Sir Kwang Hu",
                "Carter Fang",
                "Raquel Urtasun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01444v1",
                "http://arxiv.org/pdf/2311.01444v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01442v3",
            "title": "Deep Double Descent for Time Series Forecasting: Avoiding Undertrained\n  Models",
            "updated": "2023-11-30T06:51:26Z",
            "published": "2023-11-02T17:55:41Z",
            "summary": "Deep learning models, particularly Transformers, have achieved impressive\nresults in various domains, including time series forecasting. While existing\ntime series literature primarily focuses on model architecture modifications\nand data augmentation techniques, this paper explores the training schema of\ndeep learning models for time series; how models are trained regardless of\ntheir architecture. We perform extensive experiments to investigate the\noccurrence of deep double descent in several Transformer models trained on\npublic time series data sets. We demonstrate epoch-wise deep double descent and\nthat overfitting can be reverted using more epochs. Leveraging these findings,\nwe achieve state-of-the-art results for long sequence time series forecasting\nin nearly 70% of the 72 benchmarks tested. This suggests that many models in\nthe literature may possess untapped potential. Additionally, we introduce a\ntaxonomy for classifying training schema modifications, covering data\naugmentation, model inputs, model targets, time series per model, and\ncomputational budget.",
            "author": [
                "Valentino Assandri",
                "Sam Heshmati",
                "Burhaneddin Yaman",
                "Anton Iakovlev",
                "Ariel Emiliano Repetur"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01442v3",
                "http://arxiv.org/pdf/2311.01442v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01441v1",
            "title": "Distilling Out-of-Distribution Robustness from Vision-Language\n  Foundation Models",
            "updated": "2023-11-02T17:55:13Z",
            "published": "2023-11-02T17:55:13Z",
            "summary": "We propose a conceptually simple and lightweight framework for improving the\nrobustness of vision models through the combination of knowledge distillation\nand data augmentation. We address the conjecture that larger models do not make\nfor better teachers by showing strong gains in out-of-distribution robustness\nwhen distilling from pretrained foundation models. Following this finding, we\npropose Discrete Adversarial Distillation (DAD), which leverages a robust\nteacher to generate adversarial examples and a VQGAN to discretize them,\ncreating more informative samples than standard data augmentation techniques.\nWe provide a theoretical framework for the use of a robust teacher in the\nknowledge distillation with data augmentation setting and demonstrate strong\ngains in out-of-distribution robustness and clean accuracy across different\nstudent architectures. Notably, our method adds minor computational overhead\ncompared to similar techniques and can be easily combined with other data\naugmentations for further improvements.",
            "author": [
                "Andy Zhou",
                "Jindong Wang",
                "Yu-Xiong Wang",
                "Haohan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01441v1",
                "http://arxiv.org/pdf/2311.01441v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01435v1",
            "title": "Contrastive Moments: Unsupervised Halfspace Learning in Polynomial Time",
            "updated": "2023-11-02T17:51:10Z",
            "published": "2023-11-02T17:51:10Z",
            "summary": "We give a polynomial-time algorithm for learning high-dimensional halfspaces\nwith margins in $d$-dimensional space to within desired TV distance when the\nambient distribution is an unknown affine transformation of the $d$-fold\nproduct of an (unknown) symmetric one-dimensional logconcave distribution, and\nthe halfspace is introduced by deleting at least an $\\epsilon$ fraction of the\ndata in one of the component distributions. Notably, our algorithm does not\nneed labels and establishes the unique (and efficient) identifiability of the\nhidden halfspace under this distributional assumption. The sample and time\ncomplexity of the algorithm are polynomial in the dimension and $1/\\epsilon$.\nThe algorithm uses only the first two moments of suitable re-weightings of the\nempirical distribution, which we call contrastive moments; its analysis uses\nclassical facts about generalized Dirichlet polynomials and relies crucially on\na new monotonicity property of the moment ratio of truncations of logconcave\ndistributions. Such algorithms, based only on first and second moments were\nsuggested in earlier work, but hitherto eluded rigorous guarantees.\n  Prior work addressed the special case when the underlying distribution is\nGaussian via Non-Gaussian Component Analysis. We improve on this by providing\npolytime guarantees based on Total Variation (TV) distance, in place of\nexisting moment-bound guarantees that can be super-polynomial. Our work is also\nthe first to go beyond Gaussians in this setting.",
            "author": [
                "Xinyuan Cao",
                "Santosh S. Vempala"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01435v1",
                "http://arxiv.org/pdf/2311.01435v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.PR",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01434v1",
            "title": "Tailoring Mixup to Data using Kernel Warping functions",
            "updated": "2023-11-02T17:48:28Z",
            "published": "2023-11-02T17:48:28Z",
            "summary": "Data augmentation is an essential building block for learning efficient deep\nlearning models. Among all augmentation techniques proposed so far, linear\ninterpolation of training data points, also called mixup, has found to be\neffective for a large panel of applications. While the majority of works have\nfocused on selecting the right points to mix, or applying complex non-linear\ninterpolation, we are interested in mixing similar points more frequently and\nstrongly than less similar ones. To this end, we propose to dynamically change\nthe underlying distribution of interpolation coefficients through warping\nfunctions, depending on the similarity between data points to combine. We\ndefine an efficient and flexible framework to do so without losing in\ndiversity. We provide extensive experiments for classification and regression\ntasks, showing that our proposed method improves both performance and\ncalibration of models. Code available in\nhttps://github.com/ENSTA-U2IS/torch-uncertainty",
            "author": [
                "Quentin Bouniot",
                "Pavlo Mozharovskyi",
                "Florence d'Alch\u00e9-Buc"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01434v1",
                "http://arxiv.org/pdf/2311.01434v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01428v1",
            "title": "Identifying Alzheimer Disease Dementia Levels Using Machine Learning\n  Methods",
            "updated": "2023-11-02T17:44:28Z",
            "published": "2023-11-02T17:44:28Z",
            "summary": "Dementia, a prevalent neurodegenerative condition, is a major manifestation\nof Alzheimer's disease (AD). As the condition progresses from mild to severe,\nit significantly impairs the individual's ability to perform daily tasks\nindependently, necessitating the need for timely and accurate AD\nclassification. Machine learning or deep learning models have emerged as\neffective tools for this purpose. In this study, we suggested an approach for\nclassifying the four stages of dementia using RF, SVM, and CNN algorithms,\naugmented with watershed segmentation for feature extraction from MRI images.\nOur results reveal that SVM with watershed features achieves an impressive\naccuracy of 96.25%, surpassing other classification methods. The ADNI dataset\nis utilized to evaluate the effectiveness of our method, and we observed that\nthe inclusion of watershed segmentation contributes to the enhanced performance\nof the models.",
            "author": [
                "Md Gulzar Hussain",
                "Ye Shiren"
            ],
            "link": [
                "http://dx.doi.org/10.18103/mra.v11i7.1.4039",
                "http://arxiv.org/abs/2311.01428v1",
                "http://arxiv.org/pdf/2311.01428v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01425v1",
            "title": "Exploring Deep Learning Techniques for Glaucoma Detection: A\n  Comprehensive Review",
            "updated": "2023-11-02T17:39:40Z",
            "published": "2023-11-02T17:39:40Z",
            "summary": "Glaucoma is one of the primary causes of vision loss around the world,\nnecessitating accurate and efficient detection methods. Traditional manual\ndetection approaches have limitations in terms of cost, time, and subjectivity.\nRecent developments in deep learning approaches demonstrate potential in\nautomating glaucoma detection by detecting relevant features from retinal\nfundus images. This article provides a comprehensive overview of cutting-edge\ndeep learning methods used for the segmentation, classification, and detection\nof glaucoma. By analyzing recent studies, the effectiveness and limitations of\nthese techniques are evaluated, key findings are highlighted, and potential\nareas for further research are identified. The use of deep learning algorithms\nmay significantly improve the efficacy, usefulness, and accuracy of glaucoma\ndetection. The findings from this research contribute to the ongoing\nadvancements in automated glaucoma detection and have implications for\nimproving patient outcomes and reducing the global burden of glaucoma.",
            "author": [
                "Aized Amin Soofi",
                "Fazal-e-Amin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01425v1",
                "http://arxiv.org/pdf/2311.01425v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01423v2",
            "title": "CenterRadarNet: Joint 3D Object Detection and Tracking Framework using\n  4D FMCW Radar",
            "updated": "2023-11-04T21:30:42Z",
            "published": "2023-11-02T17:36:40Z",
            "summary": "Robust perception is a vital component for ensuring safe autonomous and\nassisted driving. Automotive radar (77 to 81 GHz), which offers\nweather-resilient sensing, provides a complementary capability to the vision-\nor LiDAR-based autonomous driving systems. Raw radio-frequency (RF) radar\ntensors contain rich spatiotemporal semantics besides 3D location information.\nThe majority of previous methods take in 3D (Doppler-range-azimuth) RF radar\ntensors, allowing prediction of an object's location, heading angle, and size\nin bird's-eye-view (BEV). However, they lack the ability to at the same time\ninfer objects' size, orientation, and identity in the 3D space. To overcome\nthis limitation, we propose an efficient joint architecture called\nCenterRadarNet, designed to facilitate high-resolution representation learning\nfrom 4D (Doppler-range-azimuth-elevation) radar data for 3D object detection\nand re-identification (re-ID) tasks. As a single-stage 3D object detector,\nCenterRadarNet directly infers the BEV object distribution confidence maps,\ncorresponding 3D bounding box attributes, and appearance embedding for each\npixel. Moreover, we build an online tracker utilizing the learned appearance\nembedding for re-ID. CenterRadarNet achieves the state-of-the-art result on the\nK-Radar 3D object detection benchmark. In addition, we present the first 3D\nobject-tracking result using radar on the K-Radar dataset V2. In diverse\ndriving scenarios, CenterRadarNet shows consistent, robust performance,\nemphasizing its wide applicability.",
            "author": [
                "Jen-Hao Cheng",
                "Sheng-Yao Kuan",
                "Hugo Latapie",
                "Gaowen Liu",
                "Jenq-Neng Hwang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01423v2",
                "http://arxiv.org/pdf/2311.01423v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01420v1",
            "title": "Holistic Transfer: Towards Non-Disruptive Fine-Tuning with Partial\n  Target Data",
            "updated": "2023-11-02T17:35:16Z",
            "published": "2023-11-02T17:35:16Z",
            "summary": "We propose a learning problem involving adapting a pre-trained source model\nto the target domain for classifying all classes that appeared in the source\ndata, using target data that covers only a partial label space. This problem is\npractical, as it is unrealistic for the target end-users to collect data for\nall classes prior to adaptation. However, it has received limited attention in\nthe literature. To shed light on this issue, we construct benchmark datasets\nand conduct extensive experiments to uncover the inherent challenges. We found\na dilemma -- on the one hand, adapting to the new target domain is important to\nclaim better performance; on the other hand, we observe that preserving the\nclassification accuracy of classes missing in the target adaptation data is\nhighly challenging, let alone improving them. To tackle this, we identify two\nkey directions: 1) disentangling domain gradients from classification\ngradients, and 2) preserving class relationships. We present several effective\nsolutions that maintain the accuracy of the missing classes and enhance the\noverall performance, establishing solid baselines for holistic transfer of\npre-trained models with partial target data.",
            "author": [
                "Cheng-Hao Tu",
                "Hong-You Chen",
                "Zheda Mai",
                "Jike Zhong",
                "Vardaan Pahuja",
                "Tanya Berger-Wolf",
                "Song Gao",
                "Charles Stewart",
                "Yu Su",
                "Wei-Lun Chao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01420v1",
                "http://arxiv.org/pdf/2311.01420v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01419v1",
            "title": "Constrained-Context Conditional Diffusion Models for Imitation Learning",
            "updated": "2023-11-02T17:33:47Z",
            "published": "2023-11-02T17:33:47Z",
            "summary": "Offline Imitation Learning (IL) is a powerful paradigm to learn visuomotor\nskills, especially for high-precision manipulation tasks. However, IL methods\nare prone to spurious correlation - expressive models may focus on distractors\nthat are irrelevant to action prediction - and are thus fragile in real-world\ndeployment. Prior methods have addressed this challenge by exploring different\nmodel architectures and action representations. However, none were able to\nbalance between sample efficiency, robustness against distractors, and solving\nhigh-precision manipulation tasks with complex action space. To this end, we\npresent $\\textbf{C}$onstrained-$\\textbf{C}$ontext $\\textbf{C}$onditional\n$\\textbf{D}$iffusion $\\textbf{M}$odel (C3DM), a diffusion model policy for\nsolving 6-DoF robotic manipulation tasks with high precision and ability to\nignore distractions. A key component of C3DM is a fixation step that helps the\naction denoiser to focus on task-relevant regions around the predicted action\nwhile ignoring distractors in the context. We empirically show that C3DM is\nable to consistently achieve high success rate on a wide array of tasks,\nranging from table top manipulation to industrial kitting, that require varying\nlevels of precision and robustness to distractors. For details, please visit\nthis https://sites.google.com/view/c3dm-imitation-learning",
            "author": [
                "Vaibhav Saxena",
                "Yotto Koga",
                "Danfei Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01419v1",
                "http://arxiv.org/pdf/2311.01419v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01412v1",
            "title": "Castor: Causal Temporal Regime Structure Learning",
            "updated": "2023-11-02T17:26:49Z",
            "published": "2023-11-02T17:26:49Z",
            "summary": "The task of uncovering causal relationships among multivariate time series\ndata stands as an essential and challenging objective that cuts across a broad\narray of disciplines ranging from climate science to healthcare. Such data\nentails linear or non-linear relationships, and usually follow multiple a\npriori unknown regimes. Existing causal discovery methods can infer summary\ncausal graphs from heterogeneous data with known regimes, but they fall short\nin comprehensively learning both regimes and the corresponding causal graph. In\nthis paper, we introduce CASTOR, a novel framework designed to learn causal\nrelationships in heterogeneous time series data composed of various regimes,\neach governed by a distinct causal graph. Through the maximization of a score\nfunction via the EM algorithm, CASTOR infers the number of regimes and learns\nlinear or non-linear causal relationships in each regime. We demonstrate the\nrobust convergence properties of CASTOR, specifically highlighting its\nproficiency in accurately identifying unique regimes. Empirical evidence,\ngarnered from exhaustive synthetic experiments and two real-world benchmarks,\nconfirm CASTOR's superior performance in causal discovery compared to baseline\nmethods. By learning a full temporal causal graph for each regime, CASTOR\nestablishes itself as a distinctly interpretable method for causal discovery in\nheterogeneous time series.",
            "author": [
                "Abdellah Rahmani",
                "Pascal Frossard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01412v1",
                "http://arxiv.org/pdf/2311.01412v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01410v1",
            "title": "The Blessing of Randomness: SDE Beats ODE in General Diffusion-based\n  Image Editing",
            "updated": "2023-11-02T17:23:14Z",
            "published": "2023-11-02T17:23:14Z",
            "summary": "We present a unified probabilistic formulation for diffusion-based image\nediting, where a latent variable is edited in a task-specific manner and\ngenerally deviates from the corresponding marginal distribution induced by the\noriginal stochastic or ordinary differential equation (SDE or ODE). Instead, it\ndefines a corresponding SDE or ODE for editing. In the formulation, we prove\nthat the Kullback-Leibler divergence between the marginal distributions of the\ntwo SDEs gradually decreases while that for the ODEs remains as the time\napproaches zero, which shows the promise of SDE in image editing. Inspired by\nit, we provide the SDE counterparts for widely used ODE baselines in various\ntasks including inpainting and image-to-image translation, where SDE shows a\nconsistent and substantial improvement. Moreover, we propose SDE-Drag -- a\nsimple yet effective method built upon the SDE formulation for point-based\ncontent dragging. We build a challenging benchmark (termed DragBench) with\nopen-set natural, art, and AI-generated images for evaluation. A user study on\nDragBench indicates that SDE-Drag significantly outperforms our ODE baseline,\nexisting diffusion-based methods, and the renowned DragGAN. Our results\ndemonstrate the superiority and versatility of SDE in image editing and push\nthe boundary of diffusion-based editing methods.",
            "author": [
                "Shen Nie",
                "Hanzhong Allan Guo",
                "Cheng Lu",
                "Yuhao Zhou",
                "Chenyu Zheng",
                "Chongxuan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01410v1",
                "http://arxiv.org/pdf/2311.01410v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01409v1",
            "title": "A Coreset-based, Tempered Variational Posterior for Accurate and\n  Scalable Stochastic Gaussian Process Inference",
            "updated": "2023-11-02T17:22:22Z",
            "published": "2023-11-02T17:22:22Z",
            "summary": "We present a novel stochastic variational Gaussian process ($\\mathcal{GP}$)\ninference method, based on a posterior over a learnable set of weighted pseudo\ninput-output points (coresets). Instead of a free-form variational family, the\nproposed coreset-based, variational tempered family for $\\mathcal{GP}$s (CVTGP)\nis defined in terms of the $\\mathcal{GP}$ prior and the data-likelihood; hence,\naccommodating the modeling inductive biases. We derive CVTGP's lower bound for\nthe log-marginal likelihood via marginalization of the proposed posterior over\nlatent $\\mathcal{GP}$ coreset variables, and show it is amenable to stochastic\noptimization. CVTGP reduces the learnable parameter size to $\\mathcal{O}(M)$,\nenjoys numerical stability, and maintains $\\mathcal{O}(M^3)$ time- and\n$\\mathcal{O}(M^2)$ space-complexity, by leveraging a coreset-based tempered\nposterior that, in turn, provides sparse and explainable representations of the\ndata. Results on simulated and real-world regression problems with Gaussian\nobservation noise validate that CVTGP provides better evidence lower-bound\nestimates and predictive root mean squared error than alternative stochastic\n$\\mathcal{GP}$ inference methods.",
            "author": [
                "Mert Ketenci",
                "Adler Perotte",
                "No\u00e9mie Elhadad",
                "I\u00f1igo Urteaga"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01409v1",
                "http://arxiv.org/pdf/2311.01409v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01406v1",
            "title": "Analysis of Information Propagation in Ethereum Network Using Combined\n  Graph Attention Network and Reinforcement Learning to Optimize Network\n  Efficiency and Scalability",
            "updated": "2023-11-02T17:19:45Z",
            "published": "2023-11-02T17:19:45Z",
            "summary": "Blockchain technology has revolutionized the way information is propagated in\ndecentralized networks. Ethereum plays a pivotal role in facilitating smart\ncontracts and decentralized applications. Understanding information propagation\ndynamics in Ethereum is crucial for ensuring network efficiency, security, and\nscalability. In this study, we propose an innovative approach that utilizes\nGraph Convolutional Networks (GCNs) to analyze the information propagation\npatterns in the Ethereum network. The first phase of our research involves data\ncollection from the Ethereum blockchain, consisting of blocks, transactions,\nand node degrees. We construct a transaction graph representation using\nadjacency matrices to capture the node embeddings; while our major contribution\nis to develop a combined Graph Attention Network (GAT) and Reinforcement\nLearning (RL) model to optimize the network efficiency and scalability. It\nlearns the best actions to take in various network states, ultimately leading\nto improved network efficiency, throughput, and optimize gas limits for block\nprocessing. In the experimental evaluation, we analyze the performance of our\nmodel on a large-scale Ethereum dataset. We investigate effectively aggregating\ninformation from neighboring nodes capturing graph structure and updating node\nembeddings using GCN with the objective of transaction pattern prediction,\naccounting for varying network loads and number of blocks. Not only we design a\ngas limit optimization model and provide the algorithm, but also to address\nscalability, we demonstrate the use and implementation of sparse matrices in\nGraphConv, GraphSAGE, and GAT. The results indicate that our designed GAT-RL\nmodel achieves superior results compared to other GCN models in terms of\nperformance. It effectively propagates information across the network,\noptimizing gas limits for block processing and improving network efficiency.",
            "author": [
                "Stefan Kambiz Behfar",
                "Jon Crowcroft"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01406v1",
                "http://arxiv.org/pdf/2311.01406v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01405v1",
            "title": "Learning to See Physical Properties with Active Sensing Motor Policies",
            "updated": "2023-11-02T17:19:18Z",
            "published": "2023-11-02T17:19:18Z",
            "summary": "Knowledge of terrain's physical properties inferred from color images can aid\nin making efficient robotic locomotion plans. However, unlike image\nclassification, it is unintuitive for humans to label image patches with\nphysical properties. Without labeled data, building a vision system that takes\nas input the observed terrain and predicts physical properties remains\nchallenging. We present a method that overcomes this challenge by\nself-supervised labeling of images captured by robots during real-world\ntraversal with physical property estimators trained in simulation. To ensure\naccurate labeling, we introduce Active Sensing Motor Policies (ASMP), which are\ntrained to explore locomotion behaviors that increase the accuracy of\nestimating physical parameters. For instance, the quadruped robot learns to\nswipe its foot against the ground to estimate the friction coefficient\naccurately. We show that the visual system trained with a small amount of\nreal-world traversal data accurately predicts physical parameters. The trained\nsystem is robust and works even with overhead images captured by a drone\ndespite being trained on data collected by cameras attached to a quadruped\nrobot walking on the ground.",
            "author": [
                "Gabriel B. Margolis",
                "Xiang Fu",
                "Yandong Ji",
                "Pulkit Agrawal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01405v1",
                "http://arxiv.org/pdf/2311.01405v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01404v2",
            "title": "Normalizing flows as approximations of optimal transport maps via\n  linear-control neural ODEs",
            "updated": "2023-11-17T11:06:52Z",
            "published": "2023-11-02T17:17:03Z",
            "summary": "The term \"Normalizing Flows\" is related to the task of constructing\ninvertible transport maps between probability measures by means of deep neural\nnetworks. In this paper, we consider the problem of recovering the\n$W_2$-optimal transport map $T$ between absolutely continuous measures\n$\\mu,\\nu\\in\\mathcal{P}(\\mathbb{R}^n)$ as the flow of a linear-control neural\nODE. We first show that, under suitable assumptions on $\\mu,\\nu$ and on the\ncontrolled vector fields, the optimal transport map is contained in the\n$C^0_c$-closure of the flows generated by the system. Assuming that discrete\napproximations $\\mu_N,\\nu_N$ of the original measures $\\mu,\\nu$ are available,\nwe use a discrete optimal coupling $\\gamma_N$ to define an optimal control\nproblem. With a $\\Gamma$-convergence argument, we prove that its solutions\ncorrespond to flows that approximate the optimal transport map $T$. Finally,\ntaking advantage of the Pontryagin Maximum Principle, we propose an iterative\nnumerical scheme for the resolution of the optimal control problem, resulting\nin an algorithm for the practical computation of the approximated optimal\ntransport map.",
            "author": [
                "Alessandro Scagliotti",
                "Sara Farinelli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01404v2",
                "http://arxiv.org/pdf/2311.01404v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "34H05, 49Q22, 49J45, 49M05"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01401v1",
            "title": "Machine Learning Design of Perovskite Catalytic Properties",
            "updated": "2023-11-02T17:15:29Z",
            "published": "2023-11-02T17:15:29Z",
            "summary": "Discovering new materials that efficiently catalyze the oxygen reduction and\nevolution reactions is critical for facilitating the widespread adoption of\nsolid oxide fuel cell and electrolyzer (SOFC/SOEC) technologies. Here, we\ndevelop machine learning (ML) models to predict perovskite catalytic properties\ncritical for SOFC/SOEC applications, including oxygen surface exchange, oxygen\ndiffusivity, and area specific resistance (ASR). The models are based on\ntrivial-to-calculate elemental features and are more accurate and dramatically\nfaster than the best models based on ab initio-derived features, potentially\neliminating the need for ab initio calculations in descriptor-based screening.\nOur model of ASR enables temperature-dependent predictions, has well calibrated\nuncertainty estimates and online accessibility. Use of temporal\ncross-validation reveals our model to be effective at discovering new promising\nmaterials prior to their initial discovery, demonstrating our model can make\nmeaningful predictions. Using the SHapley Additive ExPlanations (SHAP)\napproach, we provide detailed discussion of different approaches of model\nfeaturization for ML property prediction. Finally, we use our model to screen\nmore than 19 million perovskites to develop a list of promising cheap,\nearth-abundant, stable, and high performing materials, and find some top\nmaterials contain mixtures of less-explored elements (e.g., K, Bi, Y, Ni, Cu)\nworth exploring in more detail.",
            "author": [
                "Ryan Jacobs",
                "Jian Liu",
                "Harry Abernathy",
                "Dane Morgan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01401v1",
                "http://arxiv.org/pdf/2311.01401v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01398v1",
            "title": "Server-side Rescoring of Spoken Entity-centric Knowledge Queries for\n  Virtual Assistants",
            "updated": "2023-11-02T17:07:23Z",
            "published": "2023-11-02T17:07:23Z",
            "summary": "On-device Virtual Assistants (VAs) powered by Automatic Speech Recognition\n(ASR) require effective knowledge integration for the challenging entity-rich\nquery recognition. In this paper, we conduct an empirical study of modeling\nstrategies for server-side rescoring of spoken information domain queries using\nvarious categories of Language Models (LMs) (N-gram word LMs, sub-word neural\nLMs). We investigate the combination of on-device and server-side signals, and\ndemonstrate significant WER improvements of 23%-35% on various entity-centric\nquery subpopulations by integrating various server-side LMs compared to\nperforming ASR on-device only. We also perform a comparison between LMs trained\non domain data and a GPT-3 variant offered by OpenAI as a baseline.\nFurthermore, we also show that model fusion of multiple server-side LMs trained\nfrom scratch most effectively combines complementary strengths of each model\nand integrates knowledge learned from domain-specific data to a VA ASR system.",
            "author": [
                "Youyuan Zhang",
                "Sashank Gondala",
                "Thiago Fraga-Silva",
                "Christophe Van Gysel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01398v1",
                "http://arxiv.org/pdf/2311.01398v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01394v1",
            "title": "Learning Realistic Traffic Agents in Closed-loop",
            "updated": "2023-11-02T16:55:23Z",
            "published": "2023-11-02T16:55:23Z",
            "summary": "Realistic traffic simulation is crucial for developing self-driving software\nin a safe and scalable manner prior to real-world deployment. Typically,\nimitation learning (IL) is used to learn human-like traffic agents directly\nfrom real-world observations collected offline, but without explicit\nspecification of traffic rules, agents trained from IL alone frequently display\nunrealistic infractions like collisions and driving off the road. This problem\nis exacerbated in out-of-distribution and long-tail scenarios. On the other\nhand, reinforcement learning (RL) can train traffic agents to avoid\ninfractions, but using RL alone results in unhuman-like driving behaviors. We\npropose Reinforcing Traffic Rules (RTR), a holistic closed-loop learning\nobjective to match expert demonstrations under a traffic compliance constraint,\nwhich naturally gives rise to a joint IL + RL approach, obtaining the best of\nboth worlds. Our method learns in closed-loop simulations of both nominal\nscenarios from real-world datasets as well as procedurally generated long-tail\nscenarios. Our experiments show that RTR learns more realistic and\ngeneralizable traffic simulation policies, achieving significantly better\ntradeoffs between human-like driving and traffic compliance in both nominal and\nlong-tail scenarios. Moreover, when used as a data generation tool for training\nprediction models, our learned traffic policy leads to considerably improved\ndownstream prediction metrics compared to baseline traffic agents. For more\ninformation, visit the project website: https://waabi.ai/rtr",
            "author": [
                "Chris Zhang",
                "James Tu",
                "Lunjun Zhang",
                "Kelvin Wong",
                "Simon Suo",
                "Raquel Urtasun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01394v1",
                "http://arxiv.org/pdf/2311.01394v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01489v1",
            "title": "Invariant Causal Imitation Learning for Generalizable Policies",
            "updated": "2023-11-02T16:52:36Z",
            "published": "2023-11-02T16:52:36Z",
            "summary": "Consider learning an imitation policy on the basis of demonstrated behavior\nfrom multiple environments, with an eye towards deployment in an unseen\nenvironment. Since the observable features from each setting may be different,\ndirectly learning individual policies as mappings from features to actions is\nprone to spurious correlations -- and may not generalize well. However, the\nexpert's policy is often a function of a shared latent structure underlying\nthose observable features that is invariant across settings. By leveraging data\nfrom multiple environments, we propose Invariant Causal Imitation Learning\n(ICIL), a novel technique in which we learn a feature representation that is\ninvariant across domains, on the basis of which we learn an imitation policy\nthat matches expert behavior. To cope with transition dynamics mismatch, ICIL\nlearns a shared representation of causal features (for all training\nenvironments), that is disentangled from the specific representations of noise\nvariables (for each of those environments). Moreover, to ensure that the\nlearned policy matches the observation distribution of the expert's policy,\nICIL estimates the energy of the expert's observations and uses a\nregularization term that minimizes the imitator policy's next state energy.\nExperimentally, we compare our methods against several benchmarks in control\nand healthcare tasks and show its effectiveness in learning imitation policies\ncapable of generalizing to unseen environments.",
            "author": [
                "Ioana Bica",
                "Daniel Jarrett",
                "Mihaela van der Schaar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01489v1",
                "http://arxiv.org/pdf/2311.01489v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01388v1",
            "title": "Time-series Generation by Contrastive Imitation",
            "updated": "2023-11-02T16:45:25Z",
            "published": "2023-11-02T16:45:25Z",
            "summary": "Consider learning a generative model for time-series data. The sequential\nsetting poses a unique challenge: Not only should the generator capture the\nconditional dynamics of (stepwise) transitions, but its open-loop rollouts\nshould also preserve the joint distribution of (multi-step) trajectories. On\none hand, autoregressive models trained by MLE allow learning and computing\nexplicit transition distributions, but suffer from compounding error during\nrollouts. On the other hand, adversarial models based on GAN training alleviate\nsuch exposure bias, but transitions are implicit and hard to assess. In this\nwork, we study a generative framework that seeks to combine the strengths of\nboth: Motivated by a moment-matching objective to mitigate compounding error,\nwe optimize a local (but forward-looking) transition policy, where the\nreinforcement signal is provided by a global (but stepwise-decomposable) energy\nmodel trained by contrastive estimation. At training, the two components are\nlearned cooperatively, avoiding the instabilities typical of adversarial\nobjectives. At inference, the learned policy serves as the generator for\niterative sampling, and the learned energy serves as a trajectory-level measure\nfor evaluating sample quality. By expressly training a policy to imitate\nsequential behavior of time-series features in a dataset, this approach\nembodies \"generation by imitation\". Theoretically, we illustrate the\ncorrectness of this formulation and the consistency of the algorithm.\nEmpirically, we evaluate its ability to generate predictively useful samples\nfrom real-world datasets, verifying that it performs at the standard of\nexisting benchmarks.",
            "author": [
                "Daniel Jarrett",
                "Ioana Bica",
                "Mihaela van der Schaar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01388v1",
                "http://arxiv.org/pdf/2311.01388v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01386v1",
            "title": "Can Language Models Be Tricked by Language Illusions? Easier with\n  Syntax, Harder with Semantics",
            "updated": "2023-11-02T16:44:24Z",
            "published": "2023-11-02T16:44:24Z",
            "summary": "Language models (LMs) have been argued to overlap substantially with human\nbeings in grammaticality judgment tasks. But when humans systematically make\nerrors in language processing, should we expect LMs to behave like cognitive\nmodels of language and mimic human behavior? We answer this question by\ninvestigating LMs' more subtle judgments associated with \"language illusions\"\n-- sentences that are vague in meaning, implausible, or ungrammatical but\nreceive unexpectedly high acceptability judgments by humans. We looked at three\nillusions: the comparative illusion (e.g. \"More people have been to Russia than\nI have\"), the depth-charge illusion (e.g. \"No head injury is too trivial to be\nignored\"), and the negative polarity item (NPI) illusion (e.g. \"The hunter who\nno villager believed to be trustworthy will ever shoot a bear\"). We found that\nprobabilities represented by LMs were more likely to align with human judgments\nof being \"tricked\" by the NPI illusion which examines a structural dependency,\ncompared to the comparative and the depth-charge illusions which require\nsophisticated semantic understanding. No single LM or metric yielded results\nthat are entirely consistent with human behavior. Ultimately, we show that LMs\nare limited both in their construal as cognitive models of human language\nprocessing and in their capacity to recognize nuanced but critical information\nin complicated language materials.",
            "author": [
                "Yuhan Zhang",
                "Edward Gibson",
                "Forrest Davis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01386v1",
                "http://arxiv.org/pdf/2311.01386v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01378v2",
            "title": "Vision-Language Foundation Models as Effective Robot Imitators",
            "updated": "2023-11-06T07:40:27Z",
            "published": "2023-11-02T16:34:33Z",
            "summary": "Recent progress in vision language foundation models has shown their ability\nto understand multimodal data and resolve complicated vision language tasks,\nincluding robotics manipulation. We seek a straightforward way of making use of\nexisting vision-language models (VLMs) with simple fine-tuning on robotics\ndata. To this end, we derive a simple and novel vision-language manipulation\nframework, dubbed RoboFlamingo, built upon the open-source VLMs, OpenFlamingo.\nUnlike prior works, RoboFlamingo utilizes pre-trained VLMs for single-step\nvision-language comprehension, models sequential history information with an\nexplicit policy head, and is slightly fine-tuned by imitation learning only on\nlanguage-conditioned manipulation datasets. Such a decomposition provides\nRoboFlamingo the flexibility for open-loop control and deployment on\nlow-performance platforms. By exceeding the state-of-the-art performance with a\nlarge margin on the tested benchmark, we show RoboFlamingo can be an effective\nand competitive alternative to adapt VLMs to robot control. Our extensive\nexperimental results also reveal several interesting conclusions regarding the\nbehavior of different pre-trained VLMs on manipulation tasks. We believe\nRoboFlamingo has the potential to be a cost-effective and easy-to-use solution\nfor robotics manipulation, empowering everyone with the ability to fine-tune\ntheir own robotics policy.",
            "author": [
                "Xinghang Li",
                "Minghuan Liu",
                "Hanbo Zhang",
                "Cunjun Yu",
                "Jie Xu",
                "Hongtao Wu",
                "Chilam Cheang",
                "Ya Jing",
                "Weinan Zhang",
                "Huaping Liu",
                "Hang Li",
                "Tao Kong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01378v2",
                "http://arxiv.org/pdf/2311.01378v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01377v1",
            "title": "Analysis of tidal flows through the Strait of Gibraltar using Dynamic\n  Mode Decomposition",
            "updated": "2023-11-02T16:34:31Z",
            "published": "2023-11-02T16:34:31Z",
            "summary": "The Strait of Gibraltar is a region characterized by intricate oceanic\nsub-mesoscale features, influenced by topography, tidal forces, instabilities,\nand nonlinear hydraulic processes, all governed by the nonlinear equations of\nfluid motion. In this study, we aim to uncover the underlying physics of these\nphenomena within 3D MIT general circulation model simulations, including waves,\neddies, and gyres. To achieve this, we employ Dynamic Mode Decomposition (DMD)\nto break down simulation snapshots into Koopman modes, with distinct\nexponential growth/decay rates and oscillation frequencies. Our objectives\nencompass evaluating DMD's efficacy in capturing known features, unveiling new\nelements, ranking modes, and exploring order reduction. We also introduce\nmodifications to enhance DMD's robustness, numerical accuracy, and robustness\nof eigenvalues. DMD analysis yields a comprehensive understanding of flow\npatterns, internal wave formation, and the dynamics of the Strait of Gibraltar,\nits meandering behaviors, and the formation of a secondary gyre, notably the\nWestern Alboran Gyre, as well as the propagation of Kelvin and coastal-trapped\nwaves along the African coast. In doing so, it significantly advances our\ncomprehension of intricate oceanographic phenomena and underscores the immense\nutility of DMD as an analytical tool for such complex datasets, suggesting that\nDMD could serve as a valuable addition to the toolkit of oceanographers.",
            "author": [
                "Sathsara Dias",
                "Sudam Surasinghe",
                "Kanaththa Priyankara",
                "Marko Budi\u0161i\u0107",
                "Larry Pratt",
                "Jos\u00e9 C. Sanchez-Garrido",
                "Erik M. Bollt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01377v1",
                "http://arxiv.org/pdf/2311.01377v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "physics.flu-dyn",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01375v1",
            "title": "Monotone Generative Modeling via a Gromov-Monge Embedding",
            "updated": "2023-11-02T16:33:35Z",
            "published": "2023-11-02T16:33:35Z",
            "summary": "Generative Adversarial Networks (GANs) are powerful tools for creating new\ncontent, but they face challenges such as sensitivity to starting conditions\nand mode collapse. To address these issues, we propose a deep generative model\nthat utilizes the Gromov-Monge embedding (GME). It helps identify the\nlow-dimensional structure of the underlying measure of the data and then maps\nit, while preserving its geometry, into a measure in a low-dimensional latent\nspace, which is then optimally transported to the reference measure. We\nguarantee the preservation of the underlying geometry by the GME and\n$c$-cyclical monotonicity of the generative map, where $c$ is an intrinsic\nembedding cost employed by the GME. The latter property is a first step in\nguaranteeing better robustness to initialization of parameters and mode\ncollapse. Numerical experiments demonstrate the effectiveness of our approach\nin generating high-quality images, avoiding mode collapse, and exhibiting\nrobustness to different starting conditions.",
            "author": [
                "Wonjun Lee",
                "Yifei Yang",
                "Dongmian Zou",
                "Gilad Lerman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01375v1",
                "http://arxiv.org/pdf/2311.01375v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01372v2",
            "title": "Data-Augmented and Retrieval-Augmented Context Enrichment in Chinese\n  Media Bias Detection",
            "updated": "2023-11-18T09:45:01Z",
            "published": "2023-11-02T16:29:49Z",
            "summary": "With the increasing pursuit of objective reports, automatically understanding\nmedia bias has drawn more attention in recent research. However, most of the\nprevious work examines media bias from Western ideology, such as the left and\nright in the political spectrum, which is not applicable to Chinese outlets.\nBased on the previous lexical bias and informational bias structure, we refine\nit from the Chinese perspective and go one step further to craft data with 7\nfine-grained labels. To be specific, we first construct a dataset with Chinese\nnews reports about COVID-19 which is annotated by our newly designed system,\nand then conduct substantial experiments on it to detect media bias. However,\nthe scale of the annotated data is not enough for the latest deep-learning\ntechnology, and the cost of human annotation in media bias, which needs a lot\nof professional knowledge, is too expensive. Thus, we explore some context\nenrichment methods to automatically improve these problems. In Data-Augmented\nContext Enrichment (DACE), we enlarge the training data; while in\nRetrieval-Augmented Context Enrichment (RACE), we improve information retrieval\nmethods to select valuable information and integrate it into our models to\nbetter understand bias. Extensive experiments are conducted on both our dataset\nand an English dataset BASIL. Our results show that both methods outperform our\nbaselines, while the RACE methods are more efficient and have more potential.",
            "author": [
                "Luyang Lin",
                "Jing Li",
                "Kam-Fai Wong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01372v2",
                "http://arxiv.org/pdf/2311.01372v2"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01367v1",
            "title": "Respiratory Anomaly Detection using Reflected Infrared Light-wave\n  Signals",
            "updated": "2023-11-02T16:23:13Z",
            "published": "2023-11-02T16:23:13Z",
            "summary": "In this study, we present a non-contact respiratory anomaly detection method\nusing incoherent light-wave signals reflected from the chest of a mechanical\nrobot that can breathe like human beings. In comparison to existing radar and\ncamera-based sensing systems for vitals monitoring, this technology uses only a\nlow-cost ubiquitous light source (e.g., infrared light emitting diode) and\nsensor (e.g., photodetector). This light-wave sensing (LWS) system recognizes\ndifferent breathing anomalies from the variations of light intensity reflected\nfrom the chest of the robot within a 0.5m-1.5m range. The anomaly detection\nmodel demonstrates up to 96.6% average accuracy in classifying 7 different\ntypes of breathing data using machine learning. The model can also detect\nfaulty data collected by the system that does not contain breathing\ninformation. The developed system can be utilized at home or healthcare\nfacilities as a smart, non-contact and discreet respiration monitoring method.",
            "author": [
                "Md Zobaer Islam",
                "Brenden Martin",
                "Carly Gotcher",
                "Tyler Martinez",
                "John F. O'Hara",
                "Sabit Ekin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01367v1",
                "http://arxiv.org/pdf/2311.01367v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04228v1",
            "title": "Graph Neural Networks for Topological Feature Extraction in ECG\n  Classification",
            "updated": "2023-11-02T16:14:34Z",
            "published": "2023-11-02T16:14:34Z",
            "summary": "The electrocardiogram (ECG) is a dependable instrument for assessing the\nfunction of the cardiovascular system. There has recently been much emphasis on\nprecisely classifying ECGs. While ECG situations have numerous similarities,\nlittle attention has been paid to categorizing ECGs using graph neural\nnetworks. In this study, we offer three distinct techniques for classifying\nheartbeats using deep graph neural networks to classify the ECG signals\naccurately. We suggest using different methods to extract topological features\nfrom the ECG signal and then using a branch of the graph neural network named\ngraph isomorphism network for classifying the ECGs. On the PTB Diagnostics data\nset, we tested the three proposed techniques. According to the findings, the\nthree proposed techniques are capable of making arrhythmia classification\npredictions with the accuracy of 99.38, 98.76, and 91.93 percent, respectively.",
            "author": [
                "Kamyar Zeinalipour",
                "Marco Gori"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-981-99-3592-5_2",
                "http://arxiv.org/abs/2311.04228v1",
                "http://arxiv.org/pdf/2311.04228v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01358v1",
            "title": "The Universal Statistical Structure and Scaling Laws of Chaos and\n  Turbulence",
            "updated": "2023-11-02T16:04:48Z",
            "published": "2023-11-02T16:04:48Z",
            "summary": "Turbulence is a complex spatial and temporal structure created by the strong\nnon-linear dynamics of fluid flows at high Reynolds numbers. Despite being an\nubiquitous phenomenon that has been studied for centuries, a full understanding\nof turbulence remained a formidable challenge. Here, we introduce tools from\nthe fields of quantum chaos and Random Matrix Theory (RMT) and present a\ndetailed analysis of image datasets generated from turbulence simulations of\nincompressible and compressible fluid flows. Focusing on two observables: the\ndata Gram matrix and the single image distribution, we study both the local and\nglobal eigenvalue statistics and compare them to classical chaos, uncorrelated\nnoise and natural images. We show that from the RMT perspective, the turbulence\nGram matrices lie in the same universality class as quantum chaotic rather than\nintegrable systems, and the data exhibits power-law scalings in the bulk of its\neigenvalues which are vastly different from uncorrelated classical chaos,\nrandom data, natural images. Interestingly, we find that the single sample\ndistribution only appears as fully RMT chaotic, but deviates from chaos at\nlarger correlation lengths, as well as exhibiting different scaling properties.",
            "author": [
                "Noam Levi",
                "Yaron Oz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01358v1",
                "http://arxiv.org/pdf/2311.01358v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech",
                "hep-th",
                "nlin.CD",
                "physics.flu-dyn",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01356v2",
            "title": "Upper and lower bounds for the Lipschitz constant of random neural\n  networks",
            "updated": "2023-12-01T17:40:35Z",
            "published": "2023-11-02T16:03:26Z",
            "summary": "Empirical studies have widely demonstrated that neural networks are highly\nsensitive to small, adversarial perturbations of the input. The worst-case\nrobustness against these so-called adversarial examples can be quantified by\nthe Lipschitz constant of the neural network. In this paper, we study upper and\nlower bounds for the Lipschitz constant of random ReLU neural networks.\nSpecifically, we assume that the weights and biases follow a generalization of\nthe He initialization, where general symmetric distributions for the biases are\npermitted. For shallow neural networks, we characterize the Lipschitz constant\nup to an absolute numerical constant. For deep networks with fixed depth and\nsufficiently large width, our established bounds differ by a factor that is\nlogarithmic in the width.",
            "author": [
                "Paul Geuchen",
                "Thomas Heindl",
                "Dominik St\u00f6ger",
                "Felix Voigtlaender"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01356v2",
                "http://arxiv.org/pdf/2311.01356v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.PR",
                "68T07, 26A16, 60B20, 60G15"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01352v1",
            "title": "Deep learning based Image Compression for Microscopy Images: An\n  Empirical Study",
            "updated": "2023-11-02T16:00:32Z",
            "published": "2023-11-02T16:00:32Z",
            "summary": "With the fast development of modern microscopes and bioimaging techniques, an\nunprecedentedly large amount of imaging data are being generated, stored,\nanalyzed, and even shared through networks. The size of the data poses great\nchallenges for current data infrastructure. One common way to reduce the data\nsize is by image compression. This present study analyzes classic and deep\nlearning based image compression methods, and their impact on deep learning\nbased image processing models. Deep learning based label-free prediction models\n(i.e., predicting fluorescent images from bright field images) are used as an\nexample application for comparison and analysis. Effective image compression\nmethods could help reduce the data size significantly without losing necessary\ninformation, and therefore reduce the burden on data management infrastructure\nand permit fast transmission through the network for data sharing or cloud\ncomputing. To compress images in such a wanted way, multiple classical lossy\nimage compression techniques are compared to several AI-based compression\nmodels provided by and trained with the CompressAI toolbox using python. These\ndifferent compression techniques are compared in compression ratio, multiple\nimage similarity measures and, most importantly, the prediction accuracy from\nlabel-free models on compressed images. We found that AI-based compression\ntechniques largely outperform the classic ones and will minimally affect the\ndownstream label-free task in 2D cases. In the end, we hope the present study\ncould shed light on the potential of deep learning based image compression and\nthe impact of image compression on downstream deep learning based image\nanalysis models.",
            "author": [
                "Yu Zhou",
                "Jan Sollman",
                "Jianxu Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01352v1",
                "http://arxiv.org/pdf/2311.01352v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01349v1",
            "title": "Unreading Race: Purging Protected Features from Chest X-ray Embeddings",
            "updated": "2023-11-02T15:59:00Z",
            "published": "2023-11-02T15:59:00Z",
            "summary": "Purpose: To analyze and remove protected feature effects in chest radiograph\nembeddings of deep learning models.\n  Materials and Methods: An orthogonalization is utilized to remove the\ninfluence of protected features (e.g., age, sex, race) in chest radiograph\nembeddings, ensuring feature-independent results. To validate the efficacy of\nthe approach, we retrospectively study the MIMIC and CheXpert datasets using\nthree pre-trained models, namely a supervised contrastive, a self-supervised\ncontrastive, and a baseline classifier model. Our statistical analysis involves\ncomparing the original versus the orthogonalized embeddings by estimating\nprotected feature influences and evaluating the ability to predict race, age,\nor sex using the two types of embeddings.\n  Results: Our experiments reveal a significant influence of protected features\non predictions of pathologies. Applying orthogonalization removes these feature\neffects. Apart from removing any influence on pathology classification, while\nmaintaining competitive predictive performance, orthogonalized embeddings\nfurther make it infeasible to directly predict protected attributes and\nmitigate subgroup disparities.\n  Conclusion: The presented work demonstrates the successful application and\nevaluation of the orthogonalization technique in the domain of chest X-ray\nclassification.",
            "author": [
                "Tobias Weber",
                "Michael Ingrisch",
                "Bernd Bischl",
                "David R\u00fcgamer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01349v1",
                "http://arxiv.org/pdf/2311.01349v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01344v1",
            "title": "Like an Open Book? Read Neural Network Architecture with Simple Power\n  Analysis on 32-bit Microcontrollers",
            "updated": "2023-11-02T15:55:20Z",
            "published": "2023-11-02T15:55:20Z",
            "summary": "Model extraction is a growing concern for the security of AI systems. For\ndeep neural network models, the architecture is the most important information\nan adversary aims to recover. Being a sequence of repeated computation blocks,\nneural network models deployed on edge-devices will generate distinctive\nside-channel leakages. The latter can be exploited to extract critical\ninformation when targeted platforms are physically accessible. By combining\ntheoretical knowledge about deep learning practices and analysis of a\nwidespread implementation library (ARM CMSIS-NN), our purpose is to answer this\ncritical question: how far can we extract architecture information by simply\nexamining an EM side-channel trace? For the first time, we propose an\nextraction methodology for traditional MLP and CNN models running on a high-end\n32-bit microcontroller (Cortex-M7) that relies only on simple pattern\nrecognition analysis. Despite few challenging cases, we claim that, contrary to\nparameters extraction, the complexity of the attack is relatively low and we\nhighlight the urgent need for practicable protections that could fit the strong\nmemory and latency requirements of such platforms.",
            "author": [
                "Raphael Joud",
                "Pierre-Alain Moellic",
                "Simon Pontie",
                "Jean-Baptiste Rigaud"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01344v1",
                "http://arxiv.org/pdf/2311.01344v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01343v3",
            "title": "Collaborative Large Language Model for Recommender Systems",
            "updated": "2023-11-08T05:02:06Z",
            "published": "2023-11-02T15:52:35Z",
            "summary": "Recently, there is a growing interest in developing next-generation\nrecommender systems (RSs) based on pretrained large language models (LLMs),\nfully utilizing their encoded knowledge and reasoning ability. However, the\nsemantic gap between natural language and recommendation tasks is still not\nwell addressed, leading to multiple issues such as spuriously-correlated\nuser/item descriptors, ineffective language modeling on user/item contents, and\ninefficient recommendations via auto-regression, etc. In this paper, we propose\nCLLM4Rec, the first generative RS that tightly integrates the LLM paradigm and\nID paradigm of RS, aiming to address the above challenges simultaneously. We\nfirst extend the vocabulary of pretrained LLMs with user/item ID tokens to\nfaithfully model the user/item collaborative and content semantics.\nAccordingly, in the pretraining stage, a novel soft+hard prompting strategy is\nproposed to effectively learn user/item collaborative/content token embeddings\nvia language modeling on RS-specific corpora established from user-item\ninteractions and user/item features, where each document is split into a prompt\nconsisting of heterogeneous soft (user/item) tokens and hard (vocab) tokens and\na main text consisting of homogeneous item tokens or vocab tokens that\nfacilitates stable and effective language modeling. In addition, a novel mutual\nregularization strategy is introduced to encourage the CLLM4Rec to capture\nrecommendation-oriented information from user/item contents. Finally, we\npropose a novel recommendation-oriented finetuning strategy for CLLM4Rec, where\nan item prediction head with multinomial likelihood is added to the pretrained\nCLLM4Rec backbone to predict hold-out items based on the soft+hard prompts\nestablished from masked user-item interaction history, where recommendations of\nmultiple items can be generated efficiently.",
            "author": [
                "Yaochen Zhu",
                "Liang Wu",
                "Qi Guo",
                "Liangjie Hong",
                "Jundong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01343v3",
                "http://arxiv.org/pdf/2311.01343v3"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01337v1",
            "title": "Adaptive Identification of SIS Models",
            "updated": "2023-11-02T15:47:33Z",
            "published": "2023-11-02T15:47:33Z",
            "summary": "Effective containment of spreading processes such as epidemics requires\naccurate knowledge of several key parameters that govern their dynamics. In\nthis work, we first show that the problem of identifying the underlying\nparameters of epidemiological spreading processes is often ill-conditioned and\nlacks the persistence of excitation required for the convergence of adaptive\nlearning schemes. To tackle this challenge, we leverage a relaxed property\ncalled initial excitation combined with a recursive least squares algorithm to\ndesign an online adaptive identifier to learn the parameters of the\nsusceptible-infected-susceptible (SIS) epidemic model from the knowledge of its\nstates. We prove that the iterates generated by the proposed algorithm minimize\nan auxiliary weighted least squares cost function. We illustrate the\nconvergence of the error of the estimated epidemic parameters via several\nnumerical case studies and compare it with results obtained using conventional\napproaches.",
            "author": [
                "Chi Ho Leung",
                "William E. Retnaraj",
                "Ashish R. Hota",
                "Philip E. Par\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01337v1",
                "http://arxiv.org/pdf/2311.01337v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01335v2",
            "title": "Automatic Robot Hand-Eye Calibration Enabled by Learning-Based 3D Vision",
            "updated": "2023-11-27T14:19:34Z",
            "published": "2023-11-02T15:45:09Z",
            "summary": "Hand-eye calibration, as a fundamental task in vision-based robotic systems,\naims to estimate the transformation matrix between the coordinate frame of the\ncamera and the robot flange. Most approaches to hand-eye calibration rely on\nexternal markers or human assistance. We proposed Look at Robot Base Once\n(LRBO), a novel methodology that addresses the hand-eye calibration problem\nwithout external calibration objects or human support, but with the robot base.\nUsing point clouds of the robot base, a transformation matrix from the\ncoordinate frame of the camera to the robot base is established as I=AXB. To\nthis end, we exploit learning-based 3D detection and registration algorithms to\nestimate the location and orientation of the robot base. The robustness and\naccuracy of the method are quantified by ground-truth-based evaluation, and the\naccuracy result is compared with other 3D vision-based calibration methods. To\nassess the feasibility of our methodology, we carried out experiments utilizing\na low-cost structured light scanner across varying joint configurations and\ngroups of experiments. The proposed hand-eye calibration method achieved a\ntranslation deviation of 0.930 mm and a rotation deviation of 0.265 degrees\naccording to the experimental results. Additionally, the 3D reconstruction\nexperiments demonstrated a rotation error of 0.994 degrees and a position error\nof 1.697 mm. Moreover, our method offers the potential to be completed in 1\nsecond, which is the fastest compared to other 3D hand-eye calibration methods.\nCode is released at github.com/leihui6/LRBO.",
            "author": [
                "Leihui Li",
                "Xingyu Yang",
                "Riwei Wang",
                "Xuping Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01335v2",
                "http://arxiv.org/pdf/2311.01335v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01334v1",
            "title": "Supervised Learning Based Real-Time Adaptive Beamforming On-board\n  Multibeam Satellites",
            "updated": "2023-11-02T15:45:00Z",
            "published": "2023-11-02T15:45:00Z",
            "summary": "Satellite communications (SatCom) are crucial for global connectivity,\nespecially in the era of emerging technologies like 6G and narrowing the\ndigital divide. Traditional SatCom systems struggle with efficient resource\nmanagement due to static multibeam configurations, hindering quality of service\n(QoS) amidst dynamic traffic demands. This paper introduces an innovative\nsolution - real-time adaptive beamforming on multibeam satellites with\nsoftware-defined payloads in geostationary orbit (GEO). Utilizing a Direct\nRadiating Array (DRA) with circular polarization in the 17.7 - 20.2 GHz band,\nthe paper outlines DRA design and a supervised learning-based algorithm for\non-board beamforming. This adaptive approach not only meets precise beam\nprojection needs but also dynamically adjusts beamwidth, minimizes sidelobe\nlevels (SLL), and optimizes effective isotropic radiated power (EIRP).",
            "author": [
                "Flor Ortiz",
                "Juan A. Vasquez-Peralvo",
                "Jorge Querol",
                "Eva Lagunas",
                "Jorge L. Gonzalez Rios",
                "Marcele O. K. Mendonca",
                "Luis Garces",
                "Victor Monzon Baeza",
                "Symeon Chatzinotas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01334v1",
                "http://arxiv.org/pdf/2311.01334v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01331v2",
            "title": "Offline Imitation from Observation via Primal Wasserstein State\n  Occupancy Matching",
            "updated": "2023-11-21T18:50:49Z",
            "published": "2023-11-02T15:41:57Z",
            "summary": "In real-world scenarios, arbitrary interactions with the environment can\noften be costly, and actions of expert demonstrations are not always available.\nTo reduce the need for both, Offline Learning from Observations (LfO) is\nextensively studied, where the agent learns to solve a task with only expert\nstates and \\textit{task-agnostic} non-expert state-action pairs. The\nstate-of-the-art DIstribution Correction Estimation (DICE) methods minimize the\nstate occupancy divergence between the learner and expert policies. However,\nthey are limited to either $f$-divergences (KL and $\\chi^2$) or Wasserstein\ndistance with Rubinstein duality, the latter of which constrains the underlying\ndistance metric crucial to the performance of Wasserstein-based solutions. To\naddress this problem, we propose Primal Wasserstein DICE (PW-DICE), which\nminimizes the primal Wasserstein distance between the expert and learner state\noccupancies with a pessimistic regularizer and leverages a contrastively\nlearned distance as the underlying metric for the Wasserstein distance.\nTheoretically, we prove that our framework is a generalization of the\nstate-of-the-art, SMODICE, and unifies $f$-divergence and Wasserstein\nminimization. Empirically, we find that PW-DICE improves upon several\nstate-of-the-art methods on multiple testbeds.",
            "author": [
                "Kai Yan",
                "Alexander G. Schwing",
                "Yu-xiong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01331v2",
                "http://arxiv.org/pdf/2311.01331v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01329v1",
            "title": "A Simple Solution for Offline Imitation from Observations and Examples\n  with Possibly Incomplete Trajectories",
            "updated": "2023-11-02T15:41:09Z",
            "published": "2023-11-02T15:41:09Z",
            "summary": "Offline imitation from observations aims to solve MDPs where only\ntask-specific expert states and task-agnostic non-expert state-action pairs are\navailable. Offline imitation is useful in real-world scenarios where arbitrary\ninteractions are costly and expert actions are unavailable. The\nstate-of-the-art \"DIstribution Correction Estimation\" (DICE) methods minimize\ndivergence of state occupancy between expert and learner policies and retrieve\na policy with weighted behavior cloning; however, their results are unstable\nwhen learning from incomplete trajectories, due to a non-robust optimization in\nthe dual domain. To address the issue, in this paper, we propose\nTrajectory-Aware Imitation Learning from Observations (TAILO). TAILO uses a\ndiscounted sum along the future trajectory as the weight for weighted behavior\ncloning. The terms for the sum are scaled by the output of a discriminator,\nwhich aims to identify expert states. Despite simplicity, TAILO works well if\nthere exist trajectories or segments of expert behavior in the task-agnostic\ndata, a common assumption in prior work. In experiments across multiple\ntestbeds, we find TAILO to be more robust and effective, particularly with\nincomplete trajectories.",
            "author": [
                "Kai Yan",
                "Alexander G. Schwing",
                "Yu-Xiong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01329v1",
                "http://arxiv.org/pdf/2311.01329v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01327v1",
            "title": "High-dimensional Linear Bandits with Knapsacks",
            "updated": "2023-11-02T15:40:33Z",
            "published": "2023-11-02T15:40:33Z",
            "summary": "We study the contextual bandits with knapsack (CBwK) problem under the\nhigh-dimensional setting where the dimension of the feature is large. The\nreward of pulling each arm equals the multiplication of a sparse\nhigh-dimensional weight vector and the feature of the current arrival, with\nadditional random noise. In this paper, we investigate how to exploit this\nsparsity structure to achieve improved regret for the CBwK problem. To this\nend, we first develop an online variant of the hard thresholding algorithm that\nperforms the sparse estimation in an online manner. We further combine our\nonline estimator with a primal-dual framework, where we assign a dual variable\nto each knapsack constraint and utilize an online learning algorithm to update\nthe dual variable, thereby controlling the consumption of the knapsack\ncapacity. We show that this integrated approach allows us to achieve a\nsublinear regret that depends logarithmically on the feature dimension, thus\nimproving the polynomial dependency established in the previous literature. We\nalso apply our framework to the high-dimension contextual bandit problem\nwithout the knapsack constraint and achieve optimal regret in both the\ndata-poor regime and the data-rich regime. We finally conduct numerical\nexperiments to show the efficient empirical performance of our algorithms under\nthe high dimensional setting.",
            "author": [
                "Wanteng Ma",
                "Dong Xia",
                "Jiashuo Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01327v1",
                "http://arxiv.org/pdf/2311.01327v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14683v1",
            "title": "Data Science for Social Good",
            "updated": "2023-11-02T15:40:20Z",
            "published": "2023-11-02T15:40:20Z",
            "summary": "Data science has been described as the fourth paradigm for scientific\ndiscovery. The latest wave of data science research, pertaining to machine\nlearning and artificial intelligence (AI), is growing exponentially and\ngarnering millions of annual citations. However, this growth has been\naccompanied by a diminishing emphasis on social good challenges - our analysis\nreveals that the proportion of data science research focusing on social good is\nless than it has ever been. At the same time, the proliferation of machine\nlearning and generative AI have sparked debates about the socio-technical\nprospects and challenges associated with data science for human flourishing,\norganizations, and society. Against this backdrop, we present a framework for\n\"data science for social good\" (DSSG) research that considers the interplay\nbetween relevant data science research genres, social good challenges, and\ndifferent levels of socio-technical abstraction. We perform an analysis of the\nliterature to empirically demonstrate the paucity of work on DSSG in\ninformation systems (and other related disciplines) and highlight current\nimpediments. We then use our proposed framework to introduce the articles\nappearing in the special issue. We hope that this article and the special issue\nwill spur future DSSG research and help reverse the alarming trend across data\nscience research over the past 30-plus years in which social good challenges\nare garnering proportionately less attention with each passing day.",
            "author": [
                "Ahmed Abbasi",
                "Roger H. L. Chiang",
                "Jennifer J. Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14683v1",
                "http://arxiv.org/pdf/2311.14683v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01326v1",
            "title": "Better Together: Enhancing Generative Knowledge Graph Completion with\n  Language Models and Neighborhood Information",
            "updated": "2023-11-02T15:38:39Z",
            "published": "2023-11-02T15:38:39Z",
            "summary": "Real-world Knowledge Graphs (KGs) often suffer from incompleteness, which\nlimits their potential performance. Knowledge Graph Completion (KGC) techniques\naim to address this issue. However, traditional KGC methods are computationally\nintensive and impractical for large-scale KGs, necessitating the learning of\ndense node embeddings and computing pairwise distances. Generative\ntransformer-based language models (e.g., T5 and recent KGT5) offer a promising\nsolution as they can predict the tail nodes directly. In this study, we propose\nto include node neighborhoods as additional information to improve KGC methods\nbased on language models. We examine the effects of this imputation and show\nthat, on both inductive and transductive Wikidata subsets, our method\noutperforms KGT5 and conventional KGC approaches. We also provide an extensive\nanalysis of the impact of neighborhood on model prediction and show its\nimportance. Furthermore, we point the way to significantly improve KGC through\nmore effective neighborhood selection.",
            "author": [
                "Alla Chepurova",
                "Aydar Bulatov",
                "Yuri Kuratov",
                "Mikhail Burtsev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01326v1",
                "http://arxiv.org/pdf/2311.01326v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01323v1",
            "title": "Towards Evaluating Transfer-based Attacks Systematically, Practically,\n  and Fairly",
            "updated": "2023-11-02T15:35:58Z",
            "published": "2023-11-02T15:35:58Z",
            "summary": "The adversarial vulnerability of deep neural networks (DNNs) has drawn great\nattention due to the security risk of applying these models in real-world\napplications. Based on transferability of adversarial examples, an increasing\nnumber of transfer-based methods have been developed to fool black-box DNN\nmodels whose architecture and parameters are inaccessible. Although tremendous\neffort has been exerted, there still lacks a standardized benchmark that could\nbe taken advantage of to compare these methods systematically, fairly, and\npractically. Our investigation shows that the evaluation of some methods needs\nto be more reasonable and more thorough to verify their effectiveness, to\navoid, for example, unfair comparison and insufficient consideration of\npossible substitute/victim models. Therefore, we establish a transfer-based\nattack benchmark (TA-Bench) which implements 30+ methods. In this paper, we\nevaluate and compare them comprehensively on 25 popular substitute/victim\nmodels on ImageNet. New insights about the effectiveness of these methods are\ngained and guidelines for future evaluations are provided. Code at:\nhttps://github.com/qizhangli/TA-Bench.",
            "author": [
                "Qizhang Li",
                "Yiwen Guo",
                "Wangmeng Zuo",
                "Hao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01323v1",
                "http://arxiv.org/pdf/2311.01323v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01314v1",
            "title": "Recommendations by Concise User Profiles from Review Text",
            "updated": "2023-11-02T15:31:12Z",
            "published": "2023-11-02T15:31:12Z",
            "summary": "Recommender systems are most successful for popular items and users with\nample interactions (likes, ratings etc.). This work addresses the difficult and\nunderexplored case of supporting users who have very sparse interactions but\npost informative review texts. Our experimental studies address two book\ncommunities with these characteristics. We design a framework with\nTransformer-based representation learning, covering user-item interactions,\nitem content, and user-provided reviews. To overcome interaction sparseness, we\ndevise techniques for selecting the most informative cues to construct concise\nuser profiles. Comprehensive experiments, with datasets from Amazon and\nGoodreads, show that judicious selection of text snippets achieves the best\nperformance, even in comparison to ChatGPT-generated user profiles.",
            "author": [
                "Ghazaleh Haratinezhad Torbati",
                "Anna Tigunova",
                "Andrew Yates",
                "Gerhard Weikum"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01314v1",
                "http://arxiv.org/pdf/2311.01314v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01485v1",
            "title": "Subgroup identification using individual participant data from multiple\n  trials on low back pain",
            "updated": "2023-11-02T15:25:11Z",
            "published": "2023-11-02T15:25:11Z",
            "summary": "Model-based recursive partitioning (MOB) and its extension, metaMOB, are\npotent tools for identifying subgroups with differential treatment effects. In\nthe metaMOB approach random effects are used to model heterogeneity of the\ntreatment effects when pooling data from various trials. In situations where\ninterventions offer only small overall benefits and require extensive, costly\ntrials with a large participant enrollment, leveraging individual-participant\ndata (IPD) from multiple trials can help identify individuals who are most\nlikely to benefit from the intervention. We explore the application of MOB and\nmetaMOB in the context of non specific low back pain treatment, using\nsynthesized data based on a subset of the individual participant data\nmeta-analysis by Patel et al. Our study underscores the need to explore\nheterogeneity in intercepts and treatment effects to identify subgroups with\ndifferential treatment effects in IPD meta-analyses.",
            "author": [
                "Cynthia Huber",
                "Tim Friede"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01485v1",
                "http://arxiv.org/pdf/2311.01485v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01310v2",
            "title": "Scattering Vision Transformer: Spectral Mixing Matters",
            "updated": "2023-11-20T13:08:27Z",
            "published": "2023-11-02T15:24:23Z",
            "summary": "Vision transformers have gained significant attention and achieved\nstate-of-the-art performance in various computer vision tasks, including image\nclassification, instance segmentation, and object detection. However,\nchallenges remain in addressing attention complexity and effectively capturing\nfine-grained information within images. Existing solutions often resort to\ndown-sampling operations, such as pooling, to reduce computational cost.\nUnfortunately, such operations are non-invertible and can result in information\nloss. In this paper, we present a novel approach called Scattering Vision\nTransformer (SVT) to tackle these challenges. SVT incorporates a spectrally\nscattering network that enables the capture of intricate image details. SVT\novercomes the invertibility issue associated with down-sampling operations by\nseparating low-frequency and high-frequency components. Furthermore, SVT\nintroduces a unique spectral gating network utilizing Einstein multiplication\nfor token and channel mixing, effectively reducing complexity. We show that SVT\nachieves state-of-the-art performance on the ImageNet dataset with a\nsignificant reduction in a number of parameters and FLOPS. SVT shows 2\\%\nimprovement over LiTv2 and iFormer. SVT-H-S reaches 84.2\\% top-1 accuracy,\nwhile SVT-H-B reaches 85.2\\% (state-of-art for base versions) and SVT-H-L\nreaches 85.7\\% (again state-of-art for large versions). SVT also shows\ncomparable results in other vision tasks such as instance segmentation. SVT\nalso outperforms other transformers in transfer learning on standard datasets\nsuch as CIFAR10, CIFAR100, Oxford Flower, and Stanford Car datasets. The\nproject page is available on this\nwebpage.\\url{https://badripatro.github.io/svt/}.",
            "author": [
                "Badri N. Patro",
                "Vijay Srinivas Agneeswaran"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01310v2",
                "http://arxiv.org/pdf/2311.01310v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "eess.IV",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01305v3",
            "title": "AWEQ: Post-Training Quantization with Activation-Weight Equalization for\n  Large Language Models",
            "updated": "2023-11-12T07:54:09Z",
            "published": "2023-11-02T15:18:22Z",
            "summary": "Large language models(LLMs) exhibit excellent performance across a variety of\ntasks, but they come with significant computational and storage costs.\nQuantizing these models is an effective way to alleviate this issue. However,\nexisting methods struggle to strike a balance between model accuracy and\nhardware efficiency. This is where we introduce AWEQ, a post-training method\nthat requires no additional training overhead. AWEQ excels in both\nultra-low-bit quantization and 8-bit weight and activation (W8A8) quantization.\nThere is an observation that weight quantization is less challenging than\nactivation quantization. AWEQ transfers the difficulty of activation\nquantization to weights using channel equalization, achieving a balance between\nthe quantization difficulties of both, and thereby maximizing performance. We\nhave further refined the equalization method to mitigate quantization bias\nerror, ensuring the robustness of the model. Extensive experiments on popular\nmodels such as LLaMA and OPT demonstrate that AWEQ outperforms all existing\npost-training quantization methods for large models.",
            "author": [
                "Baisong Li",
                "Xingwang Wang",
                "Haixiao Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01305v3",
                "http://arxiv.org/pdf/2311.01305v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01301v2",
            "title": "TRIALSCOPE: A Unifying Causal Framework for Scaling Real-World Evidence\n  Generation with Biomedical Language Models",
            "updated": "2023-11-06T11:29:30Z",
            "published": "2023-11-02T15:15:47Z",
            "summary": "The rapid digitization of real-world data offers an unprecedented opportunity\nfor optimizing healthcare delivery and accelerating biomedical discovery. In\npractice, however, such data is most abundantly available in unstructured\nforms, such as clinical notes in electronic medical records (EMRs), and it is\ngenerally plagued by confounders. In this paper, we present TRIALSCOPE, a\nunifying framework for distilling real-world evidence from population-level\nobservational data. TRIALSCOPE leverages biomedical language models to\nstructure clinical text at scale, employs advanced probabilistic modeling for\ndenoising and imputation, and incorporates state-of-the-art causal inference\ntechniques to combat common confounders. Using clinical trial specification as\ngeneric representation, TRIALSCOPE provides a turn-key solution to generate and\nreason with clinical hypotheses using observational data. In extensive\nexperiments and analyses on a large-scale real-world dataset with over one\nmillion cancer patients from a large US healthcare network, we show that\nTRIALSCOPE can produce high-quality structuring of real-world data and\ngenerates comparable results to marquee cancer trials. In addition to\nfacilitating in-silicon clinical trial design and optimization, TRIALSCOPE may\nbe used to empower synthetic controls, pragmatic trials, post-market\nsurveillance, as well as support fine-grained patient-like-me reasoning in\nprecision diagnosis and treatment.",
            "author": [
                "Javier Gonz\u00e1lez",
                "Cliff Wong",
                "Zelalem Gero",
                "Jass Bagga",
                "Risa Ueno",
                "Isabel Chien",
                "Eduard Oravkin",
                "Emre Kiciman",
                "Aditya Nori",
                "Roshanthi Weerasinghe",
                "Rom S. Leidner",
                "Brian Piening",
                "Tristan Naumann",
                "Carlo Bifulco",
                "Hoifung Poon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01301v2",
                "http://arxiv.org/pdf/2311.01301v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01295v1",
            "title": "DP-Mix: Mixup-based Data Augmentation for Differentially Private\n  Learning",
            "updated": "2023-11-02T15:12:12Z",
            "published": "2023-11-02T15:12:12Z",
            "summary": "Data augmentation techniques, such as simple image transformations and\ncombinations, are highly effective at improving the generalization of computer\nvision models, especially when training data is limited. However, such\ntechniques are fundamentally incompatible with differentially private learning\napproaches, due to the latter's built-in assumption that each training image's\ncontribution to the learned model is bounded. In this paper, we investigate why\nnaive applications of multi-sample data augmentation techniques, such as mixup,\nfail to achieve good performance and propose two novel data augmentation\ntechniques specifically designed for the constraints of differentially private\nlearning. Our first technique, DP-Mix_Self, achieves SoTA classification\nperformance across a range of datasets and settings by performing mixup on\nself-augmented data. Our second technique, DP-Mix_Diff, further improves\nperformance by incorporating synthetic data from a pre-trained diffusion model\ninto the mixup process. We open-source the code at\nhttps://github.com/wenxuan-Bao/DP-Mix.",
            "author": [
                "Wenxuan Bao",
                "Francesco Pittaluga",
                "Vijay Kumar B G",
                "Vincent Bindschaedler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01295v1",
                "http://arxiv.org/pdf/2311.01295v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01282v3",
            "title": "FlashDecoding++: Faster Large Language Model Inference on GPUs",
            "updated": "2023-11-10T01:43:51Z",
            "published": "2023-11-02T14:57:03Z",
            "summary": "As the Large Language Model (LLM) becomes increasingly important in various\ndomains. However, the following challenges still remain unsolved in\naccelerating LLM inference: (1) Synchronized partial softmax update. The\nsoftmax operation requires a synchronized update operation among each partial\nsoftmax result, leading to ~20% overheads for the attention computation in\nLLMs. (2) Under-utilized computation of flat GEMM. The shape of matrices\nperforming GEMM in LLM inference is flat, leading to under-utilized computation\nand >50% performance loss after padding zeros in previous designs. (3)\nPerformance loss due to static dataflow. Kernel performance in LLM depends on\nvaried input data features, hardware configurations, etc. A single and static\ndataflow may lead to a 50.25% performance loss for GEMMs of different shapes in\nLLM inference.\n  We present FlashDecoding++, a fast LLM inference engine supporting mainstream\nLLMs and hardware back-ends. To tackle the above challenges, FlashDecoding++\ncreatively proposes: (1) Asynchronized softmax with unified max value.\nFlashDecoding++ introduces a unified max value technique for different partial\nsoftmax computations to avoid synchronization. (2) Flat GEMM optimization with\ndouble buffering. FlashDecoding++ points out that flat GEMMs with different\nshapes face varied bottlenecks. Then, techniques like double buffering are\nintroduced. (3) Heuristic dataflow with hardware resource adaptation.\nFlashDecoding++ heuristically optimizes dataflow using different hardware\nresource considering input dynamics. Due to the versatility of optimizations in\nFlashDecoding++, FlashDecoding++ can achieve up to 4.86x and 2.18x speedup on\nboth NVIDIA and AMD GPUs compared to Hugging Face implementations.\nFlashDecoding++ also achieves an average speedup of 1.37x compared to\nstate-of-the-art LLM inference engines on mainstream LLMs.",
            "author": [
                "Ke Hong",
                "Guohao Dai",
                "Jiaming Xu",
                "Qiuli Mao",
                "Xiuhong Li",
                "Jun Liu",
                "Kangdi Chen",
                "Yuhan Dong",
                "Yu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01282v3",
                "http://arxiv.org/pdf/2311.01282v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01483v2",
            "title": "FedSN: A General Federated Learning Framework over LEO Satellite\n  Networks",
            "updated": "2023-11-22T08:55:37Z",
            "published": "2023-11-02T14:47:06Z",
            "summary": "Recently, a large number of Low Earth Orbit (LEO) satellites have been\nlaunched and deployed successfully in space by commercial companies, such as\nSpaceX. Due to multimodal sensors equipped by the LEO satellites, they serve\nnot only for communication but also for various machine learning applications,\nsuch as space modulation recognition, remote sensing image classification, etc.\nHowever, the ground station (GS) may be incapable of downloading such a large\nvolume of raw sensing data for centralized model training due to the limited\ncontact time with LEO satellites (e.g. 5 minutes). Therefore, federated\nlearning (FL) has emerged as the promising solution to address this problem via\non-device training. Unfortunately, to enable FL on LEO satellites, we still\nface three critical challenges that are i) heterogeneous computing and memory\ncapabilities, ii) limited uplink rate, and iii) model staleness. To this end,\nwe propose FedSN as a general FL framework to tackle the above challenges, and\nfully explore data diversity on LEO satellites. Specifically, we first present\na novel sub-structure scheme to enable heterogeneous local model training\nconsidering different computing, memory, and communication constraints on LEO\nsatellites. Additionally, we propose a pseudo-synchronous model aggregation\nstrategy to dynamically schedule model aggregation for compensating model\nstaleness. To further demonstrate the effectiveness of the FedSN, we evaluate\nit using space modulation recognition and remote sensing image classification\ntasks by leveraging the data from real-world satellite networks. Extensive\nexperimental results demonstrate that FedSN framework achieves higher accuracy,\nlower computing, and communication overhead than the state-of-the-art\nbenchmarks and the effectiveness of each components in FedSN.",
            "author": [
                "Zheng Lin",
                "Zhe Chen",
                "Zihan Fang",
                "Xianhao Chen",
                "Xiong Wang",
                "Yue Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01483v2",
                "http://arxiv.org/pdf/2311.01483v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01276v2",
            "title": "Long-Range Neural Atom Learning for Molecular Graphs",
            "updated": "2023-11-27T13:02:50Z",
            "published": "2023-11-02T14:44:50Z",
            "summary": "Graph Neural Networks (GNNs) have been widely adopted for drug discovery with\nmolecular graphs. Nevertheless, current GNNs are mainly good at leveraging\nshort-range interactions (SRI) but struggle to capture long-range interactions\n(LRI), both of which are crucial for determining molecular properties. To\ntackle this issue, we propose a method that implicitly projects all original\natoms into a few Neural Atoms, which abstracts the collective information of\natomic groups within a molecule. Specifically, we explicitly exchange the\ninformation among neural atoms and project them back to the atoms'\nrepresentations as an enhancement. With this mechanism, neural atoms establish\nthe communication channels among distant nodes, effectively reducing the\ninteraction scope of arbitrary node pairs into a single hop. To provide an\ninspection of our method from a physical perspective, we reveal its connection\nwith the traditional LRI calculation method, Ewald Summation. We conduct\nextensive experiments on three long-range graph benchmarks, covering both\ngraph-level and link-level tasks on molecular graphs. We empirically justify\nthat our method can be equipped with an arbitrary GNN and help to capture LRI.",
            "author": [
                "Xuan Li",
                "Zhanke Zhou",
                "Jiangchao Yao",
                "Yu Rong",
                "Lu Zhang",
                "Bo Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01276v2",
                "http://arxiv.org/pdf/2311.01276v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01267v1",
            "title": "UniFolding: Towards Sample-efficient, Scalable, and Generalizable\n  Robotic Garment Folding",
            "updated": "2023-11-02T14:25:10Z",
            "published": "2023-11-02T14:25:10Z",
            "summary": "This paper explores the development of UniFolding, a sample-efficient,\nscalable, and generalizable robotic system for unfolding and folding various\ngarments. UniFolding employs the proposed UFONet neural network to integrate\nunfolding and folding decisions into a single policy model that is adaptable to\ndifferent garment types and states. The design of UniFolding is based on a\ngarment's partial point cloud, which aids in generalization and reduces\nsensitivity to variations in texture and shape. The training pipeline\nprioritizes low-cost, sample-efficient data collection. Training data is\ncollected via a human-centric process with offline and online stages. The\noffline stage involves human unfolding and folding actions via Virtual Reality,\nwhile the online stage utilizes human-in-the-loop learning to fine-tune the\nmodel in a real-world setting. The system is tested on two garment types:\nlong-sleeve and short-sleeve shirts. Performance is evaluated on 20 shirts with\nsignificant variations in textures, shapes, and materials. More experiments and\nvideos can be found in the supplementary materials and on the website:\nhttps://unifolding.robotflow.ai",
            "author": [
                "Han Xue",
                "Yutong Li",
                "Wenqiang Xu",
                "Huanyu Li",
                "Dongzhe Zheng",
                "Cewu Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01267v1",
                "http://arxiv.org/pdf/2311.01267v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12866v1",
            "title": "Modular Blended Attention Network for Video Question Answering",
            "updated": "2023-11-02T14:22:17Z",
            "published": "2023-11-02T14:22:17Z",
            "summary": "In multimodal machine learning tasks, it is due to the complexity of the\nassignments that the network structure, in most cases, is assembled in a\nsophisticated way. The holistic architecture can be separated into several\nlogical parts according to the respective ends that the modules are devised to\nachieve. As the number of modalities of information representation increases,\nconstructing ad hoc subnetworks for processing the data from divergent\nmodalities while mediating the fusion of different information types has become\na cumbersome and expensive problem. In this paper, we present an approach to\nfacilitate the question with a reusable and composable neural unit; by\nconnecting the units in series or parallel, the arduous network constructing of\nmultimodal machine learning tasks will be accomplished in a much\nstraightforward way. Additionally, through parameter sharing (weights\nreplication) among the units, the space complexity will be significantly\nreduced. We have conducted experiments on three commonly used datasets; our\nmethod achieves impressive performance compared to several video QA baselines.",
            "author": [
                "Mingjie Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12866v1",
                "http://arxiv.org/pdf/2311.12866v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01258v1",
            "title": "Formal Methods for Autonomous Systems",
            "updated": "2023-11-02T14:18:43Z",
            "published": "2023-11-02T14:18:43Z",
            "summary": "Formal methods refer to rigorous, mathematical approaches to system\ndevelopment and have played a key role in establishing the correctness of\nsafety-critical systems. The main building blocks of formal methods are models\nand specifications, which are analogous to behaviors and requirements in system\ndesign and give us the means to verify and synthesize system behaviors with\nformal guarantees.\n  This monograph provides a survey of the current state of the art on\napplications of formal methods in the autonomous systems domain. We consider\ncorrect-by-construction synthesis under various formulations, including closed\nsystems, reactive, and probabilistic settings. Beyond synthesizing systems in\nknown environments, we address the concept of uncertainty and bound the\nbehavior of systems that employ learning using formal methods. Further, we\nexamine the synthesis of systems with monitoring, a mitigation technique for\nensuring that once a system deviates from expected behavior, it knows a way of\nreturning to normalcy. We also show how to overcome some limitations of formal\nmethods themselves with learning. We conclude with future directions for formal\nmethods in reinforcement learning, uncertainty, privacy, explainability of\nformal methods, and regulation and certification.",
            "author": [
                "Tichakorn Wongpiromsarn",
                "Mahsa Ghasemi",
                "Murat Cubuktepe",
                "Georgios Bakirtzis",
                "Steven Carr",
                "Mustafa O. Karabag",
                "Cyrus Neary",
                "Parham Gohari",
                "Ufuk Topcu"
            ],
            "link": [
                "http://dx.doi.org/10.1561/2600000029",
                "http://arxiv.org/abs/2311.01258v1",
                "http://arxiv.org/pdf/2311.01258v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01256v1",
            "title": "An energy-based comparative analysis of common approaches to text\n  classification in the Legal domain",
            "updated": "2023-11-02T14:16:48Z",
            "published": "2023-11-02T14:16:48Z",
            "summary": "Most Machine Learning research evaluates the best solutions in terms of\nperformance. However, in the race for the best performing model, many important\naspects are often overlooked when, on the contrary, they should be carefully\nconsidered. In fact, sometimes the gaps in performance between different\napproaches are neglectable, whereas factors such as production costs, energy\nconsumption, and carbon footprint must take into consideration. Large Language\nModels (LLMs) are extensively adopted to address NLP problems in academia and\nindustry. In this work, we present a detailed quantitative comparison of LLM\nand traditional approaches (e.g. SVM) on the LexGLUE benchmark, which takes\ninto account both performance (standard indices) and alternative metrics such\nas timing, power consumption and cost, in a word: the carbon-footprint. In our\nanalysis, we considered the prototyping phase (model selection by\ntraining-validation-test iterations) and in-production phases separately, since\nthey follow different implementation procedures and also require different\nresources. The results indicate that very often, the simplest algorithms\nachieve performance very close to that of large LLMs but with very low power\nconsumption and lower resource demands. The results obtained could suggest\ncompanies to include additional evaluations in the choice of Machine Learning\n(ML) solutions.",
            "author": [
                "Sinan Gultekin",
                "Achille Globo",
                "Andrea Zugarini",
                "Marco Ernandes",
                "Leonardo Rigutini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01256v1",
                "http://arxiv.org/pdf/2311.01256v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01254v1",
            "title": "Human participants in AI research: Ethics and transparency in practice",
            "updated": "2023-11-02T14:12:21Z",
            "published": "2023-11-02T14:12:21Z",
            "summary": "In recent years, research involving human participants has been critical to\nadvances in artificial intelligence (AI) and machine learning (ML),\nparticularly in the areas of conversational, human-compatible, and cooperative\nAI. For example, around 12% and 6% of publications at recent AAAI and NeurIPS\nconferences indicate the collection of original human data, respectively. Yet\nAI and ML researchers lack guidelines for ethical, transparent research\npractices with human participants. Fewer than one out of every four of these\nAAAI and NeurIPS papers provide details of ethical review, the collection of\ninformed consent, or participant compensation. This paper aims to bridge this\ngap by exploring normative similarities and differences between AI research and\nrelated fields that involve human participants. Though psychology,\nhuman-computer interaction, and other adjacent fields offer historic lessons\nand helpful insights, AI research raises several specific\nconcerns$\\unicode{x2014}$namely, participatory design, crowdsourced dataset\ndevelopment, and an expansive role of corporations$\\unicode{x2014}$that\nnecessitate a contextual ethics framework. To address these concerns, this\npaper outlines a set of guidelines for ethical and transparent practice with\nhuman participants in AI and ML research. These guidelines can be found in\nSection 4 on pp. 4$\\unicode{x2013}$7.",
            "author": [
                "Kevin R. McKee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01254v1",
                "http://arxiv.org/pdf/2311.01254v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01252v1",
            "title": "Sanitized Clustering against Confounding Bias",
            "updated": "2023-11-02T14:10:14Z",
            "published": "2023-11-02T14:10:14Z",
            "summary": "Real-world datasets inevitably contain biases that arise from different\nsources or conditions during data collection. Consequently, such inconsistency\nitself acts as a confounding factor that disturbs the cluster analysis.\nExisting methods eliminate the biases by projecting data onto the orthogonal\ncomplement of the subspace expanded by the confounding factor before\nclustering. Therein, the interested clustering factor and the confounding\nfactor are coarsely considered in the raw feature space, where the correlation\nbetween the data and the confounding factor is ideally assumed to be linear for\nconvenient solutions. These approaches are thus limited in scope as the data in\nreal applications is usually complex and non-linearly correlated with the\nconfounding factor. This paper presents a new clustering framework named\nSanitized Clustering Against confounding Bias (SCAB), which removes the\nconfounding factor in the semantic latent space of complex data through a\nnon-linear dependence measure. To be specific, we eliminate the bias\ninformation in the latent space by minimizing the mutual information between\nthe confounding factor and the latent representation delivered by Variational\nAuto-Encoder (VAE). Meanwhile, a clustering module is introduced to cluster\nover the purified latent representations. Extensive experiments on complex\ndatasets demonstrate that our SCAB achieves a significant gain in clustering\nperformance by removing the confounding bias. The code is available at\n\\url{https://github.com/EvaFlower/SCAB}.",
            "author": [
                "Yinghua Yao",
                "Yuangang Pan",
                "Jing Li",
                "Ivor W. Tsang",
                "Xin Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01252v1",
                "http://arxiv.org/pdf/2311.01252v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01248v1",
            "title": "Push it to the Demonstrated Limit: Multimodal Visuotactile Imitation\n  Learning with Force Matching",
            "updated": "2023-11-02T14:02:42Z",
            "published": "2023-11-02T14:02:42Z",
            "summary": "Optical tactile sensors have emerged as an effective means to acquire dense\ncontact information during robotic manipulation. A recently-introduced\n`see-through-your-skin' (STS) variant of this type of sensor has both visual\nand tactile modes, enabled by leveraging a semi-transparent surface and\ncontrollable lighting. In this work, we investigate the benefits of pairing\nvisuotactile sensing with imitation learning for contact-rich manipulation\ntasks. First, we use tactile force measurements and a novel algorithm during\nkinesthetic teaching to yield a force profile that better matches that of the\nhuman demonstrator. Second, we add visual/tactile STS mode switching as a\ncontrol policy output, simplifying the application of the sensor. Finally, we\nstudy multiple observation configurations to compare and contrast the value of\nvisual/tactile data (both with and without mode switching) with visual data\nfrom a wrist-mounted eye-in-hand camera. We perform an extensive series of\nexperiments on a real robotic manipulator with door-opening and closing tasks,\nincluding over 3,000 real test episodes. Our results highlight the importance\nof tactile sensing for imitation learning, both for data collection to allow\nforce matching, and for policy execution to allow accurate task feedback.",
            "author": [
                "Trevor Ablett",
                "Oliver Limoyo",
                "Adam Sigal",
                "Affan Jilani",
                "Jonathan Kelly",
                "Kaleem Siddiqi",
                "Francois Hogan",
                "Gregory Dudek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01248v1",
                "http://arxiv.org/pdf/2311.01248v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01241v1",
            "title": "Exploring Deep Learning Image Super-Resolution for Iris Recognition",
            "updated": "2023-11-02T13:57:48Z",
            "published": "2023-11-02T13:57:48Z",
            "summary": "In this work we test the ability of deep learning methods to provide an\nend-to-end mapping between low and high resolution images applying it to the\niris recognition problem. Here, we propose the use of two deep learning\nsingle-image super-resolution approaches: Stacked Auto-Encoders (SAE) and\nConvolutional Neural Networks (CNN) with the most possible lightweight\nstructure to achieve fast speed, preserve local information and reduce\nartifacts at the same time. We validate the methods with a database of 1.872\nnear-infrared iris images with quality assessment and recognition experiments\nshowing the superiority of deep learning approaches over the compared\nalgorithms.",
            "author": [
                "Eduardo Ribeiro",
                "Andreas Uhl",
                "Fernando Alonso-Fernandez",
                "Reuben A. Farrugia"
            ],
            "link": [
                "http://dx.doi.org/10.23919/EUSIPCO.2017.8081595",
                "http://arxiv.org/abs/2311.01241v1",
                "http://arxiv.org/pdf/2311.01241v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01240v2",
            "title": "FacadeNet: Conditional Facade Synthesis via Selective Editing",
            "updated": "2023-11-03T11:08:03Z",
            "published": "2023-11-02T13:57:43Z",
            "summary": "We introduce FacadeNet, a deep learning approach for synthesizing building\nfacade images from diverse viewpoints. Our method employs a conditional GAN,\ntaking a single view of a facade along with the desired viewpoint information\nand generates an image of the facade from the distinct viewpoint. To precisely\nmodify view-dependent elements like windows and doors while preserving the\nstructure of view-independent components such as walls, we introduce a\nselective editing module. This module leverages image embeddings extracted from\na pre-trained vision transformer. Our experiments demonstrated state-of-the-art\nperformance on building facade generation, surpassing alternative methods.",
            "author": [
                "Yiangos Georgiou",
                "Marios Loizou",
                "Tom Kelly",
                "Melinos Averkiou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01240v2",
                "http://arxiv.org/pdf/2311.01240v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02108v1",
            "title": "A Virtual Reality Training System for Automotive Engines Assembly and\n  Disassembly",
            "updated": "2023-11-02T13:37:46Z",
            "published": "2023-11-02T13:37:46Z",
            "summary": "Automotive engine assembly and disassembly are common and crucial programs in\nthe automotive industry. Traditional education trains students to learn\nautomotive engine assembly and disassembly in lecture courses and then to\noperate with physical engines, which are generally low effectiveness and high\ncost. In this work, we developed a multi-layer structured Virtual Reality (VR)\nsystem to provide students with training in automotive engine (Buick Verano)\nassembly and disassembly. We designed the VR training system with The VR\ntraining system is designed to have several major features, including\nreplaceable engine parts and reusable tools, friendly user interfaces and\nguidance, and bottom-up designed multi-layer architecture, which can be\nextended to various engine models. The VR system is evaluated with controlled\nexperiments of two groups of students. The results demonstrate that our VR\ntraining system provides remarkable usability in terms of effectiveness and\nefficiency. Currently, our VR system has been demonstrated and employed in the\ncourses of Chinese colleges to train students in automotive engine assembly and\ndisassembly. A free-to-use executable file (Microsoft Windows) and open-source\ncode are available at https://github.com/LadissonLai/SUSTech_VREngine for\nfacilitating the development of VR systems in the automotive industry. Finally,\na video describing the operations in our VR training system is available at\nhttps://www.youtube.com/watch?v=yZe4YTwwAC4",
            "author": [
                "Gongjin Lan",
                "Qiangqiang Lai",
                "Bing Bai",
                "Zirui Zhao",
                "Qi Hao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02108v1",
                "http://arxiv.org/pdf/2311.02108v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01230v1",
            "title": "Multi-Operational Mathematical Derivations in Latent Space",
            "updated": "2023-11-02T13:33:07Z",
            "published": "2023-11-02T13:33:07Z",
            "summary": "This paper investigates the possibility of approximating multiple\nmathematical operations in latent space for expression derivation. To this end,\nwe introduce different multi-operational representation paradigms, modelling\nmathematical operations as explicit geometric transformations. By leveraging a\nsymbolic engine, we construct a large-scale dataset comprising 1.7M derivation\nsteps stemming from 61K premises and 6 operators, analysing the properties of\neach paradigm when instantiated with state-of-the-art neural encoders.\nSpecifically, we investigate how different encoding mechanisms can approximate\nequational reasoning in latent space, exploring the trade-off between learning\ndifferent operators and specialising within single operations, as well as the\nability to support multi-step derivations and out-of-distribution\ngeneralisation. Our empirical analysis reveals that the multi-operational\nparadigm is crucial for disentangling different operators, while discriminating\nthe conclusions for a single operation is achievable in the original expression\nencoder. Moreover, we show that architectural choices can heavily affect the\ntraining dynamics, structural organisation, and generalisation of the latent\nspace, resulting in significant variations across paradigms and classes of\nencoders.",
            "author": [
                "Marco Valentino",
                "Jordan Meadows",
                "Lan Zhang",
                "Andr\u00e9 Freitas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01230v1",
                "http://arxiv.org/pdf/2311.01230v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01229v1",
            "title": "Theoretical Analysis of Impact of Delayed Updates on Decentralized\n  Federated Learning",
            "updated": "2023-11-02T13:29:23Z",
            "published": "2023-11-02T13:29:23Z",
            "summary": "Decentralized Federated learning is a distributed edge intelligence framework\nby exchanging parameter updates instead of training data among participators,\nin order to retrain or fine-tune deep learning models for mobile intelligent\napplications. Considering the various topologies of edge networks in mobile\ninternet, the impact of transmission delay of updates during model training is\nnon-negligible for data-intensive intelligent applications on mobile devices,\ne.g., intelligent medical services, automated driving vehicles, etc.. To\naddress this problem, we analyze the impact of delayed updates for\ndecentralized federated learning, and provide a theoretical bound for these\nupdates to achieve model convergence. Within the theoretical bound of updating\nperiod, the latest versions for the delayed updates are reused to continue\naggregation, in case the model parameters from a specific neighbor are not\ncollected or updated in time.",
            "author": [
                "Yong Zeng",
                "Siyuan Liu",
                "Zhiwei Xu",
                "Jie Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01229v1",
                "http://arxiv.org/pdf/2311.01229v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01227v1",
            "title": "Robust Feature Learning and Global Variance-Driven Classifier Alignment\n  for Long-Tail Class Incremental Learning",
            "updated": "2023-11-02T13:28:53Z",
            "published": "2023-11-02T13:28:53Z",
            "summary": "This paper introduces a two-stage framework designed to enhance long-tail\nclass incremental learning, enabling the model to progressively learn new\nclasses, while mitigating catastrophic forgetting in the context of long-tailed\ndata distributions. Addressing the challenge posed by the under-representation\nof tail classes in long-tail class incremental learning, our approach achieves\nclassifier alignment by leveraging global variance as an informative measure\nand class prototypes in the second stage. This process effectively captures\nclass properties and eliminates the need for data balancing or additional layer\ntuning. Alongside traditional class incremental learning losses in the first\nstage, the proposed approach incorporates mixup classes to learn robust feature\nrepresentations, ensuring smoother boundaries. The proposed framework can\nseamlessly integrate as a module with any class incremental learning method to\neffectively handle long-tail class incremental learning scenarios. Extensive\nexperimentation on the CIFAR-100 and ImageNet-Subset datasets validates the\napproach's efficacy, showcasing its superiority over state-of-the-art\ntechniques across various long-tail CIL settings.",
            "author": [
                "Jayateja Kalla",
                "Soma Biswas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01227v1",
                "http://arxiv.org/pdf/2311.01227v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01224v1",
            "title": "EISim: A Platform for Simulating Intelligent Edge Orchestration\n  Solutions",
            "updated": "2023-11-02T13:24:04Z",
            "published": "2023-11-02T13:24:04Z",
            "summary": "To support the stringent requirements of the future intelligent and\ninteractive applications, intelligence needs to become an essential part of the\nresource management in the edge environment. Developing intelligent\norchestration solutions is a challenging and arduous task, where the evaluation\nand comparison of the proposed solution is a focal point. Simulation is\ncommonly used to evaluate and compare proposed solutions. However, the\ncurrently existing, openly available simulators are lacking in terms of\nsupporting the research on intelligent edge orchestration methods. To address\nthis need, this article presents a simulation platform called Edge Intelligence\nSimulator (EISim), the purpose of which is to facilitate the research on\nintelligent edge orchestration solutions. EISim is extended from an existing\nfog simulator called PureEdgeSim. In its current form, EISim supports\nsimulating deep reinforcement learning based solutions and different\norchestration control topologies in scenarios related to task offloading and\nresource pricing on edge. The platform also includes additional tools for\ncreating simulation environments, running simulations for agent training and\nevaluation, and plotting results.",
            "author": [
                "Henna Kokkonen",
                "Susanna Pirttikangas",
                "Lauri Lov\u00e9n"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01224v1",
                "http://arxiv.org/pdf/2311.01224v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01223v1",
            "title": "Diffusion Models for Reinforcement Learning: A Survey",
            "updated": "2023-11-02T13:23:39Z",
            "published": "2023-11-02T13:23:39Z",
            "summary": "Diffusion models have emerged as a prominent class of generative models,\nsurpassing previous methods regarding sample quality and training stability.\nRecent works have shown the advantages of diffusion models in improving\nreinforcement learning (RL) solutions, including as trajectory planners,\nexpressive policy classes, data synthesizers, etc. This survey aims to provide\nan overview of the advancements in this emerging field and hopes to inspire new\navenues of research. First, we examine several challenges encountered by\ncurrent RL algorithms. Then, we present a taxonomy of existing methods based on\nthe roles played by diffusion models in RL and explore how the existing\nchallenges are addressed. We further outline successful applications of\ndiffusion models in various RL-related tasks while discussing the limitations\nof current approaches. Finally, we conclude the survey and offer insights into\nfuture research directions, focusing on enhancing model performance and\napplying diffusion models to broader tasks. We are actively maintaining a\nGitHub repository for papers and other related resources in applying diffusion\nmodels in RL: https://github.com/apexrl/Diff4RLSurvey .",
            "author": [
                "Zhengbang Zhu",
                "Hanye Zhao",
                "Haoran He",
                "Yichao Zhong",
                "Shenyu Zhang",
                "Yong Yu",
                "Weinan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01223v1",
                "http://arxiv.org/pdf/2311.01223v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04919v1",
            "title": "The Impact of Preference Agreement in Reinforcement Learning from Human\n  Feedback: A Case Study in Summarization",
            "updated": "2023-11-02T13:21:23Z",
            "published": "2023-11-02T13:21:23Z",
            "summary": "Reinforcement Learning from Human Feedback (RLHF) can be used to capture\ncomplex and nuanced properties of text generation quality. As a result, the\ntask of text summarization has been identified as a good candidate for this\nprocess. In this paper, we explore how preference agreement impacts the\nefficacy of RLHF for summarization. We show that sampling human preferences to\ninclude a range of annotator agreement results in (1) higher accuracy reward\nmodels and (2) alters the characteristics of quality captured. We additionally\nshow improvements in downstream generation when using a reward model trained\nwith a range of preference agreements. Our contributions have implications for\nthe design of synthetic datasets as well as the importance of considering\nquality differentials in comparison-based data.",
            "author": [
                "Sian Gooding",
                "Hassan Mansoor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04919v1",
                "http://arxiv.org/pdf/2311.04919v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01217v1",
            "title": "The learning effects of subsidies to bundled goods: a semiparametric\n  approach",
            "updated": "2023-11-02T13:18:57Z",
            "published": "2023-11-02T13:18:57Z",
            "summary": "Can temporary subsidies to bundles induce long-run changes in demand due to\nlearning about the relative quality of one of its constituent goods? This paper\nprovides theoretical and experimental evidence on the role of this mechanism.\nTheoretically, we introduce a model where an agent learns about the quality of\nan innovation on an essential good through consumption. Our results show that\nthe contemporaneous effect of a one-off subsidy to a bundle that contains the\ninnovation may be decomposed into a direct price effect, and an indirect\nlearning motive, whereby an agent leverages the discount to increase the\ninformational bequest left to her future selves. We then assess the predictions\nof our theory in a randomised experiment in a ridesharing platform. The\nexperiment provided two-week discounts for car trips integrating with a train\nor metro station (a bundle). Given the heavy-tailed nature of our data, we\nfollow \\cite{Athey2023} and, motivated by our theory, propose a semiparametric\nmodel for treatment effects that enables the construction of more efficient\nestimators. We introduce a statistically efficient estimator for our model by\nrelying on L-moments, a robust alternative to standard moments. Our estimator\nimmediately yields a specification test for the semiparametric model; moreover,\nin our adopted parametrisation, it can be easily computed through generalized\nleast squares. Our empirical results indicate that a two-week 50\\% discount on\ncar trips integrating with train/metro leads to a contemporaneous increase in\nthe demand for integrated rides, and, consistent with our learning model,\npersistent changes in the mean and dispersion of nonintegrated rides. These\neffects persist for over four months after the discount. A simple calibration\nof our model shows that around 40\\% to 50\\% of the estimated contemporaneous\nincrease in integrated rides may be attributed to a learning motive.",
            "author": [
                "Luis Alvarez",
                "Ciro Biderman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01217v1",
                "http://arxiv.org/pdf/2311.01217v1"
            ],
            "primary_category": "econ.EM",
            "category": [
                "econ.EM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01214v1",
            "title": "High-Quality Animatable Dynamic Garment Reconstruction from Monocular\n  Videos",
            "updated": "2023-11-02T13:16:27Z",
            "published": "2023-11-02T13:16:27Z",
            "summary": "Much progress has been made in reconstructing garments from an image or a\nvideo. However, none of existing works meet the expectations of digitizing\nhigh-quality animatable dynamic garments that can be adjusted to various unseen\nposes. In this paper, we propose the first method to recover high-quality\nanimatable dynamic garments from monocular videos without depending on scanned\ndata. To generate reasonable deformations for various unseen poses, we propose\na learnable garment deformation network that formulates the garment\nreconstruction task as a pose-driven deformation problem. To alleviate the\nambiguity estimating 3D garments from monocular videos, we design a\nmulti-hypothesis deformation module that learns spatial representations of\nmultiple plausible deformations. Experimental results on several public\ndatasets demonstrate that our method can reconstruct high-quality dynamic\ngarments with coherent surface details, which can be easily animated under\nunseen poses. The code will be provided for research purposes.",
            "author": [
                "Xiongzheng Li",
                "Jinsong Zhang",
                "Yu-Kun Lai",
                "Jingyu Yang",
                "Kun Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01214v1",
                "http://arxiv.org/pdf/2311.01214v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16133v2",
            "title": "Effective Quantization for Diffusion Models on CPUs",
            "updated": "2023-11-29T08:24:57Z",
            "published": "2023-11-02T13:14:01Z",
            "summary": "Diffusion models have gained popularity for generating images from textual\ndescriptions. Nonetheless, the substantial need for computational resources\ncontinues to present a noteworthy challenge, contributing to time-consuming\nprocesses. Quantization, a technique employed to compress deep learning models\nfor enhanced efficiency, presents challenges when applied to diffusion models.\nThese models are notably more sensitive to quantization compared to other model\ntypes, potentially resulting in a degradation of image quality. In this paper,\nwe introduce a novel approach to quantize the diffusion models by leveraging\nboth quantization-aware training and distillation. Our results show the\nquantized models can maintain the high image quality while demonstrating the\ninference efficiency on CPUs. The code is publicly available at:\nhttps://github.com/intel/intel-extension-for-transformers.",
            "author": [
                "Hanwen Chang",
                "Haihao Shen",
                "Yiyang Cai",
                "Xinyu Ye",
                "Zhenzhong Xu",
                "Wenhua Cheng",
                "Kaokao Lv",
                "Weiwei Zhang",
                "Yintong Lu",
                "Heng Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16133v2",
                "http://arxiv.org/pdf/2311.16133v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01212v1",
            "title": "Multi-view Relation Learning for Cross-domain Few-shot Hyperspectral\n  Image Classification",
            "updated": "2023-11-02T13:06:03Z",
            "published": "2023-11-02T13:06:03Z",
            "summary": "Cross-domain few-shot hyperspectral image classification focuses on learning\nprior knowledge from a large number of labeled samples from source domain and\nthen transferring the knowledge to the tasks which contain only few labeled\nsamples in target domains. Following the metric-based manner, many current\nmethods first extract the features of the query and support samples, and then\ndirectly predict the classes of query samples according to their distance to\nthe support samples or prototypes. The relations between samples have not been\nfully explored and utilized. Different from current works, this paper proposes\nto learn sample relations from different views and take them into the model\nlearning process, to improve the cross-domain few-shot hyperspectral image\nclassification. Building on current DCFSL method which adopts a domain\ndiscriminator to deal with domain-level distribution difference, the proposed\nmethod applys contrastive learning to learn the class-level sample relations to\nobtain more discriminable sample features. In addition, it adopts a transformer\nbased cross-attention learning module to learn the set-level sample relations\nand acquire the attentions from query samples to support samples. Our\nexperimental results have demonstrated the contribution of the multi-view\nrelation learning mechanism for few-shot hyperspectral image classification\nwhen compared with the state of the art methods.",
            "author": [
                "Chun Liu",
                "Longwei Yang",
                "Zheng Li",
                "Wei Yang",
                "Zhigang Han",
                "Jianzhong Guo",
                "Junyong Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01212v1",
                "http://arxiv.org/pdf/2311.01212v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01206v1",
            "title": "How Does China's Household Portfolio Selection Vary with Financial\n  Inclusion?",
            "updated": "2023-11-02T13:00:08Z",
            "published": "2023-11-02T13:00:08Z",
            "summary": "Portfolio underdiversification is one of the most costly losses accumulated\nover a household's life cycle. We provide new evidence on the impact of\nfinancial inclusion services on households' portfolio choice and investment\nefficiency using 2015, 2017, and 2019 survey data for Chinese households. We\nhypothesize that higher financial inclusion penetration encourages households\nto participate in the financial market, leading to better portfolio\ndiversification and investment efficiency. The results of the baseline model\nare consistent with our proposed hypothesis that higher accessibility to\nfinancial inclusion encourages households to invest in risky assets and\nincreases investment efficiency. We further estimate a dynamic double machine\nlearning model to quantitatively investigate the non-linear causal effects and\ntrack the dynamic change of those effects over time. We observe that the\nmarginal effect increases over time, and those effects are more pronounced\namong low-asset, less-educated households and those located in non-rural areas,\nexcept for investment efficiency for high-asset households.",
            "author": [
                "Yong Bian",
                "Xiqian Wang",
                "Qin Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01206v1",
                "http://arxiv.org/pdf/2311.01206v1"
            ],
            "primary_category": "econ.GN",
            "category": [
                "econ.GN",
                "q-fin.EC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01205v1",
            "title": "Attacking Graph Neural Networks with Bit Flips: Weisfeiler and Lehman Go\n  Indifferent",
            "updated": "2023-11-02T12:59:32Z",
            "published": "2023-11-02T12:59:32Z",
            "summary": "Prior attacks on graph neural networks have mostly focused on graph poisoning\nand evasion, neglecting the network's weights and biases. Traditional\nweight-based fault injection attacks, such as bit flip attacks used for\nconvolutional neural networks, do not consider the unique properties of graph\nneural networks. We propose the Injectivity Bit Flip Attack, the first bit flip\nattack designed specifically for graph neural networks. Our attack targets the\nlearnable neighborhood aggregation functions in quantized message passing\nneural networks, degrading their ability to distinguish graph structures and\nlosing the expressivity of the Weisfeiler-Lehman test. Our findings suggest\nthat exploiting mathematical properties specific to certain graph neural\nnetwork architectures can significantly increase their vulnerability to bit\nflip attacks. Injectivity Bit Flip Attacks can degrade the maximal expressive\nGraph Isomorphism Networks trained on various graph property prediction\ndatasets to random output by flipping only a small fraction of the network's\nbits, demonstrating its higher destructive power compared to a bit flip attack\ntransferred from convolutional neural networks. Our attack is transparent and\nmotivated by theoretical insights which are confirmed by extensive empirical\nresults.",
            "author": [
                "Lorenz Kummer",
                "Samir Moustafa",
                "Nils N. Kriege",
                "Wilfried N. Gansterer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01205v1",
                "http://arxiv.org/pdf/2311.01205v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01202v1",
            "title": "Cross-Modal Information-Guided Network using Contrastive Learning for\n  Point Cloud Registration",
            "updated": "2023-11-02T12:56:47Z",
            "published": "2023-11-02T12:56:47Z",
            "summary": "The majority of point cloud registration methods currently rely on extracting\nfeatures from points. However, these methods are limited by their dependence on\ninformation obtained from a single modality of points, which can result in\ndeficiencies such as inadequate perception of global features and a lack of\ntexture information. Actually, humans can employ visual information learned\nfrom 2D images to comprehend the 3D world. Based on this fact, we present a\nnovel Cross-Modal Information-Guided Network (CMIGNet), which obtains global\nshape perception through cross-modal information to achieve precise and robust\npoint cloud registration. Specifically, we first incorporate the projected\nimages from the point clouds and fuse the cross-modal features using the\nattention mechanism. Furthermore, we employ two contrastive learning\nstrategies, namely overlapping contrastive learning and cross-modal contrastive\nlearning. The former focuses on features in overlapping regions, while the\nlatter emphasizes the correspondences between 2D and 3D features. Finally, we\npropose a mask prediction module to identify keypoints in the point clouds.\nExtensive experiments on several benchmark datasets demonstrate that our\nnetwork achieves superior registration performance.",
            "author": [
                "Yifan Xie",
                "Jihua Zhu",
                "Shiqi Li",
                "Pengcheng Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01202v1",
                "http://arxiv.org/pdf/2311.01202v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01201v1",
            "title": "Federated Learning on Edge Sensing Devices: A Review",
            "updated": "2023-11-02T12:55:26Z",
            "published": "2023-11-02T12:55:26Z",
            "summary": "The ability to monitor ambient characteristics, interact with them, and\nderive information about the surroundings has been made possible by the rapid\nproliferation of edge sensing devices like IoT, mobile, and wearable devices\nand their measuring capabilities with integrated sensors. Even though these\ndevices are small and have less capacity for data storage and processing, they\nproduce vast amounts of data. Some example application areas where sensor data\nis collected and processed include healthcare, environmental (including air\nquality and pollution levels), automotive, industrial, aerospace, and\nagricultural applications. These enormous volumes of sensing data collected\nfrom the edge devices are analyzed using a variety of Machine Learning (ML) and\nDeep Learning (DL) approaches. However, analyzing them on the cloud or a server\npresents challenges related to privacy, hardware, and connectivity limitations.\nFederated Learning (FL) is emerging as a solution to these problems while\npreserving privacy by jointly training a model without sharing raw data. In\nthis paper, we review the FL strategies from the perspective of edge sensing\ndevices to get over the limitations of conventional machine learning\ntechniques. We focus on the key FL principles, software frameworks, and\ntestbeds. We also explore the current sensor technologies, properties of the\nsensing devices and sensing applications where FL is utilized. We conclude with\na discussion on open issues and future research directions on FL for further\nstudies",
            "author": [
                "Berrenur Saylam",
                "\u00d6zlem Durmaz \u0130ncel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01201v1",
                "http://arxiv.org/pdf/2311.01201v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01200v1",
            "title": "A Study of Continual Learning Under Language Shift",
            "updated": "2023-11-02T12:54:50Z",
            "published": "2023-11-02T12:54:50Z",
            "summary": "The recent increase in data and model scale for language model pre-training\nhas led to huge training costs. In scenarios where new data become available\nover time, updating a model instead of fully retraining it would therefore\nprovide significant gains. In this paper, we study the benefits and downsides\nof updating a language model when new data comes from new languages - the case\nof continual learning under language shift. Starting from a monolingual English\nlanguage model, we incrementally add data from Norwegian and Icelandic to\ninvestigate how forward and backward transfer effects depend on the\npre-training order and characteristics of languages, for different model sizes\nand learning rate schedulers. Our results show that, while forward transfer is\nlargely positive and independent of language order, backward transfer can be\neither positive or negative depending on the order and characteristics of new\nlanguages. To explain these patterns we explore several language similarity\nmetrics and find that syntactic similarity appears to have the best correlation\nwith our results.",
            "author": [
                "Evangelia Gogoulou",
                "Timoth\u00e9e Lesort",
                "Magnus Boman",
                "Joakim Nivre"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01200v1",
                "http://arxiv.org/pdf/2311.01200v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01198v1",
            "title": "Gaussian Processes on Cellular Complexes",
            "updated": "2023-11-02T12:49:14Z",
            "published": "2023-11-02T12:49:14Z",
            "summary": "In recent years, there has been considerable interest in developing machine\nlearning models on graphs in order to account for topological inductive biases.\nIn particular, recent attention was given to Gaussian processes on such\nstructures since they can additionally account for uncertainty. However, graphs\nare limited to modelling relations between two vertices. In this paper, we go\nbeyond this dyadic setting and consider polyadic relations that include\ninteractions between vertices, edges and one of their generalisations, known as\ncells. Specifically, we propose Gaussian processes on cellular complexes, a\ngeneralisation of graphs that captures interactions between these higher-order\ncells. One of our key contributions is the derivation of two novel kernels, one\nthat generalises the graph Mat\\'ern kernel and one that additionally mixes\ninformation of different cell types.",
            "author": [
                "Mathieu Alain",
                "So Takao",
                "Brooks Paige",
                "Marc Peter Deisenroth"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01198v1",
                "http://arxiv.org/pdf/2311.01198v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01196v1",
            "title": "Combating Bilateral Edge Noise for Robust Link Prediction",
            "updated": "2023-11-02T12:47:49Z",
            "published": "2023-11-02T12:47:49Z",
            "summary": "Although link prediction on graphs has achieved great success with the\ndevelopment of graph neural networks (GNNs), the potential robustness under the\nedge noise is still less investigated. To close this gap, we first conduct an\nempirical study to disclose that the edge noise bilaterally perturbs both input\ntopology and target label, yielding severe performance degradation and\nrepresentation collapse. To address this dilemma, we propose an\ninformation-theory-guided principle, Robust Graph Information Bottleneck\n(RGIB), to extract reliable supervision signals and avoid representation\ncollapse. Different from the basic information bottleneck, RGIB further\ndecouples and balances the mutual dependence among graph topology, target\nlabels, and representation, building new learning objectives for robust\nrepresentation against the bilateral noise. Two instantiations, RGIB-SSL and\nRGIB-REP, are explored to leverage the merits of different methodologies, i.e.,\nself-supervised learning and data reparameterization, for implicit and explicit\ndata denoising, respectively. Extensive experiments on six datasets and three\nGNNs with diverse noisy scenarios verify the effectiveness of our RGIB\ninstantiations. The code is publicly available at:\nhttps://github.com/tmlr-group/RGIB.",
            "author": [
                "Zhanke Zhou",
                "Jiangchao Yao",
                "Jiaxu Liu",
                "Xiawei Guo",
                "Quanming Yao",
                "Li He",
                "Liang Wang",
                "Bo Zheng",
                "Bo Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01196v1",
                "http://arxiv.org/pdf/2311.01196v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01195v1",
            "title": "Batch Bayesian Optimization for Replicable Experimental Design",
            "updated": "2023-11-02T12:46:03Z",
            "published": "2023-11-02T12:46:03Z",
            "summary": "Many real-world experimental design problems (a) evaluate multiple\nexperimental conditions in parallel and (b) replicate each condition multiple\ntimes due to large and heteroscedastic observation noise. Given a fixed total\nbudget, this naturally induces a trade-off between evaluating more unique\nconditions while replicating each of them fewer times vs. evaluating fewer\nunique conditions and replicating each more times. Moreover, in these problems,\npractitioners may be risk-averse and hence prefer an input with both good\naverage performance and small variability. To tackle both challenges, we\npropose the Batch Thompson Sampling for Replicable Experimental Design\n(BTS-RED) framework, which encompasses three algorithms. Our BTS-RED-Known and\nBTS-RED-Unknown algorithms, for, respectively, known and unknown noise\nvariance, choose the number of replications adaptively rather than\ndeterministically such that an input with a larger noise variance is replicated\nmore times. As a result, despite the noise heteroscedasticity, both algorithms\nenjoy a theoretical guarantee and are asymptotically no-regret. Our\nMean-Var-BTS-RED algorithm aims at risk-averse optimization and is also\nasymptotically no-regret. We also show the effectiveness of our algorithms in\ntwo practical real-world applications: precision agriculture and AutoML.",
            "author": [
                "Zhongxiang Dai",
                "Quoc Phong Nguyen",
                "Sebastian Shenghong Tay",
                "Daisuke Urano",
                "Richalynn Leong",
                "Bryan Kian Hsiang Low",
                "Patrick Jaillet"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01195v1",
                "http://arxiv.org/pdf/2311.01195v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01192v1",
            "title": "Semantic Scene Graph Generation Based on an Edge Dual Scene Graph and\n  Message Passing Neural Network",
            "updated": "2023-11-02T12:36:52Z",
            "published": "2023-11-02T12:36:52Z",
            "summary": "Along with generative AI, interest in scene graph generation (SGG), which\ncomprehensively captures the relationships and interactions between objects in\nan image and creates a structured graph-based representation, has significantly\nincreased in recent years. However, relying on object-centric and dichotomous\nrelationships, existing SGG methods have a limited ability to accurately\npredict detailed relationships. To solve these problems, a new approach to the\nmodeling multiobject relationships, called edge dual scene graph generation\n(EdgeSGG), is proposed herein. EdgeSGG is based on a edge dual scene graph and\nDual Message Passing Neural Network (DualMPNN), which can capture rich\ncontextual interactions between unconstrained objects. To facilitate the\nlearning of edge dual scene graphs with a symmetric graph structure, the\nproposed DualMPNN learns both object- and relation-centric features for more\naccurately predicting relation-aware contexts and allows fine-grained\nrelational updates between objects. A comparative experiment with\nstate-of-the-art (SoTA) methods was conducted using two public datasets for SGG\noperations and six metrics for three subtasks. Compared with SoTA approaches,\nthe proposed model exhibited substantial performance improvements across all\nSGG subtasks. Furthermore, experiment on long-tail distributions revealed that\nincorporating the relationships between objects effectively mitigates existing\nlong-tail problems.",
            "author": [
                "Hyeongjin Kim",
                "Sangwon Kim",
                "Jong Taek Lee",
                "Byoung Chul Ko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01192v1",
                "http://arxiv.org/pdf/2311.01192v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01191v1",
            "title": "VIGraph: Self-supervised Learning for Class-Imbalanced Node\n  Classification",
            "updated": "2023-11-02T12:36:19Z",
            "published": "2023-11-02T12:36:19Z",
            "summary": "Class imbalance in graph data poses significant challenges for node\nclassification. Existing methods, represented by SMOTE-based approaches,\npartially alleviate this issue but still exhibit limitations during imbalanced\nscenario construction. Self-supervised learning (SSL) offers a promising\nsolution by synthesizing minority nodes from the data itself, yet its potential\nremains unexplored. In this paper, we analyze the limitations of SMOTE-based\napproaches and introduce VIGraph, a novel SSL model based on the\nself-supervised Variational Graph Auto-Encoder (VGAE) that leverages\nVariational Inference (VI) to generate minority nodes. Specifically, VIGraph\nstrictly adheres to the concept of imbalance when constructing imbalanced\ngraphs and utilizes the generative VGAE to generate minority nodes. Moreover,\nVIGraph introduces a novel Siamese contrastive strategy at the decoding phase\nto improve the overall quality of generated nodes. VIGraph can generate\nhigh-quality nodes without reintegrating them into the original graph,\neliminating the \"Generating, Reintegrating, and Retraining\" process found in\nSMOTE-based methods. Experiments on multiple real-world datasets demonstrate\nthat VIGraph achieves promising results for class-imbalanced node\nclassification tasks.",
            "author": [
                "Yulan Hu",
                "Sheng Ouyang",
                "Zhirui Yang",
                "Yong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01191v1",
                "http://arxiv.org/pdf/2311.01191v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01188v1",
            "title": "Terrain-Informed Self-Supervised Learning: Enhancing Building Footprint\n  Extraction from LiDAR Data with Limited Annotations",
            "updated": "2023-11-02T12:34:23Z",
            "published": "2023-11-02T12:34:23Z",
            "summary": "Estimating building footprint maps from geospatial data is of paramount\nimportance in urban planning, development, disaster management, and various\nother applications. Deep learning methodologies have gained prominence in\nbuilding segmentation maps, offering the promise of precise footprint\nextraction without extensive post-processing. However, these methods face\nchallenges in generalization and label efficiency, particularly in remote\nsensing, where obtaining accurate labels can be both expensive and\ntime-consuming. To address these challenges, we propose terrain-aware\nself-supervised learning, tailored to remote sensing, using digital elevation\nmodels from LiDAR data. We propose to learn a model to differentiate between\nbare Earth and superimposed structures enabling the network to implicitly learn\ndomain-relevant features without the need for extensive pixel-level\nannotations. We test the effectiveness of our approach by evaluating building\nsegmentation performance on test datasets with varying label fractions.\nRemarkably, with only 1% of the labels (equivalent to 25 labeled examples), our\nmethod improves over ImageNet pre-training, showing the advantage of leveraging\nunlabeled data for feature extraction in the domain of remote sensing. The\nperformance improvement is more pronounced in few-shot scenarios and gradually\ncloses the gap with ImageNet pre-training as the label fraction increases. We\ntest on a dataset characterized by substantial distribution shifts and labeling\nerrors to demonstrate the generalizability of our approach. When compared to\nother baselines, including ImageNet pretraining and more complex architectures,\nour approach consistently performs better, demonstrating the efficiency and\neffectiveness of self-supervised terrain-aware feature learning.",
            "author": [
                "Anuja Vats",
                "David V\u00f6lgyes",
                "Martijn Vermeer",
                "Marius Pedersen",
                "Kiran Raja",
                "Daniele S. M. Fantin",
                "Jacob Alexander Hay"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01188v1",
                "http://arxiv.org/pdf/2311.01188v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01186v1",
            "title": "Decentralized Federated Learning on the Edge over Wireless Mesh Networks",
            "updated": "2023-11-02T12:33:58Z",
            "published": "2023-11-02T12:33:58Z",
            "summary": "The rapid growth of Internet of Things (IoT) devices has generated vast\namounts of data, leading to the emergence of federated learning as a novel\ndistributed machine learning paradigm. Federated learning enables model\ntraining at the edge, leveraging the processing capacity of edge devices while\npreserving privacy and mitigating data transfer bottlenecks. However, the\nconventional centralized federated learning architecture suffers from a single\npoint of failure and susceptibility to malicious attacks. In this study, we\ndelve into an alternative approach called decentralized federated learning\n(DFL) conducted over a wireless mesh network as the communication backbone. We\nperform a comprehensive network performance analysis using stochastic geometry\ntheory and physical interference models, offering fresh insights into the\nconvergence analysis of DFL. Additionally, we conduct system simulations to\nassess the proposed decentralized architecture under various network parameters\nand different aggregator methods such as FedAvg, Krum and Median methods. Our\nmodel is trained on the widely recognized EMNIST dataset for benchmarking\nhandwritten digit classification. To minimize the model's size at the edge and\nreduce communication overhead, we employ a cutting-edge compression technique\nbased on genetic algorithms. Our simulation results reveal that the compressed\ndecentralized architecture achieves performance comparable to the baseline\ncentralized architecture and traditional DFL in terms of accuracy and average\nloss for our classification task. Moreover, it significantly reduces the size\nof shared models over the wireless channel by compressing participants' local\nmodel sizes to nearly half of their original size compared to the baselines,\neffectively reducing complexity and communication overhead.",
            "author": [
                "Abdelaziz Salama",
                "Achilleas Stergioulis",
                "Syed Ali Zaidi",
                "Des McLernon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01186v1",
                "http://arxiv.org/pdf/2311.01186v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01166v1",
            "title": "Generative Input: Towards Next-Generation Input Methods Paradigm",
            "updated": "2023-11-02T12:01:29Z",
            "published": "2023-11-02T12:01:29Z",
            "summary": "Since the release of ChatGPT, generative models have achieved tremendous\nsuccess and become the de facto approach for various NLP tasks. However, its\napplication in the field of input methods remains under-explored. Many neural\nnetwork approaches have been applied to the construction of Chinese input\nmethod engines(IMEs).Previous research often assumed that the input pinyin was\ncorrect and focused on Pinyin-to-character(P2C) task, which significantly falls\nshort of meeting users' demands. Moreover, previous research could not leverage\nuser feedback to optimize the model and provide personalized results. In this\nstudy, we propose a novel Generative Input paradigm named GeneInput. It uses\nprompts to handle all input scenarios and other intelligent auxiliary input\nfunctions, optimizing the model with user feedback to deliver personalized\nresults. The results demonstrate that we have achieved state-of-the-art\nperformance for the first time in the Full-mode Key-sequence to\nCharacters(FK2C) task. We propose a novel reward model training method that\neliminates the need for additional manual annotations and the performance\nsurpasses GPT-4 in tasks involving intelligent association and conversational\nassistance. Compared to traditional paradigms, GeneInput not only demonstrates\nsuperior performance but also exhibits enhanced robustness, scalability, and\nonline learning capabilities.",
            "author": [
                "Keyu Ding",
                "Yongcan Wang",
                "Zihang Xu",
                "Zhenzhen Jia",
                "Shijin Wang",
                "Cong Liu",
                "Enhong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01166v1",
                "http://arxiv.org/pdf/2311.01166v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02107v1",
            "title": "Generative Artificial Intelligence in Healthcare: Ethical Considerations\n  and Assessment Checklist",
            "updated": "2023-11-02T11:55:07Z",
            "published": "2023-11-02T11:55:07Z",
            "summary": "The widespread use of ChatGPT and other emerging technology powered by\ngenerative artificial intelligence (AI) has drawn much attention to potential\nethical issues, especially in high-stakes applications such as healthcare.\nHowever, less clear is how to resolve such issues beyond following guidelines\nand regulations that are still under discussion and development. On the other\nhand, other types of generative AI have been used to synthesize images and\nother types of data for research and practical purposes, which have resolved\nsome ethical issues and exposed other ethical issues, but such technology is\nless often the focus of ongoing ethical discussions. Here we highlight gaps in\ncurrent ethical discussions of generative AI via a systematic scoping review of\nrelevant existing research in healthcare, and reduce the gaps by proposing an\nethics checklist for comprehensive assessment and transparent documentation of\nethical discussions in generative AI development. While the checklist can be\nreadily integrated into the current peer review and publication system to\nenhance generative AI research, it may also be used in broader settings to\ndisclose ethics-related considerations in generative AI-powered products (or\nreal-life applications of such products) to help users establish reasonable\ntrust in their capabilities.",
            "author": [
                "Yilin Ning",
                "Salinelat Teixayavong",
                "Yuqing Shang",
                "Julian Savulescu",
                "Vaishaanth Nagaraj",
                "Di Miao",
                "Mayli Mertens",
                "Daniel Shu Wei Ting",
                "Jasmine Chiat Ling Ong",
                "Mingxuan Liu",
                "Jiuwen Cao",
                "Michael Dunn",
                "Roger Vaughan",
                "Marcus Eng Hock Ong",
                "Joseph Jao-Yiu Sung",
                "Eric J Topol",
                "Nan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02107v1",
                "http://arxiv.org/pdf/2311.02107v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01163v1",
            "title": "PDRs4All VI: Probing the Photochemical Evolution of PAHs in the Orion\n  Bar Using Machine Learning Techniques",
            "updated": "2023-11-02T11:49:45Z",
            "published": "2023-11-02T11:49:45Z",
            "summary": "[Abridged] JWST observations of the Orion Bar have shown the incredible\nrichness of PAH bands and their variation on small scales. We aim to probe the\nphotochemical evolution of PAHs across the key zones of the photodissociation\nregion (PDR) that is the Orion Bar using unsupervised machine learning. We use\nNIRSpec and MIRI IFU data from the JWST ERS Program PDRs4All. We lever\nbisecting k-means clustering to generate detailed spatial maps of the spectral\nvariability in several wavelength regions. We discuss the variations in the\ncluster profiles and connect them to the local physical conditions. We\ninterpret these variations with respect to the key zones: the HII region, the\natomic PDR zone, and the three dissociation fronts. The PAH emission exhibits\nspectral variation that depends strongly on spatial position in the PDR. We\nfind the 8.6um band to behave differently than all other bands which vary\nsystematically with one another. We find uniform variation in the 3.4-3.6um\nbands and 3.4/3.3 intensity ratio. We attribute the carrier of the 3.4-3.6um\nbands to a single side group attached to very similarly sized PAHs. Cluster\nprofiles reveal a transition between characteristic profiles classes of the\n11.2um feature from the atomic to the molecular PDR zone. We find the carriers\nof each of the profile classes to be independent, and reason the latter to be\nPAH clusters existing solely deep in the molecular PDR. Clustering also reveals\na connection between the 11.2 and 6.2um bands; and that clusters generated from\nvariation in the 10.9-11.63um region can be used to recover those in the\n5.95-6.6um region. Clustering is a powerful tool for characterizing PAH\nvariability on both spatial and spectral scales. For individual bands as well\nas global spectral behaviours, we find UV-processing to be the most important\ndriver of the evolution of PAHs and their spectral signatures in the Orion Bar.",
            "author": [
                "S. Pasquini",
                "E. Peeters",
                "B. Schefter",
                "B. Khan",
                "A. Sidhu",
                "R. Chown",
                "J. Cami",
                "A. Tielens",
                "F. Alarcon",
                "A. Canin",
                "I. Schroetter",
                "B. Trahin",
                "D. Van De Putte",
                "C. Boersma",
                "E. Dartois",
                "T. Onaka",
                "A. Candian",
                "P. Hartigan",
                "T. S. -Y. Lai",
                "G. Rouille",
                "D. A. Sales",
                "Y. Zhang",
                "E. Habart",
                "O. Berne"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01163v1",
                "http://arxiv.org/pdf/2311.01163v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01159v1",
            "title": "Search for Periodic Time Variations of the Solar $^8$B Neutrino Flux\n  Between 1996 and 2018 in Super-Kamiokande",
            "updated": "2023-11-02T11:41:51Z",
            "published": "2023-11-02T11:41:51Z",
            "summary": "We report a search for time variations of the solar $^8$B neutrino flux using\n5,804 live days of Super-Kamiokande data collected between May 31, 1996, and\nMay 30, 2018. Super-Kamiokande measured the precise time of each solar neutrino\ninteraction over 22 calendar years to search for solar neutrino flux\nmodulations with unprecedented precision. Periodic modulations are searched for\nin a data set comprised of five-day interval solar neutrino flux measurements\nwith a maximum likelihood method. We also applied the Lomb-Scargle method to\nthis data set to compare it with previous reports. The only significant\nmodulation found is due to the elliptic orbit of the Earth around the Sun. The\nobserved modulation is consistent with astronomical data: we measured an\neccentricity of (1.53$\\pm$0.35)\\,\\%, and a perihelion shift is\n($-$1.5$\\pm$13.5)\\,days.",
            "author": [
                "K. Abe",
                "C. Bronner",
                "Y. Hayato",
                "K. Hiraide",
                "K. Hosokawa",
                "K. Ieki",
                "M. Ikeda",
                "J. Kameda",
                "Y. Kanemura",
                "R. Kaneshima",
                "Y. Kashiwagi",
                "Y. Kataoka",
                "S. Miki",
                "S. Mine",
                "M. Miura",
                "S. Moriyama",
                "Y. Nakano",
                "M. Nakahata",
                "S. Nakayama",
                "Y. Noguchi",
                "K. Sato",
                "H. Sekiya",
                "H. Shiba",
                "K. Shimizu",
                "M. Shiozawa",
                "Y. Sonoda",
                "Y. Suzuki",
                "A. Takeda",
                "Y. Takemoto",
                "H. Tanaka",
                "T. Yano",
                "S. Han",
                "T. Kajita",
                "K. Okumura",
                "T. Tashiro",
                "T. Tomiya",
                "X. Wang",
                "S. Yoshida",
                "P. Fernandez",
                "L. Labarga",
                "N. Ospina",
                "B. Zaldivar",
                "B. W. Pointon",
                "E. Kearns",
                "J. L. Raaf",
                "L. Wan",
                "T. Wester",
                "J. Bian",
                "N. J. Griskevich",
                "S. Locke",
                "M. B. Smy",
                "H. W. Sobel",
                "V. Takhistov",
                "A. Yankelevich",
                "J. Hill",
                "S. H. Lee",
                "D. H. Moon",
                "R. G. Park",
                "M. C. Jang",
                "B. Bodur",
                "K. Scholberg",
                "C. W. Walter",
                "A. Beauchene",
                "O. Drapier",
                "A. Giampaolo",
                "Th. A. Mueller",
                "A. D. Santos",
                "P. Paganini",
                "B. Quilain",
                "T. Nakamura",
                "J. S. Jang",
                "L. N. Machado",
                "J. G. Learned",
                "K. Choi",
                "N. Iovine",
                "S. Cao",
                "L. H. V. Anthony",
                "D. Martin",
                "N. W. Prouse",
                "M. Scott",
                "A. A. Sztuc",
                "Y. Uchida",
                "V. Berardi",
                "M. G. Catanesi",
                "E. Radicioni",
                "N. F. Calabria",
                "A. Langella",
                "G. De Rosa",
                "G. Collazuol",
                "F. Iacob",
                "M. Mattiazzi",
                "L. Ludovici",
                "M. Gonin",
                "G. Pronost",
                "C. Fujisawa",
                "Y. Maekawa",
                "Y. Nishimura",
                "R. Okazaki",
                "R. Akutsu",
                "M. Friend",
                "T. Hasegawa",
                "T. Ishida",
                "T. Kobayashi",
                "M. Jakkapu",
                "T. Matsubara",
                "T. Nakadaira",
                "K. Nakamura",
                "Y. Oyama",
                "K. Sakashita",
                "T. Sekiguchi",
                "T. Tsukamoto",
                "N. Bhuiyan",
                "G. T. Burton",
                "F. Di Lodovico",
                "J. Gao",
                "A. Goldsack",
                "T. Katori",
                "J. Migenda",
                "Z. Xie",
                "R. M. Ramsden",
                "S. Zsoldos",
                "A. T. Suzuki",
                "Y. Takagi",
                "H. Zhong",
                "Y. Takeuchi",
                "J. Feng",
                "L. Feng",
                "J. R. Hu",
                "Z. Hu",
                "T. Kikawa",
                "M. Mori",
                "M. Kawaue",
                "T. Nakaya",
                "R. A. Wendell",
                "K. Yasutome",
                "S. J. Jenkins",
                "N. McCauley",
                "P. Mehta",
                "A. Tarant",
                "Y. Fukuda",
                "Y. Itow",
                "H. Menjo",
                "K. Ninomiya",
                "Y. Yoshioka",
                "J. Lagoda",
                "S. M. Lakshmi",
                "M. Mandal",
                "P. Mijakowski",
                "Y. S. Prabhu",
                "J. Zalipska",
                "M. Jia",
                "J. Jiang",
                "C. K. Jung",
                "M. J. Wilking",
                "C. Yanagisawa",
                "W. Shi",
                "M. Harada",
                "Y. Hino",
                "H. Ishino",
                "Y. Koshio",
                "F. Nakanishi",
                "S. Sakai",
                "T. Tada",
                "T. Tano",
                "T. Ishizuka",
                "G. Barr",
                "D. Barrow",
                "L. Cook",
                "S. Samani",
                "D. Wark",
                "A. Holin",
                "F. Nova",
                "B. S. Yang",
                "J. Y. Yang",
                "J. Yoo",
                "S. Jung",
                "J. E. P. Fannon",
                "L. Kneale",
                "M. Malek",
                "J. M. McElwee",
                "M. D. Thiesse",
                "L. F. Thompson",
                "S. T. Wilson",
                "H. Okazawa",
                "S. B. Kim",
                "E. Kwon",
                "J. W. Seo",
                "I. Yu",
                "A. K. Ichikawa",
                "K. D. Nakamura",
                "S. Tairafune",
                "K. Nishijima",
                "A. Eguchi",
                "K. Nakagiri",
                "Y. Nakajima",
                "S. Shima",
                "N. Taniuchi",
                "E. Watanabe",
                "M. Yokoyama",
                "P. de Perio",
                "S. Fujita",
                "K. Martens",
                "K. M. Tsui",
                "M. R. Vagins",
                "J. Xia",
                "S. Izumiyama",
                "M. Kuze",
                "R. Matsumoto",
                "M. Ishitsuka",
                "H. Ito",
                "Y. Ommura",
                "N. Shigeta",
                "M. Shinoki",
                "K. Yamauchi",
                "T. Yoshida",
                "R. Gaur",
                "V. Gousy-Leblanc",
                "M. Hartz",
                "A. Konaka",
                "X. Li",
                "S. Chen",
                "B. D. Xu",
                "B. Zhang",
                "M. Posiadala-Zezula",
                "S. B. Boyd",
                "R. Edwards",
                "D. Hadley",
                "M. Nicholson",
                "M. O Flaherty",
                "B. Richards",
                "A. Ali",
                "B. Jamieson",
                "S. Amanai",
                "Ll. Marti",
                "A. Minamino",
                "S. Suzuki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01159v1",
                "http://arxiv.org/pdf/2311.01159v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01155v1",
            "title": "Learning Intra and Inter-Camera Invariance for Isolated Camera\n  Supervised Person Re-identification",
            "updated": "2023-11-02T11:32:40Z",
            "published": "2023-11-02T11:32:40Z",
            "summary": "Supervised person re-identification assumes that a person has images captured\nunder multiple cameras. However when cameras are placed in distance, a person\nrarely appears in more than one camera. This paper thus studies person re-ID\nunder such isolated camera supervised (ISCS) setting. Instead of trying to\ngenerate fake cross-camera features like previous methods, we explore a novel\nperspective by making efficient use of the variation in training data. Under\nISCS setting, a person only has limited images from a single camera, so the\ncamera bias becomes a critical issue confounding ID discrimination.\nCross-camera images are prone to being recognized as different IDs simply by\ncamera style. To eliminate the confounding effect of camera bias, we propose to\nlearn both intra- and inter-camera invariance under a unified framework. First,\nwe construct style-consistent environments via clustering, and perform\nprototypical contrastive learning within each environment. Meanwhile, strongly\naugmented images are contrasted with original prototypes to enforce\nintra-camera augmentation invariance. For inter-camera invariance, we further\ndesign a much improved variant of multi-camera negative loss that optimizes the\ndistance of multi-level negatives. The resulting model learns to be invariant\nto both subtle and severe style variation within and cross-camera. On multiple\nbenchmarks, we conduct extensive experiments and validate the effectiveness and\nsuperiority of the proposed method. Code will be available at\nhttps://github.com/Terminator8758/IICI.",
            "author": [
                "Menglin Wang",
                "Xiaojin Gong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01155v1",
                "http://arxiv.org/pdf/2311.01155v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01154v1",
            "title": "A Review of Digital Twins and their Application in Cybersecurity based\n  on Artificial Intelligence",
            "updated": "2023-11-02T11:31:53Z",
            "published": "2023-11-02T11:31:53Z",
            "summary": "The potential of digital twin technology is yet to be fully realized due to\nits diversity and untapped potential. Digital twins enable systems' analysis,\ndesign, optimization, and evolution to be performed digitally or in conjunction\nwith a cyber-physical approach to improve speed, accuracy, and efficiency over\ntraditional engineering methods. Industry 4.0, factories of the future, and\ndigital twins continue to benefit from the technology and provide enhanced\nefficiency within existing systems. Due to the lack of information and security\nstandards associated with the transition to cyber digitization, cybercriminals\nhave been able to take advantage of the situation. Access to a digital twin of\na product or service is equivalent to threatening the entire collection. There\nis a robust interaction between digital twins and artificial intelligence\ntools, which leads to strong interaction between these technologies, so it can\nbe used to improve the cybersecurity of these digital platforms based on their\nintegration with these technologies. This study aims to investigate the role of\nartificial intelligence in providing cybersecurity for digital twin versions of\nvarious industries, as well as the risks associated with these versions. In\naddition, this research serves as a road map for researchers and others\ninterested in cybersecurity and digital security.",
            "author": [
                "MohammadHossein Homaei",
                "Oscar Mogollon Gutierrez",
                "Jose Carlos Sancho Nunez",
                "Mar Avila Vegas",
                "Andres Caro Lindo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01154v1",
                "http://arxiv.org/pdf/2311.01154v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01139v1",
            "title": "Add and Thin: Diffusion for Temporal Point Processes",
            "updated": "2023-11-02T10:42:35Z",
            "published": "2023-11-02T10:42:35Z",
            "summary": "Autoregressive neural networks within the temporal point process (TPP)\nframework have become the standard for modeling continuous-time event data.\nEven though these models can expressively capture event sequences in a\none-step-ahead fashion, they are inherently limited for long-term forecasting\napplications due to the accumulation of errors caused by their sequential\nnature. To overcome these limitations, we derive ADD-THIN, a principled\nprobabilistic denoising diffusion model for TPPs that operates on entire event\nsequences. Unlike existing diffusion approaches, ADD-THIN naturally handles\ndata with discrete and continuous components. In experiments on synthetic and\nreal-world datasets, our model matches the state-of-the-art TPP models in\ndensity estimation and strongly outperforms them in forecasting.",
            "author": [
                "David L\u00fcdke",
                "Marin Bilo\u0161",
                "Oleksandr Shchur",
                "Marten Lienen",
                "Stephan G\u00fcnnemann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01139v1",
                "http://arxiv.org/pdf/2311.01139v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01138v1",
            "title": "AeroPath: An airway segmentation benchmark dataset with challenging\n  pathology",
            "updated": "2023-11-02T10:41:42Z",
            "published": "2023-11-02T10:41:42Z",
            "summary": "To improve the prognosis of patients suffering from pulmonary diseases, such\nas lung cancer, early diagnosis and treatment are crucial. The analysis of CT\nimages is invaluable for diagnosis, whereas high quality segmentation of the\nairway tree are required for intervention planning and live guidance during\nbronchoscopy. Recently, the Multi-domain Airway Tree Modeling (ATM'22)\nchallenge released a large dataset, both enabling training of deep-learning\nbased models and bringing substantial improvement of the state-of-the-art for\nthe airway segmentation task. However, the ATM'22 dataset includes few patients\nwith severe pathologies affecting the airway tree anatomy. In this study, we\nintroduce a new public benchmark dataset (AeroPath), consisting of 27 CT images\nfrom patients with pathologies ranging from emphysema to large tumors, with\ncorresponding trachea and bronchi annotations. Second, we present a multiscale\nfusion design for automatic airway segmentation. Models were trained on the\nATM'22 dataset, tested on the AeroPath dataset, and further evaluated against\ncompetitive open-source methods. The same performance metrics as used in the\nATM'22 challenge were used to benchmark the different considered approaches.\nLastly, an open web application is developed, to easily test the proposed model\non new data. The results demonstrated that our proposed architecture predicted\ntopologically correct segmentations for all the patients included in the\nAeroPath dataset. The proposed method is robust and able to handle various\nanomalies, down to at least the fifth airway generation. In addition, the\nAeroPath dataset, featuring patients with challenging pathologies, will\ncontribute to development of new state-of-the-art methods. The AeroPath dataset\nand the web application are made openly available.",
            "author": [
                "Karen-Helene St\u00f8verud",
                "David Bouget",
                "Andre Pedersen",
                "H\u00e5kon Olav Leira",
                "Thomas Lang\u00f8",
                "Erlend Fagertun Hofstad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01138v1",
                "http://arxiv.org/pdf/2311.01138v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01135v1",
            "title": "Generating QM1B with PySCF$_{\\text{IPU}}$",
            "updated": "2023-11-02T10:31:20Z",
            "published": "2023-11-02T10:31:20Z",
            "summary": "The emergence of foundation models in Computer Vision and Natural Language\nProcessing have resulted in immense progress on downstream tasks. This progress\nwas enabled by datasets with billions of training examples. Similar benefits\nare yet to be unlocked for quantum chemistry, where the potential of deep\nlearning is constrained by comparatively small datasets with 100k to 20M\ntraining examples. These datasets are limited in size because the labels are\ncomputed using the accurate (but computationally demanding) predictions of\nDensity Functional Theory (DFT). Notably, prior DFT datasets were created using\nCPU supercomputers without leveraging hardware acceleration. In this paper, we\ntake a first step towards utilising hardware accelerators by introducing the\ndata generator PySCF$_{\\text{IPU}}$ using Intelligence Processing Units (IPUs).\nThis allowed us to create the dataset QM1B with one billion training examples\ncontaining 9-11 heavy atoms. We demonstrate that a simple baseline neural\nnetwork (SchNet 9M) improves its performance by simply increasing the amount of\ntraining data without additional inductive biases. To encourage future\nresearchers to use QM1B responsibly, we highlight several limitations of QM1B\nand emphasise the low-resolution of our DFT options, which also serves as\nmotivation for even larger, more accurate datasets. Code and dataset are\navailable on Github: http://github.com/graphcore-research/pyscf-ipu",
            "author": [
                "Alexander Mathiasen",
                "Hatem Helal",
                "Kerstin Klaser",
                "Paul Balanca",
                "Josef Dean",
                "Carlo Luschi",
                "Dominique Beaini",
                "Andrew Fitzgibbon",
                "Dominic Masters"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01135v1",
                "http://arxiv.org/pdf/2311.01135v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.chem-ph",
                "I.2.6; J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01130v1",
            "title": "A deep learning experiment for semantic segmentation of overlapping\n  characters in palimpsests",
            "updated": "2023-11-02T10:25:47Z",
            "published": "2023-11-02T10:25:47Z",
            "summary": "Palimpsests refer to historical manuscripts where erased writings have been\npartially covered by the superimposition of a second writing. By employing\nimaging techniques, e.g., multispectral imaging, it becomes possible to\nidentify features that are imperceptible to the naked eye, including faded and\nerased inks. When dealing with overlapping inks, Artificial Intelligence\ntechniques can be utilized to disentangle complex nodes of overlapping letters.\nIn this work, we propose deep learning-based semantic segmentation as a method\nfor identifying and segmenting individual letters in overlapping characters.\nThe experiment was conceived as a proof of concept, focusing on the palimpsests\nof the Ars Grammatica by Prisciano as a case study. Furthermore, caveats and\nprospects of our approach combined with multispectral imaging are also\ndiscussed.",
            "author": [
                "Michela Perino",
                "Michele Ginolfi",
                "Anna Candida Felici",
                "Michela Rosellini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01130v1",
                "http://arxiv.org/pdf/2311.01130v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01125v1",
            "title": "Bi-Preference Learning Heterogeneous Hypergraph Networks for\n  Session-based Recommendation",
            "updated": "2023-11-02T10:16:28Z",
            "published": "2023-11-02T10:16:28Z",
            "summary": "Session-based recommendation intends to predict next purchased items based on\nanonymous behavior sequences. Numerous economic studies have revealed that item\nprice is a key factor influencing user purchase decisions. Unfortunately,\nexisting methods for session-based recommendation only aim at capturing user\ninterest preference, while ignoring user price preference. Actually, there are\nprimarily two challenges preventing us from accessing price preference.\nFirstly, the price preference is highly associated to various item features\n(i.e., category and brand), which asks us to mine price preference from\nheterogeneous information. Secondly, price preference and interest preference\nare interdependent and collectively determine user choice, necessitating that\nwe jointly consider both price and interest preference for intent modeling. To\nhandle above challenges, we propose a novel approach Bi-Preference Learning\nHeterogeneous Hypergraph Networks (BiPNet) for session-based recommendation.\nSpecifically, the customized heterogeneous hypergraph networks with a\ntriple-level convolution are devised to capture user price and interest\npreference from heterogeneous features of items. Besides, we develop a\nBi-Preference Learning schema to explore mutual relations between price and\ninterest preference and collectively learn these two preferences under the\nmulti-task learning architecture. Extensive experiments on multiple public\ndatasets confirm the superiority of BiPNet over competitive baselines.\nAdditional research also supports the notion that the price is crucial for the\ntask.",
            "author": [
                "Xiaokun Zhang",
                "Bo Xu",
                "Fenglong Ma",
                "Chenliang Li",
                "Yuan Lin",
                "Hongfei Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01125v1",
                "http://arxiv.org/pdf/2311.01125v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04918v1",
            "title": "Low-Resource Named Entity Recognition: Can One-vs-All AUC Maximization\n  Help?",
            "updated": "2023-11-02T10:14:52Z",
            "published": "2023-11-02T10:14:52Z",
            "summary": "Named entity recognition (NER), a task that identifies and categorizes named\nentities such as persons or organizations from text, is traditionally framed as\na multi-class classification problem. However, this approach often overlooks\nthe issues of imbalanced label distributions, particularly in low-resource\nsettings, which is common in certain NER contexts, like biomedical NER\n(bioNER). To address these issues, we propose an innovative reformulation of\nthe multi-class problem as a one-vs-all (OVA) learning problem and introduce a\nloss function based on the area under the receiver operating characteristic\ncurve (AUC). To enhance the efficiency of our OVA-based approach, we propose\ntwo training strategies: one groups labels with similar linguistic\ncharacteristics, and another employs meta-learning. The superiority of our\napproach is confirmed by its performance, which surpasses traditional NER\nlearning in varying NER settings.",
            "author": [
                "Ngoc Dang Nguyen",
                "Wei Tan",
                "Lan Du",
                "Wray Buntine",
                "Richard Beare",
                "Changyou Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04918v1",
                "http://arxiv.org/pdf/2311.04918v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02106v1",
            "title": "Efficient Machine Learning Ensemble Methods for Detecting Gravitational\n  Wave Glitches in LIGO Time Series",
            "updated": "2023-11-02T10:07:30Z",
            "published": "2023-11-02T10:07:30Z",
            "summary": "The phenomenon of Gravitational Wave (GW) analysis has grown in popularity as\ntechnology has advanced and the process of observing gravitational waves has\nbecome more precise. Although the sensitivity and the frequency of observation\nof GW signals are constantly improving, the possibility of noise in the\ncollected GW data remains. In this paper, we propose two new Machine and Deep\nlearning ensemble approaches (i.e., ShallowWaves and DeepWaves Ensembles) for\ndetecting different types of noise and patterns in datasets from GW\nobservatories. Our research also investigates various Machine and Deep Learning\ntechniques for multi-class classification and provides a comprehensive\nbenchmark, emphasizing the best results in terms of three commonly used\nperformance metrics (i.e., accuracy, precision, and recall). We train and test\nour models on a dataset consisting of annotated time series from real-world\ndata collected by the Advanced Laser Interferometer GW Observatory (LIGO). We\nempirically show that the best overall accuracy is obtained by the proposed\nDeepWaves Ensemble, followed close by the ShallowWaves Ensemble.",
            "author": [
                "Elena-Simona Apostol",
                "Ciprian-Octavian Truic\u0103"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02106v1",
                "http://arxiv.org/pdf/2311.02106v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "astro-ph.IM",
                "cs.AI",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01122v1",
            "title": "Deep Joint Source-Channel Coding for DNA Image Storage: A Novel Approach\n  with Enhanced Error Resilience and Biological Constraint Optimization",
            "updated": "2023-11-02T10:06:20Z",
            "published": "2023-11-02T10:06:20Z",
            "summary": "In the current era, DeoxyriboNucleic Acid (DNA) based data storage emerges as\nan intriguing approach, garnering substantial academic interest and\ninvestigation. This paper introduces a novel deep joint source-channel coding\n(DJSCC) scheme for DNA image storage, designated as DJSCC-DNA. This paradigm\ndistinguishes itself from conventional DNA storage techniques through three key\nmodifications: 1) it employs advanced deep learning methodologies, employing\nconvolutional neural networks for DNA encoding and decoding processes; 2) it\nseamlessly integrates DNA polymerase chain reaction (PCR) amplification into\nthe network architecture, thereby augmenting data recovery precision; and 3) it\nrestructures the loss function by targeting biological constraints for\noptimization. The performance of the proposed model is demonstrated via\nnumerical results from specific channel testing, suggesting that it surpasses\nconventional deep learning methodologies in terms of peak signal-to-noise ratio\n(PSNR) and structural similarity index (SSIM). Additionally, the model\neffectively ensures positive constraints on both homopolymer run-length and GC\ncontent.",
            "author": [
                "Wenfeng Wu",
                "Luping Xiang",
                "Qiang Liu",
                "Kun Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01122v1",
                "http://arxiv.org/pdf/2311.01122v1"
            ],
            "primary_category": "cs.ET",
            "category": [
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01118v1",
            "title": "AI for Interpretable Chemistry: Predicting Radical Mechanistic Pathways\n  via Contrastive Learning",
            "updated": "2023-11-02T09:47:27Z",
            "published": "2023-11-02T09:47:27Z",
            "summary": "Deep learning-based reaction predictors have undergone significant\narchitectural evolution. However, their reliance on reactions from the US\nPatent Office results in a lack of interpretable predictions and limited\ngeneralization capability to other chemistry domains, such as radical and\natmospheric chemistry. To address these challenges, we introduce a new reaction\npredictor system, RMechRP, that leverages contrastive learning in conjunction\nwith mechanistic pathways, the most interpretable representation of chemical\nreactions. Specifically designed for radical reactions, RMechRP provides\ndifferent levels of interpretation of chemical reactions. We develop and train\nmultiple deep-learning models using RMechDB, a public database of radical\nreactions, to establish the first benchmark for predicting radical reactions.\nOur results demonstrate the effectiveness of RMechRP in providing accurate and\ninterpretable predictions of radical reactions, and its potential for various\napplications in atmospheric chemistry.",
            "author": [
                "Mohammadamin Tavakoli",
                "Yin Ting T. Chiu",
                "Alexander Shmakov",
                "Ann Marie Carlton",
                "David Van Vranken",
                "Pierre Baldi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01118v1",
                "http://arxiv.org/pdf/2311.01118v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01117v1",
            "title": "Cheating Depth: Enhancing 3D Surface Anomaly Detection via Depth\n  Simulation",
            "updated": "2023-11-02T09:44:21Z",
            "published": "2023-11-02T09:44:21Z",
            "summary": "RGB-based surface anomaly detection methods have advanced significantly.\nHowever, certain surface anomalies remain practically invisible in RGB alone,\nnecessitating the incorporation of 3D information. Existing approaches that\nemploy point-cloud backbones suffer from suboptimal representations and reduced\napplicability due to slow processing. Re-training RGB backbones, designed for\nfaster dense input processing, on industrial depth datasets is hindered by the\nlimited availability of sufficiently large datasets. We make several\ncontributions to address these challenges. (i) We propose a novel Depth-Aware\nDiscrete Autoencoder (DADA) architecture, that enables learning a general\ndiscrete latent space that jointly models RGB and 3D data for 3D surface\nanomaly detection. (ii) We tackle the lack of diverse industrial depth datasets\nby introducing a simulation process for learning informative depth features in\nthe depth encoder. (iii) We propose a new surface anomaly detection method\n3DSR, which outperforms all existing state-of-the-art on the challenging\nMVTec3D anomaly detection benchmark, both in terms of accuracy and processing\nspeed. The experimental results validate the effectiveness and efficiency of\nour approach, highlighting the potential of utilizing depth information for\nimproved surface anomaly detection.",
            "author": [
                "Vitjan Zavrtanik",
                "Matej Kristan",
                "Danijel Sko\u010daj"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01117v1",
                "http://arxiv.org/pdf/2311.01117v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01111v1",
            "title": "H-NeXt: The next step towards roto-translation invariant networks",
            "updated": "2023-11-02T09:36:20Z",
            "published": "2023-11-02T09:36:20Z",
            "summary": "The widespread popularity of equivariant networks underscores the\nsignificance of parameter efficient models and effective use of training data.\nAt a time when robustness to unseen deformations is becoming increasingly\nimportant, we present H-NeXt, which bridges the gap between equivariance and\ninvariance. H-NeXt is a parameter-efficient roto-translation invariant network\nthat is trained without a single augmented image in the training set. Our\nnetwork comprises three components: an equivariant backbone for learning\nroto-translation independent features, an invariant pooling layer for\ndiscarding roto-translation information, and a classification layer. H-NeXt\noutperforms the state of the art in classification on unaugmented training sets\nand augmented test sets of MNIST and CIFAR-10.",
            "author": [
                "Tomas Karella",
                "Filip Sroubek",
                "Jan Flusser",
                "Jan Blazek",
                "Vasek Kosik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01111v1",
                "http://arxiv.org/pdf/2311.01111v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01108v1",
            "title": "Noise-Robust Fine-Tuning of Pretrained Language Models via External\n  Guidance",
            "updated": "2023-11-02T09:20:38Z",
            "published": "2023-11-02T09:20:38Z",
            "summary": "Adopting a two-stage paradigm of pretraining followed by fine-tuning,\nPretrained Language Models (PLMs) have achieved substantial advancements in the\nfield of natural language processing. However, in real-world scenarios, data\nlabels are often noisy due to the complex annotation process, making it\nessential to develop strategies for fine-tuning PLMs with such noisy labels. To\nthis end, we introduce an innovative approach for fine-tuning PLMs using noisy\nlabels, which incorporates the guidance of Large Language Models (LLMs) like\nChatGPT. This guidance assists in accurately distinguishing between clean and\nnoisy samples and provides supplementary information beyond the noisy labels,\nthereby boosting the learning process during fine-tuning PLMs. Extensive\nexperiments on synthetic and real-world noisy datasets further demonstrate the\nsuperior advantages of our framework over the state-of-the-art baselines.",
            "author": [
                "Song Wang",
                "Zhen Tan",
                "Ruocheng Guo",
                "Jundong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01108v1",
                "http://arxiv.org/pdf/2311.01108v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02105v1",
            "title": "Making Harmful Behaviors Unlearnable for Large Language Models",
            "updated": "2023-11-02T09:18:21Z",
            "published": "2023-11-02T09:18:21Z",
            "summary": "Large language models (LLMs) have shown great potential as general-purpose AI\nassistants in various domains. To meet the requirements of different\napplications, LLMs are often customized by further fine-tuning. However, the\npowerful learning ability of LLMs not only enables them to acquire new tasks\nbut also makes them susceptible to learning undesired behaviors. For example,\neven safety-aligned LLMs can be easily fine-tuned into harmful assistants as\nthe fine-tuning data often contains implicit or explicit harmful content. Can\nwe train LLMs on harmful data without learning harmful behaviors? This paper\nproposes a controllable training framework that makes harmful behaviors\nunlearnable during the fine-tuning process. Specifically, we introduce\n``security vectors'', a few new parameters that can be separated from the LLM,\nto ensure LLM's responses are consistent with the harmful behavior. Security\nvectors are activated during fine-tuning, the consistent behavior makes LLM\nbelieve that such behavior has already been learned, there is no need to\nfurther optimize for harmful data. During inference, we can deactivate security\nvectors to restore the LLM's normal behavior. The experimental results show\nthat the security vectors generated by 100 harmful samples are enough to\nprevent LLM from learning 1000 harmful samples, while preserving the ability to\nlearn other useful information.",
            "author": [
                "Xin Zhou",
                "Yi Lu",
                "Ruotian Ma",
                "Tao Gui",
                "Qi Zhang",
                "Xuanjing Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02105v1",
                "http://arxiv.org/pdf/2311.02105v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01106v1",
            "title": "In Defense of Softmax Parametrization for Calibrated and Consistent\n  Learning to Defer",
            "updated": "2023-11-02T09:15:52Z",
            "published": "2023-11-02T09:15:52Z",
            "summary": "Enabling machine learning classifiers to defer their decision to a downstream\nexpert when the expert is more accurate will ensure improved safety and\nperformance. This objective can be achieved with the learning-to-defer\nframework which aims to jointly learn how to classify and how to defer to the\nexpert. In recent studies, it has been theoretically shown that popular\nestimators for learning to defer parameterized with softmax provide unbounded\nestimates for the likelihood of deferring which makes them uncalibrated.\nHowever, it remains unknown whether this is due to the widely used softmax\nparameterization and if we can find a softmax-based estimator that is both\nstatistically consistent and possesses a valid probability estimator. In this\nwork, we first show that the cause of the miscalibrated and unbounded estimator\nin prior literature is due to the symmetric nature of the surrogate losses used\nand not due to softmax. We then propose a novel statistically consistent\nasymmetric softmax-based surrogate loss that can produce valid estimates\nwithout the issue of unboundedness. We further analyze the non-asymptotic\nproperties of our method and empirically validate its performance and\ncalibration on benchmark datasets.",
            "author": [
                "Yuzhou Cao",
                "Hussein Mozannar",
                "Lei Feng",
                "Hongxin Wei",
                "Bo An"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01106v1",
                "http://arxiv.org/pdf/2311.01106v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01099v1",
            "title": "Dissimilar thermal transport properties in $\u03ba$-Ga$_2$O$_3$ and\n  $\u03b2$-Ga$_2$O$_3$ revealed by machine-learning homogeneous nonequilibrium\n  molecular dynamics simulations",
            "updated": "2023-11-02T09:07:05Z",
            "published": "2023-11-02T09:07:05Z",
            "summary": "The lattice thermal conductivity (LTC) of Ga$_2$O$_3$ is an important\nproperty due to the challenge in the thermal management of high-power devices.\nWe develop machine-learned neuroevolution potentials for single-crystalline\n$\\beta$-Ga$_2$O$_3$ and $\\kappa$-Ga$_2$O$_3$, and apply them to perform\nhomogeneous nonequilibrium molecular dynamics simulations to predict their\nLTCs. The LTC of $\\beta$-Ga$_2$O$_3$ was determined to be 10.3 $\\pm$ 0.2 W/(m\nK), 19.9 $\\pm$ 0.2 W/(m K), and 12.6 $\\pm$ 0.2 W/(m K) along [100], [010], and\n[001], respectively, aligning with previous experimental measurements. For the\nfirst time, we predict the LTC of $\\kappa$-Ga$_2$O$_3$ along [100], [010], and\n[001] to be 4.5 $\\pm$ 0.0 W/(m K), 3.9 $\\pm$ 0.0 W/(m K), and 4.0 $\\pm$ 0.1\nW/(m K), respectively, showing a nearly isotropic thermal transport property.\nThe reduced LTC of $\\kappa$-Ga$_2$O$_3$ versus $\\beta$-Ga$_2$O$_3$ stems from\nits restricted low-frequency phonons up to 5 THz. Furthermore, we find that the\n$\\beta$ phase exhibits a typical temperature dependence slightly stronger than\n$\\sim T^{-1}$, whereas the $\\kappa$ phase shows a weaker temperature\ndependence, ranging from $\\sim T^{-0.5}$ to $\\sim T^{-0.7}$.",
            "author": [
                "Xiaonan Wang",
                "Jinfeng Yang",
                "Penghua Ying",
                "Zheyong Fan",
                "Jin Zhang",
                "Huarui Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01099v1",
                "http://arxiv.org/pdf/2311.01099v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01092v1",
            "title": "Learning A Multi-Task Transformer Via Unified And Customized Instruction\n  Tuning For Chest Radiograph Interpretation",
            "updated": "2023-11-02T08:55:48Z",
            "published": "2023-11-02T08:55:48Z",
            "summary": "The emergence of multi-modal deep learning models has made significant\nimpacts on clinical applications in the last decade. However, the majority of\nmodels are limited to single-tasking, without considering disease diagnosis is\nindeed a multi-task procedure. Here, we demonstrate a unified transformer model\nspecifically designed for multi-modal clinical tasks by incorporating\ncustomized instruction tuning. We first compose a multi-task training dataset\ncomprising 13.4 million instruction and ground-truth pairs (with approximately\none million radiographs) for the customized tuning, involving both image- and\npixel-level tasks. Thus, we can unify the various vision-intensive tasks in a\nsingle training framework with homogeneous model inputs and outputs to increase\nclinical interpretability in one reading. Finally, we demonstrate the overall\nsuperior performance of our model compared to prior arts on various chest X-ray\nbenchmarks across multi-tasks in both direct inference and finetuning settings.\nThree radiologists further evaluate the generated reports against the recorded\nones, which also exhibit the enhanced explainability of our multi-task model.",
            "author": [
                "Lijian Xu",
                "Ziyu Ni",
                "Xinglong Liu",
                "Xiaosong Wang",
                "Hongsheng Li",
                "Shaoting Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01092v1",
                "http://arxiv.org/pdf/2311.01092v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01090v1",
            "title": "Infusion: Internal Diffusion for Video Inpainting",
            "updated": "2023-11-02T08:55:11Z",
            "published": "2023-11-02T08:55:11Z",
            "summary": "Video inpainting is the task of filling a desired region in a video in a\nvisually convincing manner. It is a very challenging task due to the high\ndimensionality of the signal and the temporal consistency required for\nobtaining convincing results. Recently, diffusion models have shown impressive\nresults in modeling complex data distributions, including images and videos.\nDiffusion models remain nonetheless very expensive to train and perform\ninference with, which strongly restrict their application to video. We show\nthat in the case of video inpainting, thanks to the highly auto-similar nature\nof videos, the training of a diffusion model can be restricted to the video to\ninpaint and still produce very satisfying results. This leads us to adopt an\ninternal learning approch, which also allows for a greatly reduced network\nsize. We call our approach \"Infusion\": an internal learning algorithm for video\ninpainting through diffusion. Due to our frugal network, we are able to propose\nthe first video inpainting approach based purely on diffusion. Other methods\nrequire supporting elements such as optical flow estimation, which limits their\nperformance in the case of dynamic textures for example. We introduce a new\nmethod for efficient training and inference of diffusion models in the context\nof internal learning. We split the diffusion process into different learning\nintervals which greatly simplifies the learning steps. We show qualititative\nand quantitative results, demonstrating that our method reaches\nstate-of-the-art performance, in particular in the case of dynamic backgrounds\nand textures.",
            "author": [
                "Nicolas Cherel",
                "Andr\u00e9s Almansa",
                "Yann Gousseau",
                "Alasdair Newson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01090v1",
                "http://arxiv.org/pdf/2311.01090v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03382v1",
            "title": "Causal Structure Representation Learning of Confounders in Latent Space\n  for Recommendation",
            "updated": "2023-11-02T08:46:07Z",
            "published": "2023-11-02T08:46:07Z",
            "summary": "Inferring user preferences from the historical feedback of users is a\nvaluable problem in recommender systems. Conventional approaches often rely on\nthe assumption that user preferences in the feedback data are equivalent to the\nreal user preferences without additional noise, which simplifies the problem\nmodeling. However, there are various confounders during user-item interactions,\nsuch as weather and even the recommendation system itself. Therefore,\nneglecting the influence of confounders will result in inaccurate user\npreferences and suboptimal performance of the model. Furthermore, the\nunobservability of confounders poses a challenge in further addressing the\nproblem. To address these issues, we refine the problem and propose a more\nrational solution. Specifically, we consider the influence of confounders,\ndisentangle them from user preferences in the latent space, and employ causal\ngraphs to model their interdependencies without specific labels. By cleverly\ncombining local and global causal graphs, we capture the user-specificity of\nconfounders on user preferences. We theoretically demonstrate the\nidentifiability of the obtained causal graph. Finally, we propose our model\nbased on Variational Autoencoders, named Causal Structure representation\nlearning of Confounders in latent space (CSC). We conducted extensive\nexperiments on one synthetic dataset and five real-world datasets,\ndemonstrating the superiority of our model. Furthermore, we demonstrate that\nthe learned causal representations of confounders are controllable, potentially\noffering users fine-grained control over the objectives of their recommendation\nlists with the learned causal graphs.",
            "author": [
                "Hangtong Xu",
                "Yuanbo Xu",
                "Yongjian Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03382v1",
                "http://arxiv.org/pdf/2311.03382v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03381v1",
            "title": "Separating and Learning Latent Confounders to Enhancing User Preferences\n  Modeling",
            "updated": "2023-11-02T08:42:50Z",
            "published": "2023-11-02T08:42:50Z",
            "summary": "Recommender models aim to capture user preferences from historical feedback\nand then predict user-specific feedback on candidate items. However, the\npresence of various unmeasured confounders causes deviations between the user\npreferences in the historical feedback and the true preferences, resulting in\nmodels not meeting their expected performance. Existing debias models either\n(1) specific to solving one particular bias or (2) directly obtain auxiliary\ninformation from user historical feedback, which cannot identify whether the\nlearned preferences are true user preferences or mixed with unmeasured\nconfounders. Moreover, we find that the former recommender system is not only a\nsuccessor to unmeasured confounders but also acts as an unmeasured confounder\naffecting user preference modeling, which has always been neglected in previous\nstudies. To this end, we incorporate the effect of the former recommender\nsystem and treat it as a proxy for all unmeasured confounders. We propose a\nnovel framework, \\textbf{S}eparating and \\textbf{L}earning Latent Confounders\n\\textbf{F}or \\textbf{R}ecommendation (\\textbf{SLFR}), which obtains the\nrepresentation of unmeasured confounders to identify the counterfactual\nfeedback by disentangling user preferences and unmeasured confounders, then\nguides the target model to capture the true preferences of users. Extensive\nexperiments in five real-world datasets validate the advantages of our method.",
            "author": [
                "Hangtong Xu",
                "Yuanbo Xu",
                "Yongjian Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03381v1",
                "http://arxiv.org/pdf/2311.03381v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01075v1",
            "title": "Contrastive Modules with Temporal Attention for Multi-Task Reinforcement\n  Learning",
            "updated": "2023-11-02T08:41:00Z",
            "published": "2023-11-02T08:41:00Z",
            "summary": "In the field of multi-task reinforcement learning, the modular principle,\nwhich involves specializing functionalities into different modules and\ncombining them appropriately, has been widely adopted as a promising approach\nto prevent the negative transfer problem that performance degradation due to\nconflicts between tasks. However, most of the existing multi-task RL methods\nonly combine shared modules at the task level, ignoring that there may be\nconflicts within the task. In addition, these methods do not take into account\nthat without constraints, some modules may learn similar functions, resulting\nin restricting the model's expressiveness and generalization capability of\nmodular methods. In this paper, we propose the Contrastive Modules with\nTemporal Attention(CMTA) method to address these limitations. CMTA constrains\nthe modules to be different from each other by contrastive learning and\ncombining shared modules at a finer granularity than the task level with\ntemporal attention, alleviating the negative transfer within the task and\nimproving the generalization ability and the performance for multi-task RL. We\nconducted the experiment on Meta-World, a multi-task RL benchmark containing\nvarious robotics manipulation tasks. Experimental results show that CMTA\noutperforms learning each task individually for the first time and achieves\nsubstantial performance improvements over the baselines.",
            "author": [
                "Siming Lan",
                "Rui Zhang",
                "Qi Yi",
                "Jiaming Guo",
                "Shaohui Peng",
                "Yunkai Gao",
                "Fan Wu",
                "Ruizhi Chen",
                "Zidong Du",
                "Xing Hu",
                "Xishan Zhang",
                "Ling Li",
                "Yunji Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01075v1",
                "http://arxiv.org/pdf/2311.01075v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01065v1",
            "title": "Novel View Synthesis from a Single RGBD Image for Indoor Scenes",
            "updated": "2023-11-02T08:34:07Z",
            "published": "2023-11-02T08:34:07Z",
            "summary": "In this paper, we propose an approach for synthesizing novel view images from\na single RGBD (Red Green Blue-Depth) input. Novel view synthesis (NVS) is an\ninteresting computer vision task with extensive applications. Methods using\nmultiple images has been well-studied, exemplary ones include training\nscene-specific Neural Radiance Fields (NeRF), or leveraging multi-view stereo\n(MVS) and 3D rendering pipelines. However, both are either computationally\nintensive or non-generalizable across different scenes, limiting their\npractical value. Conversely, the depth information embedded in RGBD images\nunlocks 3D potential from a singular view, simplifying NVS. The widespread\navailability of compact, affordable stereo cameras, and even LiDARs in\ncontemporary devices like smartphones, makes capturing RGBD images more\naccessible than ever. In our method, we convert an RGBD image into a point\ncloud and render it from a different viewpoint, then formulate the NVS task\ninto an image translation problem. We leveraged generative adversarial networks\nto style-transfer the rendered image, achieving a result similar to a\nphotograph taken from the new perspective. We explore both unsupervised\nlearning using CycleGAN and supervised learning with Pix2Pix, and demonstrate\nthe qualitative results. Our method circumvents the limitations of traditional\nmulti-image techniques, holding significant promise for practical, real-time\napplications in NVS.",
            "author": [
                "Congrui Hetang",
                "Yuping Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01065v1",
                "http://arxiv.org/pdf/2311.01065v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16132v1",
            "title": "A novel RNA pseudouridine site prediction model using Utility Kernel and\n  data-driven parameters",
            "updated": "2023-11-02T08:32:10Z",
            "published": "2023-11-02T08:32:10Z",
            "summary": "RNA protein Interactions (RPIs) play an important role in biological systems.\nRecently, we have enumerated the RPIs at the residue level and have elucidated\nthe minimum structural unit (MSU) in these interactions to be a stretch of five\nresidues (Nucleotides/amino acids). Pseudouridine is the most frequent\nmodification in RNA. The conversion of uridine to pseudouridine involves\ninteractions between pseudouridine synthase and RNA. The existing models to\npredict the pseudouridine sites in a given RNA sequence mainly depend on\nuser-defined features such as mono and dinucleotide composition/propensities of\nRNA sequences. Predicting pseudouridine sites is a non-linear classification\nproblem with limited data points. Deep Learning models are efficient\ndiscriminators when the data set size is reasonably large and fail when there\nis a paucity of data ($<1000$ samples). To mitigate this problem, we propose a\nSupport Vector Machine (SVM) Kernel based on utility theory from Economics, and\nusing data-driven parameters (i.e. MSU) as features. For this purpose, we have\nused position-specific tri/quad/pentanucleotide composition/propensity\n(PSPC/PSPP) besides nucleotide and dineculeotide composition as features. SVMs\nare known to work well in small data regimes and kernels in SVM are designed to\nclassify non-linear data. The proposed model outperforms the existing\nstate-of-the-art models significantly (10%-15% on average).",
            "author": [
                "Sourabh Patil",
                "Archana Mathur",
                "Raviprasad Aduri",
                "Snehanshu Saha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16132v1",
                "http://arxiv.org/pdf/2311.16132v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01064v1",
            "title": "Multimodal Foundation Models for Zero-shot Animal Species Recognition in\n  Camera Trap Images",
            "updated": "2023-11-02T08:32:00Z",
            "published": "2023-11-02T08:32:00Z",
            "summary": "Due to deteriorating environmental conditions and increasing human activity,\nconservation efforts directed towards wildlife is crucial. Motion-activated\ncamera traps constitute an efficient tool for tracking and monitoring wildlife\npopulations across the globe. Supervised learning techniques have been\nsuccessfully deployed to analyze such imagery, however training such techniques\nrequires annotations from experts. Reducing the reliance on costly labelled\ndata therefore has immense potential in developing large-scale wildlife\ntracking solutions with markedly less human labor. In this work we propose\nWildMatch, a novel zero-shot species classification framework that leverages\nmultimodal foundation models. In particular, we instruction tune\nvision-language models to generate detailed visual descriptions of camera trap\nimages using similar terminology to experts. Then, we match the generated\ncaption to an external knowledge base of descriptions in order to determine the\nspecies in a zero-shot manner. We investigate techniques to build instruction\ntuning datasets for detailed animal description generation and propose a novel\nknowledge augmentation technique to enhance caption quality. We demonstrate the\nperformance of WildMatch on a new camera trap dataset collected in the\nMagdalena Medio region of Colombia.",
            "author": [
                "Zalan Fabian",
                "Zhongqi Miao",
                "Chunyuan Li",
                "Yuanhan Zhang",
                "Ziwei Liu",
                "Andr\u00e9s Hern\u00e1ndez",
                "Andr\u00e9s Montes-Rojas",
                "Rafael Escucha",
                "Laura Siabatto",
                "Andr\u00e9s Link",
                "Pablo Arbel\u00e1ez",
                "Rahul Dodhia",
                "Juan Lavista Ferres"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01064v1",
                "http://arxiv.org/pdf/2311.01064v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01061v1",
            "title": "Deep Learning for real-time neural decoding of grasp",
            "updated": "2023-11-02T08:26:29Z",
            "published": "2023-11-02T08:26:29Z",
            "summary": "Neural decoding involves correlating signals acquired from the brain to\nvariables in the physical world like limb movement or robot control in Brain\nMachine Interfaces. In this context, this work starts from a specific\npre-existing dataset of neural recordings from monkey motor cortex and presents\na Deep Learning-based approach to the decoding of neural signals for grasp type\nclassification. Specifically, we propose here an approach that exploits LSTM\nnetworks to classify time series containing neural data (i.e., spike trains)\ninto classes representing the object being grasped. The main goal of the\npresented approach is to improve over state-of-the-art decoding accuracy\nwithout relying on any prior neuroscience knowledge, and leveraging only the\ncapability of deep learning models to extract correlations from data. The paper\npresents the results achieved for the considered dataset and compares them with\nprevious works on the same dataset, showing a significant improvement in\nclassification accuracy, even if considering simulated real-time decoding.",
            "author": [
                "Paolo Viviani",
                "Ilaria Gesmundo",
                "Elios Ghinato",
                "Andres Agudelo-Toro",
                "Chiara Vercellino",
                "Giacomo Vitali",
                "Letizia Bergamasco",
                "Alberto Scionti",
                "Marco Ghislieri",
                "Valentina Agostini",
                "Olivier Terzo",
                "Hansj\u00f6rg Scherberger"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-43427-3_23",
                "http://arxiv.org/abs/2311.01061v1",
                "http://arxiv.org/pdf/2311.01061v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01059v1",
            "title": "Adapt On-the-Go: Behavior Modulation for Single-Life Robot Deployment",
            "updated": "2023-11-02T08:22:28Z",
            "published": "2023-11-02T08:22:28Z",
            "summary": "To succeed in the real world, robots must cope with situations that differ\nfrom those seen during training. We study the problem of adapting on-the-fly to\nsuch novel scenarios during deployment, by drawing upon a diverse repertoire of\npreviously learned behaviors. Our approach, RObust Autonomous Modulation\n(ROAM), introduces a mechanism based on the perceived value of pre-trained\nbehaviors to select and adapt pre-trained behaviors to the situation at hand.\nCrucially, this adaptation process all happens within a single episode at test\ntime, without any human supervision. We provide theoretical analysis of our\nselection mechanism and demonstrate that ROAM enables a robot to adapt rapidly\nto changes in dynamics both in simulation and on a real Go1 quadruped, even\nsuccessfully moving forward with roller skates on its feet. Our approach adapts\nover 2x as efficiently compared to existing methods when facing a variety of\nout-of-distribution situations during deployment by effectively choosing and\nadapting relevant behaviors on-the-fly.",
            "author": [
                "Annie S. Chen",
                "Govind Chada",
                "Laura Smith",
                "Archit Sharma",
                "Zipeng Fu",
                "Sergey Levine",
                "Chelsea Finn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01059v1",
                "http://arxiv.org/pdf/2311.01059v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03380v1",
            "title": "An attempt to generate new bridge types from latent space of variational\n  autoencoder",
            "updated": "2023-11-02T08:18:37Z",
            "published": "2023-11-02T08:18:37Z",
            "summary": "Try to generate new bridge types using generative artificial intelligence\ntechnology. The grayscale images of the bridge facade with the change of\ncomponent width was rendered by 3dsMax animation software, and then the OpenCV\nmodule performed an appropriate amount of geometric transformation (rotation,\nhorizontal scale, vertical scale) to obtain the image dataset of three-span\nbeam bridge, arch bridge, cable-stayed bridge and suspension bridge. Based on\nPython programming language, TensorFlow and Keras deep learning platform\nframework, variational autoencoder was constructed and trained, and\nlow-dimensional bridge-type latent space that is convenient for vector\noperations was obtained. Variational autoencoder can combine two bridge types\non the basis of the original of human into one that is a new bridge type.\nGenerative artificial intelligence technology can assist bridge designers in\nbridge-type innovation, and can be used as copilot.",
            "author": [
                "Hongjun Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03380v1",
                "http://arxiv.org/pdf/2311.03380v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01057v2",
            "title": "Ultra-Efficient On-Device Object Detection on AI-Integrated Smart\n  Glasses with TinyissimoYOLO",
            "updated": "2023-11-03T15:25:55Z",
            "published": "2023-11-02T08:01:49Z",
            "summary": "Smart glasses are rapidly gaining advanced functionality thanks to\ncutting-edge computing technologies, accelerated hardware architectures, and\ntiny AI algorithms. Integrating AI into smart glasses featuring a small form\nfactor and limited battery capacity is still challenging when targeting\nfull-day usage for a satisfactory user experience. This paper illustrates the\ndesign and implementation of tiny machine-learning algorithms exploiting novel\nlow-power processors to enable prolonged continuous operation in smart glasses.\nWe explore the energy- and latency-efficient of smart glasses in the case of\nreal-time object detection. To this goal, we designed a smart glasses prototype\nas a research platform featuring two microcontrollers, including a novel\nmilliwatt-power RISC-V parallel processor with a hardware accelerator for\nvisual AI, and a Bluetooth low-power module for communication. The smart\nglasses integrate power cycling mechanisms, including image and audio sensing\ninterfaces. Furthermore, we developed a family of novel tiny deep-learning\nmodels based on YOLO with sub-million parameters customized for\nmicrocontroller-based inference dubbed TinyissimoYOLO v1.3, v5, and v8, aiming\nat benchmarking object detection with smart glasses for energy and latency.\nEvaluations on the prototype of the smart glasses demonstrate TinyissimoYOLO's\n17ms inference latency and 1.59mJ energy consumption per inference while\nensuring acceptable detection accuracy. Further evaluation reveals an\nend-to-end latency from image capturing to the algorithm's prediction of 56ms\nor equivalently 18 fps, with a total power consumption of 62.9mW, equivalent to\na 9.3 hours of continuous run time on a 154mAh battery. These results\noutperform MCUNet (TinyNAS+TinyEngine), which runs a simpler task (image\nclassification) at just 7.3 fps per second.",
            "author": [
                "Julian Moosmann",
                "Pietro Bonazzi",
                "Yawei Li",
                "Sizhen Bian",
                "Philipp Mayer",
                "Luca Benini",
                "Michele Magno"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01057v2",
                "http://arxiv.org/pdf/2311.01057v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01056v1",
            "title": "Collaboration and Transition: Distilling Item Transitions into\n  Multi-Query Self-Attention for Sequential Recommendation",
            "updated": "2023-11-02T08:01:36Z",
            "published": "2023-11-02T08:01:36Z",
            "summary": "Modern recommender systems employ various sequential modules such as\nself-attention to learn dynamic user interests. However, these methods are less\neffective in capturing collaborative and transitional signals within user\ninteraction sequences. First, the self-attention architecture uses the\nembedding of a single item as the attention query, which is inherently\nchallenging to capture collaborative signals. Second, these methods typically\nfollow an auto-regressive framework, which is unable to learn global item\ntransition patterns. To overcome these limitations, we propose a new method\ncalled Multi-Query Self-Attention with Transition-Aware Embedding Distillation\n(MQSA-TED). First, we propose an $L$-query self-attention module that employs\nflexible window sizes for attention queries to capture collaborative signals.\nIn addition, we introduce a multi-query self-attention method that balances the\nbias-variance trade-off in modeling user preferences by combining long and\nshort-query self-attentions. Second, we develop a transition-aware embedding\ndistillation module that distills global item-to-item transition patterns into\nitem embeddings, which enables the model to memorize and leverage transitional\nsignals and serves as a calibrator for collaborative signals. Experimental\nresults on four real-world datasets show the superiority of our proposed method\nover state-of-the-art sequential recommendation methods.",
            "author": [
                "Tianyu Zhu",
                "Yansong Shi",
                "Yuan Zhang",
                "Yihong Wu",
                "Fengran Mo",
                "Jian-Yun Nie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01056v1",
                "http://arxiv.org/pdf/2311.01056v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01052v2",
            "title": "Resilient Multiple Choice Learning: A learned scoring scheme with\n  application to audio scene analysis",
            "updated": "2023-11-16T11:04:53Z",
            "published": "2023-11-02T07:54:03Z",
            "summary": "We introduce Resilient Multiple Choice Learning (rMCL), an extension of the\nMCL approach for conditional distribution estimation in regression settings\nwhere multiple targets may be sampled for each training input. Multiple Choice\nLearning is a simple framework to tackle multimodal density estimation, using\nthe Winner-Takes-All (WTA) loss for a set of hypotheses. In regression\nsettings, the existing MCL variants focus on merging the hypotheses, thereby\neventually sacrificing the diversity of the predictions. In contrast, our\nmethod relies on a novel learned scoring scheme underpinned by a mathematical\nframework based on Voronoi tessellations of the output space, from which we can\nderive a probabilistic interpretation. After empirically validating rMCL with\nexperiments on synthetic data, we further assess its merits on the sound source\nlocalization problem, demonstrating its practical usefulness and the relevance\nof its interpretation.",
            "author": [
                "Victor Letzelter",
                "Mathieu Fontaine",
                "Micka\u00ebl Chen",
                "Patrick P\u00e9rez",
                "Slim Essid",
                "Ga\u00ebl Richard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01052v2",
                "http://arxiv.org/pdf/2311.01052v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01050v1",
            "title": "Application and Energy-Aware Data Aggregation using Vector\n  Synchronization in Distributed Battery-less IoT Networks",
            "updated": "2023-11-02T07:51:23Z",
            "published": "2023-11-02T07:51:23Z",
            "summary": "The battery-less Internet of Things (IoT) devices are a key element in the\nsustainable green initiative for the next-generation wireless networks. These\nbattery-free devices use the ambient energy, harvested from the environment.\nThe energy harvesting environment is dynamic and causes intermittent task\nexecution. The harvested energy is stored in small capacitors and it is\nchallenging to assure the application task execution. The main goal is to\nprovide a mechanism to aggregate the sensor data and provide a sustainable\napplication support in the distributed battery-less IoT network. We model the\ndistributed IoT network system consisting of many battery-free IoT sensor\nhardware modules and heterogeneous IoT applications that are being supported in\nthe device-edge-cloud continuum. The applications require sensor data from a\ndistributed set of battery-less hardware modules and there is provision of\njoint control over the module actuators. We propose an application-aware task\nand energy manager (ATEM) for the IoT devices and a vector-synchronization\nbased data aggregator (VSDA). The ATEM is supported by device-level federated\nenergy harvesting and system-level energy-aware heterogeneous application\nmanagement. In our proposed framework the data aggregator forecasts the\navailable power from the ambient energy harvester using long-short-term-memory\n(LSTM) model and sets the device profile as well as the application task rates\naccordingly. Our proposed scheme meets the heterogeneous application\nrequirements with negligible overhead; reduces the data loss and packet delay;\nincreases the hardware component availability; and makes the components\navailable sooner as compared to the state-of-the-art.",
            "author": [
                "Chetna Singhal",
                "Subhrajit Barick",
                "Rishabh Sonkar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01050v1",
                "http://arxiv.org/pdf/2311.01050v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01049v1",
            "title": "Multi-dimensional data refining strategy for effective fine-tuning LLMs",
            "updated": "2023-11-02T07:50:43Z",
            "published": "2023-11-02T07:50:43Z",
            "summary": "Data is a cornerstone for fine-tuning large language models, yet acquiring\nsuitable data remains challenging. Challenges encompassed data scarcity,\nlinguistic diversity, and domain-specific content. This paper presents lessons\nlearned while crawling and refining data tailored for fine-tuning Vietnamese\nlanguage models. Crafting such a dataset, while accounting for linguistic\nintricacies and striking a balance between inclusivity and accuracy, demands\nmeticulous planning. Our paper presents a multidimensional strategy including\nleveraging existing datasets in the English language and developing customized\ndata-crawling scripts with the assistance of generative AI tools. A fine-tuned\nLLM model for the Vietnamese language, which was produced using resultant\ndatasets, demonstrated good performance while generating Vietnamese news\narticles from prompts. The study offers practical solutions and guidance for\nfuture fine-tuning models in languages like Vietnamese.",
            "author": [
                "Thanh Nguyen Ngoc",
                "Quang Nhat Tran",
                "Arthur Tang",
                "Bao Nguyen",
                "Thuy Nguyen",
                "Thanh Pham"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01049v1",
                "http://arxiv.org/pdf/2311.01049v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01048v1",
            "title": "AI-assisted Learning for Electronic Engineering Courses in High\n  Education",
            "updated": "2023-11-02T07:48:10Z",
            "published": "2023-11-02T07:48:10Z",
            "summary": "This study evaluates the efficacy of ChatGPT as an AI teaching and learning\nsupport tool in an integrated circuit systems course at a higher education\ninstitution in an Asian country. Various question types were completed, and\nChatGPT responses were assessed to gain valuable insights for further\ninvestigation. The objective is to assess ChatGPT's ability to provide\ninsights, personalized support, and interactive learning experiences in\nengineering education. The study includes the evaluation and reflection of\ndifferent stakeholders: students, lecturers, and engineers. The findings of\nthis study shed light on the benefits and limitations of ChatGPT as an AI tool,\npaving the way for innovative learning approaches in technical disciplines.\nFurthermore, the study contributes to our understanding of how digital\ntransformation is likely to unfold in the education sector.",
            "author": [
                "Thanh Nguyen Ngoc",
                "Quang Nhat Tran",
                "Arthur Tang",
                "Bao Nguyen",
                "Thuy Nguyen",
                "Thanh Pham"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01048v1",
                "http://arxiv.org/pdf/2311.01048v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01047v1",
            "title": "Improving Robustness via Tilted Exponential Layer: A\n  Communication-Theoretic Perspective",
            "updated": "2023-11-02T07:47:42Z",
            "published": "2023-11-02T07:47:42Z",
            "summary": "State-of-the-art techniques for enhancing robustness of deep networks mostly\nrely on empirical risk minimization with suitable data augmentation. In this\npaper, we propose a complementary approach motivated by communication theory,\naimed at enhancing the signal-to-noise ratio at the output of a neural network\nlayer via neural competition during learning and inference. In addition to\nminimization of a standard end-to-end cost, neurons compete to sparsely\nrepresent layer inputs by maximization of a tilted exponential (TEXP) objective\nfunction for the layer. TEXP learning can be interpreted as maximum likelihood\nestimation of matched filters under a Gaussian model for data noise. Inference\nin a TEXP layer is accomplished by replacing batch norm by a tilted softmax,\nwhich can be interpreted as computation of posterior probabilities for the\ncompeting signaling hypotheses represented by each neuron. After providing\ninsights via simplified models, we show, by experimentation on standard image\ndatasets, that TEXP learning and inference enhances robustness against noise\nand other common corruptions, without requiring data augmentation. Further\ncumulative gains in robustness against this array of distortions can be\nobtained by appropriately combining TEXP with data augmentation techniques.",
            "author": [
                "Bhagyashree Puranik",
                "Ahmad Beirami",
                "Yao Qin",
                "Upamanyu Madhow"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01047v1",
                "http://arxiv.org/pdf/2311.01047v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01046v1",
            "title": "Time-Independent Information-Theoretic Generalization Bounds for SGLD",
            "updated": "2023-11-02T07:42:23Z",
            "published": "2023-11-02T07:42:23Z",
            "summary": "We provide novel information-theoretic generalization bounds for stochastic\ngradient Langevin dynamics (SGLD) under the assumptions of smoothness and\ndissipativity, which are widely used in sampling and non-convex optimization\nstudies. Our bounds are time-independent and decay to zero as the sample size\nincreases, regardless of the number of iterations and whether the step size is\nfixed. Unlike previous studies, we derive the generalization error bounds by\nfocusing on the time evolution of the Kullback--Leibler divergence, which is\nrelated to the stability of datasets and is the upper bound of the mutual\ninformation between output parameters and an input dataset. Additionally, we\nestablish the first information-theoretic generalization bound when the\ntraining and test loss are the same by showing that a loss function of SGLD is\nsub-exponential. This bound is also time-independent and removes the\nproblematic step size dependence in existing work, leading to an improved\nexcess risk bound by combining our analysis with the existing non-convex\noptimization error bounds.",
            "author": [
                "Futoshi Futami",
                "Masahiro Fujisawa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01046v1",
                "http://arxiv.org/pdf/2311.01046v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01043v2",
            "title": "LLM4Drive: A Survey of Large Language Models for Autonomous Driving",
            "updated": "2023-11-27T05:43:45Z",
            "published": "2023-11-02T07:23:33Z",
            "summary": "Autonomous driving technology, a catalyst for revolutionizing transportation\nand urban mobility, has the tend to transition from rule-based systems to\ndata-driven strategies. Traditional module-based systems are constrained by\ncumulative errors among cascaded modules and inflexible pre-set rules. In\ncontrast, end-to-end autonomous driving systems have the potential to avoid\nerror accumulation due to their fully data-driven training process, although\nthey often lack transparency due to their \"black box\" nature, complicating the\nvalidation and traceability of decisions. Recently, large language models\n(LLMs) have demonstrated abilities including understanding context, logical\nreasoning, and generating answers. A natural thought is to utilize these\nabilities to empower autonomous driving. By combining LLM with foundation\nvision models, it could open the door to open-world understanding, reasoning,\nand few-shot learning, which current autonomous driving systems are lacking. In\nthis paper, we systematically review a research line about \\textit{Large\nLanguage Models for Autonomous Driving (LLM4AD)}. This study evaluates the\ncurrent state of technological advancements, distinctly outlining the principal\nchallenges and prospective directions for the field. For the convenience of\nresearchers in academia and industry, we provide real-time updates on the\nlatest advances in the field as well as relevant open-source resources via the\ndesignated link: https://github.com/Thinklab-SJTU/Awesome-LLM4AD.",
            "author": [
                "Zhenjie Yang",
                "Xiaosong Jia",
                "Hongyang Li",
                "Junchi Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01043v2",
                "http://arxiv.org/pdf/2311.01043v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01041v1",
            "title": "Learn to Refuse: Making Large Language Models More Controllable and\n  Reliable through Knowledge Scope Limitation and Refusal Mechanism",
            "updated": "2023-11-02T07:20:49Z",
            "published": "2023-11-02T07:20:49Z",
            "summary": "Large language models (LLMs) have demonstrated impressive language\nunderstanding and generation capabilities, enabling them to answer a wide range\nof questions across various domains. However, these models are not flawless and\noften produce responses that contain errors or misinformation. These\ninaccuracies, commonly referred to as hallucinations, render LLMs unreliable\nand even unusable in many scenarios. In this paper, our focus is on mitigating\nthe issue of hallucination in LLMs, particularly in the context of\nquestion-answering. Instead of attempting to answer all questions, we explore a\nrefusal mechanism that instructs LLMs to refuse to answer challenging questions\nin order to avoid errors. We then propose a simple yet effective solution\ncalled Learn to Refuse (L2R), which incorporates the refusal mechanism to\nenable LLMs to recognize and refuse to answer questions that they find\ndifficult to address. To achieve this, we utilize a structured knowledge base\nto represent all the LLM's understanding of the world, enabling it to provide\ntraceable gold knowledge. This knowledge base is separate from the LLM and\ninitially empty, and it is progressively expanded with validated knowledge.\nWhen an LLM encounters questions outside its domain, the system recognizes its\nknowledge scope and determines whether it can answer the question\nindependently. Additionally, we introduce a method for automatically and\nefficiently expanding the knowledge base of LLMs. Through qualitative and\nquantitative analysis, we demonstrate that our approach enhances the\ncontrollability and reliability of LLMs.",
            "author": [
                "Lang Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01041v1",
                "http://arxiv.org/pdf/2311.01041v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01038v2",
            "title": "Better with Less: A Data-Active Perspective on Pre-Training Graph Neural\n  Networks",
            "updated": "2023-11-21T05:48:06Z",
            "published": "2023-11-02T07:09:59Z",
            "summary": "Pre-training on graph neural networks (GNNs) aims to learn transferable\nknowledge for downstream tasks with unlabeled data, and it has recently become\nan active research area. The success of graph pre-training models is often\nattributed to the massive amount of input data. In this paper, however, we\nidentify the curse of big data phenomenon in graph pre-training: more training\ndata do not necessarily lead to better downstream performance. Motivated by\nthis observation, we propose a better-with-less framework for graph\npre-training: fewer, but carefully chosen data are fed into a GNN model to\nenhance pre-training. The proposed pre-training pipeline is called the\ndata-active graph pre-training (APT) framework, and is composed of a graph\nselector and a pre-training model. The graph selector chooses the most\nrepresentative and instructive data points based on the inherent properties of\ngraphs as well as predictive uncertainty. The proposed predictive uncertainty,\nas feedback from the pre-training model, measures the confidence level of the\nmodel in the data. When fed with the chosen data, on the other hand, the\npre-training model grasps an initial understanding of the new, unseen data, and\nat the same time attempts to remember the knowledge learned from previous data.\nTherefore, the integration and interaction between these two components form a\nunified framework (APT), in which graph pre-training is performed in a\nprogressive and iterative way. Experiment results show that the proposed APT is\nable to obtain an efficient pre-training model with fewer training data and\nbetter downstream performance.",
            "author": [
                "Jiarong Xu",
                "Renhong Huang",
                "Xin Jiang",
                "Yuxuan Cao",
                "Carl Yang",
                "Chunping Wang",
                "Yang Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01038v2",
                "http://arxiv.org/pdf/2311.01038v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01034v1",
            "title": "Learning to Adapt CLIP for Few-Shot Monocular Depth Estimation",
            "updated": "2023-11-02T06:56:50Z",
            "published": "2023-11-02T06:56:50Z",
            "summary": "Pre-trained Vision-Language Models (VLMs), such as CLIP, have shown enhanced\nperformance across a range of tasks that involve the integration of visual and\nlinguistic modalities. When CLIP is used for depth estimation tasks, the\npatches, divided from the input images, can be combined with a series of\nsemantic descriptions of the depth information to obtain similarity results.\nThe coarse estimation of depth is then achieved by weighting and summing the\ndepth values, called depth bins, corresponding to the predefined semantic\ndescriptions. The zero-shot approach circumvents the computational and\ntime-intensive nature of traditional fully-supervised depth estimation methods.\nHowever, this method, utilizing fixed depth bins, may not effectively\ngeneralize as images from different scenes may exhibit distinct depth\ndistributions. To address this challenge, we propose a few-shot-based method\nwhich learns to adapt the VLMs for monocular depth estimation to balance\ntraining costs and generalization capabilities. Specifically, it assigns\ndifferent depth bins for different scenes, which can be selected by the model\nduring inference. Additionally, we incorporate learnable prompts to preprocess\nthe input text to convert the easily human-understood text into easily\nmodel-understood vectors and further enhance the performance. With only one\nimage per scene for training, our extensive experiment results on the NYU V2\nand KITTI dataset demonstrate that our method outperforms the previous\nstate-of-the-art method by up to 10.6\\% in terms of MARE.",
            "author": [
                "Xueting Hu",
                "Ce Zhang",
                "Yi Zhang",
                "Bowen Hai",
                "Ke Yu",
                "Zhihai He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01034v1",
                "http://arxiv.org/pdf/2311.01034v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01033v1",
            "title": "Non-Autoregressive Diffusion-based Temporal Point Processes for\n  Continuous-Time Long-Term Event Prediction",
            "updated": "2023-11-02T06:52:44Z",
            "published": "2023-11-02T06:52:44Z",
            "summary": "Continuous-time long-term event prediction plays an important role in many\napplication scenarios. Most existing works rely on autoregressive frameworks to\npredict event sequences, which suffer from error accumulation, thus\ncompromising prediction quality. Inspired by the success of denoising diffusion\nprobabilistic models, we propose a diffusion-based non-autoregressive temporal\npoint process model for long-term event prediction in continuous time. Instead\nof generating events one at a time in an autoregressive way, our model predicts\nthe future event sequence entirely as a whole. In order to perform diffusion\nprocesses on event sequences, we develop a bidirectional map between target\nevent sequences and the Euclidean vector space. Furthermore, we design a novel\ndenoising network to capture both sequential and contextual features for better\nsample quality. Extensive experiments are conducted to prove the superiority of\nour proposed model over state-of-the-art methods on long-term event prediction\nin continuous time. To the best of our knowledge, this is the first work to\napply diffusion methods to long-term event prediction problems.",
            "author": [
                "Wang-Tao Zhou",
                "Zhao Kang",
                "Ling Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01033v1",
                "http://arxiv.org/pdf/2311.01033v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01030v1",
            "title": "Joint Learning of Local and Global Features for Aspect-based Sentiment\n  Classification",
            "updated": "2023-11-02T06:43:50Z",
            "published": "2023-11-02T06:43:50Z",
            "summary": "Aspect-based sentiment classification (ASC) aims to judge the sentiment\npolarity conveyed by the given aspect term in a sentence. The sentiment\npolarity is not only determined by the local context but also related to the\nwords far away from the given aspect term. Most recent efforts related to the\nattention-based models can not sufficiently distinguish which words they should\npay more attention to in some cases. Meanwhile, graph-based models are coming\ninto ASC to encode syntactic dependency tree information. But these models do\nnot fully leverage syntactic dependency trees as they neglect to incorporate\ndependency relation tag information into representation learning effectively.\nIn this paper, we address these problems by effectively modeling the local and\nglobal features. Firstly, we design a local encoder containing: a Gaussian mask\nlayer and a covariance self-attention layer. The Gaussian mask layer tends to\nadjust the receptive field around aspect terms adaptively to deemphasize the\neffects of unrelated words and pay more attention to local information. The\ncovariance self-attention layer can distinguish the attention weights of\ndifferent words more obviously. Furthermore, we propose a dual-level graph\nattention network as a global encoder by fully employing dependency tag\ninformation to capture long-distance information effectively. Our model\nachieves state-of-the-art performance on both SemEval 2014 and Twitter\ndatasets.",
            "author": [
                "Hao Niu",
                "Yun Xiong",
                "Xiaosu Wang",
                "Philip S. Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01030v1",
                "http://arxiv.org/pdf/2311.01030v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01028v1",
            "title": "Nonnegative/Binary Matrix Factorization for Image Classification using\n  Quantum Annealing",
            "updated": "2023-11-02T06:41:27Z",
            "published": "2023-11-02T06:41:27Z",
            "summary": "Classical computing has borne witness to the development of machine learning.\nThe integration of quantum technology into this mix will lead to unimaginable\nbenefits and be regarded as a giant leap forward in mankind's ability to\ncompute. Demonstrating the benefits of this integration now becomes essential.\nWith the advance of quantum computing, several machine-learning techniques have\nbeen proposed that use quantum annealing. In this study, we implement a matrix\nfactorization method using quantum annealing for image classification and\ncompare the performance with traditional machine-learning methods.\nNonnegative/binary matrix factorization (NBMF) was originally introduced as a\ngenerative model, and we propose a multiclass classification model as an\napplication. We extract the features of handwritten digit images using NBMF and\napply them to solve the classification problem. Our findings show that when the\namount of data, features, and epochs is small, the accuracy of models trained\nby NBMF is superior to classical machine-learning methods, such as neural\nnetworks. Moreover, we found that training models using a quantum annealing\nsolver significantly reduces computation time. Under certain conditions, there\nis a benefit to using quantum annealing technology with machine learning.",
            "author": [
                "Hinako Asaoka",
                "Kazue Kudo"
            ],
            "link": [
                "http://dx.doi.org/10.1038/s41598-023-43729-z",
                "http://arxiv.org/abs/2311.01028v1",
                "http://arxiv.org/pdf/2311.01028v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01024v1",
            "title": "Distance-Based Propagation for Efficient Knowledge Graph Reasoning",
            "updated": "2023-11-02T06:37:46Z",
            "published": "2023-11-02T06:37:46Z",
            "summary": "Knowledge graph completion (KGC) aims to predict unseen edges in knowledge\ngraphs (KGs), resulting in the discovery of new facts. A new class of methods\nhave been proposed to tackle this problem by aggregating path information.\nThese methods have shown tremendous ability in the task of KGC. However they\nare plagued by efficiency issues. Though there are a few recent attempts to\naddress this through learnable path pruning, they often sacrifice the\nperformance to gain efficiency. In this work, we identify two intrinsic\nlimitations of these methods that affect the efficiency and representation\nquality. To address the limitations, we introduce a new method, TAGNet, which\nis able to efficiently propagate information. This is achieved by only\naggregating paths in a fixed window for each source-target pair. We demonstrate\nthat the complexity of TAGNet is independent of the number of layers. Extensive\nexperiments demonstrate that TAGNet can cut down on the number of propagated\nmessages by as much as 90% while achieving competitive performance on multiple\nKG datasets. The code is available at https://github.com/HarryShomer/TAGNet.",
            "author": [
                "Harry Shomer",
                "Yao Ma",
                "Juanhui Li",
                "Bo Wu",
                "Charu C. Aggarwal",
                "Jiliang Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01024v1",
                "http://arxiv.org/pdf/2311.01024v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01023v1",
            "title": "Augmentation is AUtO-Net: Augmentation-Driven Contrastive Multiview\n  Learning for Medical Image Segmentation",
            "updated": "2023-11-02T06:31:08Z",
            "published": "2023-11-02T06:31:08Z",
            "summary": "The utilisation of deep learning segmentation algorithms that learn complex\norgans and tissue patterns and extract essential regions of interest from the\nnoisy background to improve the visual ability for medical image diagnosis has\nachieved impressive results in Medical Image Computing (MIC). This thesis\nfocuses on retinal blood vessel segmentation tasks, providing an extensive\nliterature review of deep learning-based medical image segmentation approaches\nwhile comparing the methodologies and empirical performances. The work also\nexamines the limitations of current state-of-the-art methods by pointing out\nthe two significant existing limitations: data size constraints and the\ndependency on high computational resources. To address such problems, this work\nproposes a novel efficient, simple multiview learning framework that\ncontrastively learns invariant vessel feature representation by comparing with\nmultiple augmented views by various transformations to overcome data shortage\nand improve generalisation ability. Moreover, the hybrid network architecture\nintegrates the attention mechanism into a Convolutional Neural Network to\nfurther capture complex continuous curvilinear vessel structures. The result\ndemonstrates the proposed method validated on the CHASE-DB1 dataset, attaining\nthe highest F1 score of 83.46% and the highest Intersection over Union (IOU)\nscore of 71.62% with UNet structure, surpassing existing benchmark UNet-based\nmethods by 1.95% and 2.8%, respectively. The combination of the metrics\nindicates the model detects the vessel object accurately with a highly\ncoincidental location with the ground truth. Moreover, the proposed approach\ncould be trained within 30 minutes by consuming less than 3 GB GPU RAM, and\nsuch characteristics support the efficient implementation for real-world\napplications and deployments.",
            "author": [
                "Yanming Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01023v1",
                "http://arxiv.org/pdf/2311.01023v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01022v1",
            "title": "NeuroWrite: Predictive Handwritten Digit Classification using Deep\n  Neural Networks",
            "updated": "2023-11-02T06:29:53Z",
            "published": "2023-11-02T06:29:53Z",
            "summary": "The rapid evolution of deep neural networks has revolutionized the field of\nmachine learning, enabling remarkable advancements in various domains. In this\narticle, we introduce NeuroWrite, a unique method for predicting the\ncategorization of handwritten digits using deep neural networks. Our model\nexhibits outstanding accuracy in identifying and categorising handwritten\ndigits by utilising the strength of convolutional neural networks (CNNs) and\nrecurrent neural networks (RNNs).In this article, we give a thorough\nexamination of the data preparation methods, network design, and training\nmethods used in NeuroWrite. By implementing state-of-the-art techniques, we\nshowcase how NeuroWrite can achieve high classification accuracy and robust\ngeneralization on handwritten digit datasets, such as MNIST. Furthermore, we\nexplore the model's potential for real-world applications, including digit\nrecognition in digitized documents, signature verification, and automated\npostal code recognition. NeuroWrite is a useful tool for computer vision and\npattern recognition because of its performance and adaptability.The\narchitecture, training procedure, and evaluation metrics of NeuroWrite are\ncovered in detail in this study, illustrating how it can improve a number of\napplications that call for handwritten digit classification. The outcomes show\nthat NeuroWrite is a promising method for raising the bar for deep neural\nnetwork-based handwritten digit recognition.",
            "author": [
                "Kottakota Asish",
                "P. Sarath Teja",
                "R. Kishan Chander",
                "Dr. D. Deva Hema"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01022v1",
                "http://arxiv.org/pdf/2311.01022v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "68T10, 68T45, 68T60",
                "I.4.8; I.5.2; J.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01020v1",
            "title": "On the Concerns of Developers When Using GitHub Copilot",
            "updated": "2023-11-02T06:24:38Z",
            "published": "2023-11-02T06:24:38Z",
            "summary": "With the recent advancement of Artificial Intelligence (AI) and the emergence\nof Large Language Models (LLMs), AI-based code generation tools have achieved\nsignificant progress and become a practical solution for software development.\nGitHub Copilot, referred to as AI pair programmer, utilizes machine learning\nmodels that are trained on a large corpus of code snippets to generate code\nsuggestions or auto-complete code using natural language processing. Despite\nits popularity, there is little empirical evidence on the actual experiences of\nsoftware developers who work with Copilot. To this end, we conducted an\nempirical study to understand the issues and challenges that developers face\nwhen using Copilot in practice, as well as their underlying causes and\npotential solutions. We collected data from 476 GitHub issues, 706 GitHub\ndiscussions, and 184 Stack Overflow posts, and identified the issues, causes\nthat trigger the issues, and solutions that resolve the issues when using\nCopilot. Our results reveal that (1) Usage Issue and Compatibility Issue are\nthe most common problems faced by Copilot users, (2) Copilot Internal Issue,\nNetwork Connection Issue, and Editor/IDE Compatibility Issue are identified as\nthe most frequent causes, and (3) Bug Fixed by Copilot, Modify\nConfiguration/Setting, and Use Suitable Version are the predominant solutions.\nBased on the results, we delve into the main challenges users encounter when\nimplementing Copilot in practical development, the possible impact of Copilot\non the coding process, aspects in which Copilot can be further enhanced, and\npotential new features desired by Copilot users.",
            "author": [
                "Xiyu Zhou",
                "Peng Liang",
                "Beiqi Zhang",
                "Zengyang Li",
                "Aakash Ahmad",
                "Mojtaba Shahin",
                "Muhammad Waseem"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01020v1",
                "http://arxiv.org/pdf/2311.01020v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01017v2",
            "title": "Learning Unsupervised World Models for Autonomous Driving via Discrete\n  Diffusion",
            "updated": "2023-11-24T00:24:06Z",
            "published": "2023-11-02T06:21:56Z",
            "summary": "Learning world models can teach an agent how the world works in an\nunsupervised manner. Even though it can be viewed as a special case of sequence\nmodeling, progress for scaling world models on robotic applications such as\nautonomous driving has been somewhat less rapid than scaling language models\nwith Generative Pre-trained Transformers (GPT). We identify two reasons as\nmajor bottlenecks: dealing with complex and unstructured observation space, and\nhaving a scalable generative model. Consequently, we propose a novel world\nmodeling approach that first tokenizes sensor observations with VQVAE, then\npredicts the future via discrete diffusion. To efficiently decode and denoise\ntokens in parallel, we recast Masked Generative Image Transformer into the\ndiscrete diffusion framework with a few simple changes, resulting in notable\nimprovement. When applied to learning world models on point cloud observations,\nour model reduces prior SOTA Chamfer distance by more than 65% for 1s\nprediction, and more than 50% for 3s prediction, across NuScenes, KITTI\nOdometry, and Argoverse2 datasets. Our results demonstrate that discrete\ndiffusion on tokenized agent experience can unlock the power of GPT-like\nunsupervised learning for robotic agents.",
            "author": [
                "Lunjun Zhang",
                "Yuwen Xiong",
                "Ze Yang",
                "Sergio Casas",
                "Rui Hu",
                "Raquel Urtasun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01017v2",
                "http://arxiv.org/pdf/2311.01017v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01011v1",
            "title": "Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game",
            "updated": "2023-11-02T06:13:36Z",
            "published": "2023-11-02T06:13:36Z",
            "summary": "While Large Language Models (LLMs) are increasingly being used in real-world\napplications, they remain vulnerable to prompt injection attacks: malicious\nthird party prompts that subvert the intent of the system designer. To help\nresearchers study this problem, we present a dataset of over 126,000 prompt\ninjection attacks and 46,000 prompt-based \"defenses\" against prompt injection,\nall created by players of an online game called Tensor Trust. To the best of\nour knowledge, this is currently the largest dataset of human-generated\nadversarial examples for instruction-following LLMs. The attacks in our dataset\nhave a lot of easily interpretable stucture, and shed light on the weaknesses\nof LLMs. We also use the dataset to create a benchmark for resistance to two\ntypes of prompt injection, which we refer to as prompt extraction and prompt\nhijacking. Our benchmark results show that many models are vulnerable to the\nattack strategies in the Tensor Trust dataset. Furthermore, we show that some\nattack strategies from the dataset generalize to deployed LLM-based\napplications, even though they have a very different set of constraints to the\ngame. We release all data and source code at https://tensortrust.ai/paper",
            "author": [
                "Sam Toyer",
                "Olivia Watkins",
                "Ethan Adrian Mendes",
                "Justin Svegliato",
                "Luke Bailey",
                "Tiffany Wang",
                "Isaac Ong",
                "Karim Elmaaroufi",
                "Pieter Abbeel",
                "Trevor Darrell",
                "Alan Ritter",
                "Stuart Russell"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01011v1",
                "http://arxiv.org/pdf/2311.01011v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01010v1",
            "title": "Exploring Unified Perspective For Fast Shapley Value Estimation",
            "updated": "2023-11-02T06:09:24Z",
            "published": "2023-11-02T06:09:24Z",
            "summary": "Shapley values have emerged as a widely accepted and trustworthy tool,\ngrounded in theoretical axioms, for addressing challenges posed by black-box\nmodels like deep neural networks. However, computing Shapley values encounters\nexponential complexity in the number of features. Various approaches, including\nApproSemivalue, KernelSHAP, and FastSHAP, have been explored to expedite the\ncomputation. We analyze the consistency of existing works and conclude that\nstochastic estimators can be unified as the linear transformation of importance\nsampling of feature subsets. Based on this, we investigate the possibility of\ndesigning simple amortized estimators and propose a straightforward and\nefficient one, SimSHAP, by eliminating redundant techniques. Extensive\nexperiments conducted on tabular and image datasets validate the effectiveness\nof our SimSHAP, which significantly accelerates the computation of accurate\nShapley values.",
            "author": [
                "Borui Zhang",
                "Baotong Tian",
                "Wenzhao Zheng",
                "Jie Zhou",
                "Jiwen Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01010v1",
                "http://arxiv.org/pdf/2311.01010v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01009v1",
            "title": "Revamping AI Models in Dermatology: Overcoming Critical Challenges for\n  Enhanced Skin Lesion Diagnosis",
            "updated": "2023-11-02T06:08:49Z",
            "published": "2023-11-02T06:08:49Z",
            "summary": "The surge in developing deep learning models for diagnosing skin lesions\nthrough image analysis is notable, yet their clinical black faces challenges.\nCurrent dermatology AI models have limitations: limited number of possible\ndiagnostic outputs, lack of real-world testing on uncommon skin lesions,\ninability to detect out-of-distribution images, and over-reliance on\ndermoscopic images. To address these, we present an All-In-One\n\\textbf{H}ierarchical-\\textbf{O}ut of Distribution-\\textbf{C}linical Triage\n(HOT) model. For a clinical image, our model generates three outputs: a\nhierarchical prediction, an alert for out-of-distribution images, and a\nrecommendation for dermoscopy if clinical image alone is insufficient for\ndiagnosis. When the recommendation is pursued, it integrates both clinical and\ndermoscopic images to deliver final diagnosis. Extensive experiments on a\nrepresentative cutaneous lesion dataset demonstrate the effectiveness and\nsynergy of each component within our framework. Our versatile model provides\nvaluable decision support for lesion diagnosis and sets a promising precedent\nfor medical AI applications.",
            "author": [
                "Deval Mehta",
                "Brigid Betz-Stablein",
                "Toan D Nguyen",
                "Yaniv Gal",
                "Adrian Bowling",
                "Martin Haskett",
                "Maithili Sashindranath",
                "Paul Bonnington",
                "Victoria Mar",
                "H Peter Soyer",
                "Zongyuan Ge"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01009v1",
                "http://arxiv.org/pdf/2311.01009v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01007v2",
            "title": "Effective Human-AI Teams via Learned Natural Language Rules and\n  Onboarding",
            "updated": "2023-11-07T20:34:09Z",
            "published": "2023-11-02T06:00:48Z",
            "summary": "People are relying on AI agents to assist them with various tasks. The human\nmust know when to rely on the agent, collaborate with the agent, or ignore its\nsuggestions. In this work, we propose to learn rules, grounded in data regions\nand described in natural language, that illustrate how the human should\ncollaborate with the AI. Our novel region discovery algorithm finds local\nregions in the data as neighborhoods in an embedding space where prior human\nbehavior should be corrected. Each region is then described using a large\nlanguage model in an iterative and contrastive procedure. We then teach these\nrules to the human via an onboarding stage. Through user studies on object\ndetection and question-answering tasks, we show that our method can lead to\nmore accurate human-AI teams. We also evaluate our region discovery and\ndescription algorithms separately.",
            "author": [
                "Hussein Mozannar",
                "Jimin J Lee",
                "Dennis Wei",
                "Prasanna Sattigeri",
                "Subhro Das",
                "David Sontag"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01007v2",
                "http://arxiv.org/pdf/2311.01007v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01004v1",
            "title": "Sam-Guided Enhanced Fine-Grained Encoding with Mixed Semantic Learning\n  for Medical Image Captioning",
            "updated": "2023-11-02T05:44:13Z",
            "published": "2023-11-02T05:44:13Z",
            "summary": "With the development of multimodality and large language models, the deep\nlearning-based technique for medical image captioning holds the potential to\noffer valuable diagnostic recommendations. However, current generic text and\nimage pre-trained models do not yield satisfactory results when it comes to\ndescribing intricate details within medical images. In this paper, we present a\nnovel medical image captioning method guided by the segment anything model\n(SAM) to enable enhanced encoding with both general and detailed feature\nextraction. In addition, our approach employs a distinctive pre-training\nstrategy with mixed semantic learning to simultaneously capture both the\noverall information and finer details within medical images. We demonstrate the\neffectiveness of this approach, as it outperforms the pre-trained BLIP2 model\non various evaluation metrics for generating descriptions of medical images.",
            "author": [
                "Gaoang Wang",
                "Zhenyu Zhang",
                "Benlu Wang",
                "Weijie Liang",
                "Yizhi Li",
                "Xuechen Guo",
                "Guanhong Wang",
                "Shiyan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01004v1",
                "http://arxiv.org/pdf/2311.01004v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01002v1",
            "title": "Robust Data Pruning under Label Noise via Maximizing Re-labeling\n  Accuracy",
            "updated": "2023-11-02T05:40:26Z",
            "published": "2023-11-02T05:40:26Z",
            "summary": "Data pruning, which aims to downsize a large training set into a small\ninformative subset, is crucial for reducing the enormous computational costs of\nmodern deep learning. Though large-scale data collections invariably contain\nannotation noise and numerous robust learning methods have been developed, data\npruning for the noise-robust learning scenario has received little attention.\nWith state-of-the-art Re-labeling methods that self-correct erroneous labels\nwhile training, it is challenging to identify which subset induces the most\naccurate re-labeling of erroneous labels in the entire training set. In this\npaper, we formalize the problem of data pruning with re-labeling. We first show\nthat the likelihood of a training example being correctly re-labeled is\nproportional to the prediction confidence of its neighborhood in the subset.\nTherefore, we propose a novel data pruning algorithm, Prune4Rel, that finds a\nsubset maximizing the total neighborhood confidence of all training examples,\nthereby maximizing the re-labeling accuracy and generalization performance.\nExtensive experiments on four real and one synthetic noisy datasets show that\n\\algname{} outperforms the baselines with Re-labeling models by up to 9.1% as\nwell as those with a standard model by up to 21.6%.",
            "author": [
                "Dongmin Park",
                "Seola Choi",
                "Doyoung Kim",
                "Hwanjun Song",
                "Jae-Gil Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01002v1",
                "http://arxiv.org/pdf/2311.01002v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.01479v2",
            "title": "Detecting Out-of-Distribution Through the Lens of Neural Collapse",
            "updated": "2023-11-07T01:40:19Z",
            "published": "2023-11-02T05:18:28Z",
            "summary": "Out-of-distribution (OOD) detection is essential for the safe deployment of\nAI. Particularly, OOD detectors should generalize effectively across diverse\nscenarios. To improve upon the generalizability of existing OOD detectors, we\nintroduce a highly versatile OOD detector, called Neural Collapse inspired OOD\ndetector (NC-OOD). We extend the prevalent observation that in-distribution\n(ID) features tend to form clusters, whereas OOD features are far away.\nParticularly, based on the recent observation, Neural Collapse, we further\ndemonstrate that ID features tend to cluster in proximity to weight vectors.\nFrom our extended observation, we propose to detect OOD based on feature\nproximity to weight vectors. To further rule out OOD samples, we leverage the\nobservation that OOD features tend to reside closer to the origin than ID\nfeatures. Extensive experiments show that our approach enhances the\ngeneralizability of existing work and can consistently achieve state-of-the-art\nOOD detection performance across a wide range of OOD Benchmarks over different\nclassification tasks, training losses, and model architectures.",
            "author": [
                "Litian Liu",
                "Yao Qin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.01479v2",
                "http://arxiv.org/pdf/2311.01479v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00994v1",
            "title": "LaughTalk: Expressive 3D Talking Head Generation with Laughter",
            "updated": "2023-11-02T05:04:33Z",
            "published": "2023-11-02T05:04:33Z",
            "summary": "Laughter is a unique expression, essential to affirmative social interactions\nof humans. Although current 3D talking head generation methods produce\nconvincing verbal articulations, they often fail to capture the vitality and\nsubtleties of laughter and smiles despite their importance in social context.\nIn this paper, we introduce a novel task to generate 3D talking heads capable\nof both articulate speech and authentic laughter. Our newly curated dataset\ncomprises 2D laughing videos paired with pseudo-annotated and human-validated\n3D FLAME parameters and vertices. Given our proposed dataset, we present a\nstrong baseline with a two-stage training scheme: the model first learns to\ntalk and then acquires the ability to express laughter. Extensive experiments\ndemonstrate that our method performs favorably compared to existing approaches\nin both talking head generation and expressing laughter signals. We further\nexplore potential applications on top of our proposed method for rigging\nrealistic avatars.",
            "author": [
                "Kim Sung-Bin",
                "Lee Hyun",
                "Da Hye Hong",
                "Suekyeong Nam",
                "Janghoon Ju",
                "Tae-Hyun Oh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00994v1",
                "http://arxiv.org/pdf/2311.00994v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14681v1",
            "title": "Instance-Specific Asymmetric Sensitivity in Differential Privacy",
            "updated": "2023-11-02T05:01:45Z",
            "published": "2023-11-02T05:01:45Z",
            "summary": "We provide a new algorithmic framework for differentially private estimation\nof general functions that adapts to the hardness of the underlying dataset. We\nbuild upon previous work that gives a paradigm for selecting an output through\nthe exponential mechanism based upon closeness of the inverse to the underlying\ndataset, termed the inverse sensitivity mechanism. Our framework will slightly\nmodify the closeness metric and instead give a simple and efficient application\nof the sparse vector technique. While the inverse sensitivity mechanism was\nshown to be instance optimal, it was only with respect to a class of unbiased\nmechanisms such that the most likely outcome matches the underlying data. We\nbreak this assumption in order to more naturally navigate the bias-variance\ntradeoff, which will also critically allow for extending our method to\nunbounded data. In consideration of this tradeoff, we provide strong intuition\nand empirical validation that our technique will be particularly effective when\nthe distances to the underlying dataset are asymmetric. This asymmetry is\ninherent to a range of important problems including fundamental statistics such\nas variance, as well as commonly used machine learning performance metrics for\nboth classification and regression tasks. We efficiently instantiate our method\nin $O(n)$ time for these problems and empirically show that our techniques will\ngive substantially improved differentially private estimations.",
            "author": [
                "David Durfee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14681v1",
                "http://arxiv.org/pdf/2311.14681v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00993v1",
            "title": "Scalable Probabilistic Forecasting in Retail with Gradient Boosted\n  Trees: A Practitioner's Approach",
            "updated": "2023-11-02T04:46:32Z",
            "published": "2023-11-02T04:46:32Z",
            "summary": "The recent M5 competition has advanced the state-of-the-art in retail\nforecasting. However, we notice important differences between the competition\nchallenge and the challenges we face in a large e-commerce company. The\ndatasets in our scenario are larger (hundreds of thousands of time series), and\ne-commerce can afford to have a larger assortment than brick-and-mortar\nretailers, leading to more intermittent data. To scale to larger dataset sizes\nwith feasible computational effort, firstly, we investigate a two-layer\nhierarchy and propose a top-down approach to forecasting at an aggregated level\nwith less amount of series and intermittency, and then disaggregating to obtain\nthe decision-level forecasts. Probabilistic forecasts are generated under\ndistributional assumptions. Secondly, direct training at the lower level with\nsubsamples can also be an alternative way of scaling. Performance of modelling\nwith subsets is evaluated with the main dataset. Apart from a proprietary\ndataset, the proposed scalable methods are evaluated using the Favorita dataset\nand the M5 dataset. We are able to show the differences in characteristics of\nthe e-commerce and brick-and-mortar retail datasets. Notably, our top-down\nforecasting framework enters the top 50 of the original M5 competition, even\nwith models trained at a higher level under a much simpler setting.",
            "author": [
                "Xueying Long",
                "Quang Bui",
                "Grady Oktavian",
                "Daniel F. Schmidt",
                "Christoph Bergmeir",
                "Rakshitha Godahewa",
                "Seong Per Lee",
                "Kaifeng Zhao",
                "Paul Condylis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00993v1",
                "http://arxiv.org/pdf/2311.00993v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00987v1",
            "title": "CML-MOTS: Collaborative Multi-task Learning for Multi-Object Tracking\n  and Segmentation",
            "updated": "2023-11-02T04:32:24Z",
            "published": "2023-11-02T04:32:24Z",
            "summary": "The advancement of computer vision has pushed visual analysis tasks from\nstill images to the video domain. In recent years, video instance segmentation,\nwhich aims to track and segment multiple objects in video frames, has drawn\nmuch attention for its potential applications in various emerging areas such as\nautonomous driving, intelligent transportation, and smart retail. In this\npaper, we propose an effective framework for instance-level visual analysis on\nvideo frames, which can simultaneously conduct object detection, instance\nsegmentation, and multi-object tracking. The core idea of our method is\ncollaborative multi-task learning which is achieved by a novel structure, named\nassociative connections among detection, segmentation, and tracking task heads\nin an end-to-end learnable CNN. These additional connections allow information\npropagation across multiple related tasks, so as to benefit these tasks\nsimultaneously. We evaluate the proposed method extensively on KITTI MOTS and\nMOTS Challenge datasets and obtain quite encouraging results.",
            "author": [
                "Yiming Cui",
                "Cheng Han",
                "Dongfang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00987v1",
                "http://arxiv.org/pdf/2311.00987v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    }
]