[
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18471v2",
            "title": "Causal disentanglement of multimodal data",
            "updated": "2023-11-08T18:54:52Z",
            "published": "2023-10-27T20:30:11Z",
            "summary": "Causal representation learning algorithms discover lower-dimensional\nrepresentations of data that admit a decipherable interpretation of cause and\neffect; as achieving such interpretable representations is challenging, many\ncausal learning algorithms utilize elements indicating prior information, such\nas (linear) structural causal models, interventional data, or weak supervision.\nUnfortunately, in exploratory causal representation learning, such elements and\nprior information may not be available or warranted. Alternatively, scientific\ndatasets often have multiple modalities or physics-based constraints, and the\nuse of such scientific, multimodal data has been shown to improve\ndisentanglement in fully unsupervised settings. Consequently, we introduce a\ncausal representation learning algorithm (causalPIMA) that can use multimodal\ndata and known physics to discover important features with causal\nrelationships. Our innovative algorithm utilizes a new differentiable\nparametrization to learn a directed acyclic graph (DAG) together with a latent\nspace of a variational autoencoder in an end-to-end differentiable framework\nvia a single, tractable evidence lower bound loss function. We place a Gaussian\nmixture prior on the latent space and identify each of the mixtures with an\noutcome of the DAG nodes; this novel identification enables feature discovery\nwith causal relationships. Tested against a synthetic and a scientific dataset,\nour results demonstrate the capability of learning an interpretable causal\nstructure while simultaneously discovering key features in a fully unsupervised\nsetting.",
            "author": [
                "Elise Walker",
                "Jonas A. Actor",
                "Carianne Martinez",
                "Nathaniel Trask"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18471v2",
                "http://arxiv.org/pdf/2310.18471v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML",
                "68T07"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18469v1",
            "title": "Semi-Synthetic Dataset Augmentation for Application-Specific Gaze\n  Estimation",
            "updated": "2023-10-27T20:27:22Z",
            "published": "2023-10-27T20:27:22Z",
            "summary": "Although the number of gaze estimation datasets is growing, the application\nof appearance-based gaze estimation methods is mostly limited to estimating the\npoint of gaze on a screen. This is in part because most datasets are generated\nin a similar fashion, where the gaze target is on a screen close to camera's\norigin. In other applications such as assistive robotics or marketing research,\nthe 3D point of gaze might not be close to the camera's origin, meaning models\ntrained on current datasets do not generalize well to these tasks. We therefore\nsuggest generating a textured tridimensional mesh of the face and rendering the\ntraining images from a virtual camera at a specific position and orientation\nrelated to the application as a mean of augmenting the existing datasets. In\nour tests, this lead to an average 47% decrease in gaze estimation angular\nerror.",
            "author": [
                "Cedric Leblond-Menard",
                "Gabriel Picard-Krashevski",
                "Sofiane Achiche"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18469v1",
                "http://arxiv.org/pdf/2310.18469v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18465v1",
            "title": "Minimax Optimal Submodular Optimization with Bandit Feedback",
            "updated": "2023-10-27T20:19:03Z",
            "published": "2023-10-27T20:19:03Z",
            "summary": "We consider maximizing a monotonic, submodular set function $f: 2^{[n]}\n\\rightarrow [0,1]$ under stochastic bandit feedback. Specifically, $f$ is\nunknown to the learner but at each time $t=1,\\dots,T$ the learner chooses a set\n$S_t \\subset [n]$ with $|S_t| \\leq k$ and receives reward $f(S_t) + \\eta_t$\nwhere $\\eta_t$ is mean-zero sub-Gaussian noise. The objective is to minimize\nthe learner's regret over $T$ times with respect to ($1-e^{-1}$)-approximation\nof maximum $f(S_*)$ with $|S_*| = k$, obtained through greedy maximization of\n$f$. To date, the best regret bound in the literature scales as $k n^{1/3}\nT^{2/3}$. And by trivially treating every set as a unique arm one deduces that\n$\\sqrt{ {n \\choose k} T }$ is also achievable. In this work, we establish the\nfirst minimax lower bound for this setting that scales like\n$\\mathcal{O}(\\min_{i \\le k}(in^{1/3}T^{2/3} + \\sqrt{n^{k-i}T}))$. Moreover, we\npropose an algorithm that is capable of matching the lower bound regret.",
            "author": [
                "Artin Tajdini",
                "Lalit Jain",
                "Kevin Jamieson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18465v1",
                "http://arxiv.org/pdf/2310.18465v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18459v1",
            "title": "VFAS-Grasp: Closed Loop Grasping with Visual Feedback and Adaptive\n  Sampling",
            "updated": "2023-10-27T20:12:30Z",
            "published": "2023-10-27T20:12:30Z",
            "summary": "We consider the problem of closed-loop robotic grasping and present a novel\nplanner which uses Visual Feedback and an uncertainty-aware Adaptive Sampling\nstrategy (VFAS) to close the loop. At each iteration, our method VFAS-Grasp\nbuilds a set of candidate grasps by generating random perturbations of a seed\ngrasp. The candidates are then scored using a novel metric which combines a\nlearned grasp-quality estimator, the uncertainty in the estimate and the\ndistance from the seed proposal to promote temporal consistency. Additionally,\nwe present two mechanisms to improve the efficiency of our sampling strategy:\nWe dynamically scale the sampling region size and number of samples in it based\non past grasp scores. We also leverage a motion vector field estimator to shift\nthe center of our sampling region. We demonstrate that our algorithm can run in\nreal time (20 Hz) and is capable of improving grasp performance for static\nscenes by refining the initial grasp proposal. We also show that it can enable\ngrasping of slow moving objects, such as those encountered during human to\nrobot handover.",
            "author": [
                "Pedro Piacenza",
                "Jiacheng Yuan",
                "Jinwook Huh",
                "Volkan Isler"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18459v1",
                "http://arxiv.org/pdf/2310.18459v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18457v1",
            "title": "LLMSTEP: LLM proofstep suggestions in Lean",
            "updated": "2023-10-27T20:10:56Z",
            "published": "2023-10-27T20:10:56Z",
            "summary": "We present LLMSTEP, a tool for integrating a language model into the Lean\nproof assistant. LLMSTEP is a Lean 4 tactic that sends a user's proof state to\na server hosting a language model. The language model generates suggestions,\nwhich are checked in Lean and displayed to a user in their development\nenvironment. We provide a baseline language model, along with code for\nfine-tuning and evaluation to support further development. We provide server\nimplementations that run on CPU, a CUDA GPU, or a Google Colab notebook, as a\nstep towards fast, effective language model suggestions for any user.",
            "author": [
                "Sean Welleck",
                "Rahul Saha"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18457v1",
                "http://arxiv.org/pdf/2310.18457v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "I.2.2; I.2.5; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18455v1",
            "title": "Approximate Heavy Tails in Offline (Multi-Pass) Stochastic Gradient\n  Descent",
            "updated": "2023-10-27T20:06:03Z",
            "published": "2023-10-27T20:06:03Z",
            "summary": "A recent line of empirical studies has demonstrated that SGD might exhibit a\nheavy-tailed behavior in practical settings, and the heaviness of the tails\nmight correlate with the overall performance. In this paper, we investigate the\nemergence of such heavy tails. Previous works on this problem only considered,\nup to our knowledge, online (also called single-pass) SGD, in which the\nemergence of heavy tails in theoretical findings is contingent upon access to\nan infinite amount of data. Hence, the underlying mechanism generating the\nreported heavy-tailed behavior in practical settings, where the amount of\ntraining data is finite, is still not well-understood. Our contribution aims to\nfill this gap. In particular, we show that the stationary distribution of\noffline (also called multi-pass) SGD exhibits 'approximate' power-law tails and\nthe approximation error is controlled by how fast the empirical distribution of\nthe training data converges to the true underlying data distribution in the\nWasserstein metric. Our main takeaway is that, as the number of data points\nincreases, offline SGD will behave increasingly 'power-law-like'. To achieve\nthis result, we first prove nonasymptotic Wasserstein convergence bounds for\noffline SGD to online SGD as the number of data points increases, which can be\ninteresting on their own. Finally, we illustrate our theory on various\nexperiments conducted on synthetic data and neural networks.",
            "author": [
                "Krunoslav Lehman Pavasovic",
                "Alain Durmus",
                "Umut Simsekli"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18455v1",
                "http://arxiv.org/pdf/2310.18455v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18454v1",
            "title": "T5 meets Tybalt: Author Attribution in Early Modern English Drama Using\n  Large Language Models",
            "updated": "2023-10-27T20:04:57Z",
            "published": "2023-10-27T20:04:57Z",
            "summary": "Large language models have shown breakthrough potential in many NLP domains.\nHere we consider their use for stylometry, specifically authorship\nidentification in Early Modern English drama. We find both promising and\nconcerning results; LLMs are able to accurately predict the author of\nsurprisingly short passages but are also prone to confidently misattribute\ntexts to specific authors. A fine-tuned t5-large model outperforms all tested\nbaselines, including logistic regression, SVM with a linear kernel, and cosine\ndelta, at attributing small passages. However, we see indications that the\npresence of certain authors in the model's pre-training data affects predictive\nresults in ways that are difficult to assess.",
            "author": [
                "Rebecca M. M. Hicke",
                "David Mimno"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18454v1",
                "http://arxiv.org/pdf/2310.18454v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18449v1",
            "title": "Bayesian Optimization with Hidden Constraints via Latent Decision Models",
            "updated": "2023-10-27T19:47:26Z",
            "published": "2023-10-27T19:47:26Z",
            "summary": "Bayesian optimization (BO) has emerged as a potent tool for addressing\nintricate decision-making challenges, especially in public policy domains such\nas police districting. However, its broader application in public policymaking\nis hindered by the complexity of defining feasible regions and the\nhigh-dimensionality of decisions. This paper introduces the Hidden-Constrained\nLatent Space Bayesian Optimization (HC-LSBO), a novel BO method integrated with\na latent decision model. This approach leverages a variational autoencoder to\nlearn the distribution of feasible decisions, enabling a two-way mapping\nbetween the original decision space and a lower-dimensional latent space. By\ndoing so, HC-LSBO captures the nuances of hidden constraints inherent in public\npolicymaking, allowing for optimization in the latent space while evaluating\nobjectives in the original space. We validate our method through numerical\nexperiments on both synthetic and real data sets, with a specific focus on\nlarge-scale police districting problems in Atlanta, Georgia. Our results reveal\nthat HC-LSBO offers notable improvements in performance and efficiency compared\nto the baselines.",
            "author": [
                "Wenqian Xing",
                "Jungho Lee",
                "Chong Liu",
                "Shixiang Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18449v1",
                "http://arxiv.org/pdf/2310.18449v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18446v2",
            "title": "A Novel Skip Orthogonal List for Dynamic Optimal Transport Problem",
            "updated": "2023-11-25T19:05:40Z",
            "published": "2023-10-27T19:42:23Z",
            "summary": "Optimal transportation is a fundamental topic that has attracted a great\namount of attention from machine learning community in the past decades. In\nthis paper, we consider an interesting discrete dynamic optimal transport\nproblem: can we efficiently update the optimal transport plan when the weights\nor the locations of the data points change? This problem is naturally motivated\nby several applications in machine learning. For example, we often need to\ncompute the optimal transportation cost between two different data sets; if\nsome change happens to a few data points, should we re-compute the high\ncomplexity cost function or update the cost by some efficient dynamic data\nstructure? We are aware that several dynamic maximum flow algorithms have been\nproposed before, however, the research on dynamic minimum cost flow problem is\nstill quite limited, to the best of our knowledge. We propose a novel 2D Skip\nOrthogonal List together with some dynamic tree techniques. Although our\nalgorithm is based on the conventional simplex method, it can efficiently\ncomplete each pivoting operation within $O(|V|)$ time with high probability\nwhere $V$ is the set of all supply and demand nodes. Since dynamic\nmodifications typically do not introduce significant changes, our algorithm\nrequires only a few simplex iterations in practice. So our algorithm is more\nefficient than re-computing the optimal transportation cost that needs at least\none traversal over all the $O(|E|) = O(|V|^2)$ variables in general cases. Our\nexperiments demonstrate that our algorithm significantly outperforms existing\nalgorithms in the dynamic scenarios.",
            "author": [
                "Xiaoyang Xu",
                "Hu Ding"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18446v2",
                "http://arxiv.org/pdf/2310.18446v2"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.AI",
                "cs.CG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18444v1",
            "title": "M3C: A Framework towards Convergent, Flexible, and Unsupervised Learning\n  of Mixture Graph Matching and Clustering",
            "updated": "2023-10-27T19:40:34Z",
            "published": "2023-10-27T19:40:34Z",
            "summary": "Existing graph matching methods typically assume that there are similar\nstructures between graphs and they are matchable. However, these assumptions do\nnot align with real-world applications. This work addresses a more realistic\nscenario where graphs exhibit diverse modes, requiring graph grouping before or\nalong with matching, a task termed mixture graph matching and clustering. We\nintroduce Minorize-Maximization Matching and Clustering (M3C), a learning-free\nalgorithm that guarantees theoretical convergence through the\nMinorize-Maximization framework and offers enhanced flexibility via relaxed\nclustering. Building on M3C, we develop UM3C, an unsupervised model that\nincorporates novel edge-wise affinity learning and pseudo label selection.\nExtensive experimental results on public benchmarks demonstrate that our method\noutperforms state-of-the-art graph matching and mixture graph matching and\nclustering approaches in both accuracy and efficiency. Source code will be made\npublicly available.",
            "author": [
                "Jiaxin Lu",
                "Zetian Jiang",
                "Tianzhe Wang",
                "Junchi Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18444v1",
                "http://arxiv.org/pdf/2310.18444v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18443v1",
            "title": "Towards a fuller understanding of neurons with Clustered Compositional\n  Explanations",
            "updated": "2023-10-27T19:39:50Z",
            "published": "2023-10-27T19:39:50Z",
            "summary": "Compositional Explanations is a method for identifying logical formulas of\nconcepts that approximate the neurons' behavior. However, these explanations\nare linked to the small spectrum of neuron activations (i.e., the highest ones)\nused to check the alignment, thus lacking completeness. In this paper, we\npropose a generalization, called Clustered Compositional Explanations, that\ncombines Compositional Explanations with clustering and a novel search\nheuristic to approximate a broader spectrum of the neurons' behavior. We define\nand address the problems connected to the application of these methods to\nmultiple ranges of activations, analyze the insights retrievable by using our\nalgorithm, and propose desiderata qualities that can be used to study the\nexplanations returned by different algorithms.",
            "author": [
                "Biagio La Rosa",
                "Leilani H. Gilpin",
                "Roberto Capobianco"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18443v1",
                "http://arxiv.org/pdf/2310.18443v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18439v1",
            "title": "Machine learning detecting Majorana Zero Mode from Zero Bias Peak\n  measurements",
            "updated": "2023-10-27T19:26:55Z",
            "published": "2023-10-27T19:26:55Z",
            "summary": "Majorana zero modes (MZMs), emerging as exotic quasiparticles that carry\nnon-Abelian statistics, hold great promise for achieving fault-tolerant\ntopological quantum computation. A key signature of the presence of MZMs is the\nzero-bias peaks (ZBPs) from tunneling differential conductance. However, the\nidentification of MZMs from ZBPs has faced tremendous challenges, due to the\npresence of topological trivial states that generate spurious ZBP signals. In\nthis work, we introduce a machine-learning framework that can discern MZM from\nother signals using ZBP data. Quantum transport simulation from tight-binding\nmodels is used to generate the training data, while persistent cohomology\nanalysis confirms the feasibility of classification via machine learning. In\nparticular, even with added data noise, XGBoost classifier reaches $85\\%$\naccuracy for 1D tunneling conductance data and $94\\%$ for 2D data incorporating\nZeeman splitting. Tests on prior ZBP experiments show that some data are more\nlikely to originate from MZM than others. Our model offers a quantitative\napproach to assess MZMs using ZBP data. Furthermore, our results shed light on\nthe use of machine learning on exotic quantum systems with\nexperimental-computational integration.",
            "author": [
                "Mouyang Cheng",
                "Ryotaro Okabe",
                "Abhijatmedhi Chotrattanapituk",
                "Mingda Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18439v1",
                "http://arxiv.org/pdf/2310.18439v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18438v1",
            "title": "Exploring Shape Embedding for Cloth-Changing Person Re-Identification\n  via 2D-3D Correspondences",
            "updated": "2023-10-27T19:26:30Z",
            "published": "2023-10-27T19:26:30Z",
            "summary": "Cloth-Changing Person Re-Identification (CC-ReID) is a common and realistic\nproblem since fashion constantly changes over time and people's aesthetic\npreferences are not set in stone. While most existing cloth-changing ReID\nmethods focus on learning cloth-agnostic identity representations from coarse\nsemantic cues (e.g. silhouettes and part segmentation maps), they neglect the\ncontinuous shape distributions at the pixel level. In this paper, we propose\nContinuous Surface Correspondence Learning (CSCL), a new shape embedding\nparadigm for cloth-changing ReID. CSCL establishes continuous correspondences\nbetween a 2D image plane and a canonical 3D body surface via pixel-to-vertex\nclassification, which naturally aligns a person image to the surface of a 3D\nhuman model and simultaneously obtains pixel-wise surface embeddings. We\nfurther extract fine-grained shape features from the learned surface embeddings\nand then integrate them with global RGB features via a carefully designed\ncross-modality fusion module. The shape embedding paradigm based on 2D-3D\ncorrespondences remarkably enhances the model's global understanding of human\nbody shape. To promote the study of ReID under clothing change, we construct 3D\nDense Persons (DP3D), which is the first large-scale cloth-changing ReID\ndataset that provides densely annotated 2D-3D correspondences and a precise 3D\nmesh for each person image, while containing diverse cloth-changing cases over\nall four seasons. Experiments on both cloth-changing and cloth-consistent ReID\nbenchmarks validate the effectiveness of our method.",
            "author": [
                "Yubin Wang",
                "Huimin Yu",
                "Yuming Yan",
                "Shuyi Song",
                "Biyang Liu",
                "Yichong Lu"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3611715",
                "http://arxiv.org/abs/2310.18438v1",
                "http://arxiv.org/pdf/2310.18438v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18437v1",
            "title": "Inclination Angles for Be Stars Determined Using Machine Learning",
            "updated": "2023-10-27T19:23:55Z",
            "published": "2023-10-27T19:23:55Z",
            "summary": "We test the viability of training machine learning algorithms with synthetic\nH alpha line profiles to determine the inclination angles of Be stars (the\nangle between the central B star's rotation axis and the observer's line of\nsight) from a single observed medium-resolution, moderate S/N, spectrum. The\nperformance of three different machine learning algorithms were compared:\nneural networks tasked with regression, neural networks tasked with\nclassification, and support vector regression. Of these three algorithms,\nneural networks tasked with regression consistently outperformed the other\nmethods with a RMSE error of 7.6 degrees on an observational sample of 92\ngalactic Be stars with inclination angles known from direct H alpha profile\nfitting, from the spectroscopic signature of gravitational darkening, and, in a\nfew cases, from interferometric observations that resolved the disk. The\ntrained neural networks enable a quick and useful determination of the\ninclination angles of observed Be stars which can be used to search for\ncorrelated spin axes in young open clusters or to extract an equatorial\nrotation velocity from a measurement of v sin(i).",
            "author": [
                "B. D. Lailey",
                "T. A. A. Sigut"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18437v1",
                "http://arxiv.org/pdf/2310.18437v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18434v1",
            "title": "Bridging Distributionally Robust Learning and Offline RL: An Approach to\n  Mitigate Distribution Shift and Partial Data Coverage",
            "updated": "2023-10-27T19:19:30Z",
            "published": "2023-10-27T19:19:30Z",
            "summary": "The goal of an offline reinforcement learning (RL) algorithm is to learn\noptimal polices using historical (offline) data, without access to the\nenvironment for online exploration. One of the main challenges in offline RL is\nthe distribution shift which refers to the difference between the state-action\nvisitation distribution of the data generating policy and the learning policy.\nMany recent works have used the idea of pessimism for developing offline RL\nalgorithms and characterizing their sample complexity under a relatively weak\nassumption of single policy concentrability. Different from the offline RL\nliterature, the area of distributionally robust learning (DRL) offers a\nprincipled framework that uses a minimax formulation to tackle model mismatch\nbetween training and testing environments. In this work, we aim to bridge these\ntwo areas by showing that the DRL approach can be used to tackle the\ndistributional shift problem in offline RL. In particular, we propose two\noffline RL algorithms using the DRL framework, for the tabular and linear\nfunction approximation settings, and characterize their sample complexity under\nthe single policy concentrability assumption. We also demonstrate the superior\nperformance our proposed algorithm through simulation experiments.",
            "author": [
                "Kishan Panaganti",
                "Zaiyan Xu",
                "Dileep Kalathil",
                "Mohammad Ghavamzadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18434v1",
                "http://arxiv.org/pdf/2310.18434v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18430v1",
            "title": "MCRAGE: Synthetic Healthcare Data for Fairness",
            "updated": "2023-10-27T19:02:22Z",
            "published": "2023-10-27T19:02:22Z",
            "summary": "In the field of healthcare, electronic health records (EHR) serve as crucial\ntraining data for developing machine learning models for diagnosis, treatment,\nand the management of healthcare resources. However, medical datasets are often\nimbalanced in terms of sensitive attributes such as race/ethnicity, gender, and\nage. Machine learning models trained on class-imbalanced EHR datasets perform\nsignificantly worse in deployment for individuals of the minority classes\ncompared to samples from majority classes, which may lead to inequitable\nhealthcare outcomes for minority groups. To address this challenge, we propose\nMinority Class Rebalancing through Augmentation by Generative modeling\n(MCRAGE), a novel approach to augment imbalanced datasets using samples\ngenerated by a deep generative model. The MCRAGE process involves training a\nConditional Denoising Diffusion Probabilistic Model (CDDPM) capable of\ngenerating high-quality synthetic EHR samples from underrepresented classes. We\nuse this synthetic data to augment the existing imbalanced dataset, thereby\nachieving a more balanced distribution across all classes, which can be used to\ntrain an unbiased machine learning model. We measure the performance of MCRAGE\nversus alternative approaches using Accuracy, F1 score and AUROC. We provide\ntheoretical justification for our method in terms of recent convergence results\nfor DDPMs with minimal assumptions.",
            "author": [
                "Keira Behal",
                "Jiayi Chen",
                "Caleb Fikes",
                "Sophia Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18430v1",
                "http://arxiv.org/pdf/2310.18430v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18428v2",
            "title": "The Bayesian Stability Zoo",
            "updated": "2023-12-05T09:50:00Z",
            "published": "2023-10-27T18:59:31Z",
            "summary": "We show that many definitions of stability found in the learning theory\nliterature are equivalent to one another. We distinguish between two families\nof definitions of stability: distribution-dependent and\ndistribution-independent Bayesian stability. Within each family, we establish\nequivalences between various definitions, encompassing approximate differential\nprivacy, pure differential privacy, replicability, global stability, perfect\ngeneralization, TV stability, mutual information stability, KL-divergence\nstability, and R\\'enyi-divergence stability. Along the way, we prove boosting\nresults that enable the amplification of the stability of a learning rule. This\nwork is a step towards a more systematic taxonomy of stability notions in\nlearning theory, which can promote clarity and an improved understanding of an\narray of stability concepts that have emerged in recent years.",
            "author": [
                "Shay Moran",
                "Hilla Schefler",
                "Jonathan Shafer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18428v2",
                "http://arxiv.org/pdf/2310.18428v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18427v1",
            "title": "Maximizing Equitable Reach and Accessibility of ETDs",
            "updated": "2023-10-27T18:57:27Z",
            "published": "2023-10-27T18:57:27Z",
            "summary": "This poster addresses accessibility issues of electronic theses and\ndissertations (ETDs) in digital libraries (DLs). ETDs are available primarily\nas PDF files, which present barriers to equitable access, especially for users\nwith visual impairments, cognitive or learning disabilities, or for anyone\nneeding more efficient and effective ways of finding relevant information\nwithin these long documents. We propose using AI techniques, including natural\nlanguage processing (NLP), computer vision, and text analysis, to convert PDFs\ninto machine-readable HTML documents with semantic tags and structure,\nextracting figures and tables, and generating summaries and keywords. Our goal\nis to increase the accessibility of ETDs and to make this important scholarship\navailable to a wider audience.",
            "author": [
                "William A. Ingram",
                "Jian Wu",
                "Edward A. Fox"
            ],
            "link": [
                "http://dx.doi.org/10.1109/JCDL57899.2023.00049",
                "http://arxiv.org/abs/2310.18427v1",
                "http://arxiv.org/pdf/2310.18427v1"
            ],
            "primary_category": "cs.DL",
            "category": [
                "cs.DL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18424v2",
            "title": "Fast Machine Learning Method with Vector Embedding on Orthonormal Basis\n  and Spectral Transform",
            "updated": "2023-11-13T16:48:01Z",
            "published": "2023-10-27T18:48:54Z",
            "summary": "This paper presents a novel fast machine learning method that leverages two\ntechniques: Vector Embedding on Orthonormal Basis (VEOB) and Spectral Transform\n(ST). The VEOB converts the original data encoding into a vector embedding with\ncoordinates projected onto orthonormal bases. The Singular Value Decomposition\n(SVD) technique is used to calculate the vector basis and projection\ncoordinates, leading to an enhanced distance measurement in the embedding space\nand facilitating data compression by preserving the projection vectors\nassociated with the largest singular values. On the other hand, ST transforms\nsequence of vector data into spectral space. By applying the Discrete Cosine\nTransform (DCT) and selecting the most significant components, it streamlines\nthe handling of lengthy vector sequences. The paper provides examples of word\nembedding, text chunk embedding, and image embedding, implemented in Julia\nlanguage with a vector database. It also investigates unsupervised learning and\nsupervised learning using this method, along with strategies for handling large\ndata volumes.",
            "author": [
                "Louis Yu Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18424v2",
                "http://arxiv.org/pdf/2310.18424v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18417v1",
            "title": "Teacher Perception of Automatically Extracted Grammar Concepts for L2\n  Language Learning",
            "updated": "2023-10-27T18:17:29Z",
            "published": "2023-10-27T18:17:29Z",
            "summary": "One of the challenges in language teaching is how best to organize rules\nregarding syntax, semantics, or phonology in a meaningful manner. This not only\nrequires content creators to have pedagogical skills, but also have that\nlanguage's deep understanding. While comprehensive materials to develop such\ncurricula are available in English and some broadly spoken languages, for many\nother languages, teachers need to manually create them in response to their\nstudents' needs. This is challenging because i) it requires that such experts\nbe accessible and have the necessary resources, and ii) describing all the\nintricacies of a language is time-consuming and prone to omission. In this\nwork, we aim to facilitate this process by automatically discovering and\nvisualizing grammar descriptions. We extract descriptions from a natural text\ncorpus that answer questions about morphosyntax (learning of word order,\nagreement, case marking, or word formation) and semantics (learning of\nvocabulary). We apply this method for teaching two Indian languages, Kannada\nand Marathi, which, unlike English, do not have well-developed resources for\nsecond language learning. To assess the perceived utility of the extracted\nmaterial, we enlist the help of language educators from schools in North\nAmerica to perform a manual evaluation, who find the materials have potential\nto be used for their lesson preparation and learner evaluation.",
            "author": [
                "Aditi Chaudhary",
                "Arun Sampath",
                "Ashwin Sheshadri",
                "Antonios Anastasopoulos",
                "Graham Neubig"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18417v1",
                "http://arxiv.org/pdf/2310.18417v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18413v1",
            "title": "On the Fairness ROAD: Robust Optimization for Adversarial Debiasing",
            "updated": "2023-10-27T18:08:42Z",
            "published": "2023-10-27T18:08:42Z",
            "summary": "In the field of algorithmic fairness, significant attention has been put on\ngroup fairness criteria, such as Demographic Parity and Equalized Odds.\nNevertheless, these objectives, measured as global averages, have raised\nconcerns about persistent local disparities between sensitive groups. In this\nwork, we address the problem of local fairness, which ensures that the\npredictor is unbiased not only in terms of expectations over the whole\npopulation, but also within any subregion of the feature space, unknown at\ntraining time. To enforce this objective, we introduce ROAD, a novel approach\nthat leverages the Distributionally Robust Optimization (DRO) framework within\na fair adversarial learning objective, where an adversary tries to infer the\nsensitive attribute from the predictions. Using an instance-level re-weighting\nstrategy, ROAD is designed to prioritize inputs that are likely to be locally\nunfair, i.e. where the adversary faces the least difficulty in reconstructing\nthe sensitive attribute. Numerical experiments demonstrate the effectiveness of\nour method: it achieves Pareto dominance with respect to local fairness and\naccuracy for a given global fairness level across three standard datasets, and\nalso enhances fairness generalization under distribution shift.",
            "author": [
                "Vincent Grari",
                "Thibault Laugel",
                "Tatsunori Hashimoto",
                "Sylvain Lamprier",
                "Marcin Detyniecki"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18413v1",
                "http://arxiv.org/pdf/2310.18413v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18411v1",
            "title": "A general learning scheme for classical and quantum Ising machines",
            "updated": "2023-10-27T18:07:02Z",
            "published": "2023-10-27T18:07:02Z",
            "summary": "An Ising machine is any hardware specifically designed for finding the ground\nstate of the Ising model. Relevant examples are coherent Ising machines and\nquantum annealers. In this paper, we propose a new machine learning model that\nis based on the Ising structure and can be efficiently trained using gradient\ndescent. We provide a mathematical characterization of the training process,\nwhich is based upon optimizing a loss function whose partial derivatives are\nnot explicitly calculated but estimated by the Ising machine itself. Moreover,\nwe present some experimental results on the training and execution of the\nproposed learning model. These results point out new possibilities offered by\nIsing machines for different learning tasks. In particular, in the quantum\nrealm, the quantum resources are used for both the execution and the training\nof the model, providing a promising perspective in quantum machine learning.",
            "author": [
                "Ludwig Schmid",
                "Enrico Zardini",
                "Davide Pastorello"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18411v1",
                "http://arxiv.org/pdf/2310.18411v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18409v1",
            "title": "State-Action Similarity-Based Representations for Off-Policy Evaluation",
            "updated": "2023-10-27T18:00:57Z",
            "published": "2023-10-27T18:00:57Z",
            "summary": "In reinforcement learning, off-policy evaluation (OPE) is the problem of\nestimating the expected return of an evaluation policy given a fixed dataset\nthat was collected by running one or more different policies. One of the more\nempirically successful algorithms for OPE has been the fitted q-evaluation\n(FQE) algorithm that uses temporal difference updates to learn an action-value\nfunction, which is then used to estimate the expected return of the evaluation\npolicy. Typically, the original fixed dataset is fed directly into FQE to learn\nthe action-value function of the evaluation policy. Instead, in this paper, we\nseek to enhance the data-efficiency of FQE by first transforming the fixed\ndataset using a learned encoder, and then feeding the transformed dataset into\nFQE. To learn such an encoder, we introduce an OPE-tailored state-action\nbehavioral similarity metric, and use this metric and the fixed dataset to\nlearn an encoder that models this metric. Theoretically, we show that this\nmetric allows us to bound the error in the resulting OPE estimate. Empirically,\nwe show that other state-action similarity metrics lead to representations that\ncannot represent the action-value function of the evaluation policy, and that\nour state-action representation method boosts the data-efficiency of FQE and\nlowers OPE error relative to other OPE-based representation learning methods on\nchallenging OPE tasks. We also empirically show that the learned\nrepresentations significantly mitigate divergence of FQE under varying\ndistribution shifts. Our code is available here:\nhttps://github.com/Badger-RL/ROPE.",
            "author": [
                "Brahma S. Pavse",
                "Josiah P. Hanna"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18409v1",
                "http://arxiv.org/pdf/2310.18409v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18313v1",
            "title": "FP8-LM: Training FP8 Large Language Models",
            "updated": "2023-10-27T17:59:51Z",
            "published": "2023-10-27T17:59:51Z",
            "summary": "In this paper, we explore FP8 low-bit data formats for efficient training of\nlarge language models (LLMs). Our key insight is that most variables, such as\ngradients and optimizer states, in LLM training can employ low-precision data\nformats without compromising model accuracy and requiring no changes to\nhyper-parameters. Specifically, we propose a new FP8 automatic mixed-precision\nframework for training LLMs. This framework offers three levels of FP8\nutilization to streamline mixed-precision and distributed parallel training for\nLLMs. It gradually incorporates 8-bit gradients, optimizer states, and\ndistributed learning in an incremental manner. Experiment results show that,\nduring the training of GPT-175B model on H100 GPU platform, our FP8\nmixed-precision training framework not only achieved a remarkable 42% reduction\nin real memory usage but also ran 64% faster than the widely adopted BF16\nframework (i.e., Megatron-LM), surpassing the speed of Nvidia Transformer\nEngine by 17%. This largely reduces the training costs for large foundation\nmodels. Furthermore, our FP8 mixed-precision training methodology is generic.\nIt can be seamlessly applied to other tasks such as LLM instruction tuning and\nreinforcement learning with human feedback, offering savings in fine-tuning\nexpenses. Our FP8 low-precision training framework is open-sourced at\n{https://github.com/Azure/MS-AMP}{aka.ms/MS.AMP}.",
            "author": [
                "Houwen Peng",
                "Kan Wu",
                "Yixuan Wei",
                "Guoshuai Zhao",
                "Yuxiang Yang",
                "Ze Liu",
                "Yifan Xiong",
                "Ziyue Yang",
                "Bolin Ni",
                "Jingcheng Hu",
                "Ruihang Li",
                "Miaosen Zhang",
                "Chen Li",
                "Jia Ning",
                "Ruizhe Wang",
                "Zheng Zhang",
                "Shuguang Liu",
                "Joe Chau",
                "Han Hu",
                "Peng Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18313v1",
                "http://arxiv.org/pdf/2310.18313v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18308v1",
            "title": "Gen2Sim: Scaling up Robot Learning in Simulation with Generative Models",
            "updated": "2023-10-27T17:55:32Z",
            "published": "2023-10-27T17:55:32Z",
            "summary": "Generalist robot manipulators need to learn a wide variety of manipulation\nskills across diverse environments. Current robot training pipelines rely on\nhumans to provide kinesthetic demonstrations or to program simulation\nenvironments and to code up reward functions for reinforcement learning. Such\nhuman involvement is an important bottleneck towards scaling up robot learning\nacross diverse tasks and environments. We propose Generation to Simulation\n(Gen2Sim), a method for scaling up robot skill learning in simulation by\nautomating generation of 3D assets, task descriptions, task decompositions and\nreward functions using large pre-trained generative models of language and\nvision. We generate 3D assets for simulation by lifting open-world 2D\nobject-centric images to 3D using image diffusion models and querying LLMs to\ndetermine plausible physics parameters. Given URDF files of generated and\nhuman-developed assets, we chain-of-thought prompt LLMs to map these to\nrelevant task descriptions, temporal decompositions, and corresponding python\nreward functions for reinforcement learning. We show Gen2Sim succeeds in\nlearning policies for diverse long horizon tasks, where reinforcement learning\nwith non temporally decomposed reward functions fails. Gen2Sim provides a\nviable path for scaling up reinforcement learning for robot manipulators in\nsimulation, both by diversifying and expanding task and environment\ndevelopment, and by facilitating the discovery of reinforcement-learned\nbehaviors through temporal task decomposition in RL. Our work contributes\nhundreds of simulated assets, tasks and demonstrations, taking a step towards\nfully autonomous robotic manipulation skill acquisition in simulation.",
            "author": [
                "Pushkal Katara",
                "Zhou Xian",
                "Katerina Fragkiadaki"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18308v1",
                "http://arxiv.org/pdf/2310.18308v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18306v2",
            "title": "Supervised and Penalized Baseline Correction",
            "updated": "2023-11-14T22:36:17Z",
            "published": "2023-10-27T17:55:17Z",
            "summary": "Spectroscopic measurements can show distorted spectral shapes arising from a\nmixture of absorbing and scattering contributions. These distortions (or\nbaselines) often manifest themselves as non-constant offsets or low-frequency\noscillations. As a result, these baselines can adversely affect analytical and\nquantitative results. Baseline correction is an umbrella term where one applies\npre-processing methods to obtain baseline spectra (the unwanted distortions)\nand then remove the distortions by differencing. However, current state-of-the\nart baseline correction methods do not utilize analyte concentrations even if\nthey are available, or even if they contribute significantly to the observed\nspectral variability. We examine a class of state-of-the-art methods (penalized\nbaseline correction) and modify them such that they can accommodate a priori\nanalyte concentrations such that prediction can be enhanced. Performance will\nbe assessed on two near infra-red data sets across both classical penalized\nbaseline correction methods (without analyte information) and modified\npenalized baseline correction methods (leveraging analyte information).",
            "author": [
                "Erik Andries",
                "Ramin Nikzad-Langerodi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18306v2",
                "http://arxiv.org/pdf/2310.18306v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "eess.SP",
                "15, 62"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18304v1",
            "title": "A Stability Principle for Learning under Non-Stationarity",
            "updated": "2023-10-27T17:53:53Z",
            "published": "2023-10-27T17:53:53Z",
            "summary": "We develop a versatile framework for statistical learning in non-stationary\nenvironments. In each time period, our approach applies a stability principle\nto select a look-back window that maximizes the utilization of historical data\nwhile keeping the cumulative bias within an acceptable range relative to the\nstochastic error. Our theory showcases the adaptability of this approach to\nunknown non-stationarity. The regret bound is minimax optimal up to logarithmic\nfactors when the population losses are strongly convex, or Lipschitz only. At\nthe heart of our analysis lie two novel components: a measure of similarity\nbetween functions and a segmentation technique for dividing the non-stationary\ndata sequence into quasi-stationary pieces.",
            "author": [
                "Chengpiao Huang",
                "Kaizheng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18304v1",
                "http://arxiv.org/pdf/2310.18304v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.OC",
                "stat.ML",
                "68T05, 90C15"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18301v4",
            "title": "Interactive Joint Planning for Autonomous Vehicles",
            "updated": "2023-11-22T22:25:54Z",
            "published": "2023-10-27T17:48:25Z",
            "summary": "In highly interactive driving scenarios, the actions of one agent greatly\ninfluences those of its neighbors. Planning safe motions for autonomous\nvehicles in such interactive environments, therefore, requires reasoning about\nthe impact of the ego's intended motion plan on nearby agents' behavior.\nDeep-learning-based models have recently achieved great success in trajectory\nprediction and many models in the literature allow for ego-conditioned\nprediction. However, leveraging ego-conditioned prediction remains challenging\nin downstream planning due to the complex nature of neural networks, limiting\nthe planner structure to simple ones, e.g., sampling-based planner. Despite\ntheir ability to generate fine-grained high-quality motion plans, it is\ndifficult for gradient-based planning algorithms, such as model predictive\ncontrol (MPC), to leverage ego-conditioned prediction due to their iterative\nnature and need for gradient. We present Interactive Joint Planning (IJP) that\nbridges MPC with learned prediction models in a computationally scalable manner\nto provide us the best of both the worlds. In particular, IJP jointly optimizes\nover the behavior of the ego and the surrounding agents and leverages\ndeep-learned prediction models as prediction priors that the join trajectory\noptimization tries to stay close to. Furthermore, by leveraging homotopy\nclasses, our joint optimizer searches over diverse motion plans to avoid\ngetting stuck at local minima. Closed-loop simulation result shows that IJP\nsignificantly outperforms the baselines that are either without joint\noptimization or running sampling-based planning.",
            "author": [
                "Yuxiao Chen",
                "Sushant Veer",
                "Peter Karkus",
                "Marco Pavone"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18301v4",
                "http://arxiv.org/pdf/2310.18301v4"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18291v1",
            "title": "Addressing GAN Training Instabilities via Tunable Classification Losses",
            "updated": "2023-10-27T17:29:07Z",
            "published": "2023-10-27T17:29:07Z",
            "summary": "Generative adversarial networks (GANs), modeled as a zero-sum game between a\ngenerator (G) and a discriminator (D), allow generating synthetic data with\nformal guarantees. Noting that D is a classifier, we begin by reformulating the\nGAN value function using class probability estimation (CPE) losses. We prove a\ntwo-way correspondence between CPE loss GANs and $f$-GANs which minimize\n$f$-divergences. We also show that all symmetric $f$-divergences are equivalent\nin convergence. In the finite sample and model capacity setting, we define and\nobtain bounds on estimation and generalization errors. We specialize these\nresults to $\\alpha$-GANs, defined using $\\alpha$-loss, a tunable CPE loss\nfamily parametrized by $\\alpha\\in(0,\\infty]$. We next introduce a class of\ndual-objective GANs to address training instabilities of GANs by modeling each\nplayer's objective using $\\alpha$-loss to obtain $(\\alpha_D,\\alpha_G)$-GANs. We\nshow that the resulting non-zero sum game simplifies to minimizing an\n$f$-divergence under appropriate conditions on $(\\alpha_D,\\alpha_G)$.\nGeneralizing this dual-objective formulation using CPE losses, we define and\nobtain upper bounds on an appropriately defined estimation error. Finally, we\nhighlight the value of tuning $(\\alpha_D,\\alpha_G)$ in alleviating training\ninstabilities for the synthetic 2D Gaussian mixture ring as well as the large\npublicly available Celeb-A and LSUN Classroom image datasets.",
            "author": [
                "Monica Welfert",
                "Gowtham R. Kurri",
                "Kyle Otstot",
                "Lalitha Sankar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18291v1",
                "http://arxiv.org/pdf/2310.18291v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "math.IT",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18290v1",
            "title": "An Approach to Automatically generating Riddles aiding Concept\n  Attainment",
            "updated": "2023-10-27T17:28:23Z",
            "published": "2023-10-27T17:28:23Z",
            "summary": "One of the primary challenges in online learning environments, is to retain\nlearner engagement. Several different instructional strategies are proposed\nboth in online and offline environments to enhance learner engagement. The\nConcept Attainment Model is one such instructional strategy that focuses on\nlearners acquiring a deeper understanding of a concept rather than just its\ndictionary definition. This is done by searching and listing the properties\nused to distinguish examples from non-examples of various concepts. Our work\nattempts to apply the Concept Attainment Model to build conceptual riddles, to\ndeploy over online learning environments. The approach involves creating\nfactual triples from learning resources, classifying them based on their\nuniqueness to a concept into `Topic Markers' and `Common', followed by\ngenerating riddles based on the Concept Attainment Model's format and capturing\nall possible solutions to those riddles. The results obtained from the human\nevaluation of riddles prove encouraging.",
            "author": [
                "Niharika Sri Parasa",
                "Chaitali Diwan",
                "Srinath Srinivasa"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18290v1",
                "http://arxiv.org/pdf/2310.18290v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18288v3",
            "title": "Sustainable Concrete via Bayesian Optimization",
            "updated": "2023-11-20T16:17:38Z",
            "published": "2023-10-27T17:25:12Z",
            "summary": "Eight percent of global carbon dioxide emissions can be attributed to the\nproduction of cement, the main component of concrete, which is also the\ndominant source of CO2 emissions in the construction of data centers. The\ndiscovery of lower-carbon concrete formulae is therefore of high significance\nfor sustainability. However, experimenting with new concrete formulae is time\nconsuming and labor intensive, as one usually has to wait to record the\nconcrete's 28-day compressive strength, a quantity whose measurement can by its\ndefinition not be accelerated. This provides an opportunity for experimental\ndesign methodology like Bayesian Optimization (BO) to accelerate the search for\nstrong and sustainable concrete formulae. Herein, we 1) propose modeling steps\nthat make concrete strength amenable to be predicted accurately by a Gaussian\nprocess model with relatively few measurements, 2) formulate the search for\nsustainable concrete as a multi-objective optimization problem, and 3) leverage\nthe proposed model to carry out multi-objective BO with real-world strength\nmeasurements of the algorithmically proposed mixes. Our experimental results\nshow improved trade-offs between the mixtures' global warming potential (GWP)\nand their associated compressive strengths, compared to mixes based on current\nindustry practices. Our methods are open-sourced at\ngithub.com/facebookresearch/SustainableConcrete.",
            "author": [
                "Sebastian Ament",
                "Andrew Witte",
                "Nishant Garg",
                "Julius Kusuma"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18288v3",
                "http://arxiv.org/pdf/2310.18288v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18286v1",
            "title": "Optimal Transport for Treatment Effect Estimation",
            "updated": "2023-10-27T17:22:45Z",
            "published": "2023-10-27T17:22:45Z",
            "summary": "Estimating conditional average treatment effect from observational data is\nhighly challenging due to the existence of treatment selection bias. Prevalent\nmethods mitigate this issue by aligning distributions of different treatment\ngroups in the latent space. However, there are two critical problems that these\nmethods fail to address: (1) mini-batch sampling effects (MSE), which causes\nmisalignment in non-ideal mini-batches with outcome imbalance and outliers; (2)\nunobserved confounder effects (UCE), which results in inaccurate discrepancy\ncalculation due to the neglect of unobserved confounders. To tackle these\nproblems, we propose a principled approach named Entire Space CounterFactual\nRegression (ESCFR), which is a new take on optimal transport in the context of\ncausality. Specifically, based on the framework of stochastic optimal\ntransport, we propose a relaxed mass-preserving regularizer to address the MSE\nissue and design a proximal factual outcome regularizer to handle the UCE\nissue. Extensive experiments demonstrate that our proposed ESCFR can\nsuccessfully tackle the treatment selection bias and achieve significantly\nbetter performance than state-of-the-art methods.",
            "author": [
                "Hao Wang",
                "Zhichao Chen",
                "Jiajun Fan",
                "Haoxuan Li",
                "Tianqiao Liu",
                "Weiming Liu",
                "Quanyu Dai",
                "Yichao Wang",
                "Zhenhua Dong",
                "Ruiming Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18286v1",
                "http://arxiv.org/pdf/2310.18286v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.AP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18285v2",
            "title": "Unlocking the Potential of Prompt-Tuning in Bridging Generalized and\n  Personalized Federated Learning",
            "updated": "2023-11-24T06:49:25Z",
            "published": "2023-10-27T17:22:09Z",
            "summary": "Vision Transformers (ViT) and Visual Prompt Tuning (VPT) achieve\nstate-of-the-art performance with improved efficiency in various computer\nvision tasks. This suggests a promising paradigm shift of adapting pre-trained\nViT models to Federated Learning (FL) settings. However, the challenge of data\nheterogeneity among FL clients presents a significant hurdle in effectively\ndeploying ViT models. Existing Generalized FL (GFL) and Personalized FL (PFL)\nmethods have limitations in balancing performance across both global and local\ndata distributions. In this paper, we present a novel algorithm, SGPT, that\nintegrates GFL and PFL approaches by employing a unique combination of both\nshared and group-specific prompts. This design enables SGPT to capture both\ncommon and group-specific features. A key feature of SGPT is its prompt\nselection module, which facilitates the training of a single global model\ncapable of automatically adapting to diverse local client data distributions\nwithout the need for local fine-tuning. To effectively train the prompts, we\nutilize block coordinate descent (BCD), learning from common feature\ninformation (shared prompts), and then more specialized knowledge (group\nprompts) iteratively. Theoretically, we justify that learning the proposed\nprompts can reduce the gap between global and local performance. Empirically,\nwe conduct experiments on both label and feature heterogeneity settings in\ncomparison with state-of-the-art baselines, along with extensive ablation\nstudies, to substantiate the superior performance of SGPT.",
            "author": [
                "Wenlong Deng",
                "Christos Thrampoulidis",
                "Xiaoxiao Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18285v2",
                "http://arxiv.org/pdf/2310.18285v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18280v1",
            "title": "Universality for the global spectrum of random inner-product kernel\n  matrices in the polynomial regime",
            "updated": "2023-10-27T17:15:55Z",
            "published": "2023-10-27T17:15:55Z",
            "summary": "We consider certain large random matrices, called random inner-product kernel\nmatrices, which are essentially given by a nonlinear function $f$ applied\nentrywise to a sample-covariance matrix, $f(X^TX)$, where $X \\in \\mathbb{R}^{d\n\\times N}$ is random and normalized in such a way that $f$ typically has\norder-one arguments. We work in the polynomial regime, where $N \\asymp d^\\ell$\nfor some $\\ell > 0$, not just the linear regime where $\\ell = 1$. Earlier work\nby various authors showed that, when the columns of $X$ are either uniform on\nthe sphere or standard Gaussian vectors, and when $\\ell$ is an integer (the\nlinear regime $\\ell = 1$ is particularly well-studied), the bulk eigenvalues of\nsuch matrices behave in a simple way: They are asymptotically given by the free\nconvolution of the semicircular and Mar\\v{c}enko-Pastur distributions, with\nrelative weights given by expanding $f$ in the Hermite basis. In this paper, we\nshow that this phenomenon is universal, holding as soon as $X$ has i.i.d.\nentries with all finite moments. In the case of non-integer $\\ell$, the\nMar\\v{c}enko-Pastur term disappears (its weight in the free convolution\nvanishes), and the spectrum is just semicircular.",
            "author": [
                "Sofiia Dubova",
                "Yue M. Lu",
                "Benjamin McKenna",
                "Horng-Tzer Yau"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18280v1",
                "http://arxiv.org/pdf/2310.18280v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "stat.ML",
                "60B20, 15B52"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18278v1",
            "title": "Navigating protein landscapes with a machine-learned transferable\n  coarse-grained model",
            "updated": "2023-10-27T17:10:23Z",
            "published": "2023-10-27T17:10:23Z",
            "summary": "The most popular and universally predictive protein simulation models employ\nall-atom molecular dynamics (MD), but they come at extreme computational cost.\nThe development of a universal, computationally efficient coarse-grained (CG)\nmodel with similar prediction performance has been a long-standing challenge.\nBy combining recent deep learning methods with a large and diverse training set\nof all-atom protein simulations, we here develop a bottom-up CG force field\nwith chemical transferability, which can be used for extrapolative molecular\ndynamics on new sequences not used during model parametrization. We demonstrate\nthat the model successfully predicts folded structures, intermediates,\nmetastable folded and unfolded basins, and the fluctuations of intrinsically\ndisordered proteins while it is several orders of magnitude faster than an\nall-atom model. This showcases the feasibility of a universal and\ncomputationally efficient machine-learned CG model for proteins.",
            "author": [
                "Nicholas E. Charron",
                "Felix Musil",
                "Andrea Guljas",
                "Yaoyi Chen",
                "Klara Bonneau",
                "Aldo S. Pasos-Trejo",
                "Jacopo Venturin",
                "Daria Gusew",
                "Iryna Zaporozhets",
                "Andreas Kr\u00e4mer",
                "Clark Templeton",
                "Atharva Kelkar",
                "Aleksander E. P. Durumeric",
                "Simon Olsson",
                "Adri\u00e0 P\u00e9rez",
                "Maciej Majewski",
                "Brooke E. Husic",
                "Ankit Patel",
                "Gianni De Fabritiis",
                "Frank No\u00e9",
                "Cecilia Clementi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18278v1",
                "http://arxiv.org/pdf/2310.18278v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "physics.bio-ph",
                "physics.chem-ph",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18390v1",
            "title": "Entity Embeddings : Perspectives Towards an Omni-Modality Era for Large\n  Language Models",
            "updated": "2023-10-27T17:04:10Z",
            "published": "2023-10-27T17:04:10Z",
            "summary": "Large Language Models (LLMs) are evolving to integrate multiple modalities,\nsuch as text, image, and audio into a unified linguistic space. We envision a\nfuture direction based on this framework where conceptual entities defined in\nsequences of text can also be imagined as modalities. Such a formulation has\nthe potential to overcome the cognitive and computational limitations of\ncurrent models. Several illustrative examples of such potential implicit\nmodalities are given. Along with vast promises of the hypothesized structure,\nexpected challenges are discussed as well.",
            "author": [
                "Eren Unlu",
                "Unver Ciftci"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18390v1",
                "http://arxiv.org/pdf/2310.18390v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18274v1",
            "title": "LipSim: A Provably Robust Perceptual Similarity Metric",
            "updated": "2023-10-27T16:59:51Z",
            "published": "2023-10-27T16:59:51Z",
            "summary": "Recent years have seen growing interest in developing and applying perceptual\nsimilarity metrics. Research has shown the superiority of perceptual metrics\nover pixel-wise metrics in aligning with human perception and serving as a\nproxy for the human visual system. On the other hand, as perceptual metrics\nrely on neural networks, there is a growing concern regarding their resilience,\ngiven the established vulnerability of neural networks to adversarial attacks.\nIt is indeed logical to infer that perceptual metrics may inherit both the\nstrengths and shortcomings of neural networks. In this work, we demonstrate the\nvulnerability of state-of-the-art perceptual similarity metrics based on an\nensemble of ViT-based feature extractors to adversarial attacks. We then\npropose a framework to train a robust perceptual similarity metric called\nLipSim (Lipschitz Similarity Metric) with provable guarantees. By leveraging\n1-Lipschitz neural networks as the backbone, LipSim provides guarded areas\naround each data point and certificates for all perturbations within an\n$\\ell_2$ ball. Finally, a comprehensive set of experiments shows the\nperformance of LipSim in terms of natural and certified scores and on the image\nretrieval application. The code is available at\nhttps://github.com/SaraGhazanfari/LipSim.",
            "author": [
                "Sara Ghazanfari",
                "Alexandre Araujo",
                "Prashanth Krishnamurthy",
                "Farshad Khorrami",
                "Siddharth Garg"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18274v1",
                "http://arxiv.org/pdf/2310.18274v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18268v1",
            "title": "PlantPlotGAN: A Physics-Informed Generative Adversarial Network for\n  Plant Disease Prediction",
            "updated": "2023-10-27T16:56:28Z",
            "published": "2023-10-27T16:56:28Z",
            "summary": "Monitoring plantations is crucial for crop management and producing healthy\nharvests. Unmanned Aerial Vehicles (UAVs) have been used to collect\nmultispectral images that aid in this monitoring. However, given the number of\nhectares to be monitored and the limitations of flight, plant disease signals\nbecome visually clear only in the later stages of plant growth and only if the\ndisease has spread throughout a significant portion of the plantation. This\nlimited amount of relevant data hampers the prediction models, as the\nalgorithms struggle to generalize patterns with unbalanced or unrealistic\naugmented datasets effectively. To address this issue, we propose PlantPlotGAN,\na physics-informed generative model capable of creating synthetic multispectral\nplot images with realistic vegetation indices. These indices served as a proxy\nfor disease detection and were used to evaluate if our model could help\nincrease the accuracy of prediction models. The results demonstrate that the\nsynthetic imagery generated from PlantPlotGAN outperforms state-of-the-art\nmethods regarding the Fr\\'echet inception distance. Moreover, prediction models\nachieve higher accuracy metrics when trained with synthetic and original\nimagery for earlier plant disease detection compared to the training processes\nbased solely on real imagery.",
            "author": [
                "Felipe A. Lopes",
                "Vasit Sagan",
                "Flavio Esposito"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18268v1",
                "http://arxiv.org/pdf/2310.18268v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18265v1",
            "title": "Structured Semidefinite Programming for Recovering Structured\n  Preconditioners",
            "updated": "2023-10-27T16:54:29Z",
            "published": "2023-10-27T16:54:29Z",
            "summary": "We develop a general framework for finding approximately-optimal\npreconditioners for solving linear systems. Leveraging this framework we obtain\nimproved runtimes for fundamental preconditioning and linear system solving\nproblems including the following. We give an algorithm which, given positive\ndefinite $\\mathbf{K} \\in \\mathbb{R}^{d \\times d}$ with\n$\\mathrm{nnz}(\\mathbf{K})$ nonzero entries, computes an $\\epsilon$-optimal\ndiagonal preconditioner in time $\\widetilde{O}(\\mathrm{nnz}(\\mathbf{K}) \\cdot\n\\mathrm{poly}(\\kappa^\\star,\\epsilon^{-1}))$, where $\\kappa^\\star$ is the\noptimal condition number of the rescaled matrix. We give an algorithm which,\ngiven $\\mathbf{M} \\in \\mathbb{R}^{d \\times d}$ that is either the pseudoinverse\nof a graph Laplacian matrix or a constant spectral approximation of one, solves\nlinear systems in $\\mathbf{M}$ in $\\widetilde{O}(d^2)$ time. Our diagonal\npreconditioning results improve state-of-the-art runtimes of $\\Omega(d^{3.5})$\nattained by general-purpose semidefinite programming, and our solvers improve\nstate-of-the-art runtimes of $\\Omega(d^{\\omega})$ where $\\omega > 2.3$ is the\ncurrent matrix multiplication constant. We attain our results via new\nalgorithms for a class of semidefinite programs (SDPs) we call\nmatrix-dictionary approximation SDPs, which we leverage to solve an associated\nproblem we call matrix-dictionary recovery.",
            "author": [
                "Arun Jambulapati",
                "Jerry Li",
                "Christopher Musco",
                "Kirankumar Shiragur",
                "Aaron Sidford",
                "Kevin Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18265v1",
                "http://arxiv.org/pdf/2310.18265v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18264v1",
            "title": "Learning to Search Feasible and Infeasible Regions of Routing Problems\n  with Flexible Neural k-Opt",
            "updated": "2023-10-27T16:51:41Z",
            "published": "2023-10-27T16:51:41Z",
            "summary": "In this paper, we present Neural k-Opt (NeuOpt), a novel learning-to-search\n(L2S) solver for routing problems. It learns to perform flexible k-opt\nexchanges based on a tailored action factorization method and a customized\nrecurrent dual-stream decoder. As a pioneering work to circumvent the pure\nfeasibility masking scheme and enable the autonomous exploration of both\nfeasible and infeasible regions, we then propose the Guided Infeasible Region\nExploration (GIRE) scheme, which supplements the NeuOpt policy network with\nfeasibility-related features and leverages reward shaping to steer\nreinforcement learning more effectively. Additionally, we equip NeuOpt with\nDynamic Data Augmentation (D2A) for more diverse searches during inference.\nExtensive experiments on the Traveling Salesman Problem (TSP) and Capacitated\nVehicle Routing Problem (CVRP) demonstrate that our NeuOpt not only\nsignificantly outstrips existing (masking-based) L2S solvers, but also\nshowcases superiority over the learning-to-construct (L2C) and\nlearning-to-predict (L2P) solvers. Notably, we offer fresh perspectives on how\nneural solvers can handle VRP constraints. Our code is available:\nhttps://github.com/yining043/NeuOpt.",
            "author": [
                "Yining Ma",
                "Zhiguang Cao",
                "Yeow Meng Chee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18264v1",
                "http://arxiv.org/pdf/2310.18264v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18263v1",
            "title": "MalFake: A Multimodal Fake News Identification for Malayalam using\n  Recurrent Neural Networks and VGG-16",
            "updated": "2023-10-27T16:51:29Z",
            "published": "2023-10-27T16:51:29Z",
            "summary": "The amount of news being consumed online has substantially expanded in recent\nyears. Fake news has become increasingly common, especially in regional\nlanguages like Malayalam, due to the rapid publication and lack of editorial\nstandards on some online sites. Fake news may have a terrible effect on\nsociety, causing people to make bad judgments, lose faith in authorities, and\neven engage in violent behavior. When we take into the context of India, there\nare many regional languages, and fake news is spreading in every language.\nTherefore, providing efficient techniques for identifying false information in\nregional tongues is crucial. Until now, little to no work has been done in\nMalayalam, extracting features from multiple modalities to classify fake news.\nMultimodal approaches are more accurate in detecting fake news, as features\nfrom multiple modalities are extracted to build the deep learning\nclassification model. As far as we know, this is the first piece of work in\nMalayalam that uses multimodal deep learning to tackle false information.\nModels trained with more than one modality typically outperform models taught\nwith only one modality. Our study in the Malayalam language utilizing\nmultimodal deep learning is a significant step toward more effective\nmisinformation detection and mitigation.",
            "author": [
                "Adhish S. Sujan",
                "Ajitha. V",
                "Aleena Benny",
                "Amiya M. P.",
                "V. S. Anoop"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18263v1",
                "http://arxiv.org/pdf/2310.18263v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18261v1",
            "title": "Label Shift Estimators for Non-Ignorable Missing Data",
            "updated": "2023-10-27T16:50:13Z",
            "published": "2023-10-27T16:50:13Z",
            "summary": "We consider the problem of estimating the mean of a random variable Y subject\nto non-ignorable missingness, i.e., where the missingness mechanism depends on\nY . We connect the auxiliary proxy variable framework for non-ignorable\nmissingness (West and Little, 2013) to the label shift setting (Saerens et al.,\n2002). Exploiting this connection, we construct an estimator for non-ignorable\nmissing data that uses high-dimensional covariates (or proxies) without the\nneed for a generative model. In synthetic and semi-synthetic experiments, we\nstudy the behavior of the proposed estimator, comparing it to commonly used\nignorable estimators in both well-specified and misspecified settings.\nAdditionally, we develop a score to assess how consistent the data are with the\nlabel shift assumption. We use our approach to estimate disease prevalence\nusing a large health survey, comparing ignorable and non-ignorable approaches.\nWe show that failing to account for non-ignorable missingness can have profound\nconsequences on conclusions drawn from non-representative samples.",
            "author": [
                "Andrew C. Miller",
                "Joseph Futoma"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18261v1",
                "http://arxiv.org/pdf/2310.18261v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18260v1",
            "title": "Concepts and Paradigms for Neuromorphic Programming",
            "updated": "2023-10-27T16:48:11Z",
            "published": "2023-10-27T16:48:11Z",
            "summary": "The value of neuromorphic computers depends crucially on our ability to\nprogram them for relevant tasks. Currently, neuromorphic computers are mostly\nlimited to machine learning methods adapted from deep learning. However,\nneuromorphic computers have potential far beyond deep learning if we can only\nmake use of their computational properties to harness their full power.\nNeuromorphic programming will necessarily be different from conventional\nprogramming, requiring a paradigm shift in how we think about programming in\ngeneral. The contributions of this paper are 1) a conceptual analysis of what\n\"programming\" means in the context of neuromorphic computers and 2) an\nexploration of existing programming paradigms that are promising yet overlooked\nin neuromorphic computing. The goal is to expand the horizon of neuromorphic\nprogramming methods, thereby allowing researchers to move beyond the shackles\nof current methods and explore novel directions.",
            "author": [
                "Steven Abreu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18260v1",
                "http://arxiv.org/pdf/2310.18260v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18251v1",
            "title": "A Self-Supervised Approach to Land Cover Segmentation",
            "updated": "2023-10-27T16:37:36Z",
            "published": "2023-10-27T16:37:36Z",
            "summary": "Land use/land cover change (LULC) maps are integral resources in earth\nscience and agricultural research. Due to the nature of such maps, the creation\nof LULC maps is often constrained by the time and human resources necessary to\naccurately annotate satellite imagery and remote sensing data. While computer\nvision models that perform semantic segmentation to create detailed labels from\nsuch data are not uncommon, litle research has been done on self-supervised and\nunsupervised approaches to labelling LULC maps without the use of ground-truth\nmasks. Here, we demonstrate a self-supervised method of land cover segmentation\nthat has no need for high-quality ground truth labels. The proposed deep\nlearning employs a frozen pre-trained ViT backbone transferred from DINO in a\nSTEGO architecture and is fine-tuned using a custom dataset consisting of very\nhigh resolution (VHR) sattelite imagery. After only 10 epochs of fine-tuning,\nan accuracy of roughly 52% was observed across 5 samples, signifying the\nfeasibility of self-supervised models for the automated labelling of VHR LULC\nmaps.",
            "author": [
                "Charles Moore",
                "Dakota Hester"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18251v1",
                "http://arxiv.org/pdf/2310.18251v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18249v1",
            "title": "Leveraging Machine Learning Models for Peptide-Protein Interaction\n  Prediction",
            "updated": "2023-10-27T16:36:06Z",
            "published": "2023-10-27T16:36:06Z",
            "summary": "Peptides play a pivotal role in a wide range of biological activities through\nparticipating in up to 40% protein-protein interactions in cellular processes.\nThey also demonstrate remarkable specificity and efficacy, making them\npromising candidates for drug development. However, predicting peptide-protein\ncomplexes by traditional computational approaches, such as Docking and\nMolecular Dynamics simulations, still remains a challenge due to high\ncomputational cost, flexible nature of peptides, and limited structural\ninformation of peptide-protein complexes. In recent years, the surge of\navailable biological data has given rise to the development of an increasing\nnumber of machine learning models for predicting peptide-protein interactions.\nThese models offer efficient solutions to address the challenges associated\nwith traditional computational approaches. Furthermore, they offer enhanced\naccuracy, robustness, and interpretability in their predictive outcomes. This\nreview presents a comprehensive overview of machine learning and deep learning\nmodels that have emerged in recent years for the prediction of peptide-protein\ninteractions.",
            "author": [
                "Song Yin",
                "Xuenan Mi",
                "Diwakar Shukla"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18249v1",
                "http://arxiv.org/pdf/2310.18249v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18247v1",
            "title": "Guided Data Augmentation for Offline Reinforcement Learning and\n  Imitation Learning",
            "updated": "2023-10-27T16:34:00Z",
            "published": "2023-10-27T16:34:00Z",
            "summary": "Learning from demonstration (LfD) is a popular technique that uses expert\ndemonstrations to learn robot control policies. However, the difficulty in\nacquiring expert-quality demonstrations limits the applicability of LfD\nmethods: real-world data collection is often costly, and the quality of the\ndemonstrations depends greatly on the demonstrator's abilities and safety\nconcerns. A number of works have leveraged data augmentation (DA) to\ninexpensively generate additional demonstration data, but most DA works\ngenerate augmented data in a random fashion and ultimately produce highly\nsuboptimal data. In this work, we propose Guided Data Augmentation (GuDA), a\nhuman-guided DA framework that generates expert-quality augmented data. The key\ninsight of GuDA is that while it may be difficult to demonstrate the sequence\nof actions required to produce expert data, a user can often easily identify\nwhen an augmented trajectory segment represents task progress. Thus, the user\ncan impose a series of simple rules on the DA process to automatically generate\naugmented samples that approximate expert behavior. To extract a policy from\nGuDA, we use off-the-shelf offline reinforcement learning and behavior cloning\nalgorithms. We evaluate GuDA on a physical robot soccer task as well as\nsimulated D4RL navigation tasks, a simulated autonomous driving task, and a\nsimulated soccer task. Empirically, we find that GuDA enables learning from a\nsmall set of potentially suboptimal demonstrations and substantially\noutperforms a DA strategy that samples augmented data randomly.",
            "author": [
                "Nicholas E. Corrado",
                "Yuxiao Qu",
                "John U. Balis",
                "Adam Labiosa",
                "Josiah P. Hanna"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18247v1",
                "http://arxiv.org/pdf/2310.18247v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18241v1",
            "title": "$\u03b1$-Mutual Information: A Tunable Privacy Measure for Privacy\n  Protection in Data Sharing",
            "updated": "2023-10-27T16:26:14Z",
            "published": "2023-10-27T16:26:14Z",
            "summary": "This paper adopts Arimoto's $\\alpha$-Mutual Information as a tunable privacy\nmeasure, in a privacy-preserving data release setting that aims to prevent\ndisclosing private data to adversaries. By fine-tuning the privacy metric, we\ndemonstrate that our approach yields superior models that effectively thwart\nattackers across various performance dimensions. We formulate a general\ndistortion-based mechanism that manipulates the original data to offer privacy\nprotection. The distortion metrics are determined according to the data\nstructure of a specific experiment. We confront the problem expressed in the\nformulation by employing a general adversarial deep learning framework that\nconsists of a releaser and an adversary, trained with opposite goals. This\nstudy conducts empirical experiments on images and time-series data to verify\nthe functionality of $\\alpha$-Mutual Information. We evaluate the\nprivacy-utility trade-off of customized models and compare them to mutual\ninformation as the baseline measure. Finally, we analyze the consequence of an\nattacker's access to side information about private data and witness that\nadapting the privacy measure results in a more refined model than the\nstate-of-the-art in terms of resiliency against side information.",
            "author": [
                "MirHamed Jafarzadeh Asl",
                "Mohammadhadi Shateri",
                "Fabrice Labeau"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18241v1",
                "http://arxiv.org/pdf/2310.18241v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18237v2",
            "title": "Generative AI Model for Artistic Style Transfer Using Convolutional\n  Neural Networks",
            "updated": "2023-10-30T16:55:43Z",
            "published": "2023-10-27T16:21:17Z",
            "summary": "Artistic style transfer, a captivating application of generative artificial\nintelligence, involves fusing the content of one image with the artistic style\nof another to create unique visual compositions. This paper presents a\ncomprehensive overview of a novel technique for style transfer using\nConvolutional Neural Networks (CNNs). By leveraging deep image representations\nlearned by CNNs, we demonstrate how to separate and manipulate image content\nand style, enabling the synthesis of high-quality images that combine content\nand style in a harmonious manner. We describe the methodology, including\ncontent and style representations, loss computation, and optimization, and\nshowcase experimental results highlighting the effectiveness and versatility of\nthe approach across different styles and content",
            "author": [
                "Jonayet Miah",
                "Duc M Cao",
                "Md Abu Sayed",
                "Md. Sabbirul Haque"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18237v2",
                "http://arxiv.org/pdf/2310.18237v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18236v1",
            "title": "How Re-sampling Helps for Long-Tail Learning?",
            "updated": "2023-10-27T16:20:34Z",
            "published": "2023-10-27T16:20:34Z",
            "summary": "Long-tail learning has received significant attention in recent years due to\nthe challenge it poses with extremely imbalanced datasets. In these datasets,\nonly a few classes (known as the head classes) have an adequate number of\ntraining samples, while the rest of the classes (known as the tail classes) are\ninfrequent in the training data. Re-sampling is a classical and widely used\napproach for addressing class imbalance issues. Unfortunately, recent studies\nclaim that re-sampling brings negligible performance improvements in modern\nlong-tail learning tasks. This paper aims to investigate this phenomenon\nsystematically. Our research shows that re-sampling can considerably improve\ngeneralization when the training images do not contain semantically irrelevant\ncontexts. In other scenarios, however, it can learn unexpected spurious\ncorrelations between irrelevant contexts and target labels. We design\nexperiments on two homogeneous datasets, one containing irrelevant context and\nthe other not, to confirm our findings. To prevent the learning of spurious\ncorrelations, we propose a new context shift augmentation module that generates\ndiverse training images for the tail class by maintaining a context bank\nextracted from the head-class images. Experiments demonstrate that our proposed\nmodule can boost the generalization and outperform other approaches, including\nclass-balanced re-sampling, decoupled classifier re-training, and data\naugmentation methods. The source code is available at\nhttps://www.lamda.nju.edu.cn/code_CSA.ashx.",
            "author": [
                "Jiang-Xin Shi",
                "Tong Wei",
                "Yuke Xiang",
                "Yu-Feng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18236v1",
                "http://arxiv.org/pdf/2310.18236v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18235v2",
            "title": "Davidsonian Scene Graph: Improving Reliability in Fine-grained\n  Evaluation for Text-to-Image Generation",
            "updated": "2023-10-30T16:00:49Z",
            "published": "2023-10-27T16:20:10Z",
            "summary": "Evaluating text-to-image models is notoriously difficult. A strong recent\napproach for assessing text-image faithfulness is based on QG/A (question\ngeneration and answering), which uses pre-trained foundational models to\nautomatically generate a set of questions and answers from the prompt, and\noutput images are scored based on whether these answers extracted with a visual\nquestion answering model are consistent with the prompt-based answers. This\nkind of evaluation is naturally dependent on the quality of the underlying QG\nand QA models. We identify and address several reliability challenges in\nexisting QG/A work: (a) QG questions should respect the prompt (avoiding\nhallucinations, duplications, and omissions) and (b) VQA answers should be\nconsistent (not asserting that there is no motorcycle in an image while also\nclaiming the motorcycle is blue). We address these issues with Davidsonian\nScene Graph (DSG), an empirically grounded evaluation framework inspired by\nformal semantics. DSG is an automatic, graph-based QG/A that is modularly\nimplemented to be adaptable to any QG/A module. DSG produces atomic and unique\nquestions organized in dependency graphs, which (i) ensure appropriate semantic\ncoverage and (ii) sidestep inconsistent answers. With extensive experimentation\nand human evaluation on a range of model configurations (LLM, VQA, and T2I), we\nempirically demonstrate that DSG addresses the challenges noted above. Finally,\nwe present DSG-1k, an open-sourced evaluation benchmark that includes 1,060\nprompts, covering a wide range of fine-grained semantic categories with a\nbalanced distribution. We release the DSG-1k prompts and the corresponding DSG\nquestions.",
            "author": [
                "Jaemin Cho",
                "Yushi Hu",
                "Roopal Garg",
                "Peter Anderson",
                "Ranjay Krishna",
                "Jason Baldridge",
                "Mohit Bansal",
                "Jordi Pont-Tuset",
                "Su Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18235v2",
                "http://arxiv.org/pdf/2310.18235v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18234v1",
            "title": "Edge AI-Based Vein Detector for Efficient Venipuncture in the\n  Antecubital Fossa",
            "updated": "2023-10-27T16:19:26Z",
            "published": "2023-10-27T16:19:26Z",
            "summary": "Assessing the condition and visibility of veins is a crucial step before\nobtaining intravenous access in the antecubital fossa, which is a common\nprocedure to draw blood or administer intravenous therapies (IV therapies).\nEven though medical practitioners are highly skilled at intravenous\ncannulation, they usually struggle to perform the procedure in patients with\nlow visible veins due to fluid retention, age, overweight, dark skin tone, or\ndiabetes. Recently, several investigations proposed combining Near Infrared\n(NIR) imaging and deep learning (DL) techniques for forearm vein segmentation.\nAlthough they have demonstrated compelling results, their use has been rather\nlimited owing to the portability and precision requirements to perform\nvenipuncture. In this paper, we aim to contribute to bridging this gap using\nthree strategies. First, we introduce a new NIR-based forearm vein segmentation\ndataset of 2,016 labelled images collected from 1,008 subjects with low visible\nveins. Second, we propose a modified U-Net architecture that locates veins\nspecifically in the antecubital fossa region of the examined patient. Finally,\na compressed version of the proposed architecture was deployed inside a\nbespoke, portable vein finder device after testing four common embedded\nmicrocomputers and four common quantization modalities. Experimental results\nshowed that the model compressed with Dynamic Range Quantization and deployed\non a Raspberry Pi 4B card produced the best execution time and precision\nbalance, with 5.14 FPS and 0.957 of latency and Intersection over Union (IoU),\nrespectively. These results show promising performance inside a\nresource-restricted low-cost device.",
            "author": [
                "Edwin Salcedo",
                "Patricia Pe\u00f1aloza"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-47640-2_24",
                "http://arxiv.org/abs/2310.18234v1",
                "http://arxiv.org/pdf/2310.18234v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18230v2",
            "title": "Deep Transformed Gaussian Processes",
            "updated": "2023-11-02T10:25:56Z",
            "published": "2023-10-27T16:09:39Z",
            "summary": "Transformed Gaussian Processes (TGPs) are stochastic processes specified by\ntransforming samples from the joint distribution from a prior process\n(typically a GP) using an invertible transformation; increasing the flexibility\nof the base process.\n  Furthermore, they achieve competitive results compared with Deep Gaussian\nProcesses (DGPs), which are another generalization constructed by a\nhierarchical concatenation of GPs. In this work, we propose a generalization of\nTGPs named Deep Transformed Gaussian Processes (DTGPs), which follows the trend\nof concatenating layers of stochastic processes. More precisely, we obtain a\nmulti-layer model in which each layer is a TGP. This generalization implies an\nincrement of flexibility with respect to both TGPs and DGPs. Exact inference in\nsuch a model is intractable. However, we show that one can use variational\ninference to approximate the required computations yielding a straightforward\nextension of the popular DSVI inference algorithm Salimbeni et al (2017). The\nexperiments conducted evaluate the proposed novel DTGPs in multiple regression\ndatasets, achieving good scalability and performance.",
            "author": [
                "Francisco Javier S\u00e1ez-Maldonado",
                "Juan Maro\u00f1as",
                "Daniel Hern\u00e1ndez-Lobato"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18230v2",
                "http://arxiv.org/pdf/2310.18230v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18222v1",
            "title": "TBDLNet: a network for classifying multidrug-resistant and\n  drug-sensitive tuberculosis",
            "updated": "2023-10-27T15:51:33Z",
            "published": "2023-10-27T15:51:33Z",
            "summary": "This paper proposes applying a novel deep-learning model, TBDLNet, to\nrecognize CT images to classify multidrug-resistant and drug-sensitive\ntuberculosis automatically. The pre-trained ResNet50 is selected to extract\nfeatures. Three randomized neural networks are used to alleviate the\noverfitting problem. The ensemble of three RNNs is applied to boost the\nrobustness via majority voting. The proposed model is evaluated by five-fold\ncross-validation. Five indexes are selected in this paper, which are accuracy,\nsensitivity, precision, F1-score, and specificity. The TBDLNet achieves 0.9822\naccuracy, 0.9815 specificity, 0.9823 precision, 0.9829 sensitivity, and 0.9826\nF1-score, respectively. The TBDLNet is suitable for classifying\nmultidrug-resistant tuberculosis and drug-sensitive tuberculosis. It can detect\nmultidrug-resistant pulmonary tuberculosis as early as possible, which helps to\nadjust the treatment plan in time and improve the treatment effect.",
            "author": [
                "Ziquan Zhu",
                "Jing Tao",
                "Shuihua Wang",
                "Xin Zhang",
                "Yudong Zhang"
            ],
            "link": [
                "http://dx.doi.org/10.1002/ENG2.12815",
                "http://arxiv.org/abs/2310.18222v1",
                "http://arxiv.org/pdf/2310.18222v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18215v1",
            "title": "One Model Fits All: Cross-Region Taxi-Demand Forecasting",
            "updated": "2023-10-27T15:42:04Z",
            "published": "2023-10-27T15:42:04Z",
            "summary": "The growing demand for ride-hailing services has led to an increasing need\nfor accurate taxi demand prediction. Existing systems are limited to specific\nregions, lacking generalizability to unseen areas. This paper presents a novel\ntaxi demand forecasting system that leverages a graph neural network to capture\nspatial dependencies and patterns in urban environments. Additionally, the\nproposed system employs a region-neutral approach, enabling it to train a model\nthat can be applied to any region, including unseen regions. To achieve this,\nthe framework incorporates the power of Variational Autoencoder to disentangle\nthe input features into region-specific and region-neutral components. The\nregion-neutral features facilitate cross-region taxi demand predictions,\nallowing the model to generalize well across different urban areas.\nExperimental results demonstrate the effectiveness of the proposed system in\naccurately forecasting taxi demand, even in previously unobserved regions, thus\nshowcasing its potential for optimizing taxi services and improving\ntransportation efficiency on a broader scale.",
            "author": [
                "Ren Ozeki",
                "Haruki Yonekura",
                "Aidana Baimbetova",
                "Hamada Rizk",
                "Hirozumi Yamaguchi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18215v1",
                "http://arxiv.org/pdf/2310.18215v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18212v1",
            "title": "Robustness of Algorithms for Causal Structure Learning to Hyperparameter\n  Choice",
            "updated": "2023-10-27T15:34:08Z",
            "published": "2023-10-27T15:34:08Z",
            "summary": "Hyperparameters play a critical role in machine learning. Hyperparameter\ntuning can make the difference between state-of-the-art and poor prediction\nperformance for any algorithm, but it is particularly challenging for structure\nlearning due to its unsupervised nature. As a result, hyperparameter tuning is\noften neglected in favour of using the default values provided by a particular\nimplementation of an algorithm. While there have been numerous studies on\nperformance evaluation of causal discovery algorithms, how hyperparameters\naffect individual algorithms, as well as the choice of the best algorithm for a\nspecific problem, has not been studied in depth before. This work addresses\nthis gap by investigating the influence of hyperparameters on causal structure\nlearning tasks. Specifically, we perform an empirical evaluation of\nhyperparameter selection for some seminal learning algorithms on datasets of\nvarying levels of complexity. We find that, while the choice of algorithm\nremains crucial to obtaining state-of-the-art performance, hyperparameter\nselection in ensemble settings strongly influences the choice of algorithm, in\nthat a poor choice of hyperparameters can lead to analysts using algorithms\nwhich do not give state-of-the-art performance for their data.",
            "author": [
                "Damian Machlanski",
                "Spyridon Samothrakis",
                "Paul Clarke"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18212v1",
                "http://arxiv.org/pdf/2310.18212v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18209v1",
            "title": "Alignment and Outer Shell Isotropy for Hyperbolic Graph Contrastive\n  Learning",
            "updated": "2023-10-27T15:31:42Z",
            "published": "2023-10-27T15:31:42Z",
            "summary": "Learning good self-supervised graph representations that are beneficial to\ndownstream tasks is challenging. Among a variety of methods, contrastive\nlearning enjoys competitive performance. The embeddings of contrastive learning\nare arranged on a hypersphere that enables the Cosine distance measurement in\nthe Euclidean space. However, the underlying structure of many domains such as\ngraphs exhibits highly non-Euclidean latent geometry. To this end, we propose a\nnovel contrastive learning framework to learn high-quality graph embedding.\nSpecifically, we design the alignment metric that effectively captures the\nhierarchical data-invariant information, as well as we propose a substitute of\nuniformity metric to prevent the so-called dimensional collapse. We show that\nin the hyperbolic space one has to address the leaf- and height-level\nuniformity which are related to properties of trees, whereas in the ambient\nspace of the hyperbolic manifold, these notions translate into imposing an\nisotropic ring density towards boundaries of Poincar\\'e ball. This ring density\ncan be easily imposed by promoting the isotropic feature distribution on the\ntangent space of manifold. In the experiments, we demonstrate the efficacy of\nour proposed method across different hyperbolic graph embedding techniques in\nboth supervised and self-supervised learning settings.",
            "author": [
                "Yifei Zhang",
                "Hao Zhu",
                "Jiahong Liu",
                "Piotr Koniusz",
                "Irwin King"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18209v1",
                "http://arxiv.org/pdf/2310.18209v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18208v2",
            "title": "ArcheType: A Novel Framework for Open-Source Column Type Annotation\n  using Large Language Models",
            "updated": "2023-11-06T13:16:27Z",
            "published": "2023-10-27T15:31:22Z",
            "summary": "Existing deep-learning approaches to semantic column type annotation (CTA)\nhave important shortcomings: they rely on semantic types which are fixed at\ntraining time; require a large number of training samples per type and incur\nlarge run-time inference costs; and their performance can degrade when\nevaluated on novel datasets, even when types remain constant. Large language\nmodels have exhibited strong zero-shot classification performance on a wide\nrange of tasks and in this paper we explore their use for CTA. We introduce\nArcheType, a simple, practical method for context sampling, prompt\nserialization, model querying, and label remapping, which enables large\nlanguage models to solve CTA problems in a fully zero-shot manner. We ablate\neach component of our method separately, and establish that improvements to\ncontext sampling and label remapping provide the most consistent gains.\nArcheType establishes a new state-of-the-art performance on zero-shot CTA\nbenchmarks (including three new domain-specific benchmarks which we release\nalong with this paper), and when used in conjunction with classical CTA\ntechniques, it outperforms a SOTA DoDuo model on the fine-tuned SOTAB\nbenchmark. Our code is available at https://github.com/penfever/ArcheType.",
            "author": [
                "Benjamin Feuer",
                "Yurong Liu",
                "Chinmay Hegde",
                "Juliana Freire"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18208v2",
                "http://arxiv.org/pdf/2310.18208v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18207v1",
            "title": "INA: An Integrative Approach for Enhancing Negotiation Strategies with\n  Reward-Based Dialogue System",
            "updated": "2023-10-27T15:31:16Z",
            "published": "2023-10-27T15:31:16Z",
            "summary": "In this paper, we propose a novel negotiation dialogue agent designed for the\nonline marketplace. Our agent is integrative in nature i.e, it possesses the\ncapability to negotiate on price as well as other factors, such as the addition\nor removal of items from a deal bundle, thereby offering a more flexible and\ncomprehensive negotiation experience. We create a new dataset called\nIntegrative Negotiation Dataset (IND) to enable this functionality. For this\ndataset creation, we introduce a new semi-automated data creation method, which\ncombines defining negotiation intents, actions, and intent-action simulation\nbetween users and the agent to generate potential dialogue flows. Finally, the\nprompting of GPT-J, a state-of-the-art language model, is done to generate\ndialogues for a given intent, with a human-in-the-loop process for post-editing\nand refining minor errors to ensure high data quality. We employ a set of novel\nrewards, specifically tailored for the negotiation task to train our\nNegotiation Agent, termed as the Integrative Negotiation Agent (INA). These\nrewards incentivize the chatbot to learn effective negotiation strategies that\ncan adapt to various contextual requirements and price proposals. By leveraging\nthe IND, we train our model and conduct experiments to evaluate the\neffectiveness of our reward-based dialogue system for negotiation. Our results\ndemonstrate that the proposed approach and reward system significantly enhance\nthe agent's negotiation capabilities. The INA successfully engages in\nintegrative negotiations, displaying the ability to dynamically adjust prices\nand negotiate the inclusion or exclusion of items in a bundle deal",
            "author": [
                "Zishan Ahmad",
                "Suman Saurabh",
                "Vaishakh Sreekanth Menon",
                "Asif Ekbal",
                "Roshni Ramnani",
                "Anutosh Maitra"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18207v1",
                "http://arxiv.org/pdf/2310.18207v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16123v1",
            "title": "Exploring Multiple Neighborhood Neural Cellular Automata (MNNCA) for\n  Enhanced Texture Learning",
            "updated": "2023-10-27T15:16:19Z",
            "published": "2023-10-27T15:16:19Z",
            "summary": "Cellular Automata (CA) have long been foundational in simulating dynamical\nsystems computationally. With recent innovations, this model class has been\nbrought into the realm of deep learning by parameterizing the CA's update rule\nusing an artificial neural network, termed Neural Cellular Automata (NCA). This\nallows NCAs to be trained via gradient descent, enabling them to evolve into\nspecific shapes, generate textures, and mimic behaviors such as swarming.\nHowever, a limitation of traditional NCAs is their inability to exhibit\nsufficiently complex behaviors, restricting their potential in creative and\nmodeling tasks. Our research explores enhancing the NCA framework by\nincorporating multiple neighborhoods and introducing structured noise for seed\nstates. This approach is inspired by techniques that have historically\namplified the expressiveness of classical continuous CA. All code and example\nvideos are publicly available on https://github.com/MagnusPetersen/MNNCA.",
            "author": [
                "Magnus Petersen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16123v1",
                "http://arxiv.org/pdf/2311.16123v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "nlin.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18192v1",
            "title": "Artifact-Robust Graph-Based Learning in Digital Pathology",
            "updated": "2023-10-27T15:06:01Z",
            "published": "2023-10-27T15:06:01Z",
            "summary": "Whole slide images~(WSIs) are digitized images of tissues placed in glass\nslides using advanced scanners. The digital processing of WSIs is challenging\nas they are gigapixel images and stored in multi-resolution format. A common\nchallenge with WSIs is that perturbations/artifacts are inevitable during\nstoring the glass slides and digitizing them. These perturbations include\nmotion, which often arises from slide movement during placement, and changes in\nhue and brightness due to variations in staining chemicals and the quality of\ndigitizing scanners. In this work, a novel robust learning approach to account\nfor these artifacts is presented. Due to the size and resolution of WSIs and to\naccount for neighborhood information, graph-based methods are called for. We\nuse graph convolutional network~(GCN) to extract features from the graph\nrepresenting WSI. Through a denoiser {and pooling layer}, the effects of\nperturbations in WSIs are controlled and the output is followed by a\ntransformer for the classification of different grades of prostate cancer. To\ncompare the efficacy of the proposed approach, the model without denoiser is\ntrained and tested with WSIs without any perturbation and then different\nperturbations are introduced in WSIs and passed through the network with the\ndenoiser. The accuracy and kappa scores of the proposed model with prostate\ncancer dataset compared with non-robust algorithms show significant improvement\nin cancer diagnosis.",
            "author": [
                "Saba Heidari Gheshlaghi",
                "Milan Aryal",
                "Nasim Yahyasoltani",
                "Masoud Ganji"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18192v1",
                "http://arxiv.org/pdf/2310.18192v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18191v1",
            "title": "Is Scaling Learned Optimizers Worth It? Evaluating The Value of VeLO's\n  4000 TPU Months",
            "updated": "2023-10-27T15:04:00Z",
            "published": "2023-10-27T15:04:00Z",
            "summary": "We analyze VeLO (versatile learned optimizer), the largest scale attempt to\ntrain a general purpose \"foundational\" optimizer to date. VeLO was trained on\nthousands of machine learning tasks using over 4000 TPU months with the goal of\nproducing an optimizer capable of generalizing to new problems while being\nhyperparameter free, and outperforming industry standards such as Adam. We\nindependently evaluate VeLO on the MLCommons optimizer benchmark suite. We find\nthat, contrary to initial claims: (1) VeLO has a critical hyperparameter that\nneeds problem-specific tuning, (2) VeLO does not necessarily outperform\ncompetitors in quality of solution found, and (3) VeLO is not faster than\ncompeting optimizers at reducing the training loss. These observations call\ninto question VeLO's generality and the value of the investment in training it.",
            "author": [
                "Fady Rezk",
                "Antreas Antoniou",
                "Henry Gouk",
                "Timothy Hospedales"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18191v1",
                "http://arxiv.org/pdf/2310.18191v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18186v1",
            "title": "Model-free Posterior Sampling via Learning Rate Randomization",
            "updated": "2023-10-27T14:59:44Z",
            "published": "2023-10-27T14:59:44Z",
            "summary": "In this paper, we introduce Randomized Q-learning (RandQL), a novel\nrandomized model-free algorithm for regret minimization in episodic Markov\nDecision Processes (MDPs). To the best of our knowledge, RandQL is the first\ntractable model-free posterior sampling-based algorithm. We analyze the\nperformance of RandQL in both tabular and non-tabular metric space settings. In\ntabular MDPs, RandQL achieves a regret bound of order\n$\\widetilde{\\mathcal{O}}(\\sqrt{H^{5}SAT})$, where $H$ is the planning horizon,\n$S$ is the number of states, $A$ is the number of actions, and $T$ is the\nnumber of episodes. For a metric state-action space, RandQL enjoys a regret\nbound of order $\\widetilde{\\mathcal{O}}(H^{5/2} T^{(d_z+1)/(d_z+2)})$, where\n$d_z$ denotes the zooming dimension. Notably, RandQL achieves optimistic\nexploration without using bonuses, relying instead on a novel idea of learning\nrate randomization. Our empirical study shows that RandQL outperforms existing\napproaches on baseline exploration environments.",
            "author": [
                "Daniil Tiapkin",
                "Denis Belomestny",
                "Daniele Calandriello",
                "Eric Moulines",
                "Remi Munos",
                "Alexey Naumov",
                "Pierre Perrault",
                "Michal Valko",
                "Pierre Menard"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18186v1",
                "http://arxiv.org/pdf/2310.18186v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.04224v1",
            "title": "MELEP: A Novel Predictive Measure of Transferability in Multi-Label ECG\n  Analysis",
            "updated": "2023-10-27T14:57:10Z",
            "published": "2023-10-27T14:57:10Z",
            "summary": "We introduce MELEP, which stands for Muti-label Expected Log of Empirical\nPredictions, a novel measure to estimate how effective it is to transfer\nknowledge from a pre-trained model to a downstream task in a multi-label\nsettings. The measure is generic to work with new target data having a\ndifferent label set from source data. It is also computationally efficient,\nonly requires forward passing the downstream dataset through the pre-trained\nmodel once. To the best of our knowledge, we are the first to develop such a\ntransferability metric for multi-label ECG classification problems. Our\nexperiments show that MELEP can predict the performance of pre-trained\nconvolutional and recurrent deep neural networks, on small and imbalanced ECG\ndata. Specifically, strong correlation coefficients, with absolute values\nexceeding 0.6 in most cases, were observed between MELEP and the actual average\nF1 scores of the fine-tuned models.",
            "author": [
                "Cuong V. Nguyen",
                "Hieu Minh Duong",
                "Cuong D. Do"
            ],
            "link": [
                "http://arxiv.org/abs/2311.04224v1",
                "http://arxiv.org/pdf/2311.04224v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18177v1",
            "title": "Reinterpreting Fundamental Plane Correlations with Machine Learning",
            "updated": "2023-10-27T14:44:06Z",
            "published": "2023-10-27T14:44:06Z",
            "summary": "This work explores the relationships between galaxy sizes and related\nobservable galaxy properties in a large volume cosmological hydrodynamical\nsimulation. The objectives of this work are to both develop a better\nunderstanding of the correlations between galaxy properties and the influence\nof environment on galaxy physics in order to build an improved model for the\ngalaxy sizes, building off of the {\\it fundamental plane}. With an accurate\nintrinsic galaxy size predictor, the residuals in the observed galaxy sizes can\npotentially be used for multiple cosmological applications, including making\nmeasurements of galaxy velocities in spectroscopic samples, estimating the rate\nof cosmic expansion, and constraining the uncertainties in the photometric\nredshifts of galaxies. Using projection pursuit regression, the model\naccurately predicts intrinsic galaxy sizes and have residuals which have\nlimited correlation with galaxy properties. The model decreases the spatial\ncorrelation of galaxy size residuals by a factor of $\\sim$ 5 at small scales\ncompared to the baseline correlation when the mean size is used as a predictor.",
            "author": [
                "Chad Schafer",
                "Sukhdeep Singh",
                "Yesukhei Jagvaral"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18177v1",
                "http://arxiv.org/pdf/2310.18177v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.00718v1",
            "title": "Chat GPT Integrated with Voice Assistant as Learning Oral Chat-based\n  Constructive Communication to Improve Communicative Competence for EFL\n  earners",
            "updated": "2023-10-27T14:29:36Z",
            "published": "2023-10-27T14:29:36Z",
            "summary": "Chat GPT belongs to the category of Generative Pre-trained Transformer (GPT)\nlanguage models, which have received specialized training to produce text based\non natural language inputs. Its purpose is to imitate human-like conversation\nand can be implemented in multiple applications, such as chatbots, virtual\nassistants, and language translation systems, starting with an introduction to\nthe new trends and differences between artificial intelligence, machine\nlearning, and artificial neural networks, and highlighting the rigorous\nlanguage logic and powerful text generation capabilities of Chat GPT. This\npaper delves into how advances in artificial intelligence will shape e-learning\nin the coming decades, particularly in terms of Chat- GPT's ability to improve\nlearners' Communicative Competence when English is a second language. The\ncombination of new trends in artificial intelligence, mainly in the particular\ncase of English as a second language, and, at the academic level, chatbot\ntechnology, will be the next step in the replacement of the human academic\ncommunity by virtual assistants, apparently until a certain point. Despite the\ncontroversy, this very innovative solution will be able to bridge the gap\nbetween technology and education. Moreover, such innovative practices\nfacilitate communication by enabling its inclusion in various applications,\nincluding virtual assistants, chatbots, and language education. Keyword: Chat\nGPT, artificial intelligence, Communicative Competence, Communicative Language\nTeaching (CLT)",
            "author": [
                "Wei Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.00718v1",
                "http://arxiv.org/pdf/2311.00718v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18168v3",
            "title": "Personas as a Way to Model Truthfulness in Language Models",
            "updated": "2023-11-21T09:19:03Z",
            "published": "2023-10-27T14:27:43Z",
            "summary": "Large Language Models (LLMs) are trained on vast amounts of text from the\ninternet, which contains both factual and misleading information about the\nworld. Can language models discern truth from falsehood in this contradicting\ndata? Expanding on the view that LLMs can model different communicative agents,\nwe present the persona hypothesis: LLMs can cluster agents into personas using\ncommon features of their generations. For instance, a truthful persona is a\ngroup of agents that are likely to produce truthful text and that share similar\nfeatures like formal writing styles and scientific references. By modeling this\npersona, LLMs can generalize truthfulness beyond the specific contexts in which\neach agent generated the training text. For example, the model can infer that\nthe agent ``Wikipedia'' will behave truthfully on topics that were only\ngenerated by ``Science'' because they both belong to the truthful persona. We\nshow evidence for the persona hypothesis via two observations: (1) we can probe\nwhether a model's answer will be truthful before it is generated; (2)\nfinetuning a model on a set of facts improves its truthfulness on unseen\ntopics. Next, using arithmetics as a synthetic environment, we show that\nlanguage models can separate true and false statements, and generalize\ntruthfulness across agents; but only if agents in the training data share a\ntruthful generative process that enables the creation of a truthful persona.\nOverall, our findings suggest that models can exploit hierarchical structures\nin the data to learn abstract concepts like truthfulness.",
            "author": [
                "Nitish Joshi",
                "Javier Rando",
                "Abulhair Saparov",
                "Najoung Kim",
                "He He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18168v3",
                "http://arxiv.org/pdf/2310.18168v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18165v1",
            "title": "Enhancing Enterprise Network Security: Comparing Machine-Level and\n  Process-Level Analysis for Dynamic Malware Detection",
            "updated": "2023-10-27T14:17:35Z",
            "published": "2023-10-27T14:17:35Z",
            "summary": "Analysing malware is important to understand how malicious software works and\nto develop appropriate detection and prevention methods. Dynamic analysis can\novercome evasion techniques commonly used to bypass static analysis and provide\ninsights into malware runtime activities. Much research on dynamic analysis\nfocused on investigating machine-level information (e.g., CPU, memory, network\nusage) to identify whether a machine is running malicious activities. A\nmalicious machine does not necessarily mean all running processes on the\nmachine are also malicious. If we can isolate the malicious process instead of\nisolating the whole machine, we could kill the malicious process, and the\nmachine can keep doing its job. Another challenge dynamic malware detection\nresearch faces is that the samples are executed in one machine without any\nbackground applications running. It is unrealistic as a computer typically runs\nmany benign (background) applications when a malware incident happens. Our\nexperiment with machine-level data shows that the existence of background\napplications decreases previous state-of-the-art accuracy by about 20.12% on\naverage. We also proposed a process-level Recurrent Neural Network (RNN)-based\ndetection model. Our proposed model performs better than the machine-level\ndetection model; 0.049 increase in detection rate and a false-positive rate\nbelow 0.1.",
            "author": [
                "Baskoro Adi Pratomo",
                "Toby Jackson",
                "Pete Burnap",
                "Andrew Hood",
                "Eirini Anthi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18165v1",
                "http://arxiv.org/pdf/2310.18165v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03374v1",
            "title": "Generative AI for Software Metadata: Overview of the Information\n  Retrieval in Software Engineering Track at FIRE 2023",
            "updated": "2023-10-27T14:13:23Z",
            "published": "2023-10-27T14:13:23Z",
            "summary": "The Information Retrieval in Software Engineering (IRSE) track aims to\ndevelop solutions for automated evaluation of code comments in a machine\nlearning framework based on human and large language model generated labels. In\nthis track, there is a binary classification task to classify comments as\nuseful and not useful. The dataset consists of 9048 code comments and\nsurrounding code snippet pairs extracted from open source github C based\nprojects and an additional dataset generated individually by teams using large\nlanguage models. Overall 56 experiments have been submitted by 17 teams from\nvarious universities and software companies. The submissions have been\nevaluated quantitatively using the F1-Score and qualitatively based on the type\nof features developed, the supervised learning model used and their\ncorresponding hyper-parameters. The labels generated from large language models\nincrease the bias in the prediction model but lead to less over-fitted results.",
            "author": [
                "Srijoni Majumdar",
                "Soumen Paul",
                "Debjyoti Paul",
                "Ayan Bandyopadhyay",
                "Samiran Chattopadhyay",
                "Partha Pratim Das",
                "Paul D Clough",
                "Prasenjit Majumder"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03374v1",
                "http://arxiv.org/pdf/2311.03374v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18162v1",
            "title": "Proportional Fairness in Clustering: A Social Choice Perspective",
            "updated": "2023-10-27T14:12:56Z",
            "published": "2023-10-27T14:12:56Z",
            "summary": "We study the proportional clustering problem of Chen et al. [ICML'19] and\nrelate it to the area of multiwinner voting in computational social choice. We\nshow that any clustering satisfying a weak proportionality notion of Brill and\nPeters [EC'23] simultaneously obtains the best known approximations to the\nproportional fairness notion of Chen et al. [ICML'19], but also to individual\nfairness [Jung et al., FORC'20] and the \"core\" [Li et al. ICML'21]. In fact, we\nshow that any approximation to proportional fairness is also an approximation\nto individual fairness and vice versa. Finally, we also study stronger notions\nof proportional representation, in which deviations do not only happen to\nsingle, but multiple candidate centers, and show that stronger proportionality\nnotions of Brill and Peters [EC'23] imply approximations to these stronger\nguarantees.",
            "author": [
                "Leon Kellerhals",
                "Jannik Peters"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18162v1",
                "http://arxiv.org/pdf/2310.18162v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18159v1",
            "title": "DESiRED -- Dynamic, Enhanced, and Smart iRED: A P4-AQM with Deep\n  Reinforcement Learning and In-band Network Telemetry",
            "updated": "2023-10-27T14:06:57Z",
            "published": "2023-10-27T14:06:57Z",
            "summary": "Active Queue Management (AQM) is a mechanism employed to alleviate transient\ncongestion in network device buffers, such as routers and switches. Traditional\nAQM algorithms use fixed thresholds, like target delay or queue occupancy, to\ncompute random packet drop probabilities. A very small target delay can\nincrease packet losses and reduce link utilization, while a large target delay\nmay increase queueing delays while lowering drop probability. Due to dynamic\nnetwork traffic characteristics, where traffic fluctuations can lead to\nsignificant queue variations, maintaining a fixed threshold AQM may not suit\nall applications. Consequently, we explore the question: \\textit{What is the\nideal threshold (target delay) for AQMs?} In this work, we introduce DESiRED\n(Dynamic, Enhanced, and Smart iRED), a P4-based AQM that leverages precise\nnetwork feedback from In-band Network Telemetry (INT) to feed a Deep\nReinforcement Learning (DRL) model. This model dynamically adjusts the target\ndelay based on rewards that maximize application Quality of Service (QoS). We\nevaluate DESiRED in a realistic P4-based test environment running an MPEG-DASH\nservice. Our findings demonstrate up to a 90x reduction in video stall and a\n42x increase in high-resolution video playback quality when the target delay is\nadjusted dynamically by DESiRED.",
            "author": [
                "Leandro C. de Almeida",
                "Washington Rodrigo Dias da Silva",
                "Thiago C. Tavares",
                "Rafael Pasquini",
                "Chrysa Papagianni",
                "F\u00e1bio L. Verdi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18159v1",
                "http://arxiv.org/pdf/2310.18159v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18152v2",
            "title": "Disentangled Representation Learning with Large Language Models for\n  Text-Attributed Graphs",
            "updated": "2023-11-06T12:54:14Z",
            "published": "2023-10-27T14:00:04Z",
            "summary": "Text-attributed graphs (TAGs) are prevalent on the web and research over TAGs\nsuch as citation networks, e-commerce networks and social networks has\nattracted considerable attention in the web community. Recently, large language\nmodels (LLMs) have demonstrated exceptional capabilities across a wide range of\ntasks. However, the existing works focus on harnessing the potential of LLMs\nsolely relying on prompts to convey graph structure information to LLMs, thus\nsuffering from insufficient understanding of the complex structural\nrelationships within TAGs. To address this problem, in this paper we present\nthe Disentangled Graph-Text Learner (DGTL) model, which is able to enhance the\nreasoning and predicting capabilities of LLMs for TAGs. Our proposed DGTL model\nincorporates graph structure information through tailored disentangled graph\nneural network (GNN) layers, enabling LLMs to capture the intricate\nrelationships hidden in text-attributed graphs from multiple structural\nfactors. Furthermore, DGTL operates with frozen pre-trained LLMs, reducing\ncomputational costs and allowing much more flexibility in combining with\ndifferent LLM models. Experimental evaluations demonstrate the effectiveness of\nthe proposed DGTL model on achieving superior or comparable performance over\nstate-of-the-art baselines. Additionally, we also demonstrate that our DGTL\nmodel can offer natural language explanations for predictions, thereby\nsignificantly enhancing model interpretability.",
            "author": [
                "Yijian Qin",
                "Xin Wang",
                "Ziwei Zhang",
                "Wenwu Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18152v2",
                "http://arxiv.org/pdf/2310.18152v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18144v3",
            "title": "Improving Intrinsic Exploration by Creating Stationary Objectives",
            "updated": "2023-12-04T17:32:31Z",
            "published": "2023-10-27T13:51:18Z",
            "summary": "Exploration bonuses in reinforcement learning guide long-horizon exploration\nby defining custom intrinsic objectives. Several exploration objectives like\ncount-based bonuses, pseudo-counts, and state-entropy maximization are\nnon-stationary and hence are difficult to optimize for the agent. While this\nissue is generally known, it is usually omitted and solutions remain\nunder-explored. The key contribution of our work lies in transforming the\noriginal non-stationary rewards into stationary rewards through an augmented\nstate representation. For this purpose, we introduce the Stationary Objectives\nFor Exploration (SOFE) framework. SOFE requires identifying sufficient\nstatistics for different exploration bonuses and finding an efficient encoding\nof these statistics to use as input to a deep network. SOFE is based on\nproposing state augmentations that expand the state space but hold the promise\nof simplifying the optimization of the agent's objective. We show that SOFE\nimproves the performance of several exploration objectives, including\ncount-based bonuses, pseudo-counts, and state-entropy maximization. Moreover,\nSOFE outperforms prior methods that attempt to stabilize the optimization of\nintrinsic objectives. We demonstrate the efficacy of SOFE in hard-exploration\nproblems, including sparse-reward tasks, pixel-based observations, 3D\nnavigation, and procedurally generated environments.",
            "author": [
                "Roger Creus Castanyer",
                "Joshua Romoff",
                "Glen Berseth"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18144v3",
                "http://arxiv.org/pdf/2310.18144v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18142v1",
            "title": "Semi-Supervised Panoptic Narrative Grounding",
            "updated": "2023-10-27T13:47:09Z",
            "published": "2023-10-27T13:47:09Z",
            "summary": "Despite considerable progress, the advancement of Panoptic Narrative\nGrounding (PNG) remains hindered by costly annotations. In this paper, we\nintroduce a novel Semi-Supervised Panoptic Narrative Grounding (SS-PNG)\nlearning scheme, capitalizing on a smaller set of labeled image-text pairs and\na larger set of unlabeled pairs to achieve competitive performance. Unlike\nvisual segmentation tasks, PNG involves one pixel belonging to multiple\nopen-ended nouns. As a result, existing multi-class based semi-supervised\nsegmentation frameworks cannot be directly applied to this task. To address\nthis challenge, we first develop a novel SS-PNG Network (SS-PNG-NW) tailored to\nthe SS-PNG setting. We thoroughly investigate strategies such as Burn-In and\ndata augmentation to determine the optimal generic configuration for the\nSS-PNG-NW. Additionally, to tackle the issue of imbalanced pseudo-label\nquality, we propose a Quality-Based Loss Adjustment (QLA) approach to adjust\nthe semi-supervised objective, resulting in an enhanced SS-PNG-NW+. Employing\nour proposed QLA, we improve BCE Loss and Dice loss at pixel and mask levels,\nrespectively. We conduct extensive experiments on PNG datasets, with our\nSS-PNG-NW+ demonstrating promising results comparable to fully-supervised\nmodels across all data ratios. Remarkably, our SS-PNG-NW+ outperforms\nfully-supervised models with only 30% and 50% supervision data, exceeding their\nperformance by 0.8% and 1.1% respectively. This highlights the effectiveness of\nour proposed SS-PNG-NW+ in overcoming the challenges posed by limited\nannotations and enhancing the applicability of PNG tasks. The source code is\navailable at https://github.com/nini0919/SSPNG.",
            "author": [
                "Danni Yang",
                "Jiayi Ji",
                "Xiaoshuai Sun",
                "Haowei Wang",
                "Yinan Li",
                "Yiwei Ma",
                "Rongrong Ji"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3581783.3612259",
                "http://arxiv.org/abs/2310.18142v1",
                "http://arxiv.org/pdf/2310.18142v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18141v1",
            "title": "Unsupervised Representation Learning for Diverse Deformable Shape\n  Collections",
            "updated": "2023-10-27T13:45:30Z",
            "published": "2023-10-27T13:45:30Z",
            "summary": "We introduce a novel learning-based method for encoding and manipulating 3D\nsurface meshes. Our method is specifically designed to create an interpretable\nembedding space for deformable shape collections. Unlike previous 3D mesh\nautoencoders that require meshes to be in a 1-to-1 correspondence, our approach\nis trained on diverse meshes in an unsupervised manner. Central to our method\nis a spectral pooling technique that establishes a universal latent space,\nbreaking free from traditional constraints of mesh connectivity and shape\ncategories. The entire process consists of two stages. In the first stage, we\nemploy the functional map paradigm to extract point-to-point (p2p) maps between\na collection of shapes in an unsupervised manner. These p2p maps are then\nutilized to construct a common latent space, which ensures straightforward\ninterpretation and independence from mesh connectivity and shape category.\nThrough extensive experiments, we demonstrate that our method achieves\nexcellent reconstructions and produces more realistic and smoother\ninterpolations than baseline approaches.",
            "author": [
                "Sara Hahner",
                "Souhaib Attaiki",
                "Jochen Garcke",
                "Maks Ovsjanikov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18141v1",
                "http://arxiv.org/pdf/2310.18141v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19903v1",
            "title": "A Multi-agent Reinforcement Learning Study of Emergence of Social\n  Classes out of Arbitrary Governance: The Role of Environment",
            "updated": "2023-10-27T13:31:53Z",
            "published": "2023-10-27T13:31:53Z",
            "summary": "There are several theories in economics regarding the roots or causes of\nprosperity in a society. One of these theories or hypotheses -- named geography\nhypothesis -- mentions that the reason why some countries are prosperous and\nsome others are poor is the geographical location of the countries in the world\nas makes their climate and environment favorable or unfavorable regarding\nnatural resources. Another competing hypothesis states that man-made\ninstitutions particularly inclusive political institutions are the reasons why\nsome countries are prosperous and some others are poor. On the other hand,\nthere is a specific political theory developed for the long-term social\ndevelopment in Iran -- named Arbitrary Rule and Aridisolatic Society which\nparticularly emphasizes on the role of aridity to shape arbitrary political and\neconomical institutions in Iran, without any functional social classes in the\nsociety. In this paper, by extending the AI-Economist -- a recently developed\ntwo-level multi-agent reinforcement learning environment -- I show that when\nthe central planner is ruling the environment by arbitrary rules, the society\nevolves through different paths in different environments. In the environment\nhaving band-like vertical isolated patches of natural resources, all mobile\nagents are equally exploited by the central planner and the central planner is\nalso not gaining any income, while in the society having more uniformly\ndistributed natural resources, the productivity and Maximin are higher and the\nsociety generates a heterogeneous stratified social structure. All these\nfindings provide a partial answer to the above debate and reconcile the role of\ngeography and political institutions on the long-term development in a region.",
            "author": [
                "Aslan S. Dizaji"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19903v1",
                "http://arxiv.org/pdf/2310.19903v1"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18131v2",
            "title": "End-to-end Video Gaze Estimation via Capturing Head-face-eye\n  Spatial-temporal Interaction Context",
            "updated": "2023-11-01T09:13:29Z",
            "published": "2023-10-27T13:23:38Z",
            "summary": "In this letter, we propose a new method, Multi-Clue Gaze (MCGaze), to\nfacilitate video gaze estimation via capturing spatial-temporal interaction\ncontext among head, face, and eye in an end-to-end learning way, which has not\nbeen well concerned yet. The main advantage of MCGaze is that the tasks of clue\nlocalization of head, face, and eye can be solved jointly for gaze estimation\nin a one-step way, with joint optimization to seek optimal performance. During\nthis, spatial-temporal context exchange happens among the clues on the head,\nface, and eye. Accordingly, the final gazes obtained by fusing features from\nvarious queries can be aware of global clues from heads and faces, and local\nclues from eyes simultaneously, which essentially leverages performance.\nMeanwhile, the one-step running way also ensures high running efficiency.\nExperiments on the challenging Gaze360 dataset verify the superiority of our\nproposition. The source code will be released at\nhttps://github.com/zgchen33/MCGaze.",
            "author": [
                "Yiran Guan",
                "Zhuoguang Chen",
                "Wenzheng Zeng",
                "Zhiguo Cao",
                "Yang Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18131v2",
                "http://arxiv.org/pdf/2310.18131v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18129v1",
            "title": "TabAttention: Learning Attention Conditionally on Tabular Data",
            "updated": "2023-10-27T13:21:37Z",
            "published": "2023-10-27T13:21:37Z",
            "summary": "Medical data analysis often combines both imaging and tabular data processing\nusing machine learning algorithms. While previous studies have investigated the\nimpact of attention mechanisms on deep learning models, few have explored\nintegrating attention modules and tabular data. In this paper, we introduce\nTabAttention, a novel module that enhances the performance of Convolutional\nNeural Networks (CNNs) with an attention mechanism that is trained\nconditionally on tabular data. Specifically, we extend the Convolutional Block\nAttention Module to 3D by adding a Temporal Attention Module that uses\nmulti-head self-attention to learn attention maps. Furthermore, we enhance all\nattention modules by integrating tabular data embeddings. Our approach is\ndemonstrated on the fetal birth weight (FBW) estimation task, using 92 fetal\nabdominal ultrasound video scans and fetal biometry measurements. Our results\nindicate that TabAttention outperforms clinicians and existing methods that\nrely on tabular and/or imaging data for FBW prediction. This novel approach has\nthe potential to improve computer-aided diagnosis in various clinical workflows\nwhere imaging and tabular data are combined. We provide a source code for\nintegrating TabAttention in CNNs at\nhttps://github.com/SanoScience/Tab-Attention.",
            "author": [
                "Michal K. Grzeszczyk",
                "Szymon P\u0142otka",
                "Beata Rebizant",
                "Katarzyna Kosi\u0144ska-Kaczy\u0144ska",
                "Micha\u0142 Lipa",
                "Robert Brawura-Biskupski-Samaha",
                "Przemys\u0142aw Korzeniowski",
                "Tomasz Trzci\u0144ski",
                "Arkadiusz Sitek"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-43990-2_33",
                "http://arxiv.org/abs/2310.18129v1",
                "http://arxiv.org/pdf/2310.18129v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18127v1",
            "title": "Ask more, know better: Reinforce-Learned Prompt Questions for Decision\n  Making with Large Language Models",
            "updated": "2023-10-27T13:19:19Z",
            "published": "2023-10-27T13:19:19Z",
            "summary": "Large language models (LLMs) demonstrate their promise in tackling\ncomplicated practical challenges by combining action-based policies with chain\nof thought (CoT) reasoning. Having high-quality prompts on hand, however, is\nvital to the framework's effectiveness. Currently, these prompts are\nhandcrafted utilizing extensive human labor, resulting in CoT policies that\nfrequently fail to generalize. Human intervention is also required in order to\ndevelop grounding functions that ensure low-level controllers appropriately\nprocess CoT reasoning. In this paper, we take the first step towards a fully\nintegrated end-to-end framework for task-solving in real settings employing\ncomplicated reasoning. To that purpose, we offer a new leader-follower bilevel\nframework capable of learning to ask relevant questions (prompts) and\nsubsequently undertaking reasoning to guide the learning of actions to be\nperformed in an environment. A good prompt should make introspective revisions\nbased on historical findings, leading the CoT to consider the anticipated\ngoals. A prompt-generator policy has its own aim in our system, allowing it to\nadapt to the action policy and automatically root the CoT process towards\noutputs that lead to decisive, high-performing actions. Meanwhile, the action\npolicy is learning how to use the CoT outputs to take specific actions. Our\nempirical data reveal that our system outperforms leading methods in agent\nlearning benchmarks such as Overcooked and FourRoom.",
            "author": [
                "Xue Yan",
                "Yan Song",
                "Xinyu Cui",
                "Filippos Christianos",
                "Haifeng Zhang",
                "David Henry Mguni",
                "Jun Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18127v1",
                "http://arxiv.org/pdf/2310.18127v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18123v1",
            "title": "Sample Complexity Bounds for Score-Matching: Causal Discovery and\n  Generative Modeling",
            "updated": "2023-10-27T13:09:56Z",
            "published": "2023-10-27T13:09:56Z",
            "summary": "This paper provides statistical sample complexity bounds for score-matching\nand its applications in causal discovery. We demonstrate that accurate\nestimation of the score function is achievable by training a standard deep ReLU\nneural network using stochastic gradient descent. We establish bounds on the\nerror rate of recovering causal relationships using the score-matching-based\ncausal discovery method of Rolland et al. [2022], assuming a sufficiently good\nestimation of the score function. Finally, we analyze the upper bound of\nscore-matching estimation within the score-based generative modeling, which has\nbeen applied for causal discovery but is also of independent interest within\nthe domain of generative models.",
            "author": [
                "Zhenyu Zhu",
                "Francesco Locatello",
                "Volkan Cevher"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18123v1",
                "http://arxiv.org/pdf/2310.18123v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18119v1",
            "title": "Towards a Unified Conversational Recommendation System: Multi-task\n  Learning via Contextualized Knowledge Distillation",
            "updated": "2023-10-27T13:06:24Z",
            "published": "2023-10-27T13:06:24Z",
            "summary": "In Conversational Recommendation System (CRS), an agent is asked to recommend\na set of items to users within natural language conversations. To address the\nneed for both conversational capability and personalized recommendations, prior\nworks have utilized separate recommendation and dialogue modules. However, such\napproach inevitably results in a discrepancy between recommendation results and\ngenerated responses. To bridge the gap, we propose a multi-task learning for a\nunified CRS, where a single model jointly learns both tasks via Contextualized\nKnowledge Distillation (ConKD). We introduce two versions of ConKD: hard gate\nand soft gate. The former selectively gates between two task-specific teachers,\nwhile the latter integrates knowledge from both teachers. Our gates are\ncomputed on-the-fly in a context-specific manner, facilitating flexible\nintegration of relevant knowledge. Extensive experiments demonstrate that our\nsingle model significantly improves recommendation performance while enhancing\nfluency, and achieves comparable results in terms of diversity.",
            "author": [
                "Yeongseo Jung",
                "Eunseo Jung",
                "Lei Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18119v1",
                "http://arxiv.org/pdf/2310.18119v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18118v1",
            "title": "A Global Multi-Unit Calibration as a Method for Large Scale IoT\n  Particulate Matter Monitoring Systems Deployments",
            "updated": "2023-10-27T13:04:53Z",
            "published": "2023-10-27T13:04:53Z",
            "summary": "Scalable and effective calibration is a fundamental requirement for Low Cost\nAir Quality Monitoring Systems and will enable accurate and pervasive\nmonitoring in cities. Suffering from environmental interferences and\nfabrication variance, these devices need to encompass sensors specific and\ncomplex calibration processes for reaching a sufficient accuracy to be deployed\nas indicative measurement devices in Air Quality (AQ) monitoring networks.\nConcept and sensor drift often force calibration process to be frequently\nrepeated. These issues lead to unbearable calibration costs which denies their\nmassive deployment when accuracy is a concern. In this work, We propose a zero\ntransfer samples, global calibration methodology as a technological enabler for\nIoT AQ multisensory devices which relies on low cost Particulate Matter (PM)\nsensors. This methodology is based on field recorded responses from a limited\nnumber of IoT AQ multisensors units and machine learning concepts and can be\nuniversally applied to all units of the same type. A multi season test campaign\nshown that, when applied to different sensors, this methodology performances\nmatch those of state of the art methodology which requires to derive different\ncalibration parameters for each different unit. If confirmed, these results\nshow that, when properly derived, a global calibration law can be exploited for\na large number of networked devices with dramatic cost reduction eventually\nallowing massive deployment of accurate IoT AQ monitoring devices. Furthermore,\nthis calibration model could be easily embedded on board of the device or\nimplemented on the edge allowing immediate access to accurate readings for\npersonal exposure monitor applications as well as reducing long range data\ntransfer needs.",
            "author": [
                "Saverio De Vito",
                "Gerardo D Elia",
                "Sergio Ferlito",
                "Girolamo Di Francia",
                "Milos Davidovic",
                "Duska Kleut",
                "Danka Stojanovic",
                "Milena Jovasevic Stojanovic"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TIM.2023.3331428",
                "http://arxiv.org/abs/2310.18118v1",
                "http://arxiv.org/pdf/2310.18118v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18116v2",
            "title": "Direct Unsupervised Denoising",
            "updated": "2023-12-04T17:38:31Z",
            "published": "2023-10-27T13:02:12Z",
            "summary": "Traditional supervised denoisers are trained using pairs of noisy input and\nclean target images. They learn to predict a central tendency of the posterior\ndistribution over possible clean images. When, e.g., trained with the popular\nquadratic loss function, the network's output will correspond to the minimum\nmean square error (MMSE) estimate. Unsupervised denoisers based on Variational\nAutoEncoders (VAEs) have succeeded in achieving state-of-the-art results while\nrequiring only unpaired noisy data as training input. In contrast to the\ntraditional supervised approach, unsupervised denoisers do not directly produce\na single prediction, such as the MMSE estimate, but allow us to draw samples\nfrom the posterior distribution of clean solutions corresponding to the noisy\ninput. To approximate the MMSE estimate during inference, unsupervised methods\nhave to create and draw a large number of samples - a computationally expensive\nprocess - rendering the approach inapplicable in many situations. Here, we\npresent an alternative approach that trains a deterministic network alongside\nthe VAE to directly predict a central tendency. Our method achieves results\nthat surpass the results achieved by the unsupervised method at a fraction of\nthe computational cost.",
            "author": [
                "Benjamin Salmon",
                "Alexander Krull"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18116v2",
                "http://arxiv.org/pdf/2310.18116v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18112v1",
            "title": "er.autopilot 1.0: The Full Autonomous Stack for Oval Racing at High\n  Speeds",
            "updated": "2023-10-27T12:52:34Z",
            "published": "2023-10-27T12:52:34Z",
            "summary": "The Indy Autonomous Challenge (IAC) brought together for the first time in\nhistory nine autonomous racing teams competing at unprecedented speed and in\nhead-to-head scenario, using independently developed software on open-wheel\nracecars. This paper presents the complete software architecture used by team\nTII EuroRacing (TII-ER), covering all the modules needed to avoid static\nobstacles, perform active overtakes and reach speeds above 75 m/s (270 km/h).\nIn addition to the most common modules related to perception, planning, and\ncontrol, we discuss the approaches used for vehicle dynamics modelling,\nsimulation, telemetry, and safety. Overall results and the performance of each\nmodule are described, as well as the lessons learned during the first two\nevents of the competition on oval tracks, where the team placed respectively\nsecond and third.",
            "author": [
                "Ayoub Raji",
                "Danilo Caporale",
                "Francesco Gatti",
                "Andrea Giove",
                "Micaela Verucchi",
                "Davide Malatesta",
                "Nicola Musiu",
                "Alessandro Toschi",
                "Silviu Roberto Popitanu",
                "Fabio Bagni",
                "Massimiliano Bosi",
                "Alexander Liniger",
                "Marko Bertogna",
                "Daniele Morra",
                "Francesco Amerotti",
                "Luca Bartoli",
                "Federico Martello",
                "Riccardo Porta"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18112v1",
                "http://arxiv.org/pdf/2310.18112v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18111v1",
            "title": "Ab initio study of transition paths between (meta)stable phases of Nb\n  and Ta-substituted Nb",
            "updated": "2023-10-27T12:52:20Z",
            "published": "2023-10-27T12:52:20Z",
            "summary": "Although Niobium is a well characterized material it still shows some\nanomalies that are not yet understood. Therefore we revisit its metastable\nphases using density functional theory. First, we systematically compare\nenergies and ground state volumes of chosen crystal structures and discuss\npossible transition paths to the bcc ground state structure and the energy\nlandscape for tetragonal distortions. Furthermore, we discuss their stability\nby means of their phonon spectra and vibronic free energies. Second we analyze\nthe impact of tantalum impurities on phase stability. Surprisingly we find new\naspects of the energy landscape of the material which have been overlooked so\nfar: A new local energy minimum on the bcc to omega transition path, a flat\nenergy landscape with respect to uniaxial strain along [111] and a considerable\nstabilization of the sigma phase by Ta substitution.",
            "author": [
                "Susanne Kunzmann",
                "Thomas Hammerschmidt",
                "Gabi Schierning",
                "Anna Gr\u00fcnebohm"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18111v1",
                "http://arxiv.org/pdf/2310.18111v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18108v1",
            "title": "Transductive conformal inference with adaptive scores",
            "updated": "2023-10-27T12:48:30Z",
            "published": "2023-10-27T12:48:30Z",
            "summary": "Conformal inference is a fundamental and versatile tool that provides\ndistribution-free guarantees for many machine learning tasks. We consider the\ntransductive setting, where decisions are made on a test sample of $m$ new\npoints, giving rise to $m$ conformal $p$-values. {While classical results only\nconcern their marginal distribution, we show that their joint distribution\nfollows a P\\'olya urn model, and establish a concentration inequality for their\nempirical distribution function.} The results hold for arbitrary exchangeable\nscores, including {\\it adaptive} ones that can use the covariates of the\ntest+calibration samples at training stage for increased accuracy. We\ndemonstrate the usefulness of these theoretical results through uniform,\nin-probability guarantees for two machine learning tasks of current interest:\ninterval prediction for transductive transfer learning and novelty detection\nbased on two-class classification.",
            "author": [
                "Ulysse Gazin",
                "Gilles Blanchard",
                "Etienne Roquain"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18108v1",
                "http://arxiv.org/pdf/2310.18108v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18103v1",
            "title": "A Novel Application of Polynomial Solvers in mmWave Analog Radio\n  Beamforming",
            "updated": "2023-10-27T12:41:41Z",
            "published": "2023-10-27T12:41:41Z",
            "summary": "Beamforming is a signal processing technique where an array of antenna\nelements can be steered to transmit and receive radio signals in a specific\ndirection. The usage of millimeter wave (mmWave) frequencies and multiple input\nmultiple output (MIMO) beamforming are considered as the key innovations of 5th\nGeneration (5G) and beyond communication systems. The technique initially\nperforms a beam alignment procedure, followed by data transfer in the aligned\ndirections between the transmitter and the receiver. Traditionally, beam\nalignment involves periodical and exhaustive beam sweeping at both transmitter\nand the receiver, which is a slow process causing extra communication overhead\nwith MIMO and massive MIMO radio units. In applications such as beam tracking,\nangular velocity, beam steering etc., the beam alignment procedure is optimized\nby estimating the beam directions using first order polynomial approximations.\nRecent learning-based SOTA strategies for fast mmWave beam alignment also\nrequire exploration over exhaustive beam pairs during the training procedure,\ncausing overhead to learning strategies for higher antenna configurations. In\nthis work, we first optimize the beam alignment cost functions e.g. the data\nrate, to reduce the beam sweeping overhead by applying polynomial\napproximations of its partial derivatives which can then be solved as a system\nof polynomial equations using well-known tools from algebraic geometry. At this\npoint, a question arises: 'what is a good polynomial approximation?' In this\nwork, we attempt to obtain a 'good polynomial approximation'. Preliminary\nexperiments indicate that our estimated polynomial approximations attain a\nso-called sweet-spot in terms of the solver speed and accuracy, when evaluated\non test beamforming problems.",
            "author": [
                "Snehal Bhayani",
                "Praneeth Susarla",
                "S. S. Krishna Chaitanya Bulusu",
                "Olli Silven",
                "Markku Juntti",
                "Janne Heikkila"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18103v1",
                "http://arxiv.org/pdf/2310.18103v1"
            ],
            "primary_category": "cs.SC",
            "category": [
                "cs.SC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18100v1",
            "title": "Analysis of the Generalization Error of deep learning based on\n  Randomized Quasi-Monte Carlo for Solving Linear Kolmogorov PDEs",
            "updated": "2023-10-27T12:36:55Z",
            "published": "2023-10-27T12:36:55Z",
            "summary": "Deep learning algorithms have been widely used to solve linear Kolmogorov\npartial differential equations~(PDEs) in high dimensions, where the loss\nfunction is defined as a mathematical expectation. We propose to use the\nrandomized quasi-Monte Carlo (RQMC) method instead of the Monte Carlo (MC)\nmethod for computing the loss function. In theory, we decompose the error from\nempirical risk minimization~(ERM) into the generalization error and the\napproximation error. Notably, the approximation error is independent of the\nsampling methods. We prove that the convergence order of the mean\ngeneralization error for the RQMC method is $O(n^{-1+\\epsilon})$ for\narbitrarily small $\\epsilon>0$, while for the MC method it is\n$O(n^{-1/2+\\epsilon})$ for arbitrarily small $\\epsilon>0$. Consequently, we\nfind that the overall error for the RQMC method is asymptotically smaller than\nthat for the MC method as $n$ increases. Our numerical experiments show that\nthe algorithm based on the RQMC method consistently achieves smaller relative\n$L^{2}$ error than that based on the MC method.",
            "author": [
                "Jichang Xiao",
                "Fengjiang Fu",
                "Xiaoqun Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18100v1",
                "http://arxiv.org/pdf/2310.18100v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "65C30, 65D30, 65N15, 68T07"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18091v1",
            "title": "Adversarial Anomaly Detection using Gaussian Priors and Nonlinear\n  Anomaly Scores",
            "updated": "2023-10-27T12:24:08Z",
            "published": "2023-10-27T12:24:08Z",
            "summary": "Anomaly detection in imbalanced datasets is a frequent and crucial problem,\nespecially in the medical domain where retrieving and labeling irregularities\nis often expensive. By combining the generative stability of a\n$\\beta$-variational autoencoder (VAE) with the discriminative strengths of\ngenerative adversarial networks (GANs), we propose a novel model,\n$\\beta$-VAEGAN. We investigate methods for composing anomaly scores based on\nthe discriminative and reconstructive capabilities of our model. Existing work\nfocuses on linear combinations of these components to determine if data is\nanomalous. We advance existing work by training a kernelized support vector\nmachine (SVM) on the respective error components to also consider nonlinear\nrelationships. This improves anomaly detection performance, while allowing\nfaster optimization. Lastly, we use the deviations from the Gaussian prior of\n$\\beta$-VAEGAN to form a novel anomaly score component. In comparison to\nstate-of-the-art work, we improve the $F_1$ score during anomaly detection from\n0.85 to 0.92 on the widely used MITBIH Arrhythmia Database.",
            "author": [
                "Fiete L\u00fcer",
                "Tobias Weber",
                "Maxim Dolgich",
                "Christian B\u00f6hm"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18091v1",
                "http://arxiv.org/pdf/2310.18091v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18080v1",
            "title": "Unveiling the Potential of Probabilistic Embeddings in Self-Supervised\n  Learning",
            "updated": "2023-10-27T12:01:16Z",
            "published": "2023-10-27T12:01:16Z",
            "summary": "In recent years, self-supervised learning has played a pivotal role in\nadvancing machine learning by allowing models to acquire meaningful\nrepresentations from unlabeled data. An intriguing research avenue involves\ndeveloping self-supervised models within an information-theoretic framework,\nbut many studies often deviate from the stochasticity assumptions made when\nderiving their objectives. To gain deeper insights into this issue, we propose\nto explicitly model the representation with stochastic embeddings and assess\ntheir effects on performance, information compression and potential for\nout-of-distribution detection. From an information-theoretic perspective, we\nseek to investigate the impact of probabilistic modeling on the information\nbottleneck, shedding light on a trade-off between compression and preservation\nof information in both representation and loss space. Emphasizing the\nimportance of distinguishing between these two spaces, we demonstrate how\nconstraining one can affect the other, potentially leading to performance\ndegradation. Moreover, our findings suggest that introducing an additional\nbottleneck in the loss space can significantly enhance the ability to detect\nout-of-distribution examples, only leveraging either representation features or\nthe variance of their underlying distribution.",
            "author": [
                "Denis Janiak",
                "Jakub Binkowski",
                "Piotr Bielak",
                "Tomasz Kajdanowicz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18080v1",
                "http://arxiv.org/pdf/2310.18080v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18079v1",
            "title": "Supporting Better Insights of Data Science Pipelines with Fine-grained\n  Provenance",
            "updated": "2023-10-27T12:00:22Z",
            "published": "2023-10-27T12:00:22Z",
            "summary": "Successful data-driven science requires complex data engineering pipelines to\nclean, transform, and alter data in preparation for machine learning, and\nrobust results can only be achieved when each step in the pipeline can be\njustified, and its effect on the data explained. In this framework, our aim is\nto provide data scientists with facilities to gain an in-depth understanding of\nhow each step in the pipeline affects the data, from the raw input to training\nsets ready to be used for learning. Starting from an extensible set of data\npreparation operators commonly used within a data science setting, in this work\nwe present a provenance management infrastructure for generating, storing, and\nquerying very granular accounts of data transformations, at the level of\nindividual elements within datasets whenever possible. Then, from the formal\ndefinition of a core set of data science preprocessing operators, we derive a\nprovenance semantics embodied by a collection of templates expressed in PROV, a\nstandard model for data provenance. Using those templates as a reference, our\nprovenance generation algorithm generalises to any operator with observable\ninput/output pairs. We provide a prototype implementation of an\napplication-level provenance capture library to produce, in a semi-automatic\nway, complete provenance documents that account for the entire pipeline. We\nreport on the ability of our implementations to capture provenance in real ML\nbenchmark pipelines and over TCP-DI synthetic data. We finally show how the\ncollected provenance can be used to answer a suite of provenance benchmark\nqueries that underpin some common pipeline inspection questions, as expressed\non the Data Science Stack Exchange.",
            "author": [
                "Adriane Chapman",
                "Luca Lauro",
                "Paolo Missier",
                "Riccardo Torlone"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18079v1",
                "http://arxiv.org/pdf/2310.18079v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB",
                "68",
                "H.1; H.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18078v1",
            "title": "Lipschitz and H\u00f6lder Continuity in Reproducing Kernel Hilbert Spaces",
            "updated": "2023-10-27T11:56:43Z",
            "published": "2023-10-27T11:56:43Z",
            "summary": "Reproducing kernel Hilbert spaces (RKHSs) are very important function spaces,\nplaying an important role in machine learning, statistics, numerical analysis\nand pure mathematics. Since Lipschitz and H\\\"older continuity are important\nregularity properties, with many applications in interpolation, approximation\nand optimization problems, in this work we investigate these continuity notion\nin RKHSs. We provide several sufficient conditions as well as an in depth\ninvestigation of reproducing kernels inducing prescribed Lipschitz or H\\\"older\ncontinuity. Apart from new results, we also collect related known results from\nthe literature, making the present work also a convenient reference on this\ntopic.",
            "author": [
                "Christian Fiedler"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18078v1",
                "http://arxiv.org/pdf/2310.18078v1"
            ],
            "primary_category": "math.FA",
            "category": [
                "math.FA",
                "cs.LG",
                "46E22 (Primary), 51F30, 47B34, 47G10 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18074v1",
            "title": "On kernel-based statistical learning in the mean field limit",
            "updated": "2023-10-27T11:42:56Z",
            "published": "2023-10-27T11:42:56Z",
            "summary": "In many applications of machine learning, a large number of variables are\nconsidered. Motivated by machine learning of interacting particle systems, we\nconsider the situation when the number of input variables goes to infinity.\nFirst, we continue the recent investigation of the mean field limit of kernels\nand their reproducing kernel Hilbert spaces, completing the existing theory.\nNext, we provide results relevant for approximation with such kernels in the\nmean field limit, including a representer theorem. Finally, we use these\nkernels in the context of statistical learning in the mean field limit,\nfocusing on Support Vector Machines. In particular, we show mean field\nconvergence of empirical and infinite-sample solutions as well as the\nconvergence of the corresponding risks. On the one hand, our results establish\nrigorous mean field limits in the context of kernel methods, providing new\ntheoretical tools and insights for large-scale problems. On the other hand, our\nsetting corresponds to a new form of limit of learning problems, which seems to\nhave not been investigated yet in the statistical learning theory literature.",
            "author": [
                "Christian Fiedler",
                "Michael Herty",
                "Sebastian Trimpe"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18074v1",
                "http://arxiv.org/pdf/2310.18074v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18063v1",
            "title": "\"Honey, Tell Me What's Wrong\", Global Explanation of Textual\n  Discriminative Models through Cooperative Generation",
            "updated": "2023-10-27T11:26:27Z",
            "published": "2023-10-27T11:26:27Z",
            "summary": "The ubiquity of complex machine learning has raised the importance of\nmodel-agnostic explanation algorithms. These methods create artificial\ninstances by slightly perturbing real instances, capturing shifts in model\ndecisions. However, such methods rely on initial data and only provide\nexplanations of the decision for these. To tackle these problems, we propose\nTherapy, the first global and model-agnostic explanation method adapted to text\nwhich requires no input dataset. Therapy generates texts following the\ndistribution learned by a classifier through cooperative generation. Because it\ndoes not rely on initial samples, it allows to generate explanations even when\ndata is absent (e.g., for confidentiality reasons). Moreover, conversely to\nexisting methods that combine multiple local explanations into a global one,\nTherapy offers a global overview of the model behavior on the input space. Our\nexperiments show that although using no input data to generate samples, Therapy\nprovides insightful information about features used by the classifier that is\ncompetitive with the ones from methods relying on input samples and outperforms\nthem when input samples are not specific to the studied model.",
            "author": [
                "Antoine Chaffin",
                "Julien Delaunay"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18063v1",
                "http://arxiv.org/pdf/2310.18063v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06280v1",
            "title": "A Data-driven Deep Learning Approach for Bitcoin Price Forecasting",
            "updated": "2023-10-27T10:35:47Z",
            "published": "2023-10-27T10:35:47Z",
            "summary": "Bitcoin as a cryptocurrency has been one of the most important digital coins\nand the first decentralized digital currency. Deep neural networks, on the\nother hand, has shown promising results recently; however, we require huge\namount of high-quality data to leverage their power. There are some techniques\nsuch as augmentation that can help us with increasing the dataset size, but we\ncannot exploit them on historical bitcoin data. As a result, we propose a\nshallow Bidirectional-LSTM (Bi-LSTM) model, fed with feature engineered data\nusing our proposed method to forecast bitcoin closing prices in a daily time\nframe. We compare the performance with that of other forecasting methods, and\nshow that with the help of the proposed feature engineering method, a shallow\ndeep neural network outperforms other popular price forecasting models.",
            "author": [
                "Parth Daxesh Modi",
                "Kamyar Arshi",
                "Pertami J. Kunz",
                "Abdelhak M. Zoubir"
            ],
            "link": [
                "http://arxiv.org/abs/2311.06280v1",
                "http://arxiv.org/pdf/2311.06280v1"
            ],
            "primary_category": "q-fin.ST",
            "category": [
                "q-fin.ST",
                "cs.AI",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18035v1",
            "title": "High Throughput Screening of Ternary Nitrides with Convolutional Neural\n  Networks",
            "updated": "2023-10-27T10:27:57Z",
            "published": "2023-10-27T10:27:57Z",
            "summary": "The development of new materials is a core aspect of advancement in synthesis\nand application for industry. There is a vast number of possible chemical\npermutations of the basic elements that can be explored to synthesize materials\nthat possess attractive catalytic, mechanical and electrical properties that\nmay not be easily accessible to traditional experimental methods for various\nreasons, including cost and time considerations. Nitrides, as examples, require\nvery stringent and precise conditions to successfully synthesize making their\nexperimental exploration very slow. In this paper, we employ the use of machine\nlearning algorithms to predict the bulk properties of Ternary Metal Nitrides\n(TMN), specifically their bulk modulus which is correlated with the hardness of\nthe material. We were able to develop a consistent model with encouraging\naccuracy, that was able to predict the bulk moduli of materials that previously\ndid not have computed values. The model was trained on $10^3$ ternary materials\nwith known elastic properties and defined structures, and was able to predict\nthe bulk modulus of $\\thickapprox 1,000$ Ternary Metal Nitrides (TMNs) to\n$\\thickapprox 80\\%$ accuracy. This approach is orders of magnitude faster than\nthe traditional computational approaches like density functional theory\n(DFT)\\cite{dft-paper} which makes exploratory identification of materials with\npromising properties fast. We propose that such models be used to select\ninteresting candidates for high throughput computation from first principles.",
            "author": [
                "Antony A. Ayieko",
                "Michael O. Atambo",
                "George O. Amolo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18035v1",
                "http://arxiv.org/pdf/2310.18035v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18027v3",
            "title": "Bayesian Prognostic Covariate Adjustment With Additive Mixture Priors",
            "updated": "2023-11-23T00:57:01Z",
            "published": "2023-10-27T10:05:06Z",
            "summary": "Effective and rapid decision-making from randomized controlled trials (RCTs)\nrequires unbiased and precise treatment effect inferences. Two strategies to\naddress this requirement are to adjust for covariates that are highly\ncorrelated with the outcome, and to leverage historical control information via\nBayes' theorem. We propose a new Bayesian prognostic covariate adjustment\nmethodology, referred to as Bayesian PROCOVA, that combines these two\nstrategies. Covariate adjustment in Bayesian PROCOVA is based on generative\nartificial intelligence (AI) algorithms that construct a digital twin generator\n(DTG) for RCT participants. The DTG is trained on historical control data and\nyields a digital twin (DT) probability distribution for each RCT participant's\noutcome under the control treatment. The expectation of the DT distribution,\nreferred to as the prognostic score, defines the covariate for adjustment.\nHistorical control information is leveraged via an additive mixture prior with\ntwo components: an informative prior probability distribution specified based\non historical control data, and a weakly informative prior distribution. The\nmixture weight determines the extent to which posterior inferences are drawn\nfrom the informative component, versus the weakly informative component. This\nweight has a prior distribution as well, and so the entire additive mixture\nprior is completely pre-specifiable without involving any RCT information. We\nestablish an efficient Gibbs algorithm for sampling from the posterior\ndistribution, and derive closed-form expressions for the posterior mean and\nvariance of the treatment effect parameter conditional on the weight, in\nBayesian PROCOVA. We evaluate efficiency gains of Bayesian PROCOVA via its bias\ncontrol and variance reduction compared to frequentist PROCOVA in simulation\nstudies that encompass different discrepancies. These gains translate to\nsmaller RCTs.",
            "author": [
                "Alyssa M. Vanderbeek",
                "Arman Sabbaghi",
                "Jon R. Walsh",
                "Charles K. Fisher"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18027v3",
                "http://arxiv.org/pdf/2310.18027v3"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP",
                "stat.ML",
                "62F15"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18021v3",
            "title": "FormalGeo: The First Step Toward Human-like IMO-level Geometric\n  Automated Reasoning",
            "updated": "2023-11-28T07:00:35Z",
            "published": "2023-10-27T09:55:12Z",
            "summary": "This is the first paper in a series of work we have accomplished over the\npast three years. In this paper, we have constructed a complete and compatible\nformal plane geometry system. This will serve as a crucial bridge between\nIMO-level plane geometry challenges and readable AI automated reasoning. Within\nthis formal framework, we have been able to seamlessly integrate modern AI\nmodels with our formal system. AI is now capable of providing deductive\nreasoning solutions to IMO-level plane geometry problems, just like handling\nother natural languages, and these proofs are readable, traceable, and\nverifiable. We propose the geometry formalization theory (GFT) to guide the\ndevelopment of the geometry formal system. Based on the GFT, we have\nestablished the FormalGeo, which consists of 88 geometric predicates and 196\ntheorems. It can represent, validate, and solve IMO-level geometry problems. we\nalso have crafted the FGPS (formal geometry problem solver) in Python. It\nserves as both an interactive assistant for verifying problem-solving processes\nand an automated problem solver. We've annotated the formalgeo7k and\nformalgeo-imo datasets. The former contains 6,891 (expand to 133,818 through\ndata augmentation) geometry problems, while the latter includes 18 (expand to\n2,627 and continuously increasing) IMO-level challenging geometry problems. All\nannotated problems include detailed formal language descriptions and solutions.\nImplementation of the formal system and experiments validate the correctness\nand utility of the GFT. The backward depth-first search method only yields a\n2.42% problem-solving failure rate, and we can incorporate deep learning\ntechniques to achieve lower one. The source code of FGPS and datasets are\navailable at https://github.com/BitSecret/FGPS.",
            "author": [
                "Xiaokai Zhang",
                "Na Zhu",
                "Yiming He",
                "Jia Zou",
                "Qike Huang",
                "Xiaoxiao Jin",
                "Yanjun Guo",
                "Chenyang Mao",
                "Zhe Zhu",
                "Dengfeng Yue",
                "Fangzhen Zhu",
                "Yang Li",
                "Yifan Wang",
                "Yiwen Huang",
                "Runan Wang",
                "Cheng Qin",
                "Zhenbing Zeng",
                "Shaorong Xie",
                "Xiangfeng Luo",
                "Tuo Leng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18021v3",
                "http://arxiv.org/pdf/2310.18021v3"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18019v1",
            "title": "Temperature Monitoring of Agricultural Areas in a Secure Data Room",
            "updated": "2023-10-27T09:49:52Z",
            "published": "2023-10-27T09:49:52Z",
            "summary": "Agricultural production is highly dependent on naturally occurring\nenvironmental conditions like change of seasons and the weather. Especially in\nfruit and wine growing, late frosts occurring shortly after the crops have\nsprouted have the potential to cause massive damage to plants [L1,L2] [1]. In\nthis article we present a cost-efficient temperature monitoring system for\ndetecting and reacting to late frosts to prevent crop failures. The proposed\nsolution includes a data space where Internet of Things (IoT) devices can form\na cyber-physical system (CPS) to interact with their nearby environment and\nsecurely exchange data. Based on this data, more accurate predictions can be\nmade in the future using machine learning (ML), which will further contribute\nto minimising economic damage caused by crop failures.",
            "author": [
                "Thomas Ederer",
                "Martin Ivancsits",
                "Igor Ivki\u0107"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18019v1",
                "http://arxiv.org/pdf/2310.18019v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18004v1",
            "title": "Text2Bundle: Towards Personalized Query-based Bundle Generation",
            "updated": "2023-10-27T09:24:38Z",
            "published": "2023-10-27T09:24:38Z",
            "summary": "Bundle generation aims to provide a bundle of items for the user, and has\nbeen widely studied and applied on online service platforms. Existing bundle\ngeneration methods mainly utilized user's preference from historical\ninteractions in common recommendation paradigm, and ignored the potential\ntextual query which is user's current explicit intention. There can be a\nscenario in which a user proactively queries a bundle with some natural\nlanguage description, the system should be able to generate a bundle that\nexactly matches the user's intention through the user's query and preferences.\nIn this work, we define this user-friendly scenario as Query-based Bundle\nGeneration task and propose a novel framework Text2Bundle that leverages both\nthe user's short-term interests from the query and the user's long-term\npreferences from the historical interactions. Our framework consists of three\nmodules: (1) a query interest extractor that mines the user's fine-grained\ninterests from the query; (2) a unified state encoder that learns the current\nbundle context state and the user's preferences based on historical interaction\nand current query; and (3) a bundle generator that generates personalized and\ncomplementary bundles using a reinforcement learning with specifically designed\nrewards. We conduct extensive experiments on three real-world datasets and\ndemonstrate the effectiveness of our framework compared with several\nstate-of-the-art methods.",
            "author": [
                "Shixuan Zhu",
                "Chuan Cui",
                "JunTong Hu",
                "Qi Shen",
                "Yu Ji",
                "Zhihua Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18004v1",
                "http://arxiv.org/pdf/2310.18004v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18001v1",
            "title": "DP-SGD with weight clipping",
            "updated": "2023-10-27T09:17:15Z",
            "published": "2023-10-27T09:17:15Z",
            "summary": "Recently, due to the popularity of deep neural networks and other methods\nwhose training typically relies on the optimization of an objective function,\nand due to concerns for data privacy, there is a lot of interest in\ndifferentially private gradient descent methods. To achieve differential\nprivacy guarantees with a minimum amount of noise, it is important to be able\nto bound precisely the sensitivity of the information which the participants\nwill observe. In this study, we present a novel approach that mitigates the\nbias arising from traditional gradient clipping. By leveraging public\ninformation concerning the current global model and its location within the\nsearch domain, we can achieve improved gradient bounds, leading to enhanced\nsensitivity determinations and refined noise level adjustments. We extend the\nstate of the art algorithms, present improved differential privacy guarantees\nrequiring less noise and present an empirical evaluation.",
            "author": [
                "Antoine Barczewski",
                "Jan Ramon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18001v1",
                "http://arxiv.org/pdf/2310.18001v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17998v1",
            "title": "Closing the Gap Between the Upper Bound and the Lower Bound of Adam's\n  Iteration Complexity",
            "updated": "2023-10-27T09:16:58Z",
            "published": "2023-10-27T09:16:58Z",
            "summary": "Recently, Arjevani et al. [1] established a lower bound of iteration\ncomplexity for the first-order optimization under an $L$-smooth condition and a\nbounded noise variance assumption. However, a thorough review of existing\nliterature on Adam's convergence reveals a noticeable gap: none of them meet\nthe above lower bound. In this paper, we close the gap by deriving a new\nconvergence guarantee of Adam, with only an $L$-smooth condition and a bounded\nnoise variance assumption. Our results remain valid across a broad spectrum of\nhyperparameters. Especially with properly chosen hyperparameters, we derive an\nupper bound of the iteration complexity of Adam and show that it meets the\nlower bound for first-order optimizers. To the best of our knowledge, this is\nthe first to establish such a tight upper bound for Adam's convergence. Our\nproof utilizes novel techniques to handle the entanglement between momentum and\nadaptive learning rate and to convert the first-order term in the Descent Lemma\nto the gradient norm, which may be of independent interest.",
            "author": [
                "Bohan Wang",
                "Jingwen Fu",
                "Huishuai Zhang",
                "Nanning Zheng",
                "Wei Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17998v1",
                "http://arxiv.org/pdf/2310.17998v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17997v1",
            "title": "Deep Learning Enables Large Depth-of-Field Images for\n  Sub-Diffraction-Limit Scanning Superlens Microscopy",
            "updated": "2023-10-27T09:16:56Z",
            "published": "2023-10-27T09:16:56Z",
            "summary": "Scanning electron microscopy (SEM) is indispensable in diverse applications\nranging from microelectronics to food processing because it provides large\ndepth-of-field images with a resolution beyond the optical diffraction limit.\nHowever, the technology requires coating conductive films on insulator samples\nand a vacuum environment. We use deep learning to obtain the mapping\nrelationship between optical super-resolution (OSR) images and SEM domain\nimages, which enables the transformation of OSR images into SEM-like large\ndepth-of-field images. Our custom-built scanning superlens microscopy (SSUM)\nsystem, which requires neither coating samples by conductive films nor a vacuum\nenvironment, is used to acquire the OSR images with features down to ~80 nm.\nThe peak signal-to-noise ratio (PSNR) and structural similarity index measure\nvalues indicate that the deep learning method performs excellently in\nimage-to-image translation, with a PSNR improvement of about 0.74 dB over the\noptical super-resolution images. The proposed method provides a high level of\ndetail in the reconstructed results, indicating that it has broad applicability\nto chip-level defect detection, biological sample analysis, forensics, and\nvarious other fields.",
            "author": [
                "Hui Sun",
                "Hao Luo",
                "Feifei Wang",
                "Qingjiu Chen",
                "Meng Chen",
                "Xiaoduo Wang",
                "Haibo Yu",
                "Guanglie Zhang",
                "Lianqing Liu",
                "Jianping Wang",
                "Dapeng Wu",
                "Wen Jung Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17997v1",
                "http://arxiv.org/pdf/2310.17997v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "cs.AI",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17974v1",
            "title": "FaultSeg Swin-UNETR: Transformer-Based Self-Supervised Pretraining Model\n  for Fault Recognition",
            "updated": "2023-10-27T08:38:59Z",
            "published": "2023-10-27T08:38:59Z",
            "summary": "This paper introduces an approach to enhance seismic fault recognition\nthrough self-supervised pretraining. Seismic fault interpretation holds great\nsignificance in the fields of geophysics and geology. However, conventional\nmethods for seismic fault recognition encounter various issues, including\ndependence on data quality and quantity, as well as susceptibility to\ninterpreter subjectivity. Currently, automated fault recognition methods\nproposed based on small synthetic datasets experience performance degradation\nwhen applied to actual seismic data. To address these challenges, we have\nintroduced the concept of self-supervised learning, utilizing a substantial\namount of relatively easily obtainable unlabeled seismic data for pretraining.\nSpecifically, we have employed the Swin Transformer model as the core network\nand employed the SimMIM pretraining task to capture unique features related to\ndiscontinuities in seismic data. During the fine-tuning phase, inspired by edge\ndetection techniques, we have also refined the structure of the Swin-UNETR\nmodel, enabling multiscale decoding and fusion for more effective fault\ndetection. Experimental results demonstrate that our proposed method attains\nstate-of-the-art performance on the Thebe dataset, as measured by the OIS and\nODS metrics.",
            "author": [
                "Zeren Zhang",
                "Ran Chen",
                "Jinwen Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17974v1",
                "http://arxiv.org/pdf/2310.17974v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17972v1",
            "title": "CEFL: Carbon-Efficient Federated Learning",
            "updated": "2023-10-27T08:37:10Z",
            "published": "2023-10-27T08:37:10Z",
            "summary": "Federated Learning (FL) distributes machine learning (ML) training across\nmany edge devices to reduce data transfer overhead and protect data privacy.\nSince FL model training may span millions of devices and is thus\nresource-intensive, prior work has focused on improving its resource efficiency\nto optimize time-to-accuracy. However, prior work generally treats all\nresources the same, while, in practice, they may incur widely different costs,\nwhich instead motivates optimizing cost-to-accuracy. To address the problem, we\ndesign CEFL, which uses adaptive cost-aware client selection policies to\noptimize an arbitrary cost metric when training FL models. Our policies extend\nand combine prior work on utility-based client selection and critical learning\nperiods by making them cost-aware. We demonstrate CEFL by designing\ncarbon-efficient FL, where energy's carbon-intensity is the cost, and show that\nit i) reduces carbon emissions by 93\\% and reduces training time by 50%\ncompared to random client selection and ii) reduces carbon emissions by 80%,\nwhile only increasing training time by 38%, compared to a state-of-the-art\napproach that optimizes training time.",
            "author": [
                "Talha Mehboob",
                "Noman Bashir",
                "Jesus Omana Iglesias",
                "Michael Zink",
                "David Irwin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17972v1",
                "http://arxiv.org/pdf/2310.17972v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17966v2",
            "title": "Train Once, Get a Family: State-Adaptive Balances for Offline-to-Online\n  Reinforcement Learning",
            "updated": "2023-10-30T05:22:23Z",
            "published": "2023-10-27T08:30:54Z",
            "summary": "Offline-to-online reinforcement learning (RL) is a training paradigm that\ncombines pre-training on a pre-collected dataset with fine-tuning in an online\nenvironment. However, the incorporation of online fine-tuning can intensify the\nwell-known distributional shift problem. Existing solutions tackle this problem\nby imposing a policy constraint on the policy improvement objective in both\noffline and online learning. They typically advocate a single balance between\npolicy improvement and constraints across diverse data collections. This\none-size-fits-all manner may not optimally leverage each collected sample due\nto the significant variation in data quality across different states. To this\nend, we introduce Family Offline-to-Online RL (FamO2O), a simple yet effective\nframework that empowers existing algorithms to determine state-adaptive\nimprovement-constraint balances. FamO2O utilizes a universal model to train a\nfamily of policies with different improvement/constraint intensities, and a\nbalance model to select a suitable policy for each state. Theoretically, we\nprove that state-adaptive balances are necessary for achieving a higher policy\nperformance upper bound. Empirically, extensive experiments show that FamO2O\noffers a statistically significant improvement over various existing methods,\nachieving state-of-the-art performance on the D4RL benchmark. Codes are\navailable at https://github.com/LeapLabTHU/FamO2O.",
            "author": [
                "Shenzhi Wang",
                "Qisen Yang",
                "Jiawei Gao",
                "Matthieu Gaetan Lin",
                "Hao Chen",
                "Liwei Wu",
                "Ning Jia",
                "Shiji Song",
                "Gao Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17966v2",
                "http://arxiv.org/pdf/2310.17966v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17954v1",
            "title": "Multivessel Coronary Artery Segmentation and Stenosis Localisation using\n  Ensemble Learning",
            "updated": "2023-10-27T08:03:12Z",
            "published": "2023-10-27T08:03:12Z",
            "summary": "Coronary angiography analysis is a common clinical task performed by\ncardiologists to diagnose coronary artery disease (CAD) through an assessment\nof atherosclerotic plaque's accumulation. This study introduces an end-to-end\nmachine learning solution developed as part of our solution for the MICCAI 2023\nAutomatic Region-based Coronary Artery Disease diagnostics using x-ray\nangiography imagEs (ARCADE) challenge, which aims to benchmark solutions for\nmultivessel coronary artery segmentation and potential stenotic lesion\nlocalisation from X-ray coronary angiograms. We adopted a robust baseline model\ntraining strategy to progressively improve performance, comprising five\nsuccessive stages of binary class pretraining, multivessel segmentation,\nfine-tuning using class frequency weighted dataloaders, fine-tuning using\nF1-based curriculum learning strategy (F1-CLS), and finally multi-target\nangiogram view classifier-based collective adaptation. Unlike many other\nmedical imaging procedures, this task exhibits a notable degree of\ninterobserver variability. %, making it particularly amenable to automated\nanalysis. Our ensemble model combines the outputs from six baseline models\nusing the weighted ensembling approach, which our analysis shows is found to\ndouble the predictive accuracy of the proposed solution. The final prediction\nwas further refined, targeting the correction of misclassified blobs. Our\nsolution achieved a mean F1 score of $37.69\\%$ for coronary artery\nsegmentation, and $39.41\\%$ for stenosis localisation, positioning our team in\nthe 5th position on both leaderboards. This work demonstrates the potential of\nautomated tools to aid CAD diagnosis, guide interventions, and improve the\naccuracy of stent injections in clinical settings.",
            "author": [
                "Muhammad Bilal",
                "Dinis Martinho",
                "Reiner Sim",
                "Adnan Qayyum",
                "Hunaid Vohra",
                "Massimo Caputo",
                "Taofeek Akinosho",
                "Sofiat Abioye",
                "Zaheer Khan",
                "Waleed Niaz",
                "Junaid Qadir"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17954v1",
                "http://arxiv.org/pdf/2310.17954v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17952v2",
            "title": "Shape-centered Representation Learning for Visible-Infrared Person\n  Re-identification",
            "updated": "2023-10-30T01:37:18Z",
            "published": "2023-10-27T07:57:24Z",
            "summary": "Current Visible-Infrared Person Re-Identification (VI-ReID) methods\nprioritize extracting distinguishing appearance features, ignoring the natural\nresistance of body shape against modality changes. Initially, we gauged the\ndiscriminative potential of shapes by a straightforward concatenation of shape\nand appearance features. However, two unresolved issues persist in the\nutilization of shape features. One pertains to the dependence on auxiliary\nmodels for shape feature extraction in the inference phase, along with the\nerrors in generated infrared shapes due to the intrinsic modality disparity.\nThe other issue involves the inadequately explored correlation between shape\nand appearance features. To tackle the aforementioned challenges, we propose\nthe Shape-centered Representation Learning framework (ScRL), which focuses on\nlearning shape features and appearance features associated with shapes.\nSpecifically, we devise the Shape Feature Propagation (SFP), facilitating\ndirect extraction of shape features from original images with minimal\ncomplexity costs during inference. To restitute inaccuracies in infrared body\nshapes at the feature level, we present the Infrared Shape Restitution (ISR).\nFurthermore, to acquire appearance features related to shape, we design the\nAppearance Feature Enhancement (AFE), which accentuates identity-related\nfeatures while suppressing identity-unrelated features guided by shape\nfeatures. Extensive experiments are conducted to validate the effectiveness of\nthe proposed ScRL. Achieving remarkable results, the Rank-1 (mAP) accuracy\nattains 76.1%, 71.2%, 92.4% (72.6%, 52.9%, 86.7%) on the SYSU-MM01, HITSZ-VCM,\nRegDB datasets respectively, outperforming existing state-of-the-art methods.",
            "author": [
                "Shuang Li",
                "Jiaxu Leng",
                "Ji Gan",
                "Mengjingcheng Mo",
                "Xinbo Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17952v2",
                "http://arxiv.org/pdf/2310.17952v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17949v2",
            "title": "Instance Segmentation under Occlusions via Location-aware Copy-Paste\n  Data Augmentation",
            "updated": "2023-11-21T05:55:10Z",
            "published": "2023-10-27T07:44:25Z",
            "summary": "Occlusion is a long-standing problem in computer vision, particularly in\ninstance segmentation. ACM MMSports 2023 DeepSportRadar has introduced a\ndataset that focuses on segmenting human subjects within a basketball context\nand a specialized evaluation metric for occlusion scenarios. Given the modest\nsize of the dataset and the highly deformable nature of the objects to be\nsegmented, this challenge demands the application of robust data augmentation\ntechniques and wisely-chosen deep learning architectures. Our work (ranked 1st\nin the competition) first proposes a novel data augmentation technique, capable\nof generating more training samples with wider distribution. Then, we adopt a\nnew architecture - Hybrid Task Cascade (HTC) framework with CBNetV2 as backbone\nand MaskIoU head to improve segmentation performance. Furthermore, we employ a\nStochastic Weight Averaging (SWA) training strategy to improve the model's\ngeneralization. As a result, we achieve a remarkable occlusion score (OM) of\n0.533 on the challenge dataset, securing the top-1 position on the leaderboard.\nSource code is available at this\nhttps://github.com/nguyendinhson-kaist/MMSports23-Seg-AutoID.",
            "author": [
                "Son Nguyen",
                "Mikel Lainsa",
                "Hung Dao",
                "Daeyoung Kim",
                "Giang Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17949v2",
                "http://arxiv.org/pdf/2310.17949v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17945v1",
            "title": "A Comprehensive and Reliable Feature Attribution Method: Double-sided\n  Remove and Reconstruct (DoRaR)",
            "updated": "2023-10-27T07:40:45Z",
            "published": "2023-10-27T07:40:45Z",
            "summary": "The limited transparency of the inner decision-making mechanism in deep\nneural networks (DNN) and other machine learning (ML) models has hindered their\napplication in several domains. In order to tackle this issue, feature\nattribution methods have been developed to identify the crucial features that\nheavily influence decisions made by these black box models. However, many\nfeature attribution methods have inherent downsides. For example, one category\nof feature attribution methods suffers from the artifacts problem, which feeds\nout-of-distribution masked inputs directly through the classifier that was\noriginally trained on natural data points. Another category of feature\nattribution method finds explanations by using jointly trained feature\nselectors and predictors. While avoiding the artifacts problem, this new\ncategory suffers from the Encoding Prediction in the Explanation (EPITE)\nproblem, in which the predictor's decisions rely not on the features, but on\nthe masks that selects those features. As a result, the credibility of\nattribution results is undermined by these downsides. In this research, we\nintroduce the Double-sided Remove and Reconstruct (DoRaR) feature attribution\nmethod based on several improvement methods that addresses these issues. By\nconducting thorough testing on MNIST, CIFAR10 and our own synthetic dataset, we\ndemonstrate that the DoRaR feature attribution method can effectively bypass\nthe above issues and can aid in training a feature selector that outperforms\nother state-of-the-art feature attribution methods. Our code is available at\nhttps://github.com/dxq21/DoRaR.",
            "author": [
                "Dong Qin",
                "George Amariucai",
                "Daji Qiao",
                "Yong Guan",
                "Shen Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17945v1",
                "http://arxiv.org/pdf/2310.17945v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17944v1",
            "title": "Trustworthy Edge Machine Learning: A Survey",
            "updated": "2023-10-27T07:39:54Z",
            "published": "2023-10-27T07:39:54Z",
            "summary": "The convergence of Edge Computing (EC) and Machine Learning (ML), known as\nEdge Machine Learning (EML), has become a highly regarded research area by\nutilizing distributed network resources to perform joint training and inference\nin a cooperative manner. However, EML faces various challenges due to resource\nconstraints, heterogeneous network environments, and diverse service\nrequirements of different applications, which together affect the\ntrustworthiness of EML in the eyes of its stakeholders. This survey provides a\ncomprehensive summary of definitions, attributes, frameworks, techniques, and\nsolutions for trustworthy EML. Specifically, we first emphasize the importance\nof trustworthy EML within the context of Sixth-Generation (6G) networks. We\nthen discuss the necessity of trustworthiness from the perspective of\nchallenges encountered during deployment and real-world application scenarios.\nSubsequently, we provide a preliminary definition of trustworthy EML and\nexplore its key attributes. Following this, we introduce fundamental frameworks\nand enabling technologies for trustworthy EML systems, and provide an in-depth\nliterature review of the latest solutions to enhance trustworthiness of EML.\nFinally, we discuss corresponding research challenges and open issues.",
            "author": [
                "Xiaojie Wang",
                "Beibei Wang",
                "Yu Wu",
                "Zhaolong Ning",
                "Song Guo",
                "Fei Richard Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17944v1",
                "http://arxiv.org/pdf/2310.17944v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17942v1",
            "title": "Diversifying Spatial-Temporal Perception for Video Domain Generalization",
            "updated": "2023-10-27T07:36:36Z",
            "published": "2023-10-27T07:36:36Z",
            "summary": "Video domain generalization aims to learn generalizable video classification\nmodels for unseen target domains by training in a source domain. A critical\nchallenge of video domain generalization is to defend against the heavy\nreliance on domain-specific cues extracted from the source domain when\nrecognizing target videos. To this end, we propose to perceive diverse\nspatial-temporal cues in videos, aiming to discover potential domain-invariant\ncues in addition to domain-specific cues. We contribute a novel model named\nSpatial-Temporal Diversification Network (STDN), which improves the diversity\nfrom both space and time dimensions of video data. First, our STDN proposes to\ndiscover various types of spatial cues within individual frames by spatial\ngrouping. Then, our STDN proposes to explicitly model spatial-temporal\ndependencies between video contents at multiple space-time scales by\nspatial-temporal relation modeling. Extensive experiments on three benchmarks\nof different types demonstrate the effectiveness and versatility of our\napproach.",
            "author": [
                "Kun-Yu Lin",
                "Jia-Run Du",
                "Yipeng Gao",
                "Jiaming Zhou",
                "Wei-Shi Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17942v1",
                "http://arxiv.org/pdf/2310.17942v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17940v4",
            "title": "Unified Segment-to-Segment Framework for Simultaneous Sequence\n  Generation",
            "updated": "2023-11-30T08:26:16Z",
            "published": "2023-10-27T07:34:51Z",
            "summary": "Simultaneous sequence generation is a pivotal task for real-time scenarios,\nsuch as streaming speech recognition, simultaneous machine translation and\nsimultaneous speech translation, where the target sequence is generated while\nreceiving the source sequence. The crux of achieving high-quality generation\nwith low latency lies in identifying the optimal moments for generating,\naccomplished by learning a mapping between the source and target sequences.\nHowever, existing methods often rely on task-specific heuristics for different\nsequence types, limiting the model's capacity to adaptively learn the\nsource-target mapping and hindering the exploration of multi-task learning for\nvarious simultaneous tasks. In this paper, we propose a unified\nsegment-to-segment framework (Seg2Seg) for simultaneous sequence generation,\nwhich learns the mapping in an adaptive and unified manner. During the process\nof simultaneous generation, the model alternates between waiting for a source\nsegment and generating a target segment, making the segment serve as the\nnatural bridge between the source and target. To accomplish this, Seg2Seg\nintroduces a latent segment as the pivot between source to target and explores\nall potential source-target mappings via the proposed expectation training,\nthereby learning the optimal moments for generating. Experiments on multiple\nsimultaneous generation tasks demonstrate that Seg2Seg achieves\nstate-of-the-art performance and exhibits better generality across various\ntasks.",
            "author": [
                "Shaolei Zhang",
                "Yang Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17940v4",
                "http://arxiv.org/pdf/2310.17940v4"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17936v1",
            "title": "Transformers as Graph-to-Graph Models",
            "updated": "2023-10-27T07:21:37Z",
            "published": "2023-10-27T07:21:37Z",
            "summary": "We argue that Transformers are essentially graph-to-graph models, with\nsequences just being a special case. Attention weights are functionally\nequivalent to graph edges. Our Graph-to-Graph Transformer architecture makes\nthis ability explicit, by inputting graph edges into the attention weight\ncomputations and predicting graph edges with attention-like functions, thereby\nintegrating explicit graphs into the latent graphs learned by pretrained\nTransformers. Adding iterative graph refinement provides a joint embedding of\ninput, output, and latent graphs, allowing non-autoregressive graph prediction\nto optimise the complete graph without any bespoke pipeline or decoding\nstrategy. Empirical results show that this architecture achieves\nstate-of-the-art accuracies for modelling a variety of linguistic structures,\nintegrating very effectively with the latent linguistic representations learned\nby pretraining.",
            "author": [
                "James Henderson",
                "Alireza Mohammadshahi",
                "Andrei C. Coman",
                "Lesly Miculicich"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17936v1",
                "http://arxiv.org/pdf/2310.17936v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18384v1",
            "title": "MicroNAS: Memory and Latency Constrained Hardware-Aware Neural\n  Architecture Search for Time Series Classification on Microcontrollers",
            "updated": "2023-10-27T06:55:15Z",
            "published": "2023-10-27T06:55:15Z",
            "summary": "This paper presents MicroNAS, a system designed to automatically search and\ngenerate neural network architectures capable of classifying time series data\non resource-constrained microcontrollers (MCUs) and generating standard tf-lite\nML models. MicroNAS takes into account user-defined constraints on execution\nlatency and peak memory consumption on a target MCU. This approach ensures that\nthe resulting neural network architectures are optimised for the specific\nconstraints and requirements of the MCU on which they are implemented. To\nachieve this, MicroNAS uses a look-up table estimation approach for accurate\nexecution latency calculations, with a minimum error of only 1.02ms. This\naccurate latency estimation on MCUs sets it apart from other hardware-aware\nneural architecture search (HW-NAS) methods that use less accurate estimation\ntechniques. Finally, MicroNAS delivers performance close to that of\nstate-of-the-art models running on desktop computers, achieving high\nclassification accuracies on recognised datasets (93.93% on UCI-HAR and 96.33%\non SkodaR) while running on a Cortex-M4 MCU.",
            "author": [
                "Tobias King",
                "Yexu Zhou",
                "Tobias R\u00f6ddiger",
                "Michael Beigl"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18384v1",
                "http://arxiv.org/pdf/2310.18384v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17923v1",
            "title": "Dynamic Grasping of Unknown Objects with a Multi-Fingered Hand",
            "updated": "2023-10-27T06:37:33Z",
            "published": "2023-10-27T06:37:33Z",
            "summary": "An important prerequisite for autonomous robots is their ability to reliably\ngrasp a wide variety of objects. Most state-of-the-art systems employ\nspecialized or simple end-effectors, such as two-jaw grippers, which severely\nlimit the range of objects to manipulate. Additionally, they conventionally\nrequire a structured and fully predictable environment while the vast majority\nof our world is complex, unstructured, and dynamic. This paper presents an\nimplementation to overcome both issues. Firstly, the integration of a\nfive-finger hand enhances the variety of possible grasps and manipulable\nobjects. This kinematically complex end-effector is controlled by a deep\nlearning based generative grasping network. The required virtual model of the\nunknown target object is iteratively completed by processing visual sensor\ndata. Secondly, this visual feedback is employed to realize closed-loop servo\ncontrol which compensates for external disturbances. Our experiments on real\nhardware confirm the system's capability to reliably grasp unknown dynamic\ntarget objects without a priori knowledge of their trajectories. To the best of\nour knowledge, this is the first method to achieve dynamic multi-fingered\ngrasping for unknown objects. A video of the experiments is available at\nhttps://youtu.be/Ut28yM1gnvI.",
            "author": [
                "Yannick Burkhardt",
                "Qian Feng",
                "Karan Sharma",
                "Zhaopeng Chen",
                "Alois Knoll"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17923v1",
                "http://arxiv.org/pdf/2310.17923v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17922v1",
            "title": "Chain-of-Choice Hierarchical Policy Learning for Conversational\n  Recommendation",
            "updated": "2023-10-27T06:36:31Z",
            "published": "2023-10-27T06:36:31Z",
            "summary": "Conversational Recommender Systems (CRS) illuminate user preferences via\nmulti-round interactive dialogues, ultimately navigating towards precise and\nsatisfactory recommendations. However, contemporary CRS are limited to\ninquiring binary or multi-choice questions based on a single attribute type\n(e.g., color) per round, which causes excessive rounds of interaction and\ndiminishes the user's experience. To address this, we propose a more realistic\nand efficient conversational recommendation problem setting, called\nMulti-Type-Attribute Multi-round Conversational Recommendation (MTAMCR), which\nenables CRS to inquire about multi-choice questions covering multiple types of\nattributes in each round, thereby improving interactive efficiency. Moreover,\nby formulating MTAMCR as a hierarchical reinforcement learning task, we propose\na Chain-of-Choice Hierarchical Policy Learning (CoCHPL) framework to enhance\nboth the questioning efficiency and recommendation effectiveness in MTAMCR.\nSpecifically, a long-term policy over options (i.e., ask or recommend)\ndetermines the action type, while two short-term intra-option policies\nsequentially generate the chain of attributes or items through multi-step\nreasoning and selection, optimizing the diversity and interdependence of\nquestioning attributes. Finally, extensive experiments on four benchmarks\ndemonstrate the superior performance of CoCHPL over prevailing state-of-the-art\nmethods.",
            "author": [
                "Wei Fan",
                "Weijia Zhang",
                "Weiqi Wang",
                "Yangqiu Song",
                "Hao Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17922v1",
                "http://arxiv.org/pdf/2310.17922v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17915v1",
            "title": "Lifting the Veil: Unlocking the Power of Depth in Q-learning",
            "updated": "2023-10-27T06:15:33Z",
            "published": "2023-10-27T06:15:33Z",
            "summary": "With the help of massive data and rich computational resources, deep\nQ-learning has been widely used in operations research and management science\nand has contributed to great success in numerous applications, including\nrecommender systems, supply chains, games, and robotic manipulation. However,\nthe success of deep Q-learning lacks solid theoretical verification and\ninterpretability. The aim of this paper is to theoretically verify the power of\ndepth in deep Q-learning. Within the framework of statistical learning theory,\nwe rigorously prove that deep Q-learning outperforms its traditional version by\ndemonstrating its good generalization error bound. Our results reveal that the\nmain reason for the success of deep Q-learning is the excellent performance of\ndeep neural networks (deep nets) in capturing the special properties of rewards\nnamely, spatial sparseness and piecewise constancy, rather than their large\ncapacities. In this paper, we make fundamental contributions to the field of\nreinforcement learning by answering to the following three questions: Why does\ndeep Q-learning perform so well? When does deep Q-learning perform better than\ntraditional Q-learning? How many samples are required to achieve a specific\nprediction accuracy for deep Q-learning? Our theoretical assertions are\nverified by applying deep Q-learning in the well-known beer game in supply\nchain management and a simulated recommender system.",
            "author": [
                "Shao-Bo Lin",
                "Tao Li",
                "Shaojie Tang",
                "Yao Wang",
                "Ding-Xuan Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17915v1",
                "http://arxiv.org/pdf/2310.17915v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17912v1",
            "title": "Restoring the Broken Covenant Between Compilers and Deep Learning\n  Accelerators",
            "updated": "2023-10-27T06:14:45Z",
            "published": "2023-10-27T06:14:45Z",
            "summary": "Deep learning accelerators address the computational demands of Deep Neural\nNetworks (DNNs), departing from the traditional Von Neumann execution model.\nThey leverage specialized hardware to align with the application domain's\nstructure. Compilers for these accelerators face distinct challenges compared\nto those for general-purpose processors. These challenges include exposing and\nmanaging more micro-architectural features, handling software-managed scratch\npads for on-chip storage, explicitly managing data movement, and matching DNN\nlayers with varying hardware capabilities. These complexities necessitate a new\napproach to compiler design, as traditional compilers mainly focused on\ngenerating fine-grained instruction sequences while abstracting\nmicro-architecture details. This paper introduces the Architecture Covenant\nGraph (ACG), an abstract representation of an architectural structure's\ncomponents and their programmable capabilities. By enabling the compiler to\nwork with the ACG, it allows for adaptable compilation workflows when making\nchanges to accelerator design, reducing the need for a complete compiler\nredevelopment. Codelets, which express DNN operation functionality and evolve\ninto execution mappings on the ACG, are key to this process. The Covenant\ncompiler efficiently targets diverse deep learning accelerators, achieving\n93.8% performance compared to state-of-the-art, hand-tuned DNN layer\nimplementations when compiling 14 DNN layers from various models on two\ndifferent architectures.",
            "author": [
                "Sean Kinzer",
                "Soroush Ghodrati",
                "Rohan Mahapatra",
                "Byung Hoon Ahn",
                "Edwin Mascarenhas",
                "Xiaolong Li",
                "Janarbek Matai",
                "Liang Zhang",
                "Hadi Esmaeilzadeh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17912v1",
                "http://arxiv.org/pdf/2310.17912v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17903v1",
            "title": "Pitfalls in Language Models for Code Intelligence: A Taxonomy and Survey",
            "updated": "2023-10-27T05:32:57Z",
            "published": "2023-10-27T05:32:57Z",
            "summary": "Modern language models (LMs) have been successfully employed in source code\ngeneration and understanding, leading to a significant increase in research\nfocused on learning-based code intelligence, such as automated bug repair, and\ntest case generation. Despite their great potential, language models for code\nintelligence (LM4Code) are susceptible to potential pitfalls, which hinder\nrealistic performance and further impact their reliability and applicability in\nreal-world deployment. Such challenges drive the need for a comprehensive\nunderstanding - not just identifying these issues but delving into their\npossible implications and existing solutions to build more reliable language\nmodels tailored to code intelligence. Based on a well-defined systematic\nresearch approach, we conducted an extensive literature review to uncover the\npitfalls inherent in LM4Code. Finally, 67 primary studies from top-tier venues\nhave been identified. After carefully examining these studies, we designed a\ntaxonomy of pitfalls in LM4Code research and conducted a systematic study to\nsummarize the issues, implications, current solutions, and challenges of\ndifferent pitfalls for LM4Code systems. We developed a comprehensive\nclassification scheme that dissects pitfalls across four crucial aspects: data\ncollection and labeling, system design and learning, performance evaluation,\nand deployment and maintenance. Through this study, we aim to provide a roadmap\nfor researchers and practitioners, facilitating their understanding and\nutilization of LM4Code in reliable and trustworthy ways.",
            "author": [
                "Xinyu She",
                "Yue Liu",
                "Yanjie Zhao",
                "Yiling He",
                "Li Li",
                "Chakkrit Tantithamthavorn",
                "Zhan Qin",
                "Haoyu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17903v1",
                "http://arxiv.org/pdf/2310.17903v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17902v1",
            "title": "CPIA Dataset: A Comprehensive Pathological Image Analysis Dataset for\n  Self-supervised Learning Pre-training",
            "updated": "2023-10-27T05:32:16Z",
            "published": "2023-10-27T05:32:16Z",
            "summary": "Pathological image analysis is a crucial field in computer-aided diagnosis,\nwhere deep learning is widely applied. Transfer learning using pre-trained\nmodels initialized on natural images has effectively improved the downstream\npathological performance. However, the lack of sophisticated domain-specific\npathological initialization hinders their potential. Self-supervised learning\n(SSL) enables pre-training without sample-level labels, which has great\npotential to overcome the challenge of expensive annotations. Thus, studies\nfocusing on pathological SSL pre-training call for a comprehensive and\nstandardized dataset, similar to the ImageNet in computer vision. This paper\npresents the comprehensive pathological image analysis (CPIA) dataset, a\nlarge-scale SSL pre-training dataset combining 103 open-source datasets with\nextensive standardization. The CPIA dataset contains 21,427,877 standardized\nimages, covering over 48 organs/tissues and about 100 kinds of diseases, which\nincludes two main data types: whole slide images (WSIs) and characteristic\nregions of interest (ROIs). A four-scale WSI standardization process is\nproposed based on the uniform resolution in microns per pixel (MPP), while the\nROIs are divided into three scales artificially. This multi-scale dataset is\nbuilt with the diagnosis habits under the supervision of experienced senior\npathologists. The CPIA dataset facilitates a comprehensive pathological\nunderstanding and enables pattern discovery explorations. Additionally, to\nlaunch the CPIA dataset, several state-of-the-art (SOTA) baselines of SSL\npre-training and downstream evaluation are specially conducted. The CPIA\ndataset along with baselines is available at\nhttps://github.com/zhanglab2021/CPIA_Dataset.",
            "author": [
                "Nan Ying",
                "Yanli Lei",
                "Tianyi Zhang",
                "Shangqing Lyu",
                "Chunhui Li",
                "Sicheng Chen",
                "Zeyu Liu",
                "Yu Zhao",
                "Guanglei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17902v1",
                "http://arxiv.org/pdf/2310.17902v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17901v1",
            "title": "Improving the Knowledge Gradient Algorithm",
            "updated": "2023-10-27T05:25:02Z",
            "published": "2023-10-27T05:25:02Z",
            "summary": "The knowledge gradient (KG) algorithm is a popular policy for the best arm\nidentification (BAI) problem. It is built on the simple idea of always choosing\nthe measurement that yields the greatest expected one-step improvement in the\nestimate of the best mean of the arms. In this research, we show that this\npolicy has limitations, causing the algorithm not asymptotically optimal. We\nnext provide a remedy for it, by following the manner of one-step look ahead of\nKG, but instead choosing the measurement that yields the greatest one-step\nimprovement in the probability of selecting the best arm. The new policy is\ncalled improved knowledge gradient (iKG). iKG can be shown to be asymptotically\noptimal. In addition, we show that compared to KG, it is easier to extend iKG\nto variant problems of BAI, with the $\\epsilon$-good arm identification and\nfeasible arm identification as two examples. The superior performances of iKG\non these problems are further demonstrated using numerical examples.",
            "author": [
                "Yang Le",
                "Gao Siyang",
                "Ho Chin Pang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17901v1",
                "http://arxiv.org/pdf/2310.17901v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17897v1",
            "title": "Event Generation and Consistence Test for Physics with Sliced\n  Wasserstein Distance",
            "updated": "2023-10-27T05:08:25Z",
            "published": "2023-10-27T05:08:25Z",
            "summary": "In the field of modern high-energy physics research, there is a growing\nemphasis on utilizing deep learning techniques to optimize event simulation,\nthereby expanding the statistical sample size for more accurate physical\nanalysis. Traditional simulation methods often encounter challenges when\ndealing with complex physical processes and high-dimensional data\ndistributions, resulting in slow performance. To overcome these limitations, we\npropose a solution based on deep learning with the sliced Wasserstein distance\nas the loss function. Our method shows its ability on high precision and\nlarge-scale simulations, and demonstrates its effectiveness in handling complex\nphysical processes. By employing an advanced transformer learning architecture,\nwe initiate the learning process from a Monte Carlo sample, and generate\nhigh-dimensional data while preserving all original distribution features. The\ngenerated data samples have passed the consistence test, that is developed to\ncalculate the confidence of the high-dimentional distributions of the generated\ndata samples through permutation tests. This fast simulation strategy, enabled\nby deep learning, holds significant potential not only for increasing sample\nsizes and reducing statistical uncertainties but also for applications in\nnumerical integration, which is crucial in partial wave analysis,\nhigh-precision sample checks, and other related fields. It opens up new\npossibilities for improving event simulation in high-energy physics research.",
            "author": [
                "Chu-Cheng Pan",
                "Xiang Dong",
                "Yu-Chang Sun",
                "Ao-Yan Cheng",
                "Ao-Bo Wang",
                "Yu-Xuan Hu",
                "Hao Cai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17897v1",
                "http://arxiv.org/pdf/2310.17897v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17896v1",
            "title": "Inferring to C or not to C: Evolutionary games with Bayesian inferential\n  strategies",
            "updated": "2023-10-27T05:06:34Z",
            "published": "2023-10-27T05:06:34Z",
            "summary": "Strategies for sustaining cooperation and preventing exploitation by selfish\nagents in repeated games have mostly been restricted to Markovian strategies\nwhere the response of an agent depends on the actions in the previous round.\nSuch strategies are characterized by lack of learning. However, learning from\naccumulated evidence over time and using the evidence to dynamically update our\nresponse is a key feature of living organisms. Bayesian inference provides a\nframework for such evidence-based learning mechanisms. It is therefore\nimperative to understand how strategies based on Bayesian learning fare in\nrepeated games with Markovian strategies. Here, we consider a scenario where\nthe Bayesian player uses the accumulated evidence of the opponent's actions\nover several rounds to continuously update her belief about the reactive\nopponent's strategy. The Bayesian player can then act on her inferred belief in\ndifferent ways. By studying repeated Prisoner's dilemma games with such\nBayesian inferential strategies, both in infinite and finite populations, we\nidentify the conditions under which such strategies can be evolutionarily\nstable. We find that a Bayesian strategy that is less altruistic than the\ninferred belief about the opponent's strategy can outperform a larger set of\nreactive strategies, whereas one that is more generous than the inferred belief\nis more successful when the benefit-to-cost ratio of mutual cooperation is\nhigh. Our analysis reveals how learning the opponent's strategy through\nBayesian inference, as opposed to utility maximization, can be beneficial in\nthe long run, in preventing exploitation and eventual invasion by reactive\nstrategies.",
            "author": [
                "Arunava Patra",
                "Supratim Sengupta",
                "Ayan Paul",
                "Sagar Chakraborty"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17896v1",
                "http://arxiv.org/pdf/2310.17896v1"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE",
                "physics.bio-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.06278v1",
            "title": "Boosting Stock Price Prediction with Anticipated Macro Policy Changes",
            "updated": "2023-10-27T04:57:45Z",
            "published": "2023-10-27T04:57:45Z",
            "summary": "Prediction of stock prices plays a significant role in aiding the\ndecision-making of investors. Considering its importance, a growing literature\nhas emerged trying to forecast stock prices with improved accuracy. In this\nstudy, we introduce an innovative approach for forecasting stock prices with\ngreater accuracy. We incorporate external economic environment-related\ninformation along with stock prices. In our novel approach, we improve the\nperformance of stock price prediction by taking into account variations due to\nfuture expected macroeconomic policy changes as investors adjust their current\nbehavior ahead of time based on expected future macroeconomic policy changes.\nFurthermore, we incorporate macroeconomic variables along with historical stock\nprices to make predictions. Results from this strongly support the inclusion of\nfuture economic policy changes along with current macroeconomic information. We\nconfirm the supremacy of our method over the conventional approach using\nseveral tree-based machine-learning algorithms. Results are strongly conclusive\nacross various machine learning models. Our preferred model outperforms the\nconventional approach with an RMSE value of 1.61 compared to an RMSE value of\n1.75 from the conventional approach.",
            "author": [
                "Md Sabbirul Haque",
                "Md Shahedul Amin",
                "Jonayet Miah",
                "Duc Minh Cao",
                "Ashiqul Haque Ahmed"
            ],
            "link": [
                "http://dx.doi.org/10.32996/jmss",
                "http://arxiv.org/abs/2311.06278v1",
                "http://arxiv.org/pdf/2311.06278v1"
            ],
            "primary_category": "q-fin.ST",
            "category": [
                "q-fin.ST",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17890v1",
            "title": "Submodel Partitioning in Hierarchical Federated Learning: Algorithm\n  Design and Convergence Analysis",
            "updated": "2023-10-27T04:42:59Z",
            "published": "2023-10-27T04:42:59Z",
            "summary": "Hierarchical federated learning (HFL) has demonstrated promising scalability\nadvantages over the traditional \"star-topology\" architecture-based federated\nlearning (FL). However, HFL still imposes significant computation,\ncommunication, and storage burdens on the edge, especially when training a\nlarge-scale model over resource-constrained Internet of Things (IoT) devices.\nIn this paper, we propose hierarchical independent submodel training (HIST), a\nnew FL methodology that aims to address these issues in hierarchical settings.\nThe key idea behind HIST is a hierarchical version of model partitioning, where\nwe partition the global model into disjoint submodels in each round, and\ndistribute them across different cells, so that each cell is responsible for\ntraining only one partition of the full model. This enables each client to save\ncomputation/storage costs while alleviating the communication loads throughout\nthe hierarchy. We characterize the convergence behavior of HIST for non-convex\nloss functions under mild assumptions, showing the impact of several attributes\n(e.g., number of cells, local and global aggregation frequency) on the\nperformance-efficiency tradeoff. Finally, through numerical experiments, we\nverify that HIST is able to save communication costs by a wide margin while\nachieving the same target testing accuracy.",
            "author": [
                "Wenzhi Fang",
                "Dong-Jun Han",
                "Christopher G. Brinton"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17890v1",
                "http://arxiv.org/pdf/2310.17890v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17889v1",
            "title": "Towards optimal multimode fiber imaging by leveraging input polarization\n  and conditional generative adversarial networks",
            "updated": "2023-10-27T04:39:23Z",
            "published": "2023-10-27T04:39:23Z",
            "summary": "Deep learning techniques provide a plausible route towards achieving\npractical imaging through multimode fibers. However, the results produced by\nthese methods are often influenced by physical factors like temperature, fiber\nlength, external perturbations, and polarization state of the input light. The\nimpact of other factors, except input light polarization, has been discussed in\nthe literature for imaging applications. The input polarization has been\nconsidered by researchers while looking at the characterization and control of\npolarization in multimode fibers. Here, we show experimentally that the state\nof polarization of light, being injected at multimode fiber input, affects the\nfidelity of reconstructed images from speckle patterns. Certain polarization\nstates produce high-quality images at fiber output, while some yield degraded\nresults. We have designed a conditional generative adversarial network~(CGAN)\nfor image regeneration at various degrees of input light polarization. We\ndemonstrate that in the case of multimode fibers that are held fixed, optimal\nimaging can be achieved by leveraging our CGAN model with the input light\npolarization state, where the fidelity of images is maximum. Our work exhibits\nhigh average structural similarity index values exceeding 0.9, surpassing the\npreviously reported value of 0.8772. We also show that the model can be\ngeneralized to image adequately for all input light polarization states when\nthe fiber has bends or twists. We anticipate our work will be a stepping stone\ntoward developing high-resolution and less invasive multimode fiber endoscopes.",
            "author": [
                "Jawaria Maqbool",
                "Syed Talal Hassan",
                "M. Imran Cheema"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17889v1",
                "http://arxiv.org/pdf/2310.17889v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17888v1",
            "title": "Large Language Models as Subpopulation Representative Models: A Review",
            "updated": "2023-10-27T04:31:27Z",
            "published": "2023-10-27T04:31:27Z",
            "summary": "Of the many commercial and scientific opportunities provided by large\nlanguage models (LLMs; including Open AI's ChatGPT, Meta's LLaMA, and\nAnthropic's Claude), one of the more intriguing applications has been the\nsimulation of human behavior and opinion. LLMs have been used to generate human\nsimulcra to serve as experimental participants, survey respondents, or other\nindependent agents, with outcomes that often closely parallel the observed\nbehavior of their genuine human counterparts. Here, we specifically consider\nthe feasibility of using LLMs to estimate subpopulation representative models\n(SRMs). SRMs could provide an alternate or complementary way to measure public\nopinion among demographic, geographic, or political segments of the population.\nHowever, the introduction of new technology to the socio-technical\ninfrastructure does not come without risk. We provide an overview of behavior\nelicitation techniques for LLMs, and a survey of existing SRM implementations.\nWe offer frameworks for the analysis, development, and practical implementation\nof LLMs as SRMs, consider potential risks, and suggest directions for future\nwork.",
            "author": [
                "Gabriel Simmons",
                "Christopher Hare"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17888v1",
                "http://arxiv.org/pdf/2310.17888v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17887v1",
            "title": "Impressions: Understanding Visual Semiotics and Aesthetic Impact",
            "updated": "2023-10-27T04:30:18Z",
            "published": "2023-10-27T04:30:18Z",
            "summary": "Is aesthetic impact different from beauty? Is visual salience a reflection of\nits capacity for effective communication? We present Impressions, a novel\ndataset through which to investigate the semiotics of images, and how specific\nvisual features and design choices can elicit specific emotions, thoughts and\nbeliefs. We posit that the impactfulness of an image extends beyond formal\ndefinitions of aesthetics, to its success as a communicative act, where style\ncontributes as much to meaning formation as the subject matter. However, prior\nimage captioning datasets are not designed to empower state-of-the-art\narchitectures to model potential human impressions or interpretations of\nimages. To fill this gap, we design an annotation task heavily inspired by\nimage analysis techniques in the Visual Arts to collect 1,440 image-caption\npairs and 4,320 unique annotations exploring impact, pragmatic image\ndescription, impressions, and aesthetic design choices. We show that existing\nmultimodal image captioning and conditional generation models struggle to\nsimulate plausible human responses to images. However, this dataset\nsignificantly improves their ability to model impressions and aesthetic\nevaluations of images through fine-tuning and few-shot adaptation.",
            "author": [
                "Julia Kruk",
                "Caleb Ziems",
                "Diyi Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17887v1",
                "http://arxiv.org/pdf/2310.17887v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17882v1",
            "title": "Machine Learning Infused Distributed Optimization for Coordinating\n  Virtual Power Plant Assets",
            "updated": "2023-10-27T04:11:13Z",
            "published": "2023-10-27T04:11:13Z",
            "summary": "Amid the increasing interest in the deployment of Distributed Energy\nResources (DERs), the Virtual Power Plant (VPP) has emerged as a pivotal tool\nfor aggregating diverse DERs and facilitating their participation in wholesale\nenergy markets. These VPP deployments have been fueled by the Federal Energy\nRegulatory Commission's Order 2222, which makes DERs and VPPs competitive\nacross market segments. However, the diversity and decentralized nature of DERs\npresent significant challenges to the scalable coordination of VPP assets. To\naddress efficiency and speed bottlenecks, this paper presents a novel machine\nlearning-assisted distributed optimization to coordinate VPP assets. Our\nmethod, named LOOP-MAC(Learning to Optimize the Optimization Process for\nMulti-agent Coordination), adopts a multi-agent coordination perspective where\neach VPP agent manages multiple DERs and utilizes neural network approximators\nto expedite the solution search. The LOOP-MAC method employs a gauge map to\nguarantee strict compliance with local constraints, effectively reducing the\nneed for additional post-processing steps. Our results highlight the advantages\nof LOOP-MAC, showcasing accelerated solution times per iteration and\nsignificantly reduced convergence times. The LOOP-MAC method outperforms\nconventional centralized and distributed optimization methods in optimization\ntasks that require repetitive and sequential execution.",
            "author": [
                "Meiyi Li",
                "Javad Mohammadi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17882v1",
                "http://arxiv.org/pdf/2310.17882v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17880v1",
            "title": "Reconstructive Latent-Space Neural Radiance Fields for Efficient 3D\n  Scene Representations",
            "updated": "2023-10-27T03:52:08Z",
            "published": "2023-10-27T03:52:08Z",
            "summary": "Neural Radiance Fields (NeRFs) have proven to be powerful 3D representations,\ncapable of high quality novel view synthesis of complex scenes. While NeRFs\nhave been applied to graphics, vision, and robotics, problems with slow\nrendering speed and characteristic visual artifacts prevent adoption in many\nuse cases. In this work, we investigate combining an autoencoder (AE) with a\nNeRF, in which latent features (instead of colours) are rendered and then\nconvolutionally decoded. The resulting latent-space NeRF can produce novel\nviews with higher quality than standard colour-space NeRFs, as the AE can\ncorrect certain visual artifacts, while rendering over three times faster. Our\nwork is orthogonal to other techniques for improving NeRF efficiency. Further,\nwe can control the tradeoff between efficiency and image quality by shrinking\nthe AE architecture, achieving over 13 times faster rendering with only a small\ndrop in performance. We hope that our approach can form the basis of an\nefficient, yet high-fidelity, 3D scene representation for downstream tasks,\nespecially when retaining differentiability is useful, as in many robotics\nscenarios requiring continual learning.",
            "author": [
                "Tristan Aumentado-Armstrong",
                "Ashkan Mirzaei",
                "Marcus A. Brubaker",
                "Jonathan Kelly",
                "Alex Levinshtein",
                "Konstantinos G. Derpanis",
                "Igor Gilitschenski"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17880v1",
                "http://arxiv.org/pdf/2310.17880v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17878v1",
            "title": "A Sublinear-Time Spectral Clustering Oracle with Improved Preprocessing\n  Time",
            "updated": "2023-10-27T03:40:37Z",
            "published": "2023-10-27T03:40:37Z",
            "summary": "We address the problem of designing a sublinear-time spectral clustering\noracle for graphs that exhibit strong clusterability. Such graphs contain $k$\nlatent clusters, each characterized by a large inner conductance (at least\n$\\varphi$) and a small outer conductance (at most $\\varepsilon$). Our aim is to\npreprocess the graph to enable clustering membership queries, with the key\nrequirement that both preprocessing and query answering should be performed in\nsublinear time, and the resulting partition should be consistent with a\n$k$-partition that is close to the ground-truth clustering. Previous oracles\nhave relied on either a $\\textrm{poly}(k)\\log n$ gap between inner and outer\nconductances or exponential (in $k/\\varepsilon$) preprocessing time. Our\nalgorithm relaxes these assumptions, albeit at the cost of a slightly higher\nmisclassification ratio. We also show that our clustering oracle is robust\nagainst a few random edge deletions. To validate our theoretical bounds, we\nconducted experiments on synthetic networks.",
            "author": [
                "Ranran Shen",
                "Pan Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17878v1",
                "http://arxiv.org/pdf/2310.17878v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17877v1",
            "title": "ASPIRO: Any-shot Structured Parsing-error-Induced ReprOmpting for\n  Consistent Data-to-Text Generation",
            "updated": "2023-10-27T03:39:51Z",
            "published": "2023-10-27T03:39:51Z",
            "summary": "We present ASPIRO, an approach for structured data verbalisation into short\ntemplate sentences in zero to few-shot settings. Unlike previous methods, our\napproach prompts large language models (LLMs) to directly produce\nentity-agnostic templates, rather than relying on LLMs to faithfully copy the\ngiven example entities, or validating/crafting the templates manually. We\nincorporate LLM re-prompting, triggered by algorithmic parsing checks, as well\nas the PARENT metric induced consistency validation to identify and rectify\ntemplate generation problems in real-time. ASPIRO, compared to direct LLM\noutput, averages 66\\% parsing error rate reduction in generated verbalisations\nof RDF triples on the DART dataset. Our best 5-shot text-davinci-003 setup,\nscoring BLEU of 50.62, METEOR of 45.16, BLEURT of 0.82, NUBIA of 0.87, and\nPARENT of 0.8962 on the Rel2Text dataset, competes effectively with recent\nfine-tuned pre-trained language models.",
            "author": [
                "Martin Vejvar",
                "Yasutaka Fujimoto"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17877v1",
                "http://arxiv.org/pdf/2310.17877v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17874v1",
            "title": "SmooSeg: Smoothness Prior for Unsupervised Semantic Segmentation",
            "updated": "2023-10-27T03:29:25Z",
            "published": "2023-10-27T03:29:25Z",
            "summary": "Unsupervised semantic segmentation is a challenging task that segments images\ninto semantic groups without manual annotation. Prior works have primarily\nfocused on leveraging prior knowledge of semantic consistency or priori\nconcepts from self-supervised learning methods, which often overlook the\ncoherence property of image segments. In this paper, we demonstrate that the\nsmoothness prior, asserting that close features in a metric space share the\nsame semantics, can significantly simplify segmentation by casting unsupervised\nsemantic segmentation as an energy minimization problem. Under this paradigm,\nwe propose a novel approach called SmooSeg that harnesses self-supervised\nlearning methods to model the closeness relationships among observations as\nsmoothness signals. To effectively discover coherent semantic segments, we\nintroduce a novel smoothness loss that promotes piecewise smoothness within\nsegments while preserving discontinuities across different segments.\nAdditionally, to further enhance segmentation quality, we design an asymmetric\nteacher-student style predictor that generates smoothly updated pseudo labels,\nfacilitating an optimal fit between observations and labeling outputs. Thanks\nto the rich supervision cues of the smoothness prior, our SmooSeg significantly\noutperforms STEGO in terms of pixel accuracy on three datasets: COCOStuff\n(+14.9%), Cityscapes (+13.0%), and Potsdam-3 (+5.7%).",
            "author": [
                "Mengcheng Lan",
                "Xinjiang Wang",
                "Yiping Ke",
                "Jiaxing Xu",
                "Litong Feng",
                "Wayne Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17874v1",
                "http://arxiv.org/pdf/2310.17874v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17870v1",
            "title": "Ranking with Slot Constraints",
            "updated": "2023-10-27T03:14:50Z",
            "published": "2023-10-27T03:14:50Z",
            "summary": "We introduce the problem of ranking with slot constraints, which can be used\nto model a wide range of application problems -- from college admission with\nlimited slots for different majors, to composing a stratified cohort of\neligible participants in a medical trial. We show that the conventional\nProbability Ranking Principle (PRP) can be highly sub-optimal for\nslot-constrained ranking problems, and we devise a new ranking algorithm,\ncalled MatchRank. The goal of MatchRank is to produce rankings that maximize\nthe number of filled slots if candidates are evaluated by a human decision\nmaker in the order of the ranking. In this way, MatchRank generalizes the PRP,\nand it subsumes the PRP as a special case when there are no slot constraints.\nOur theoretical analysis shows that MatchRank has a strong approximation\nguarantee without any independence assumptions between slots or candidates.\nFurthermore, we show how MatchRank can be implemented efficiently. Beyond the\ntheoretical guarantees, empirical evaluations show that MatchRank can provide\nsubstantial improvements over a range of synthetic and real-world tasks.",
            "author": [
                "Wentao Guo",
                "Andrew Wang",
                "Bradon Thymes",
                "Thorsten Joachims"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17870v1",
                "http://arxiv.org/pdf/2310.17870v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17869v1",
            "title": "Grid Jigsaw Representation with CLIP: A New Perspective on Image\n  Clustering",
            "updated": "2023-10-27T03:07:05Z",
            "published": "2023-10-27T03:07:05Z",
            "summary": "Unsupervised representation learning for image clustering is essential in\ncomputer vision. Although the advancement of visual models has improved image\nclustering with efficient visual representations, challenges still remain.\nFirstly, these features often lack the ability to represent the internal\nstructure of images, hindering the accurate clustering of visually similar\nimages. Secondly, the existing features tend to lack finer-grained semantic\nlabels, limiting the ability to capture nuanced differences and similarities\nbetween images.\n  In this paper, we first introduce Jigsaw based strategy method for image\nclustering called Grid Jigsaw Representation (GJR) with systematic exposition\nfrom pixel to feature in discrepancy against human and computer. We emphasize\nthat this algorithm, which mimics human jigsaw puzzle, can effectively improve\nthe model to distinguish the spatial feature between different samples and\nenhance the clustering ability. GJR modules are appended to a variety of deep\nconvolutional networks and tested with significant improvements on a wide range\nof benchmark datasets including CIFAR-10, CIFAR-100/20, STL-10, ImageNet-10 and\nImageNetDog-15.\n  On the other hand, convergence efficiency is always an important challenge\nfor unsupervised image clustering. Recently, pretrained representation learning\nhas made great progress and released models can extract mature visual\nrepresentations. It is obvious that use the pretrained model as feature\nextractor can speed up the convergence of clustering where our aim is to\nprovide new perspective in image clustering with reasonable resource\napplication and provide new baseline. Further, we innovate pretrain-based Grid\nJigsaw Representation (pGJR) with improvement by GJR. The experiment results\nshow the effectiveness on the clustering task with respect to the ACC, NMI and\nARI three metrics and super fast convergence speed.",
            "author": [
                "Zijie Song",
                "Zhenzhen Hu",
                "Richang Hong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17869v1",
                "http://arxiv.org/pdf/2310.17869v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17868v1",
            "title": "Resource Allocation for Near-Field Communications: Fundamentals, Tools,\n  and Outlooks",
            "updated": "2023-10-27T03:06:56Z",
            "published": "2023-10-27T03:06:56Z",
            "summary": "Extremely large-scale multiple-input-multiple output (XL-MIMO) is a promising\ntechnology to achieve high spectral efficiency (SE) and energy efficiency (EE)\nin future wireless systems. The larger array aperture of XL-MIMO makes\ncommunication scenarios closer to the near-field region. Therefore, near-field\nresource allocation is essential in realizing the above key performance\nindicators (KPIs). Moreover, the overall performance of XL-MIMO systems heavily\ndepends on the channel characteristics of the selected users, eliminating\ninterference between users through beamforming, power control, etc. The above\nresource allocation issue constitutes a complex joint multi-objective\noptimization problem since many variables and parameters must be optimized,\nincluding the spatial degree of freedom, rate, power allocation, and\ntransmission technique. In this article, we review the basic properties of\nnear-field communications and focus on the corresponding \"resource allocation\"\nproblems. First, we identify available resources in near-field communication\nsystems and highlight their distinctions from far-field communications. Then,\nwe summarize optimization tools, such as numerical techniques and machine\nlearning methods, for addressing near-field resource allocation, emphasizing\ntheir strengths and limitations. Finally, several important research directions\nof near-field communications are pointed out for further investigation.",
            "author": [
                "Bokai Xu",
                "Jiayi Zhang",
                "Hongyang Du",
                "Zhe Wang",
                "Yuanwei Liu",
                "Dusit Niyato",
                "Bo Ai",
                "Khaled B. Letaief"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17868v1",
                "http://arxiv.org/pdf/2310.17868v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17867v1",
            "title": "Reproducibility in Multiple Instance Learning: A Case For Algorithmic\n  Unit Tests",
            "updated": "2023-10-27T03:05:11Z",
            "published": "2023-10-27T03:05:11Z",
            "summary": "Multiple Instance Learning (MIL) is a sub-domain of classification problems\nwith positive and negative labels and a \"bag\" of inputs, where the label is\npositive if and only if a positive element is contained within the bag, and\notherwise is negative. Training in this context requires associating the\nbag-wide label to instance-level information, and implicitly contains a causal\nassumption and asymmetry to the task (i.e., you can't swap the labels without\nchanging the semantics). MIL problems occur in healthcare (one malignant cell\nindicates cancer), cyber security (one malicious executable makes an infected\ncomputer), and many other tasks. In this work, we examine five of the most\nprominent deep-MIL models and find that none of them respects the standard MIL\nassumption. They are able to learn anti-correlated instances, i.e., defaulting\nto \"positive\" labels until seeing a negative counter-example, which should not\nbe possible for a correct MIL model. We suspect that enhancements and other\nworks derived from these models will share the same issue. In any context in\nwhich these models are being used, this creates the potential for learning\nincorrect models, which creates risk of operational failure. We identify and\ndemonstrate this problem via a proposed \"algorithmic unit test\", where we\ncreate synthetic datasets that can be solved by a MIL respecting model, and\nwhich clearly reveal learning that violates MIL assumptions. The five evaluated\nmethods each fail one or more of these tests. This provides a model-agnostic\nway to identify violations of modeling assumptions, which we hope will be\nuseful for future development and evaluation of MIL models.",
            "author": [
                "Edward Raff",
                "James Holt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17867v1",
                "http://arxiv.org/pdf/2310.17867v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17864v1",
            "title": "TorchAudio 2.1: Advancing speech recognition, self-supervised learning,\n  and audio processing components for PyTorch",
            "updated": "2023-10-27T03:00:51Z",
            "published": "2023-10-27T03:00:51Z",
            "summary": "TorchAudio is an open-source audio and speech processing library built for\nPyTorch. It aims to accelerate the research and development of audio and speech\ntechnologies by providing well-designed, easy-to-use, and performant PyTorch\ncomponents. Its contributors routinely engage with users to understand their\nneeds and fulfill them by developing impactful features. Here, we survey\nTorchAudio's development principles and contents and highlight key features we\ninclude in its latest version (2.1): self-supervised learning pre-trained\npipelines and training recipes, high-performance CTC decoders, speech\nrecognition models and training recipes, advanced media I/O capabilities, and\ntools for performing forced alignment, multi-channel speech enhancement, and\nreference-less speech assessment. For a selection of these features, through\nempirical studies, we demonstrate their efficacy and show that they achieve\ncompetitive or state-of-the-art performance.",
            "author": [
                "Jeff Hwang",
                "Moto Hira",
                "Caroline Chen",
                "Xiaohui Zhang",
                "Zhaoheng Ni",
                "Guangzhi Sun",
                "Pingchuan Ma",
                "Ruizhe Huang",
                "Vineel Pratap",
                "Yuekai Zhang",
                "Anurag Kumar",
                "Chin-Yun Yu",
                "Chuang Zhu",
                "Chunxi Liu",
                "Jacob Kahn",
                "Mirco Ravanelli",
                "Peng Sun",
                "Shinji Watanabe",
                "Yangyang Shi",
                "Yumeng Tao",
                "Robin Scheibler",
                "Samuele Cornell",
                "Sean Kim",
                "Stavros Petridis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17864v1",
                "http://arxiv.org/pdf/2310.17864v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18382v1",
            "title": "From Generative AI to Generative Internet of Things: Fundamentals,\n  Framework, and Outlooks",
            "updated": "2023-10-27T02:58:11Z",
            "published": "2023-10-27T02:58:11Z",
            "summary": "Generative Artificial Intelligence (GAI) possesses the capabilities of\ngenerating realistic data and facilitating advanced decision-making. By\nintegrating GAI into modern Internet of Things (IoT), Generative Internet of\nThings (GIoT) is emerging and holds immense potential to revolutionize various\naspects of society, enabling more efficient and intelligent IoT applications,\nsuch as smart surveillance and voice assistants. In this article, we present\nthe concept of GIoT and conduct an exploration of its potential prospects.\nSpecifically, we first overview four GAI techniques and investigate promising\nGIoT applications. Then, we elaborate on the main challenges in enabling GIoT\nand propose a general GAI-based secure incentive mechanism framework to address\nthem, in which we adopt Generative Diffusion Models (GDMs) for incentive\nmechanism designs and apply blockchain technologies for secure GIoT management.\nMoreover, we conduct a case study on modern Internet of Vehicle traffic\nmonitoring, which utilizes GDMs to generate effective contracts for\nincentivizing users to contribute sensing data with high quality. Finally, we\nsuggest several open directions worth investigating for the future popularity\nof GIoT.",
            "author": [
                "Jinbo Wen",
                "Jiangtian Nie",
                "Jiawen Kang",
                "Dusit Niyato",
                "Hongyang Du",
                "Yang Zhang",
                "Mohsen Guizani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18382v1",
                "http://arxiv.org/pdf/2310.18382v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.GT",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18381v1",
            "title": "Unveil Sleep Spindles with Concentration of Frequency and Time",
            "updated": "2023-10-27T02:46:58Z",
            "published": "2023-10-27T02:46:58Z",
            "summary": "Objective: Sleep spindles contain crucial brain dynamics information. We\nintroduce the novel non-linear time-frequency analysis tool 'Concentration of\nFrequency and Time' (ConceFT) to create an interpretable automated algorithm\nfor sleep spindle annotation in EEG data and to measure spindle instantaneous\nfrequencies (IFs). Methods: ConceFT effectively reduces stochastic EEG\ninfluence, enhancing spindle visibility in the time-frequency representation.\nOur automated spindle detection algorithm, ConceFT-Spindle (ConceFT-S), is\ncompared to A7 (non-deep learning) and SUMO (deep learning) using Dream and\nMASS benchmark databases. We also quantify spindle IF dynamics. Results:\nConceFT-S achieves F1 scores of 0.749 in Dream and 0.786 in MASS, which is\nequivalent to or surpass A7 and SUMO with statistical significance. We reveal\nthat spindle IF is generally nonlinear. Conclusion: ConceFT offers an accurate,\ninterpretable EEG-based sleep spindle detection algorithm and enables spindle\nIF quantification.",
            "author": [
                "Riki Shimizu",
                "Hau-Tieng Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18381v1",
                "http://arxiv.org/pdf/2310.18381v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17860v1",
            "title": "A meta-analysis of distance measurements to M87",
            "updated": "2023-10-27T02:26:01Z",
            "published": "2023-10-27T02:26:01Z",
            "summary": "We obtain the median, arithmetic mean, and the weighted mean-based central\nestimates for the distance to M87 using all the measurements collated in De\nGrijs et al (2020). We then reconstruct the error distribution for the\nresiduals of the combined measurements and also splitting them based on the\ntracers used. We then checked for consistency with a Gaussian distribution and\nother symmetric distributions such as Cauchy, Laplacian, and Students-$t$\ndistributions. We find that when we analyze the combined data, the weighted\nmean-based estimates show a poor agreement with the Gaussian distribution,\nindicating that there are unaccounted systematic errors in some of the\nmeasurements. Therefore, the median-based estimate for the distance to M87\nwould be the most robust. This median-based distance modulus to M87 is given by\n$31.08 \\pm 0.09$ mag and $31.07 \\pm 0.09$ mag, with and without considering\nmeasurements categorized as \"averages\", respectively. This estimate agrees with\nthe corresponding value obtained in DeGrijs et al (2020) to within $1\\sigma$.",
            "author": [
                "Gunasekar Ramakrishnan",
                "Shantanu Desai"
            ],
            "link": [
                "http://dx.doi.org/10.1093/ptep/ptad137",
                "http://arxiv.org/abs/2310.17860v1",
                "http://arxiv.org/pdf/2310.17860v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17852v1",
            "title": "Function Space Bayesian Pseudocoreset for Bayesian Neural Networks",
            "updated": "2023-10-27T02:04:31Z",
            "published": "2023-10-27T02:04:31Z",
            "summary": "A Bayesian pseudocoreset is a compact synthetic dataset summarizing essential\ninformation of a large-scale dataset and thus can be used as a proxy dataset\nfor scalable Bayesian inference. Typically, a Bayesian pseudocoreset is\nconstructed by minimizing a divergence measure between the posterior\nconditioning on the pseudocoreset and the posterior conditioning on the full\ndataset. However, evaluating the divergence can be challenging, particularly\nfor the models like deep neural networks having high-dimensional parameters. In\nthis paper, we propose a novel Bayesian pseudocoreset construction method that\noperates on a function space. Unlike previous methods, which construct and\nmatch the coreset and full data posteriors in the space of model parameters\n(weights), our method constructs variational approximations to the coreset\nposterior on a function space and matches it to the full data posterior in the\nfunction space. By working directly on the function space, our method could\nbypass several challenges that may arise when working on a weight space,\nincluding limited scalability and multi-modality issue. Through various\nexperiments, we demonstrate that the Bayesian pseudocoresets constructed from\nour method enjoys enhanced uncertainty quantification and better robustness\nacross various model architectures.",
            "author": [
                "Balhae Kim",
                "Hyungi Lee",
                "Juho Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17852v1",
                "http://arxiv.org/pdf/2310.17852v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17848v1",
            "title": "Boosting Data Analytics With Synthetic Volume Expansion",
            "updated": "2023-10-27T01:57:27Z",
            "published": "2023-10-27T01:57:27Z",
            "summary": "Synthetic data generation, a cornerstone of Generative Artificial\nIntelligence, signifies a paradigm shift in data science by addressing data\nscarcity and privacy while enabling unprecedented performance. As synthetic\ndata gains prominence, questions arise concerning the accuracy of statistical\nmethods when applied to synthetic data compared to raw data. In this article,\nwe introduce the Synthetic Data Generation for Analytics framework. This\nframework employs statistical methods on high-fidelity synthetic data generated\nby advanced models such as tabular diffusion and Generative Pre-trained\nTransformer models. These models, trained on raw data, are further enhanced\nwith insights from pertinent studies. A significant discovery within this\nframework is the generational effect: the error of a statistical method on\nsynthetic data initially diminishes with added synthetic data but may\neventually increase or plateau. This phenomenon, rooted in the complexities of\nreplicating raw data distributions, highlights a \"reflection point\"--an optimal\nthreshold in the size of synthetic data determined by specific error metrics.\nThrough three illustrative case studies-sentiment analysis of texts, predictive\nmodeling of structured data, and inference in tabular data--we demonstrate the\neffectiveness of this framework over traditional ones. We underline its\npotential to amplify various statistical methods, including gradient boosting\nfor prediction and hypothesis testing, thereby underscoring the transformative\npotential of synthetic data generation in data science.",
            "author": [
                "Xiaotong Shen",
                "Yifei Liu",
                "Rex Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17848v1",
                "http://arxiv.org/pdf/2310.17848v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17844v1",
            "title": "Adaptive operator learning for infinite-dimensional Bayesian inverse\n  problems",
            "updated": "2023-10-27T01:50:33Z",
            "published": "2023-10-27T01:50:33Z",
            "summary": "The fundamental computational issues in Bayesian inverse problems (BIPs)\ngoverned by partial differential equations (PDEs) stem from the requirement of\nrepeated forward model evaluations. A popular strategy to reduce such cost is\nto replace expensive model simulations by computationally efficient\napproximations using operator learning, motivated by recent progresses in deep\nlearning. However, using the approximated model directly may introduce a\nmodeling error, exacerbating the already ill-posedness of inverse problems.\nThus, balancing between accuracy and efficiency is essential for the effective\nimplementation of such approaches. To this end, we develop an adaptive operator\nlearning framework that can reduce modeling error gradually by forcing the\nsurrogate to be accurate in local areas. This is accomplished by fine-tuning\nthe pre-trained approximate model during the inversion process with adaptive\npoints selected by a greedy algorithm, which requires only a few forward model\nevaluations. To validate our approach, we adopt DeepOnet to construct the\nsurrogate and use unscented Kalman inversion (UKI) to approximate the solution\nof BIPs, respectively. Furthermore, we present rigorous convergence guarantee\nin the linear case using the framework of UKI. We test the approach on several\nbenchmarks, including the Darcy flow, the heat source inversion problem, and\nthe reaction diffusion problems. Numerical results demonstrate that our method\ncan significantly reduce computational costs while maintaining inversion\naccuracy.",
            "author": [
                "Zhiwei Gao",
                "Liang Yan",
                "Tao Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17844v1",
                "http://arxiv.org/pdf/2310.17844v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA",
                "stat.CO",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17843v1",
            "title": "A Data-Centric Online Market for Machine Learning: From Discovery to\n  Pricing",
            "updated": "2023-10-27T01:49:13Z",
            "published": "2023-10-27T01:49:13Z",
            "summary": "Data fuels machine learning (ML) - rich and high-quality training data is\nessential to the success of ML. However, to transform ML from the race among a\nfew large corporations to an accessible technology that serves numerous normal\nusers' data analysis requests, there still exist important challenges. One gap\nwe observed is that many ML users can benefit from new data that other data\nowners possess, whereas these data owners sit on piles of data without knowing\nwho can benefit from it. This gap creates the opportunity for building an\nonline market that can automatically connect supply with demand. While online\nmatching markets are prevalent (e.g., ride-hailing systems), designing a\ndata-centric market for ML exhibits many unprecedented challenges.\n  This paper develops new techniques to tackle two core challenges in designing\nsuch a market: (a) to efficiently match demand with supply, we design an\nalgorithm to automatically discover useful data for any ML task from a pool of\nthousands of datasets, achieving high-quality matching between ML models and\ndata; (b) to encourage market participation of ML users without much ML\nexpertise, we design a new pricing mechanism for selling data-augmented ML\nmodels. Furthermore, our market is designed to be API-compatible with existing\nonline ML markets like Vertex AI and Sagemaker, making it easy to use while\nproviding better results due to joint data and model search. We envision that\nthe synergy of our data and model discovery algorithm and pricing mechanism\nwill be an important step towards building a new data-centric online market\nthat serves ML users effectively.",
            "author": [
                "Minbiao Han",
                "Jonathan Light",
                "Steven Xia",
                "Sainyam Galhotra",
                "Raul Castro Fernandez",
                "Haifeng Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17843v1",
                "http://arxiv.org/pdf/2310.17843v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17836v1",
            "title": "Positional Encoding-based Resident Identification in Multi-resident\n  Smart Homes",
            "updated": "2023-10-27T01:29:41Z",
            "published": "2023-10-27T01:29:41Z",
            "summary": "We propose a novel resident identification framework to identify residents in\na multi-occupant smart environment. The proposed framework employs a feature\nextraction model based on the concepts of positional encoding. The feature\nextraction model considers the locations of homes as a graph. We design a novel\nalgorithm to build such graphs from layout maps of smart environments. The\nNode2Vec algorithm is used to transform the graph into high-dimensional node\nembeddings. A Long Short-Term Memory (LSTM) model is introduced to predict the\nidentities of residents using temporal sequences of sensor events with the node\nembeddings. Extensive experiments show that our proposed scheme effectively\nidentifies residents in a multi-occupant environment. Evaluation results on two\nreal-world datasets demonstrate that our proposed approach achieves 94.5% and\n87.9% accuracy, respectively.",
            "author": [
                "Zhiyi Song",
                "Dipankar Chaki",
                "Abdallah Lakhdari",
                "Athman Bouguettaya"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17836v1",
                "http://arxiv.org/pdf/2310.17836v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17835v1",
            "title": "One Style is All you Need to Generate a Video",
            "updated": "2023-10-27T01:17:48Z",
            "published": "2023-10-27T01:17:48Z",
            "summary": "In this paper, we propose a style-based conditional video generative model.\nWe introduce a novel temporal generator based on a set of learned sinusoidal\nbases. Our method learns dynamic representations of various actions that are\nindependent of image content and can be transferred between different actors.\nBeyond the significant enhancement of video quality compared to prevalent\nmethods, we demonstrate that the disentangled dynamic and content permit their\nindependent manipulation, as well as temporal GAN-inversion to retrieve and\ntransfer a video motion from one content or identity to another without further\npreprocessing such as landmark points.",
            "author": [
                "Sandeep Manandhar",
                "Auguste Genovesio"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17835v1",
                "http://arxiv.org/pdf/2310.17835v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18377v1",
            "title": "Large-scale Foundation Models and Generative AI for BigData Neuroscience",
            "updated": "2023-10-27T00:44:40Z",
            "published": "2023-10-27T00:44:40Z",
            "summary": "Recent advances in machine learning have made revolutionary breakthroughs in\ncomputer games, image and natural language understanding, and scientific\ndiscovery. Foundation models and large-scale language models (LLMs) have\nrecently achieved human-like intelligence thanks to BigData. With the help of\nself-supervised learning (SSL) and transfer learning, these models may\npotentially reshape the landscapes of neuroscience research and make a\nsignificant impact on the future. Here we present a mini-review on recent\nadvances in foundation models and generative AI models as well as their\napplications in neuroscience, including natural language and speech, semantic\nmemory, brain-machine interfaces (BMIs), and data augmentation. We argue that\nthis paradigm-shift framework will open new avenues for many neuroscience\nresearch directions and discuss the accompanying challenges and opportunities.",
            "author": [
                "Ran Wang",
                "Zhe Sage Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18377v1",
                "http://arxiv.org/pdf/2310.18377v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.AI",
                "cs.HC",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17829v1",
            "title": "Hybrid Optical Turbulence Models Using Machine Learning and Local\n  Measurements",
            "updated": "2023-10-27T00:41:55Z",
            "published": "2023-10-27T00:41:55Z",
            "summary": "Accurate prediction of atmospheric optical turbulence in localized\nenvironments is essential for estimating the performance of free-space optical\nsystems. Macro-meteorological models developed to predict turbulent effects in\none environment may fail when applied in new environments. However, existing\nmacro-meteorological models are expected to offer some predictive power.\nBuilding a new model from locally-measured macro-meteorology and scintillometer\nreadings can require significant time and resources, as well as a large number\nof observations. These challenges motivate the development of a\nmachine-learning informed hybrid model framework. By combining some baseline\nmacro-meteorological model with local observations, hybrid models were trained\nto improve upon the predictive power of each baseline model. Comparisons\nbetween the performance of the hybrid models, the selected baseline\nmacro-meteorological models, and machine-learning models trained only on local\nobservations highlight potential use cases for the hybrid model framework when\nlocal data is expensive to collect. Both the hybrid and data-only models were\ntrained using the Gradient Boosted Decision Tree (GBDT) architecture with a\nvariable number of in-situ meteorological observations. The hybrid and\ndata-only models were found to outperform three baseline macro-meteorological\nmodels, even for low numbers of observations, in some cases as little as one\nday. For the first baseline macro-meteorological model investigated, the hybrid\nmodel achieves an estimated 29% reduction in mean absolute error (MAE) using\nonly one days-equivalent of observation, growing to 41% after only two days,\nand 68% after 180 days-equivalent training data. The number of days-equivalent\ntraining data required is potentially indicative of the seasonal variation in\nthe local microclimate and its propagation environment.",
            "author": [
                "Christopher Jellen",
                "Charles Nelson",
                "John Burkhardt",
                "Cody Brownell"
            ],
            "link": [
                "http://dx.doi.org/10.1364/AO.487280",
                "http://arxiv.org/abs/2310.17829v1",
                "http://arxiv.org/pdf/2310.17829v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18376v1",
            "title": "SQLformer: Deep Auto-Regressive Query Graph Generation for Text-to-SQL\n  Translation",
            "updated": "2023-10-27T00:13:59Z",
            "published": "2023-10-27T00:13:59Z",
            "summary": "In recent years, there has been growing interest in text-to-SQL translation,\nwhich is the task of converting natural language questions into executable SQL\nqueries. This technology is important for its potential to democratize data\nextraction from databases. However, some of its key hurdles include domain\ngeneralisation, which is the ability to adapt to previously unseen databases,\nand alignment of natural language questions with the corresponding SQL queries.\nTo overcome these challenges, we introduce SQLformer, a novel Transformer\narchitecture specifically crafted to perform text-to-SQL translation tasks. Our\nmodel predicts SQL queries as abstract syntax trees (ASTs) in an autoregressive\nway, incorporating structural inductive bias in the encoder and decoder layers.\nThis bias, guided by database table and column selection, aids the decoder in\ngenerating SQL query ASTs represented as graphs in a Breadth-First Search\ncanonical order. Comprehensive experiments illustrate the state-of-the-art\nperformance of SQLformer in the challenging text-to-SQL Spider benchmark. Our\nimplementation is available at https://github.com/AdrianBZG/SQLformer",
            "author": [
                "Adri\u00e1n Bazaga",
                "Pietro Li\u00f2",
                "Gos Micklem"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18376v1",
                "http://arxiv.org/pdf/2310.18376v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17820v1",
            "title": "Sparse Bayesian Multidimensional Item Response Theory",
            "updated": "2023-10-26T23:50:50Z",
            "published": "2023-10-26T23:50:50Z",
            "summary": "Multivariate Item Response Theory (MIRT) is sought-after widely by applied\nresearchers looking for interpretable (sparse) explanations underlying response\npatterns in questionnaire data. There is, however, an unmet demand for such\nsparsity discovery tools in practice. Our paper develops a Bayesian platform\nfor binary and ordinal item MIRT which requires minimal tuning and scales well\non relatively large datasets due to its parallelizable features. Bayesian\nmethodology for MIRT models has traditionally relied on MCMC simulation, which\ncannot only be slow in practice, but also often renders exact sparsity recovery\nimpossible without additional thresholding. In this work, we develop a scalable\nBayesian EM algorithm to estimate sparse factor loadings from binary and\nordinal item responses. We address the seemingly insurmountable problem of\nunknown latent factor dimensionality with tools from Bayesian nonparametrics\nwhich enable estimating the number of factors. Rotations to sparsity through\nparameter expansion further enhance convergence and interpretability without\nidentifiability constraints. In our simulation study, we show that our method\nreliably recovers both the factor dimensionality as well as the latent\nstructure on high-dimensional synthetic data even for small samples. We\ndemonstrate the practical usefulness of our approach on two datasets: an\neducational item response dataset and a quality-of-life measurement dataset.\nBoth demonstrations show that our tool yields interpretable estimates,\nfacilitating interesting discoveries that might otherwise go unnoticed under a\npure confirmatory factor analysis setting. We provide an easy-to-use software\nwhich is a useful new addition to the MIRT toolkit and which will hopefully\nserve as the go-to method for practitioners.",
            "author": [
                "Jiguang Li",
                "Robert Gibbons",
                "Veronika Rockova"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17820v1",
                "http://arxiv.org/pdf/2310.17820v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17813v1",
            "title": "A Spectral Condition for Feature Learning",
            "updated": "2023-10-26T23:17:39Z",
            "published": "2023-10-26T23:17:39Z",
            "summary": "The push to train ever larger neural networks has motivated the study of\ninitialization and training at large network width. A key challenge is to scale\ntraining so that a network's internal representations evolve nontrivially at\nall widths, a process known as feature learning. Here, we show that feature\nlearning is achieved by scaling the spectral norm of weight matrices and their\nupdates like $\\sqrt{\\texttt{fan-out}/\\texttt{fan-in}}$, in contrast to widely\nused but heuristic scalings based on Frobenius norm and entry size. Our\nspectral scaling analysis also leads to an elementary derivation of\n\\emph{maximal update parametrization}. All in all, we aim to provide the reader\nwith a solid conceptual understanding of feature learning in neural networks.",
            "author": [
                "Greg Yang",
                "James B. Simon",
                "Jeremy Bernstein"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17813v1",
                "http://arxiv.org/pdf/2310.17813v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17807v1",
            "title": "Clover: Closed-Loop Verifiable Code Generation",
            "updated": "2023-10-26T22:58:19Z",
            "published": "2023-10-26T22:58:19Z",
            "summary": "The use of large language models for code generation is a rapidly growing\ntrend in software development. However, without effective methods for ensuring\nthe correctness of generated code, this trend could lead to any number of\nundesirable outcomes. In this paper, we lay out a vision for addressing this\nchallenge: the Clover paradigm, short for Closed-Loop Verifiable Code\nGeneration, which reduces correctness checking to the more accessible problem\nof consistency checking. At the core of Clover lies a checker that performs\nconsistency checks among code, docstrings, and formal annotations. The checker\nis implemented using a novel integration of formal verification tools and large\nlanguage models. We provide a theoretical analysis to support our thesis that\nClover should be effective at consistency checking. We also empirically\ninvestigate its feasibility on a hand-designed dataset (CloverBench) featuring\nannotated Dafny programs at a textbook level of difficulty. Experimental\nresults show that for this dataset, (i) LLMs are reasonably successful at\nautomatically generating formal specifications; and (ii) our consistency\nchecker achieves a promising acceptance rate (up to 87%) for correct instances\nwhile maintaining zero tolerance for incorrect ones (no false positives).",
            "author": [
                "Chuyue Sun",
                "Ying Sheng",
                "Oded Padon",
                "Clark Barrett"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17807v1",
                "http://arxiv.org/pdf/2310.17807v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17805v1",
            "title": "Reward Scale Robustness for Proximal Policy Optimization via DreamerV3\n  Tricks",
            "updated": "2023-10-26T22:40:30Z",
            "published": "2023-10-26T22:40:30Z",
            "summary": "Most reinforcement learning methods rely heavily on dense, well-normalized\nenvironment rewards. DreamerV3 recently introduced a model-based method with a\nnumber of tricks that mitigate these limitations, achieving state-of-the-art on\na wide range of benchmarks with a single set of hyperparameters. This result\nsparked discussion about the generality of the tricks, since they appear to be\napplicable to other reinforcement learning algorithms. Our work applies\nDreamerV3's tricks to PPO and is the first such empirical study outside of the\noriginal work. Surprisingly, we find that the tricks presented do not transfer\nas general improvements to PPO. We use a high quality PPO reference\nimplementation and present extensive ablation studies totaling over 10,000 A100\nhours on the Arcade Learning Environment and the DeepMind Control Suite. Though\nour experiments demonstrate that these tricks do not generally outperform PPO,\nwe identify cases where they succeed and offer insight into the relationship\nbetween the implementation tricks. In particular, PPO with these tricks\nperforms comparably to PPO on Atari games with reward clipping and\nsignificantly outperforms PPO without reward clipping.",
            "author": [
                "Ryan Sullivan",
                "Akarsh Kumar",
                "Shengyi Huang",
                "John P. Dickerson",
                "Joseph Suarez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17805v1",
                "http://arxiv.org/pdf/2310.17805v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17804v1",
            "title": "BlackJack: Secure machine learning on IoT devices through hardware-based\n  shuffling",
            "updated": "2023-10-26T22:37:52Z",
            "published": "2023-10-26T22:37:52Z",
            "summary": "Neural networks are seeing increased use in diverse Internet of Things (IoT)\napplications such as healthcare, smart homes and industrial monitoring. Their\nwidespread use makes neural networks a lucrative target for theft. An attacker\ncan obtain a model without having access to the training data or incurring the\ncost of training. Also, networks trained using private data (e.g., medical\nrecords) can reveal information about this data. Networks can be stolen by\nleveraging side channels such as power traces of the IoT device when it is\nrunning the network. Existing attacks require operations to occur in the same\norder each time; an attacker must collect and analyze several traces of the\ndevice to steal the network. Therefore, to prevent this type of attack, we\nrandomly shuffle the order of operations each time. With shuffling, each\noperation can now happen at many different points in each execution, making the\nattack intractable. However, we show that shuffling in software can leak\ninformation which can be used to subvert this solution. Therefore, to perform\nsecure shuffling and reduce latency, we present BlackJack, hardware added as a\nfunctional unit within the CPU. BlackJack secures neural networks on IoT\ndevices by increasing the time needed for an attack to centuries, while adding\njust 2.46% area, 3.28% power and 0.56% latency overhead on an ARM M0+ SoC.",
            "author": [
                "Karthik Ganesan",
                "Michal Fishkin",
                "Ourong Lin",
                "Natalie Enright Jerger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17804v1",
                "http://arxiv.org/pdf/2310.17804v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AR",
                "C.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03373v1",
            "title": "Unscrambling the Rectification of Adversarial Attacks Transferability\n  across Computer Networks",
            "updated": "2023-10-26T22:36:24Z",
            "published": "2023-10-26T22:36:24Z",
            "summary": "Convolutional neural networks (CNNs) models play a vital role in achieving\nstate-of-the-art performances in various technological fields. CNNs are not\nlimited to Natural Language Processing (NLP) or Computer Vision (CV) but also\nhave substantial applications in other technological domains, particularly in\ncybersecurity. The reliability of CNN's models can be compromised because of\ntheir susceptibility to adversarial attacks, which can be generated\neffortlessly, easily applied, and transferred in real-world scenarios.\n  In this paper, we present a novel and comprehensive method to improve the\nstrength of attacks and assess the transferability of adversarial examples in\nCNNs when such strength changes, as well as whether the transferability\nproperty issue exists in computer network applications. In the context of our\nstudy, we initially examined six distinct modes of attack: the Carlini and\nWagner (C&W), Fast Gradient Sign Method (FGSM), Iterative Fast Gradient Sign\nMethod (I-FGSM), Jacobian-based Saliency Map (JSMA), Limited-memory Broyden\nfletcher Goldfarb Shanno (L-BFGS), and Projected Gradient Descent (PGD) attack.\nWe applied these attack techniques on two popular datasets: the CIC and UNSW\ndatasets. The outcomes of our experiment demonstrate that an improvement in\ntransferability occurs in the targeted scenarios for FGSM, JSMA, LBFGS, and\nother attacks. Our findings further indicate that the threats to security posed\nby adversarial examples, even in computer network applications, necessitate the\ndevelopment of novel defense mechanisms to enhance the security of DL-based\ntechniques.",
            "author": [
                "Ehsan Nowroozi",
                "Samaneh Ghelichkhani",
                "Imran Haider",
                "Ali Dehghantanha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03373v1",
                "http://arxiv.org/pdf/2311.03373v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17801v1",
            "title": "Image Prior and Posterior Conditional Probability Representation for\n  Efficient Damage Assessment",
            "updated": "2023-10-26T22:17:37Z",
            "published": "2023-10-26T22:17:37Z",
            "summary": "It is important to quantify Damage Assessment (DA) for Human Assistance and\nDisaster Response (HADR) applications. In this paper, to achieve efficient and\nscalable DA in HADR, an image prior and posterior conditional probability\n(IP2CP) is developed as an effective computational imaging representation.\nEquipped with the IP2CP representation, the matching pre- and post-disaster\nimages are effectively encoded into one image that is then processed using deep\nlearning approaches to determine the damage levels. Two scenarios of crucial\nimportance for the practical use of DA in HADR applications are examined:\npixel-wise semantic segmentation and patch-based contrastive learning-based\nglobal damage classification. Results achieved by IP2CP in both scenarios\ndemonstrate promising performances, showing that our IP2CP-based methods within\nthe deep learning framework can effectively achieve data and computational\nefficiency, which is of utmost importance for the DA in HADR applications.",
            "author": [
                "Jie Wei",
                "Weicong Feng",
                "Erik Blasch",
                "Erika Ardiles-Cruz",
                "Haibin Ling"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17801v1",
                "http://arxiv.org/pdf/2310.17801v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "I.4.6, I.5.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17800v1",
            "title": "Interacting Diffusion Processes for Event Sequence Forecasting",
            "updated": "2023-10-26T22:17:25Z",
            "published": "2023-10-26T22:17:25Z",
            "summary": "Neural Temporal Point Processes (TPPs) have emerged as the primary framework\nfor predicting sequences of events that occur at irregular time intervals, but\ntheir sequential nature can hamper performance for long-horizon forecasts. To\naddress this, we introduce a novel approach that incorporates a diffusion\ngenerative model. The model facilitates sequence-to-sequence prediction,\nallowing multi-step predictions based on historical event sequences. In\ncontrast to previous approaches, our model directly learns the joint\nprobability distribution of types and inter-arrival times for multiple events.\nThis allows us to fully leverage the high dimensional modeling capability of\nmodern generative models. Our model is composed of two diffusion processes, one\nfor the time intervals and one for the event types. These processes interact\nthrough their respective denoising functions, which can take as input\nintermediate representations from both processes, allowing the model to learn\ncomplex interactions. We demonstrate that our proposal outperforms\nstate-of-the-art baselines for long-horizon forecasting of TPP.",
            "author": [
                "Mai Zeng",
                "Florence Regol",
                "Mark Coates"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17800v1",
                "http://arxiv.org/pdf/2310.17800v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17797v1",
            "title": "Neuromorphic Online Clustering and Classification",
            "updated": "2023-10-26T21:59:19Z",
            "published": "2023-10-26T21:59:19Z",
            "summary": "The bottom two layers of a neuromorphic architecture are designed and shown\nto be capable of online clustering and supervised classification. An active\nspiking dendrite model is used, and a single dendritic segment performs\nessentially the same function as a classic integrate-and-fire point neuron. A\nsingle dendrite is then composed of multiple segments and is capable of online\nclustering. Although this work focuses primarily on dendrite functionality, a\nmulti-point neuron can be formed by combining multiple dendrites. To\ndemonstrate its clustering capability, a dendrite is applied to spike sorting,\nan important component of brain-computer interface applications. Supervised\nonline classification is implemented as a network composed of multiple\ndendrites and a simple voting mechanism. The dendrites operate independently\nand in parallel. The network learns in an online fashion and can adapt to\nmacro-level changes in the input stream. Achieving brain-like capabilities,\nefficiencies, and adaptability will require a significantly different approach\nthan conventional deep networks that learn via compute-intensive back\npropagation. The model described herein may serve as the foundation for such an\napproach.",
            "author": [
                "J. E. Smith"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17797v1",
                "http://arxiv.org/pdf/2310.17797v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "68T07"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17790v1",
            "title": "Neural Stress Fields for Reduced-order Elastoplasticity and Fracture",
            "updated": "2023-10-26T21:37:32Z",
            "published": "2023-10-26T21:37:32Z",
            "summary": "We propose a hybrid neural network and physics framework for reduced-order\nmodeling of elastoplasticity and fracture. State-of-the-art scientific\ncomputing models like the Material Point Method (MPM) faithfully simulate\nlarge-deformation elastoplasticity and fracture mechanics. However, their long\nruntime and large memory consumption render them unsuitable for applications\nconstrained by computation time and memory usage, e.g., virtual reality. To\novercome these barriers, we propose a reduced-order framework. Our key\ninnovation is training a low-dimensional manifold for the Kirchhoff stress\nfield via an implicit neural representation. This low-dimensional neural stress\nfield (NSF) enables efficient evaluations of stress values and,\ncorrespondingly, internal forces at arbitrary spatial locations. In addition,\nwe also train neural deformation and affine fields to build low-dimensional\nmanifolds for the deformation and affine momentum fields. These neural stress,\ndeformation, and affine fields share the same low-dimensional latent space,\nwhich uniquely embeds the high-dimensional simulation state. After training, we\nrun new simulations by evolving in this single latent space, which drastically\nreduces the computation time and memory consumption. Our general\ncontinuum-mechanics-based reduced-order framework is applicable to any\nphenomena governed by the elastodynamics equation. To showcase the versatility\nof our framework, we simulate a wide range of material behaviors, including\nelastica, sand, metal, non-Newtonian fluids, fracture, contact, and collision.\nWe demonstrate dimension reduction by up to 100,000X and time savings by up to\n10X.",
            "author": [
                "Zeshun Zong",
                "Xuan Li",
                "Minchen Li",
                "Maurizio M. Chiaramonte",
                "Wojciech Matusik",
                "Eitan Grinspun",
                "Kevin Carlberg",
                "Chenfanfu Jiang",
                "Peter Yichen Chen"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3610548.3618207",
                "http://arxiv.org/abs/2310.17790v1",
                "http://arxiv.org/pdf/2310.17790v1"
            ],
            "primary_category": "cs.GR",
            "category": [
                "cs.GR",
                "cs.CE",
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17786v1",
            "title": "Understanding when Dynamics-Invariant Data Augmentations Benefit\n  Model-Free Reinforcement Learning Updates",
            "updated": "2023-10-26T21:28:50Z",
            "published": "2023-10-26T21:28:50Z",
            "summary": "Recently, data augmentation (DA) has emerged as a method for leveraging\ndomain knowledge to inexpensively generate additional data in reinforcement\nlearning (RL) tasks, often yielding substantial improvements in data\nefficiency. While prior work has demonstrated the utility of incorporating\naugmented data directly into model-free RL updates, it is not well-understood\nwhen a particular DA strategy will improve data efficiency. In this paper, we\nseek to identify general aspects of DA responsible for observed learning\nimprovements. Our study focuses on sparse-reward tasks with dynamics-invariant\ndata augmentation functions, serving as an initial step towards a more general\nunderstanding of DA and its integration into RL training. Experimentally, we\nisolate three relevant aspects of DA: state-action coverage, reward density,\nand the number of augmented transitions generated per update (the augmented\nreplay ratio). From our experiments, we draw two conclusions: (1) increasing\nstate-action coverage often has a much greater impact on data efficiency than\nincreasing reward density, and (2) decreasing the augmented replay ratio\nsubstantially improves data efficiency. In fact, certain tasks in our empirical\nstudy are solvable only when the replay ratio is sufficiently low.",
            "author": [
                "Nicholas E. Corrado",
                "Josiah P. Hanna"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17786v1",
                "http://arxiv.org/pdf/2310.17786v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17785v2",
            "title": "Learning Extrinsic Dexterity with Parameterized Manipulation Primitives",
            "updated": "2023-11-02T20:32:09Z",
            "published": "2023-10-26T21:28:23Z",
            "summary": "Many practically relevant robot grasping problems feature a target object for\nwhich all grasps are occluded, e.g., by the environment. Single-shot grasp\nplanning invariably fails in such scenarios. Instead, it is necessary to first\nmanipulate the object into a configuration that affords a grasp. We solve this\nproblem by learning a sequence of actions that utilize the environment to\nchange the object's pose. Concretely, we employ hierarchical reinforcement\nlearning to combine a sequence of learned parameterized manipulation\nprimitives. By learning the low-level manipulation policies, our approach can\ncontrol the object's state through exploiting interactions between the object,\nthe gripper, and the environment. Designing such a complex behavior\nanalytically would be infeasible under uncontrolled conditions, as an analytic\napproach requires accurate physical modeling of the interaction and contact\ndynamics. In contrast, we learn a hierarchical policy model that operates\ndirectly on depth perception data, without the need for object detection, pose\nestimation, or manual design of controllers. We evaluate our approach on\npicking box-shaped objects of various weight, shape, and friction properties\nfrom a constrained table-top workspace. Our method transfers to a real robot\nand is able to successfully complete the object picking task in 98\\% of\nexperimental trials.",
            "author": [
                "Shih-Min Yang",
                "Martin Magnusson",
                "Johannes A. Stork",
                "Todor Stoyanov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17785v2",
                "http://arxiv.org/pdf/2310.17785v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17780v1",
            "title": "AutoCT: Automated CT registration, segmentation, and quantification",
            "updated": "2023-10-26T21:09:47Z",
            "published": "2023-10-26T21:09:47Z",
            "summary": "The processing and analysis of computed tomography (CT) imaging is important\nfor both basic scientific development and clinical applications. In AutoCT, we\nprovide a comprehensive pipeline that integrates an end-to-end automatic\npreprocessing, registration, segmentation, and quantitative analysis of 3D CT\nscans. The engineered pipeline enables atlas-based CT segmentation and\nquantification leveraging diffeomorphic transformations through efficient\nforward and inverse mappings. The extracted localized features from the\ndeformation field allow for downstream statistical learning that may facilitate\nmedical diagnostics. On a lightweight and portable software platform, AutoCT\nprovides a new toolkit for the CT imaging community to underpin the deployment\nof artificial intelligence-driven applications.",
            "author": [
                "Zhe Bai",
                "Abdelilah Essiari",
                "Talita Perciano",
                "Kristofer E. Bouchard"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17780v1",
                "http://arxiv.org/pdf/2310.17780v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17773v1",
            "title": "Graph Convolutional Networks for Complex Traffic Scenario Classification",
            "updated": "2023-10-26T20:51:24Z",
            "published": "2023-10-26T20:51:24Z",
            "summary": "A scenario-based testing approach can reduce the time required to obtain\nstatistically significant evidence of the safety of Automated Driving Systems\n(ADS). Identifying these scenarios in an automated manner is a challenging\ntask. Most methods on scenario classification do not work for complex scenarios\nwith diverse environments (highways, urban) and interaction with other traffic\nagents. This is mirrored in their approaches which model an individual vehicle\nin relation to its environment, but neglect the interaction between multiple\nvehicles (e.g. cut-ins, stationary lead vehicle). Furthermore, existing\ndatasets lack diversity and do not have per-frame annotations to accurately\nlearn the start and end time of a scenario. We propose a method for complex\ntraffic scenario classification that is able to model the interaction of a\nvehicle with the environment, as well as other agents. We use Graph\nConvolutional Networks to model spatial and temporal aspects of these\nscenarios. Expanding the nuScenes and Argoverse 2 driving datasets, we\nintroduce a scenario-labeled dataset, which covers different driving\nenvironments and is annotated per frame. Training our method on this dataset,\nwe present a promising baseline for future research on per-frame complex\nscenario classification.",
            "author": [
                "Tobias Hoek",
                "Holger Caesar",
                "Andreas Falkov\u00e9n",
                "Tommy Johansson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17773v1",
                "http://arxiv.org/pdf/2310.17773v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.MA",
                "I.2; I.4; I.5"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17772v1",
            "title": "Learning Optimal Classification Trees Robust to Distribution Shifts",
            "updated": "2023-10-26T20:37:29Z",
            "published": "2023-10-26T20:37:29Z",
            "summary": "We consider the problem of learning classification trees that are robust to\ndistribution shifts between training and testing/deployment data. This problem\narises frequently in high stakes settings such as public health and social work\nwhere data is often collected using self-reported surveys which are highly\nsensitive to e.g., the framing of the questions, the time when and place where\nthe survey is conducted, and the level of comfort the interviewee has in\nsharing information with the interviewer. We propose a method for learning\noptimal robust classification trees based on mixed-integer robust optimization\ntechnology. In particular, we demonstrate that the problem of learning an\noptimal robust tree can be cast as a single-stage mixed-integer robust\noptimization problem with a highly nonlinear and discontinuous objective. We\nreformulate this problem equivalently as a two-stage linear robust optimization\nproblem for which we devise a tailored solution procedure based on constraint\ngeneration. We evaluate the performance of our approach on numerous publicly\navailable datasets, and compare the performance to a regularized, non-robust\noptimal tree. We show an increase of up to 12.48% in worst-case accuracy and of\nup to 4.85% in average-case accuracy across several datasets and distribution\nshifts from using our robust solution in comparison to the non-robust one.",
            "author": [
                "Nathan Justin",
                "Sina Aghaei",
                "Andr\u00e9s G\u00f3mez",
                "Phebe Vayanos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17772v1",
                "http://arxiv.org/pdf/2310.17772v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17770v1",
            "title": "GROOViST: A Metric for Grounding Objects in Visual Storytelling",
            "updated": "2023-10-26T20:27:16Z",
            "published": "2023-10-26T20:27:16Z",
            "summary": "A proper evaluation of stories generated for a sequence of images -- the task\ncommonly referred to as visual storytelling -- must consider multiple aspects,\nsuch as coherence, grammatical correctness, and visual grounding. In this work,\nwe focus on evaluating the degree of grounding, that is, the extent to which a\nstory is about the entities shown in the images. We analyze current metrics,\nboth designed for this purpose and for general vision-text alignment. Given\ntheir observed shortcomings, we propose a novel evaluation tool, GROOViST, that\naccounts for cross-modal dependencies, temporal misalignments (the fact that\nthe order in which entities appear in the story and the image sequence may not\nmatch), and human intuitions on visual grounding. An additional advantage of\nGROOViST is its modular design, where the contribution of each component can be\nassessed and interpreted individually.",
            "author": [
                "Aditya K Surikuchi",
                "Sandro Pezzelle",
                "Raquel Fern\u00e1ndez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17770v1",
                "http://arxiv.org/pdf/2310.17770v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17769v2",
            "title": "Social Contract AI: Aligning AI Assistants with Implicit Group Norms",
            "updated": "2023-12-03T17:42:33Z",
            "published": "2023-10-26T20:27:03Z",
            "summary": "We explore the idea of aligning an AI assistant by inverting a model of\nusers' (unknown) preferences from observed interactions. To validate our\nproposal, we run proof-of-concept simulations in the economic ultimatum game,\nformalizing user preferences as policies that guide the actions of simulated\nplayers. We find that the AI assistant accurately aligns its behavior to match\nstandard policies from the economic literature (e.g., selfish, altruistic).\nHowever, the assistant's learned policies lack robustness and exhibit limited\ngeneralization in an out-of-distribution setting when confronted with a\ncurrency (e.g., grams of medicine) that was not included in the assistant's\ntraining distribution. Additionally, we find that when there is inconsistency\nin the relationship between language use and an unknown policy (e.g., an\naltruistic policy combined with rude language), the assistant's learning of the\npolicy is slowed. Overall, our preliminary results suggest that developing\nsimulation frameworks in which AI assistants need to infer preferences from\ndiverse users can provide a valuable approach for studying practical alignment\nquestions.",
            "author": [
                "Jan-Philipp Fr\u00e4nken",
                "Sam Kwok",
                "Peixuan Ye",
                "Kanishk Gandhi",
                "Dilip Arumugam",
                "Jared Moore",
                "Alex Tamkin",
                "Tobias Gerstenberg",
                "Noah D. Goodman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17769v2",
                "http://arxiv.org/pdf/2310.17769v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17765v1",
            "title": "Autonomous convergence of STM control parameters using Bayesian\n  Optimization",
            "updated": "2023-10-26T20:15:48Z",
            "published": "2023-10-26T20:15:48Z",
            "summary": "Scanning Tunneling microscopy (STM) is a widely used tool for atomic imaging\nof novel materials and its surface energetics. However, the optimization of the\nimaging conditions is a tedious process due to the extremely sensitive\ntip-surface interaction, and thus limits the throughput efficiency. Here we\ndeploy a machine learning (ML) based framework to achieve optimal-atomically\nresolved imaging conditions in real time. The experimental workflow leverages\nBayesian optimization (BO) method to rapidly improve the image quality, defined\nby the peak intensity in the Fourier space. The outcome of the BO prediction is\nincorporated into the microscope controls, i.e., the current setpoint and the\ntip bias, to dynamically improve the STM scan conditions. We present strategies\nto either selectively explore or exploit across the parameter space. As a\nresult, suitable policies are developed for autonomous convergence of the\ncontrol-parameters. The ML-based framework serves as a general workflow\nmethodology across a wide range of materials.",
            "author": [
                "Ganesh Narasimha",
                "Saban Hus",
                "Arpan Biswas",
                "Rama Vasudevan",
                "Maxim Ziatdinov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17765v1",
                "http://arxiv.org/pdf/2310.17765v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph",
                "cond-mat.mtrl-sci",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17764v1",
            "title": "SynergyNet: Bridging the Gap between Discrete and Continuous\n  Representations for Precise Medical Image Segmentation",
            "updated": "2023-10-26T20:13:44Z",
            "published": "2023-10-26T20:13:44Z",
            "summary": "In recent years, continuous latent space (CLS) and discrete latent space\n(DLS) deep learning models have been proposed for medical image analysis for\nimproved performance. However, these models encounter distinct challenges. CLS\nmodels capture intricate details but often lack interpretability in terms of\nstructural representation and robustness due to their emphasis on low-level\nfeatures. Conversely, DLS models offer interpretability, robustness, and the\nability to capture coarse-grained information thanks to their structured latent\nspace. However, DLS models have limited efficacy in capturing fine-grained\ndetails. To address the limitations of both DLS and CLS models, we propose\nSynergyNet, a novel bottleneck architecture designed to enhance existing\nencoder-decoder segmentation frameworks. SynergyNet seamlessly integrates\ndiscrete and continuous representations to harness complementary information\nand successfully preserves both fine and coarse-grained details in the learned\nrepresentations. Our extensive experiment on multi-organ segmentation and\ncardiac datasets demonstrates that SynergyNet outperforms other state of the\nart methods, including TransUNet: dice scores improving by 2.16%, and Hausdorff\nscores improving by 11.13%, respectively. When evaluating skin lesion and brain\ntumor segmentation datasets, we observe a remarkable improvement of 1.71% in\nIntersection-over Union scores for skin lesion segmentation and of 8.58% for\nbrain tumor segmentation. Our innovative approach paves the way for enhancing\nthe overall performance and capabilities of deep learning models in the\ncritical domain of medical image analysis.",
            "author": [
                "Vandan Gorade",
                "Sparsh Mittal",
                "Debesh Jha",
                "Ulas Bagci"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17764v1",
                "http://arxiv.org/pdf/2310.17764v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17761v1",
            "title": "Distributed Personalized Empirical Risk Minimization",
            "updated": "2023-10-26T20:07:33Z",
            "published": "2023-10-26T20:07:33Z",
            "summary": "This paper advocates a new paradigm Personalized Empirical Risk Minimization\n(PERM) to facilitate learning from heterogeneous data sources without imposing\nstringent constraints on computational resources shared by participating\ndevices. In PERM, we aim to learn a distinct model for each client by learning\nwho to learn with and personalizing the aggregation of local empirical losses\nby effectively estimating the statistical discrepancy among data distributions,\nwhich entails optimal statistical accuracy for all local distributions and\novercomes the data heterogeneity issue. To learn personalized models at scale,\nwe propose a distributed algorithm that replaces the standard model averaging\nwith model shuffling to simultaneously optimize PERM objectives for all\ndevices. This also allows us to learn distinct model architectures (e.g.,\nneural networks with different numbers of parameters) for different clients,\nthus confining underlying memory and compute resources of individual clients.\nWe rigorously analyze the convergence of the proposed algorithm and conduct\nexperiments that corroborate the effectiveness of the proposed paradigm.",
            "author": [
                "Yuyang Deng",
                "Mohammad Mahdi Kamani",
                "Pouria Mahdavinia",
                "Mehrdad Mahdavi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17761v1",
                "http://arxiv.org/pdf/2310.17761v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17759v1",
            "title": "Optimal Guarantees for Algorithmic Reproducibility and Gradient\n  Complexity in Convex Optimization",
            "updated": "2023-10-26T19:56:52Z",
            "published": "2023-10-26T19:56:52Z",
            "summary": "Algorithmic reproducibility measures the deviation in outputs of machine\nlearning algorithms upon minor changes in the training process. Previous work\nsuggests that first-order methods would need to trade-off convergence rate\n(gradient complexity) for better reproducibility. In this work, we challenge\nthis perception and demonstrate that both optimal reproducibility and\nnear-optimal convergence guarantees can be achieved for smooth convex\nminimization and smooth convex-concave minimax problems under various\nerror-prone oracle settings. Particularly, given the inexact initialization\noracle, our regularization-based algorithms achieve the best of both worlds -\noptimal reproducibility and near-optimal gradient complexity - for minimization\nand minimax optimization. With the inexact gradient oracle, the near-optimal\nguarantees also hold for minimax optimization. Additionally, with the\nstochastic gradient oracle, we show that stochastic gradient descent ascent is\noptimal in terms of both reproducibility and gradient complexity. We believe\nour results contribute to an enhanced understanding of the\nreproducibility-convergence trade-off in the context of convex optimization.",
            "author": [
                "Liang Zhang",
                "Junchi Yang",
                "Amin Karbasi",
                "Niao He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17759v1",
                "http://arxiv.org/pdf/2310.17759v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17758v2",
            "title": "Graph Neural Networks for Enhanced Decoding of Quantum LDPC Codes",
            "updated": "2023-11-06T20:44:45Z",
            "published": "2023-10-26T19:56:25Z",
            "summary": "In this work, we propose a fully differentiable iterative decoder for quantum\nlow-density parity-check (LDPC) codes. The proposed algorithm is composed of\nclassical belief propagation (BP) decoding stages and intermediate graph neural\nnetwork (GNN) layers. Both component decoders are defined over the same sparse\ndecoding graph enabling a seamless integration and scalability to large codes.\nThe core idea is to use the GNN component between consecutive BP runs, so that\nthe knowledge from the previous BP run, if stuck in a local minima caused by\ntrapping sets or short cycles in the decoding graph, can be leveraged to better\ninitialize the next BP run. By doing so, the proposed decoder can learn to\ncompensate for sub-optimal BP decoding graphs that result from the design\nconstraints of quantum LDPC codes. Since the entire decoder remains\ndifferentiable, gradient descent-based training is possible. We compare the\nerror rate performance of the proposed decoder against various post-processing\nmethods such as random perturbation, enhanced feedback, augmentation, and\nordered-statistics decoding (OSD) and show that a carefully designed training\nprocess lowers the error-floor significantly. As a result, our proposed decoder\noutperforms the former three methods using significantly fewer post-processing\nattempts. The source code of our experiments is available online.",
            "author": [
                "Anqi Gong",
                "Sebastian Cammerer",
                "Joseph M. Renes"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17758v2",
                "http://arxiv.org/pdf/2310.17758v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17755v1",
            "title": "Alzheimers Disease Diagnosis by Deep Learning Using MRI-Based Approaches",
            "updated": "2023-10-26T19:48:08Z",
            "published": "2023-10-26T19:48:08Z",
            "summary": "The most frequent kind of dementia of the nervous system, Alzheimer's\ndisease, weakens several brain processes (such as memory) and eventually\nresults in death. The clinical study uses magnetic resonance imaging to\ndiagnose AD. Deep learning algorithms are capable of pattern recognition and\nfeature extraction from the inputted raw data. As early diagnosis and stage\ndetection are the most crucial elements in enhancing patient care and treatment\noutcomes, deep learning algorithms for MRI images have recently allowed for\ndiagnosing a medical condition at the beginning stage and identifying\nparticular symptoms of Alzheimer's disease. As a result, we aimed to analyze\nfive specific studies focused on AD diagnosis using MRI-based deep learning\nalgorithms between 2021 and 2023 in this study. To completely illustrate the\ndifferences between these techniques and comprehend how deep learning\nalgorithms function, we attempted to explore selected approaches in depth.",
            "author": [
                "Sarasadat Foroughipoor",
                "Kimia Moradi",
                "Hamidreza Bolhasani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17755v1",
                "http://arxiv.org/pdf/2310.17755v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17752v1",
            "title": "PockEngine: Sparse and Efficient Fine-tuning in a Pocket",
            "updated": "2023-10-26T19:46:11Z",
            "published": "2023-10-26T19:46:11Z",
            "summary": "On-device learning and efficient fine-tuning enable continuous and\nprivacy-preserving customization (e.g., locally fine-tuning large language\nmodels on personalized data). However, existing training frameworks are\ndesigned for cloud servers with powerful accelerators (e.g., GPUs, TPUs) and\nlack the optimizations for learning on the edge, which faces challenges of\nresource limitations and edge hardware diversity. We introduce PockEngine: a\ntiny, sparse and efficient engine to enable fine-tuning on various edge\ndevices. PockEngine supports sparse backpropagation: it prunes the backward\ngraph and sparsely updates the model with measured memory saving and latency\nreduction while maintaining the model quality. Secondly, PockEngine is\ncompilation first: the entire training graph (including forward, backward and\noptimization steps) is derived at compile-time, which reduces the runtime\noverhead and brings opportunities for graph transformations. PockEngine also\nintegrates a rich set of training graph optimizations, thus can further\naccelerate the training cost, including operator reordering and backend\nswitching. PockEngine supports diverse applications, frontends and hardware\nbackends: it flexibly compiles and tunes models defined in\nPyTorch/TensorFlow/Jax and deploys binaries to mobile CPU/GPU/DSPs. We\nevaluated PockEngine on both vision models and large language models.\nPockEngine achieves up to 15 $\\times$ speedup over off-the-shelf TensorFlow\n(Raspberry Pi), 5.6 $\\times$ memory saving back-propagation (Jetson AGX Orin).\nRemarkably, PockEngine enables fine-tuning LLaMav2-7B on NVIDIA Jetson AGX Orin\nat 550 tokens/s, 7.9$\\times$ faster than the PyTorch.",
            "author": [
                "Ligeng Zhu",
                "Lanxiang Hu",
                "Ji Lin",
                "Wei-Chen Wang",
                "Wei-Ming Chen",
                "Chuang Gan",
                "Song Han"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3613424.3614307",
                "http://arxiv.org/abs/2310.17752v1",
                "http://arxiv.org/pdf/2310.17752v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17748v1",
            "title": "Making the End-User a Priority in Benchmarking: OrionBench for\n  Unsupervised Time Series Anomaly Detection",
            "updated": "2023-10-26T19:43:16Z",
            "published": "2023-10-26T19:43:16Z",
            "summary": "Time series anomaly detection is a prevalent problem in many application\ndomains such as patient monitoring in healthcare, forecasting in finance, or\npredictive maintenance in energy. This has led to the emergence of a plethora\nof anomaly detection methods, including more recently, deep learning based\nmethods. Although several benchmarks have been proposed to compare newly\ndeveloped models, they usually rely on one-time execution over a limited set of\ndatasets and the comparison is restricted to a few models. We propose\nOrionBench -- a user centric continuously maintained benchmark for unsupervised\ntime series anomaly detection. The framework provides universal abstractions to\nrepresent models, extensibility to add new pipelines and datasets,\nhyperparameter standardization, pipeline verification, and frequent releases\nwith published benchmarks. We demonstrate the usage of OrionBench, and the\nprogression of pipelines across 15 releases published over the course of three\nyears. Moreover, we walk through two real scenarios we experienced with\nOrionBench that highlight the importance of continuous benchmarks in\nunsupervised time series anomaly detection.",
            "author": [
                "Sarah Alnegheimish",
                "Laure Berti-Equille",
                "Kalyan Veeramachaneni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17748v1",
                "http://arxiv.org/pdf/2310.17748v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17743v2",
            "title": "StyleBART: Decorate Pretrained Model with Style Adapters for\n  Unsupervised Stylistic Headline Generation",
            "updated": "2023-11-13T06:38:53Z",
            "published": "2023-10-26T19:31:22Z",
            "summary": "Stylistic headline generation is the task to generate a headline that not\nonly summarizes the content of an article, but also reflects a desired style\nthat attracts users. As style-specific article-headline pairs are scarce,\nprevious researches focus on unsupervised approaches with a standard headline\ngeneration dataset and mono-style corpora. In this work, we follow this line\nand propose StyleBART, an unsupervised approach for stylistic headline\ngeneration. Our method decorates the pretrained BART model with adapters that\nare responsible for different styles and allows the generation of headlines\nwith diverse styles by simply switching the adapters. Different from previous\nworks, StyleBART separates the task of style learning and headline generation,\nmaking it possible to freely combine the base model and the style adapters\nduring inference. We further propose an inverse paraphrasing task to enhance\nthe style adapters. Extensive automatic and human evaluations show that\nStyleBART achieves new state-of-the-art performance in the unsupervised\nstylistic headline generation task, producing high-quality headlines with the\ndesired style.",
            "author": [
                "Hanqing Wang",
                "Yajing Luo",
                "Boya Xiong",
                "Guanhua Chen",
                "Yun Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17743v2",
                "http://arxiv.org/pdf/2310.17743v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17742v1",
            "title": "BERT-PIN: A BERT-based Framework for Recovering Missing Data Segments in\n  Time-series Load Profiles",
            "updated": "2023-10-26T19:30:31Z",
            "published": "2023-10-26T19:30:31Z",
            "summary": "Inspired by the success of the Transformer model in natural language\nprocessing and computer vision, this paper introduces BERT-PIN, a Bidirectional\nEncoder Representations from Transformers (BERT) powered Profile Inpainting\nNetwork. BERT-PIN recovers multiple missing data segments (MDSs) using load and\ntemperature time-series profiles as inputs. To adopt a standard Transformer\nmodel structure for profile inpainting, we segment the load and temperature\nprofiles into line segments, treating each segment as a word and the entire\nprofile as a sentence. We incorporate a top candidates selection process in\nBERT-PIN, enabling it to produce a sequence of probability distributions, based\non which users can generate multiple plausible imputed data sets, each\nreflecting different confidence levels. We develop and evaluate BERT-PIN using\nreal-world dataset for two applications: multiple MDSs recovery and demand\nresponse baseline estimation. Simulation results show that BERT-PIN outperforms\nthe existing methods in accuracy while is capable of restoring multiple MDSs\nwithin a longer window. BERT-PIN, served as a pre-trained model, can be\nfine-tuned for conducting many downstream tasks, such as classification and\nsuper resolution.",
            "author": [
                "Yi Hu",
                "Kai Ye",
                "Hyeonjin Kim",
                "Ning Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17742v1",
                "http://arxiv.org/pdf/2310.17742v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17741v1",
            "title": "Probing Light Fermiophobic Higgs Boson via diphoton jets at the HL-LHC",
            "updated": "2023-10-26T19:27:53Z",
            "published": "2023-10-26T19:27:53Z",
            "summary": "In this study, we explore the phenomenological signatures associated with a\nlight fermiophobic Higgs boson, $h_{\\rm f}$, within the type-I\ntwo-Higgs-doublet model at the HL-LHC. Our meticulous parameter scan\nilluminates an intriguing mass range for $m_{h_{\\rm f}}$, spanning\n$[1,10]{\\;{\\rm GeV}}$. This mass range owes its viability to substantial\nparameter points, largely due to the inherent challenges of detecting the soft\ndecay products of $h_{\\rm f}$ at contemporary high-energy colliders. Given that\nthis light $h_{\\rm f}$ ensures $Br(h_{\\rm f}\\to\\gamma\\gamma)\\simeq 1$,\n$Br(H^\\pm \\to h_{\\rm f} W^\\pm)\\simeq 1$, and $M_{H^\\pm}\\lesssim 330{\\;{\\rm\nGeV}}$, we propose a golden discovery channel: $pp\\to h_{\\rm f}H^\\pm\\to\n\\gamma\\gamma\\gamma\\gamma \\,l^\\pm\\nu$, where $l^\\pm$ includes $e^\\pm$ and\n$\\mu^\\pm$. However, a significant obstacle arises as the two photons from the\n$h_{\\rm f}$ decay mostly merge into a single jet due to their proximity within\n$\\Delta R<0.4$. This results in a final state characterized by two jets, rather\nthan four isolated photons, thus intensifying the QCD backgrounds. To tackle\nthis, we devise a strategy within \\textsc{Delphes} to identify jets with two\nleading subparticles as photons, termed diphoton jets. Our thorough\ndetector-level simulations across 18 benchmark points predominantly show signal\nsignificances exceeding the $5\\sigma$ threshold at an integrated luminosity of\n$3{\\;{\\rm ab}^{-1}}$. Furthermore, our approach facilitates accurate mass\nreconstructions for both $m_{h_{\\rm f}}$ and $M_{H^\\pm}$. Notably, in the\nintricate scenarios with heavy charged Higgs bosons, our application of machine\nlearning techniques provides a significant boost in significance.",
            "author": [
                "Daohan Wang",
                "Jin-Hwan Cho",
                "Jinheung Kim",
                "Soojin Lee",
                "Prasenjit Sanyal",
                "Jeonghyeon Song"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17741v1",
                "http://arxiv.org/pdf/2310.17741v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17737v1",
            "title": "ArchBERT: Bi-Modal Understanding of Neural Architectures and Natural\n  Languages",
            "updated": "2023-10-26T18:58:52Z",
            "published": "2023-10-26T18:58:52Z",
            "summary": "Building multi-modal language models has been a trend in the recent years,\nwhere additional modalities such as image, video, speech, etc. are jointly\nlearned along with natural languages (i.e., textual information). Despite the\nsuccess of these multi-modal language models with different modalities, there\nis no existing solution for neural network architectures and natural languages.\nProviding neural architectural information as a new modality allows us to\nprovide fast architecture-2-text and text-2-architecture retrieval/generation\nservices on the cloud with a single inference. Such solution is valuable in\nterms of helping beginner and intermediate ML users to come up with better\nneural architectures or AutoML approaches with a simple text query. In this\npaper, we propose ArchBERT, a bi-modal model for joint learning and\nunderstanding of neural architectures and natural languages, which opens up new\navenues for research in this area. We also introduce a pre-training strategy\nnamed Masked Architecture Modeling (MAM) for a more generalized joint learning.\nMoreover, we introduce and publicly release two new bi-modal datasets for\ntraining and validating our methods. The ArchBERT's performance is verified\nthrough a set of numerical experiments on different downstream tasks such as\narchitecture-oriented reasoning, question answering, and captioning\n(summarization). Datasets, codes, and demos are available supplementary\nmaterials.",
            "author": [
                "Mohammad Akbari",
                "Saeed Ranjbar Alvar",
                "Behnam Kamranian",
                "Amin Banitalebi-Dehkordi",
                "Yong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17737v1",
                "http://arxiv.org/pdf/2310.17737v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17732v1",
            "title": "GNN-GMVO: Graph Neural Networks for Optimizing Gross Merchandise Value\n  in Similar Item Recommendation",
            "updated": "2023-10-26T18:43:16Z",
            "published": "2023-10-26T18:43:16Z",
            "summary": "Similar item recommendation is a critical task in the e-Commerce industry,\nwhich helps customers explore similar and relevant alternatives based on their\ninterested products. Despite the traditional machine learning models, Graph\nNeural Networks (GNNs), by design, can understand complex relations like\nsimilarity between products. However, in contrast to their wide usage in\nretrieval tasks and their focus on optimizing the relevance, the current GNN\narchitectures are not tailored toward maximizing revenue-related objectives\nsuch as Gross Merchandise Value (GMV), which is one of the major business\nmetrics for e-Commerce companies. In addition, defining accurate edge relations\nin GNNs is non-trivial in large-scale e-Commerce systems, due to the\nheterogeneity nature of the item-item relationships. This work aims to address\nthese issues by designing a new GNN architecture called GNN-GMVO (Graph Neural\nNetwork - Gross Merchandise Value Optimizer). This model directly optimizes GMV\nwhile considering the complex relations between items. In addition, we propose\na customized edge construction method to tailor the model toward similar item\nrecommendation task and alleviate the noisy and complex item-item relations. In\nour comprehensive experiments on three real-world datasets, we show higher\nprediction performance and expected GMV for top ranked items recommended by our\nmodel when compared with selected state-of-the-art benchmark models.",
            "author": [
                "Ramin Giahi",
                "Reza Yousefi Maragheh",
                "Nima Farrokhsiar",
                "Jianpeng Xu",
                "Jason Cho",
                "Evren Korpeoglu",
                "Sushant Kumar",
                "Kannan Achan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17732v1",
                "http://arxiv.org/pdf/2310.17732v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17729v1",
            "title": "Improving Traffic Density Forecasting in Intelligent Transportation\n  Systems Using Gated Graph Neural Networks",
            "updated": "2023-10-26T18:40:28Z",
            "published": "2023-10-26T18:40:28Z",
            "summary": "This study delves into the application of graph neural networks in the realm\nof traffic forecasting, a crucial facet of intelligent transportation systems.\nAccurate traffic predictions are vital for functions like trip planning,\ntraffic control, and vehicle routing in such systems. Three prominent GNN\narchitectures Graph Convolutional Networks (Graph Sample and Aggregation) and\nGated Graph Neural Networks are explored within the context of traffic\nprediction. Each architecture's methodology is thoroughly examined, including\nlayer configurations, activation functions,and hyperparameters. The primary\ngoal is to minimize prediction errors, with GGNNs emerging as the most\neffective choice among the three models. The research outlines outcomes for\neach architecture, elucidating their predictive performance through root mean\nsquared error and mean absolute error (MAE). Hypothetical results reveal\nintriguing insights: GCNs display an RMSE of 9.10 and an MAE of 8.00, while\nGraphSAGE shows improvement with an RMSE of 8.3 and an MAE of 7.5. Gated Graph\nNeural Networks (GGNNs) exhibit the lowest RMSE at 9.15 and an impressive MAE\nof 7.1, positioning them as the frontrunner.",
            "author": [
                "Razib Hayat Khan",
                "Jonayet Miah",
                "S M Yasir Arafat",
                "M M Mahbubul Syeed",
                "Duc M Ca"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17729v1",
                "http://arxiv.org/pdf/2310.17729v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17723v1",
            "title": "ZeroQuant-HERO: Hardware-Enhanced Robust Optimized Post-Training\n  Quantization Framework for W8A8 Transformers",
            "updated": "2023-10-26T18:34:41Z",
            "published": "2023-10-26T18:34:41Z",
            "summary": "Quantization techniques are pivotal in reducing the memory and computational\ndemands of deep neural network inference. Existing solutions, such as\nZeroQuant, offer dynamic quantization for models like BERT and GPT but overlook\ncrucial memory-bounded operators and the complexities of per-token\nquantization. Addressing these gaps, we present a novel, fully\nhardware-enhanced robust optimized post-training W8A8 quantization framework,\nZeroQuant-HERO. This framework uniquely integrates both memory bandwidth and\ncompute-intensive operators, aiming for optimal hardware performance.\nAdditionally, it offers flexibility by allowing specific INT8 modules to switch\nto FP16/BF16 mode, enhancing accuracy.",
            "author": [
                "Zhewei Yao",
                "Reza Yazdani Aminabadi",
                "Stephen Youn",
                "Xiaoxia Wu",
                "Elton Zheng",
                "Yuxiong He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17723v1",
                "http://arxiv.org/pdf/2310.17723v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17722v1",
            "title": "Large Language Models as Generalizable Policies for Embodied Tasks",
            "updated": "2023-10-26T18:32:05Z",
            "published": "2023-10-26T18:32:05Z",
            "summary": "We show that large language models (LLMs) can be adapted to be generalizable\npolicies for embodied visual tasks. Our approach, called Large LAnguage model\nReinforcement Learning Policy (LLaRP), adapts a pre-trained frozen LLM to take\nas input text instructions and visual egocentric observations and output\nactions directly in the environment. Using reinforcement learning, we train\nLLaRP to see and act solely through environmental interactions. We show that\nLLaRP is robust to complex paraphrasings of task instructions and can\ngeneralize to new tasks that require novel optimal behavior. In particular, on\n1,000 unseen tasks it achieves 42% success rate, 1.7x the success rate of other\ncommon learned baselines or zero-shot applications of LLMs. Finally, to aid the\ncommunity in studying language conditioned, massively multi-task, embodied AI\nproblems we release a novel benchmark, Language Rearrangement, consisting of\n150,000 training and 1,000 testing tasks for language-conditioned\nrearrangement. Video examples of LLaRP in unseen Language Rearrangement\ninstructions are at https://llm-rl.github.io.",
            "author": [
                "Andrew Szot",
                "Max Schwarzer",
                "Harsh Agrawal",
                "Bogdan Mazoure",
                "Walter Talbott",
                "Katherine Metcalf",
                "Natalie Mackraz",
                "Devon Hjelm",
                "Alexander Toshev"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17722v1",
                "http://arxiv.org/pdf/2310.17722v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17720v1",
            "title": "Advancing Brain Tumor Detection: A Thorough Investigation of CNNs,\n  Clustering, and SoftMax Classification in the Analysis of MRI Images",
            "updated": "2023-10-26T18:27:20Z",
            "published": "2023-10-26T18:27:20Z",
            "summary": "Brain tumors pose a significant global health challenge due to their high\nprevalence and mortality rates across all age groups. Detecting brain tumors at\nan early stage is crucial for effective treatment and patient outcomes. This\nstudy presents a comprehensive investigation into the use of Convolutional\nNeural Networks (CNNs) for brain tumor detection using Magnetic Resonance\nImaging (MRI) images. The dataset, consisting of MRI scans from both healthy\nindividuals and patients with brain tumors, was processed and fed into the CNN\narchitecture. The SoftMax Fully Connected layer was employed to classify the\nimages, achieving an accuracy of 98%. To evaluate the CNN's performance, two\nother classifiers, Radial Basis Function (RBF) and Decision Tree (DT), were\nutilized, yielding accuracy rates of 98.24% and 95.64%, respectively. The study\nalso introduced a clustering method for feature extraction, improving CNN's\naccuracy. Sensitivity, Specificity, and Precision were employed alongside\naccuracy to comprehensively evaluate the network's performance. Notably, the\nSoftMax classifier demonstrated the highest accuracy among the categorizers,\nachieving 99.52% accuracy on test data. The presented research contributes to\nthe growing field of deep learning in medical image analysis. The combination\nof CNNs and MRI data offers a promising tool for accurately detecting brain\ntumors, with potential implications for early diagnosis and improved patient\ncare.",
            "author": [
                "Jonayet Miah",
                "Duc M Cao",
                "Md Abu Sayed3",
                "Md Siam Taluckder",
                "Md Sabbirul Haque",
                "Fuad Mahmud"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17720v1",
                "http://arxiv.org/pdf/2310.17720v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17716v1",
            "title": "Unifying (Quantum) Statistical and Parametrized (Quantum) Algorithms",
            "updated": "2023-10-26T18:23:21Z",
            "published": "2023-10-26T18:23:21Z",
            "summary": "Kearns' statistical query (SQ) oracle (STOC'93) lends a unifying perspective\nfor most classical machine learning algorithms. This ceases to be true in\nquantum learning, where many settings do not admit, neither an SQ analog nor a\nquantum statistical query (QSQ) analog. In this work, we take inspiration from\nKearns' SQ oracle and Valiant's weak evaluation oracle (TOCT'14) and establish\na unified perspective bridging the statistical and parametrized learning\nparadigms in a novel way. We explore the problem of learning from an evaluation\noracle, which provides an estimate of function values, and introduce an\nextensive yet intuitive framework that yields unconditional lower bounds for\nlearning from evaluation queries and characterizes the query complexity for\nlearning linear function classes. The framework is directly applicable to the\nQSQ setting and virtually all algorithms based on loss function optimization.\n  Our first application is to extend prior results on the learnability of\noutput distributions of quantum circuits and Clifford unitaries from the SQ to\nthe (multi-copy) QSQ setting, implying exponential separations between learning\nstabilizer states from (multi-copy) QSQs versus from quantum samples. Our\nsecond application is to analyze some popular quantum machine learning (QML)\nsettings. We gain an intuitive picture of the hardness of many QML tasks which\ngoes beyond existing methods such as barren plateaus and the statistical\ndimension, and contains crucial setting-dependent implications. Our framework\nnot only unifies the perspective of cost concentration with that of the\nstatistical dimension in a unified language but exposes their connectedness and\nsimilarity.",
            "author": [
                "Alexander Nietner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17716v1",
                "http://arxiv.org/pdf/2310.17716v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17712v1",
            "title": "Community Detection and Classification Guarantees Using Embeddings\n  Learned by Node2Vec",
            "updated": "2023-10-26T18:16:23Z",
            "published": "2023-10-26T18:16:23Z",
            "summary": "Embedding the nodes of a large network into an Euclidean space is a common\nobjective in modern machine learning, with a variety of tools available. These\nembeddings can then be used as features for tasks such as community\ndetection/node clustering or link prediction, where they achieve state of the\nart performance. With the exception of spectral clustering methods, there is\nlittle theoretical understanding for other commonly used approaches to learning\nembeddings. In this work we examine the theoretical properties of the\nembeddings learned by node2vec. Our main result shows that the use of k-means\nclustering on the embedding vectors produced by node2vec gives weakly\nconsistent community recovery for the nodes in (degree corrected) stochastic\nblock models. We also discuss the use of these embeddings for node and link\nprediction tasks. We demonstrate this result empirically, and examine how this\nrelates to other embedding tools for network data.",
            "author": [
                "Andrew Davison",
                "S. Carlyle Morgan",
                "Owen G. Ward"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17712v1",
                "http://arxiv.org/pdf/2310.17712v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "cs.SI",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17705v1",
            "title": "A Wireless AI-Generated Content (AIGC) Provisioning Framework Empowered\n  by Semantic Communication",
            "updated": "2023-10-26T18:05:22Z",
            "published": "2023-10-26T18:05:22Z",
            "summary": "Generative AI applications are recently catering to a vast user base by\ncreating diverse and high-quality AI-generated content (AIGC). With the\nproliferation of mobile devices and rapid growth of mobile traffic, providing\nubiquitous access to high-quality AIGC services via wireless communication\nnetworks is becoming the future direction for AIGC products. However, it is\nchallenging to provide optimal AIGC services in wireless networks with unstable\nchannels, limited bandwidth resources, and unevenly distributed computational\nresources. To tackle these challenges, we propose a semantic communication\n(SemCom)-empowered AIGC (SemAIGC) generation and transmission framework, where\nonly semantic information of the content rather than all the binary bits should\nbe extracted and transmitted by using SemCom. Specifically, SemAIGC integrates\ndiffusion-based models within the semantic encoder and decoder for efficient\ncontent generation and flexible adjustment of the computing workload of both\ntransmitter and receiver. Meanwhile, we devise a resource-aware workload\ntrade-off (ROOT) scheme into the SemAIGC framework to intelligently decide\ntransmitter/receiver workload, thus adjusting the utilization of computational\nresource according to service requirements. Simulations verify the superiority\nof our proposed SemAIGC framework in terms of latency and content quality\ncompared to conventional approaches.",
            "author": [
                "Runze Cheng",
                "Yao Sun",
                "Dusit Niyato",
                "Lan Zhang",
                "Lei Zhang",
                "Muhammad Ali Imran"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17705v1",
                "http://arxiv.org/pdf/2310.17705v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.AI",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17690v1",
            "title": "Non-contrastive sentence representations via self-supervision",
            "updated": "2023-10-26T18:00:00Z",
            "published": "2023-10-26T18:00:00Z",
            "summary": "Sample contrastive methods, typically referred to simply as contrastive are\nthe foundation of most unsupervised methods to learn text and sentence\nembeddings. On the other hand, a different class of self-supervised loss\nfunctions and methods have been considered in the computer vision community and\nreferred to as dimension contrastive. In this paper, we thoroughly compare this\nclass of methods with the standard baseline for contrastive sentence\nembeddings, SimCSE. We find that self-supervised embeddings trained using\ndimension contrastive objectives can outperform SimCSE on downstream tasks\nwithout needing auxiliary loss functions.",
            "author": [
                "Marco Farina",
                "Duccio Pappadopulo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17690v1",
                "http://arxiv.org/pdf/2310.17690v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17653v1",
            "title": "Fantastic Gains and Where to Find Them: On the Existence and Prospect of\n  General Knowledge Transfer between Any Pretrained Model",
            "updated": "2023-10-26T17:59:46Z",
            "published": "2023-10-26T17:59:46Z",
            "summary": "Training deep networks requires various design decisions regarding for\ninstance their architecture, data augmentation, or optimization. In this work,\nwe find these training variations to result in networks learning unique feature\nsets from the data. Using public model libraries comprising thousands of models\ntrained on canonical datasets like ImageNet, we observe that for arbitrary\npairings of pretrained models, one model extracts significant data context\nunavailable in the other -- independent of overall performance. Given any\narbitrary pairing of pretrained models and no external rankings (such as\nseparate test sets, e.g. due to data privacy), we investigate if it is possible\nto transfer such \"complementary\" knowledge from one model to another without\nperformance degradation -- a task made particularly difficult as additional\nknowledge can be contained in stronger, equiperformant or weaker models. Yet\nfacilitating robust transfer in scenarios agnostic to pretrained model pairings\nwould unlock auxiliary gains and knowledge fusion from any model repository\nwithout restrictions on model and problem specifics - including from weaker,\nlower-performance models. This work therefore provides an initial, in-depth\nexploration on the viability of such general-purpose knowledge transfer. Across\nlarge-scale experiments, we first reveal the shortcomings of standard knowledge\ndistillation techniques, and then propose a much more general extension through\ndata partitioning for successful transfer between nearly all pretrained models,\nwhich we show can also be done unsupervised. Finally, we assess both the\nscalability and impact of fundamental model properties on successful\nmodel-agnostic knowledge transfer.",
            "author": [
                "Karsten Roth",
                "Lukas Thede",
                "Almut Sophia Koepke",
                "Oriol Vinyals",
                "Olivier H\u00e9naff",
                "Zeynep Akata"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17653v1",
                "http://arxiv.org/pdf/2310.17653v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17651v2",
            "title": "High-Dimensional Prediction for Sequential Decision Making",
            "updated": "2023-10-27T17:59:29Z",
            "published": "2023-10-26T17:59:32Z",
            "summary": "We study the problem of making predictions of an adversarially chosen\nhigh-dimensional state that are unbiased subject to an arbitrary collection of\nconditioning events, with the goal of tailoring these events to downstream\ndecision makers. We give efficient algorithms for solving this problem, as well\nas a number of applications that stem from choosing an appropriate set of\nconditioning events.\n  For example, we can efficiently make predictions targeted at polynomially\nmany decision makers, giving each of them optimal swap regret if they\nbest-respond to our predictions. We generalize this to online combinatorial\noptimization, where the decision makers have a very large action space, to give\nthe first algorithms offering polynomially many decision makers no regret on\npolynomially many subsequences that may depend on their actions and the\ncontext. We apply these results to get efficient no-subsequence-regret\nalgorithms in extensive-form games (EFGs), yielding a new family of regret\nguarantees for EFGs that generalizes some existing EFG regret notions, e.g.\nregret to informed causal deviations, and is generally incomparable to other\nknown such notions.\n  Next, we develop a novel transparent alternative to conformal prediction for\nbuilding valid online adversarial multiclass prediction sets. We produce class\nscores that downstream algorithms can use for producing valid-coverage\nprediction sets, as if these scores were the true conditional class\nprobabilities. We show this implies strong conditional validity guarantees\nincluding set-size-conditional and multigroup-fair coverage for polynomially\nmany downstream prediction sets. Moreover, our class scores can be guaranteed\nto have improved $L_2$ loss, cross-entropy loss, and generally any Bregman\nloss, compared to any collection of benchmark models, yielding a\nhigh-dimensional real-valued version of omniprediction.",
            "author": [
                "Georgy Noarov",
                "Ramya Ramalingam",
                "Aaron Roth",
                "Stephan Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17651v2",
                "http://arxiv.org/pdf/2310.17651v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17650v1",
            "title": "A Coarse-to-Fine Pseudo-Labeling (C2FPL) Framework for Unsupervised\n  Video Anomaly Detection",
            "updated": "2023-10-26T17:59:19Z",
            "published": "2023-10-26T17:59:19Z",
            "summary": "Detection of anomalous events in videos is an important problem in\napplications such as surveillance. Video anomaly detection (VAD) is\nwell-studied in the one-class classification (OCC) and weakly supervised (WS)\nsettings. However, fully unsupervised (US) video anomaly detection methods,\nwhich learn a complete system without any annotation or human supervision, have\nnot been explored in depth. This is because the lack of any ground truth\nannotations significantly increases the magnitude of the VAD challenge. To\naddress this challenge, we propose a simple-but-effective two-stage\npseudo-label generation framework that produces segment-level (normal/anomaly)\npseudo-labels, which can be further used to train a segment-level anomaly\ndetector in a supervised manner. The proposed coarse-to-fine pseudo-label\n(C2FPL) generator employs carefully-designed hierarchical divisive clustering\nand statistical hypothesis testing to identify anomalous video segments from a\nset of completely unlabeled videos. The trained anomaly detector can be\ndirectly applied on segments of an unseen test video to obtain segment-level,\nand subsequently, frame-level anomaly predictions. Extensive studies on two\nlarge-scale public-domain datasets, UCF-Crime and XD-Violence, demonstrate that\nthe proposed unsupervised approach achieves superior performance compared to\nall existing OCC and US methods , while yielding comparable performance to the\nstate-of-the-art WS methods.",
            "author": [
                "Anas Al-lahham",
                "Nurbek Tastan",
                "Zaigham Zaheer",
                "Karthik Nandakumar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17650v1",
                "http://arxiv.org/pdf/2310.17650v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17649v1",
            "title": "6-DoF Stability Field via Diffusion Models",
            "updated": "2023-10-26T17:59:12Z",
            "published": "2023-10-26T17:59:12Z",
            "summary": "A core capability for robot manipulation is reasoning over where and how to\nstably place objects in cluttered environments. Traditionally, robots have\nrelied on object-specific, hand-crafted heuristics in order to perform such\nreasoning, with limited generalizability beyond a small number of object\ninstances and object interaction patterns. Recent approaches instead learn\nnotions of physical interaction, namely motion prediction, but require\nsupervision in the form of labeled object information or come at the cost of\nhigh sample complexity, and do not directly reason over stability or object\nplacement. We present 6-DoFusion, a generative model capable of generating 3D\nposes of an object that produces a stable configuration of a given scene.\nUnderlying 6-DoFusion is a diffusion model that incrementally refines a\nrandomly initialized SE(3) pose to generate a sample from a learned,\ncontext-dependent distribution over stable poses. We evaluate our model on\ndifferent object placement and stacking tasks, demonstrating its ability to\nconstruct stable scenes that involve novel object classes as well as to improve\nthe accuracy of state-of-the-art 3D pose estimation methods.",
            "author": [
                "Takuma Yoneda",
                "Tianchong Jiang",
                "Gregory Shakhnarovich",
                "Matthew R. Walter"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17649v1",
                "http://arxiv.org/pdf/2310.17649v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17688v2",
            "title": "Managing AI Risks in an Era of Rapid Progress",
            "updated": "2023-11-12T14:33:20Z",
            "published": "2023-10-26T17:59:06Z",
            "summary": "In this short consensus paper, we outline risks from upcoming, advanced AI\nsystems. We examine large-scale social harms and malicious uses, as well as an\nirreversible loss of human control over autonomous AI systems. In light of\nrapid and continuing AI progress, we propose urgent priorities for AI R&D and\ngovernance.",
            "author": [
                "Yoshua Bengio",
                "Geoffrey Hinton",
                "Andrew Yao",
                "Dawn Song",
                "Pieter Abbeel",
                "Yuval Noah Harari",
                "Ya-Qin Zhang",
                "Lan Xue",
                "Shai Shalev-Shwartz",
                "Gillian Hadfield",
                "Jeff Clune",
                "Tegan Maharaj",
                "Frank Hutter",
                "At\u0131l\u0131m G\u00fcne\u015f Baydin",
                "Sheila McIlraith",
                "Qiqi Gao",
                "Ashwin Acharya",
                "David Krueger",
                "Anca Dragan",
                "Philip Torr",
                "Stuart Russell",
                "Daniel Kahneman",
                "Jan Brauner",
                "S\u00f6ren Mindermann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17688v2",
                "http://arxiv.org/pdf/2310.17688v2"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17687v1",
            "title": "Counterfactual Fairness for Predictions using Generative Adversarial\n  Networks",
            "updated": "2023-10-26T17:58:39Z",
            "published": "2023-10-26T17:58:39Z",
            "summary": "Fairness in predictions is of direct importance in practice due to legal,\nethical, and societal reasons. It is often achieved through counterfactual\nfairness, which ensures that the prediction for an individual is the same as\nthat in a counterfactual world under a different sensitive attribute. However,\nachieving counterfactual fairness is challenging as counterfactuals are\nunobservable. In this paper, we develop a novel deep neural network called\nGenerative Counterfactual Fairness Network (GCFN) for making predictions under\ncounterfactual fairness. Specifically, we leverage a tailored generative\nadversarial network to directly learn the counterfactual distribution of the\ndescendants of the sensitive attribute, which we then use to enforce fair\npredictions through a novel counterfactual mediator regularization. If the\ncounterfactual distribution is learned sufficiently well, our method is\nmathematically guaranteed to ensure the notion of counterfactual fairness.\nThereby, our GCFN addresses key shortcomings of existing baselines that are\nbased on inferring latent variables, yet which (a) are potentially correlated\nwith the sensitive attributes and thus lead to bias, and (b) have weak\ncapability in constructing latent representations and thus low prediction\nperformance. Across various experiments, our method achieves state-of-the-art\nperformance. Using a real-world case study from recidivism prediction, we\nfurther demonstrate that our method makes meaningful predictions in practice.",
            "author": [
                "Yuchen Ma",
                "Dennis Frauen",
                "Valentyn Melnychuk",
                "Stefan Feuerriegel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17687v1",
                "http://arxiv.org/pdf/2310.17687v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17646v1",
            "title": "Do Graph Neural Networks Dream of Landau Damping? Insights from Kinetic\n  Simulations of a Plasma Sheet Model",
            "updated": "2023-10-26T17:58:12Z",
            "published": "2023-10-26T17:58:12Z",
            "summary": "We explore the possibility of fully replacing a plasma physics kinetic\nsimulator with a graph neural network-based simulator. We focus on this class\nof surrogate models given the similarity between their message-passing update\nmechanism and the traditional physics solver update, and the possibility of\nenforcing known physical priors into the graph construction and update. We show\nthat our model learns the kinetic plasma dynamics of the one-dimensional plasma\nmodel, a predecessor of contemporary kinetic plasma simulation codes, and\nrecovers a wide range of well-known kinetic plasma processes, including plasma\nthermalization, electrostatic fluctuations about thermal equilibrium, and the\ndrag on a fast sheet and Landau damping. We compare the performance against the\noriginal plasma model in terms of run-time, conservation laws, and temporal\nevolution of key physical quantities. The limitations of the model are\npresented and possible directions for higher-dimensional surrogate models for\nkinetic plasmas are discussed.",
            "author": [
                "Diogo D Carvalho",
                "Diogo R Ferreira",
                "Luis O Silva"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17646v1",
                "http://arxiv.org/pdf/2310.17646v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph",
                "cs.LG",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17645v1",
            "title": "Defending Against Transfer Attacks From Public Models",
            "updated": "2023-10-26T17:58:08Z",
            "published": "2023-10-26T17:58:08Z",
            "summary": "Adversarial attacks have been a looming and unaddressed threat in the\nindustry. However, through a decade-long history of the robustness evaluation\nliterature, we have learned that mounting a strong or optimal attack is\nchallenging. It requires both machine learning and domain expertise. In other\nwords, the white-box threat model, religiously assumed by a large majority of\nthe past literature, is unrealistic. In this paper, we propose a new practical\nthreat model where the adversary relies on transfer attacks through publicly\navailable surrogate models. We argue that this setting will become the most\nprevalent for security-sensitive applications in the future. We evaluate the\ntransfer attacks in this setting and propose a specialized defense method based\non a game-theoretic perspective. The defenses are evaluated under 24 public\nmodels and 11 attack algorithms across three datasets (CIFAR-10, CIFAR-100, and\nImageNet). Under this threat model, our defense, PubDef, outperforms the\nstate-of-the-art white-box adversarial training by a large margin with almost\nno loss in the normal accuracy. For instance, on ImageNet, our defense achieves\n62% accuracy under the strongest transfer attack vs only 36% of the best\nadversarially trained model. Its accuracy when not under attack is only 2%\nlower than that of an undefended model (78% vs 80%). We release our code at\nhttps://github.com/wagner-group/pubdef.",
            "author": [
                "Chawin Sitawarin",
                "Jaewon Chang",
                "David Huang",
                "Wesson Altoyan",
                "David Wagner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17645v1",
                "http://arxiv.org/pdf/2310.17645v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17644v1",
            "title": "torchdistill Meets Hugging Face Libraries for Reproducible, Coding-Free\n  Deep Learning Studies: A Case Study on NLP",
            "updated": "2023-10-26T17:57:15Z",
            "published": "2023-10-26T17:57:15Z",
            "summary": "Reproducibility in scientific work has been becoming increasingly important\nin research communities such as machine learning, natural language processing,\nand computer vision communities due to the rapid development of the research\ndomains supported by recent advances in deep learning. In this work, we present\na significantly upgraded version of torchdistill, a modular-driven coding-free\ndeep learning framework significantly upgraded from the initial release, which\nsupports only image classification and object detection tasks for reproducible\nknowledge distillation experiments. To demonstrate that the upgraded framework\ncan support more tasks with third-party libraries, we reproduce the GLUE\nbenchmark results of BERT models using a script based on the upgraded\ntorchdistill, harmonizing with various Hugging Face libraries. All the 27\nfine-tuned BERT models and configurations to reproduce the results are\npublished at Hugging Face, and the model weights have already been widely used\nin research communities. We also reimplement popular small-sized models and new\nknowledge distillation methods and perform additional experiments for computer\nvision tasks.",
            "author": [
                "Yoshitomo Matsubara"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17644v1",
                "http://arxiv.org/pdf/2310.17644v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17643v1",
            "title": "Where you go is who you are -- A study on machine learning based\n  semantic privacy attacks",
            "updated": "2023-10-26T17:56:50Z",
            "published": "2023-10-26T17:56:50Z",
            "summary": "Concerns about data privacy are omnipresent, given the increasing usage of\ndigital applications and their underlying business model that includes selling\nuser data. Location data is particularly sensitive since they allow us to infer\nactivity patterns and interests of users, e.g., by categorizing visited\nlocations based on nearby points of interest (POI). On top of that, machine\nlearning methods provide new powerful tools to interpret big data. In light of\nthese considerations, we raise the following question: What is the actual risk\nthat realistic, machine learning based privacy attacks can obtain meaningful\nsemantic information from raw location data, subject to inaccuracies in the\ndata? In response, we present a systematic analysis of two attack scenarios,\nnamely location categorization and user profiling. Experiments on the\nFoursquare dataset and tracking data demonstrate the potential for abuse of\nhigh-quality spatial information, leading to a significant privacy loss even\nwith location inaccuracy of up to 200m. With location obfuscation of more than\n1 km, spatial information hardly adds any value, but a high privacy risk solely\nfrom temporal information remains. The availability of public context data such\nas POIs plays a key role in inference based on spatial information. Our\nfindings point out the risks of ever-growing databases of tracking data and\nspatial context data, which policymakers should consider for privacy\nregulations, and which could guide individuals in their personal location\nprotection measures.",
            "author": [
                "Nina Wiedemann",
                "Ourania Kounadi",
                "Martin Raubal",
                "Krzysztof Janowicz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17643v1",
                "http://arxiv.org/pdf/2310.17643v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.CE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17642v1",
            "title": "Drive Anywhere: Generalizable End-to-end Autonomous Driving with\n  Multi-modal Foundation Models",
            "updated": "2023-10-26T17:56:35Z",
            "published": "2023-10-26T17:56:35Z",
            "summary": "As autonomous driving technology matures, end-to-end methodologies have\nemerged as a leading strategy, promising seamless integration from perception\nto control via deep learning. However, existing systems grapple with challenges\nsuch as unexpected open set environments and the complexity of black-box\nmodels. At the same time, the evolution of deep learning introduces larger,\nmultimodal foundational models, offering multi-modal visual and textual\nunderstanding. In this paper, we harness these multimodal foundation models to\nenhance the robustness and adaptability of autonomous driving systems, enabling\nout-of-distribution, end-to-end, multimodal, and more explainable autonomy.\nSpecifically, we present an approach to apply end-to-end open-set (any\nenvironment/scene) autonomous driving that is capable of providing driving\ndecisions from representations queryable by image and text. To do so, we\nintroduce a method to extract nuanced spatial (pixel/patch-aligned) features\nfrom transformers to enable the encapsulation of both spatial and semantic\nfeatures. Our approach (i) demonstrates unparalleled results in diverse tests\nwhile achieving significantly greater robustness in out-of-distribution\nsituations, and (ii) allows the incorporation of latent space simulation (via\ntext) for improved training (data augmentation via text) and policy debugging.\nWe encourage the reader to check our explainer video at\nhttps://www.youtube.com/watch?v=4n-DJf8vXxo&feature=youtu.be and to view the\ncode and demos on our project webpage at https://drive-anywhere.github.io/.",
            "author": [
                "Tsun-Hsuan Wang",
                "Alaa Maalouf",
                "Wei Xiao",
                "Yutong Ban",
                "Alexander Amini",
                "Guy Rosman",
                "Sertac Karaman",
                "Daniela Rus"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17642v1",
                "http://arxiv.org/pdf/2310.17642v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17639v2",
            "title": "In-Context Learning Dynamics with Random Binary Sequences",
            "updated": "2023-11-27T21:05:54Z",
            "published": "2023-10-26T17:54:52Z",
            "summary": "Large language models (LLMs) trained on huge corpora of text datasets\ndemonstrate intriguing capabilities, achieving state-of-the-art performance on\ntasks they were not explicitly trained for. The precise nature of LLM\ncapabilities is often mysterious, and different prompts can elicit different\ncapabilities through in-context learning. We propose a framework that enables\nus to analyze in-context learning dynamics to understand latent concepts\nunderlying LLMs' behavioral patterns. This provides a more nuanced\nunderstanding than success-or-failure evaluation benchmarks, but does not\nrequire observing internal activations as a mechanistic interpretation of\ncircuits would. Inspired by the cognitive science of human randomness\nperception, we use random binary sequences as context and study dynamics of\nin-context learning by manipulating properties of context data, such as\nsequence length. In the latest GPT-3.5+ models, we find emergent abilities to\ngenerate seemingly random numbers and learn basic formal languages, with\nstriking in-context learning dynamics where model outputs transition sharply\nfrom seemingly random behaviors to deterministic repetition.",
            "author": [
                "Eric J. Bigelow",
                "Ekdeep Singh Lubana",
                "Robert P. Dick",
                "Hidenori Tanaka",
                "Tomer D. Ullman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17639v2",
                "http://arxiv.org/pdf/2310.17639v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17638v1",
            "title": "Generative Fractional Diffusion Models",
            "updated": "2023-10-26T17:53:24Z",
            "published": "2023-10-26T17:53:24Z",
            "summary": "We generalize the continuous time framework for score-based generative models\nfrom an underlying Brownian motion (BM) to an approximation of fractional\nBrownian motion (FBM). We derive a continuous reparameterization trick and the\nreverse time model by representing FBM as a stochastic integral over a family\nof Ornstein-Uhlenbeck processes to define generative fractional diffusion\nmodels (GFDM) with driving noise converging to a non-Markovian process of\ninfinite quadratic variation. The Hurst index $H\\in(0,1)$ of FBM enables\ncontrol of the roughness of the distribution transforming path. To the best of\nour knowledge, this is the first attempt to build a generative model upon a\nstochastic process with infinite quadratic variation.",
            "author": [
                "Gabriel Nobis",
                "Marco Aversa",
                "Maximilian Springenberg",
                "Michael Detzel",
                "Stefano Ermon",
                "Shinichi Nakajima",
                "Roderick Murray-Smith",
                "Sebastian Lapuschkin",
                "Christoph Knochenhauer",
                "Luis Oala",
                "Wojciech Samek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17638v1",
                "http://arxiv.org/pdf/2310.17638v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML",
                "I.2.4; F.4.1; G.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17634v1",
            "title": "Grow Your Limits: Continuous Improvement with Real-World RL for Robotic\n  Locomotion",
            "updated": "2023-10-26T17:51:46Z",
            "published": "2023-10-26T17:51:46Z",
            "summary": "Deep reinforcement learning (RL) can enable robots to autonomously acquire\ncomplex behaviors, such as legged locomotion. However, RL in the real world is\ncomplicated by constraints on efficiency, safety, and overall training\nstability, which limits its practical applicability. We present APRL, a policy\nregularization framework that modulates the robot's exploration over the course\nof training, striking a balance between flexible improvement potential and\nfocused, efficient exploration. APRL enables a quadrupedal robot to efficiently\nlearn to walk entirely in the real world within minutes and continue to improve\nwith more training where prior work saturates in performance. We demonstrate\nthat continued training with APRL results in a policy that is substantially\nmore capable of navigating challenging situations and is able to adapt to\nchanges in dynamics with continued training.",
            "author": [
                "Laura Smith",
                "Yunhao Cao",
                "Sergey Levine"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17634v1",
                "http://arxiv.org/pdf/2310.17634v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17629v1",
            "title": "Approximate Leave-one-out Cross Validation for Regression with $\\ell_1$\n  Regularizers (extended version)",
            "updated": "2023-10-26T17:48:10Z",
            "published": "2023-10-26T17:48:10Z",
            "summary": "The out-of-sample error (OO) is the main quantity of interest in risk\nestimation and model selection. Leave-one-out cross validation (LO) offers a\n(nearly) distribution-free yet computationally demanding approach to estimate\nOO. Recent theoretical work showed that approximate leave-one-out cross\nvalidation (ALO) is a computationally efficient and statistically reliable\nestimate of LO (and OO) for generalized linear models with differentiable\nregularizers. For problems involving non-differentiable regularizers, despite\nsignificant empirical evidence, the theoretical understanding of ALO's error\nremains unknown. In this paper, we present a novel theory for a wide class of\nproblems in the generalized linear model family with non-differentiable\nregularizers. We bound the error |ALO - LO| in terms of intuitive metrics such\nas the size of leave-i-out perturbations in active sets, sample size n, number\nof features p and regularization parameters. As a consequence, for the\n$\\ell_1$-regularized problems, we show that |ALO - LO| goes to zero as p goes\nto infinity while n/p and SNR are fixed and bounded.",
            "author": [
                "Arnab Auddy",
                "Haolin Zou",
                "Kamiar Rahnama Rad",
                "Arian Maleki"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17629v1",
                "http://arxiv.org/pdf/2310.17629v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.ME",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17626v1",
            "title": "A Survey on Transferability of Adversarial Examples across Deep Neural\n  Networks",
            "updated": "2023-10-26T17:45:26Z",
            "published": "2023-10-26T17:45:26Z",
            "summary": "The emergence of Deep Neural Networks (DNNs) has revolutionized various\ndomains, enabling the resolution of complex tasks spanning image recognition,\nnatural language processing, and scientific problem-solving. However, this\nprogress has also exposed a concerning vulnerability: adversarial examples.\nThese crafted inputs, imperceptible to humans, can manipulate machine learning\nmodels into making erroneous predictions, raising concerns for safety-critical\napplications. An intriguing property of this phenomenon is the transferability\nof adversarial examples, where perturbations crafted for one model can deceive\nanother, often with a different architecture. This intriguing property enables\n\"black-box\" attacks, circumventing the need for detailed knowledge of the\ntarget model. This survey explores the landscape of the adversarial\ntransferability of adversarial examples. We categorize existing methodologies\nto enhance adversarial transferability and discuss the fundamental principles\nguiding each approach. While the predominant body of research primarily\nconcentrates on image classification, we also extend our discussion to\nencompass other vision tasks and beyond. Challenges and future prospects are\ndiscussed, highlighting the importance of fortifying DNNs against adversarial\nvulnerabilities in an evolving landscape.",
            "author": [
                "Jindong Gu",
                "Xiaojun Jia",
                "Pau de Jorge",
                "Wenqain Yu",
                "Xinwei Liu",
                "Avery Ma",
                "Yuan Xun",
                "Anjun Hu",
                "Ashkan Khakzar",
                "Zhijiang Li",
                "Xiaochun Cao",
                "Philip Torr"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17626v1",
                "http://arxiv.org/pdf/2310.17626v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17623v2",
            "title": "Proving Test Set Contamination in Black Box Language Models",
            "updated": "2023-11-24T01:45:16Z",
            "published": "2023-10-26T17:43:13Z",
            "summary": "Large language models are trained on vast amounts of internet data, prompting\nconcerns and speculation that they have memorized public benchmarks. Going from\nspeculation to proof of contamination is challenging, as the pretraining data\nused by proprietary models are often not publicly accessible. We show that it\nis possible to provide provable guarantees of test set contamination in\nlanguage models without access to pretraining data or model weights. Our\napproach leverages the fact that when there is no data contamination, all\norderings of an exchangeable benchmark should be equally likely. In contrast,\nthe tendency for language models to memorize example order means that a\ncontaminated language model will find certain canonical orderings to be much\nmore likely than others. Our test flags potential contamination whenever the\nlikelihood of a canonically ordered benchmark dataset is significantly higher\nthan the likelihood after shuffling the examples. We demonstrate that our\nprocedure is sensitive enough to reliably prove test set contamination in\nchallenging situations, including models as small as 1.4 billion parameters, on\nsmall test sets of only 1000 examples, and datasets that appear only a few\ntimes in the pretraining corpus. Using our test, we audit five popular publicly\naccessible language models for test set contamination and find little evidence\nfor pervasive contamination.",
            "author": [
                "Yonatan Oren",
                "Nicole Meister",
                "Niladri Chatterji",
                "Faisal Ladhak",
                "Tatsunori B. Hashimoto"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17623v2",
                "http://arxiv.org/pdf/2310.17623v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17622v1",
            "title": "Combating Representation Learning Disparity with Geometric Harmonization",
            "updated": "2023-10-26T17:41:11Z",
            "published": "2023-10-26T17:41:11Z",
            "summary": "Self-supervised learning (SSL) as an effective paradigm of representation\nlearning has achieved tremendous success on various curated datasets in diverse\nscenarios. Nevertheless, when facing the long-tailed distribution in real-world\napplications, it is still hard for existing methods to capture transferable and\nrobust representation. Conventional SSL methods, pursuing sample-level\nuniformity, easily leads to representation learning disparity where head\nclasses dominate the feature regime but tail classes passively collapse. To\naddress this problem, we propose a novel Geometric Harmonization (GH) method to\nencourage category-level uniformity in representation learning, which is more\nbenign to the minority and almost does not hurt the majority under long-tailed\ndistribution. Specially, GH measures the population statistics of the embedding\nspace on top of self-supervised learning, and then infer an fine-grained\ninstance-wise calibration to constrain the space expansion of head classes and\navoid the passive collapse of tail classes. Our proposal does not alter the\nsetting of SSL and can be easily integrated into existing methods in a low-cost\nmanner. Extensive results on a range of benchmark datasets show the\neffectiveness of GH with high tolerance to the distribution skewness. Our code\nis available at https://github.com/MediaBrain-SJTU/Geometric-Harmonization.",
            "author": [
                "Zhihan Zhou",
                "Jiangchao Yao",
                "Feng Hong",
                "Ya Zhang",
                "Bo Han",
                "Yanfeng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17622v1",
                "http://arxiv.org/pdf/2310.17622v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17614v1",
            "title": "Topological and magnetic properties of the interacting\n  Bernevig-Hughes-Zhang model",
            "updated": "2023-10-26T17:36:11Z",
            "published": "2023-10-26T17:36:11Z",
            "summary": "We investigate the effects of electronic correlations on the\nBernevig-Hughes-Zhang model using the real-space density matrix renormalization\ngroup (DMRG) algorithm. We introduce a method to probe topological phase\ntransitions in systems with strong correlations using DMRG, substantiated by an\nunsupervised machine learning methodology that analyzes the orbital structure\nof the real-space edges. Including the full multi-orbital Hubbard interaction\nterm, we construct a phase diagram as a function of a gap parameter ($m$) and\nthe Hubbard interaction strength ($U$) via exact DMRG simulations on $N\\times\n4$ cylinders. Our analysis confirms that the topological phase persists in the\npresence of interactions, consistent with previous studies, but it also reveals\nan intriguing phase transition from a paramagnetic to an antiferromagnetic\ntopological insulator. The combination of the magnetic structure factor,\nstrength of magnetic moments, and the orbitally resolved density, provides\nreal-space information on both topology and magnetism in a strongly correlated\nsystem.",
            "author": [
                "Rahul Soni",
                "Harini Radhakrishnan",
                "Bernd Rosenow",
                "Gonzalo Alvarez",
                "Adrian Del Maestro"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17614v1",
                "http://arxiv.org/pdf/2310.17614v1"
            ],
            "primary_category": "cond-mat.str-el",
            "category": [
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17611v1",
            "title": "Uncovering Meanings of Embeddings via Partial Orthogonality",
            "updated": "2023-10-26T17:34:32Z",
            "published": "2023-10-26T17:34:32Z",
            "summary": "Machine learning tools often rely on embedding text as vectors of real\nnumbers. In this paper, we study how the semantic structure of language is\nencoded in the algebraic structure of such embeddings. Specifically, we look at\na notion of ``semantic independence'' capturing the idea that, e.g.,\n``eggplant'' and ``tomato'' are independent given ``vegetable''. Although such\nexamples are intuitive, it is difficult to formalize such a notion of semantic\nindependence. The key observation here is that any sensible formalization\nshould obey a set of so-called independence axioms, and thus any algebraic\nencoding of this structure should also obey these axioms. This leads us\nnaturally to use partial orthogonality as the relevant algebraic structure. We\ndevelop theory and methods that allow us to demonstrate that partial\northogonality does indeed capture semantic independence. Complementary to this,\nwe also introduce the concept of independence preserving embeddings where\nembeddings preserve the conditional independence structures of a distribution,\nand we prove the existence of such embeddings and approximations to them.",
            "author": [
                "Yibo Jiang",
                "Bryon Aragam",
                "Victor Veitch"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17611v1",
                "http://arxiv.org/pdf/2310.17611v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17610v1",
            "title": "A qualitative difference between gradient flows of convex functions in\n  finite- and infinite-dimensional Hilbert spaces",
            "updated": "2023-10-26T17:33:52Z",
            "published": "2023-10-26T17:33:52Z",
            "summary": "We consider gradient flow/gradient descent and heavy ball/accelerated\ngradient descent optimization for convex objective functions. In the gradient\nflow case, we prove the following:\n  1. If $f$ does not have a minimizer, the convergence $f(x_t)\\to \\inf f$ can\nbe arbitrarily slow.\n  2. If $f$ does have a minimizer, the excess energy $f(x_t) - \\inf f$ is\nintegrable/summable in time. In particular, $f(x_t) - \\inf f = o(1/t)$ as\n$t\\to\\infty$.\n  3. In Hilbert spaces, this is optimal: $f(x_t) - \\inf f$ can decay to $0$ as\nslowly as any given function which is monotone decreasing and integrable at\n$\\infty$, even for a fixed quadratic objective.\n  4. In finite dimension (or more generally, for all gradient flow curves of\nfinite length), this is not optimal: We prove that there are convex monotone\ndecreasing integrable functions $g(t)$ which decrease to zero slower than\n$f(x_t)-\\inf f$ for the gradient flow of any convex function on $\\mathbb R^d$.\nFor instance, we show that any gradient flow $x_t$ of a convex function $f$ in\nfinite dimension satisfies $\\liminf_{t\\to\\infty} \\big(t\\cdot \\log^2(t)\\cdot\n\\big\\{f(x_t) -\\inf f\\big\\}\\big)=0$.\n  This improves on the commonly reported $O(1/t)$ rate and provides a sharp\ncharacterization of the energy decay law. We also note that it is impossible to\nestablish a rate $O(1/(t\\phi(t))$ for any function $\\phi$ which satisfies\n$\\lim_{t\\to\\infty}\\phi(t) = \\infty$, even asymptotically.\n  Similar results are obtained in related settings for (1) discrete time\ngradient descent, (2) stochastic gradient descent with multiplicative noise and\n(3) the heavy ball ODE. In the case of stochastic gradient descent, the\nsummability of $\\mathbb E[f(x_n) - \\inf f]$ is used to prove that $f(x_n)\\to\n\\inf f$ almost surely - an improvement on the convergence almost surely up to a\nsubsequence which follows from the $O(1/n)$ decay estimate.",
            "author": [
                "Jonathan W. Siegel",
                "Stephan Wojtowytsch"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17610v1",
                "http://arxiv.org/pdf/2310.17610v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "cs.NA",
                "math.CA",
                "math.NA",
                "stat.ML",
                "26A51, 34A34"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17605v1",
            "title": "Orbital-optimized Density Functional Calculations of Molecular Rydberg\n  Excited States with Real Space Grid Representation and Self-Interaction\n  Correction",
            "updated": "2023-10-26T17:28:46Z",
            "published": "2023-10-26T17:28:46Z",
            "summary": "Density functional calculations of Rydberg excited states up to high energy\nare carried out for several molecules using an approach where the orbitals are\nvariationally optimized by converging on saddle points on the electronic energy\nsurface within a real space grid representation. Remarkably good agreement with\nexperimental estimates of the excitation energy is obtained using the\ngeneralized gradient approximation (GGA) functional of Perdew, Burke and\nErnzerhof (PBE) when Perdew-Zunger self-interaction correction is applied in\ncombination with complex-valued orbitals. Even without the correction, the PBE\nfunctional gives quite good results despite the fact that corresponding Rydberg\nvirtual orbitals have positive energy in the ground state calculation. Results\nobtained using the TPSS and r2SCAN meta-GGA functionals are also presented, but\nthey do not provide a systematic improvement over the results from the\nuncorrected PBE functional. The grid representation combined with the projector\naugmented-wave approach gives a simpler and better representation of the\ndiffuse Rydberg orbitals than a linear combination of atomic orbitals with\ncommonly used basis sets, the latter leading to an overestimation of the\nexcitation energy due to confinement of the excited states.",
            "author": [
                "Alec E. Sigur\u00f0arson",
                "Yorick L. A. Schmerwitz",
                "Dagr\u00fan K. V. Tveiten",
                "Gianluca Levi",
                "Hannes J\u00f3nsson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17605v1",
                "http://arxiv.org/pdf/2310.17605v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17596v1",
            "title": "MimicGen: A Data Generation System for Scalable Robot Learning using\n  Human Demonstrations",
            "updated": "2023-10-26T17:17:31Z",
            "published": "2023-10-26T17:17:31Z",
            "summary": "Imitation learning from a large set of human demonstrations has proved to be\nan effective paradigm for building capable robot agents. However, the\ndemonstrations can be extremely costly and time-consuming to collect. We\nintroduce MimicGen, a system for automatically synthesizing large-scale, rich\ndatasets from only a small number of human demonstrations by adapting them to\nnew contexts. We use MimicGen to generate over 50K demonstrations across 18\ntasks with diverse scene configurations, object instances, and robot arms from\njust ~200 human demonstrations. We show that robot agents can be effectively\ntrained on this generated dataset by imitation learning to achieve strong\nperformance in long-horizon and high-precision tasks, such as multi-part\nassembly and coffee preparation, across broad initial state distributions. We\nfurther demonstrate that the effectiveness and utility of MimicGen data compare\nfavorably to collecting additional human demonstrations, making it a powerful\nand economical approach towards scaling up robot learning. Datasets, simulation\nenvironments, videos, and more at https://mimicgen.github.io .",
            "author": [
                "Ajay Mandlekar",
                "Soroush Nasiriany",
                "Bowen Wen",
                "Iretiayo Akinola",
                "Yashraj Narang",
                "Linxi Fan",
                "Yuke Zhu",
                "Dieter Fox"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17596v1",
                "http://arxiv.org/pdf/2310.17596v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17594v2",
            "title": "SPA: A Graph Spectral Alignment Perspective for Domain Adaptation",
            "updated": "2023-10-27T08:40:15Z",
            "published": "2023-10-26T17:13:48Z",
            "summary": "Unsupervised domain adaptation (UDA) is a pivotal form in machine learning to\nextend the in-domain model to the distinctive target domains where the data\ndistributions differ. Most prior works focus on capturing the inter-domain\ntransferability but largely overlook rich intra-domain structures, which\nempirically results in even worse discriminability. In this work, we introduce\na novel graph SPectral Alignment (SPA) framework to tackle the tradeoff. The\ncore of our method is briefly condensed as follows: (i)-by casting the DA\nproblem to graph primitives, SPA composes a coarse graph alignment mechanism\nwith a novel spectral regularizer towards aligning the domain graphs in\neigenspaces; (ii)-we further develop a fine-grained message propagation module\n-- upon a novel neighbor-aware self-training mechanism -- in order for enhanced\ndiscriminability in the target domain. On standardized benchmarks, the\nextensive experiments of SPA demonstrate that its performance has surpassed the\nexisting cutting-edge DA methods. Coupled with dense model analysis, we\nconclude that our approach indeed possesses superior efficacy, robustness,\ndiscriminability, and transferability. Code and data are available at:\nhttps://github.com/CrownX/SPA.",
            "author": [
                "Zhiqing Xiao",
                "Haobo Wang",
                "Ying Jin",
                "Lei Feng",
                "Gang Chen",
                "Fei Huang",
                "Junbo Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17594v2",
                "http://arxiv.org/pdf/2310.17594v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17588v1",
            "title": "PAC-tuning:Fine-tuning Pretrained Language Models with PAC-driven\n  Perturbed Gradient Descent",
            "updated": "2023-10-26T17:09:13Z",
            "published": "2023-10-26T17:09:13Z",
            "summary": "Fine-tuning pretrained language models (PLMs) for downstream tasks is a\nlarge-scale optimization problem, in which the choice of the training algorithm\ncritically determines how well the trained model can generalize to unseen test\ndata, especially in the context of few-shot learning. To achieve good\ngeneralization performance and avoid overfitting, techniques such as data\naugmentation and pruning are often applied. However, adding these\nregularizations necessitates heavy tuning of the hyperparameters of\noptimization algorithms, such as the popular Adam optimizer. In this paper, we\npropose a two-stage fine-tuning method, PAC-tuning, to address this\noptimization challenge. First, based on PAC-Bayes training, PAC-tuning directly\nminimizes the PAC-Bayes generalization bound to learn proper parameter\ndistribution. Second, PAC-tuning modifies the gradient by injecting noise with\nthe variance learned in the first stage into the model parameters during\ntraining, resulting in a variant of perturbed gradient descent (PGD). In the\npast, the few-shot scenario posed difficulties for PAC-Bayes training because\nthe PAC-Bayes bound, when applied to large models with limited training data,\nmight not be stringent. Our experimental results across 5 GLUE benchmark tasks\ndemonstrate that PAC-tuning successfully handles the challenges of fine-tuning\ntasks and outperforms strong baseline methods by a visible margin, further\nconfirming the potential to apply PAC training for any other settings where the\nAdam optimizer is currently used for training.",
            "author": [
                "Guangliang Liu",
                "Zhiyu Xue",
                "Xitong Zhang",
                "Kristen Marie Johnson",
                "Rongrong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17588v1",
                "http://arxiv.org/pdf/2310.17588v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17584v2",
            "title": "A minimax optimal control approach for robust neural ODEs",
            "updated": "2023-11-03T11:37:19Z",
            "published": "2023-10-26T17:07:43Z",
            "summary": "In this paper, we address the adversarial training of neural ODEs from a\nrobust control perspective. This is an alternative to the classical training\nvia empirical risk minimization, and it is widely used to enforce reliable\noutcomes for input perturbations. Neural ODEs allow the interpretation of deep\nneural networks as discretizations of control systems, unlocking powerful tools\nfrom control theory for the development and the understanding of machine\nlearning. In this specific case, we formulate the adversarial training with\nperturbed data as a minimax optimal control problem, for which we derive first\norder optimality conditions in the form of Pontryagin's Maximum Principle. We\nprovide a novel interpretation of robust training leading to an alternative\nweighted technique, which we test on a low-dimensional classification task.",
            "author": [
                "Cristina Cipriani",
                "Alessandro Scagliotti",
                "Tobias W\u00f6hrer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17584v2",
                "http://arxiv.org/pdf/2310.17584v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17582v1",
            "title": "Convergence of flow-based generative models via proximal gradient\n  descent in Wasserstein space",
            "updated": "2023-10-26T17:06:23Z",
            "published": "2023-10-26T17:06:23Z",
            "summary": "Flow-based generative models enjoy certain advantages in computing the data\ngeneration and the likelihood, and have recently shown competitive empirical\nperformance. Compared to the accumulating theoretical studies on related\nscore-based diffusion models, analysis of flow-based models, which are\ndeterministic in both forward (data-to-noise) and reverse (noise-to-data)\ndirections, remain sparse. In this paper, we provide a theoretical guarantee of\ngenerating data distribution by a progressive flow model, the so-called JKO\nflow model, which implements the Jordan-Kinderleherer-Otto (JKO) scheme in a\nnormalizing flow network. Leveraging the exponential convergence of the\nproximal gradient descent (GD) in Wasserstein space, we prove the\nKullback-Leibler (KL) guarantee of data generation by a JKO flow model to be\n$O(\\varepsilon^2)$ when using $N \\lesssim \\log (1/\\varepsilon)$ many JKO steps\n($N$ Residual Blocks in the flow) where $\\varepsilon $ is the error in the\nper-step first-order condition. The assumption on data density is merely a\nfinite second moment, and the theory extends to data distributions without\ndensity and when there are inversion errors in the reverse process where we\nobtain KL-$W_2$ mixed error guarantees. The non-asymptotic convergence rate of\nthe JKO-type $W_2$-proximal GD is proved for a general class of convex\nobjective functionals that includes the KL divergence as a special case, which\ncan be of independent interest.",
            "author": [
                "Xiuyuan Cheng",
                "Jianfeng Lu",
                "Yixin Tan",
                "Yao Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17582v1",
                "http://arxiv.org/pdf/2310.17582v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.OC",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18373v1",
            "title": "Can LLMs Grade Short-answer Reading Comprehension Questions :\n  Foundational Literacy Assessment in LMICs",
            "updated": "2023-10-26T17:05:40Z",
            "published": "2023-10-26T17:05:40Z",
            "summary": "This paper presents emerging evidence of using generative large language\nmodels (i.e., GPT-4) to reliably evaluate short-answer reading comprehension\nquestions. Specifically, we explore how various configurations of generative\n(LLMs) are able to evaluate student responses from a new dataset, drawn from a\nbattery of reading assessments conducted with over 150 students in Ghana. As\nthis dataset is novel and hence not used in training runs of GPT, it offers an\nopportunity to test for domain shift and evaluate the generalizability of\ngenerative LLMs, which are predominantly designed and trained on data from\nhigh-income North American countries. We found that GPT-4, with minimal prompt\nengineering performed extremely well on evaluating the novel dataset (Quadratic\nWeighted Kappa 0.923, F1 0.88), substantially outperforming transfer-learning\nbased approaches, and even exceeding expert human raters (Quadratic Weighted\nKappa 0.915, F1 0.87). To the best of our knowledge, our work is the first to\nempirically evaluate the performance of generative LLMs on short-answer reading\ncomprehension questions, using real student data, and suggests that generative\nLLMs have the potential to reliably evaluate foundational literacy. Currently\nthe assessment of formative literacy and numeracy is infrequent in many low and\nmiddle-income countries (LMICs) due to the cost and operational complexities of\nconducting them at scale. Automating the grading process for reading assessment\ncould enable wider usage, and in turn improve decision-making regarding\ncurricula, school management, and teaching practice at the classroom level.\nImportantly, in contrast transfer learning based approaches, generative LLMs\ngeneralize well and the technical barriers to their use are low, making them\nmore feasible to implement and scale in lower resource educational contexts.",
            "author": [
                "Owen Henkel",
                "Libby Hills",
                "Bill Roberts",
                "Joshua McGrane"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18373v1",
                "http://arxiv.org/pdf/2310.18373v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17579v1",
            "title": "BLIS-Net: Classifying and Analyzing Signals on Graphs",
            "updated": "2023-10-26T17:03:14Z",
            "published": "2023-10-26T17:03:14Z",
            "summary": "Graph neural networks (GNNs) have emerged as a powerful tool for tasks such\nas node classification and graph classification. However, much less work has\nbeen done on signal classification, where the data consists of many functions\n(referred to as signals) defined on the vertices of a single graph. These tasks\nrequire networks designed differently from those designed for traditional GNN\ntasks. Indeed, traditional GNNs rely on localized low-pass filters, and signals\nof interest may have intricate multi-frequency behavior and exhibit long range\ninteractions. This motivates us to introduce the BLIS-Net (Bi-Lipschitz\nScattering Net), a novel GNN that builds on the previously introduced geometric\nscattering transform. Our network is able to capture both local and global\nsignal structure and is able to capture both low-frequency and high-frequency\ninformation. We make several crucial changes to the original geometric\nscattering architecture which we prove increase the ability of our network to\ncapture information about the input signal and show that BLIS-Net achieves\nsuperior performance on both synthetic and real-world data sets based on\ntraffic flow and fMRI data.",
            "author": [
                "Charles Xu",
                "Laney Goldman",
                "Valentina Guo",
                "Benjamin Hollander-Bodie",
                "Maedee Trank-Greene",
                "Ian Adelstein",
                "Edward De Brouwer",
                "Rex Ying",
                "Smita Krishnaswamy",
                "Michael Perlmutter"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17579v1",
                "http://arxiv.org/pdf/2310.17579v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17577v2",
            "title": "Global Structure-Aware Diffusion Process for Low-Light Image Enhancement",
            "updated": "2023-10-27T08:26:49Z",
            "published": "2023-10-26T17:01:52Z",
            "summary": "This paper studies a diffusion-based framework to address the low-light image\nenhancement problem. To harness the capabilities of diffusion models, we delve\ninto this intricate process and advocate for the regularization of its inherent\nODE-trajectory. To be specific, inspired by the recent research that low\ncurvature ODE-trajectory results in a stable and effective diffusion process,\nwe formulate a curvature regularization term anchored in the intrinsic\nnon-local structures of image data, i.e., global structure-aware\nregularization, which gradually facilitates the preservation of complicated\ndetails and the augmentation of contrast during the diffusion process. This\nincorporation mitigates the adverse effects of noise and artifacts resulting\nfrom the diffusion process, leading to a more precise and flexible enhancement.\nTo additionally promote learning in challenging regions, we introduce an\nuncertainty-guided regularization technique, which wisely relaxes constraints\non the most extreme regions of the image. Experimental evaluations reveal that\nthe proposed diffusion-based framework, complemented by rank-informed\nregularization, attains distinguished performance in low-light enhancement. The\noutcomes indicate substantial advancements in image quality, noise suppression,\nand contrast amplification in comparison with state-of-the-art methods. We\nbelieve this innovative approach will stimulate further exploration and\nadvancement in low-light image processing, with potential implications for\nother applications of diffusion models. The code is publicly available at\nhttps://github.com/jinnh/GSAD.",
            "author": [
                "Jinhui Hou",
                "Zhiyu Zhu",
                "Junhui Hou",
                "Hui Liu",
                "Huanqiang Zeng",
                "Hui Yuan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17577v2",
                "http://arxiv.org/pdf/2310.17577v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17571v1",
            "title": "Inside the black box: Neural network-based real-time prediction of US\n  recessions",
            "updated": "2023-10-26T16:58:16Z",
            "published": "2023-10-26T16:58:16Z",
            "summary": "Feedforward neural network (FFN) and two specific types of recurrent neural\nnetwork, long short-term memory (LSTM) and gated recurrent unit (GRU), are used\nfor modeling US recessions in the period from 1967 to 2021. The estimated\nmodels are then employed to conduct real-time predictions of the Great\nRecession and the Covid-19 recession in US. Their predictive performances are\ncompared to those of the traditional linear models, the logistic regression\nmodel both with and without the ridge penalty. The out-of-sample performance\nsuggests the application of LSTM and GRU in the area of recession forecasting,\nespecially for the long-term forecasting tasks. They outperform other types of\nmodels across 5 forecasting horizons with respect to different types of\nstatistical performance metrics. Shapley additive explanations (SHAP) method is\napplied to the fitted GRUs across different forecasting horizons to gain\ninsight into the feature importance. The evaluation of predictor importance\ndiffers between the GRU and ridge logistic regression models, as reflected in\nthe variable order determined by SHAP values. When considering the top 5\npredictors, key indicators such as the S\\&P 500 index, real GDP, and private\nresidential fixed investment consistently appear for short-term forecasts (up\nto 3 months). In contrast, for longer-term predictions (6 months or more), the\nterm spread and producer price index become more prominent. These findings are\nsupported by both local interpretable model-agnostic explanations (LIME) and\nmarginal effects.",
            "author": [
                "Seulki Chung"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17571v1",
                "http://arxiv.org/pdf/2310.17571v1"
            ],
            "primary_category": "econ.EM",
            "category": [
                "econ.EM",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17569v1",
            "title": "SD4Match: Learning to Prompt Stable Diffusion Model for Semantic\n  Matching",
            "updated": "2023-10-26T16:58:01Z",
            "published": "2023-10-26T16:58:01Z",
            "summary": "In this paper, we address the challenge of matching semantically similar\nkeypoints across image pairs. Existing research indicates that the intermediate\noutput of the UNet within the Stable Diffusion (SD) can serve as robust image\nfeature maps for such a matching task. We demonstrate that by employing a basic\nprompt tuning technique, the inherent potential of Stable Diffusion can be\nharnessed, resulting in a significant enhancement in accuracy over previous\napproaches. We further introduce a novel conditional prompting module that\nconditions the prompt on the local details of the input image pairs, leading to\na further improvement in performance. We designate our approach as SD4Match,\nshort for Stable Diffusion for Semantic Matching. Comprehensive evaluations of\nSD4Match on the PF-Pascal, PF-Willow, and SPair-71k datasets show that it sets\nnew benchmarks in accuracy across all these datasets. Particularly, SD4Match\noutperforms the previous state-of-the-art by a margin of 12 percentage points\non the challenging SPair-71k dataset.",
            "author": [
                "Xinghui Li",
                "Jingyi Lu",
                "Kai Han",
                "Victor Prisacariu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17569v1",
                "http://arxiv.org/pdf/2310.17569v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17567v1",
            "title": "Skill-Mix: a Flexible and Expandable Family of Evaluations for AI models",
            "updated": "2023-10-26T16:55:05Z",
            "published": "2023-10-26T16:55:05Z",
            "summary": "With LLMs shifting their role from statistical modeling of language to\nserving as general-purpose AI agents, how should LLM evaluations change?\nArguably, a key ability of an AI agent is to flexibly combine, as needed, the\nbasic skills it has learned. The capability to combine skills plays an\nimportant role in (human) pedagogy and also in a paper on emergence phenomena\n(Arora & Goyal, 2023).\n  This work introduces Skill-Mix, a new evaluation to measure ability to\ncombine skills. Using a list of $N$ skills the evaluator repeatedly picks\nrandom subsets of $k$ skills and asks the LLM to produce text combining that\nsubset of skills. Since the number of subsets grows like $N^k$, for even modest\n$k$ this evaluation will, with high probability, require the LLM to produce\ntext significantly different from any text in the training set. The paper\ndevelops a methodology for (a) designing and administering such an evaluation,\nand (b) automatic grading (plus spot-checking by humans) of the results using\nGPT-4 as well as the open LLaMA-2 70B model.\n  Administering a version of to popular chatbots gave results that, while\ngenerally in line with prior expectations, contained surprises. Sizeable\ndifferences exist among model capabilities that are not captured by their\nranking on popular LLM leaderboards (\"cramming for the leaderboard\").\nFurthermore, simple probability calculations indicate that GPT-4's reasonable\nperformance on $k=5$ is suggestive of going beyond \"stochastic parrot\" behavior\n(Bender et al., 2021), i.e., it combines skills in ways that it had not seen\nduring training.\n  We sketch how the methodology can lead to a Skill-Mix based eco-system of\nopen evaluations for AI capabilities of future models.",
            "author": [
                "Dingli Yu",
                "Simran Kaur",
                "Arushi Gupta",
                "Jonah Brown-Cohen",
                "Anirudh Goyal",
                "Sanjeev Arora"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17567v1",
                "http://arxiv.org/pdf/2310.17567v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17561v1",
            "title": "Bifurcations and loss jumps in RNN training",
            "updated": "2023-10-26T16:49:44Z",
            "published": "2023-10-26T16:49:44Z",
            "summary": "Recurrent neural networks (RNNs) are popular machine learning tools for\nmodeling and forecasting sequential data and for inferring dynamical systems\n(DS) from observed time series. Concepts from DS theory (DST) have variously\nbeen used to further our understanding of both, how trained RNNs solve complex\ntasks, and the training process itself. Bifurcations are particularly important\nphenomena in DS, including RNNs, that refer to topological (qualitative)\nchanges in a system's dynamical behavior as one or more of its parameters are\nvaried. Knowing the bifurcation structure of an RNN will thus allow to deduce\nmany of its computational and dynamical properties, like its sensitivity to\nparameter variations or its behavior during training. In particular,\nbifurcations may account for sudden loss jumps observed in RNN training that\ncould severely impede the training process. Here we first mathematically prove\nfor a particular class of ReLU-based RNNs that certain bifurcations are indeed\nassociated with loss gradients tending toward infinity or zero. We then\nintroduce a novel heuristic algorithm for detecting all fixed points and\nk-cycles in ReLU-based RNNs and their existence and stability regions, hence\nbifurcation manifolds in parameter space. In contrast to previous numerical\nalgorithms for finding fixed points and common continuation methods, our\nalgorithm provides exact results and returns fixed points and cycles up to high\norders with surprisingly good scaling behavior. We exemplify the algorithm on\nthe analysis of the training process of RNNs, and find that the recently\nintroduced technique of generalized teacher forcing completely avoids certain\ntypes of bifurcations in training. Thus, besides facilitating the DST analysis\nof trained RNNs, our algorithm provides a powerful instrument for analyzing the\ntraining process itself.",
            "author": [
                "Lukas Eisenmann",
                "Zahra Monfared",
                "Niclas Alexander G\u00f6ring",
                "Daniel Durstewitz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17561v1",
                "http://arxiv.org/pdf/2310.17561v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17559v1",
            "title": "Instability of computer vision models is a necessary result of the task\n  itself",
            "updated": "2023-10-26T16:48:36Z",
            "published": "2023-10-26T16:48:36Z",
            "summary": "Adversarial examples resulting from instability of current computer vision\nmodels are an extremely important topic due to their potential to compromise\nany application. In this paper we demonstrate that instability is inevitable\ndue to a) symmetries (translational invariance) of the data, b) the categorical\nnature of the classification task, and c) the fundamental discrepancy of\nclassifying images as objects themselves. The issue is further exacerbated by\nnon-exhaustive labelling of the training data. Therefore we conclude that\ninstability is a necessary result of how the problem of computer vision is\ncurrently formulated. While the problem cannot be eliminated, through the\nanalysis of the causes, we have arrived at ways how it can be partially\nalleviated. These include i) increasing the resolution of images, ii) providing\ncontextual information for the image, iii) exhaustive labelling of training\ndata, and iv) preventing attackers from frequent access to the computer vision\nsystem.",
            "author": [
                "Oliver Turnbull",
                "George Cevora"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17559v1",
                "http://arxiv.org/pdf/2310.17559v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17558v1",
            "title": "Towards Matching Phones and Speech Representations",
            "updated": "2023-10-26T16:47:52Z",
            "published": "2023-10-26T16:47:52Z",
            "summary": "Learning phone types from phone instances has been a long-standing problem,\nwhile still being open. In this work, we revisit this problem in the context of\nself-supervised learning, and pose it as the problem of matching cluster\ncentroids to phone embeddings. We study two key properties that enable\nmatching, namely, whether cluster centroids of self-supervised representations\nreduce the variability of phone instances and respect the relationship among\nphones. We then use the matching result to produce pseudo-labels and introduce\na new loss function for improving self-supervised representations. Our\nexperiments show that the matching result captures the relationship among\nphones. Training the new loss function jointly with the regular self-supervised\nlosses, such as APC and CPC, significantly improves the downstream phone\nclassification.",
            "author": [
                "Gene-Ping Yang",
                "Hao Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17558v1",
                "http://arxiv.org/pdf/2310.17558v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17556v1",
            "title": "Efficient Numerical Algorithm for Large-Scale Damped Natural Gradient\n  Descent",
            "updated": "2023-10-26T16:46:13Z",
            "published": "2023-10-26T16:46:13Z",
            "summary": "We propose a new algorithm for efficiently solving the damped Fisher matrix\nin large-scale scenarios where the number of parameters significantly exceeds\nthe number of available samples. This problem is fundamental for natural\ngradient descent and stochastic reconfiguration. Our algorithm is based on\nCholesky decomposition and is generally applicable. Benchmark results show that\nthe algorithm is significantly faster than existing methods.",
            "author": [
                "Yixiao Chen",
                "Hao Xie",
                "Han Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17556v1",
                "http://arxiv.org/pdf/2310.17556v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17555v1",
            "title": "Interactive Robot Learning from Verbal Correction",
            "updated": "2023-10-26T16:46:12Z",
            "published": "2023-10-26T16:46:12Z",
            "summary": "The ability to learn and refine behavior after deployment has become ever\nmore important for robots as we design them to operate in unstructured\nenvironments like households. In this work, we design a new learning system\nbased on large language model (LLM), OLAF, that allows everyday users to teach\na robot using verbal corrections when the robot makes mistakes, e.g., by saying\n\"Stop what you're doing. You should move closer to the cup.\" A key feature of\nOLAF is its ability to update the robot's visuomotor neural policy based on the\nverbal feedback to avoid repeating mistakes in the future. This is in contrast\nto existing LLM-based robotic systems, which only follow verbal commands or\ncorrections but not learn from them. We demonstrate the efficacy of our design\nin experiments where a user teaches a robot to perform long-horizon\nmanipulation tasks both in simulation and on physical hardware, achieving on\naverage 20.0% improvement in policy success rate. Videos and more results are\nat https://ut-austin-rpl.github.io/olaf/",
            "author": [
                "Huihan Liu",
                "Alice Chen",
                "Yuke Zhu",
                "Adith Swaminathan",
                "Andrey Kolobov",
                "Ching-An Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17555v1",
                "http://arxiv.org/pdf/2310.17555v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17552v1",
            "title": "Model-Based Runtime Monitoring with Interactive Imitation Learning",
            "updated": "2023-10-26T16:45:44Z",
            "published": "2023-10-26T16:45:44Z",
            "summary": "Robot learning methods have recently made great strides, but generalization\nand robustness challenges still hinder their widespread deployment. Failing to\ndetect and address potential failures renders state-of-the-art learning systems\nnot combat-ready for high-stakes tasks. Recent advances in interactive\nimitation learning have presented a promising framework for human-robot\nteaming, enabling the robots to operate safely and continually improve their\nperformances over long-term deployments. Nonetheless, existing methods\ntypically require constant human supervision and preemptive feedback, limiting\ntheir practicality in realistic domains. This work aims to endow a robot with\nthe ability to monitor and detect errors during task execution. We introduce a\nmodel-based runtime monitoring algorithm that learns from deployment data to\ndetect system anomalies and anticipate failures. Unlike prior work that cannot\nforesee future failures or requires failure experiences for training, our\nmethod learns a latent-space dynamics model and a failure classifier, enabling\nour method to simulate future action outcomes and detect out-of-distribution\nand high-risk states preemptively. We train our method within an interactive\nimitation learning framework, where it continually updates the model from the\nexperiences of the human-robot team collected using trustworthy deployments.\nConsequently, our method reduces the human workload needed over time while\nensuring reliable task execution. Our method outperforms the baselines across\nsystem-level and unit-test metrics, with 23% and 40% higher success rates in\nsimulation and on physical hardware, respectively. More information at\nhttps://ut-austin-rpl.github.io/sirius-runtime-monitor/",
            "author": [
                "Huihan Liu",
                "Shivin Dass",
                "Roberto Mart\u00edn-Mart\u00edn",
                "Yuke Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17552v1",
                "http://arxiv.org/pdf/2310.17552v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17550v2",
            "title": "Human-Guided Complexity-Controlled Abstractions",
            "updated": "2023-10-27T14:31:25Z",
            "published": "2023-10-26T16:45:34Z",
            "summary": "Neural networks often learn task-specific latent representations that fail to\ngeneralize to novel settings or tasks. Conversely, humans learn discrete\nrepresentations (i.e., concepts or words) at a variety of abstraction levels\n(e.g., \"bird\" vs. \"sparrow\") and deploy the appropriate abstraction based on\ntask. Inspired by this, we train neural models to generate a spectrum of\ndiscrete representations, and control the complexity of the representations\n(roughly, how many bits are allocated for encoding inputs) by tuning the\nentropy of the distribution over representations. In finetuning experiments,\nusing only a small number of labeled examples for a new task, we show that (1)\ntuning the representation to a task-appropriate complexity level supports the\nhighest finetuning performance, and (2) in a human-participant study, users\nwere able to identify the appropriate complexity level for a downstream task\nusing visualizations of discrete representations. Our results indicate a\npromising direction for rapid model finetuning by leveraging human insight.",
            "author": [
                "Andi Peng",
                "Mycal Tucker",
                "Eoin Kenny",
                "Noga Zaslavsky",
                "Pulkit Agrawal",
                "Julie Shah"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17550v2",
                "http://arxiv.org/pdf/2310.17550v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17545v1",
            "title": "Using Buckingham's $\u03c0$ Theorem for Multi-System Learning Transfer: a\n  Case-study with 3 Vehicles Sharing a Database",
            "updated": "2023-10-26T16:42:13Z",
            "published": "2023-10-26T16:42:13Z",
            "summary": "Learning schemes for planning and control are limited by the difficulty of\ncollecting large amounts of experimental data or having to rely on\nhigh-fidelity simulations. This paper explores the potential of a proposed\nlearning scheme that leverages dimensionless numbers based on Buckingham's\n$\\pi$ theorem to improve data efficiency and facilitate knowledge sharing\nbetween similar systems. A case study using car-like robots compares\ntraditional and dimensionless learning models on simulated and experimental\ndata to validate the benefits of the new dimensionless learning approach.\nPreliminary results show that this new dimensionless approach could accelerate\nthe learning rate and improve the accuracy of the model and should be\ninvestigated further.",
            "author": [
                "William Therrien",
                "Olivier Lecompte",
                "Alexandre Girard"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17545v1",
                "http://arxiv.org/pdf/2310.17545v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17544v1",
            "title": "Hierarchical Ensemble-Based Feature Selection for Time Series\n  Forecasting",
            "updated": "2023-10-26T16:40:09Z",
            "published": "2023-10-26T16:40:09Z",
            "summary": "We study a novel ensemble approach for feature selection based on\nhierarchical stacking in cases of non-stationarity and limited number of\nsamples with large number of features. Our approach exploits the co-dependency\nbetween features using a hierarchical structure. Initially, a machine learning\nmodel is trained using a subset of features, and then the model's output is\nupdated using another algorithm with the remaining features to minimize the\ntarget loss. This hierarchical structure allows for flexible depth and feature\nselection. By exploiting feature co-dependency hierarchically, our proposed\napproach overcomes the limitations of traditional feature selection methods and\nfeature importance scores. The effectiveness of the approach is demonstrated on\nsynthetic and real-life datasets, indicating improved performance with\nscalability and stability compared to the traditional methods and\nstate-of-the-art approaches.",
            "author": [
                "Aysin Tumay",
                "Mustafa E. Aydin",
                "Suleyman S. Kozat"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17544v1",
                "http://arxiv.org/pdf/2310.17544v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17540v1",
            "title": "EqDrive: Efficient Equivariant Motion Forecasting with Multi-Modality\n  for Autonomous Driving",
            "updated": "2023-10-26T16:32:34Z",
            "published": "2023-10-26T16:32:34Z",
            "summary": "Forecasting vehicular motions in autonomous driving requires a deep\nunderstanding of agent interactions and the preservation of motion equivariance\nunder Euclidean geometric transformations. Traditional models often lack the\nsophistication needed to handle the intricate dynamics inherent to autonomous\nvehicles and the interaction relationships among agents in the scene. As a\nresult, these models have a lower model capacity, which then leads to higher\nprediction errors and lower training efficiency. In our research, we employ\nEqMotion, a leading equivariant particle, and human prediction model that also\naccounts for invariant agent interactions, for the task of multi-agent vehicle\nmotion forecasting. In addition, we use a multi-modal prediction mechanism to\naccount for multiple possible future paths in a probabilistic manner. By\nleveraging EqMotion, our model achieves state-of-the-art (SOTA) performance\nwith fewer parameters (1.2 million) and a significantly reduced training time\n(less than 2 hours).",
            "author": [
                "Yuping Wang",
                "Jier Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17540v1",
                "http://arxiv.org/pdf/2310.17540v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17538v1",
            "title": "Little Exploration is All You Need",
            "updated": "2023-10-26T16:28:29Z",
            "published": "2023-10-26T16:28:29Z",
            "summary": "The prevailing principle of \"Optimism in the Face of Uncertainty\" advocates\nfor the incorporation of an exploration bonus, generally assumed to be\nproportional to the inverse square root of the visit count ($1/\\sqrt{n}$),\nwhere $n$ is the number of visits to a particular state-action pair. This\napproach, however, exclusively focuses on \"uncertainty,\" neglecting the\ninherent \"difficulty\" of different options. To address this gap, we introduce a\nnovel modification of standard UCB algorithm in the multi-armed bandit problem,\nproposing an adjusted bonus term of $1/n^\\tau$, where $\\tau > 1/2$, that\naccounts for task difficulty. Our proposed algorithm, denoted as UCB$^\\tau$, is\nsubstantiated through comprehensive regret and risk analyses, confirming its\ntheoretical robustness. Comparative evaluations with standard UCB and Thompson\nSampling algorithms on synthetic datasets demonstrate that UCB$^\\tau$ not only\noutperforms in efficacy but also exhibits lower risk across various\nenvironmental conditions and hyperparameter settings.",
            "author": [
                "Henry H. H. Chen",
                "Jiaming Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17538v1",
                "http://arxiv.org/pdf/2310.17538v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17537v1",
            "title": "Neuro-Inspired Fragmentation and Recall to Overcome Catastrophic\n  Forgetting in Curiosity",
            "updated": "2023-10-26T16:28:17Z",
            "published": "2023-10-26T16:28:17Z",
            "summary": "Deep reinforcement learning methods exhibit impressive performance on a range\nof tasks but still struggle on hard exploration tasks in large environments\nwith sparse rewards. To address this, intrinsic rewards can be generated using\nforward model prediction errors that decrease as the environment becomes known,\nand incentivize an agent to explore novel states. While prediction-based\nintrinsic rewards can help agents solve hard exploration tasks, they can suffer\nfrom catastrophic forgetting and actually increase at visited states. We first\nexamine the conditions and causes of catastrophic forgetting in grid world\nenvironments. We then propose a new method FARCuriosity, inspired by how humans\nand animals learn. The method depends on fragmentation and recall: an agent\nfragments an environment based on surprisal, and uses different local curiosity\nmodules (prediction-based intrinsic reward functions) for each fragment so that\nmodules are not trained on the entire environment. At each fragmentation event,\nthe agent stores the current module in long-term memory (LTM) and either\ninitializes a new module or recalls a previously stored module based on its\nmatch with the current state. With fragmentation and recall, FARCuriosity\nachieves less forgetting and better overall performance in games with varied\nand heterogeneous environments in the Atari benchmark suite of tasks. Thus,\nthis work highlights the problem of catastrophic forgetting in prediction-based\ncuriosity methods and proposes a solution.",
            "author": [
                "Jaedong Hwang",
                "Zhang-Wei Hong",
                "Eric Chen",
                "Akhilan Boopathy",
                "Pulkit Agrawal",
                "Ila Fiete"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17537v1",
                "http://arxiv.org/pdf/2310.17537v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17534v1",
            "title": "SoK: Pitfalls in Evaluating Black-Box Attacks",
            "updated": "2023-10-26T16:23:40Z",
            "published": "2023-10-26T16:23:40Z",
            "summary": "Numerous works study black-box attacks on image classifiers. However, these\nworks make different assumptions on the adversary's knowledge and current\nliterature lacks a cohesive organization centered around the threat model. To\nsystematize knowledge in this area, we propose a taxonomy over the threat space\nspanning the axes of feedback granularity, the access of interactive queries,\nand the quality and quantity of the auxiliary data available to the attacker.\nOur new taxonomy provides three key insights. 1) Despite extensive literature,\nnumerous under-explored threat spaces exist, which cannot be trivially solved\nby adapting techniques from well-explored settings. We demonstrate this by\nestablishing a new state-of-the-art in the less-studied setting of access to\ntop-k confidence scores by adapting techniques from well-explored settings of\naccessing the complete confidence vector, but show how it still falls short of\nthe more restrictive setting that only obtains the prediction label,\nhighlighting the need for more research. 2) Identification the threat model of\ndifferent attacks uncovers stronger baselines that challenge prior\nstate-of-the-art claims. We demonstrate this by enhancing an initially weaker\nbaseline (under interactive query access) via surrogate models, effectively\noverturning claims in the respective paper. 3) Our taxonomy reveals\ninteractions between attacker knowledge that connect well to related areas,\nsuch as model inversion and extraction attacks. We discuss how advances in\nother areas can enable potentially stronger black-box attacks. Finally, we\nemphasize the need for a more realistic assessment of attack success by\nfactoring in local attack runtime. This approach reveals the potential for\ncertain attacks to achieve notably higher success rates and the need to\nevaluate attacks in diverse and harder settings, highlighting the need for\nbetter selection criteria.",
            "author": [
                "Fnu Suya",
                "Anshuman Suri",
                "Tingwei Zhang",
                "Jingtao Hong",
                "Yuan Tian",
                "David Evans"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17534v1",
                "http://arxiv.org/pdf/2310.17534v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17531v1",
            "title": "Learning Regularized Graphon Mean-Field Games with Unknown Graphons",
            "updated": "2023-10-26T16:19:24Z",
            "published": "2023-10-26T16:19:24Z",
            "summary": "We design and analyze reinforcement learning algorithms for Graphon\nMean-Field Games (GMFGs). In contrast to previous works that require the\nprecise values of the graphons, we aim to learn the Nash Equilibrium (NE) of\nthe regularized GMFGs when the graphons are unknown. Our contributions are\nthreefold. First, we propose the Proximal Policy Optimization for GMFG\n(GMFG-PPO) algorithm and show that it converges at a rate of $O(T^{-1/3})$\nafter $T$ iterations with an estimation oracle, improving on a previous work by\nXie et al. (ICML, 2021). Second, using kernel embedding of distributions, we\ndesign efficient algorithms to estimate the transition kernels, reward\nfunctions, and graphons from sampled agents. Convergence rates are then derived\nwhen the positions of the agents are either known or unknown. Results for the\ncombination of the optimization algorithm GMFG-PPO and the estimation algorithm\nare then provided. These algorithms are the first specifically designed for\nlearning graphons from sampled agents. Finally, the efficacy of the proposed\nalgorithms are corroborated through simulations. These simulations demonstrate\nthat learning the unknown graphons reduces the exploitability effectively.",
            "author": [
                "Fengzhuo Zhang",
                "Vincent Y. F. Tan",
                "Zhaoran Wang",
                "Zhuoran Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17531v1",
                "http://arxiv.org/pdf/2310.17531v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17530v1",
            "title": "Evaluating Bias and Fairness in Gender-Neutral Pretrained\n  Vision-and-Language Models",
            "updated": "2023-10-26T16:19:19Z",
            "published": "2023-10-26T16:19:19Z",
            "summary": "Pretrained machine learning models are known to perpetuate and even amplify\nexisting biases in data, which can result in unfair outcomes that ultimately\nimpact user experience. Therefore, it is crucial to understand the mechanisms\nbehind those prejudicial biases to ensure that model performance does not\nresult in discriminatory behaviour toward certain groups or populations. In\nthis work, we define gender bias as our case study. We quantify bias\namplification in pretraining and after fine-tuning on three families of\nvision-and-language models. We investigate the connection, if any, between the\ntwo learning stages, and evaluate how bias amplification reflects on model\nperformance. Overall, we find that bias amplification in pretraining and after\nfine-tuning are independent. We then examine the effect of continued\npretraining on gender-neutral data, finding that this reduces group\ndisparities, i.e., promotes fairness, on VQAv2 and retrieval tasks without\nsignificantly compromising task performance.",
            "author": [
                "Laura Cabello",
                "Emanuele Bugliarello",
                "Stephanie Brandl",
                "Desmond Elliott"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17530v1",
                "http://arxiv.org/pdf/2310.17530v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17526v2",
            "title": "Can large language models replace humans in the systematic review\n  process? Evaluating GPT-4's efficacy in screening and extracting data from\n  peer-reviewed and grey literature in multiple languages",
            "updated": "2023-10-27T12:14:27Z",
            "published": "2023-10-26T16:18:30Z",
            "summary": "Systematic reviews are vital for guiding practice, research, and policy, yet\nthey are often slow and labour-intensive. Large language models (LLMs) could\noffer a way to speed up and automate systematic reviews, but their performance\nin such tasks has not been comprehensively evaluated against humans, and no\nstudy has tested GPT-4, the biggest LLM so far. This pre-registered study\nevaluates GPT-4's capability in title/abstract screening, full-text review, and\ndata extraction across various literature types and languages using a\n'human-out-of-the-loop' approach. Although GPT-4 had accuracy on par with human\nperformance in most tasks, results were skewed by chance agreement and dataset\nimbalance. After adjusting for these, there was a moderate level of performance\nfor data extraction, and - barring studies that used highly reliable prompts -\nscreening performance levelled at none to moderate for different stages and\nlanguages. When screening full-text literature using highly reliable prompts,\nGPT-4's performance was 'almost perfect.' Penalising GPT-4 for missing key\nstudies using highly reliable prompts improved its performance even more. Our\nfindings indicate that, currently, substantial caution should be used if LLMs\nare being used to conduct systematic reviews, but suggest that, for certain\nsystematic review tasks delivered under reliable prompts, LLMs can rival human\nperformance.",
            "author": [
                "Qusai Khraisha",
                "Sophie Put",
                "Johanna Kappenberg",
                "Azza Warraitch",
                "Kristin Hadfield"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17526v2",
                "http://arxiv.org/pdf/2310.17526v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17525v1",
            "title": "Measuring Wigner functions of quantum states of light in the\n  undergraduate laboratory",
            "updated": "2023-10-26T16:17:54Z",
            "published": "2023-10-26T16:17:54Z",
            "summary": "In this work, we present an educational activity aimed at measuring the\nWigner distribution functions of quantum states of light in the undergraduate\nlaboratory. This project was conceived by students from various courses within\nthe physics undergraduate curriculum, and its outcomes were used in an\nintroductory Quantum Optics course at the Universidad de los Andes in Bogot\\'a,\nColombia. The activity entails a two-hour laboratory practice in which students\nengage with a pre-aligned experimental setup. They subsequently employ an\nopen-access, custom-made computational graphical user interface to reconstruct\nthe Wigner distribution function for various quantum states of light. Given\nthat the testing phase coincided with the COVID-19 pandemic, we incorporated\nthe capacity to analyze simulated data into the computational user interface.\nThe activity is now part of the course syllabus and its virtual component has\nproven to be highly valuable for the implementation of distance learning in\nquantum optics.",
            "author": [
                "Juan-Rafael \u00c1lvarez",
                "Andr\u00e9s Mart\u00ednez Silva",
                "Alejandra Valencia"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17525v1",
                "http://arxiv.org/pdf/2310.17525v1"
            ],
            "primary_category": "physics.ed-ph",
            "category": [
                "physics.ed-ph",
                "physics.optics",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17523v2",
            "title": "Adaptive Resource Management for Edge Network Slicing using Incremental\n  Multi-Agent Deep Reinforcement Learning",
            "updated": "2023-10-27T09:13:06Z",
            "published": "2023-10-26T16:16:08Z",
            "summary": "Multi-access edge computing provides local resources in mobile networks as\nthe essential means for meeting the demands of emerging ultra-reliable\nlow-latency communications. At the edge, dynamic computing requests require\nadvanced resource management for adaptive network slicing, including resource\nallocations, function scaling and load balancing to utilize only the necessary\nresources in resource-constraint networks. Recent solutions are designed for a\nstatic number of slices. Therefore, the painful process of optimization is\nrequired again with any update on the number of slices. In addition, these\nsolutions intend to maximize instant rewards, neglecting long-term resource\nscheduling. Unlike these efforts, we propose an algorithmic approach based on\nmulti-agent deep deterministic policy gradient (MADDPG) for optimizing resource\nmanagement for edge network slicing. Our objective is two-fold: (i) maximizing\nlong-term network slicing benefits in terms of delay and energy consumption,\nand (ii) adapting to slice number changes. Through simulations, we demonstrate\nthat MADDPG outperforms benchmark solutions including a static slicing-based\none from the literature, achieving stable and high long-term performance.\nAdditionally, we leverage incremental learning to facilitate a dynamic number\nof edge slices, with enhanced performance compared to pre-trained base models.\nRemarkably, this approach yields superior reward performance while saving\napproximately 90% of training time costs.",
            "author": [
                "Haiyuan Li",
                "Yuelin Liu",
                "Xueqing Zhou",
                "Xenofon Vasilakos",
                "Reza Nejabati",
                "Shuangyi Yan",
                "Dimitra Simeonidou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17523v2",
                "http://arxiv.org/pdf/2310.17523v2"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17519v2",
            "title": "FLARE: Fast Learning of Animatable and Relightable Mesh Avatars",
            "updated": "2023-10-27T09:11:32Z",
            "published": "2023-10-26T16:13:00Z",
            "summary": "Our goal is to efficiently learn personalized animatable 3D head avatars from\nvideos that are geometrically accurate, realistic, relightable, and compatible\nwith current rendering systems. While 3D meshes enable efficient processing and\nare highly portable, they lack realism in terms of shape and appearance. Neural\nrepresentations, on the other hand, are realistic but lack compatibility and\nare slow to train and render. Our key insight is that it is possible to\nefficiently learn high-fidelity 3D mesh representations via differentiable\nrendering by exploiting highly-optimized methods from traditional computer\ngraphics and approximating some of the components with neural networks. To that\nend, we introduce FLARE, a technique that enables the creation of animatable\nand relightable mesh avatars from a single monocular video. First, we learn a\ncanonical geometry using a mesh representation, enabling efficient\ndifferentiable rasterization and straightforward animation via learned\nblendshapes and linear blend skinning weights. Second, we follow\nphysically-based rendering and factor observed colors into intrinsic albedo,\nroughness, and a neural representation of the illumination, allowing the\nlearned avatars to be relit in novel scenes. Since our input videos are\ncaptured on a single device with a narrow field of view, modeling the\nsurrounding environment light is non-trivial. Based on the split-sum\napproximation for modeling specular reflections, we address this by\napproximating the pre-filtered environment map with a multi-layer perceptron\n(MLP) modulated by the surface roughness, eliminating the need to explicitly\nmodel the light. We demonstrate that our mesh-based avatar formulation,\ncombined with learned deformation, material, and lighting MLPs, produces\navatars with high-quality geometry and appearance, while also being efficient\nto train and render compared to existing approaches.",
            "author": [
                "Shrisha Bharadwaj",
                "Yufeng Zheng",
                "Otmar Hilliges",
                "Michael J. Black",
                "Victoria Fernandez-Abrevaya"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3618401",
                "http://arxiv.org/abs/2310.17519v2",
                "http://arxiv.org/pdf/2310.17519v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17516v1",
            "title": "Crashing with disorder: Reaching the precision limit with tensor-based\n  wavefront shaping",
            "updated": "2023-10-26T16:12:08Z",
            "published": "2023-10-26T16:12:08Z",
            "summary": "Perturbations in complex media, due to their own dynamical evolution or to\nexternal effects, are often seen as detrimental. Therefore, a common strategy,\nespecially for telecommunication and imaging applications, is to limit the\nsensitivity to those perturbations in order to avoid them. Here, we instead\nconsider crashing straight into them in order to maximize the interaction\nbetween light and the perturbations and thus produce the largest change in\noutput intensity. Our work hinges on the innovative use of tensor-based\ntechniques, presently at the forefront of machine learning explorations, to\nstudy intensity-based measurements where its quadratic relationship to the\nfield prevents the use of standard matrix methods. With this tensor-based\nframework, we are able to identify the optimal crashing channel which maximizes\nthe change in its output intensity distribution and the Fisher information\nencoded in it about a given perturbation. We further demonstrate experimentally\nits superiority for robust and precise sensing applications. Additionally, we\nderive the appropriate strategy to reach the precision limit for\nintensity-based measurements leading to an increase in Fisher information by\nmore than four orders of magnitude with respect to the mean for random\nwavefronts when measured with the pixels of a camera.",
            "author": [
                "Rodrigo Guti\u00e9rrez-Cuevas",
                "Dorian Bouchet",
                "Julien de Rosny",
                "S\u00e9bastien M. Popoff"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17516v1",
                "http://arxiv.org/pdf/2310.17516v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17513v2",
            "title": "The Expressive Power of Low-Rank Adaptation",
            "updated": "2023-10-27T02:36:44Z",
            "published": "2023-10-26T16:08:33Z",
            "summary": "Low-Rank Adaptation (LoRA), a parameter-efficient fine-tuning method that\nleverages low-rank adaptation of weight matrices, has emerged as a prevalent\ntechnique for fine-tuning pre-trained models such as large language models and\ndiffusion models. Despite its huge success in practice, the theoretical\nunderpinnings of LoRA have largely remained unexplored. This paper takes the\nfirst step to bridge this gap by theoretically analyzing the expressive power\nof LoRA. We prove that, for fully connected neural networks, LoRA can adapt any\nmodel $f$ to accurately represent any smaller target model $\\overline{f}$ if\nLoRA-rank $\\geq(\\text{width of }f) \\times \\frac{\\text{depth of\n}\\overline{f}}{\\text{depth of }f}$. We also quantify the approximation error\nwhen LoRA-rank is lower than the threshold. For Transformer networks, we show\nany model can be adapted to a target model of the same size with\nrank-$(\\frac{\\text{embedding size}}{2})$ LoRA adapters.",
            "author": [
                "Yuchen Zeng",
                "Kangwook Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17513v2",
                "http://arxiv.org/pdf/2310.17513v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17512v1",
            "title": "CompeteAI: Understanding the Competition Behaviors in Large Language\n  Model-based Agents",
            "updated": "2023-10-26T16:06:20Z",
            "published": "2023-10-26T16:06:20Z",
            "summary": "Large language models (LLMs) have been widely used as agents to complete\ndifferent tasks, such as personal assistance or event planning. While most work\nhas focused on cooperation and collaboration between agents, little work\nexplores competition, another important mechanism that fosters the development\nof society and economy. In this paper, we seek to examine the competition\nbehaviors in LLM-based agents. We first propose a general framework to study\nthe competition between agents. Then, we implement a practical competitive\nenvironment using GPT-4 to simulate a virtual town with two types of agents,\nincluding restaurant agents and customer agents. Specifically, restaurant\nagents compete with each other to attract more customers, where the competition\nfosters them to transform, such as cultivating new operating strategies. The\nresults of our experiments reveal several interesting findings ranging from\nsocial learning to Matthew Effect, which aligns well with existing sociological\nand economic theories. We believe that competition between agents deserves\nfurther investigation to help us understand society better. The code will be\nreleased soon.",
            "author": [
                "Qinlin Zhao",
                "Jindong Wang",
                "Yixuan Zhang",
                "Yiqiao Jin",
                "Kaijie Zhu",
                "Hao Chen",
                "Xing Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17512v1",
                "http://arxiv.org/pdf/2310.17512v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.HC",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17506v1",
            "title": "Predicting Patient No-Shows in Community Health Clinics: A Case Study in\n  Designing a Data Analytic Product",
            "updated": "2023-10-26T15:56:43Z",
            "published": "2023-10-26T15:56:43Z",
            "summary": "The data science revolution has highlighted the varying roles that data\nanalytic products can play in a different industries and applications. There\nhas been particular interest in using analytic products coupled with\nalgorithmic prediction models to aid in human decision-making. However,\ndetailed descriptions of the decision-making process that leads to the design\nand development of analytic products are lacking in the statistical literature,\nmaking it difficult to accumulate a body of knowledge where students interested\nin the field of data science may look to learn about this process. In this\npaper, we present a case study describing the development of an analytic\nproduct for predicting whether patients will show up for scheduled appointments\nat a community health clinic. We consider the stakeholders involved and their\ninterests, along with the real-world analytical and technical trade-offs\ninvolved in developing and deploying the product. Our goal here is to highlight\nthe decisions made and evaluate them in the context of possible alternatives.\nWe find that although this case study has some unique characteristics, there\nare lessons to be learned that could translate to other settings and\napplications.",
            "author": [
                "Roger D. Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17506v1",
                "http://arxiv.org/pdf/2310.17506v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17502v1",
            "title": "Controllable Generation of Artificial Speaker Embeddings through\n  Discovery of Principal Directions",
            "updated": "2023-10-26T15:54:12Z",
            "published": "2023-10-26T15:54:12Z",
            "summary": "Customizing voice and speaking style in a speech synthesis system with\nintuitive and fine-grained controls is challenging, given that little data with\nappropriate labels is available. Furthermore, editing an existing human's voice\nalso comes with ethical concerns. In this paper, we propose a method to\ngenerate artificial speaker embeddings that cannot be linked to a real human\nwhile offering intuitive and fine-grained control over the voice and speaking\nstyle of the embeddings, without requiring any labels for speaker or style. The\nartificial and controllable embeddings can be fed to a speech synthesis system,\nconditioned on embeddings of real humans during training, without sacrificing\nprivacy during inference.",
            "author": [
                "Florian Lux",
                "Pascal Tilli",
                "Sarina Meyer",
                "Ngoc Thang Vu"
            ],
            "link": [
                "http://dx.doi.org/10.21437/Interspeech.2023-858",
                "http://arxiv.org/abs/2310.17502v1",
                "http://arxiv.org/pdf/2310.17502v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17499v1",
            "title": "The IMS Toucan System for the Blizzard Challenge 2023",
            "updated": "2023-10-26T15:53:29Z",
            "published": "2023-10-26T15:53:29Z",
            "summary": "For our contribution to the Blizzard Challenge 2023, we improved on the\nsystem we submitted to the Blizzard Challenge 2021. Our approach entails a\nrule-based text-to-phoneme processing system that includes rule-based\ndisambiguation of homographs in the French language. It then transforms the\nphonemes to spectrograms as intermediate representations using a fast and\nefficient non-autoregressive synthesis architecture based on Conformer and\nGlow. A GAN based neural vocoder that combines recent state-of-the-art\napproaches converts the spectrogram to the final wave. We carefully designed\nthe data processing, training, and inference procedures for the challenge data.\nOur system identifier is G. Open source code and demo are available.",
            "author": [
                "Florian Lux",
                "Julia Koch",
                "Sarina Meyer",
                "Thomas Bott",
                "Nadja Schauffler",
                "Pavel Denisov",
                "Antje Schweitzer",
                "Ngoc Thang Vu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17499v1",
                "http://arxiv.org/pdf/2310.17499v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17498v1",
            "title": "CBD: A Certified Backdoor Detector Based on Local Dominant Probability",
            "updated": "2023-10-26T15:53:18Z",
            "published": "2023-10-26T15:53:18Z",
            "summary": "Backdoor attack is a common threat to deep neural networks. During testing,\nsamples embedded with a backdoor trigger will be misclassified as an\nadversarial target by a backdoored model, while samples without the backdoor\ntrigger will be correctly classified. In this paper, we present the first\ncertified backdoor detector (CBD), which is based on a novel, adjustable\nconformal prediction scheme based on our proposed statistic local dominant\nprobability. For any classifier under inspection, CBD provides 1) a detection\ninference, 2) the condition under which the attacks are guaranteed to be\ndetectable for the same classification domain, and 3) a probabilistic upper\nbound for the false positive rate. Our theoretical results show that attacks\nwith triggers that are more resilient to test-time noise and have smaller\nperturbation magnitudes are more likely to be detected with guarantees.\nMoreover, we conduct extensive experiments on four benchmark datasets\nconsidering various backdoor types, such as BadNet, CB, and Blend. CBD achieves\ncomparable or even higher detection accuracy than state-of-the-art detectors,\nand it in addition provides detection certification. Notably, for backdoor\nattacks with random perturbation triggers bounded by $\\ell_2\\leq0.75$ which\nachieves more than 90\\% attack success rate, CBD achieves 100\\% (98\\%), 100\\%\n(84\\%), 98\\% (98\\%), and 72\\% (40\\%) empirical (certified) detection true\npositive rates on the four benchmark datasets GTSRB, SVHN, CIFAR-10, and\nTinyImageNet, respectively, with low false positive rates.",
            "author": [
                "Zhen Xiang",
                "Zidi Xiong",
                "Bo Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17498v1",
                "http://arxiv.org/pdf/2310.17498v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17496v2",
            "title": "Tackling Interference Induced by Data Training Loops in A/B Tests: A\n  Weighted Training Approach",
            "updated": "2023-10-29T01:38:36Z",
            "published": "2023-10-26T15:52:34Z",
            "summary": "In modern recommendation systems, the standard pipeline involves training\nmachine learning models on historical data to predict user behaviors and\nimprove recommendations continuously. However, these data training loops can\nintroduce interference in A/B tests, where data generated by control and\ntreatment algorithms, potentially with different distributions, are combined.\nTo address these challenges, we introduce a novel approach called weighted\ntraining. This approach entails training a model to predict the probability of\neach data point appearing in either the treatment or control data and\nsubsequently applying weighted losses during model training. We demonstrate\nthat this approach achieves the least variance among all estimators without\ncausing shifts in the training distributions. Through simulation studies, we\ndemonstrate the lower bias and variance of our approach compared to other\nmethods.",
            "author": [
                "Nian Si"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17496v2",
                "http://arxiv.org/pdf/2310.17496v2"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG",
                "econ.EM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17492v1",
            "title": "Orchestration of Emulator Assisted Mobile Edge Tuning for AI Foundation\n  Models: A Multi-Agent Deep Reinforcement Learning Approach",
            "updated": "2023-10-26T15:47:51Z",
            "published": "2023-10-26T15:47:51Z",
            "summary": "The efficient deployment and fine-tuning of foundation models are pivotal in\ncontemporary artificial intelligence. In this study, we present a\ngroundbreaking paradigm integrating Mobile Edge Computing (MEC) with foundation\nmodels, specifically designed to enhance local task performance on user\nequipment (UE). Central to our approach is the innovative Emulator-Adapter\narchitecture, segmenting the foundation model into two cohesive modules. This\ndesign not only conserves computational resources but also ensures adaptability\nand fine-tuning efficiency for downstream tasks. Additionally, we introduce an\nadvanced resource allocation mechanism that is fine-tuned to the needs of the\nEmulator-Adapter structure in decentralized settings. To address the challenges\npresented by this system, we employ a hybrid multi-agent Deep Reinforcement\nLearning (DRL) strategy, adept at handling mixed discrete-continuous action\nspaces, ensuring dynamic and optimal resource allocations. Our comprehensive\nsimulations and validations underscore the practical viability of our approach,\ndemonstrating its robustness, efficiency, and scalability. Collectively, this\nwork offers a fresh perspective on deploying foundation models and balancing\ncomputational efficiency with task proficiency.",
            "author": [
                "Wenhan Yu",
                "Terence Jie Chua",
                "Jun Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17492v1",
                "http://arxiv.org/pdf/2310.17492v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.DC",
                "cs.LG",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17491v1",
            "title": "FedPEAT: Convergence of Federated Learning, Parameter-Efficient Fine\n  Tuning, and Emulator Assisted Tuning for Artificial Intelligence Foundation\n  Models with Mobile Edge Computing",
            "updated": "2023-10-26T15:47:44Z",
            "published": "2023-10-26T15:47:44Z",
            "summary": "The emergence of foundation models, including language and vision models, has\nreshaped AI's landscape, offering capabilities across various applications.\nDeploying and fine-tuning these large models, like GPT-3 and BERT, presents\nchallenges, especially in the current foundation model era. We introduce\nEmulator-Assisted Tuning (EAT) combined with Parameter-Efficient Fine-Tuning\n(PEFT) to form Parameter-Efficient Emulator-Assisted Tuning (PEAT). Further, we\nexpand this into federated learning as Federated PEAT (FedPEAT). FedPEAT uses\nadapters, emulators, and PEFT for federated model tuning, enhancing model\nprivacy and memory efficiency. Adapters adjust pre-trained models, while\nemulators give a compact representation of original models, addressing both\nprivacy and efficiency. Adaptable to various neural networks, our approach also\nuses deep reinforcement learning for hyper-parameter optimization. We tested\nFedPEAT in a unique scenario with a server participating in collaborative\nfederated tuning, showcasing its potential in tackling foundation model\nchallenges.",
            "author": [
                "Terence Jie Chua",
                "Wenhan Yu",
                "Jun Zhao",
                "Kwok-Yan Lam"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17491v1",
                "http://arxiv.org/pdf/2310.17491v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17489v1",
            "title": "Bias in Evaluation Processes: An Optimization-Based Model",
            "updated": "2023-10-26T15:45:01Z",
            "published": "2023-10-26T15:45:01Z",
            "summary": "Biases with respect to socially-salient attributes of individuals have been\nwell documented in evaluation processes used in settings such as admissions and\nhiring. We view such an evaluation process as a transformation of a\ndistribution of the true utility of an individual for a task to an observed\ndistribution and model it as a solution to a loss minimization problem subject\nto an information constraint. Our model has two parameters that have been\nidentified as factors leading to biases: the resource-information trade-off\nparameter in the information constraint and the risk-averseness parameter in\nthe loss function. We characterize the distributions that arise from our model\nand study the effect of the parameters on the observed distribution. The\noutputs of our model enrich the class of distributions that can be used to\ncapture variation across groups in the observed evaluations. We empirically\nvalidate our model by fitting real-world datasets and use it to study the\neffect of interventions in a downstream selection task. These results\ncontribute to an understanding of the emergence of bias in evaluation processes\nand provide tools to guide the deployment of interventions to mitigate biases.",
            "author": [
                "L. Elisa Celis",
                "Amit Kumar",
                "Anay Mehrotra",
                "Nisheeth K. Vishnoi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17489v1",
                "http://arxiv.org/pdf/2310.17489v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17485v1",
            "title": "Fair collaborative vehicle routing: A deep multi-agent reinforcement\n  learning approach",
            "updated": "2023-10-26T15:42:29Z",
            "published": "2023-10-26T15:42:29Z",
            "summary": "Collaborative vehicle routing occurs when carriers collaborate through\nsharing their transportation requests and performing transportation requests on\nbehalf of each other. This achieves economies of scale, thus reducing cost,\ngreenhouse gas emissions and road congestion. But which carrier should partner\nwith whom, and how much should each carrier be compensated? Traditional game\ntheoretic solution concepts are expensive to calculate as the characteristic\nfunction scales exponentially with the number of agents. This would require\nsolving the vehicle routing problem (NP-hard) an exponential number of times.\nWe therefore propose to model this problem as a coalitional bargaining game\nsolved using deep multi-agent reinforcement learning, where - crucially -\nagents are not given access to the characteristic function. Instead, we\nimplicitly reason about the characteristic function; thus, when deployed in\nproduction, we only need to evaluate the expensive post-collaboration vehicle\nrouting problem once. Our contribution is that we are the first to consider\nboth the route allocation problem and gain sharing problem simultaneously -\nwithout access to the expensive characteristic function. Through decentralised\nmachine learning, our agents bargain with each other and agree to outcomes that\ncorrelate well with the Shapley value - a fair profit allocation mechanism.\nImportantly, we are able to achieve a reduction in run-time of 88%.",
            "author": [
                "Stephen Mak",
                "Liming Xu",
                "Tim Pearce",
                "Michael Ostroumov",
                "Alexandra Brintrup"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.trc.2023.104376",
                "http://arxiv.org/abs/2310.17485v1",
                "http://arxiv.org/pdf/2310.17485v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17477v1",
            "title": "Secure short-term load forecasting for smart grids with\n  transformer-based federated learning",
            "updated": "2023-10-26T15:27:55Z",
            "published": "2023-10-26T15:27:55Z",
            "summary": "Electricity load forecasting is an essential task within smart grids to\nassist demand and supply balance. While advanced deep learning models require\nlarge amounts of high-resolution data for accurate short-term load predictions,\nfine-grained load profiles can expose users' electricity consumption behaviors,\nwhich raises privacy and security concerns. One solution to improve data\nprivacy is federated learning, where models are trained locally on private\ndata, and only the trained model parameters are merged and updated on a global\nserver. Therefore, this paper presents a novel transformer-based deep learning\napproach with federated learning for short-term electricity load prediction. To\nevaluate our results, we benchmark our federated learning architecture against\ncentral and local learning and compare the performance of our model to long\nshort-term memory models and convolutional neural networks. Our simulations are\nbased on a dataset from a German university campus and show that\ntransformer-based forecasting is a promising alternative to state-of-the-art\nmodels within federated learning.",
            "author": [
                "Jonas Sievers",
                "Thomas Blank"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ICCEP57914.2023.10247363",
                "http://arxiv.org/abs/2310.17477v1",
                "http://arxiv.org/pdf/2310.17477v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17471v1",
            "title": "Foundation Model Based Native AI Framework in 6G with Cloud-Edge-End\n  Collaboration",
            "updated": "2023-10-26T15:19:40Z",
            "published": "2023-10-26T15:19:40Z",
            "summary": "Future wireless communication networks are in a position to move beyond\ndata-centric, device-oriented connectivity and offer intelligent, immersive\nexperiences based on task-oriented connections, especially in the context of\nthe thriving development of pre-trained foundation models (PFM) and the\nevolving vision of 6G native artificial intelligence (AI). Therefore,\nredefining modes of collaboration between devices and servers and constructing\nnative intelligence libraries become critically important in 6G. In this paper,\nwe analyze the challenges of achieving 6G native AI from the perspectives of\ndata, intelligence, and networks. Then, we propose a 6G native AI framework\nbased on foundation models, provide a customization approach for intent-aware\nPFM, present a construction of a task-oriented AI toolkit, and outline a novel\ncloud-edge-end collaboration paradigm. As a practical use case, we apply this\nframework for orchestration, achieving the maximum sum rate within a wireless\ncommunication system, and presenting preliminary evaluation results. Finally,\nwe outline research directions for achieving native AI in 6G.",
            "author": [
                "Xiang Chen",
                "Zhiheng Guo",
                "Xijun Wang",
                "Howard H. Yang",
                "Chenyuan Feng",
                "Junshen Su",
                "Sihui Zheng",
                "Tony Q. S. Quek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17471v1",
                "http://arxiv.org/pdf/2310.17471v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.DC",
                "cs.LG",
                "cs.NI",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17470v1",
            "title": "Adaptive Digital Twin for UAV-Assisted Integrated Sensing,\n  Communication, and Computation Networks",
            "updated": "2023-10-26T15:17:15Z",
            "published": "2023-10-26T15:17:15Z",
            "summary": "In this paper, we study a digital twin (DT)-empowered integrated sensing,\ncommunication, and computation network. Specifically, the users perform radar\nsensing and computation offloading on the same spectrum, while unmanned aerial\nvehicles (UAVs) are deployed to provide edge computing service. We first\nformulate a multi-objective optimization problem to minimize the beampattern\nperformance of multi-input multi-output (MIMO) radars and the computation\noffloading energy consumption simultaneously. Then, we explore the prediction\ncapability of DT to provide intelligent offloading decision, where the DT\nestimation deviation is considered. To track this challenge, we reformulate the\noriginal problem as a multi-agent Markov decision process and design a\nmulti-agent proximal policy optimization (MAPPO) framework to achieve a\nflexible learning policy. Furthermore, the Beta-policy and attention mechanism\nare used to improve the training performance. Numerical results show that the\nproposed method is able to balance the performance tradeoff between sensing and\ncomputation functions, while reducing the energy consumption compared with the\nexisting studies.",
            "author": [
                "Bin Li",
                "Wenshuai Liu",
                "Wancheng Xie",
                "Ning Zhang",
                "Yan Zhang"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TGCN.2023.3298039",
                "http://arxiv.org/abs/2310.17470v1",
                "http://arxiv.org/pdf/2310.17470v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17468v1",
            "title": "Cross-modal Active Complementary Learning with Self-refining\n  Correspondence",
            "updated": "2023-10-26T15:15:11Z",
            "published": "2023-10-26T15:15:11Z",
            "summary": "Recently, image-text matching has attracted more and more attention from\nacademia and industry, which is fundamental to understanding the latent\ncorrespondence across visual and textual modalities. However, most existing\nmethods implicitly assume the training pairs are well-aligned while ignoring\nthe ubiquitous annotation noise, a.k.a noisy correspondence (NC), thereby\ninevitably leading to a performance drop. Although some methods attempt to\naddress such noise, they still face two challenging problems: excessive\nmemorizing/overfitting and unreliable correction for NC, especially under high\nnoise. To address the two problems, we propose a generalized Cross-modal Robust\nComplementary Learning framework (CRCL), which benefits from a novel Active\nComplementary Loss (ACL) and an efficient Self-refining Correspondence\nCorrection (SCC) to improve the robustness of existing methods. Specifically,\nACL exploits active and complementary learning losses to reduce the risk of\nproviding erroneous supervision, leading to theoretically and experimentally\ndemonstrated robustness against NC. SCC utilizes multiple self-refining\nprocesses with momentum correction to enlarge the receptive field for\ncorrecting correspondences, thereby alleviating error accumulation and\nachieving accurate and stable corrections. We carry out extensive experiments\non three image-text benchmarks, i.e., Flickr30K, MS-COCO, and CC152K, to verify\nthe superior robustness of our CRCL against synthetic and real-world noisy\ncorrespondences.",
            "author": [
                "Yang Qin",
                "Yuan Sun",
                "Dezhong Peng",
                "Joey Tianyi Zhou",
                "Xi Peng",
                "Peng Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17468v1",
                "http://arxiv.org/pdf/2310.17468v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17467v1",
            "title": "The statistical thermodynamics of generative diffusion models",
            "updated": "2023-10-26T15:15:01Z",
            "published": "2023-10-26T15:15:01Z",
            "summary": "Generative diffusion models have achieved spectacular performance in many\nareas of generative modeling. While the fundamental ideas behind these models\ncome from non-equilibrium physics, in this paper we show that many aspects of\nthese models can be understood using the tools of equilibrium statistical\nmechanics. Using this reformulation, we show that generative diffusion models\nundergo second-order phase transitions corresponding to symmetry breaking\nphenomena. We argue that this lead to a form of instability that lies at the\nheart of their generative capabilities and that can be described by a set of\nmean field critical exponents. We conclude by analyzing recent work connecting\ndiffusion models and associative memory networks in view of the thermodynamic\nformulations.",
            "author": [
                "Luca Ambrogioni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17467v1",
                "http://arxiv.org/pdf/2310.17467v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17463v1",
            "title": "Bayesian Neural Controlled Differential Equations for Treatment Effect\n  Estimation",
            "updated": "2023-10-26T15:10:35Z",
            "published": "2023-10-26T15:10:35Z",
            "summary": "Treatment effect estimation in continuous time is crucial for personalized\nmedicine. However, existing methods for this task are limited to point\nestimates of the potential outcomes, whereas uncertainty estimates have been\nignored. Needless to say, uncertainty quantification is crucial for reliable\ndecision-making in medical applications. To fill this gap, we propose a novel\nBayesian neural controlled differential equation (BNCDE) for treatment effect\nestimation in continuous time. In our BNCDE, the time dimension is modeled\nthrough a coupled system of neural controlled differential equations and neural\nstochastic differential equations, where the neural stochastic differential\nequations allow for tractable variational Bayesian inference. Thereby, for an\nassigned sequence of treatments, our BNCDE provides meaningful posterior\npredictive distributions of the potential outcomes. To the best of our\nknowledge, ours is the first tailored neural method to provide uncertainty\nestimates of treatment effects in continuous time. As such, our method is of\ndirect practical value for promoting reliable decision-making in medicine.",
            "author": [
                "Konstantin Hess",
                "Valentyn Melnychuk",
                "Dennis Frauen",
                "Stefan Feuerriegel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17463v1",
                "http://arxiv.org/pdf/2310.17463v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17462v2",
            "title": "Towards Learning Monocular 3D Object Localization From 2D Labels using\n  the Physical Laws of Motion",
            "updated": "2023-11-29T14:33:28Z",
            "published": "2023-10-26T15:10:10Z",
            "summary": "We present a novel method for precise 3D object localization in single images\nfrom a single calibrated camera using only 2D labels. No expensive 3D labels\nare needed. Thus, instead of using 3D labels, our model is trained with\neasy-to-annotate 2D labels along with the physical knowledge of the object's\nmotion. Given this information, the model can infer the latent third dimension,\neven though it has never seen this information during training. Our method is\nevaluated on both synthetic and real-world datasets, and we are able to achieve\na mean distance error of just 6 cm in our experiments on real data. The results\nindicate the method's potential as a step towards learning 3D object location\nestimation, where collecting 3D data for training is not feasible.",
            "author": [
                "Daniel Kienzle",
                "Julian Lorenz",
                "Katja Ludwig",
                "Rainer Lienhart"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17462v2",
                "http://arxiv.org/pdf/2310.17462v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17458v1",
            "title": "Coalitional Bargaining via Reinforcement Learning: An Application to\n  Collaborative Vehicle Routing",
            "updated": "2023-10-26T15:04:23Z",
            "published": "2023-10-26T15:04:23Z",
            "summary": "Collaborative Vehicle Routing is where delivery companies cooperate by\nsharing their delivery information and performing delivery requests on behalf\nof each other. This achieves economies of scale and thus reduces cost,\ngreenhouse gas emissions, and road congestion. But which company should partner\nwith whom, and how much should each company be compensated? Traditional game\ntheoretic solution concepts, such as the Shapley value or nucleolus, are\ndifficult to calculate for the real-world problem of Collaborative Vehicle\nRouting due to the characteristic function scaling exponentially with the\nnumber of agents. This would require solving the Vehicle Routing Problem (an\nNP-Hard problem) an exponential number of times. We therefore propose to model\nthis problem as a coalitional bargaining game where - crucially - agents are\nnot given access to the characteristic function. Instead, we implicitly reason\nabout the characteristic function, and thus eliminate the need to evaluate the\nVRP an exponential number of times - we only need to evaluate it once. Our\ncontribution is that our decentralised approach is both scalable and considers\nthe self-interested nature of companies. The agents learn using a modified\nIndependent Proximal Policy Optimisation. Our RL agents outperform a strong\nheuristic bot. The agents correctly identify the optimal coalitions 79% of the\ntime with an average optimality gap of 4.2% and reduction in run-time of 62%.",
            "author": [
                "Stephen Mak",
                "Liming Xu",
                "Tim Pearce",
                "Michael Ostroumov",
                "Alexandra Brintrup"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17458v1",
                "http://arxiv.org/pdf/2310.17458v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17455v1",
            "title": "OTMatch: Improving Semi-Supervised Learning with Optimal Transport",
            "updated": "2023-10-26T15:01:54Z",
            "published": "2023-10-26T15:01:54Z",
            "summary": "Semi-supervised learning has made remarkable strides by effectively utilizing\na limited amount of labeled data while capitalizing on the abundant information\npresent in unlabeled data. However, current algorithms often prioritize\naligning image predictions with specific classes generated through\nself-training techniques, thereby neglecting the inherent relationships that\nexist within these classes. In this paper, we present a new approach called\nOTMatch, which leverages semantic relationships among classes by employing an\noptimal transport loss function. By utilizing optimal transport, our proposed\nmethod consistently outperforms established state-of-the-art methods. Notably,\nwe observed a substantial improvement of a certain percentage in accuracy\ncompared to the current state-of-the-art method, FreeMatch. OTMatch achieves\n3.18%, 3.46%, and 1.28% error rate reduction over FreeMatch on CIFAR-10 with 1\nlabel per class, STL-10 with 4 labels per class, and ImageNet with 100 labels\nper class, respectively. This demonstrates the effectiveness and superiority of\nour approach in harnessing semantic relationships to enhance learning\nperformance in a semi-supervised setting.",
            "author": [
                "Zhiquan Tan",
                "Kaipeng Zheng",
                "Weiran Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17455v1",
                "http://arxiv.org/pdf/2310.17455v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17451v1",
            "title": "Generating by Understanding: Neural Visual Generation with Logical\n  Symbol Groundings",
            "updated": "2023-10-26T15:00:21Z",
            "published": "2023-10-26T15:00:21Z",
            "summary": "Despite the great success of neural visual generative models in recent years,\nintegrating them with strong symbolic knowledge reasoning systems remains a\nchallenging task. The main challenges are two-fold: one is symbol assignment,\ni.e. bonding latent factors of neural visual generators with meaningful symbols\nfrom knowledge reasoning systems. Another is rule learning, i.e. learning new\nrules, which govern the generative process of the data, to augment the\nknowledge reasoning systems. To deal with these symbol grounding problems, we\npropose a neural-symbolic learning approach, Abductive Visual Generation\n(AbdGen), for integrating logic programming systems with neural visual\ngenerative models based on the abductive learning framework. To achieve\nreliable and efficient symbol assignment, the quantized abduction method is\nintroduced for generating abduction proposals by the nearest-neighbor lookups\nwithin semantic codebooks. To achieve precise rule learning, the contrastive\nmeta-abduction method is proposed to eliminate wrong rules with positive cases\nand avoid less-informative rules with negative cases simultaneously.\nExperimental results on various benchmark datasets show that compared to the\nbaselines, AbdGen requires significantly fewer instance-level labeling\ninformation for symbol assignment. Furthermore, our approach can effectively\nlearn underlying logical generative rules from data, which is out of the\ncapability of existing approaches.",
            "author": [
                "Yifei Peng",
                "Yu Jin",
                "Zhexu Luo",
                "Yao-Xiang Ding",
                "Wang-Zhou Dai",
                "Zhong Ren",
                "Kun Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17451v1",
                "http://arxiv.org/pdf/2310.17451v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17439v1",
            "title": "Designing Hash and Encryption Engines using Quantum Computing",
            "updated": "2023-10-26T14:49:51Z",
            "published": "2023-10-26T14:49:51Z",
            "summary": "Quantum computing (QC) holds the promise of revolutionizing problem-solving\nby exploiting quantum phenomena like superposition and entanglement. It offers\nexponential speed-ups across various domains, from machine learning and\nsecurity to drug discovery and optimization. In parallel, quantum encryption\nand key distribution have garnered substantial interest, leveraging quantum\nengines to enhance cryptographic techniques. Classical cryptography faces\nimminent threats from quantum computing, exemplified by Shors algorithms\ncapacity to breach established encryption schemes. However, quantum circuits\nand algorithms, capitalizing on superposition and entanglement, offer\ninnovative avenues for enhancing security. In this paper we explore\nquantum-based hash functions and encryption to fortify data security. Quantum\nhash functions and encryption can have numerous potential application cases,\nsuch as password storage, digital signatures, cryptography, anti-tampering etc.\nThe integration of quantum and classical methods demonstrates potential in\nsecuring data in the era of quantum computing.",
            "author": [
                "Suryansh Upadhyay",
                "Rupshali Roy",
                "Swaroop Ghosh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17439v1",
                "http://arxiv.org/pdf/2310.17439v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17437v1",
            "title": "Sign Languague Recognition without frame-sequencing constraints: A proof\n  of concept on the Argentinian Sign Language",
            "updated": "2023-10-26T14:47:11Z",
            "published": "2023-10-26T14:47:11Z",
            "summary": "Automatic sign language recognition (SLR) is an important topic within the\nareas of human-computer interaction and machine learning. On the one hand, it\nposes a complex challenge that requires the intervention of various knowledge\nareas, such as video processing, image processing, intelligent systems and\nlinguistics. On the other hand, robust recognition of sign language could\nassist in the translation process and the integration of hearing-impaired\npeople, as well as the teaching of sign language for the hearing population.\n  SLR systems usually employ Hidden Markov Models, Dynamic Time Warping or\nsimilar models to recognize signs. Such techniques exploit the sequential\nordering of frames to reduce the number of hypothesis. This paper presents a\ngeneral probabilistic model for sign classification that combines\nsub-classifiers based on different types of features such as position, movement\nand handshape. The model employs a bag-of-words approach in all classification\nsteps, to explore the hypothesis that ordering is not essential for\nrecognition. The proposed model achieved an accuracy rate of 97% on an\nArgentinian Sign Language dataset containing 64 classes of signs and 3200\nsamples, providing some evidence that indeed recognition without ordering is\npossible.",
            "author": [
                "Franco Ronchetti",
                "Facundo Manuel Quiroga",
                "C\u00e9sar Estrebou",
                "Laura Lanzarini",
                "Alejandro Rosete"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-319-47955-2_28",
                "http://arxiv.org/abs/2310.17437v1",
                "http://arxiv.org/pdf/2310.17437v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17683v1",
            "title": "Sliceformer: Make Multi-head Attention as Simple as Sorting in\n  Discriminative Tasks",
            "updated": "2023-10-26T14:43:07Z",
            "published": "2023-10-26T14:43:07Z",
            "summary": "As one of the most popular neural network modules, Transformer plays a\ncentral role in many fundamental deep learning models, e.g., the ViT in\ncomputer vision and the BERT and GPT in natural language processing. The\neffectiveness of the Transformer is often attributed to its multi-head\nattention (MHA) mechanism. In this study, we discuss the limitations of MHA,\nincluding the high computational complexity due to its ``query-key-value''\narchitecture and the numerical issue caused by its softmax operation.\nConsidering the above problems and the recent development tendency of the\nattention layer, we propose an effective and efficient surrogate of the\nTransformer, called Sliceformer. Our Sliceformer replaces the classic MHA\nmechanism with an extremely simple ``slicing-sorting'' operation, i.e.,\nprojecting inputs linearly to a latent space and sorting them along different\nfeature dimensions (or equivalently, called channels). For each feature\ndimension, the sorting operation implicitly generates an implicit attention map\nwith sparse, full-rank, and doubly-stochastic structures. We consider different\nimplementations of the slicing-sorting operation and analyze their impacts on\nthe Sliceformer. We test the Sliceformer in the Long-Range Arena benchmark,\nimage classification, text classification, and molecular property prediction,\ndemonstrating its advantage in computational complexity and universal\neffectiveness in discriminative tasks. Our Sliceformer achieves comparable or\nbetter performance with lower memory cost and faster speed than the Transformer\nand its variants. Moreover, the experimental results reveal that applying our\nSliceformer can empirically suppress the risk of mode collapse when\nrepresenting data. The code is available at\n\\url{https://github.com/SDS-Lab/sliceformer}.",
            "author": [
                "Shen Yuan",
                "Hongteng Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17683v1",
                "http://arxiv.org/pdf/2310.17683v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17432v1",
            "title": "Likelihood-based Out-of-Distribution Detection with Denoising Diffusion\n  Probabilistic Models",
            "updated": "2023-10-26T14:40:30Z",
            "published": "2023-10-26T14:40:30Z",
            "summary": "Out-of-Distribution detection between dataset pairs has been extensively\nexplored with generative models. We show that likelihood-based\nOut-of-Distribution detection can be extended to diffusion models by leveraging\nthe fact that they, like other likelihood-based generative models, are\ndramatically affected by the input sample complexity. Currently, all\nOut-of-Distribution detection methods with Diffusion Models are\nreconstruction-based. We propose a new likelihood ratio for Out-of-Distribution\ndetection with Deep Denoising Diffusion Models, which we call the Complexity\nCorrected Likelihood Ratio. Our likelihood ratio is constructed using Evidence\nLower-Bound evaluations from an individual model at various noising levels. We\npresent results that are comparable to state-of-the-art Out-of-Distribution\ndetection methods with generative models.",
            "author": [
                "Joseph Goodier",
                "Neill D. F. Campbell"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17432v1",
                "http://arxiv.org/pdf/2310.17432v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17431v1",
            "title": "Efficient safe learning for controller tuning with experimental\n  validation",
            "updated": "2023-10-26T14:40:11Z",
            "published": "2023-10-26T14:40:11Z",
            "summary": "Optimization-based controller tuning is challenging because it requires\nformulating optimization problems explicitly as functions of controller\nparameters. Safe learning algorithms overcome the challenge by creating\nsurrogate models from measured data. To ensure safety, such data-driven\nalgorithms often rely on exhaustive grid search, which is computationally\ninefficient. In this paper, we propose a novel approach to safe learning by\nformulating a series of optimization problems instead of a grid search. We also\ndevelop a method for initializing the optimization problems to guarantee\nfeasibility while using numerical solvers. The performance of the new method is\nfirst validated in a simulated precision motion system, demonstrating improved\ncomputational efficiency, and illustrating the role of exploiting numerical\nsolvers to reach the desired precision. Experimental validation on an\nindustrial-grade precision motion system confirms that the proposed algorithm\nachieves 30% better tracking at sub-micrometer precision as a state-of-the-art\nsafe learning algorithm, improves the default auto-tuning solution, and reduces\nthe computational cost seven times compared to learning algorithms based on\nexhaustive search.",
            "author": [
                "Marta Zagorowska",
                "Christopher K\u00f6nig",
                "Hanlin Yu",
                "Efe C. Balta",
                "Alisa Rupenyan",
                "John Lygeros"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17431v1",
                "http://arxiv.org/pdf/2310.17431v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17430v1",
            "title": "A near-autonomous and incremental intrusion detection system through\n  active learning of known and unknown attacks",
            "updated": "2023-10-26T14:37:54Z",
            "published": "2023-10-26T14:37:54Z",
            "summary": "Intrusion detection is a traditional practice of security experts, however,\nthere are several issues which still need to be tackled. Therefore, in this\npaper, after highlighting these issues, we present an architecture for a hybrid\nIntrusion Detection System (IDS) for an adaptive and incremental detection of\nboth known and unknown attacks. The IDS is composed of supervised and\nunsupervised modules, namely, a Deep Neural Network (DNN) and the K-Nearest\nNeighbors (KNN) algorithm, respectively. The proposed system is near-autonomous\nsince the intervention of the expert is minimized through the active learning\n(AL) approach. A query strategy for the labeling process is presented, it aims\nat teaching the supervised module to detect unknown attacks and improve the\ndetection of the already-known attacks. This teaching is achieved through\nsliding windows (SW) in an incremental fashion where the DNN is retrained when\nthe data is available over time, thus rendering the IDS adaptive to cope with\nthe evolutionary aspect of the network traffic. A set of experiments was\nconducted on the CICIDS2017 dataset in order to evaluate the performance of the\nIDS, promising results were obtained.",
            "author": [
                "Lynda Boukela",
                "Gongxuan Zhang",
                "Meziane Yacoub",
                "Samia Bouzefrane"
            ],
            "link": [
                "http://dx.doi.org/10.1109/SPAC53836.2021.9539947",
                "http://arxiv.org/abs/2310.17430v1",
                "http://arxiv.org/pdf/2310.17430v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "68"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17429v1",
            "title": "LSA64: An Argentinian Sign Language Dataset",
            "updated": "2023-10-26T14:37:01Z",
            "published": "2023-10-26T14:37:01Z",
            "summary": "Automatic sign language recognition is a research area that encompasses\nhuman-computer interaction, computer vision and machine learning. Robust\nautomatic recognition of sign language could assist in the translation process\nand the integration of hearing-impaired people, as well as the teaching of sign\nlanguage to the hearing population. Sign languages differ significantly in\ndifferent countries and even regions, and their syntax and semantics are\ndifferent as well from those of written languages. While the techniques for\nautomatic sign language recognition are mostly the same for different\nlanguages, training a recognition system for a new language requires having an\nentire dataset for that language. This paper presents a dataset of 64 signs\nfrom the Argentinian Sign Language (LSA). The dataset, called LSA64, contains\n3200 videos of 64 different LSA signs recorded by 10 subjects, and is a first\nstep towards building a comprehensive research-level dataset of Argentinian\nsigns, specifically tailored to sign language recognition or other machine\nlearning tasks. The subjects that performed the signs wore colored gloves to\nease the hand tracking and segmentation steps, allowing experiments on the\ndataset to focus specifically on the recognition of signs. We also present a\npre-processed version of the dataset, from which we computed statistics of\nmovement, position and handshape of the signs.",
            "author": [
                "Franco Ronchetti",
                "Facundo Manuel Quiroga",
                "C\u00e9sar Estrebou",
                "Laura Lanzarini",
                "Alejandro Rosete"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17429v1",
                "http://arxiv.org/pdf/2310.17429v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "I.5.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17427v1",
            "title": "Handshape recognition for Argentinian Sign Language using ProbSom",
            "updated": "2023-10-26T14:32:44Z",
            "published": "2023-10-26T14:32:44Z",
            "summary": "Automatic sign language recognition is an important topic within the areas of\nhuman-computer interaction and machine learning. On the one hand, it poses a\ncomplex challenge that requires the intervention of various knowledge areas,\nsuch as video processing, image processing, intelligent systems and\nlinguistics. On the other hand, robust recognition of sign language could\nassist in the translation process and the integration of hearing-impaired\npeople.\n  This paper offers two main contributions: first, the creation of a database\nof handshapes for the Argentinian Sign Language (LSA), which is a topic that\nhas barely been discussed so far. Secondly, a technique for image processing,\ndescriptor extraction and subsequent handshape classification using a\nsupervised adaptation of self-organizing maps that is called ProbSom. This\ntechnique is compared to others in the state of the art, such as Support Vector\nMachines (SVM), Random Forests, and Neural Networks.\n  The database that was built contains 800 images with 16 LSA handshapes, and\nis a first step towards building a comprehensive database of Argentinian signs.\nThe ProbSom-based neural classifier, using the proposed descriptor, achieved an\naccuracy rate above 90%.",
            "author": [
                "Franco Ronchetti",
                "Facundo Manuel Quiroga",
                "C\u00e9sar Estrebou",
                "Laura Lanzarini"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17427v1",
                "http://arxiv.org/pdf/2310.17427v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17426v1",
            "title": "Stealthy SWAPs: Adversarial SWAP Injection in Multi-Tenant Quantum\n  Computing",
            "updated": "2023-10-26T14:31:21Z",
            "published": "2023-10-26T14:31:21Z",
            "summary": "Quantum computing (QC) holds tremendous promise in revolutionizing\nproblem-solving across various domains. It has been suggested in literature\nthat 50+ qubits are sufficient to achieve quantum advantage (i.e., to surpass\nsupercomputers in solving certain class of optimization problems).The hardware\nsize of existing Noisy Intermediate-Scale Quantum (NISQ) computers have been\never increasing over the years. Therefore, Multi-tenant computing (MTC) has\nemerged as a potential solution for efficient hardware utilization, enabling\nshared resource access among multiple quantum programs. However, MTC can also\nbring new security concerns. This paper proposes one such threat for MTC in\nsuperconducting quantum hardware i.e., adversarial SWAP gate injection in\nvictims program during compilation for MTC. We present a representative\nscheduler designed for optimal resource allocation. To demonstrate the impact\nof this attack model, we conduct a detailed case study using a sample\nscheduler. Exhaustive experiments on circuits with varying depths and qubits\noffer valuable insights into the repercussions of these attacks. We report a\nmax of approximately 55 percent and a median increase of approximately 25\npercent in SWAP overhead. As a countermeasure, we also propose a sample machine\nlearning model for detecting any abnormal user behavior and priority\nadjustment.",
            "author": [
                "Suryansh Upadhyay",
                "Swaroop Ghosh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17426v1",
                "http://arxiv.org/pdf/2310.17426v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17417v1",
            "title": "Training for Open-Ended Drilling through a Virtual Reality Simulation",
            "updated": "2023-10-26T14:22:30Z",
            "published": "2023-10-26T14:22:30Z",
            "summary": "Virtual Reality (VR) can support effective and scalable training of\npsychomotor skills in manufacturing. However, many industry training modules\noffer experiences that are close-ended and do not allow for human error. We aim\nto address this gap in VR training tools for psychomotor skills training by\nexploring an open-ended approach to the system design. We designed a VR\ntraining simulation prototype to perform open-ended practice of drilling using\na 3-axis milling machine. The simulation employs near \"end-to-end\" instruction\nthrough a safety module, a setup and drilling tutorial, open-ended practice\ncomplete with warnings of mistakes and failures, and a function to assess the\ngeometries and locations of drilled holes against an engineering drawing. We\ndeveloped and conducted a user study within an undergraduate-level introductory\nfabrication course to investigate the impact of open-ended VR practice on\nlearning outcomes. Study results reveal positive trends, with the VR group\nsuccessfully completing the machining task of drilling at a higher rate (75% vs\n64%), with fewer mistakes (1.75 vs 2.14 score), and in less time (17.67 mins vs\n21.57 mins) compared to the control group. We discuss our findings and\nlimitations and implications for the design of open-ended VR training systems\nfor learning psychomotor skills.",
            "author": [
                "Hing Lie",
                "Kachina Studer",
                "Zhen Zhao",
                "Ben Thomson",
                "Dishita G Turakhia",
                "John Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17417v1",
                "http://arxiv.org/pdf/2310.17417v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17416v1",
            "title": "Goals are Enough: Inducing AdHoc cooperation among unseen Multi-Agent\n  systems in IMFs",
            "updated": "2023-10-26T14:21:36Z",
            "published": "2023-10-26T14:21:36Z",
            "summary": "Intent-based management will play a critical role in achieving customers'\nexpectations in the next-generation mobile networks. Traditional methods cannot\nperform efficient resource management since they tend to handle each\nexpectation independently. Existing approaches, e.g., based on multi-agent\nreinforcement learning (MARL) allocate resources in an efficient fashion when\nthere are conflicting expectations on the network slice. However, in reality,\nsystems are often far more complex to be addressed by a standalone MARL\nformulation. Often there exists a hierarchical structure of intent fulfilment\nwhere multiple pre-trained, self-interested agents may need to be further\norchestrated by a supervisor or controller agent. Such agents may arrive in the\nsystem adhoc, which then needs to be orchestrated along with other available\nagents. Retraining the whole system every time is often infeasible given the\nassociated time and cost. Given the challenges, such adhoc coordination of\npre-trained systems could be achieved through an intelligent supervisor agent\nwhich incentivizes pre-trained RL/MARL agents through sets of dynamic contracts\n(goals or bonuses) and encourages them to act as a cohesive unit towards\nfulfilling a global expectation. Some approaches use a rule-based supervisor\nagent and deploy the hierarchical constituent agents sequentially, based on\nhuman-coded rules.\n  In the current work, we propose a framework whereby pre-trained agents can be\norchestrated in parallel leveraging an AI-based supervisor agent. For this, we\npropose to use Adhoc-Teaming approaches which assign optimal goals to the MARL\nagents and incentivize them to exhibit certain desired behaviours. Results on\nthe network emulator show that the proposed approach results in faster and\nimproved fulfilment of expectations when compared to rule-based approaches and\neven generalizes to changes in environments.",
            "author": [
                "Kaushik Dey",
                "Satheesh K. Perepu",
                "Abir Das"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17416v1",
                "http://arxiv.org/pdf/2310.17416v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17415v1",
            "title": "PETA: Evaluating the Impact of Protein Transfer Learning with Sub-word\n  Tokenization on Downstream Applications",
            "updated": "2023-10-26T14:20:44Z",
            "published": "2023-10-26T14:20:44Z",
            "summary": "Large protein language models are adept at capturing the underlying\nevolutionary information in primary structures, offering significant practical\nvalue for protein engineering. Compared to natural language models, protein\namino acid sequences have a smaller data volume and a limited combinatorial\nspace. Choosing an appropriate vocabulary size to optimize the pre-trained\nmodel is a pivotal issue. Moreover, despite the wealth of benchmarks and\nstudies in the natural language community, there remains a lack of a\ncomprehensive benchmark for systematically evaluating protein language model\nquality. Given these challenges, PETA trained language models with 14 different\nvocabulary sizes under three tokenization methods. It conducted thousands of\ntests on 33 diverse downstream datasets to assess the models' transfer learning\ncapabilities, incorporating two classification heads and three random seeds to\nmitigate potential biases. Extensive experiments indicate that vocabulary sizes\nbetween 50 and 200 optimize the model, whereas sizes exceeding 800\ndetrimentally affect the model's representational performance. Our code, model\nweights and datasets are available at\nhttps://github.com/ginnm/ProteinPretraining.",
            "author": [
                "Yang Tan",
                "Mingchen Li",
                "Pan Tan",
                "Ziyi Zhou",
                "Huiqun Yu",
                "Guisheng Fan",
                "Liang Hong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17415v1",
                "http://arxiv.org/pdf/2310.17415v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17410v1",
            "title": "Synthesizing Efficiently Monitorable Formulas in Metric Temporal Logic",
            "updated": "2023-10-26T14:13:15Z",
            "published": "2023-10-26T14:13:15Z",
            "summary": "In runtime verification, manually formalizing a specification for monitoring\nsystem executions is a tedious and error-prone process. To address this issue,\nwe consider the problem of automatically synthesizing formal specifications\nfrom system executions. To demonstrate our approach, we consider the popular\nspecification language Metric Temporal Logic (MTL), which is particularly\ntailored towards specifying temporal properties for cyber-physical systems\n(CPS). Most of the classical approaches for synthesizing temporal logic\nformulas aim at minimizing the size of the formula. However, for efficiency in\nmonitoring, along with the size, the amount of \"lookahead\" required for the\nspecification becomes relevant, especially for safety-critical applications. We\nformalize this notion and devise a learning algorithm that synthesizes concise\nformulas having bounded lookahead. To do so, our algorithm reduces the\nsynthesis task to a series of satisfiability problems in Linear Real Arithmetic\n(LRA) and generates MTL formulas from their satisfying assignments. The\nreduction uses a novel encoding of a popular MTL monitoring procedure using\nLRA. Finally, we implement our algorithm in a tool called TEAL and demonstrate\nits ability to synthesize efficiently monitorable MTL formulas in a CPS\napplication.",
            "author": [
                "Ritam Raha",
                "Rajarshi Roy",
                "Nathanael Fijalkow",
                "Daniel Neider",
                "Guillermo A. Perez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17410v1",
                "http://arxiv.org/pdf/2310.17410v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17405v1",
            "title": "Causal Modeling with Stationary Diffusions",
            "updated": "2023-10-26T14:01:17Z",
            "published": "2023-10-26T14:01:17Z",
            "summary": "We develop a novel approach towards causal inference. Rather than structural\nequations over a causal graph, we learn stochastic differential equations\n(SDEs) whose stationary densities model a system's behavior under\ninterventions. These stationary diffusion models do not require the formalism\nof causal graphs, let alone the common assumption of acyclicity. We show that\nin several cases, they generalize to unseen interventions on their variables,\noften better than classical approaches. Our inference method is based on a new\ntheoretical result that expresses a stationarity condition on the diffusion's\ngenerator in a reproducing kernel Hilbert space. The resulting kernel deviation\nfrom stationarity (KDS) is an objective function of independent interest.",
            "author": [
                "Lars Lorch",
                "Andreas Krause",
                "Bernhard Sch\u00f6lkopf"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17405v1",
                "http://arxiv.org/pdf/2310.17405v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17404v1",
            "title": "Invariance Measures for Neural Networks",
            "updated": "2023-10-26T13:59:39Z",
            "published": "2023-10-26T13:59:39Z",
            "summary": "Invariances in neural networks are useful and necessary for many tasks.\nHowever, the representation of the invariance of most neural network models has\nnot been characterized. We propose measures to quantify the invariance of\nneural networks in terms of their internal representation. The measures are\nefficient and interpretable, and can be applied to any neural network model.\nThey are also more sensitive to invariance than previously defined measures. We\nvalidate the measures and their properties in the domain of affine\ntransformations and the CIFAR10 and MNIST datasets, including their stability\nand interpretability. Using the measures, we perform a first analysis of CNN\nmodels and show that their internal invariance is remarkably stable to random\nweight initializations, but not to changes in dataset or transformation. We\nbelieve the measures will enable new avenues of research in invariance\nrepresentation.",
            "author": [
                "Facundo Manuel Quiroga",
                "Jordina Torrents-Barrena",
                "Laura Cristina Lanzarini",
                "Domenec Puig-Valls"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.asoc.2022.109817",
                "http://arxiv.org/abs/2310.17404v1",
                "http://arxiv.org/pdf/2310.17404v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17403v2",
            "title": "Detection Defenses: An Empty Promise against Adversarial Patch Attacks\n  on Optical Flow",
            "updated": "2023-11-02T08:28:29Z",
            "published": "2023-10-26T13:56:12Z",
            "summary": "Adversarial patches undermine the reliability of optical flow predictions\nwhen placed in arbitrary scene locations. Therefore, they pose a realistic\nthreat to real-world motion detection and its downstream applications.\nPotential remedies are defense strategies that detect and remove adversarial\npatches, but their influence on the underlying motion prediction has not been\ninvestigated. In this paper, we thoroughly examine the currently available\ndetect-and-remove defenses ILP and LGS for a wide selection of state-of-the-art\noptical flow methods, and illuminate their side effects on the quality and\nrobustness of the final flow predictions. In particular, we implement\ndefense-aware attacks to investigate whether current defenses are able to\nwithstand attacks that take the defense mechanism into account. Our experiments\nyield two surprising results: Detect-and-remove defenses do not only lower the\noptical flow quality on benign scenes, in doing so, they also harm the\nrobustness under patch attacks for all tested optical flow methods except\nFlowNetC. As currently employed detect-and-remove defenses fail to deliver the\npromised adversarial robustness for optical flow, they evoke a false sense of\nsecurity. The code is available at\nhttps://github.com/cv-stuttgart/DetectionDefenses.",
            "author": [
                "Erik Scheurer",
                "Jenny Schmalfuss",
                "Alexander Lis",
                "Andr\u00e9s Bruhn"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17403v2",
                "http://arxiv.org/pdf/2310.17403v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17402v1",
            "title": "Learning to learn with an evolutionary strategy applied to variational\n  quantum algorithms",
            "updated": "2023-10-26T13:55:01Z",
            "published": "2023-10-26T13:55:01Z",
            "summary": "Variational Quantum Algorithms (VQAs) employ quantum circuits parameterized\nby $U$, optimized using classical methods to minimize a cost function. While\nVQAs have found broad applications, certain challenges persist. Notably, a\nsignificant computational burden arises during parameter optimization. The\nprevailing ``parameter shift rule'' mandates a double evaluation of the cost\nfunction for each parameter. In this article, we introduce a novel optimization\napproach named ``Learning to Learn with an Evolutionary Strategy'' (LLES). LLES\nunifies ``Learning to Learn'' and ``Evolutionary Strategy'' methods. ``Learning\nto Learn'' treats optimization as a learning problem, utilizing recurrent\nneural networks to iteratively propose VQA parameters. Conversely,\n``Evolutionary Strategy'' employs gradient searches to estimate function\ngradients. Our optimization method is applied to two distinct tasks:\ndetermining the ground state of an Ising Hamiltonian and training a quantum\nneural network. Results underscore the efficacy of this novel approach.\nAdditionally, we identify a key hyperparameter that significantly influences\ngradient estimation using the ``Evolutionary Strategy'' method.",
            "author": [
                "Lucas Friedrich",
                "Jonas Maziero"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17402v1",
                "http://arxiv.org/pdf/2310.17402v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17395v1",
            "title": "Learning Temporal Sentence Grounding From Narrated EgoVideos",
            "updated": "2023-10-26T13:46:20Z",
            "published": "2023-10-26T13:46:20Z",
            "summary": "The onset of long-form egocentric datasets such as Ego4D and EPIC-Kitchens\npresents a new challenge for the task of Temporal Sentence Grounding (TSG).\nCompared to traditional benchmarks on which this task is evaluated, these\ndatasets offer finer-grained sentences to ground in notably longer videos. In\nthis paper, we develop an approach for learning to ground sentences in these\ndatasets using only narrations and their corresponding rough narration\ntimestamps. We propose to artificially merge clips to train for temporal\ngrounding in a contrastive manner using text-conditioning attention. This Clip\nMerging (CliMer) approach is shown to be effective when compared with a high\nperforming TSG method -- e.g. mean R@1 improves from 3.9 to 5.7 on Ego4D and\nfrom 10.7 to 13.0 on EPIC-Kitchens. Code and data splits available from:\nhttps://github.com/keflanagan/CliMer",
            "author": [
                "Kevin Flanagan",
                "Dima Damen",
                "Michael Wray"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17395v1",
                "http://arxiv.org/pdf/2310.17395v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17394v1",
            "title": "Enhancing Graph Neural Networks with Structure-Based Prompt",
            "updated": "2023-10-26T13:46:18Z",
            "published": "2023-10-26T13:46:18Z",
            "summary": "Graph Neural Networks (GNNs) are powerful in learning semantics of graph\ndata. Recently, a new paradigm \"pre-train, prompt\" has shown promising results\nin adapting GNNs to various tasks with less supervised data. The success of\nsuch paradigm can be attributed to the more consistent objectives of\npre-training and task-oriented prompt tuning, where the pre-trained knowledge\ncan be effectively transferred to downstream tasks. However, an overlooked\nissue of existing studies is that the structure information of graph is usually\nexploited during pre-training for learning node representations, while\nneglected in the prompt tuning stage for learning task-specific parameters. To\nbridge this gap, we propose a novel structure-based prompting method for GNNs,\nnamely SAP, which consistently exploits structure information in both\npre-training and prompt tuning stages. In particular, SAP 1) employs a\ndual-view contrastive learning to align the latent semantic spaces of node\nattributes and graph structure, and 2) incorporates structure information in\nprompted graph to elicit more pre-trained knowledge in prompt tuning. We\nconduct extensive experiments on node classification and graph classification\ntasks to show the effectiveness of SAP. Moreover, we show that SAP can lead to\nbetter performance in more challenging few-shot scenarios on both homophilous\nand heterophilous graphs.",
            "author": [
                "Qingqing Ge",
                "Zeyuan Zhao",
                "Yiding Liu",
                "Anfeng Cheng",
                "Xiang Li",
                "Shuaiqiang Wang",
                "Dawei Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17394v1",
                "http://arxiv.org/pdf/2310.17394v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17386v1",
            "title": "A Challenge in Reweighting Data with Bilevel Optimization",
            "updated": "2023-10-26T13:33:26Z",
            "published": "2023-10-26T13:33:26Z",
            "summary": "In many scenarios, one uses a large training set to train a model with the\ngoal of performing well on a smaller testing set with a different distribution.\nLearning a weight for each data point of the training set is an appealing\nsolution, as it ideally allows one to automatically learn the importance of\neach training point for generalization on the testing set. This task is usually\nformalized as a bilevel optimization problem. Classical bilevel solvers are\nbased on a warm-start strategy where both the parameters of the models and the\ndata weights are learned at the same time. We show that this joint dynamic may\nlead to sub-optimal solutions, for which the final data weights are very\nsparse. This finding illustrates the difficulty of data reweighting and offers\na clue as to why this method is rarely used in practice.",
            "author": [
                "Anastasia Ivanova",
                "Pierre Ablin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17386v1",
                "http://arxiv.org/pdf/2310.17386v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17385v1",
            "title": "Multitask Online Learning: Listen to the Neighborhood Buzz",
            "updated": "2023-10-26T13:32:49Z",
            "published": "2023-10-26T13:32:49Z",
            "summary": "We study multitask online learning in a setting where agents can only\nexchange information with their neighbors on an arbitrary communication\nnetwork. We introduce $\\texttt{MT-CO}_2\\texttt{OL}$, a decentralized algorithm\nfor this setting whose regret depends on the interplay between the task\nsimilarities and the network structure. Our analysis shows that the regret of\n$\\texttt{MT-CO}_2\\texttt{OL}$ is never worse (up to constants) than the bound\nobtained when agents do not share information. On the other hand, our bounds\nsignificantly improve when neighboring agents operate on similar tasks. In\naddition, we prove that our algorithm can be made differentially private with a\nnegligible impact on the regret when the losses are linear. Finally, we provide\nexperimental support for our theory.",
            "author": [
                "Juliette Achddou",
                "Nicol\u00f2 Cesa-Bianchi",
                "Pierre Laforgue"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17385v1",
                "http://arxiv.org/pdf/2310.17385v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17383v1",
            "title": "On the recognition of the game type based on physiological signals and\n  eye tracking",
            "updated": "2023-10-26T13:27:23Z",
            "published": "2023-10-26T13:27:23Z",
            "summary": "Automated interpretation of signals yields many impressive applications from\nthe area of affective computing and human activity recognition (HAR). In this\npaper we ask the question about possibility of cognitive activity recognition\non the base of particular set of signals. We use recognition of the game played\nby the participant as a playground for exploration of the problem. We build\nclassifier of three different games (Space Invaders, Tetris, Tower Defence) and\ninter-game pause. We validate classifier in the player-independent and\nplayer-dependent scenario. We discuss the improvement in the player-dependent\nscenario in the context of biometric person recognition. On the base of the\nresults obtained in game classification, we consider potential applications in\nsmart surveillance and quantified self.",
            "author": [
                "\u0141ukasz Czekaj",
                "\u0141ukasz Radzinski",
                "Mateusz Kolimaga",
                "Jakub Domaszewicz",
                "Robert Kit\u0142owski",
                "Mariusz Szwoch",
                "W\u0142odzis\u0142aw Duch"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17383v1",
                "http://arxiv.org/pdf/2310.17383v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17378v2",
            "title": "Optimization dependent generalization bound for ReLU networks based on\n  sensitivity in the tangent bundle",
            "updated": "2023-12-04T15:57:40Z",
            "published": "2023-10-26T13:14:13Z",
            "summary": "Recent advances in deep learning have given us some very promising results on\nthe generalization ability of deep neural networks, however literature still\nlacks a comprehensive theory explaining why heavily over-parametrized models\nare able to generalize well while fitting the training data. In this paper we\npropose a PAC type bound on the generalization error of feedforward ReLU\nnetworks via estimating the Rademacher complexity of the set of networks\navailable from an initial parameter vector via gradient descent. The key idea\nis to bound the sensitivity of the network's gradient to perturbation of the\ninput data along the optimization trajectory. The obtained bound does not\nexplicitly depend on the depth of the network. Our results are experimentally\nverified on the MNIST and CIFAR-10 datasets.",
            "author": [
                "D\u00e1niel R\u00e1cz",
                "Mih\u00e1ly Petreczky",
                "Andr\u00e1s Csert\u00e1n",
                "B\u00e1lint Dar\u00f3czy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17378v2",
                "http://arxiv.org/pdf/2310.17378v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "68",
                "I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17376v1",
            "title": "A Risk Management Perspective on Statistical Estimation and Generalized\n  Variational Inference",
            "updated": "2023-10-26T13:13:50Z",
            "published": "2023-10-26T13:13:50Z",
            "summary": "Generalized variational inference (GVI) provides an optimization-theoretic\nframework for statistical estimation that encapsulates many traditional\nestimation procedures. The typical GVI problem is to compute a distribution of\nparameters that maximizes the expected payoff minus the divergence of the\ndistribution from a specified prior. In this way, GVI enables likelihood-free\nestimation with the ability to control the influence of the prior by tuning the\nso-called learning rate. Recently, GVI was shown to outperform traditional\nBayesian inference when the model and prior distribution are misspecified. In\nthis paper, we introduce and analyze a new GVI formulation based on utility\ntheory and risk management. Our formulation is to maximize the expected payoff\nwhile enforcing constraints on the maximizing distribution. We recover the\noriginal GVI distribution by choosing the feasible set to include a constraint\non the divergence of the distribution from the prior. In doing so, we\nautomatically determine the learning rate as the Lagrange multiplier for the\nconstraint. In this setting, we are able to transform the infinite-dimensional\nestimation problem into a two-dimensional convex program. This reformulation\nfurther provides an analytic expression for the optimal density of parameters.\nIn addition, we prove asymptotic consistency results for empirical\napproximations of our optimal distributions. Throughout, we draw connections\nbetween our estimation procedure and risk management. In fact, we demonstrate\nthat our estimation procedure is equivalent to evaluating a risk measure. We\ntest our procedure on an estimation problem with a misspecified model and prior\ndistribution, and conclude with some extensions of our approach.",
            "author": [
                "Aurya S. Javeed",
                "Drew P. Kouri",
                "Thomas M. Surowiec"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17376v1",
                "http://arxiv.org/pdf/2310.17376v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "math.PR",
                "math.ST",
                "stat.TH",
                "62A10, 62A15, 62C12, 62G05, 62G07"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17373v1",
            "title": "FMMRec: Fairness-aware Multimodal Recommendation",
            "updated": "2023-10-26T13:10:59Z",
            "published": "2023-10-26T13:10:59Z",
            "summary": "Recently, multimodal recommendations have gained increasing attention for\neffectively addressing the data sparsity problem by incorporating\nmodality-based representations. Although multimodal recommendations excel in\naccuracy, the introduction of different modalities (e.g., images, text, and\naudio) may expose more users' sensitive information (e.g., gender and age) to\nrecommender systems, resulting in potentially more serious unfairness issues.\nDespite many efforts on fairness, existing fairness-aware methods are either\nincompatible with multimodal scenarios, or lead to suboptimal fairness\nperformance due to neglecting sensitive information of multimodal content. To\nachieve counterfactual fairness in multimodal recommendations, we propose a\nnovel fairness-aware multimodal recommendation approach (dubbed as FMMRec) to\ndisentangle the sensitive and non-sensitive information from modal\nrepresentations and leverage the disentangled modal representations to guide\nfairer representation learning. Specifically, we first disentangle biased and\nfiltered modal representations by maximizing and minimizing their sensitive\nattribute prediction ability respectively. With the disentangled modal\nrepresentations, we mine the modality-based unfair and fair (corresponding to\nbiased and filtered) user-user structures for enhancing explicit user\nrepresentation with the biased and filtered neighbors from the corresponding\nstructures, followed by adversarially filtering out sensitive information.\nExperiments on two real-world public datasets demonstrate the superiority of\nour FMMRec relative to the state-of-the-art baselines. Our source code is\navailable at https://anonymous.4open.science/r/FMMRec.",
            "author": [
                "Weixin Chen",
                "Li Chen",
                "Yongxin Ni",
                "Yuhan Zhao",
                "Fajie Yuan",
                "Yongfeng Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17373v1",
                "http://arxiv.org/pdf/2310.17373v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17368v1",
            "title": "Leveraging Contextual Information for Robustness in Vehicle Routing\n  Problems",
            "updated": "2023-10-26T12:59:21Z",
            "published": "2023-10-26T12:59:21Z",
            "summary": "We investigate the benefit of using contextual information in data-driven\ndemand predictions to solve the robust capacitated vehicle routing problem with\ntime windows. Instead of estimating the demand distribution or its mean, we\nintroduce contextual machine learning models that predict demand quantiles even\nwhen the number of historical observations for some or all customers is\nlimited. We investigate the use of such predicted quantiles to make routing\ndecisions, comparing deterministic with robust optimization models.\nFurthermore, we evaluate the efficiency and robustness of the decisions\nobtained, both using exact or heuristic methods to solve the optimization\nmodels. Our extensive computational experiments show that using a robust\noptimization model and predicting multiple quantiles is promising when\nsubstantial historical data is available. In scenarios with a limited demand\nhistory, using a deterministic model with just a single quantile exhibits\ngreater potential. Interestingly, our results also indicate that the use of\nappropriate quantile demand values within a deterministic model results in\nsolutions with robustness levels comparable to those of robust models. This is\nimportant because, in most applications, practitioners use deterministic models\nas the industry standard, even in an uncertain environment. Furthermore, as\nthey present fewer computational challenges and require only a single demand\nvalue prediction, deterministic models paired with an appropriate machine\nlearning model hold the potential for robust decision-making.",
            "author": [
                "Ali \u0130rfan Mahmuto\u011fullar\u0131",
                "Tias Guns"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17368v1",
                "http://arxiv.org/pdf/2310.17368v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17360v1",
            "title": "Towards Unifying Diffusion Models for Probabilistic Spatio-Temporal\n  Graph Learning",
            "updated": "2023-10-26T12:48:43Z",
            "published": "2023-10-26T12:48:43Z",
            "summary": "Spatio-temporal graph learning is a fundamental problem in the Web of Things\nera, which enables a plethora of Web applications such as smart cities, human\nmobility and climate analysis. Existing approaches tackle different learning\ntasks independently, tailoring their models to unique task characteristics.\nThese methods, however, fall short of modeling intrinsic uncertainties in the\nspatio-temporal data. Meanwhile, their specialized designs limit their\nuniversality as general spatio-temporal learning solutions. In this paper, we\npropose to model the learning tasks in a unified perspective, viewing them as\npredictions based on conditional information with shared spatio-temporal\npatterns. Based on this proposal, we introduce Unified Spatio-Temporal\nDiffusion Models (USTD) to address the tasks uniformly within the\nuncertainty-aware diffusion framework. USTD is holistically designed,\ncomprising a shared spatio-temporal encoder and attention-based denoising\nnetworks that are task-specific. The shared encoder, optimized by a\npre-training strategy, effectively captures conditional spatio-temporal\npatterns. The denoising networks, utilizing both cross- and self-attention,\nintegrate conditional dependencies and generate predictions. Opting for\nforecasting and kriging as downstream tasks, we design Gated Attention (SGA)\nand Temporal Gated Attention (TGA) for each task, with different emphases on\nthe spatial and temporal dimensions, respectively. By combining the advantages\nof deterministic encoders and probabilistic diffusion models, USTD achieves\nstate-of-the-art performances compared to deterministic and probabilistic\nbaselines in both tasks, while also providing valuable uncertainty estimates.",
            "author": [
                "Junfeng Hu",
                "Xu Liu",
                "Zhencheng Fan",
                "Yuxuan Liang",
                "Roger Zimmermann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17360v1",
                "http://arxiv.org/pdf/2310.17360v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17359v1",
            "title": "SE(3) Diffusion Model-based Point Cloud Registration for Robust 6D\n  Object Pose Estimation",
            "updated": "2023-10-26T12:47:26Z",
            "published": "2023-10-26T12:47:26Z",
            "summary": "In this paper, we introduce an SE(3) diffusion model-based point cloud\nregistration framework for 6D object pose estimation in real-world scenarios.\nOur approach formulates the 3D registration task as a denoising diffusion\nprocess, which progressively refines the pose of the source point cloud to\nobtain a precise alignment with the model point cloud. Training our framework\ninvolves two operations: An SE(3) diffusion process and an SE(3) reverse\nprocess. The SE(3) diffusion process gradually perturbs the optimal rigid\ntransformation of a pair of point clouds by continuously injecting noise\n(perturbation transformation). By contrast, the SE(3) reverse process focuses\non learning a denoising network that refines the noisy transformation\nstep-by-step, bringing it closer to the optimal transformation for accurate\npose estimation. Unlike standard diffusion models used in linear Euclidean\nspaces, our diffusion model operates on the SE(3) manifold. This requires\nexploiting the linear Lie algebra $\\mathfrak{se}(3)$ associated with SE(3) to\nconstrain the transformation transitions during the diffusion and reverse\nprocesses. Additionally, to effectively train our denoising network, we derive\na registration-specific variational lower bound as the optimization objective\nfor model learning. Furthermore, we show that our denoising network can be\nconstructed with a surrogate registration model, making our approach applicable\nto different deep registration networks. Extensive experiments demonstrate that\nour diffusion registration framework presents outstanding pose estimation\nperformance on the real-world TUD-L, LINEMOD, and Occluded-LINEMOD datasets.",
            "author": [
                "Haobo Jiang",
                "Mathieu Salzmann",
                "Zheng Dang",
                "Jin Xie",
                "Jian Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17359v1",
                "http://arxiv.org/pdf/2310.17359v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17356v1",
            "title": "Sky Imager-Based Forecast of Solar Irradiance Using Machine Learning",
            "updated": "2023-10-26T12:44:45Z",
            "published": "2023-10-26T12:44:45Z",
            "summary": "Ahead-of-time forecasting of the output power of power plants is essential\nfor the stability of the electricity grid and ensuring uninterrupted service.\nHowever, forecasting renewable energy sources is difficult due to the chaotic\nbehavior of natural energy sources. This paper presents a new approach to\nestimate short-term solar irradiance from sky images. The~proposed algorithm\nextracts features from sky images and use learning-based techniques to estimate\nthe solar irradiance. The~performance of proposed machine learning (ML)\nalgorithm is evaluated using two publicly available datasets of sky images.\nThe~datasets contain over 350,000 images for an interval of 16 years, from 2004\nto 2020, with the corresponding global horizontal irradiance (GHI) of each\nimage as the ground truth. Compared to the state-of-the-art computationally\nheavy algorithms proposed in the literature, our approach achieves competitive\nresults with much less computational complexity for both nowcasting and\nforecasting up to 4 h ahead of time.",
            "author": [
                "Anas Al-lahham",
                "Obaidah Theeb",
                "Khaled Elalem",
                "Tariq A. Alshawi",
                "Saleh A. Alshebeili"
            ],
            "link": [
                "http://dx.doi.org/10.3390/electronics9101700",
                "http://arxiv.org/abs/2310.17356v1",
                "http://arxiv.org/pdf/2310.17356v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17355v2",
            "title": "Exploring the Trie of Rules: a fast data structure for the\n  representation of association rules",
            "updated": "2023-11-21T13:27:01Z",
            "published": "2023-10-26T12:44:33Z",
            "summary": "Association rule mining techniques can generate a large volume of sequential\ndata when implemented on transactional databases. Extracting insights from a\nlarge set of association rules has been found to be a challenging process. When\nexamining a ruleset, the fundamental question is how to summarise and represent\nmeaningful mined knowledge efficiently. Many algorithms and strategies have\nbeen developed to address issue of knowledge extraction; however, the\neffectiveness of this process can be limited by the data structures. A better\ndata structure can sufficiently affect the speed of the knowledge extraction\nprocess. This paper proposes a novel data structure, called the Trie of rules,\nfor storing a ruleset that is generated by association rule mining. The\nresulting data structure is a prefix-tree graph structure made of pre-mined\nrules. This graph stores the rules as paths within the prefix-tree in a way\nthat similar rules overlay each other. Each node in the tree represents a rule\nwhere a consequent is this node, and an antecedent is a path from this node to\nthe root of the tree. The evaluation showed that the proposed representation\ntechnique is promising. It compresses a ruleset with almost no data loss and\nbenefits in terms of time for basic operations such as searching for a specific\nrule and sorting, which is the base for many knowledge discovery methods.\nMoreover, our method demonstrated a significant improvement in traversing time,\nachieving an 8-fold increase compared to traditional data structures.",
            "author": [
                "Mikhail Kudriavtsev",
                "Marija Bezbradica",
                "Andrew McCarren"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17355v2",
                "http://arxiv.org/pdf/2310.17355v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "I.2.4; H.3.3; E.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17348v1",
            "title": "Network Intrusion Detection with Edge-Directed Graph Multi-Head\n  Attention Networks",
            "updated": "2023-10-26T12:30:11Z",
            "published": "2023-10-26T12:30:11Z",
            "summary": "A network intrusion usually involves a number of network locations. Data flow\n(including the data generated by intrusion behaviors) among these locations\n(usually represented by IP addresses) naturally forms a graph. Thus, graph\nneural networks (GNNs) have been used in the construction of intrusion\ndetection models in recent years since they have an excellent ability to\ncapture graph topological features of intrusion data flow. However, existing\nGNN models treat node mean aggregation equally in node information aggregation.\nIn reality, the correlations of nodes and their neighbors as well as the linked\nedges are different. Assigning higher weights to nodes and edges with high\nsimilarity can highlight the correlation among them, which will enhance the\naccuracy and expressiveness of the model. To this end, this paper proposes\nnovel Edge-Directed Graph Multi-Head Attention Networks (EDGMAT) for network\nintrusion detection. The proposed EDGMAT model introduces a multi-head\nattention mechanism into the intrusion detection model. Additional weight\nlearning is realized through the combination of a multi-head attention\nmechanism and edge features. Weighted aggregation makes better use of the\nrelationship between different network traffic data. Experimental results on\nfour recent NIDS benchmark datasets show that the performance of EDGMAT in\nterms of weighted F1-Score is significantly better than that of four\nstate-of-the-art models in multi-class detection tasks.",
            "author": [
                "Xiang Li",
                "Jing Zhang",
                "Yali Yuan",
                "Cangqi Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17348v1",
                "http://arxiv.org/pdf/2310.17348v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17342v1",
            "title": "ACT-SQL: In-Context Learning for Text-to-SQL with\n  Automatically-Generated Chain-of-Thought",
            "updated": "2023-10-26T12:16:25Z",
            "published": "2023-10-26T12:16:25Z",
            "summary": "Recently Large Language Models (LLMs) have been proven to have strong\nabilities in various domains and tasks. We study the problem of prompt\ndesigning in the text-to-SQL task and attempt to improve the LLMs' reasoning\nability when generating SQL queries. Besides the trivial few-shot in-context\nlearning setting, we design our chain-of-thought (CoT) prompt with a similar\nmethod to schema linking. We provide a method named ACT-SQL to automatically\ngenerate auto-CoT exemplars and thus the whole process doesn't need manual\nlabeling. Our approach is cost-saving since we only use the LLMs' API call once\nwhen generating one SQL query. Furthermore, we extend our in-context learning\nmethod to the multi-turn text-to-SQL task. The experiment results show that the\nLLMs' performance can benefit from our ACT-SQL approach. Our approach achieves\nSOTA performance on the Spider dev set among existing in-context learning\napproaches.",
            "author": [
                "Hanchong Zhang",
                "Ruisheng Cao",
                "Lu Chen",
                "Hongshen Xu",
                "Kai Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17342v1",
                "http://arxiv.org/pdf/2310.17342v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17341v3",
            "title": "De-novo Chemical Reaction Generation by Means of Temporal Convolutional\n  Neural Networks",
            "updated": "2023-11-01T23:27:13Z",
            "published": "2023-10-26T12:15:56Z",
            "summary": "We present here a combination of two networks, Recurrent Neural Networks\n(RNN) and Temporarily Convolutional Neural Networks (TCN) in de novo reaction\ngeneration using the novel Reaction Smiles-like representation of reactions\n(CGRSmiles) with atom mapping directly incorporated. Recurrent Neural Networks\nare known for their autoregressive properties and are frequently used in\nlanguage modelling with direct application to SMILES generation. The relatively\nnovel TCNs possess similar properties with wide receptive field while obeying\nthe causality required for natural language processing (NLP). The combination\nof both latent representations expressed through TCN and RNN results in an\noverall better performance compared to RNN alone. Additionally, it is shown\nthat different fine-tuning protocols have a profound impact on generative scope\nof the model when applied on a dataset of interest via transfer learning.",
            "author": [
                "Andrei Buin",
                "Hung Yi Chiang",
                "S. Andrew Gadsden",
                "Faraz A. Alderson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17341v3",
                "http://arxiv.org/pdf/2310.17341v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17335v1",
            "title": "A multi-artifact EEG denoising by frequency-based deep learning",
            "updated": "2023-10-26T12:01:47Z",
            "published": "2023-10-26T12:01:47Z",
            "summary": "Electroencephalographic (EEG) signals are fundamental to neuroscience\nresearch and clinical applications such as brain-computer interfaces and\nneurological disorder diagnosis. These signals are typically a combination of\nneurological activity and noise, originating from various sources, including\nphysiological artifacts like ocular and muscular movements. Under this setting,\nwe tackle the challenge of distinguishing neurological activity from\nnoise-related sources. We develop a novel EEG denoising model that operates in\nthe frequency domain, leveraging prior knowledge about noise spectral features\nto adaptively compute optimal convolutional filters for noise separation. The\nmodel is trained to learn an empirical relationship connecting the spectral\ncharacteristics of noise and noisy signal to a non-linear transformation which\nallows signal denoising. Performance evaluation on the EEGdenoiseNet dataset\nshows that the proposed model achieves optimal results according to both\ntemporal and spectral metrics. The model is found to remove physiological\nartifacts from input EEG data, thus achieving effective EEG denoising. Indeed,\nthe model performance either matches or outperforms that achieved by benchmark\nmodels, proving to effectively remove both muscle and ocular artifacts without\nthe need to perform any training on the particular type of artifact.",
            "author": [
                "Matteo Gabardi",
                "Aurora Saibene",
                "Francesca Gasparini",
                "Daniele Rizzo",
                "Fabio Antonio Stella"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17335v1",
                "http://arxiv.org/pdf/2310.17335v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17332v1",
            "title": "On Forecast Stability",
            "updated": "2023-10-26T11:55:30Z",
            "published": "2023-10-26T11:55:30Z",
            "summary": "Forecasts are typically not produced in a vacuum but in a business context,\nwhere forecasts are generated on a regular basis and interact with each other.\nFor decisions, it may be important that forecasts do not change arbitrarily,\nand are stable in some sense. However, this area has received only limited\nattention in the forecasting literature. In this paper, we explore two types of\nforecast stability that we call vertical stability and horizontal stability.\nThe existing works in the literature are only applicable to certain base models\nand extending these frameworks to be compatible with any base model is not\nstraightforward. Furthermore, these frameworks can only stabilise the forecasts\nvertically. To fill this gap, we propose a simple linear-interpolation-based\napproach that is applicable to stabilise the forecasts provided by any base\nmodel vertically and horizontally. The approach can produce both accurate and\nstable forecasts. Using N-BEATS, Pooled Regression and LightGBM as the base\nmodels, in our evaluation on four publicly available datasets, the proposed\nframework is able to achieve significantly higher stability and/or accuracy\ncompared to a set of benchmarks including a state-of-the-art forecast\nstabilisation method across three error metrics and six stability metrics.",
            "author": [
                "Rakshitha Godahewa",
                "Christoph Bergmeir",
                "Zeynep Erkin Baz",
                "Chengjun Zhu",
                "Zhangdi Song",
                "Salvador Garc\u00eda",
                "Dario Benavides"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17332v1",
                "http://arxiv.org/pdf/2310.17332v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17330v1",
            "title": "CQM: Curriculum Reinforcement Learning with a Quantized World Model",
            "updated": "2023-10-26T11:50:58Z",
            "published": "2023-10-26T11:50:58Z",
            "summary": "Recent curriculum Reinforcement Learning (RL) has shown notable progress in\nsolving complex tasks by proposing sequences of surrogate tasks. However, the\nprevious approaches often face challenges when they generate curriculum goals\nin a high-dimensional space. Thus, they usually rely on manually specified goal\nspaces. To alleviate this limitation and improve the scalability of the\ncurriculum, we propose a novel curriculum method that automatically defines the\nsemantic goal space which contains vital information for the curriculum\nprocess, and suggests curriculum goals over it. To define the semantic goal\nspace, our method discretizes continuous observations via vector\nquantized-variational autoencoders (VQ-VAE) and restores the temporal relations\nbetween the discretized observations by a graph. Concurrently, ours suggests\nuncertainty and temporal distance-aware curriculum goals that converges to the\nfinal goals over the automatically composed goal space. We demonstrate that the\nproposed method allows efficient explorations in an uninformed environment with\nraw goal examples only. Also, ours outperforms the state-of-the-art curriculum\nRL methods on data efficiency and performance, in various goal-reaching tasks\neven with ego-centric visual inputs.",
            "author": [
                "Seungjae Lee",
                "Daesol Cho",
                "Jonghae Park",
                "H. Jin Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17330v1",
                "http://arxiv.org/pdf/2310.17330v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17325v1",
            "title": "C-Disentanglement: Discovering Causally-Independent Generative Factors\n  under an Inductive Bias of Confounder",
            "updated": "2023-10-26T11:44:42Z",
            "published": "2023-10-26T11:44:42Z",
            "summary": "Representation learning assumes that real-world data is generated by a few\nsemantically meaningful generative factors (i.e., sources of variation) and\naims to discover them in the latent space. These factors are expected to be\ncausally disentangled, meaning that distinct factors are encoded into separate\nlatent variables, and changes in one factor will not affect the values of the\nothers. Compared to statistical independence, causal disentanglement allows\nmore controllable data generation, improved robustness, and better\ngeneralization. However, most existing work assumes unconfoundedness in the\ndiscovery process, that there are no common causes to the generative factors\nand thus obtain only statistical independence. In this paper, we recognize the\nimportance of modeling confounders in discovering causal generative factors.\nUnfortunately, such factors are not identifiable without proper inductive bias.\nWe fill the gap by introducing a framework entitled Confounded-Disentanglement\n(C-Disentanglement), the first framework that explicitly introduces the\ninductive bias of confounder via labels from domain expertise. In addition, we\naccordingly propose an approach to sufficiently identify the causally\ndisentangled factors under any inductive bias of the confounder. We conduct\nextensive experiments on both synthetic and real-world datasets. Our method\ndemonstrates competitive results compared to various SOTA baselines in\nobtaining causally disentangled features and downstream tasks under domain\nshifts.",
            "author": [
                "Xiaoyu Liu",
                "Jiaxin Yuan",
                "Bang An",
                "Yuancheng Xu",
                "Yifan Yang",
                "Furong Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17325v1",
                "http://arxiv.org/pdf/2310.17325v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17681v1",
            "title": "Feature Extraction and Classification from Planetary Science Datasets\n  enabled by Machine Learning",
            "updated": "2023-10-26T11:43:55Z",
            "published": "2023-10-26T11:43:55Z",
            "summary": "In this paper we present two examples of recent investigations that we have\nundertaken, applying Machine Learning (ML) neural networks (NN) to image\ndatasets from outer planet missions to achieve feature recognition. Our first\ninvestigation was to recognize ice blocks (also known as rafts, plates,\npolygons) in the chaos regions of fractured ice on Europa. We used a transfer\nlearning approach, adding and training new layers to an industry-standard Mask\nR-CNN (Region-based Convolutional Neural Network) to recognize labeled blocks\nin a training dataset. Subsequently, the updated model was tested against a new\ndataset, achieving 68% precision. In a different application, we applied the\nMask R-CNN to recognize clouds on Titan, again through updated training\nfollowed by testing against new data, with a precision of 95% over 369 images.\nWe evaluate the relative successes of our techniques and suggest how training\nand recognition could be further improved. The new approaches we have used for\nplanetary datasets can further be applied to similar recognition tasks on other\nplanets, including Earth. For imagery of outer planets in particular, the\ntechnique holds the possibility of greatly reducing the volume of returned\ndata, via onboard identification of the most interesting image subsets, or by\nreturning only differential data (images where changes have occurred) greatly\nenhancing the information content of the final data stream.",
            "author": [
                "Conor Nixon",
                "Zachary Yahn",
                "Ethan Duncan",
                "Ian Neidel",
                "Alyssa Mills",
                "Beno\u00eet Seignovert",
                "Andrew Larsen",
                "Kathryn Gansler",
                "Charles Liles",
                "Catherine Walker",
                "Douglas Trent",
                "John Santerre"
            ],
            "link": [
                "http://dx.doi.org/10.1109/AERO55745.2023.10115556",
                "http://arxiv.org/abs/2310.17681v1",
                "http://arxiv.org/pdf/2310.17681v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.IM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16122v1",
            "title": "Semantic Generative Augmentations for Few-Shot Counting",
            "updated": "2023-10-26T11:42:48Z",
            "published": "2023-10-26T11:42:48Z",
            "summary": "With the availability of powerful text-to-image diffusion models, recent\nworks have explored the use of synthetic data to improve image classification\nperformances. These works show that it can effectively augment or even replace\nreal data. In this work, we investigate how synthetic data can benefit few-shot\nclass-agnostic counting. This requires to generate images that correspond to a\ngiven input number of objects. However, text-to-image models struggle to grasp\nthe notion of count. We propose to rely on a double conditioning of Stable\nDiffusion with both a prompt and a density map in order to augment a training\ndataset for few-shot counting. Due to the small dataset size, the fine-tuned\nmodel tends to generate images close to the training images. We propose to\nenhance the diversity of synthesized images by exchanging captions between\nimages thus creating unseen configurations of object types and spatial layout.\nOur experiments show that our diversified generation strategy significantly\nimproves the counting accuracy of two recent and performing few-shot counting\nmodels on FSC147 and CARPK.",
            "author": [
                "Perla Doubinsky",
                "Nicolas Audebert",
                "Michel Crucianu",
                "Herv\u00e9 Le Borgne"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16122v1",
                "http://arxiv.org/pdf/2311.16122v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17319v1",
            "title": "Trust Region Methods For Nonconvex Stochastic Optimization Beyond\n  Lipschitz Smoothness",
            "updated": "2023-10-26T11:37:28Z",
            "published": "2023-10-26T11:37:28Z",
            "summary": "In many important machine learning applications, the standard assumption of\nhaving a globally Lipschitz continuous gradient may fail to hold. This paper\ndelves into a more general $(L_0, L_1)$-smoothness setting, which gains\nparticular significance within the realms of deep neural networks and\ndistributionally robust optimization (DRO). We demonstrate the significant\nadvantage of trust region methods for stochastic nonconvex optimization under\nsuch generalized smoothness assumption. We show that first-order trust region\nmethods can recover the normalized and clipped stochastic gradient as special\ncases and then provide a unified analysis to show their convergence to\nfirst-order stationary conditions. Motivated by the important application of\nDRO, we propose a generalized high-order smoothness condition, under which\nsecond-order trust region methods can achieve a complexity of\n$\\mathcal{O}(\\epsilon^{-3.5})$ for convergence to second-order stationary\npoints. By incorporating variance reduction, the second-order trust region\nmethod obtains an even better complexity of $\\mathcal{O}(\\epsilon^{-3})$,\nmatching the optimal bound for standard smooth optimization. To our best\nknowledge, this is the first work to show convergence beyond the first-order\nstationary condition for generalized smooth optimization. Preliminary\nexperiments show that our proposed algorithms perform favorably compared with\nexisting methods.",
            "author": [
                "Chenghan Xie",
                "Chenxi Li",
                "Chuwen Zhang",
                "Qi Deng",
                "Dongdong Ge",
                "Yinyu Ye"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17319v1",
                "http://arxiv.org/pdf/2310.17319v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17306v3",
            "title": "FormaT5: Abstention and Examples for Conditional Table Formatting with\n  Natural Language",
            "updated": "2023-11-01T17:31:30Z",
            "published": "2023-10-26T11:05:15Z",
            "summary": "Formatting is an important property in tables for visualization,\npresentation, and analysis. Spreadsheet software allows users to automatically\nformat their tables by writing data-dependent conditional formatting (CF)\nrules. Writing such rules is often challenging for users as it requires them to\nunderstand and implement the underlying logic. We present FormaT5, a\ntransformer-based model that can generate a CF rule given the target table and\na natural language description of the desired formatting logic. We find that\nuser descriptions for these tasks are often under-specified or ambiguous,\nmaking it harder for code generation systems to accurately learn the desired\nrule in a single step. To tackle this problem of under-specification and\nminimise argument errors, FormaT5 learns to predict placeholders though an\nabstention objective. These placeholders can then be filled by a second model\nor, when examples of rows that should be formatted are available, by a\nprogramming-by-example system. To evaluate FormaT5 on diverse and real\nscenarios, we create an extensive benchmark of 1053 CF tasks, containing\nreal-world descriptions collected from four different sources. We release our\nbenchmarks to encourage research in this area. Abstention and filling allow\nFormaT5 to outperform 8 different neural approaches on our benchmarks, both\nwith and without examples. Our results illustrate the value of building\ndomain-specific learning systems.",
            "author": [
                "Mukul Singh",
                "Jos\u00e9 Cambronero",
                "Sumit Gulwani",
                "Vu Le",
                "Carina Negreanu",
                "Elnaz Nouri",
                "Mohammad Raza",
                "Gust Verbruggen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17306v3",
                "http://arxiv.org/pdf/2310.17306v3"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.DB",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17303v1",
            "title": "Demonstration-Regularized RL",
            "updated": "2023-10-26T10:54:47Z",
            "published": "2023-10-26T10:54:47Z",
            "summary": "Incorporating expert demonstrations has empirically helped to improve the\nsample efficiency of reinforcement learning (RL). This paper quantifies\ntheoretically to what extent this extra information reduces RL's sample\ncomplexity. In particular, we study the demonstration-regularized reinforcement\nlearning that leverages the expert demonstrations by KL-regularization for a\npolicy learned by behavior cloning. Our findings reveal that using\n$N^{\\mathrm{E}}$ expert demonstrations enables the identification of an optimal\npolicy at a sample complexity of order\n$\\widetilde{\\mathcal{O}}(\\mathrm{Poly}(S,A,H)/(\\varepsilon^2 N^{\\mathrm{E}}))$\nin finite and $\\widetilde{\\mathcal{O}}(\\mathrm{Poly}(d,H)/(\\varepsilon^2\nN^{\\mathrm{E}}))$ in linear Markov decision processes, where $\\varepsilon$ is\nthe target precision, $H$ the horizon, $A$ the number of action, $S$ the number\nof states in the finite case and $d$ the dimension of the feature space in the\nlinear case. As a by-product, we provide tight convergence guarantees for the\nbehaviour cloning procedure under general assumptions on the policy classes.\nAdditionally, we establish that demonstration-regularized methods are provably\nefficient for reinforcement learning from human feedback (RLHF). In this\nrespect, we provide theoretical evidence showing the benefits of\nKL-regularization for RLHF in tabular and linear MDPs. Interestingly, we avoid\npessimism injection by employing computationally feasible regularization to\nhandle reward estimation uncertainty, thus setting our approach apart from the\nprior works.",
            "author": [
                "Daniil Tiapkin",
                "Denis Belomestny",
                "Daniele Calandriello",
                "Eric Moulines",
                "Alexey Naumov",
                "Pierre Perrault",
                "Michal Valko",
                "Pierre Menard"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17303v1",
                "http://arxiv.org/pdf/2310.17303v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17293v1",
            "title": "Learning with a linear loss function. Excess risk and estimation bounds\n  for ERM, minmax MOM and their regularized versions. Applications to\n  robustness in sparse PCA",
            "updated": "2023-10-26T10:18:39Z",
            "published": "2023-10-26T10:18:39Z",
            "summary": "Motivated by several examples, we consider a general framework of learning\nwith linear loss functions. In this context, we provide excess risk and\nestimation bounds that hold with large probability for four estimators: ERM,\nminmax MOM and their regularized versions. These general bounds are applied for\nthe problem of robustness in sparse PCA. In particular, we improve the state of\nthe art result for this this problems, obtain results under weak moment\nassumptions as well as for adversarial contaminated data.",
            "author": [
                "Guillaume Lecu\u00e9",
                "Lucie Neirac"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17293v1",
                "http://arxiv.org/pdf/2310.17293v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.TH",
                "62F35"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17284v1",
            "title": "Learning to Abstract with Nonparametric Variational Information\n  Bottleneck",
            "updated": "2023-10-26T10:04:31Z",
            "published": "2023-10-26T10:04:31Z",
            "summary": "Learned representations at the level of characters, sub-words, words and\nsentences, have each contributed to advances in understanding different NLP\ntasks and linguistic phenomena. However, learning textual embeddings is costly\nas they are tokenization specific and require different models to be trained\nfor each level of abstraction. We introduce a novel language representation\nmodel which can learn to compress to different levels of abstraction at\ndifferent layers of the same model. We apply Nonparametric Variational\nInformation Bottleneck (NVIB) to stacked Transformer self-attention layers in\nthe encoder, which encourages an information-theoretic compression of the\nrepresentations through the model. We find that the layers within the model\ncorrespond to increasing levels of abstraction and that their representations\nare more linguistically informed. Finally, we show that NVIB compression\nresults in a model which is more robust to adversarial perturbations.",
            "author": [
                "Melika Behjati",
                "Fabio Fehr",
                "James Henderson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17284v1",
                "http://arxiv.org/pdf/2310.17284v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17679v1",
            "title": "Fast Scalable and Accurate Discovery of DAGs Using the Best Order Score\n  Search and Grow-Shrink Trees",
            "updated": "2023-10-26T10:03:12Z",
            "published": "2023-10-26T10:03:12Z",
            "summary": "Learning graphical conditional independence structures is an important\nmachine learning problem and a cornerstone of causal discovery. However, the\naccuracy and execution time of learning algorithms generally struggle to scale\nto problems with hundreds of highly connected variables -- for instance,\nrecovering brain networks from fMRI data. We introduce the best order score\nsearch (BOSS) and grow-shrink trees (GSTs) for learning directed acyclic graphs\n(DAGs) in this paradigm. BOSS greedily searches over permutations of variables,\nusing GSTs to construct and score DAGs from permutations. GSTs efficiently\ncache scores to eliminate redundant calculations. BOSS achieves\nstate-of-the-art performance in accuracy and execution time, comparing\nfavorably to a variety of combinatorial and gradient-based learning algorithms\nunder a broad range of conditions. To demonstrate its practicality, we apply\nBOSS to two sets of resting-state fMRI data: simulated data with\npseudo-empirical noise distributions derived from randomized empirical fMRI\ncortical signals and clinical data from 3T fMRI scans processed into cortical\nparcels. BOSS is available for use within the TETRAD project which includes\nPython and R wrappers.",
            "author": [
                "Bryan Andrews",
                "Joseph Ramsey",
                "Ruben Sanchez-Romero",
                "Jazmin Camchong",
                "Erich Kummerfeld"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17679v1",
                "http://arxiv.org/pdf/2310.17679v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17281v1",
            "title": "BEVContrast: Self-Supervision in BEV Space for Automotive Lidar Point\n  Clouds",
            "updated": "2023-10-26T10:02:33Z",
            "published": "2023-10-26T10:02:33Z",
            "summary": "We present a surprisingly simple and efficient method for self-supervision of\n3D backbone on automotive Lidar point clouds. We design a contrastive loss\nbetween features of Lidar scans captured in the same scene. Several such\napproaches have been proposed in the literature from PointConstrast, which uses\na contrast at the level of points, to the state-of-the-art TARL, which uses a\ncontrast at the level of segments, roughly corresponding to objects. While the\nformer enjoys a great simplicity of implementation, it is surpassed by the\nlatter, which however requires a costly pre-processing. In BEVContrast, we\ndefine our contrast at the level of 2D cells in the Bird's Eye View plane.\nResulting cell-level representations offer a good trade-off between the\npoint-level representations exploited in PointContrast and segment-level\nrepresentations exploited in TARL: we retain the simplicity of PointContrast\n(cell representations are cheap to compute) while surpassing the performance of\nTARL in downstream semantic segmentation.",
            "author": [
                "Corentin Sautier",
                "Gilles Puy",
                "Alexandre Boulch",
                "Renaud Marlet",
                "Vincent Lepetit"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17281v1",
                "http://arxiv.org/pdf/2310.17281v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17273v3",
            "title": "Looping in the Human: Collaborative and Explainable Bayesian\n  Optimization",
            "updated": "2023-11-06T19:25:58Z",
            "published": "2023-10-26T09:50:31Z",
            "summary": "Like many optimizers, Bayesian optimization often falls short of gaining user\ntrust due to opacity. While attempts have been made to develop human-centric\noptimizers, they typically assume user knowledge is well-specified and\nerror-free, employing users mainly as supervisors of the optimization process.\nWe relax these assumptions and propose a more balanced human-AI partnership\nwith our Collaborative and Explainable Bayesian Optimization (CoExBO)\nframework. Instead of explicitly requiring a user to provide a knowledge model,\nCoExBO employs preference learning to seamlessly integrate human insights into\nthe optimization, resulting in algorithmic suggestions that resonate with user\npreference. CoExBO explains its candidate selection every iteration to foster\ntrust, empowering users with a clearer grasp of the optimization. Furthermore,\nCoExBO offers a no-harm guarantee, allowing users to make mistakes; even with\nextreme adversarial interventions, the algorithm converges asymptotically to a\nvanilla Bayesian optimization. We validate CoExBO's efficacy through human-AI\nteaming experiments in lithium-ion battery design, highlighting substantial\nimprovements over conventional methods.",
            "author": [
                "Masaki Adachi",
                "Brady Planden",
                "David A. Howey",
                "Krikamol Muandet",
                "Michael A. Osborne",
                "Siu Lun Chau"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17273v3",
                "http://arxiv.org/pdf/2310.17273v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.HC",
                "stat.ML",
                "62C10, 62F15"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17271v1",
            "title": "Understanding the Role of Input Token Characters in Language Models: How\n  Does Information Loss Affect Performance?",
            "updated": "2023-10-26T09:47:50Z",
            "published": "2023-10-26T09:47:50Z",
            "summary": "Understanding how and what pre-trained language models (PLMs) learn about\nlanguage is an open challenge in natural language processing. Previous work has\nfocused on identifying whether they capture semantic and syntactic information,\nand how the data or the pre-training objective affects their performance.\nHowever, to the best of our knowledge, no previous work has specifically\nexamined how information loss in input token characters affects the performance\nof PLMs. In this study, we address this gap by pre-training language models\nusing small subsets of characters from individual tokens. Surprisingly, we find\nthat pre-training even under extreme settings, i.e. using only one character of\neach token, the performance retention in standard NLU benchmarks and probing\ntasks compared to full-token models is high. For instance, a model pre-trained\nonly on single first characters from tokens achieves performance retention of\napproximately $90$\\% and $77$\\% of the full-token model in SuperGLUE and GLUE\ntasks, respectively.",
            "author": [
                "Ahmed Alajrami",
                "Katerina Margatina",
                "Nikolaos Aletras"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17271v1",
                "http://arxiv.org/pdf/2310.17271v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17264v1",
            "title": "Variance of ML-based software fault predictors: are we really improving\n  fault prediction?",
            "updated": "2023-10-26T09:31:32Z",
            "published": "2023-10-26T09:31:32Z",
            "summary": "Software quality assurance activities become increasingly difficult as\nsoftware systems become more and more complex and continuously grow in size.\nMoreover, testing becomes even more expensive when dealing with large-scale\nsystems. Thus, to effectively allocate quality assurance resources, researchers\nhave proposed fault prediction (FP) which utilizes machine learning (ML) to\npredict fault-prone code areas. However, ML algorithms typically make use of\nstochastic elements to increase the prediction models' generalizability and\nefficiency of the training process. These stochastic elements, also known as\nnondeterminism-introducing (NI) factors, lead to variance in the training\nprocess and as a result, lead to variance in prediction accuracy and training\ntime. This variance poses a challenge for reproducibility in research. More\nimportantly, while fault prediction models may have shown good performance in\nthe lab (e.g., often-times involving multiple runs and averaging outcomes),\nhigh variance of results can pose the risk that these models show low\nperformance when applied in practice. In this work, we experimentally analyze\nthe variance of a state-of-the-art fault prediction approach. Our experimental\nresults indicate that NI factors can indeed cause considerable variance in the\nfault prediction models' accuracy. We observed a maximum variance of 10.10% in\nterms of the per-class accuracy metric. We thus, also discuss how to deal with\nsuch variance.",
            "author": [
                "Xhulja Shahini",
                "Domenic Bubel",
                "Andreas Metzger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17264v1",
                "http://arxiv.org/pdf/2310.17264v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17256v1",
            "title": "fairret: a Framework for Differentiable Fairness Regularization Terms",
            "updated": "2023-10-26T09:13:15Z",
            "published": "2023-10-26T09:13:15Z",
            "summary": "Current tools for machine learning fairness only admit a limited range of\nfairness definitions and have seen little integration with automatic\ndifferentiation libraries, despite the central role these libraries play in\nmodern machine learning pipelines.\n  We introduce a framework of fairness regularization terms (fairrets) which\nquantify bias as modular objectives that are easily integrated in automatic\ndifferentiation pipelines. By employing a general definition of fairness in\nterms of linear-fractional statistics, a wide class of fairrets can be computed\nefficiently. Experiments show the behavior of their gradients and their utility\nin enforcing fairness with minimal loss of predictive power compared to\nbaselines. Our contribution includes a PyTorch implementation of the fairret\nframework.",
            "author": [
                "Maarten Buyl",
                "MaryBeth Defrance",
                "Tijl De Bie"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17256v1",
                "http://arxiv.org/pdf/2310.17256v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17255v2",
            "title": "Generalizing to Unseen Domains in Diabetic Retinopathy Classification",
            "updated": "2023-10-27T04:34:33Z",
            "published": "2023-10-26T09:11:55Z",
            "summary": "Diabetic retinopathy (DR) is caused by long-standing diabetes and is among\nthe fifth leading cause for visual impairments. The process of early diagnosis\nand treatments could be helpful in curing the disease, however, the detection\nprocedure is rather challenging and mostly tedious. Therefore, automated\ndiabetic retinopathy classification using deep learning techniques has gained\ninterest in the medical imaging community. Akin to several other real-world\napplications of deep learning, the typical assumption of i.i.d data is also\nviolated in DR classification that relies on deep learning. Therefore,\ndeveloping DR classification methods robust to unseen distributions is of great\nvalue. In this paper, we study the problem of generalizing a model to unseen\ndistributions or domains (a.k.a domain generalization) in DR classification. To\nthis end, we propose a simple and effective domain generalization (DG) approach\nthat achieves self-distillation in vision transformers (ViT) via a novel\nprediction softening mechanism. This prediction softening is an adaptive convex\ncombination one-hot labels with the model's own knowledge. We perform extensive\nexperiments on challenging open-source DR classification datasets under both\nmulti-source and single-source DG settings with three different ViT backbones\nto establish the efficacy and applicability of our approach against competing\nmethods. For the first time, we report the performance of several\nstate-of-the-art DG methods on open-source DR classification datasets after\nconducting thorough experiments. Finally, our method is also capable of\ndelivering improved calibration performance than other methods, showing its\nsuitability for safety-critical applications, including healthcare. We hope\nthat our contributions would investigate more DG research across the medical\nimaging community.",
            "author": [
                "Chamuditha Jayanga Galappaththige",
                "Gayal Kuruppu",
                "Muhammad Haris Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17255v2",
                "http://arxiv.org/pdf/2310.17255v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17250v1",
            "title": "IDENAS: Internal Dependency Exploration for Neural Architecture Search",
            "updated": "2023-10-26T08:58:29Z",
            "published": "2023-10-26T08:58:29Z",
            "summary": "Machine learning is a powerful tool for extracting valuable information and\nmaking various predictions from diverse datasets. Traditional algorithms rely\non well-defined input and output variables however, there are scenarios where\nthe distinction between the input and output variables and the underlying,\nassociated (input and output) layers of the model, are unknown. Neural\nArchitecture Search (NAS) and Feature Selection have emerged as promising\nsolutions in such scenarios. This research proposes IDENAS, an Internal\nDependency-based Exploration for Neural Architecture Search, integrating NAS\nwith feature selection. The methodology explores internal dependencies in the\ncomplete parameter space for classification involving 1D sensor and 2D image\ndata as well. IDENAS employs a modified encoder-decoder model and the\nSequential Forward Search (SFS) algorithm, combining input-output configuration\nsearch with embedded feature selection. Experimental results demonstrate\nIDENASs superior performance in comparison to other algorithms, showcasing its\neffectiveness in model development pipelines and automated machine learning. On\naverage, IDENAS achieved significant modelling improvements, underscoring its\nsignificant contribution to advancing the state-of-the-art in neural\narchitecture search and feature selection integration.",
            "author": [
                "Anh T. Hoang",
                "Zsolt J. Viharos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17250v1",
                "http://arxiv.org/pdf/2310.17250v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NE",
                "68T07, 68T10, 93A10",
                "I.5.2; I.5.1; I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17247v1",
            "title": "Grokking Beyond Neural Networks: An Empirical Exploration with Model\n  Complexity",
            "updated": "2023-10-26T08:47:42Z",
            "published": "2023-10-26T08:47:42Z",
            "summary": "In some settings neural networks exhibit a phenomenon known as grokking,\nwhere they achieve perfect or near-perfect accuracy on the validation set long\nafter the same performance has been achieved on the training set. In this\npaper, we discover that grokking is not limited to neural networks but occurs\nin other settings such as Gaussian process (GP) classification, GP regression\nand linear regression. We also uncover a mechanism by which to induce grokking\non algorithmic datasets via the addition of dimensions containing spurious\ninformation. The presence of the phenomenon in non-neural architectures\nprovides evidence that grokking is not specific to SGD or weight norm\nregularisation. Instead, grokking may be possible in any setting where solution\nsearch is guided by complexity and error. Based on this insight and further\ntrends we see in the training trajectories of a Bayesian neural network (BNN)\nand GP regression model, we make progress towards a more general theory of\ngrokking. Specifically, we hypothesise that the phenomenon is governed by the\naccessibility of certain regions in the error and complexity landscapes.",
            "author": [
                "Jack Miller",
                "Charles O'Neill",
                "Thang Bui"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17247v1",
                "http://arxiv.org/pdf/2310.17247v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17245v1",
            "title": "CROP: Conservative Reward for Model-based Offline Policy Optimization",
            "updated": "2023-10-26T08:45:23Z",
            "published": "2023-10-26T08:45:23Z",
            "summary": "Offline reinforcement learning (RL) aims to optimize policy using collected\ndata without online interactions. Model-based approaches are particularly\nappealing for addressing offline RL challenges due to their capability to\nmitigate the limitations of offline data through data generation using models.\nPrior research has demonstrated that introducing conservatism into the model or\nQ-function during policy optimization can effectively alleviate the prevalent\ndistribution drift problem in offline RL. However, the investigation into the\nimpacts of conservatism in reward estimation is still lacking. This paper\nproposes a novel model-based offline RL algorithm, Conservative Reward for\nmodel-based Offline Policy optimization (CROP), which conservatively estimates\nthe reward in model training. To achieve a conservative reward estimation, CROP\nsimultaneously minimizes the estimation error and the reward of random actions.\nTheoretical analysis shows that this conservative reward mechanism leads to a\nconservative policy evaluation and helps mitigate distribution drift.\nExperiments on D4RL benchmarks showcase that the performance of CROP is\ncomparable to the state-of-the-art baselines. Notably, CROP establishes an\ninnovative connection between offline and online RL, highlighting that offline\nRL problems can be tackled by adopting online RL techniques to the empirical\nMarkov decision process trained with a conservative reward. The source code is\navailable with https://github.com/G0K0URURI/CROP.git.",
            "author": [
                "Hao Li",
                "Xiao-Hu Zhou",
                "Xiao-Liang Xie",
                "Shi-Qi Liu",
                "Zhen-Qiu Feng",
                "Xiao-Yin Liu",
                "Mei-Jiang Gui",
                "Tian-Yu Xiang",
                "De-Xing Huang",
                "Bo-Xian Yao",
                "Zeng-Guang Hou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17245v1",
                "http://arxiv.org/pdf/2310.17245v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17238v1",
            "title": "Joint Entity and Relation Extraction with Span Pruning and Hypergraph\n  Neural Networks",
            "updated": "2023-10-26T08:36:39Z",
            "published": "2023-10-26T08:36:39Z",
            "summary": "Entity and Relation Extraction (ERE) is an important task in information\nextraction. Recent marker-based pipeline models achieve state-of-the-art\nperformance, but still suffer from the error propagation issue. Also, most of\ncurrent ERE models do not take into account higher-order interactions between\nmultiple entities and relations, while higher-order modeling could be\nbeneficial.In this work, we propose HyperGraph neural network for ERE\n($\\hgnn{}$), which is built upon the PL-marker (a state-of-the-art marker-based\npipleline model). To alleviate error propagation,we use a high-recall pruner\nmechanism to transfer the burden of entity identification and labeling from the\nNER module to the joint module of our model. For higher-order modeling, we\nbuild a hypergraph, where nodes are entities (provided by the span pruner) and\nrelations thereof, and hyperedges encode interactions between two different\nrelations or between a relation and its associated subject and object entities.\nWe then run a hypergraph neural network for higher-order inference by applying\nmessage passing over the built hypergraph. Experiments on three widely used\nbenchmarks (\\acef{}, \\ace{} and \\scierc{}) for ERE task show significant\nimprovements over the previous state-of-the-art PL-marker.",
            "author": [
                "Zhaohui Yan",
                "Songlin Yang",
                "Wei Liu",
                "Kewei Tu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17238v1",
                "http://arxiv.org/pdf/2310.17238v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17237v1",
            "title": "A Unified Framework for Rank-based Loss Minimization",
            "updated": "2023-10-26T08:35:32Z",
            "published": "2023-10-26T08:35:32Z",
            "summary": "The empirical loss, commonly referred to as the average loss, is extensively\nutilized for training machine learning models. However, in order to address the\ndiverse performance requirements of machine learning models, the use of the\nrank-based loss is prevalent, replacing the empirical loss in many cases. The\nrank-based loss comprises a weighted sum of sorted individual losses,\nencompassing both convex losses like the spectral risk, which includes the\nempirical risk and conditional value-at-risk, and nonconvex losses such as the\nhuman-aligned risk and the sum of the ranked range loss. In this paper, we\nintroduce a unified framework for the optimization of the rank-based loss\nthrough the utilization of a proximal alternating direction method of\nmultipliers. We demonstrate the convergence and convergence rate of the\nproposed algorithm under mild conditions. Experiments conducted on synthetic\nand real datasets illustrate the effectiveness and efficiency of the proposed\nalgorithm.",
            "author": [
                "Rufeng Xiao",
                "Yuze Ge",
                "Rujun Jiang",
                "Yifan Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17237v1",
                "http://arxiv.org/pdf/2310.17237v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17233v1",
            "title": "EMMA-X: An EM-like Multilingual Pre-training Algorithm for Cross-lingual\n  Representation Learning",
            "updated": "2023-10-26T08:31:00Z",
            "published": "2023-10-26T08:31:00Z",
            "summary": "Expressing universal semantics common to all languages is helpful in\nunderstanding the meanings of complex and culture-specific sentences. The\nresearch theme underlying this scenario focuses on learning universal\nrepresentations across languages with the usage of massive parallel corpora.\nHowever, due to the sparsity and scarcity of parallel data, there is still a\nbig challenge in learning authentic ``universals'' for any two languages. In\nthis paper, we propose EMMA-X: an EM-like Multilingual pre-training Algorithm,\nto learn (X)Cross-lingual universals with the aid of excessive multilingual\nnon-parallel data. EMMA-X unifies the cross-lingual representation learning\ntask and an extra semantic relation prediction task within an EM framework.\nBoth the extra semantic classifier and the cross-lingual sentence encoder\napproximate the semantic relation of two sentences, and supervise each other\nuntil convergence. To evaluate EMMA-X, we conduct experiments on XRETE, a newly\nintroduced benchmark containing 12 widely studied cross-lingual tasks that\nfully depend on sentence-level representations. Results reveal that EMMA-X\nachieves state-of-the-art performance. Further geometric analysis of the built\nrepresentation space with three requirements demonstrates the superiority of\nEMMA-X over advanced models.",
            "author": [
                "Ping Guo",
                "Xiangpeng Wei",
                "Yue Hu",
                "Baosong Yang",
                "Dayiheng Liu",
                "Fei Huang",
                "Jun Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17233v1",
                "http://arxiv.org/pdf/2310.17233v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17230v1",
            "title": "Codebook Features: Sparse and Discrete Interpretability for Neural\n  Networks",
            "updated": "2023-10-26T08:28:48Z",
            "published": "2023-10-26T08:28:48Z",
            "summary": "Understanding neural networks is challenging in part because of the dense,\ncontinuous nature of their hidden states. We explore whether we can train\nneural networks to have hidden states that are sparse, discrete, and more\ninterpretable by quantizing their continuous features into what we call\ncodebook features. Codebook features are produced by finetuning neural networks\nwith vector quantization bottlenecks at each layer, producing a network whose\nhidden features are the sum of a small number of discrete vector codes chosen\nfrom a larger codebook. Surprisingly, we find that neural networks can operate\nunder this extreme bottleneck with only modest degradation in performance. This\nsparse, discrete bottleneck also provides an intuitive way of controlling\nneural network behavior: first, find codes that activate when the desired\nbehavior is present, then activate those same codes during generation to elicit\nthat behavior. We validate our approach by training codebook Transformers on\nseveral different datasets. First, we explore a finite state machine dataset\nwith far more hidden states than neurons. In this setting, our approach\novercomes the superposition problem by assigning states to distinct codes, and\nwe find that we can make the neural network behave as if it is in a different\nstate by activating the code for that state. Second, we train Transformer\nlanguage models with up to 410M parameters on two natural language datasets. We\nidentify codes in these models representing diverse, disentangled concepts\n(ranging from negative emotions to months of the year) and find that we can\nguide the model to generate different topics by activating the appropriate\ncodes during inference. Overall, codebook features appear to be a promising\nunit of analysis and control for neural networks and interpretability. Our\ncodebase and models are open-sourced at\nhttps://github.com/taufeeque9/codebook-features.",
            "author": [
                "Alex Tamkin",
                "Mohammad Taufeeque",
                "Noah D. Goodman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17230v1",
                "http://arxiv.org/pdf/2310.17230v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17220v2",
            "title": "Validating Digital Traces with Survey Data: The Use Case of Religiosity",
            "updated": "2023-11-09T13:20:52Z",
            "published": "2023-10-26T08:17:22Z",
            "summary": "This paper tests the validity of a digital trace database (Politus) obtained\nfrom Twitter, with a recently conducted representative social survey, focusing\non the use case of religiosity in Turkey. Religiosity scores in the research\nare extracted using supervised machine learning under the Politus project. The\nvalidation analysis depends on two steps. First, we compare the performances of\ntwo alternative tweet-to-user transformation strategies, and second, test for\nthe impact of resampling via the MRP technique. Estimates of the Politus are\nexamined at both aggregate and region-level. The results are intriguing for\nfuture research on measuring public opinion via social media data.",
            "author": [
                "M. Fuat K\u0131na",
                "Erdem Y\u00f6r\u00fck",
                "Ali H\u00fcrriyeto\u011flu",
                "Melih Can Yard\u0131",
                "\u015e\u00fckr\u00fc Ats\u0131zelti",
                "F\u0131rat Duru\u015fan",
                "O\u011fuz G\u00fcrerk",
                "Tolga Etg\u00fc",
                "Z\u00fcbeyir Ni\u015fanc\u0131",
                "Osman Mutlu",
                "Gizem Bacaks\u0131zlar Turbic",
                "Yusuf Akbulut"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17220v2",
                "http://arxiv.org/pdf/2310.17220v2"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17218v1",
            "title": "Prototypical Contrastive Learning-based CLIP Fine-tuning for Object\n  Re-identification",
            "updated": "2023-10-26T08:12:53Z",
            "published": "2023-10-26T08:12:53Z",
            "summary": "This work aims to adapt large-scale pre-trained vision-language models, such\nas contrastive language-image pretraining (CLIP), to enhance the performance of\nobject reidentification (Re-ID) across various supervision settings. Although\nprompt learning has enabled a recent work named CLIP-ReID to achieve promising\nperformance, the underlying mechanisms and the necessity of prompt learning\nremain unclear due to the absence of semantic labels in ReID tasks. In this\nwork, we first analyze the role prompt learning in CLIP-ReID and identify its\nlimitations. Based on our investigations, we propose a simple yet effective\napproach to adapt CLIP for supervised object Re-ID. Our approach directly\nfine-tunes the image encoder of CLIP using a prototypical contrastive learning\n(PCL) loss, eliminating the need for prompt learning. Experimental results on\nboth person and vehicle Re-ID datasets demonstrate the competitiveness of our\nmethod compared to CLIP-ReID. Furthermore, we extend our PCL-based CLIP\nfine-tuning approach to unsupervised scenarios, where we achieve state-of-the\nart performance.",
            "author": [
                "Jiachen Li",
                "Xiaojin Gong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17218v1",
                "http://arxiv.org/pdf/2310.17218v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17217v1",
            "title": "Beyond MLE: Convex Learning for Text Generation",
            "updated": "2023-10-26T08:08:43Z",
            "published": "2023-10-26T08:08:43Z",
            "summary": "Maximum likelihood estimation (MLE) is a statistical method used to estimate\nthe parameters of a probability distribution that best explain the observed\ndata. In the context of text generation, MLE is often used to train generative\nlanguage models, which can then be used to generate new text. However, we argue\nthat MLE is not always necessary and optimal, especially for closed-ended text\ngeneration tasks like machine translation. In these tasks, the goal of model is\nto generate the most appropriate response, which does not necessarily require\nit to estimate the entire data distribution with MLE. To this end, we propose a\nnovel class of training objectives based on convex functions, which enables\ntext generation models to focus on highly probable outputs without having to\nestimate the entire data distribution. We investigate the theoretical\nproperties of the optimal predicted distribution when applying convex functions\nto the loss, demonstrating that convex functions can sharpen the optimal\ndistribution, thereby enabling the model to better capture outputs with high\nprobabilities. Experiments on various text generation tasks and models show the\neffectiveness of our approach. It enables autoregressive models to bridge the\ngap between greedy and beam search, and facilitates the learning of\nnon-autoregressive models with a maximum improvement of 9+ BLEU points.\nMoreover, our approach also exhibits significant impact on large language\nmodels (LLMs), substantially enhancing their generative capability on various\ntasks. Source code is available at\n\\url{https://github.com/ictnlp/Convex-Learning}.",
            "author": [
                "Chenze Shao",
                "Zhengrui Ma",
                "Min Zhang",
                "Yang Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17217v1",
                "http://arxiv.org/pdf/2310.17217v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17216v1",
            "title": "Three-dimensional Bone Image Synthesis with Generative Adversarial\n  Networks",
            "updated": "2023-10-26T08:08:17Z",
            "published": "2023-10-26T08:08:17Z",
            "summary": "Medical image processing has been highlighted as an area where deep\nlearning-based models have the greatest potential. However, in the medical\nfield in particular, problems of data availability and privacy are hampering\nresearch progress and thus rapid implementation in clinical routine. The\ngeneration of synthetic data not only ensures privacy, but also allows to\n\\textit{draw} new patients with specific characteristics, enabling the\ndevelopment of data-driven models on a much larger scale. This work\ndemonstrates that three-dimensional generative adversarial networks (GANs) can\nbe efficiently trained to generate high-resolution medical volumes with finely\ndetailed voxel-based architectures. In addition, GAN inversion is successfully\nimplemented for the three-dimensional setting and used for extensive research\non model interpretability and applications such as image morphing, attribute\nediting and style mixing. The results are comprehensively validated on a\ndatabase of three-dimensional HR-pQCT instances representing the bone\nmicro-architecture of the distal radius.",
            "author": [
                "Christoph Angermann",
                "Johannes Bereiter-Payr",
                "Kerstin Stock",
                "Markus Haltmeier",
                "Gerald Degenhart"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17216v1",
                "http://arxiv.org/pdf/2310.17216v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17209v1",
            "title": "Weakly-Supervised Surgical Phase Recognition",
            "updated": "2023-10-26T07:54:47Z",
            "published": "2023-10-26T07:54:47Z",
            "summary": "A key element of computer-assisted surgery systems is phase recognition of\nsurgical videos. Existing phase recognition algorithms require frame-wise\nannotation of a large number of videos, which is time and money consuming. In\nthis work we join concepts of graph segmentation with self-supervised learning\nto derive a random-walk solution for per-frame phase prediction. Furthermore,\nwe utilize within our method two forms of weak supervision: sparse timestamps\nor few-shot learning. The proposed algorithm enjoys low complexity and can\noperate in lowdata regimes. We validate our method by running experiments with\nthe public Cholec80 dataset of laparoscopic cholecystectomy videos,\ndemonstrating promising performance in multiple setups.",
            "author": [
                "Roy Hirsch",
                "Regev Cohen",
                "Mathilde Caron",
                "Tomer Golany",
                "Daniel Freedman",
                "Ehud Rivlin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17209v1",
                "http://arxiv.org/pdf/2310.17209v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17207v1",
            "title": "Efficient Data Fusion using the Tsetlin Machine",
            "updated": "2023-10-26T07:49:25Z",
            "published": "2023-10-26T07:49:25Z",
            "summary": "We propose a novel way of assessing and fusing noisy dynamic data using a\nTsetlin Machine. Our approach consists in monitoring how explanations in form\nof logical clauses that a TM learns changes with possible noise in dynamic\ndata. This way TM can recognize the noise by lowering weights of previously\nlearned clauses, or reflect it in the form of new clauses. We also perform a\ncomprehensive experimental study using notably different datasets that\ndemonstrated high performance of the proposed approach.",
            "author": [
                "Rupsa Saha",
                "Vladimir I. Zadorozhny",
                "Ole-Christoffer Granmo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17207v1",
                "http://arxiv.org/pdf/2310.17207v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16121v1",
            "title": "Real-Time Neural Materials using Block-Compressed Features",
            "updated": "2023-10-26T07:45:58Z",
            "published": "2023-10-26T07:45:58Z",
            "summary": "Neural materials typically consist of a collection of neural features along\nwith a decoder network. The main challenge in integrating such models in\nreal-time rendering pipelines lies in the large size required to store their\nfeatures in GPU memory and the complexity of evaluating the network\nefficiently. We present a neural material model whose features and decoder are\nspecifically designed to be used in real-time rendering pipelines. Our\nframework leverages hardware-based block compression (BC) texture formats to\nstore the learned features and trains the model to output the material\ninformation continuously in space and scale. To achieve this, we organize the\nfeatures in a block-based manner and emulate BC6 decompression during training,\nmaking it possible to export them as regular BC6 textures. This structure\nallows us to use high resolution features while maintaining a low memory\nfootprint. Consequently, this enhances our model's overall capability, enabling\nthe use of a lightweight and simple decoder architecture that can be evaluated\ndirectly in a shader. Furthermore, since the learned features can be decoded\ncontinuously, it allows for random uv sampling and smooth transition between\nscales without needing any subsequent filtering. As a result, our neural\nmaterial has a small memory footprint, can be decoded extremely fast adding a\nminimal computational overhead to the rendering pipeline.",
            "author": [
                "Cl\u00e9ment Weinreich",
                "Louis de Oliveira",
                "Antoine Houdard",
                "Georges Nader"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16121v1",
                "http://arxiv.org/pdf/2311.16121v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17202v1",
            "title": "miditok: A Python package for MIDI file tokenization",
            "updated": "2023-10-26T07:37:44Z",
            "published": "2023-10-26T07:37:44Z",
            "summary": "Recent progress in natural language processing has been adapted to the\nsymbolic music modality. Language models, such as Transformers, have been used\nwith symbolic music for a variety of tasks among which music generation,\nmodeling or transcription, with state-of-the-art performances. These models are\nbeginning to be used in production products. To encode and decode music for the\nbackbone model, they need to rely on tokenizers, whose role is to serialize\nmusic into sequences of distinct elements called tokens. MidiTok is an\nopen-source library allowing to tokenize symbolic music with great flexibility\nand extended features. It features the most popular music tokenizations, under\na unified API. It is made to be easily used and extensible for everyone.",
            "author": [
                "Nathan Fradet",
                "Jean-Pierre Briot",
                "Fabien Chhel",
                "Amal El Fallah Seghrouchni",
                "Nicolas Gutowski"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17202v1",
                "http://arxiv.org/pdf/2310.17202v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17200v1",
            "title": "Taming Gradient Variance in Federated Learning with Networked Control\n  Variates",
            "updated": "2023-10-26T07:32:52Z",
            "published": "2023-10-26T07:32:52Z",
            "summary": "Federated learning, a decentralized approach to machine learning, faces\nsignificant challenges such as extensive communication overheads, slow\nconvergence, and unstable improvements. These challenges primarily stem from\nthe gradient variance due to heterogeneous client data distributions. To\naddress this, we introduce a novel Networked Control Variates (FedNCV)\nframework for Federated Learning. We adopt the REINFORCE Leave-One-Out (RLOO)\nas a fundamental control variate unit in the FedNCV framework, implemented at\nboth client and server levels. At the client level, the RLOO control variate is\nemployed to optimize local gradient updates, mitigating the variance introduced\nby data samples. Once relayed to the server, the RLOO-based estimator further\nprovides an unbiased and low-variance aggregated gradient, leading to robust\nglobal updates. This dual-side application is formalized as a linear\ncombination of composite control variates. We provide a mathematical expression\ncapturing this integration of double control variates within FedNCV and present\nthree theoretical results with corresponding proofs. This unique dual structure\nequips FedNCV to address data heterogeneity and scalability issues, thus\npotentially paving the way for large-scale applications. Moreover, we tested\nFedNCV on six diverse datasets under a Dirichlet distribution with {\\alpha} =\n0.1, and benchmarked its performance against six SOTA methods, demonstrating\nits superiority.",
            "author": [
                "Xingyan Chen",
                "Yaling Liu",
                "Huaming Du",
                "Mu Wang",
                "Yu Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17200v1",
                "http://arxiv.org/pdf/2310.17200v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17194v1",
            "title": "Privacy-preserving Representation Learning for Speech Understanding",
            "updated": "2023-10-26T07:20:23Z",
            "published": "2023-10-26T07:20:23Z",
            "summary": "Existing privacy-preserving speech representation learning methods target a\nsingle application domain. In this paper, we present a novel framework to\nanonymize utterance-level speech embeddings generated by pre-trained encoders\nand show its effectiveness for a range of speech classification tasks.\nSpecifically, given the representations from a pre-trained encoder, we train a\nTransformer to estimate the representations for the same utterances spoken by\nother speakers. During inference, the extracted representations can be\nconverted into different identities to preserve privacy. We compare the results\nwith the voice anonymization baselines from the VoicePrivacy 2022 challenge. We\nevaluate our framework on speaker identification for privacy and emotion\nrecognition, depression classification, and intent classification for utility.\nOur method outperforms the baselines on privacy and utility in paralinguistic\ntasks and achieves comparable performance for intent classification.",
            "author": [
                "Minh Tran",
                "Mohammad Soleymani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17194v1",
                "http://arxiv.org/pdf/2310.17194v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17191v1",
            "title": "How do Language Models Bind Entities in Context?",
            "updated": "2023-10-26T07:10:31Z",
            "published": "2023-10-26T07:10:31Z",
            "summary": "To correctly use in-context information, language models (LMs) must bind\nentities to their attributes. For example, given a context describing a \"green\nsquare\" and a \"blue circle\", LMs must bind the shapes to their respective\ncolors. We analyze LM representations and identify the binding ID mechanism: a\ngeneral mechanism for solving the binding problem, which we observe in every\nsufficiently large model from the Pythia and LLaMA families. Using causal\ninterventions, we show that LMs' internal activations represent binding\ninformation by attaching binding ID vectors to corresponding entities and\nattributes. We further show that binding ID vectors form a continuous subspace,\nin which distances between binding ID vectors reflect their discernability.\nOverall, our results uncover interpretable strategies in LMs for representing\nsymbolic knowledge in-context, providing a step towards understanding general\nin-context reasoning in large-scale LMs.",
            "author": [
                "Jiahai Feng",
                "Jacob Steinhardt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17191v1",
                "http://arxiv.org/pdf/2310.17191v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17190v1",
            "title": "Lookup Table meets Local Laplacian Filter: Pyramid Reconstruction\n  Network for Tone Mapping",
            "updated": "2023-10-26T07:05:38Z",
            "published": "2023-10-26T07:05:38Z",
            "summary": "Tone mapping aims to convert high dynamic range (HDR) images to low dynamic\nrange (LDR) representations, a critical task in the camera imaging pipeline. In\nrecent years, 3-Dimensional LookUp Table (3D LUT) based methods have gained\nattention due to their ability to strike a favorable balance between\nenhancement performance and computational efficiency. However, these methods\noften fail to deliver satisfactory results in local areas since the look-up\ntable is a global operator for tone mapping, which works based on pixel values\nand fails to incorporate crucial local information. To this end, this paper\naims to address this issue by exploring a novel strategy that integrates global\nand local operators by utilizing closed-form Laplacian pyramid decomposition\nand reconstruction. Specifically, we employ image-adaptive 3D LUTs to\nmanipulate the tone in the low-frequency image by leveraging the specific\ncharacteristics of the frequency information. Furthermore, we utilize local\nLaplacian filters to refine the edge details in the high-frequency components\nin an adaptive manner. Local Laplacian filters are widely used to preserve edge\ndetails in photographs, but their conventional usage involves manual tuning and\nfixed implementation within camera imaging pipelines or photo editing tools. We\npropose to learn parameter value maps progressively for local Laplacian filters\nfrom annotated data using a lightweight network. Our model achieves\nsimultaneous global tone manipulation and local edge detail preservation in an\nend-to-end manner. Extensive experimental results on two benchmark datasets\ndemonstrate that the proposed method performs favorably against\nstate-of-the-art methods.",
            "author": [
                "Feng Zhang",
                "Ming Tian",
                "Zhiqiang Li",
                "Bin Xu",
                "Qingbo Lu",
                "Changxin Gao",
                "Nong Sang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17190v1",
                "http://arxiv.org/pdf/2310.17190v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17189v1",
            "title": "Exploring Iterative Refinement with Diffusion Models for Video Grounding",
            "updated": "2023-10-26T07:04:44Z",
            "published": "2023-10-26T07:04:44Z",
            "summary": "Video grounding aims to localize the target moment in an untrimmed video\ncorresponding to a given sentence query. Existing methods typically select the\nbest prediction from a set of predefined proposals or directly regress the\ntarget span in a single-shot manner, resulting in the absence of a systematical\nprediction refinement process. In this paper, we propose DiffusionVG, a novel\nframework with diffusion models that formulates video grounding as a\nconditional generation task, where the target span is generated from Gaussian\nnoise inputs and interatively refined in the reverse diffusion process. During\ntraining, DiffusionVG progressively adds noise to the target span with a fixed\nforward diffusion process and learns to recover the target span in the reverse\ndiffusion process. In inference, DiffusionVG can generate the target span from\nGaussian noise inputs by the learned reverse diffusion process conditioned on\nthe video-sentence representations. Our DiffusionVG follows the encoder-decoder\narchitecture, which firstly encodes the video-sentence features and iteratively\ndenoises the predicted spans in its specialized span refining decoder. Without\nbells and whistles, our DiffusionVG demonstrates competitive or even superior\nperformance compared to existing well-crafted models on mainstream Charades-STA\nand ActivityNet Captions benchmarks.",
            "author": [
                "Xiao Liang",
                "Tao Shi",
                "Yaoyuan Liang",
                "Te Tao",
                "Shao-Lun Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17189v1",
                "http://arxiv.org/pdf/2310.17189v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17187v1",
            "title": "Multi-level Gated Bayesian Recurrent Neural Network for State Estimation",
            "updated": "2023-10-26T06:46:43Z",
            "published": "2023-10-26T06:46:43Z",
            "summary": "The optimality of Bayesian filtering relies on the completeness of prior\nmodels, while deep learning holds a distinct advantage in learning models from\noffline data. Nevertheless, the current fusion of these two methodologies\nremains largely ad hoc, lacking a theoretical foundation. This paper presents a\nnovel solution, namely a multi-level gated Bayesian recurrent neural network\nspecifically designed to state estimation under model mismatches. Firstly, we\ntransform the non-Markov state-space model into an equivalent first-order\nMarkov model with memory. It is a generalized transformation that overcomes the\nlimitations of the first-order Markov property and enables recursive filtering.\nSecondly, by deriving a data-assisted joint state-memory-mismatch Bayesian\nfiltering, we design a Bayesian multi-level gated framework that includes a\nmemory update gate for capturing the temporal regularities in state evolution,\na state prediction gate with the evolution mismatch compensation, and a state\nupdate gate with the observation mismatch compensation. The Gaussian\napproximation implementation of the filtering process within the gated\nframework is derived, taking into account the computational efficiency.\nFinally, the corresponding internal neural network structures and end-to-end\ntraining methods are designed. The Bayesian filtering theory enhances the\ninterpretability of the proposed gated network, enabling the effective\nintegration of offline data and prior models within functionally explicit gated\nunits. In comprehensive experiments, including simulations and real-world\ndatasets, the proposed gated network demonstrates superior estimation\nperformance compared to benchmark filters and state-of-the-art deep learning\nfiltering methods.",
            "author": [
                "Shi Yan",
                "Yan Liang",
                "Le Zheng",
                "Mingyang Fan",
                "Binglu Wang",
                "Xiaoxu Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17187v1",
                "http://arxiv.org/pdf/2310.17187v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17185v2",
            "title": "Adaptive importance sampling for Deep Ritz",
            "updated": "2023-10-30T11:42:29Z",
            "published": "2023-10-26T06:35:08Z",
            "summary": "We introduce an adaptive sampling method for the Deep Ritz method aimed at\nsolving partial differential equations (PDEs). Two deep neural networks are\nused. One network is employed to approximate the solution of PDEs, while the\nother one is a deep generative model used to generate new collocation points to\nrefine the training set. The adaptive sampling procedure consists of two main\nsteps. The first step is solving the PDEs using the Deep Ritz method by\nminimizing an associated variational loss discretized by the collocation points\nin the training set. The second step involves generating a new training set,\nwhich is then used in subsequent computations to further improve the accuracy\nof the current approximate solution. We treat the integrand in the variational\nloss as an unnormalized probability density function (PDF) and approximate it\nusing a deep generative model called bounded KRnet. The new samples and their\nassociated PDF values are obtained from the bounded KRnet. With these new\nsamples and their associated PDF values, the variational loss can be\napproximated more accurately by importance sampling. Compared to the original\nDeep Ritz method, the proposed adaptive method improves accuracy, especially\nfor problems characterized by low regularity and high dimensionality. We\ndemonstrate the effectiveness of our new method through a series of numerical\nexperiments.",
            "author": [
                "Xiaoliang Wan",
                "Tao Zhou",
                "Yuancheng Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17185v2",
                "http://arxiv.org/pdf/2310.17185v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17179v3",
            "title": "Linking intra- and extra-cellular metabolic domains via neural-network\n  surrogates for dynamic metabolic control",
            "updated": "2023-11-19T02:12:55Z",
            "published": "2023-10-26T06:06:24Z",
            "summary": "In this study, we aim to optimize biotechnological production by manipulating\nintracellular metabolic fluxes in microbial cell factories. Model-based dynamic\noptimization is proposed to determine the optimal dynamic trajectories of the\nmanipulatable intracellular fluxes. A challenge emerges as existing models are\noften oversimplified, lacking insights into intracellular metabolism, or are\nexcessively complex, leading to numerical and implementation challenges in\noptimal control (e.g., related to bilevel optimizations). We propose a solution\ninvolving a machine-learning surrogate derived from steady-state\nconstraint-based metabolic modeling. This surrogate bridges the gap between\nmanipulatable intracellular fluxes and process exchange rates. By integrating\nthe surrogate model with simple macro-kinetic dynamic models, we can develop\nhybrid machine-learning-supported dynamic models. Conveniently, the\nmanipulatable intracellular fluxes in these augmented models can be exploited\nas dynamic optimization degrees of freedom. We apply this modeling and\noptimization strategy to a representative metabolic network that showcases\ncommon challenges in dynamic metabolic control. We also present an example of\ncybernetic control to counteract system uncertainties. Our approach facilitates\nthe in silico evaluation of dynamic metabolic interventions and can aid in the\nselection of suitable control and actuation strategies.",
            "author": [
                "Sebasti\u00e1n Espinel-R\u00edos",
                "Jos\u00e9 L. Avalos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17179v3",
                "http://arxiv.org/pdf/2310.17179v3"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17178v1",
            "title": "Graphical Object-Centric Actor-Critic",
            "updated": "2023-10-26T06:05:12Z",
            "published": "2023-10-26T06:05:12Z",
            "summary": "There have recently been significant advances in the problem of unsupervised\nobject-centric representation learning and its application to downstream tasks.\nThe latest works support the argument that employing disentangled object\nrepresentations in image-based object-centric reinforcement learning tasks\nfacilitates policy learning. We propose a novel object-centric reinforcement\nlearning algorithm combining actor-critic and model-based approaches to utilize\nthese representations effectively. In our approach, we use a transformer\nencoder to extract object representations and graph neural networks to\napproximate the dynamics of an environment. The proposed method fills a\nresearch gap in developing efficient object-centric world models for\nreinforcement learning settings that can be used for environments with discrete\nor continuous action spaces. Our algorithm performs better in a visually\ncomplex 3D robotic environment and a 2D environment with compositional\nstructure than the state-of-the-art model-free actor-critic algorithm built\nupon transformer architecture and the state-of-the-art monolithic model-based\nalgorithm.",
            "author": [
                "Leonid Ugadiarov",
                "Aleksandr I. Panov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17178v1",
                "http://arxiv.org/pdf/2310.17178v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17176v1",
            "title": "A Deep Learning Approach to Teeth Segmentation and Orientation from\n  Panoramic X-rays",
            "updated": "2023-10-26T06:01:25Z",
            "published": "2023-10-26T06:01:25Z",
            "summary": "Accurate teeth segmentation and orientation are fundamental in modern oral\nhealthcare, enabling precise diagnosis, treatment planning, and dental implant\ndesign. In this study, we present a comprehensive approach to teeth\nsegmentation and orientation from panoramic X-ray images, leveraging deep\nlearning techniques. We build our model based on FUSegNet, a popular model\noriginally developed for wound segmentation, and introduce modifications by\nincorporating grid-based attention gates into the skip connections. We\nintroduce oriented bounding box (OBB) generation through principal component\nanalysis (PCA) for precise tooth orientation estimation. Evaluating our\napproach on the publicly available DNS dataset, comprising 543 panoramic X-ray\nimages, we achieve the highest Intersection-over-Union (IoU) score of 82.43%\nand Dice Similarity Coefficient (DSC) score of 90.37% among compared models in\nteeth instance segmentation. In OBB analysis, we obtain the Rotated IoU (RIoU)\nscore of 82.82%. We also conduct detailed analyses of individual tooth labels\nand categorical performance, shedding light on strengths and weaknesses. The\nproposed model's accuracy and versatility offer promising prospects for\nimproving dental diagnoses, treatment planning, and personalized healthcare in\nthe oral domain. Our generated OBB coordinates and codes are available at\nhttps://github.com/mrinal054/Instance_teeth_segmentation.",
            "author": [
                "Mrinal Kanti Dhar",
                "Mou Deb",
                "D. Madhab",
                "Zeyun Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17176v1",
                "http://arxiv.org/pdf/2310.17176v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17173v1",
            "title": "DSAC-C: Constrained Maximum Entropy for Robust Discrete Soft-Actor\n  Critic",
            "updated": "2023-10-26T05:54:51Z",
            "published": "2023-10-26T05:54:51Z",
            "summary": "We present a novel extension to the family of Soft Actor-Critic (SAC)\nalgorithms. We argue that based on the Maximum Entropy Principle, discrete SAC\ncan be further improved via additional statistical constraints derived from a\nsurrogate critic policy. Furthermore, our findings suggests that these\nconstraints provide an added robustness against potential domain shifts, which\nare essential for safe deployment of reinforcement learning agents in the\nreal-world. We provide theoretical analysis and show empirical results on low\ndata regimes for both in-distribution and out-of-distribution variants of Atari\n2600 games.",
            "author": [
                "Dexter Neo",
                "Tsuhan Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17173v1",
                "http://arxiv.org/pdf/2310.17173v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17168v1",
            "title": "Learning an Inventory Control Policy with General Inventory Arrival\n  Dynamics",
            "updated": "2023-10-26T05:49:13Z",
            "published": "2023-10-26T05:49:13Z",
            "summary": "In this paper we address the problem of learning and backtesting inventory\ncontrol policies in the presence of general arrival dynamics -- which we term\nas a quantity-over-time arrivals model (QOT). We also allow for order\nquantities to be modified as a post-processing step to meet vendor constraints\nsuch as order minimum and batch size constraints -- a common practice in real\nsupply chains. To the best of our knowledge this is the first work to handle\neither arbitrary arrival dynamics or an arbitrary downstream post-processing of\norder quantities. Building upon recent work (Madeka et al., 2022) we similarly\nformulate the periodic review inventory control problem as an exogenous\ndecision process, where most of the state is outside the control of the agent.\nMadeka et al. (2022) show how to construct a simulator that replays historic\ndata to solve this class of problem. In our case, we incorporate a deep\ngenerative model for the arrivals process as part of the history replay. By\nformulating the problem as an exogenous decision process, we can apply results\nfrom Madeka et al. (2022) to obtain a reduction to supervised learning.\nFinally, we show via simulation studies that this approach yields statistically\nsignificant improvements in profitability over production baselines. Using data\nfrom an ongoing real-world A/B test, we show that Gen-QOT generalizes well to\noff-policy data.",
            "author": [
                "Sohrab Andaz",
                "Carson Eisenach",
                "Dhruv Madeka",
                "Kari Torkkola",
                "Randy Jia",
                "Dean Foster",
                "Sham Kakade"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17168v1",
                "http://arxiv.org/pdf/2310.17168v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17167v1",
            "title": "Improving Denoising Diffusion Models via Simultaneous Estimation of\n  Image and Noise",
            "updated": "2023-10-26T05:43:07Z",
            "published": "2023-10-26T05:43:07Z",
            "summary": "This paper introduces two key contributions aimed at improving the speed and\nquality of images generated through inverse diffusion processes. The first\ncontribution involves reparameterizing the diffusion process in terms of the\nangle on a quarter-circular arc between the image and noise, specifically\nsetting the conventional $\\displaystyle \\sqrt{\\bar{\\alpha}}=\\cos(\\eta)$. This\nreparameterization eliminates two singularities and allows for the expression\nof diffusion evolution as a well-behaved ordinary differential equation (ODE).\nIn turn, this allows higher order ODE solvers such as Runge-Kutta methods to be\nused effectively. The second contribution is to directly estimate both the\nimage ($\\mathbf{x}_0$) and noise ($\\mathbf{\\epsilon}$) using our network, which\nenables more stable calculations of the update step in the inverse diffusion\nsteps, as accurate estimation of both the image and noise are crucial at\ndifferent stages of the process. Together with these changes, our model\nachieves faster generation, with the ability to converge on high-quality images\nmore quickly, and higher quality of the generated images, as measured by\nmetrics such as Frechet Inception Distance (FID), spatial Frechet Inception\nDistance (sFID), precision, and recall.",
            "author": [
                "Zhenkai Zhang",
                "Krista A. Ehinger",
                "Tom Drummond"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17167v1",
                "http://arxiv.org/pdf/2310.17167v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17162v1",
            "title": "Content-based Controls For Music Large Language Modeling",
            "updated": "2023-10-26T05:24:38Z",
            "published": "2023-10-26T05:24:38Z",
            "summary": "Recent years have witnessed a rapid growth of large-scale language models in\nthe domain of music audio. Such models enable end-to-end generation of\nhigher-quality music, and some allow conditioned generation using text\ndescriptions. However, the control power of text controls on music is\nintrinsically limited, as they can only describe music indirectly through\nmeta-data (such as singers and instruments) or high-level representations (such\nas genre and emotion). We aim to further equip the models with direct and\ncontent-based controls on innate music languages such as pitch, chords and drum\ntrack. To this end, we contribute Coco-Mulla, a content-based control method\nfor music large language modeling. It uses a parameter-efficient fine-tuning\n(PEFT) method tailored for Transformer-based audio models. Experiments show\nthat our approach achieved high-quality music generation with low-resource\nsemi-supervised learning, tuning with less than 4% parameters compared to the\noriginal model and training on a small dataset with fewer than 300 songs.\nMoreover, our approach enables effective content-based controls, and we\nillustrate the control power via chords and rhythms, two of the most salient\nfeatures of music audio. Furthermore, we show that by combining content-based\ncontrols and text descriptions, our system achieves flexible music variation\ngeneration and style transfer. Our source codes and demos are available online.",
            "author": [
                "Liwei Lin",
                "Gus Xia",
                "Junyan Jiang",
                "Yixiao Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17162v1",
                "http://arxiv.org/pdf/2310.17162v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17161v1",
            "title": "Structure discovery in Atomic Force Microscopy imaging of ice",
            "updated": "2023-10-26T05:20:06Z",
            "published": "2023-10-26T05:20:06Z",
            "summary": "The interaction of water with surfaces is crucially important in a wide range\nof natural and technological settings. In particular, at low temperatures,\nunveiling the atomistic structure of adsorbed water clusters would provide\nvaluable data for understanding the ice nucleation process. Using\nhigh-resolution Atomic Force Microscopy (AFM) and Scanning Tunnelling\nMicroscopy, several studies have demonstrated the presence of water pentamers,\nhexamers, heptamers (and of their combinations) on a variety of metallic\nsurfaces, as well the initial stages of 2D ice growth on an insulating surface.\nHowever, in all these cases, the observed structures were completely flat,\nproviding a relatively straightforward path to interpretation. Here, we present\nhigh-resolution AFM measurements of several new water clusters on Au(111) and\nCu(111), whose understanding presents significant challenges, due to both their\nhighly 3D configuration and to their large size. For each of them, we use a\ncombination of machine learning, atomistic modelling with neural network\npotentials and statistical sampling to propose an underlying atomic structure,\nfinally comparing its AFM simulated images to the experimental ones. These\nresults provide new insights into the early phases of ice formation, which is a\nubiquitous phenomenon ranging from biology to astrophysics.",
            "author": [
                "F. Priante",
                "N. Oinonen",
                "Y. Tian",
                "D. Guan",
                "C. Xu",
                "S. Cai",
                "P. Liljeroth",
                "Y. Jiang",
                "A. S. Foster"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17161v1",
                "http://arxiv.org/pdf/2310.17161v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17159v1",
            "title": "MaxEnt Loss: Constrained Maximum Entropy for Calibration under\n  Out-of-Distribution Shift",
            "updated": "2023-10-26T05:10:57Z",
            "published": "2023-10-26T05:10:57Z",
            "summary": "We present a new loss function that addresses the out-of-distribution (OOD)\ncalibration problem. While many objective functions have been proposed to\neffectively calibrate models in-distribution, our findings show that they do\nnot always fare well OOD. Based on the Principle of Maximum Entropy, we\nincorporate helpful statistical constraints observed during training,\ndelivering better model calibration without sacrificing accuracy. We provide\ntheoretical analysis and show empirically that our method works well in\npractice, achieving state-of-the-art calibration on both synthetic and\nreal-world benchmarks.",
            "author": [
                "Dexter Neo",
                "Stefan Winkler",
                "Tsuhan Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17159v1",
                "http://arxiv.org/pdf/2310.17159v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17158v2",
            "title": "CosmosDSR -- a methodology for automated detection and tracking of\n  orbital debris using the Unscented Kalman Filter",
            "updated": "2023-10-31T11:22:04Z",
            "published": "2023-10-26T05:02:19Z",
            "summary": "The Kessler syndrome refers to the escalating space debris from frequent\nspace activities, threatening future space exploration. Addressing this issue\nis vital. Several AI models, including Convolutional Neural Networks, Kernel\nPrincipal Component Analysis, and Model-Agnostic Meta- Learning have been\nassessed with various data types. Earlier studies highlighted the combination\nof the YOLO object detector and a linear Kalman filter (LKF) for object\ndetection and tracking. Advancing this, the current paper introduces a novel\nmethodology for the Comprehensive Orbital Surveillance and Monitoring Of Space\nby Detecting Satellite Residuals (CosmosDSR) by combining YOLOv3 with an\nUnscented Kalman Filter (UKF) for tracking satellites in sequential images.\nUsing the Spacecraft Recognition Leveraging Knowledge of Space Environment\n(SPARK) dataset for training and testing, the YOLOv3 precisely detected and\nclassified all satellite categories (Mean Average Precision=97.18%, F1=0.95)\nwith few errors (TP=4163, FP=209, FN=237). Both CosmosDSR and an implemented\nLKF used for comparison tracked satellites accurately for a mean squared error\n(MSE) and root mean squared error (RME) of MSE=2.83/RMSE=1.66 for UKF and\nMSE=2.84/RMSE=1.66 for LKF. The current study is limited to images generated in\na space simulation environment, but the CosmosDSR methodology shows great\npotential in detecting and tracking satellites, paving the way for solutions to\nthe Kessler syndrome.",
            "author": [
                "Daniel S. Roll",
                "Zeyneb Kurt",
                "Wai Lok Woo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17158v2",
                "http://arxiv.org/pdf/2310.17158v2"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.IM",
                "cs.AI",
                "cs.CV",
                "68",
                "I.2.6; K.3.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17157v1",
            "title": "Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time",
            "updated": "2023-10-26T05:01:09Z",
            "published": "2023-10-26T05:01:09Z",
            "summary": "Large language models (LLMs) with hundreds of billions of parameters have\nsparked a new wave of exciting AI applications. However, they are\ncomputationally expensive at inference time. Sparsity is a natural approach to\nreduce this cost, but existing methods either require costly retraining, have\nto forgo LLM's in-context learning ability, or do not yield wall-clock time\nspeedup on modern hardware. We hypothesize that contextual sparsity, which are\nsmall, input-dependent sets of attention heads and MLP parameters that yield\napproximately the same output as the dense model for a given input, can address\nthese issues. We show that contextual sparsity exists, that it can be\naccurately predicted, and that we can exploit it to speed up LLM inference in\nwall-clock time without compromising LLM's quality or in-context learning\nability. Based on these insights, we propose DejaVu, a system that uses a\nlow-cost algorithm to predict contextual sparsity on the fly given inputs to\neach layer, along with an asynchronous and hardware-aware implementation that\nspeeds up LLM inference. We validate that DejaVu can reduce the inference\nlatency of OPT-175B by over 2X compared to the state-of-the-art\nFasterTransformer, and over 6X compared to the widely used Hugging Face\nimplementation, without compromising model quality. The code is available at\nhttps://github.com/FMInference/DejaVu.",
            "author": [
                "Zichang Liu",
                "Jue Wang",
                "Tri Dao",
                "Tianyi Zhou",
                "Binhang Yuan",
                "Zhao Song",
                "Anshumali Shrivastava",
                "Ce Zhang",
                "Yuandong Tian",
                "Christopher Re",
                "Beidi Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17157v1",
                "http://arxiv.org/pdf/2310.17157v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17156v1",
            "title": "Learning depth from monocular video sequences",
            "updated": "2023-10-26T05:00:41Z",
            "published": "2023-10-26T05:00:41Z",
            "summary": "Learning single image depth estimation model from monocular video sequence is\na very challenging problem. In this paper, we propose a novel training loss\nwhich enables us to include more images for supervision during the training\nprocess. We propose a simple yet effective model to account the frame to frame\npixel motion. We also design a novel network architecture for single image\nestimation. When combined, our method produces state of the art results for\nmonocular depth estimation on the KITTI dataset in the self-supervised setting.",
            "author": [
                "Zhenwei Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17156v1",
                "http://arxiv.org/pdf/2310.17156v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17678v1",
            "title": "Spatio-Temporal Meta Contrastive Learning",
            "updated": "2023-10-26T04:56:31Z",
            "published": "2023-10-26T04:56:31Z",
            "summary": "Spatio-temporal prediction is crucial in numerous real-world applications,\nincluding traffic forecasting and crime prediction, which aim to improve public\ntransportation and safety management. Many state-of-the-art models demonstrate\nthe strong capability of spatio-temporal graph neural networks (STGNN) to\ncapture complex spatio-temporal correlations. However, despite their\neffectiveness, existing approaches do not adequately address several key\nchallenges. Data quality issues, such as data scarcity and sparsity, lead to\ndata noise and a lack of supervised signals, which significantly limit the\nperformance of STGNN. Although recent STGNN models with contrastive learning\naim to address these challenges, most of them use pre-defined augmentation\nstrategies that heavily depend on manual design and cannot be customized for\ndifferent Spatio-Temporal Graph (STG) scenarios. To tackle these challenges, we\npropose a new spatio-temporal contrastive learning (CL4ST) framework to encode\nrobust and generalizable STG representations via the STG augmentation paradigm.\nSpecifically, we design the meta view generator to automatically construct node\nand edge augmentation views for each disentangled spatial and temporal graph in\na data-driven manner. The meta view generator employs meta networks with\nparameterized generative model to customize the augmentations for each input.\nThis personalizes the augmentation strategies for every STG and endows the\nlearning framework with spatio-temporal-aware information. Additionally, we\nintegrate a unified spatio-temporal graph attention network with the proposed\nmeta view generator and two-branch graph contrastive learning paradigms.\nExtensive experiments demonstrate that our CL4ST significantly improves\nperformance over various state-of-the-art baselines in traffic and crime\nprediction.",
            "author": [
                "Jiabin Tang",
                "Lianghao Xia",
                "Jie Hu",
                "Chao Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17678v1",
                "http://arxiv.org/pdf/2310.17678v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17154v1",
            "title": "Deep Imbalanced Regression via Hierarchical Classification Adjustment",
            "updated": "2023-10-26T04:54:39Z",
            "published": "2023-10-26T04:54:39Z",
            "summary": "Regression tasks in computer vision, such as age estimation or counting, are\noften formulated into classification by quantizing the target space into\nclasses. Yet real-world data is often imbalanced -- the majority of training\nsamples lie in a head range of target values, while a minority of samples span\na usually larger tail range. By selecting the class quantization, one can\nadjust imbalanced regression targets into balanced classification outputs,\nthough there are trade-offs in balancing classification accuracy and\nquantization error. To improve regression performance over the entire range of\ndata, we propose to construct hierarchical classifiers for solving imbalanced\nregression tasks. The fine-grained classifiers limit the quantization error\nwhile being modulated by the coarse predictions to ensure high accuracy.\nStandard hierarchical classification approaches, however, when applied to the\nregression problem, fail to ensure that predicted ranges remain consistent\nacross the hierarchy. As such, we propose a range-preserving distillation\nprocess that can effectively learn a single classifier from the set of\nhierarchical classifiers. Our novel hierarchical classification adjustment\n(HCA) for imbalanced regression shows superior results on three diverse tasks:\nage estimation, crowd counting and depth estimation. We will release the source\ncode upon acceptance.",
            "author": [
                "Haipeng Xiong",
                "Angela Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17154v1",
                "http://arxiv.org/pdf/2310.17154v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17153v1",
            "title": "Hierarchical Semi-Implicit Variational Inference with Application to\n  Diffusion Model Acceleration",
            "updated": "2023-10-26T04:52:28Z",
            "published": "2023-10-26T04:52:28Z",
            "summary": "Semi-implicit variational inference (SIVI) has been introduced to expand the\nanalytical variational families by defining expressive semi-implicit\ndistributions in a hierarchical manner. However, the single-layer architecture\ncommonly used in current SIVI methods can be insufficient when the target\nposterior has complicated structures. In this paper, we propose hierarchical\nsemi-implicit variational inference, called HSIVI, which generalizes SIVI to\nallow more expressive multi-layer construction of semi-implicit distributions.\nBy introducing auxiliary distributions that interpolate between a simple base\ndistribution and the target distribution, the conditional layers can be trained\nby progressively matching these auxiliary distributions one layer after\nanother. Moreover, given pre-trained score networks, HSIVI can be used to\naccelerate the sampling process of diffusion models with the score matching\nobjective. We show that HSIVI significantly enhances the expressiveness of SIVI\non several Bayesian inference problems with complicated target distributions.\nWhen used for diffusion model acceleration, we show that HSIVI can produce high\nquality samples comparable to or better than the existing fast diffusion model\nbased samplers with a small number of function evaluations on various datasets.",
            "author": [
                "Longlin Yu",
                "Tianyu Xie",
                "Yu Zhu",
                "Tong Yang",
                "Xiangyu Zhang",
                "Cheng Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17153v1",
                "http://arxiv.org/pdf/2310.17153v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17152v1",
            "title": "Technical Note: Feasibility of translating 3.0T-trained Deep-Learning\n  Segmentation Models Out-of-the-Box on Low-Field MRI 0.55T Knee-MRI of Healthy\n  Controls",
            "updated": "2023-10-26T04:52:25Z",
            "published": "2023-10-26T04:52:25Z",
            "summary": "In the current study, our purpose is to evaluate the feasibility of applying\ndeep learning (DL) enabled algorithms to quantify bilateral knee biomarkers in\nhealthy controls scanned at 0.55T and compared with 3.0T. The current study\nassesses the performance of standard in-practice bone, and cartilage\nsegmentation algorithms at 0.55T, both qualitatively and quantitatively, in\nterms of comparing segmentation performance, areas of improvement, and\ncompartment-wise cartilage thickness values between 0.55T vs. 3.0T. Initial\nresults demonstrate a usable to good technical feasibility of translating\nexisting quantitative deep-learning-based image segmentation techniques,\ntrained on 3.0T, out of 0.55T for knee MRI, in a multi-vendor acquisition\nenvironment. Especially in terms of segmenting cartilage compartments, the\nmodels perform almost equivalent to 3.0T in terms of Likert ranking. The 0.55T\nlow-field sustainable and easy-to-install MRI, as demonstrated, thus, can be\nutilized for evaluating knee cartilage thickness and bone segmentations aided\nby established DL algorithms trained at higher-field strengths out-of-the-box\ninitially. This could be utilized at the far-spread point-of-care locations\nwith a lack of radiologists available to manually segment low-field images, at\nleast till a decent base of low-field data pool is collated. With further\nfine-tuning with manual labeling of low-field data or utilizing synthesized\nhigher SNR images from low-field images, OA biomarker quantification\nperformance is potentially guaranteed to be further improved.",
            "author": [
                "Rupsa Bhattacharjee",
                "Zehra Akkaya",
                "Johanna Luitjens",
                "Pan Su",
                "Yang Yang",
                "Valentina Pedoia",
                "Sharmila Majumdar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17152v1",
                "http://arxiv.org/pdf/2310.17152v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17149v1",
            "title": "Explainable Spatio-Temporal Graph Neural Networks",
            "updated": "2023-10-26T04:47:28Z",
            "published": "2023-10-26T04:47:28Z",
            "summary": "Spatio-temporal graph neural networks (STGNNs) have gained popularity as a\npowerful tool for effectively modeling spatio-temporal dependencies in diverse\nreal-world urban applications, including intelligent transportation and public\nsafety. However, the black-box nature of STGNNs limits their interpretability,\nhindering their application in scenarios related to urban resource allocation\nand policy formulation. To bridge this gap, we propose an Explainable\nSpatio-Temporal Graph Neural Networks (STExplainer) framework that enhances\nSTGNNs with inherent explainability, enabling them to provide accurate\npredictions and faithful explanations simultaneously. Our framework integrates\na unified spatio-temporal graph attention network with a positional information\nfusion layer as the STG encoder and decoder, respectively. Furthermore, we\npropose a structure distillation approach based on the Graph Information\nBottleneck (GIB) principle with an explainable objective, which is instantiated\nby the STG encoder and decoder. Through extensive experiments, we demonstrate\nthat our STExplainer outperforms state-of-the-art baselines in terms of\npredictive accuracy and explainability metrics (i.e., sparsity and fidelity) on\ntraffic and crime prediction tasks. Furthermore, our model exhibits superior\nrepresentation ability in alleviating data missing and sparsity issues. The\nimplementation code is available at: https://github.com/HKUDS/STExplainer.",
            "author": [
                "Jiabin Tang",
                "Lianghao Xia",
                "Chao Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17149v1",
                "http://arxiv.org/pdf/2310.17149v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17146v1",
            "title": "Counterfactual-Augmented Importance Sampling for Semi-Offline Policy\n  Evaluation",
            "updated": "2023-10-26T04:41:19Z",
            "published": "2023-10-26T04:41:19Z",
            "summary": "In applying reinforcement learning (RL) to high-stakes domains, quantitative\nand qualitative evaluation using observational data can help practitioners\nunderstand the generalization performance of new policies. However, this type\nof off-policy evaluation (OPE) is inherently limited since offline data may not\nreflect the distribution shifts resulting from the application of new policies.\nOn the other hand, online evaluation by collecting rollouts according to the\nnew policy is often infeasible, as deploying new policies in these domains can\nbe unsafe. In this work, we propose a semi-offline evaluation framework as an\nintermediate step between offline and online evaluation, where human users\nprovide annotations of unobserved counterfactual trajectories. While tempting\nto simply augment existing data with such annotations, we show that this naive\napproach can lead to biased results. Instead, we design a new family of OPE\nestimators based on importance sampling (IS) and a novel weighting scheme that\nincorporate counterfactual annotations without introducing additional bias. We\nanalyze the theoretical properties of our approach, showing its potential to\nreduce both bias and variance compared to standard IS estimators. Our analyses\nreveal important practical considerations for handling biased, noisy, or\nmissing annotations. In a series of proof-of-concept experiments involving\nbandits and a healthcare-inspired simulator, we demonstrate that our approach\noutperforms purely offline IS estimators and is robust to imperfect\nannotations. Our framework, combined with principled human-centered design of\nannotation solicitation, can enable the application of RL in high-stakes\ndomains.",
            "author": [
                "Shengpu Tang",
                "Jenna Wiens"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17146v1",
                "http://arxiv.org/pdf/2310.17146v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12864v1",
            "title": "OptScaler: A Hybrid Proactive-Reactive Framework for Robust Autoscaling\n  in the Cloud",
            "updated": "2023-10-26T04:38:48Z",
            "published": "2023-10-26T04:38:48Z",
            "summary": "Autoscaling is a vital mechanism in cloud computing that supports the\nautonomous adjustment of computing resources under dynamic workloads. A primary\ngoal of autoscaling is to stabilize resource utilization at a desirable level,\nthus reconciling the need for resource-saving with the satisfaction of Service\nLevel Objectives (SLOs). Existing proactive autoscaling methods anticipate the\nfuture workload and scale the resources in advance, whereas the reliability may\nsuffer from prediction deviations arising from the frequent fluctuations and\nnoise of cloud workloads; reactive methods rely on real-time system feedback,\nwhile the hysteretic nature of reactive methods could cause violations of the\nrigorous SLOs. To this end, this paper presents OptScaler, a hybrid autoscaling\nframework that integrates the power of both proactive and reactive methods for\nregulating CPU utilization. Specifically, the proactive module of OptScaler\nconsists of a sophisticated workload prediction model and an optimization\nmodel, where the former provides reliable inputs to the latter for making\noptimal scaling decisions. The reactive module provides a self-tuning estimator\nof CPU utilization to the optimization model. We embed Model Predictive Control\n(MPC) mechanism and robust optimization techniques into the optimization model\nto further enhance its reliability. Numerical results have demonstrated the\nsuperiority of both the workload prediction model and the hybrid framework of\nOptScaler in the scenario of online services compared to prevalent reactive,\nproactive, or hybrid autoscalers. OptScaler has been successfully deployed at\nAlipay, supporting the autoscaling of applets in the world-leading payment\nplatform.",
            "author": [
                "Ding Zou",
                "Wei Lu",
                "Zhibo Zhu",
                "Xingyu Lu",
                "Jun Zhou",
                "Xiaojin Wang",
                "Kangyu Liu",
                "Haiqing Wang",
                "Kefan Wang",
                "Renen Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12864v1",
                "http://arxiv.org/pdf/2311.12864v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17141v1",
            "title": "Neural style transfer of weak lensing mass maps",
            "updated": "2023-10-26T04:25:41Z",
            "published": "2023-10-26T04:25:41Z",
            "summary": "We propose a new generative model of projected cosmic mass density maps\ninferred from weak gravitational lensing observations of distant galaxies (weak\nlensing mass maps). We construct the model based on a neural style transfer so\nthat it can transform Gaussian weak lensing mass maps into deeply non-Gaussian\ncounterparts as predicted in ray-tracing lensing simulations. We develop an\nunpaired image-to-image translation method with Cycle-Consistent Generative\nAdversarial Networks (Cycle GAN), which learn efficient mapping from an input\ndomain to a target domain. Our model is designed to enjoy important advantages;\nit is trainable with no need for paired simulation data, flexible to make the\ninput domain visually meaningful, and expandable to rapidly-produce a map with\na larger sky coverage than training data without additional learning. Using\n10,000 lensing simulations, we find that appropriate labeling of training data\nbased on field variance requires the model to exhibit a desired diversity of\nvarious summary statistics for weak lensing mass maps. Compared with a popular\nlog-normal model, our model improves in predicting the statistical natures of\nthree-point correlations and local properties of rare high-density regions. We\nalso demonstrate that our model enables us to produce a continuous map with a\nsky coverage of $\\sim166\\, \\mathrm{deg}^2$ but similar non-Gaussian features to\ntraining data covering $\\sim12\\, \\mathrm{deg}^2$ in a GPU minute. Hence, our\nmodel can be beneficial to massive productions of synthetic weak lensing mass\nmaps, which is of great importance in future precise real-world analyses.",
            "author": [
                "Masato Shirasaki",
                "Shiro Ikeda"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17141v1",
                "http://arxiv.org/pdf/2310.17141v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17139v1",
            "title": "Understanding and Addressing the Pitfalls of Bisimulation-based\n  Representations in Offline Reinforcement Learning",
            "updated": "2023-10-26T04:20:55Z",
            "published": "2023-10-26T04:20:55Z",
            "summary": "While bisimulation-based approaches hold promise for learning robust state\nrepresentations for Reinforcement Learning (RL) tasks, their efficacy in\noffline RL tasks has not been up to par. In some instances, their performance\nhas even significantly underperformed alternative methods. We aim to understand\nwhy bisimulation methods succeed in online settings, but falter in offline\ntasks. Our analysis reveals that missing transitions in the dataset are\nparticularly harmful to the bisimulation principle, leading to ineffective\nestimation. We also shed light on the critical role of reward scaling in\nbounding the scale of bisimulation measurements and of the value error they\ninduce. Based on these findings, we propose to apply the expectile operator for\nrepresentation learning to our offline RL setting, which helps to prevent\noverfitting to incomplete data. Meanwhile, by introducing an appropriate reward\nscaling strategy, we avoid the risk of feature collapse in representation\nspace. We implement these recommendations on two state-of-the-art\nbisimulation-based algorithms, MICo and SimSR, and demonstrate performance\ngains on two benchmark suites: D4RL and Visual D4RL. Codes are provided at\n\\url{https://github.com/zanghyu/Offline_Bisimulation}.",
            "author": [
                "Hongyu Zang",
                "Xin Li",
                "Leiji Zhang",
                "Yang Liu",
                "Baigui Sun",
                "Riashat Islam",
                "Remi Tachet des Combes",
                "Romain Laroche"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17139v1",
                "http://arxiv.org/pdf/2310.17139v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17137v1",
            "title": "Large-Scale Gaussian Processes via Alternating Projection",
            "updated": "2023-10-26T04:20:36Z",
            "published": "2023-10-26T04:20:36Z",
            "summary": "Gaussian process (GP) hyperparameter optimization requires repeatedly solving\nlinear systems with $n \\times n$ kernel matrices. To address the prohibitive\n$\\mathcal{O}(n^3)$ time complexity, recent work has employed fast iterative\nnumerical methods, like conjugate gradients (CG). However, as datasets increase\nin magnitude, the corresponding kernel matrices become increasingly\nill-conditioned and still require $\\mathcal{O}(n^2)$ space without\npartitioning. Thus, while CG increases the size of datasets GPs can be trained\non, modern datasets reach scales beyond its applicability. In this work, we\npropose an iterative method which only accesses subblocks of the kernel matrix,\neffectively enabling \\emph{mini-batching}. Our algorithm, based on alternating\nprojection, has $\\mathcal{O}(n)$ per-iteration time and space complexity,\nsolving many of the practical challenges of scaling GPs to very large datasets.\nTheoretically, we prove our method enjoys linear convergence and empirically we\ndemonstrate its robustness to ill-conditioning. On large-scale benchmark\ndatasets up to four million datapoints our approach accelerates training by a\nfactor of 2$\\times$ to 27$\\times$ compared to CG.",
            "author": [
                "Kaiwen Wu",
                "Jonathan Wenger",
                "Haydn Jones",
                "Geoff Pleiss",
                "Jacob R. Gardner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17137v1",
                "http://arxiv.org/pdf/2310.17137v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17133v1",
            "title": "Incorporating Probing Signals into Multimodal Machine Translation via\n  Visual Question-Answering Pairs",
            "updated": "2023-10-26T04:13:49Z",
            "published": "2023-10-26T04:13:49Z",
            "summary": "This paper presents an in-depth study of multimodal machine translation\n(MMT), examining the prevailing understanding that MMT systems exhibit\ndecreased sensitivity to visual information when text inputs are complete.\nInstead, we attribute this phenomenon to insufficient cross-modal interaction,\nrather than image information redundancy. A novel approach is proposed to\ngenerate parallel Visual Question-Answering (VQA) style pairs from the source\ntext, fostering more robust cross-modal interaction. Using Large Language\nModels (LLMs), we explicitly model the probing signal in MMT to convert it into\nVQA-style data to create the Multi30K-VQA dataset. An MMT-VQA multitask\nlearning framework is introduced to incorporate explicit probing signals from\nthe dataset into the MMT training process. Experimental results on two\nwidely-used benchmarks demonstrate the effectiveness of this novel approach.\nOur code and data would be available at:\n\\url{https://github.com/libeineu/MMT-VQA}.",
            "author": [
                "Yuxin Zuo",
                "Bei Li",
                "Chuanhao Lv",
                "Tong Zheng",
                "Tong Xiao",
                "Jingbo Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17133v1",
                "http://arxiv.org/pdf/2310.17133v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17132v1",
            "title": "Unleashing the potential of GNNs via Bi-directional Knowledge Transfer",
            "updated": "2023-10-26T04:11:49Z",
            "published": "2023-10-26T04:11:49Z",
            "summary": "Based on the message-passing paradigm, there has been an amount of research\nproposing diverse and impressive feature propagation mechanisms to improve the\nperformance of GNNs. However, less focus has been put on feature\ntransformation, another major operation of the message-passing framework. In\nthis paper, we first empirically investigate the performance of the feature\ntransformation operation in several typical GNNs. Unexpectedly, we notice that\nGNNs do not completely free up the power of the inherent feature transformation\noperation. By this observation, we propose the Bi-directional Knowledge\nTransfer (BiKT), a plug-and-play approach to unleash the potential of the\nfeature transformation operations without modifying the original architecture.\nTaking the feature transformation operation as a derived representation\nlearning model that shares parameters with the original GNN, the direct\nprediction by this model provides a topological-agnostic knowledge feedback\nthat can further instruct the learning of GNN and the feature transformations\ntherein. On this basis, BiKT not only allows us to acquire knowledge from both\nthe GNN and its derived model but promotes each other by injecting the\nknowledge into the other. In addition, a theoretical analysis is further\nprovided to demonstrate that BiKT improves the generalization bound of the GNNs\nfrom the perspective of domain adaption. An extensive group of experiments on\nup to 7 datasets with 5 typical GNNs demonstrates that BiKT brings up to 0.5% -\n4% performance gain over the original GNN, which means a boosted GNN is\nobtained. Meanwhile, the derived model also shows a powerful performance to\ncompete with or even surpass the original GNN, enabling us to flexibly apply it\nindependently to some other specific downstream tasks.",
            "author": [
                "Shuai Zheng",
                "Zhizhe Liu",
                "Zhenfeng Zhu",
                "Xingxing Zhang",
                "Jianxin Li",
                "Yao Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17132v1",
                "http://arxiv.org/pdf/2310.17132v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17131v1",
            "title": "Virtual Accessory Try-On via Keypoint Hallucination",
            "updated": "2023-10-26T04:11:34Z",
            "published": "2023-10-26T04:11:34Z",
            "summary": "The virtual try-on task refers to fitting the clothes from one image onto\nanother portrait image. In this paper, we focus on virtual accessory try-on,\nwhich fits accessory (e.g., glasses, ties) onto a face or portrait image.\nUnlike clothing try-on, which relies on human silhouette as guidance, accessory\ntry-on warps the accessory into an appropriate location and shape to generate a\nplausible composite image. In contrast to previous try-on methods that treat\nforeground (i.e., accessories) and background (i.e., human faces or bodies)\nequally, we propose a background-oriented network to utilize the prior\nknowledge of human bodies and accessories. Specifically, our approach learns\nthe human body priors and hallucinates the target locations of specified\nforeground keypoints in the background. Then our approach will inject\nforeground information with accessory priors into the background UNet. Based on\nthe hallucinated target locations, the warping parameters are calculated to\nwarp the foreground. Moreover, this background-oriented network can also easily\nincorporate auxiliary human face/body semantic segmentation supervision to\nfurther boost performance. Experiments conducted on STRAT dataset validate the\neffectiveness of our proposed method.",
            "author": [
                "Junhong Gou",
                "Bo Zhang",
                "Li Niu",
                "Jianfu Zhang",
                "Jianlou Si",
                "Chen Qian",
                "Liqing Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17131v1",
                "http://arxiv.org/pdf/2310.17131v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17128v1",
            "title": "Task-driven Prompt Evolution for Foundation Models",
            "updated": "2023-10-26T04:08:07Z",
            "published": "2023-10-26T04:08:07Z",
            "summary": "Promptable foundation models, particularly Segment Anything Model (SAM), have\nemerged as a promising alternative to the traditional task-specific supervised\nlearning for image segmentation. However, many evaluation studies have found\nthat their performance on medical imaging modalities to be underwhelming\ncompared to conventional deep learning methods. In the world of large\npre-trained language and vision-language models, learning prompt from\ndownstream tasks has achieved considerable success in improving performance. In\nthis work, we propose a plug-and-play Prompt Optimization Technique for\nfoundation models like SAM (SAMPOT) that utilizes the downstream segmentation\ntask to optimize the human-provided prompt to obtain improved performance. We\ndemonstrate the utility of SAMPOT on lung segmentation in chest X-ray images\nand obtain an improvement on a significant number of cases ($\\sim75\\%$) over\nhuman-provided initial prompts. We hope this work will lead to further\ninvestigations in the nascent field of automatic visual prompt-tuning.",
            "author": [
                "Rachana Sathish",
                "Rahul Venkataramani",
                "K S Shriram",
                "Prasad Sudhakar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17128v1",
                "http://arxiv.org/pdf/2310.17128v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17127v1",
            "title": "A Method for Network Intrusion Detection Using Flow Sequence and BERT\n  Framework",
            "updated": "2023-10-26T03:56:40Z",
            "published": "2023-10-26T03:56:40Z",
            "summary": "A Network Intrusion Detection System (NIDS) is a tool that identifies\npotential threats to a network. Recently, different flow-based NIDS designs\nutilizing Machine Learning (ML) algorithms have been proposed as solutions to\ndetect intrusions efficiently. However, conventional ML-based classifiers have\nnot seen widespread adoption in the real world due to their poor domain\nadaptation capability. In this research, our goal is to explore the possibility\nof using sequences of flows to improve the domain adaptation capability of\nnetwork intrusion detection systems. Our proposal employs natural language\nprocessing techniques and Bidirectional Encoder Representations from\nTransformers framework, which is an effective technique for modeling data with\nrespect to its context. Early empirical results show that our approach has\nimproved domain adaptation capability compared to previous approaches. The\nproposed approach provides a new research method for building a robust\nintrusion detection system.",
            "author": [
                "Loc Gia Nguyen",
                "Kohei Watabe"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ICC45041.2023.10279335",
                "http://arxiv.org/abs/2310.17127v1",
                "http://arxiv.org/pdf/2310.17127v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17126v1",
            "title": "Deep Learning on SAR Imagery: Transfer Learning Versus Randomly\n  Initialized Weights",
            "updated": "2023-10-26T03:52:54Z",
            "published": "2023-10-26T03:52:54Z",
            "summary": "Deploying deep learning on Synthetic Aperture Radar (SAR) data is becoming\nmore common for mapping purposes. One such case is sea ice, which is highly\ndynamic and rapidly changes as a result of the combined effect of wind,\ntemperature, and ocean currents. Therefore, frequent mapping of sea ice is\nnecessary to ensure safe marine navigation. However, there is a general\nshortage of expert-labeled data to train deep learning algorithms. Fine-tuning\na pre-trained model on SAR imagery is a potential solution. In this paper, we\ncompare the performance of deep learning models trained from scratch using\nrandomly initialized weights against pre-trained models that we fine-tune for\nthis purpose. Our results show that pre-trained models lead to better results,\nespecially on test samples from the melt season.",
            "author": [
                "Morteza Karimzadeh",
                "Rafael Pires de Lima"
            ],
            "link": [
                "http://dx.doi.org/10.1109/IGARSS52108.2023.10281892",
                "http://arxiv.org/abs/2310.17126v1",
                "http://arxiv.org/pdf/2310.17126v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17122v1",
            "title": "Enhancing sea ice segmentation in Sentinel-1 images with atrous\n  convolutions",
            "updated": "2023-10-26T03:43:28Z",
            "published": "2023-10-26T03:43:28Z",
            "summary": "Due to the growing volume of remote sensing data and the low latency required\nfor safe marine navigation, machine learning (ML) algorithms are being\ndeveloped to accelerate sea ice chart generation, currently a manual\ninterpretation task. However, the low signal-to-noise ratio of the freely\navailable Sentinel-1 Synthetic Aperture Radar (SAR) imagery, the ambiguity of\nbackscatter signals for ice types, and the scarcity of open-source\nhigh-resolution labelled data makes automating sea ice mapping challenging. We\nuse Extreme Earth version 2, a high-resolution benchmark dataset generated for\nML training and evaluation, to investigate the effectiveness of ML for\nautomated sea ice mapping. Our customized pipeline combines ResNets and Atrous\nSpatial Pyramid Pooling for SAR image segmentation. We investigate the\nperformance of our model for: i) binary classification of sea ice and open\nwater in a segmentation framework; and ii) a multiclass segmentation of five\nsea ice types. For binary ice-water classification, models trained with our\nlargest training set have weighted F1 scores all greater than 0.95 for January\nand July test scenes. Specifically, the median weighted F1 score was 0.98,\nindicating high performance for both months. By comparison, a competitive\nbaseline U-Net has a weighted average F1 score of ranging from 0.92 to 0.94\n(median 0.93) for July, and 0.97 to 0.98 (median 0.97) for January. Multiclass\nice type classification is more challenging, and even though our models achieve\n2% improvement in weighted F1 average compared to the baseline U-Net, test\nweighted F1 is generally between 0.6 and 0.80. Our approach can efficiently\nsegment full SAR scenes in one run, is faster than the baseline U-Net, retains\nspatial resolution and dimension, and is more robust against noise compared to\napproaches that rely on patch classification.",
            "author": [
                "Rafael Pires de Lima",
                "Behzad Vahedi",
                "Nick Hughes",
                "Andrew P. Barrett",
                "Walter Meier",
                "Morteza Karimzadeh"
            ],
            "link": [
                "http://dx.doi.org/10.1080/01431161.2023.2248560",
                "http://arxiv.org/abs/2310.17122v1",
                "http://arxiv.org/pdf/2310.17122v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17120v1",
            "title": "Topic Segmentation of Semi-Structured and Unstructured Conversational\n  Datasets using Language Models",
            "updated": "2023-10-26T03:37:51Z",
            "published": "2023-10-26T03:37:51Z",
            "summary": "Breaking down a document or a conversation into multiple contiguous segments\nbased on its semantic structure is an important and challenging problem in NLP,\nwhich can assist many downstream tasks. However, current works on topic\nsegmentation often focus on segmentation of structured texts. In this paper, we\ncomprehensively analyze the generalization capabilities of state-of-the-art\ntopic segmentation models on unstructured texts. We find that: (a) Current\nstrategies of pre-training on a large corpus of structured text such as\nWiki-727K do not help in transferability to unstructured conversational data.\n(b) Training from scratch with only a relatively small-sized dataset of the\ntarget unstructured domain improves the segmentation results by a significant\nmargin. We stress-test our proposed Topic Segmentation approach by\nexperimenting with multiple loss functions, in order to mitigate effects of\nimbalance in unstructured conversational datasets. Our empirical evaluation\nindicates that Focal Loss function is a robust alternative to Cross-Entropy and\nre-weighted Cross-Entropy loss function when segmenting unstructured and\nsemi-structured chats.",
            "author": [
                "Reshmi Ghosh",
                "Harjeet Singh Kajal",
                "Sharanya Kamath",
                "Dhuri Shrivastava",
                "Samyadeep Basu",
                "Hansi Zeng",
                "Soundararajan Srinivasan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17120v1",
                "http://arxiv.org/pdf/2310.17120v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17116v1",
            "title": "Real-time Neonatal Chest Sound Separation using Deep Learning",
            "updated": "2023-10-26T03:05:40Z",
            "published": "2023-10-26T03:05:40Z",
            "summary": "Auscultation for neonates is a simple and non-invasive method of providing\ndiagnosis for cardiovascular and respiratory disease. Such diagnosis often\nrequires high-quality heart and lung sounds to be captured during auscultation.\nHowever, in most cases, obtaining such high-quality sounds is non-trivial due\nto the chest sounds containing a mixture of heart, lung, and noise sounds. As\nsuch, additional preprocessing is needed to separate the chest sounds into\nheart and lung sounds. This paper proposes a novel deep-learning approach to\nseparate such chest sounds into heart and lung sounds. Inspired by the\nConv-TasNet model, the proposed model has an encoder, decoder, and mask\ngenerator. The encoder consists of a 1D convolution model and the decoder\nconsists of a transposed 1D convolution. The mask generator is constructed\nusing stacked 1D convolutions and transformers. The proposed model outperforms\nprevious methods in terms of objective distortion measures by 2.01 dB to 5.06\ndB in the artificial dataset, as well as computation time, with at least a\n17-time improvement. Therefore, our proposed model could be a suitable\npreprocessing step for any phonocardiogram-based health monitoring system.",
            "author": [
                "Yang Yi Poh",
                "Ethan Grooby",
                "Kenneth Tan",
                "Lindsay Zhou",
                "Arrabella King",
                "Ashwin Ramanathan",
                "Atul Malhotra",
                "Mehrtash Harandi",
                "Faezeh Marzbanrad"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17116v1",
                "http://arxiv.org/pdf/2310.17116v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17115v1",
            "title": "Optimal Robotic Assembly Sequence Planning: A Sequential Decision-Making\n  Approach",
            "updated": "2023-10-26T03:01:14Z",
            "published": "2023-10-26T03:01:14Z",
            "summary": "The optimal robot assembly planning problem is challenging due to the\nnecessity of finding the optimal solution amongst an exponentially vast number\nof possible plans, all while satisfying a selection of constraints.\nTraditionally, robotic assembly planning problems have been solved using\nheuristics, but these methods are specific to a given objective structure or\nset of problem parameters. In this paper, we propose a novel approach to\nrobotic assembly planning that poses assembly sequencing as a sequential\ndecision making problem, enabling us to harness methods that far outperform the\nstate-of-the-art. We formulate the problem as a Markov Decision Process (MDP)\nand utilize Dynamic Programming (DP) to find optimal assembly policies for\nmoderately sized strictures. We further expand our framework to exploit the\ndeterministic nature of assembly planning and introduce a class of optimal\nGraph Exploration Assembly Planners (GEAPs). For larger structures, we show how\nReinforcement Learning (RL) enables us to learn policies that generate high\nreward assembly sequences. We evaluate our approach on a variety of robotic\nassembly problems, such as the assembly of the Hubble Space Telescope, the\nInternational Space Station, and the James Webb Space Telescope. We further\nshowcase how our DP, GEAP, and RL implementations are capable of finding\noptimal solutions under a variety of different objective functions and how our\nformulation allows us to translate precedence constraints to branch pruning and\nthus further improve performance. We have published our code at\nhttps://github.com/labicon/ORASP-Code.",
            "author": [
                "Kartik Nagpal",
                "Negar Mehr"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17115v1",
                "http://arxiv.org/pdf/2310.17115v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17114v1",
            "title": "On the Convergence of CART under Sufficient Impurity Decrease Condition",
            "updated": "2023-10-26T03:01:11Z",
            "published": "2023-10-26T03:01:11Z",
            "summary": "The decision tree is a flexible machine learning model that finds its success\nin numerous applications. It is usually fitted in a recursively greedy manner\nusing CART. In this paper, we investigate the convergence rate of CART under a\nregression setting. First, we establish an upper bound on the prediction error\nof CART under a sufficient impurity decrease (SID) condition\n\\cite{chi2022asymptotic} -- our result improves upon the known result by\n\\cite{chi2022asymptotic} under a similar assumption. Furthermore, we provide\nexamples that demonstrate the error bound cannot be further improved by more\nthan a constant or a logarithmic factor. Second, we introduce a set of easily\nverifiable sufficient conditions for the SID condition. Specifically, we\ndemonstrate that the SID condition can be satisfied in the case of an additive\nmodel, provided that the component functions adhere to a ``locally reverse\nPoincar{\\'e} inequality\". We discuss several well-known function classes in\nnon-parametric estimation to illustrate the practical utility of this concept.",
            "author": [
                "Rahul Mazumder",
                "Haoyue Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17114v1",
                "http://arxiv.org/pdf/2310.17114v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17110v1",
            "title": "LLM4DyG: Can Large Language Models Solve Problems on Dynamic Graphs?",
            "updated": "2023-10-26T02:37:43Z",
            "published": "2023-10-26T02:37:43Z",
            "summary": "In an era marked by the increasing adoption of Large Language Models (LLMs)\nfor various tasks, there is a growing focus on exploring LLMs' capabilities in\nhandling web data, particularly graph data. Dynamic graphs, which capture\ntemporal network evolution patterns, are ubiquitous in real-world web data.\nEvaluating LLMs' competence in understanding spatial-temporal information on\ndynamic graphs is essential for their adoption in web applications, which\nremains unexplored in the literature. In this paper, we bridge the gap via\nproposing to evaluate LLMs' spatial-temporal understanding abilities on dynamic\ngraphs, to the best of our knowledge, for the first time. Specifically, we\npropose the LLM4DyG benchmark, which includes nine specially designed tasks\nconsidering the capability evaluation of LLMs from both temporal and spatial\ndimensions. Then, we conduct extensive experiments to analyze the impacts of\ndifferent data generators, data statistics, prompting techniques, and LLMs on\nthe model performance. Finally, we propose Disentangled Spatial-Temporal\nThoughts (DST2) for LLMs on dynamic graphs to enhance LLMs' spatial-temporal\nunderstanding abilities. Our main observations are: 1) LLMs have preliminary\nspatial-temporal understanding abilities on dynamic graphs, 2) Dynamic graph\ntasks show increasing difficulties for LLMs as the graph size and density\nincrease, while not sensitive to the time span and data generation mechanism,\n3) the proposed DST2 prompting method can help to improve LLMs'\nspatial-temporal understanding abilities on dynamic graphs for most tasks. The\ndata and codes will be open-sourced at publication time.",
            "author": [
                "Zeyang Zhang",
                "Xin Wang",
                "Ziwei Zhang",
                "Haoyang Li",
                "Yijian Qin",
                "Simin Wu",
                "Wenwu Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17110v1",
                "http://arxiv.org/pdf/2310.17110v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18257v1",
            "title": "MIM-GAN-based Anomaly Detection for Multivariate Time Series Data",
            "updated": "2023-10-26T02:09:39Z",
            "published": "2023-10-26T02:09:39Z",
            "summary": "The loss function of Generative adversarial network(GAN) is an important\nfactor that affects the quality and diversity of the generated samples for\nanomaly detection. In this paper, we propose an unsupervised multiple time\nseries anomaly detection algorithm based on the GAN with message importance\nmeasure(MIM-GAN). In particular, the time series data is divided into\nsubsequences using a sliding window. Then a generator and a discriminator\ndesigned based on the Long Short-Term Memory (LSTM) are employed to capture the\ntemporal correlations of the time series data. To avoid the local optimal\nsolution of loss function and the model collapse, we introduce an exponential\ninformation measure into the loss function of GAN. Additionally, a discriminant\nreconstruction score consisting on discrimination and reconstruction loss is\ntaken into account. The global optimal solution for the loss function is\nderived and the model collapse is proved to be avoided in our proposed\nMIM-GAN-based anomaly detection algorithm. Experimental results show that the\nproposed MIM-GAN-based anomaly detection algorithm has superior performance in\nterms of precision, recall, and F1 score.",
            "author": [
                "Shan Lu",
                "Zhicheng Dong",
                "Donghong Cai",
                "Fang Fang",
                "Dongcai Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18257v1",
                "http://arxiv.org/pdf/2310.18257v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17101v1",
            "title": "Multi-Speaker Expressive Speech Synthesis via Semi-supervised\n  Contrastive Learning",
            "updated": "2023-10-26T01:58:38Z",
            "published": "2023-10-26T01:58:38Z",
            "summary": "This paper aims to build an expressive TTS system for multi-speakers,\nsynthesizing a target speaker's speech with multiple styles and emotions. To\nthis end, we propose a novel contrastive learning-based TTS approach to\ntransfer style and emotion across speakers. Specifically, we construct\npositive-negative sample pairs at both utterance and category (such as\nemotion-happy or style-poet or speaker A) levels and leverage contrastive\nlearning to better extract disentangled style, emotion, and speaker\nrepresentations from speech. Furthermore, we introduce a semi-supervised\ntraining strategy to the proposed approach to effectively leverage multi-domain\ndata, including style-labeled data, emotion-labeled data, and unlabeled data.\nWe integrate the learned representations into an improved VITS model, enabling\nit to synthesize expressive speech with diverse styles and emotions for a\ntarget speaker. Experiments on multi-domain data demonstrate the good design of\nour model.",
            "author": [
                "Xinfa Zhu",
                "Yuke Li",
                "Yi Lei",
                "Ning Jiang",
                "Guoqing Zhao",
                "Lei Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17101v1",
                "http://arxiv.org/pdf/2310.17101v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17100v1",
            "title": "Network Design through Graph Neural Networks: Identifying Challenges and\n  Improving Performance",
            "updated": "2023-10-26T01:45:20Z",
            "published": "2023-10-26T01:45:20Z",
            "summary": "Graph Neural Network (GNN) research has produced strategies to modify a\ngraph's edges using gradients from a trained GNN, with the goal of network\ndesign. However, the factors which govern gradient-based editing are\nunderstudied, obscuring why edges are chosen and if edits are grounded in an\nedge's importance. Thus, we begin by analyzing the gradient computation in\nprevious works, elucidating the factors that influence edits and highlighting\nthe potential over-reliance on structural properties. Specifically, we find\nthat edges can achieve high gradients due to structural biases, rather than\nimportance, leading to erroneous edits when the factors are unrelated to the\ndesign task. To improve editing, we propose ORE, an iterative editing method\nthat (a) edits the highest scoring edges and (b) re-embeds the edited graph to\nrefresh gradients, leading to less biased edge choices. We empirically study\nORE through a set of proposed design tasks, each with an external validation\nmethod, demonstrating that ORE improves upon previous methods by up to 50%.",
            "author": [
                "Donald Loveland",
                "Rajmonda Caceres"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17100v1",
                "http://arxiv.org/pdf/2310.17100v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17097v2",
            "title": "Navigating Data Heterogeneity in Federated Learning A Semi-Supervised\n  Approach for Object Detection",
            "updated": "2023-10-27T17:13:00Z",
            "published": "2023-10-26T01:40:28Z",
            "summary": "Federated Learning (FL) has emerged as a potent framework for training models\nacross distributed data sources while maintaining data privacy. Nevertheless,\nit faces challenges with limited high-quality labels and non-IID client data,\nparticularly in applications like autonomous driving. To address these hurdles,\nwe navigate the uncharted waters of Semi-Supervised Federated Object Detection\n(SSFOD). We present a pioneering SSFOD framework, designed for scenarios where\nlabeled data reside only at the server while clients possess unlabeled data.\nNotably, our method represents the inaugural implementation of SSFOD for\nclients with 0% labeled non-IID data, a stark contrast to previous studies that\nmaintain some subset of labels at each client. We propose FedSTO, a two-stage\nstrategy encompassing Selective Training followed by Orthogonally enhanced\nfull-parameter training, to effectively address data shift (e.g. weather\nconditions) between server and clients. Our contributions include selectively\nrefining the backbone of the detector to avert overfitting, orthogonality\nregularization to boost representation divergence, and local EMA-driven pseudo\nlabel assignment to yield high-quality pseudo labels. Extensive validation on\nprominent autonomous driving datasets (BDD100K, Cityscapes, and SODA10M)\nattests to the efficacy of our approach, demonstrating state-of-the-art\nresults. Remarkably, FedSTO, using just 20-30% of labels, performs nearly as\nwell as fully-supervised centralized training methods.",
            "author": [
                "Taehyeon Kim",
                "Eric Lin",
                "Junu Lee",
                "Christian Lau",
                "Vaikkunth Mugunthan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17097v2",
                "http://arxiv.org/pdf/2310.17097v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17091v1",
            "title": "Detecting stealthy cyberattacks on adaptive cruise control vehicles: A\n  machine learning approach",
            "updated": "2023-10-26T01:22:10Z",
            "published": "2023-10-26T01:22:10Z",
            "summary": "With the advent of vehicles equipped with advanced driver-assistance systems,\nsuch as adaptive cruise control (ACC) and other automated driving features, the\npotential for cyberattacks on these automated vehicles (AVs) has emerged. While\novert attacks that force vehicles to collide may be easily identified, more\ninsidious attacks, which only slightly alter driving behavior, can result in\nnetwork-wide increases in congestion, fuel consumption, and even crash risk\nwithout being easily detected. To address the detection of such attacks, we\nfirst present a traffic model framework for three types of potential\ncyberattacks: malicious manipulation of vehicle control commands, false data\ninjection attacks on sensor measurements, and denial-of-service (DoS) attacks.\nWe then investigate the impacts of these attacks at both the individual vehicle\n(micro) and traffic flow (macro) levels. A novel generative adversarial network\n(GAN)-based anomaly detection model is proposed for real-time identification of\nsuch attacks using vehicle trajectory data. We provide numerical evidence {to\ndemonstrate} the efficacy of our machine learning approach in detecting\ncyberattacks on ACC-equipped vehicles. The proposed method is compared against\nsome recently proposed neural network models and observed to have higher\naccuracy in identifying anomalous driving behaviors of ACC vehicles.",
            "author": [
                "Tianyi Li",
                "Mingfeng Shang",
                "Shian Wang",
                "Raphael Stern"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17091v1",
                "http://arxiv.org/pdf/2310.17091v1"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17087v1",
            "title": "Good regularity creates large learning rate implicit biases: edge of\n  stability, balancing, and catapult",
            "updated": "2023-10-26T01:11:17Z",
            "published": "2023-10-26T01:11:17Z",
            "summary": "Large learning rates, when applied to gradient descent for nonconvex\noptimization, yield various implicit biases including the edge of stability\n(Cohen et al., 2021), balancing (Wang et al., 2022), and catapult (Lewkowycz et\nal., 2020). These phenomena cannot be well explained by classical optimization\ntheory. Though significant theoretical progress has been made in understanding\nthese implicit biases, it remains unclear for which objective functions would\nthey occur. This paper provides an initial step in answering this question,\nnamely that these implicit biases are in fact various tips of the same iceberg.\nThey occur when the objective function of optimization has some good\nregularity, which, in combination with a provable preference of large learning\nrate gradient descent for moving toward flatter regions, results in these\nnontrivial dynamical phenomena. To establish this result, we develop a new\nglobal convergence theory under large learning rates, for a family of nonconvex\nfunctions without globally Lipschitz continuous gradient, which was typically\nassumed in existing convergence analysis. A byproduct is the first\nnon-asymptotic convergence rate bound for large-learning-rate gradient descent\noptimization of nonconvex functions. We also validate our theory with\nexperiments on neural networks, where different losses, activation functions,\nand batch normalization all can significantly affect regularity and lead to\nvery different training dynamics.",
            "author": [
                "Yuqing Wang",
                "Zhenghao Xu",
                "Tuo Zhao",
                "Molei Tao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17087v1",
                "http://arxiv.org/pdf/2310.17087v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.DS",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17086v1",
            "title": "Transformers Learn Higher-Order Optimization Methods for In-Context\n  Learning: A Study with Linear Models",
            "updated": "2023-10-26T01:08:47Z",
            "published": "2023-10-26T01:08:47Z",
            "summary": "Transformers are remarkably good at in-context learning (ICL) -- learning\nfrom demonstrations without parameter updates -- but how they perform ICL\nremains a mystery. Recent work suggests that Transformers may learn in-context\nby internally running Gradient Descent, a first-order optimization method. In\nthis paper, we instead demonstrate that Transformers learn to implement\nhigher-order optimization methods to perform ICL. Focusing on in-context linear\nregression, we show that Transformers learn to implement an algorithm very\nsimilar to Iterative Newton's Method, a higher-order optimization method,\nrather than Gradient Descent. Empirically, we show that predictions from\nsuccessive Transformer layers closely match different iterations of Newton's\nMethod linearly, with each middle layer roughly computing 3 iterations. In\ncontrast, exponentially more Gradient Descent steps are needed to match an\nadditional Transformers layer; this suggests that Transformers have an\ncomparable rate of convergence with high-order methods such as Iterative\nNewton, which are exponentially faster than Gradient Descent. We also show that\nTransformers can learn in-context on ill-conditioned data, a setting where\nGradient Descent struggles but Iterative Newton succeeds. Finally, we show\ntheoretical results which support our empirical findings and have a close\ncorrespondence with them: we prove that Transformers can implement $k$\niterations of Newton's method with $\\mathcal{O}(k)$ layers.",
            "author": [
                "Deqing Fu",
                "Tian-Qi Chen",
                "Robin Jia",
                "Vatsal Sharan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17086v1",
                "http://arxiv.org/pdf/2310.17086v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17080v1",
            "title": "Automating lichen monitoring in ecological studies using instance\n  segmentation of time-lapse images",
            "updated": "2023-10-26T00:45:19Z",
            "published": "2023-10-26T00:45:19Z",
            "summary": "Lichens are symbiotic organisms composed of fungi, algae, and/or\ncyanobacteria that thrive in a variety of environments. They play important\nroles in carbon and nitrogen cycling, and contribute directly and indirectly to\nbiodiversity. Ecologists typically monitor lichens by using them as indicators\nto assess air quality and habitat conditions. In particular, epiphytic lichens,\nwhich live on trees, are key markers of air quality and environmental health. A\nnew method of monitoring epiphytic lichens involves using time-lapse cameras to\ngather images of lichen populations. These cameras are used by ecologists in\nNewfoundland and Labrador to subsequently analyze and manually segment the\nimages to determine lichen thalli condition and change. These methods are\ntime-consuming and susceptible to observer bias. In this work, we aim to\nautomate the monitoring of lichens over extended periods and to estimate their\nbiomass and condition to facilitate the task of ecologists. To accomplish this,\nour proposed framework uses semantic segmentation with an effective training\napproach to automate monitoring and biomass estimation of epiphytic lichens on\ntime-lapse images. We show that our method has the potential to significantly\nimprove the accuracy and efficiency of lichen population monitoring, making it\na valuable tool for forest ecologists and environmental scientists to evaluate\nthe impact of climate change on Canada's forests. To the best of our knowledge,\nthis is the first time that such an approach has been used to assist ecologists\nin monitoring and analyzing epiphytic lichens.",
            "author": [
                "Safwen Naimi",
                "Olfa Koubaa",
                "Wassim Bouachir",
                "Guillaume-Alexandre Bilodeau",
                "Gregory Jeddore",
                "Patricia Baines",
                "David Correia",
                "Andre Arsenault"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17080v1",
                "http://arxiv.org/pdf/2310.17080v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17078v1",
            "title": "HCT: Hybrid Convnet-Transformer for Parkinson's disease detection and\n  severity prediction from gait",
            "updated": "2023-10-26T00:43:15Z",
            "published": "2023-10-26T00:43:15Z",
            "summary": "In this paper, we propose a novel deep learning method based on a new Hybrid\nConvNet-Transformer architecture to detect and stage Parkinson's disease (PD)\nfrom gait data. We adopt a two-step approach by dividing the problem into two\nsub-problems. Our Hybrid ConvNet-Transformer model first distinguishes healthy\nversus parkinsonian patients. If the patient is parkinsonian, a multi-class\nHybrid ConvNet-Transformer model determines the Hoehn and Yahr (H&Y) score to\nassess the PD severity stage. Our hybrid architecture exploits the strengths of\nboth Convolutional Neural Networks (ConvNets) and Transformers to accurately\ndetect PD and determine the severity stage. In particular, we take advantage of\nConvNets to capture local patterns and correlations in the data, while we\nexploit Transformers for handling long-term dependencies in the input signal.\nWe show that our hybrid method achieves superior performance when compared to\nother state-of-the-art methods, with a PD detection accuracy of 97% and a\nseverity staging accuracy of 87%. Our source code is available at:\nhttps://github.com/SafwenNaimi",
            "author": [
                "Safwen Naimi",
                "Wassim Bouachir",
                "Guillaume-Alexandre Bilodeau"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17078v1",
                "http://arxiv.org/pdf/2310.17078v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17075v2",
            "title": "HyperFields: Towards Zero-Shot Generation of NeRFs from Text",
            "updated": "2023-10-27T14:35:04Z",
            "published": "2023-10-26T00:36:03Z",
            "summary": "We introduce HyperFields, a method for generating text-conditioned Neural\nRadiance Fields (NeRFs) with a single forward pass and (optionally) some\nfine-tuning. Key to our approach are: (i) a dynamic hypernetwork, which learns\na smooth mapping from text token embeddings to the space of NeRFs; (ii) NeRF\ndistillation training, which distills scenes encoded in individual NeRFs into\none dynamic hypernetwork. These techniques enable a single network to fit over\na hundred unique scenes. We further demonstrate that HyperFields learns a more\ngeneral map between text and NeRFs, and consequently is capable of predicting\nnovel in-distribution and out-of-distribution scenes -- either zero-shot or\nwith a few finetuning steps. Finetuning HyperFields benefits from accelerated\nconvergence thanks to the learned general map, and is capable of synthesizing\nnovel scenes 5 to 10 times faster than existing neural optimization-based\nmethods. Our ablation experiments show that both the dynamic architecture and\nNeRF distillation are critical to the expressivity of HyperFields.",
            "author": [
                "Sudarshan Babu",
                "Richard Liu",
                "Avery Zhou",
                "Michael Maire",
                "Greg Shakhnarovich",
                "Rana Hanocka"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17075v2",
                "http://arxiv.org/pdf/2310.17075v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17074v1",
            "title": "Benign Oscillation of Stochastic Gradient Descent with Large Learning\n  Rates",
            "updated": "2023-10-26T00:35:40Z",
            "published": "2023-10-26T00:35:40Z",
            "summary": "In this work, we theoretically investigate the generalization properties of\nneural networks (NN) trained by stochastic gradient descent (SGD) algorithm\nwith large learning rates. Under such a training regime, our finding is that,\nthe oscillation of the NN weights caused by the large learning rate SGD\ntraining turns out to be beneficial to the generalization of the NN, which\npotentially improves over the same NN trained by SGD with small learning rates\nthat converges more smoothly. In view of this finding, we call such a\nphenomenon \"benign oscillation\". Our theory towards demystifying such a\nphenomenon builds upon the feature learning perspective of deep learning.\nSpecifically, we consider a feature-noise data generation model that consists\nof (i) weak features which have a small $\\ell_2$-norm and appear in each data\npoint; (ii) strong features which have a larger $\\ell_2$-norm but only appear\nin a certain fraction of all data points; and (iii) noise. We prove that NNs\ntrained by oscillating SGD with a large learning rate can effectively learn the\nweak features in the presence of those strong features. In contrast, NNs\ntrained by SGD with a small learning rate can only learn the strong features\nbut makes little progress in learning the weak features. Consequently, when it\ncomes to the new testing data which consist of only weak features, the NN\ntrained by oscillating SGD with a large learning rate could still make correct\npredictions consistently, while the NN trained by small learning rate SGD\nfails. Our theory sheds light on how large learning rate training benefits the\ngeneralization of NNs. Experimental results demonstrate our finding on \"benign\noscillation\".",
            "author": [
                "Miao Lu",
                "Beining Wu",
                "Xiaodong Yang",
                "Difan Zou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17074v1",
                "http://arxiv.org/pdf/2310.17074v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17072v1",
            "title": "Isometric Motion Manifold Primitives",
            "updated": "2023-10-26T00:28:37Z",
            "published": "2023-10-26T00:28:37Z",
            "summary": "The Motion Manifold Primitive (MMP) produces, for a given task, a continuous\nmanifold of trajectories each of which can successfully complete the task. It\nconsists of the decoder function that parametrizes the manifold and the\nprobability density in the latent coordinate space. In this paper, we first\nshow that the MMP performance can significantly degrade due to the geometric\ndistortion in the latent space -- by distortion, we mean that similar motions\nare not located nearby in the latent space. We then propose {\\it Isometric\nMotion Manifold Primitives (IMMP)} whose latent coordinate space preserves the\ngeometry of the manifold. For this purpose, we formulate and use a Riemannian\nmetric for the motion space (i.e., parametric curve space), which we call a\n{\\it CurveGeom Riemannian metric}. Experiments with planar obstacle-avoiding\nmotions and pushing manipulation tasks show that IMMP significantly outperforms\nexisting MMP methods. Code is available at\nhttps://github.com/Gabe-YHLee/IMMP-public.",
            "author": [
                "Yonghyeon Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17072v1",
                "http://arxiv.org/pdf/2310.17072v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17064v1",
            "title": "math-PVS: A Large Language Model Framework to Map Scientific\n  Publications to PVS Theories",
            "updated": "2023-10-25T23:54:04Z",
            "published": "2023-10-25T23:54:04Z",
            "summary": "As artificial intelligence (AI) gains greater adoption in a wide variety of\napplications, it has immense potential to contribute to mathematical discovery,\nby guiding conjecture generation, constructing counterexamples, assisting in\nformalizing mathematics, and discovering connections between different\nmathematical areas, to name a few.\n  While prior work has leveraged computers for exhaustive mathematical proof\nsearch, recent efforts based on large language models (LLMs) aspire to position\ncomputing platforms as co-contributors in the mathematical research process.\nDespite their current limitations in logic and mathematical tasks, there is\ngrowing interest in melding theorem proving systems with foundation models.\nThis work investigates the applicability of LLMs in formalizing advanced\nmathematical concepts and proposes a framework that can critically review and\ncheck mathematical reasoning in research papers. Given the noted reasoning\nshortcomings of LLMs, our approach synergizes the capabilities of proof\nassistants, specifically PVS, with LLMs, enabling a bridge between textual\ndescriptions in academic papers and formal specifications in PVS. By harnessing\nthe PVS environment, coupled with data ingestion and conversion mechanisms, we\nenvision an automated process, called \\emph{math-PVS}, to extract and formalize\nmathematical theorems from research papers, offering an innovative tool for\nacademic review and discovery.",
            "author": [
                "Hassen Saidi",
                "Susmit Jha",
                "Tuhin Sahai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17064v1",
                "http://arxiv.org/pdf/2310.17064v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17063v1",
            "title": "Coreset Markov Chain Monte Carlo",
            "updated": "2023-10-25T23:53:27Z",
            "published": "2023-10-25T23:53:27Z",
            "summary": "A Bayesian coreset is a small, weighted subset of data that replaces the full\ndataset during inference in order to reduce computational cost. However, state\nof the art methods for tuning coreset weights are expensive, require nontrivial\nuser input, and impose constraints on the model. In this work, we propose a new\nmethod -- Coreset MCMC -- that simulates a Markov chain targeting the coreset\nposterior, while simultaneously updating the coreset weights using those same\ndraws. Coreset MCMC is simple to implement and tune, and can be used with any\nexisting MCMC kernel. We analyze Coreset MCMC in a representative setting to\nobtain key insights about the convergence behaviour of the method. Empirical\nresults demonstrate that Coreset MCMC provides higher quality posterior\napproximations and reduced computational cost compared with other coreset\nconstruction methods. Further, compared with other general subsampling MCMC\nmethods, we find that Coreset MCMC has a higher sampling efficiency with\ncompetitively accurate posterior approximations.",
            "author": [
                "Naitong Chen",
                "Trevor Campbell"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17063v1",
                "http://arxiv.org/pdf/2310.17063v1"
            ],
            "primary_category": "stat.CO",
            "category": [
                "stat.CO",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17060v1",
            "title": "Aplicacion de Robots Humanoides como Guias Interactivos en Museos: Una\n  Simulacion con el Robot NAO",
            "updated": "2023-10-25T23:44:09Z",
            "published": "2023-10-25T23:44:09Z",
            "summary": "This article presents an application that evaluates the feasibility of\nhumanoid robots as interactive guides in art museums. The application entailes\nprogramming a NAO robot and a chatbot to provide information about art pieces\nin a simulated museum environment. In this controlled scenario, the learning\nemployees interact with the robot and the chatbot. The result is a skilled\nparticipation in the interactions, along with the effectiveness of the robot\nand chatbot that communicates the basic details of the art objects. You see\nnatural and fluid interactions between the students and the robot. This\nsuggests that the addition of humanoid robots to museums may provide a better\nexperience for visitors, but also the need to continue to do more to optimize\nthe quality of interaction. This study contributes to understanding the\npossibilities and requirements of applying humanoid technologies in a cultural\ncontext.",
            "author": [
                "Hiago Sodre",
                "Pablo Moraes",
                "Monica Rodriguez",
                "Victor Castelli",
                "Pamela Barboza",
                "Martin Mattos",
                "Guillermo Vivas",
                "Bruna de Vargas",
                "Tobias D\u00f6rnbach",
                "Ricardo Grando"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17060v1",
                "http://arxiv.org/pdf/2310.17060v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17056v1",
            "title": "Strategizing EV Charging and Renewable Integration in Texas",
            "updated": "2023-10-25T23:34:25Z",
            "published": "2023-10-25T23:34:25Z",
            "summary": "Exploring the convergence of electric vehicles (EVs), renewable energy, and\nsmart grid technologies in the context of Texas, this study addresses\nchallenges hindering the widespread adoption of EVs. Acknowledging their\nenvironmental benefits, the research focuses on grid stability concerns,\nuncoordinated charging patterns, and the complicated relationship between EVs\nand renewable energy sources. Dynamic time warping (DTW) clustering and k-means\nclustering methodologies categorize days based on total load and net load,\noffering nuanced insights into daily electricity consumption and renewable\nenergy generation patterns. By establishing optimal charging and\nvehicle-to-grid (V2G) windows tailored to specific load characteristics, the\nstudy provides a sophisticated methodology for strategic decision-making in\nenergy consumption and renewable integration. The findings contribute to the\nongoing discourse on achieving a sustainable and resilient energy future\nthrough the seamless integration of EVs into smart grids.",
            "author": [
                "Mohammad Mohammadi",
                "Jesse Thornburg"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17056v1",
                "http://arxiv.org/pdf/2310.17056v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17054v1",
            "title": "BOOST: Harnessing Black-Box Control to Boost Commonsense in LMs'\n  Generation",
            "updated": "2023-10-25T23:32:12Z",
            "published": "2023-10-25T23:32:12Z",
            "summary": "Large language models (LLMs) such as GPT-3 have demonstrated a strong\ncapability to generate coherent and contextually relevant text. However, amidst\ntheir successes, a crucial issue persists: their generated outputs still lack\ncommonsense at times. Moreover, fine-tuning the entire LLM towards more\ncommonsensical outputs is computationally expensive if not infeasible. In this\npaper, we present a computation-efficient framework that steers a frozen\nPre-Trained Language Model (PTLM) towards more commonsensical generation (i.e.,\nproducing a plausible output that incorporates a list of concepts in a\nmeaningful way). Specifically, we first construct a reference-free evaluator\nthat assigns a sentence with a commonsensical score by grounding the sentence\nto a dynamic commonsense knowledge base from four different relational aspects.\nWe then use the scorer as the oracle for commonsense knowledge, and extend the\ncontrollable generation method called NADO to train an auxiliary head that\nguides a fixed PTLM to better satisfy the oracle. We test our framework on a\nseries of GPT-2-, Flan-T5-, and Alpaca-based language models (LMs) on two\nconstrained concept-to-sentence benchmarks. Human evaluation results\ndemonstrate that our method consistently leads to the most commonsensical\noutputs.",
            "author": [
                "Yufei Tian",
                "Felix Zhang",
                "Nanyun Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17054v1",
                "http://arxiv.org/pdf/2310.17054v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17050v1",
            "title": "Exploring Question Decomposition for Zero-Shot VQA",
            "updated": "2023-10-25T23:23:57Z",
            "published": "2023-10-25T23:23:57Z",
            "summary": "Visual question answering (VQA) has traditionally been treated as a\nsingle-step task where each question receives the same amount of effort, unlike\nnatural human question-answering strategies. We explore a question\ndecomposition strategy for VQA to overcome this limitation. We probe the\nability of recently developed large vision-language models to use human-written\ndecompositions and produce their own decompositions of visual questions,\nfinding they are capable of learning both tasks from demonstrations alone.\nHowever, we show that naive application of model-written decompositions can\nhurt performance. We introduce a model-driven selective decomposition approach\nfor second-guessing predictions and correcting errors, and validate its\neffectiveness on eight VQA tasks across three domains, showing consistent\nimprovements in accuracy, including improvements of >20% on medical VQA\ndatasets and boosting the zero-shot performance of BLIP-2 above chance on a VQA\nreformulation of the challenging Winoground task. Project Site:\nhttps://zaidkhan.me/decomposition-0shot-vqa/",
            "author": [
                "Zaid Khan",
                "Vijay Kumar BG",
                "Samuel Schulter",
                "Manmohan Chandraker",
                "Yun Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17050v1",
                "http://arxiv.org/pdf/2310.17050v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17675v1",
            "title": "Early Detection of Tuberculosis with Machine Learning Cough Audio\n  Analysis: Towards More Accessible Global Triaging Usage",
            "updated": "2023-10-25T23:22:20Z",
            "published": "2023-10-25T23:22:20Z",
            "summary": "Tuberculosis (TB), a bacterial disease mainly affecting the lungs, is one of\nthe leading infectious causes of mortality worldwide. To prevent TB from\nspreading within the body, which causes life-threatening complications, timely\nand effective anti-TB treatment is crucial. Cough, an objective biomarker for\nTB, is a triage tool that monitors treatment response and regresses with\nsuccessful therapy. Current gold standards for TB diagnosis are slow or\ninaccessible, especially in rural areas where TB is most prevalent. In\naddition, current machine learning (ML) diagnosis research, like utilizing\nchest radiographs, is ineffective and does not monitor treatment progression.\nTo enable effective diagnosis, an ensemble model was developed that analyzes,\nusing a novel ML architecture, coughs' acoustic epidemiologies from\nsmartphones' microphones to detect TB. The architecture includes a 2D-CNN and\nXGBoost that was trained on 724,964 cough audio samples and demographics from 7\ncountries. After feature extraction (Mel-spectrograms) and data augmentation\n(IR-convolution), the model achieved AUROC (area under the receiving operator\ncharacteristic) of 88%, surpassing WHO's requirements for screening tests. The\nresults are available within 15 seconds and can easily be accessible via a\nmobile app. This research helps to improve TB diagnosis through a promising\naccurate, quick, and accessible triaging tool.",
            "author": [
                "Chandra Suda"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17675v1",
                "http://arxiv.org/pdf/2310.17675v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.LG",
                "cs.SD",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17049v1",
            "title": "Learning Repeatable Speech Embeddings Using An Intra-class Correlation\n  Regularizer",
            "updated": "2023-10-25T23:21:46Z",
            "published": "2023-10-25T23:21:46Z",
            "summary": "A good supervised embedding for a specific machine learning task is only\nsensitive to changes in the label of interest and is invariant to other\nconfounding factors. We leverage the concept of repeatability from measurement\ntheory to describe this property and propose to use the intra-class correlation\ncoefficient (ICC) to evaluate the repeatability of embeddings. We then propose\na novel regularizer, the ICC regularizer, as a complementary component for\ncontrastive losses to guide deep neural networks to produce embeddings with\nhigher repeatability. We use simulated data to explain why the ICC regularizer\nworks better on minimizing the intra-class variance than the contrastive loss\nalone. We implement the ICC regularizer and apply it to three speech tasks:\nspeaker verification, voice style conversion, and a clinical application for\ndetecting dysphonic voice. The experimental results demonstrate that adding an\nICC regularizer can improve the repeatability of learned embeddings compared to\nonly using the contrastive loss; further, these embeddings lead to improved\nperformance in these downstream tasks.",
            "author": [
                "Jianwei Zhang",
                "Suren Jayasuriya",
                "Visar Berisha"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17049v1",
                "http://arxiv.org/pdf/2310.17049v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.AI",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17044v1",
            "title": "Learning to Rank for Active Learning via Multi-Task Bilevel Optimization",
            "updated": "2023-10-25T22:50:09Z",
            "published": "2023-10-25T22:50:09Z",
            "summary": "Active learning is a promising paradigm to reduce the labeling cost by\nstrategically requesting labels to improve model performance. However, existing\nactive learning methods often rely on expensive acquisition function to\ncompute, extensive modeling retraining and multiple rounds of interaction with\nannotators. To address these limitations, we propose a novel approach for\nactive learning, which aims to select batches of unlabeled instances through a\nlearned surrogate model for data acquisition. A key challenge in this approach\nis developing an acquisition function that generalizes well, as the history of\ndata, which forms part of the utility function's input, grows over time. Our\nnovel algorithmic contribution is a bilevel multi-task bilevel optimization\nframework that predicts the relative utility -- measured by the validation\naccuracy -- of different training sets, and ensures the learned acquisition\nfunction generalizes effectively. For cases where validation accuracy is\nexpensive to evaluate, we introduce efficient interpolation-based surrogate\nmodels to estimate the utility function, reducing the evaluation cost. We\ndemonstrate the performance of our approach through extensive experiments on\nstandard active classification benchmarks. By employing our learned utility\nfunction, we show significant improvements over traditional techniques, paving\nthe way for more efficient and effective utility maximization in active\nlearning applications.",
            "author": [
                "Zixin Ding",
                "Si Chen",
                "Ruoxi Jia",
                "Yuxin Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17044v1",
                "http://arxiv.org/pdf/2310.17044v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17042v1",
            "title": "StochGradAdam: Accelerating Neural Networks Training with Stochastic\n  Gradient Sampling",
            "updated": "2023-10-25T22:45:31Z",
            "published": "2023-10-25T22:45:31Z",
            "summary": "In the rapidly advancing domain of deep learning optimization, this paper\nunveils the StochGradAdam optimizer, a novel adaptation of the well-regarded\nAdam algorithm. Central to StochGradAdam is its gradient sampling technique.\nThis method not only ensures stable convergence but also leverages the\nadvantages of selective gradient consideration, fostering robust training by\npotentially mitigating the effects of noisy or outlier data and enhancing the\nexploration of the loss landscape for more dependable convergence. In both\nimage classification and segmentation tasks, StochGradAdam has demonstrated\nsuperior performance compared to the traditional Adam optimizer. By judiciously\nsampling a subset of gradients at each iteration, the optimizer is optimized\nfor managing intricate models. The paper provides a comprehensive exploration\nof StochGradAdam's methodology, from its mathematical foundations to bias\ncorrection strategies, heralding a promising advancement in deep learning\ntraining techniques.",
            "author": [
                "Juyoung Yun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17042v1",
                "http://arxiv.org/pdf/2310.17042v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17037v1",
            "title": "Event-by-event Comparison between Machine-Learning- and\n  Transfer-Matrix-based Unfolding Methods",
            "updated": "2023-10-25T22:28:04Z",
            "published": "2023-10-25T22:28:04Z",
            "summary": "The unfolding of detector effects is a key aspect of comparing experimental\ndata with theoretical predictions. In recent years, different Machine-Learning\nmethods have been developed to provide novel features, e.g. high dimensionality\nor a probabilistic single-event unfolding based on generative neural networks.\nTraditionally, many analyses unfold detector effects using\ntransfer-matrix--based algorithms, which are well established in\nlow-dimensional unfolding. They yield an unfolded distribution of the total\nspectrum, together with its covariance matrix. This paper proposes a method to\nobtain probabilistic single-event unfolded distributions, together with their\nuncertainties and correlations, for the transfer-matrix--based unfolding. The\nalgorithm is first validated on a toy model and then applied to pseudo-data for\nthe $pp\\rightarrow Z\\gamma \\gamma$ process. In both examples the performance is\ncompared to the single-event unfolding of the Machine-Learning--based Iterative\ncINN unfolding (IcINN).",
            "author": [
                "Mathias Backes",
                "Anja Butter",
                "Monica Dunford",
                "Bogdan Malaescu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17037v1",
                "http://arxiv.org/pdf/2310.17037v1"
            ],
            "primary_category": "physics.data-an",
            "category": [
                "physics.data-an",
                "hep-ex",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17032v1",
            "title": "Quantum Long Short-Term Memory (QLSTM) vs Classical LSTM in Time Series\n  Forecasting: A Comparative Study in Solar Power Forecasting",
            "updated": "2023-10-25T22:19:05Z",
            "published": "2023-10-25T22:19:05Z",
            "summary": "Accurately forecasting solar power generation is crucial in the global\nprogression towards sustainable energy systems. In this study, we conduct a\nmeticulous comparison between Quantum Long Short-Term Memory (QLSTM) and\nclassical Long Short-Term Memory (LSTM) models for solar power production\nforecasting. Our controlled experiments reveal promising advantages of QLSTMs,\nincluding accelerated training convergence and substantially reduced test loss\nwithin the initial epoch compared to classical LSTMs. These empirical findings\ndemonstrate QLSTM's potential to swiftly assimilate complex time series\nrelationships, enabled by quantum phenomena like superposition. However,\nrealizing QLSTM's full capabilities necessitates further research into model\nvalidation across diverse conditions, systematic hyperparameter optimization,\nhardware noise resilience, and applications to correlated renewable forecasting\nproblems. With continued progress, quantum machine learning can offer a\nparadigm shift in renewable energy time series prediction. This pioneering work\nprovides initial evidence substantiating quantum advantages over classical\nLSTM, while acknowledging present limitations. Through rigorous benchmarking\ngrounded in real-world data, our study elucidates a promising trajectory for\nquantum learning in renewable forecasting. Additional research and development\ncan further actualize this potential to achieve unprecedented accuracy and\nreliability in predicting solar power generation worldwide.",
            "author": [
                "Saad Zafar Khan",
                "Nazeefa Muzammil",
                "Syed Mohammad Hassan Zaidi",
                "Abdulah Jeza Aljohani",
                "Haibat Khan",
                "Salman Ghafoor"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17032v1",
                "http://arxiv.org/pdf/2310.17032v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17029v1",
            "title": "Toward the use of proxies for efficient learning manipulation and\n  locomotion strategies on soft robots",
            "updated": "2023-10-25T22:12:58Z",
            "published": "2023-10-25T22:12:58Z",
            "summary": "Soft robots are naturally designed to perform safe interactions with their\nenvironment, like locomotion and manipulation. In the literature, there are now\nmany concepts, often bio-inspired, to propose new modes of locomotion or\ngrasping. However, a methodology for implementing motion planning of these\ntasks, as exists for rigid robots, is still lacking. One of the difficulties\ncomes from the modeling of these robots, which is very different, as it is\nbased on the mechanics of deformable bodies. These models, whose dimension is\noften very large, make learning and optimization methods very costly. In this\npaper, we propose a proxy approach, as exists for humanoid robotics. This proxy\nis a simplified model of the robot that enables frugal learning of a motion\nstrategy. This strategy is then transferred to the complete model to obtain the\ncorresponding actuation inputs. Our methodology is illustrated and analyzed on\ntwo classical designs of soft robots doing manipulation and locomotion tasks.",
            "author": [
                "Etienne M\u00e9nager",
                "Quentin Peyron",
                "Christian Duriez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17029v1",
                "http://arxiv.org/pdf/2310.17029v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17023v1",
            "title": "On the Identifiability and Interpretability of Gaussian Process Models",
            "updated": "2023-10-25T22:00:29Z",
            "published": "2023-10-25T22:00:29Z",
            "summary": "In this paper, we critically examine the prevalent practice of using additive\nmixtures of Mat\\'ern kernels in single-output Gaussian process (GP) models and\nexplore the properties of multiplicative mixtures of Mat\\'ern kernels for\nmulti-output GP models. For the single-output case, we derive a series of\ntheoretical results showing that the smoothness of a mixture of Mat\\'ern\nkernels is determined by the least smooth component and that a GP with such a\nkernel is effectively equivalent to the least smooth kernel component.\nFurthermore, we demonstrate that none of the mixing weights or parameters\nwithin individual kernel components are identifiable. We then turn our\nattention to multi-output GP models and analyze the identifiability of the\ncovariance matrix $A$ in the multiplicative kernel $K(x,y) = AK_0(x,y)$, where\n$K_0$ is a standard single output kernel such as Mat\\'ern. We show that $A$ is\nidentifiable up to a multiplicative constant, suggesting that multiplicative\nmixtures are well suited for multi-output tasks. Our findings are supported by\nextensive simulations and real applications for both single- and multi-output\nsettings. This work provides insight into kernel selection and interpretation\nfor GP models, emphasizing the importance of choosing appropriate kernel\nstructures for different tasks.",
            "author": [
                "Jiawen Chen",
                "Wancen Mu",
                "Yun Li",
                "Didong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17023v1",
                "http://arxiv.org/pdf/2310.17023v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "62M30"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17022v1",
            "title": "Controlled Decoding from Language Models",
            "updated": "2023-10-25T22:00:05Z",
            "published": "2023-10-25T22:00:05Z",
            "summary": "We propose controlled decoding (CD), a novel off-policy reinforcement\nlearning method to control the autoregressive generation from language models\ntowards high reward outcomes. CD solves an off-policy reinforcement learning\nproblem through a value function for the reward, which we call a prefix scorer.\nThe prefix scorer is used at inference time to steer the generation towards\nhigher reward outcomes. We show that the prefix scorer may be trained on\n(possibly) off-policy data to predict the expected reward when decoding is\ncontinued from a partially decoded response. We empirically demonstrate that CD\nis effective as a control mechanism on Reddit conversations corpus. We also\nshow that the modularity of the design of CD makes it possible to control for\nmultiple rewards, effectively solving a multi-objective reinforcement learning\nproblem with no additional complexity. Finally, we show that CD can be applied\nin a novel blockwise fashion at inference-time, again without the need for any\ntraining-time changes, essentially bridging the gap between the popular\nbest-of-$K$ strategy and token-level reinforcement learning. This makes CD a\npromising approach for alignment of language models.",
            "author": [
                "Sidharth Mudgal",
                "Jong Lee",
                "Harish Ganapathy",
                "YaGuang Li",
                "Tao Wang",
                "Yanping Huang",
                "Zhifeng Chen",
                "Heng-Tze Cheng",
                "Michael Collins",
                "Trevor Strohman",
                "Jilin Chen",
                "Alex Beutel",
                "Ahmad Beirami"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17022v1",
                "http://arxiv.org/pdf/2310.17022v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17021v2",
            "title": "Streaming Factor Trajectory Learning for Temporal Tensor Decomposition",
            "updated": "2023-11-07T23:05:42Z",
            "published": "2023-10-25T21:58:52Z",
            "summary": "Practical tensor data is often along with time information. Most existing\ntemporal decomposition approaches estimate a set of fixed factors for the\nobjects in each tensor mode, and hence cannot capture the temporal evolution of\nthe objects' representation. More important, we lack an effective approach to\ncapture such evolution from streaming data, which is common in real-world\napplications. To address these issues, we propose Streaming Factor Trajectory\nLearning for temporal tensor decomposition. We use Gaussian processes (GPs) to\nmodel the trajectory of factors so as to flexibly estimate their temporal\nevolution. To address the computational challenges in handling streaming data,\nwe convert the GPs into a state-space prior by constructing an equivalent\nstochastic differential equation (SDE). We develop an efficient online\nfiltering algorithm to estimate a decoupled running posterior of the involved\nfactor states upon receiving new data. The decoupled estimation enables us to\nconduct standard Rauch-Tung-Striebel smoothing to compute the full posterior of\nall the trajectories in parallel, without the need for revisiting any previous\ndata. We have shown the advantage of SFTL in both synthetic tasks and\nreal-world applications. The code is available at\n{https://github.com/xuangu-fang/Streaming-Factor-Trajectory-Learning}.",
            "author": [
                "Shikai Fang",
                "Xin Yu",
                "Shibo Li",
                "Zheng Wang",
                "Robert Kirby",
                "Shandian Zhe"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17021v2",
                "http://arxiv.org/pdf/2310.17021v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17019v1",
            "title": "Conditionally Combining Robot Skills using Large Language Models",
            "updated": "2023-10-25T21:46:34Z",
            "published": "2023-10-25T21:46:34Z",
            "summary": "This paper combines two contributions. First, we introduce an extension of\nthe Meta-World benchmark, which we call \"Language-World,\" which allows a large\nlanguage model to operate in a simulated robotic environment using\nsemi-structured natural language queries and scripted skills described using\nnatural language. By using the same set of tasks as Meta-World, Language-World\nresults can be easily compared to Meta-World results, allowing for a point of\ncomparison between recent methods using Large Language Models (LLMs) and those\nusing Deep Reinforcement Learning. Second, we introduce a method we call Plan\nConditioned Behavioral Cloning (PCBC), that allows finetuning the behavior of\nhigh-level plans using end-to-end demonstrations. Using Language-World, we show\nthat PCBC is able to achieve strong performance in a variety of few-shot\nregimes, often achieving task generalization with as little as a single\ndemonstration. We have made Language-World available as open-source software at\nhttps://github.com/krzentner/language-world/.",
            "author": [
                "K. R. Zentner",
                "Ryan Julian",
                "Brian Ichter",
                "Gaurav S. Sukhatme"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17019v1",
                "http://arxiv.org/pdf/2310.17019v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17015v3",
            "title": "Data Augmentation for Emotion Detection in Small Imbalanced Text Data",
            "updated": "2023-10-30T13:33:16Z",
            "published": "2023-10-25T21:29:36Z",
            "summary": "Emotion recognition in text, the task of identifying emotions such as joy or\nanger, is a challenging problem in NLP with many applications. One of the\nchallenges is the shortage of available datasets that have been annotated with\nemotions. Certain existing datasets are small, follow different emotion\ntaxonomies and display imbalance in their emotion distribution. In this work,\nwe studied the impact of data augmentation techniques precisely when applied to\nsmall imbalanced datasets, for which current state-of-the-art models (such as\nRoBERTa) under-perform. Specifically, we utilized four data augmentation\nmethods (Easy Data Augmentation EDA, static and contextual Embedding-based, and\nProtAugment) on three datasets that come from different sources and vary in\nsize, emotion categories and distributions. Our experimental results show that\nusing the augmented data when training the classifier model leads to\nsignificant improvements. Finally, we conducted two case studies: a) directly\nusing the popular chat-GPT API to paraphrase text using different prompts, and\nb) using external data to augment the training set. Results show the promising\npotential of these methods.",
            "author": [
                "Anna Koufakou",
                "Diego Grisales",
                "Ragy Costa de jesus",
                "Oscar Fox"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17015v3",
                "http://arxiv.org/pdf/2310.17015v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17010v1",
            "title": "This Reads Like That: Deep Learning for Interpretable Natural Language\n  Processing",
            "updated": "2023-10-25T21:18:35Z",
            "published": "2023-10-25T21:18:35Z",
            "summary": "Prototype learning, a popular machine learning method designed for inherently\ninterpretable decisions, leverages similarities to learned prototypes for\nclassifying new data. While it is mainly applied in computer vision, in this\nwork, we build upon prior research and further explore the extension of\nprototypical networks to natural language processing. We introduce a learned\nweighted similarity measure that enhances the similarity computation by\nfocusing on informative dimensions of pre-trained sentence embeddings.\nAdditionally, we propose a post-hoc explainability mechanism that extracts\nprediction-relevant words from both the prototype and input sentences. Finally,\nwe empirically demonstrate that our proposed method not only improves\npredictive performance on the AG News and RT Polarity datasets over a previous\nprototype-based approach, but also improves the faithfulness of explanations\ncompared to rationale-based recurrent convolutions.",
            "author": [
                "Claudio Fanconi",
                "Moritz Vandenhirtz",
                "Severin Husmann",
                "Julia E. Vogt"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17010v1",
                "http://arxiv.org/pdf/2310.17010v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17009v1",
            "title": "Simulation based stacking",
            "updated": "2023-10-25T21:17:12Z",
            "published": "2023-10-25T21:17:12Z",
            "summary": "Simulation-based inference has been popular for amortized Bayesian\ncomputation. It is typical to have more than one posterior approximation, from\ndifferent inference algorithms, different architectures, or simply the\nrandomness of initialization and stochastic gradients. With a provable\nasymptotic guarantee, we present a general stacking framework to make use of\nall available posterior approximations. Our stacking method is able to combine\ndensities, simulation draws, confidence intervals, and moments, and address the\noverall precision, calibration, coverage, and bias at the same time. We\nillustrate our method on several benchmark simulations and a challenging\ncosmological inference task.",
            "author": [
                "Yuling Yao",
                "Bruno R\u00e9galdo-Saint Blancard",
                "Justin Domke"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17009v1",
                "http://arxiv.org/pdf/2310.17009v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17006v1",
            "title": "Mode Selection and Target Classification in Cognitive Radar Networks",
            "updated": "2023-10-25T21:08:13Z",
            "published": "2023-10-25T21:08:13Z",
            "summary": "Cognitive Radar Networks were proposed by Simon Haykin in 2006 to address\nproblems with large legacy radar implementations - primarily, single-point\nvulnerabilities and lack of adaptability. This work proposes to leverage the\nadaptability of cognitive radar networks to trade between active radar\nobservation, which uses high power and risks interception, and passive signal\nparameter estimation, which uses target emissions to gain side information and\nlower the power necessary to accurately track multiple targets. The goal of the\nnetwork is to learn over many target tracks both the characteristics of the\ntargets as well as the optimal action choices for each type of target. In order\nto select between the available actions, we utilize a multi-armed bandit model,\nusing current class information as prior information. When the active radar\naction is selected, the node estimates the physical behavior of targets through\nthe radar emissions. When the passive action is selected, the node estimates\nthe radio behavior of targets through passive sensing. Over many target tracks,\nthe network collects the observed behavior of targets and forms clusters of\nsimilarly-behaved targets. In this way, the network meta-learns the target\nclass distributions while learning the optimal mode selections for each target\nclass.",
            "author": [
                "William W. Howard",
                "Samuel R. Shebert",
                "Benjamin H. Kirk",
                "R. Michael Buehrer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17006v1",
                "http://arxiv.org/pdf/2310.17006v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12862v1",
            "title": "TorchSparse++: Efficient Training and Inference Framework for Sparse\n  Convolution on GPUs",
            "updated": "2023-10-25T21:02:38Z",
            "published": "2023-10-25T21:02:38Z",
            "summary": "Sparse convolution plays a pivotal role in emerging workloads, including\npoint cloud processing in AR/VR, autonomous driving, and graph understanding in\nrecommendation systems. Since the computation pattern is sparse and irregular,\nspecialized high-performance kernels are required. Existing GPU libraries offer\ntwo dataflow types for sparse convolution. The gather-GEMM-scatter dataflow is\neasy to implement but not optimal in performance, while the dataflows with\noverlapped computation and memory access (e.g.implicit GEMM) are highly\nperformant but have very high engineering costs. In this paper, we introduce\nTorchSparse++, a new GPU library that achieves the best of both worlds. We\ncreate a highly efficient Sparse Kernel Generator that generates performant\nsparse convolution kernels at less than one-tenth of the engineering cost of\nthe current state-of-the-art system. On top of this, we design the Sparse\nAutotuner, which extends the design space of existing sparse convolution\nlibraries and searches for the best dataflow configurations for training and\ninference workloads. Consequently, TorchSparse++ achieves 2.9x, 3.3x, 2.2x and\n1.7x measured end-to-end speedup on an NVIDIA A100 GPU over state-of-the-art\nMinkowskiEngine, SpConv 1.2, TorchSparse and SpConv v2 in inference; and is\n1.2-1.3x faster than SpConv v2 in mixed precision training across seven\nrepresentative autonomous driving benchmarks. It also seamlessly supports graph\nconvolutions, achieving 2.6-7.6x faster inference speed compared with\nstate-of-the-art graph deep learning libraries.",
            "author": [
                "Haotian Tang",
                "Shang Yang",
                "Zhijian Liu",
                "Ke Hong",
                "Zhongming Yu",
                "Xiuyu Li",
                "Guohao Dai",
                "Yu Wang",
                "Song Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12862v1",
                "http://arxiv.org/pdf/2311.12862v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.CV",
                "cs.LG",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17002v1",
            "title": "Faster Recalibration of an Online Predictor via Approachability",
            "updated": "2023-10-25T20:59:48Z",
            "published": "2023-10-25T20:59:48Z",
            "summary": "Predictive models in ML need to be trustworthy and reliable, which often at\nthe very least means outputting calibrated probabilities. This can be\nparticularly difficult to guarantee in the online prediction setting when the\noutcome sequence can be generated adversarially. In this paper we introduce a\ntechnique using Blackwell's approachability theorem for taking an online\npredictive model which might not be calibrated and transforming its predictions\nto calibrated predictions without much increase to the loss of the original\nmodel. Our proposed algorithm achieves calibration and accuracy at a faster\nrate than existing techniques arXiv:1607.03594 and is the first algorithm to\noffer a flexible tradeoff between calibration error and accuracy in the online\nsetting. We demonstrate this by characterizing the space of jointly achievable\ncalibration and regret using our technique.",
            "author": [
                "Princewill Okoroafor",
                "Robert Kleinberg",
                "Wen Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17002v1",
                "http://arxiv.org/pdf/2310.17002v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16999v2",
            "title": "Trust, but Verify: Robust Image Segmentation using Deep Learning",
            "updated": "2023-10-29T04:09:48Z",
            "published": "2023-10-25T20:55:07Z",
            "summary": "We describe a method for verifying the output of a deep neural network for\nmedical image segmentation that is robust to several classes of random as well\nas worst-case perturbations i.e. adversarial attacks. This method is based on a\ngeneral approach recently developed by the authors called \"Trust, but Verify\"\nwherein an auxiliary verification network produces predictions about certain\nmasked features in the input image using the segmentation as an input. A\nwell-designed auxiliary network will produce high-quality predictions when the\ninput segmentations are accurate, but will produce low-quality predictions when\nthe segmentations are incorrect. Checking the predictions of such a network\nwith the original image allows us to detect bad segmentations. However, to\nensure the verification method is truly robust, we need a method for checking\nthe quality of the predictions that does not itself rely on a black-box neural\nnetwork. Indeed, we show that previous methods for segmentation evaluation that\ndo use deep neural regression networks are vulnerable to false negatives i.e.\ncan inaccurately label bad segmentations as good. We describe the design of a\nverification network that avoids such vulnerability and present results to\ndemonstrate its robustness compared to previous methods.",
            "author": [
                "Fahim Ahmed Zaman",
                "Xiaodong Wu",
                "Weiyu Xu",
                "Milan Sonka",
                "Raghuraman Mudumbai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16999v2",
                "http://arxiv.org/pdf/2310.16999v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16996v1",
            "title": "Towards Continually Learning Application Performance Models",
            "updated": "2023-10-25T20:48:46Z",
            "published": "2023-10-25T20:48:46Z",
            "summary": "Machine learning-based performance models are increasingly being used to\nbuild critical job scheduling and application optimization decisions.\nTraditionally, these models assume that data distribution does not change as\nmore samples are collected over time. However, owing to the complexity and\nheterogeneity of production HPC systems, they are susceptible to hardware\ndegradation, replacement, and/or software patches, which can lead to drift in\nthe data distribution that can adversely affect the performance models. To this\nend, we develop continually learning performance models that account for the\ndistribution drift, alleviate catastrophic forgetting, and improve\ngeneralizability. Our best model was able to retain accuracy, regardless of\nhaving to learn the new distribution of data inflicted by system changes, while\ndemonstrating a 2x improvement in the prediction accuracy of the whole data\nsequence in comparison to the naive approach.",
            "author": [
                "Ray A. O. Sinurat",
                "Anurag Daram",
                "Haryadi S. Gunawi",
                "Robert B. Ross",
                "Sandeep Madireddy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16996v1",
                "http://arxiv.org/pdf/2310.16996v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16995v1",
            "title": "Quality > Quantity: Synthetic Corpora from Foundation Models for\n  Closed-Domain Extractive Question Answering",
            "updated": "2023-10-25T20:48:16Z",
            "published": "2023-10-25T20:48:16Z",
            "summary": "Domain adaptation, the process of training a model in one domain and applying\nit to another, has been extensively explored in machine learning. While\ntraining a domain-specific foundation model (FM) from scratch is an option,\nrecent methods have focused on adapting pre-trained FMs for domain-specific\ntasks. However, our experiments reveal that either approach does not\nconsistently achieve state-of-the-art (SOTA) results in the target domain. In\nthis work, we study extractive question answering within closed domains and\nintroduce the concept of targeted pre-training. This involves determining and\ngenerating relevant data to further pre-train our models, as opposed to the\nconventional philosophy of utilizing domain-specific FMs trained on a wide\nrange of data. Our proposed framework uses Galactica to generate synthetic,\n``targeted'' corpora that align with specific writing styles and topics, such\nas research papers and radiology reports. This process can be viewed as a form\nof knowledge distillation. We apply our method to two biomedical extractive\nquestion answering datasets, COVID-QA and RadQA, achieving a new benchmark on\nthe former and demonstrating overall improvements on the latter. Code available\nat https://github.com/saptarshi059/CDQA-v1-Targetted-PreTraining/tree/main.",
            "author": [
                "Saptarshi Sengupta",
                "Connor Heaton",
                "Shreya Ghosh",
                "Preslav Nakov",
                "Prasenjit Mitra"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16995v1",
                "http://arxiv.org/pdf/2310.16995v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16992v1",
            "title": "How well can machine-generated texts be identified and can language\n  models be trained to avoid identification?",
            "updated": "2023-10-25T20:43:07Z",
            "published": "2023-10-25T20:43:07Z",
            "summary": "With the rise of generative pre-trained transformer models such as GPT-3,\nGPT-NeoX, or OPT, distinguishing human-generated texts from machine-generated\nones has become important. We refined five separate language models to generate\nsynthetic tweets, uncovering that shallow learning classification algorithms,\nlike Naive Bayes, achieve detection accuracy between 0.6 and 0.8.\n  Shallow learning classifiers differ from human-based detection, especially\nwhen using higher temperature values during text generation, resulting in a\nlower detection rate. Humans prioritize linguistic acceptability, which tends\nto be higher at lower temperature values. In contrast, transformer-based\nclassifiers have an accuracy of 0.9 and above. We found that using a\nreinforcement learning approach to refine our generative models can\nsuccessfully evade BERT-based classifiers with a detection accuracy of 0.15 or\nless.",
            "author": [
                "Sinclair Schneider",
                "Florian Steuber",
                "Joao A. G. Schneider",
                "Gabi Dreo Rodosek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16992v1",
                "http://arxiv.org/pdf/2310.16992v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16991v1",
            "title": "An Efficient Deep Learning-based approach for Recognizing Agricultural\n  Pests in the Wild",
            "updated": "2023-10-25T20:42:20Z",
            "published": "2023-10-25T20:42:20Z",
            "summary": "One of the biggest challenges that the farmers go through is to fight insect\npests during agricultural product yields. The problem can be solved easily and\navoid economic losses by taking timely preventive measures. This requires\nidentifying insect pests in an easy and effective manner. Most of the insect\nspecies have similarities between them. Without proper help from the\nagriculturist academician it is very challenging for the farmers to identify\nthe crop pests accurately. To address this issue we have done extensive\nexperiments considering different methods to find out the best method among\nall. This paper presents a detailed overview of the experiments done on mainly\na robust dataset named IP102 including transfer learning with finetuning,\nattention mechanism and custom architecture. Some example from another dataset\nD0 is also shown to show robustness of our experimented techniques.",
            "author": [
                "Mohtasim Hadi Rafi",
                "Mohammad Ratul Mahjabin",
                "Md Sabbir Rahman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16991v1",
                "http://arxiv.org/pdf/2310.16991v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16990v1",
            "title": "STEER: Semantic Turn Extension-Expansion Recognition for Voice\n  Assistants",
            "updated": "2023-10-25T20:41:30Z",
            "published": "2023-10-25T20:41:30Z",
            "summary": "In the context of a voice assistant system, steering refers to the phenomenon\nin which a user issues a follow-up command attempting to direct or clarify a\nprevious turn. We propose STEER, a steering detection model that predicts\nwhether a follow-up turn is a user's attempt to steer the previous command.\nConstructing a training dataset for steering use cases poses challenges due to\nthe cold-start problem. To overcome this, we developed heuristic rules to\nsample opt-in usage data, approximating positive and negative samples without\nany annotation. Our experimental results show promising performance in\nidentifying steering intent, with over 95% accuracy on our sampled data.\nMoreover, STEER, in conjunction with our sampling strategy, aligns effectively\nwith real-world steering scenarios, as evidenced by its strong zero-shot\nperformance on a human-graded evaluation set. In addition to relying solely on\nuser transcripts as input, we introduce STEER+, an enhanced version of the\nmodel. STEER+ utilizes a semantic parse tree to provide more context on\nout-of-vocabulary words, such as named entities that often occur at the\nsentence boundary. This further improves model performance, reducing error rate\nin domains where entities frequently appear, such as messaging. Lastly, we\npresent a data analysis that highlights the improvement in user experience when\nvoice assistants support steering use cases.",
            "author": [
                "Leon Liyang Zhang",
                "Jiarui Lu",
                "Joel Ruben Antony Moniz",
                "Aditya Kulkarni",
                "Dhivya Piraviperumal",
                "Tien Dung Tran",
                "Nicholas Tzou",
                "Hong Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16990v1",
                "http://arxiv.org/pdf/2310.16990v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16986v1",
            "title": "Probabilistic Integral Circuits",
            "updated": "2023-10-25T20:38:18Z",
            "published": "2023-10-25T20:38:18Z",
            "summary": "Continuous latent variables (LVs) are a key ingredient of many generative\nmodels, as they allow modelling expressive mixtures with an uncountable number\nof components. In contrast, probabilistic circuits (PCs) are hierarchical\ndiscrete mixtures represented as computational graphs composed of input, sum\nand product units. Unlike continuous LV models, PCs provide tractable inference\nbut are limited to discrete LVs with categorical (i.e. unordered) states. We\nbridge these model classes by introducing probabilistic integral circuits\n(PICs), a new language of computational graphs that extends PCs with integral\nunits representing continuous LVs. In the first place, PICs are symbolic\ncomputational graphs and are fully tractable in simple cases where analytical\nintegration is possible. In practice, we parameterise PICs with light-weight\nneural nets delivering an intractable hierarchical continuous mixture that can\nbe approximated arbitrarily well with large PCs using numerical quadrature. On\nseveral distribution estimation benchmarks, we show that such PIC-approximating\nPCs systematically outperform PCs commonly learned via expectation-maximization\nor SGD.",
            "author": [
                "Gennaro Gala",
                "Cassio de Campos",
                "Robert Peharz",
                "Antonio Vergari",
                "Erik Quaeghebeur"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16986v1",
                "http://arxiv.org/pdf/2310.16986v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16981v1",
            "title": "Reimagining Synthetic Tabular Data Generation through Data-Centric AI: A\n  Comprehensive Benchmark",
            "updated": "2023-10-25T20:32:02Z",
            "published": "2023-10-25T20:32:02Z",
            "summary": "Synthetic data serves as an alternative in training machine learning models,\nparticularly when real-world data is limited or inaccessible. However, ensuring\nthat synthetic data mirrors the complex nuances of real-world data is a\nchallenging task. This paper addresses this issue by exploring the potential of\nintegrating data-centric AI techniques which profile the data to guide the\nsynthetic data generation process. Moreover, we shed light on the often ignored\nconsequences of neglecting these data profiles during synthetic data generation\n-- despite seemingly high statistical fidelity. Subsequently, we propose a\nnovel framework to evaluate the integration of data profiles to guide the\ncreation of more representative synthetic data. In an empirical study, we\nevaluate the performance of five state-of-the-art models for tabular data\ngeneration on eleven distinct tabular datasets. The findings offer critical\ninsights into the successes and limitations of current synthetic data\ngeneration techniques. Finally, we provide practical recommendations for\nintegrating data-centric insights into the synthetic data generation process,\nwith a specific focus on classification performance, model selection, and\nfeature selection. This study aims to reevaluate conventional approaches to\nsynthetic data generation and promote the application of data-centric AI\ntechniques in improving the quality and effectiveness of synthetic data.",
            "author": [
                "Lasse Hansen",
                "Nabeel Seedat",
                "Mihaela van der Schaar",
                "Andrija Petrovic"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16981v1",
                "http://arxiv.org/pdf/2310.16981v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16979v1",
            "title": "Unsupervised Domain Adaptation for Semantic Segmentation with Pseudo\n  Label Self-Refinement",
            "updated": "2023-10-25T20:31:07Z",
            "published": "2023-10-25T20:31:07Z",
            "summary": "Deep learning-based solutions for semantic segmentation suffer from\nsignificant performance degradation when tested on data with different\ncharacteristics than what was used during the training. Adapting the models\nusing annotated data from the new domain is not always practical. Unsupervised\nDomain Adaptation (UDA) approaches are crucial in deploying these models in the\nactual operating conditions. Recent state-of-the-art (SOTA) UDA methods employ\na teacher-student self-training approach, where a teacher model is used to\ngenerate pseudo-labels for the new data which in turn guide the training\nprocess of the student model. Though this approach has seen a lot of success,\nit suffers from the issue of noisy pseudo-labels being propagated in the\ntraining process. To address this issue, we propose an auxiliary pseudo-label\nrefinement network (PRN) for online refining of the pseudo labels and also\nlocalizing the pixels whose predicted labels are likely to be noisy. Being able\nto improve the quality of pseudo labels and select highly reliable ones, PRN\nhelps self-training of segmentation models to be robust against pseudo label\nnoise propagation during different stages of adaptation. We evaluate our\napproach on benchmark datasets with three different domain shifts, and our\napproach consistently performs significantly better than the previous\nstate-of-the-art methods.",
            "author": [
                "Xingchen Zhao",
                "Niluthpol Chowdhury Mithun",
                "Abhinav Rajvanshi",
                "Han-Pang Chiu",
                "Supun Samarasekera"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16979v1",
                "http://arxiv.org/pdf/2310.16979v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16978v1",
            "title": "The Significance of Machine Learning in Clinical Disease Diagnosis: A\n  Review",
            "updated": "2023-10-25T20:28:22Z",
            "published": "2023-10-25T20:28:22Z",
            "summary": "The global need for effective disease diagnosis remains substantial, given\nthe complexities of various disease mechanisms and diverse patient symptoms. To\ntackle these challenges, researchers, physicians, and patients are turning to\nmachine learning (ML), an artificial intelligence (AI) discipline, to develop\nsolutions. By leveraging sophisticated ML and AI methods, healthcare\nstakeholders gain enhanced diagnostic and treatment capabilities. However,\nthere is a scarcity of research focused on ML algorithms for enhancing the\naccuracy and computational efficiency. This research investigates the capacity\nof machine learning algorithms to improve the transmission of heart rate data\nin time series healthcare metrics, concentrating particularly on optimizing\naccuracy and efficiency. By exploring various ML algorithms used in healthcare\napplications, the review presents the latest trends and approaches in ML-based\ndisease diagnosis (MLBDD). The factors under consideration include the\nalgorithm utilized, the types of diseases targeted, the data types employed,\nthe applications, and the evaluation metrics. This review aims to shed light on\nthe prospects of ML in healthcare, particularly in disease diagnosis. By\nanalyzing the current literature, the study provides insights into\nstate-of-the-art methodologies and their performance metrics.",
            "author": [
                "S M Atikur Rahman",
                "Sifat Ibtisum",
                "Ehsan Bazgir",
                "Tumpa Barai"
            ],
            "link": [
                "http://dx.doi.org/10.5120/ijca2023923147",
                "http://arxiv.org/abs/2310.16978v1",
                "http://arxiv.org/pdf/2310.16978v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16976v1",
            "title": "On the Interplay between Social Welfare and Tractability of Equilibria",
            "updated": "2023-10-25T20:22:51Z",
            "published": "2023-10-25T20:22:51Z",
            "summary": "Computational tractability and social welfare (aka. efficiency) of equilibria\nare two fundamental but in general orthogonal considerations in algorithmic\ngame theory. Nevertheless, we show that when (approximate) full efficiency can\nbe guaranteed via a smoothness argument \\`a la Roughgarden, Nash equilibria are\napproachable under a family of no-regret learning algorithms, thereby enabling\nfast and decentralized computation. We leverage this connection to obtain new\nconvergence results in large games -- wherein the number of players $n \\gg 1$\n-- under the well-documented property of full efficiency via smoothness in the\nlimit. Surprisingly, our framework unifies equilibrium computation in disparate\nclasses of problems including games with vanishing strategic sensitivity and\ntwo-player zero-sum games, illuminating en route an immediate but overlooked\nequivalence between smoothness and a well-studied condition in the optimization\nliterature known as the Minty property. Finally, we establish that a family of\nno-regret dynamics attains a welfare bound that improves over the smoothness\nframework while at the same time guaranteeing convergence to the set of coarse\ncorrelated equilibria. We show this by employing the clairvoyant mirror descent\nalgortihm recently introduced by Piliouras et al.",
            "author": [
                "Ioannis Anagnostides",
                "Tuomas Sandholm"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16976v1",
                "http://arxiv.org/pdf/2310.16976v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16975v1",
            "title": "Efficient Neural Network Approaches for Conditional Optimal Transport\n  with Applications in Bayesian Inference",
            "updated": "2023-10-25T20:20:09Z",
            "published": "2023-10-25T20:20:09Z",
            "summary": "We present two neural network approaches that approximate the solutions of\nstatic and dynamic conditional optimal transport (COT) problems, respectively.\nBoth approaches enable sampling and density estimation of conditional\nprobability distributions, which are core tasks in Bayesian inference. Our\nmethods represent the target conditional distributions as transformations of a\ntractable reference distribution and, therefore, fall into the framework of\nmeasure transport. COT maps are a canonical choice within this framework, with\ndesirable properties such as uniqueness and monotonicity. However, the\nassociated COT problems are computationally challenging, even in moderate\ndimensions. To improve the scalability, our numerical algorithms leverage\nneural networks to parameterize COT maps. Our methods exploit the structure of\nthe static and dynamic formulations of the COT problem. PCP-Map models\nconditional transport maps as the gradient of a partially input convex neural\nnetwork (PICNN) and uses a novel numerical implementation to increase\ncomputational efficiency compared to state-of-the-art alternatives. COT-Flow\nmodels conditional transports via the flow of a regularized neural ODE; it is\nslower to train but offers faster sampling. We demonstrate their effectiveness\nand efficiency by comparing them with state-of-the-art approaches using\nbenchmark datasets and Bayesian inverse problems.",
            "author": [
                "Zheyu Oliver Wang",
                "Ricardo Baptista",
                "Youssef Marzouk",
                "Lars Ruthotto",
                "Deepanshu Verma"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16975v1",
                "http://arxiv.org/pdf/2310.16975v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "62F15, 62M45"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16961v1",
            "title": "Neural Distributed Compressor Discovers Binning",
            "updated": "2023-10-25T20:02:20Z",
            "published": "2023-10-25T20:02:20Z",
            "summary": "We consider lossy compression of an information source when the decoder has\nlossless access to a correlated one. This setup, also known as the Wyner-Ziv\nproblem, is a special case of distributed source coding. To this day, practical\napproaches for the Wyner-Ziv problem have neither been fully developed nor\nheavily investigated. We propose a data-driven method based on machine learning\nthat leverages the universal function approximation capability of artificial\nneural networks. We find that our neural network-based compression scheme,\nbased on variational vector quantization, recovers some principles of the\noptimum theoretical solution of the Wyner-Ziv setup, such as binning in the\nsource space as well as optimal combination of the quantization index and side\ninformation, for exemplary sources. These behaviors emerge although no\nstructure exploiting knowledge of the source distributions was imposed. Binning\nis a widely used tool in information theoretic proofs and methods, and to our\nknowledge, this is the first time it has been explicitly observed to emerge\nfrom data-driven learning.",
            "author": [
                "Ezgi Ozyilkan",
                "Johannes Ball\u00e9",
                "Elza Erkip"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16961v1",
                "http://arxiv.org/pdf/2310.16961v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16960v1",
            "title": "Privately Aligning Language Models with Reinforcement Learning",
            "updated": "2023-10-25T19:58:51Z",
            "published": "2023-10-25T19:58:51Z",
            "summary": "Positioned between pre-training and user deployment, aligning large language\nmodels (LLMs) through reinforcement learning (RL) has emerged as a prevailing\nstrategy for training instruction following-models such as ChatGPT. In this\nwork, we initiate the study of privacy-preserving alignment of LLMs through\nDifferential Privacy (DP) in conjunction with RL. Following the influential\nwork of Ziegler et al. (2020), we study two dominant paradigms: (i) alignment\nvia RL without human in the loop (e.g., positive review generation) and (ii)\nalignment via RL from human feedback (RLHF) (e.g., summarization in a\nhuman-preferred way). We give a new DP framework to achieve alignment via RL,\nand prove its correctness. Our experimental results validate the effectiveness\nof our approach, offering competitive utility while ensuring strong privacy\nprotections.",
            "author": [
                "Fan Wu",
                "Huseyin A. Inan",
                "Arturs Backurs",
                "Varun Chandrasekaran",
                "Janardhan Kulkarni",
                "Robert Sim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16960v1",
                "http://arxiv.org/pdf/2310.16960v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16959v1",
            "title": "Improving Few-shot Generalization of Safety Classifiers via Data\n  Augmented Parameter-Efficient Fine-Tuning",
            "updated": "2023-10-25T19:57:07Z",
            "published": "2023-10-25T19:57:07Z",
            "summary": "As large language models (LLMs) are widely adopted, new safety issues and\npolicies emerge, to which existing safety classifiers do not generalize well.\nIf we have only observed a few examples of violations of a new safety rule, how\ncan we build a classifier to detect violations? In this paper, we study the\nnovel setting of domain-generalized few-shot learning for LLM-based text safety\nclassifiers. Unlike prior few-shot work, these new safety issues can be hard to\nuncover and we do not get to choose the few examples. We demonstrate that\nexisting few-shot techniques do not perform well in this setting, and rather we\npropose to do parameter-efficient fine-tuning (PEFT) combined with augmenting\ntraining data based on similar examples in prior existing rules. We empirically\nshow that our approach of similarity-based data-augmentation + prompt-tuning\n(DAPT) consistently outperforms baselines that either do not rely on data\naugmentation or on PEFT by 7-17% F1 score in the Social Chemistry moral\njudgement and 9-13% AUC in the Toxicity detection tasks, even when the new rule\nis loosely correlated with existing ones.",
            "author": [
                "Ananth Balashankar",
                "Xiao Ma",
                "Aradhana Sinha",
                "Ahmad Beirami",
                "Yao Qin",
                "Jilin Chen",
                "Alex Beutel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16959v1",
                "http://arxiv.org/pdf/2310.16959v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16958v1",
            "title": "Transferring a molecular foundation model for polymer property\n  predictions",
            "updated": "2023-10-25T19:55:00Z",
            "published": "2023-10-25T19:55:00Z",
            "summary": "Transformer-based large language models have remarkable potential to\naccelerate design optimization for applications such as drug development and\nmaterials discovery. Self-supervised pretraining of transformer models requires\nlarge-scale datasets, which are often sparsely populated in topical areas such\nas polymer science. State-of-the-art approaches for polymers conduct data\naugmentation to generate additional samples but unavoidably incurs extra\ncomputational costs. In contrast, large-scale open-source datasets are\navailable for small molecules and provide a potential solution to data scarcity\nthrough transfer learning. In this work, we show that using transformers\npretrained on small molecules and fine-tuned on polymer properties achieve\ncomparable accuracy to those trained on augmented polymer datasets for a series\nof benchmark prediction tasks.",
            "author": [
                "Pei Zhang",
                "Logan Kearney",
                "Debsindhu Bhowmik",
                "Zachary Fox",
                "Amit K. Naskar",
                "John Gounley"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16958v1",
                "http://arxiv.org/pdf/2310.16958v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16955v1",
            "title": "Break it, Imitate it, Fix it: Robustness by Generating Human-Like\n  Attacks",
            "updated": "2023-10-25T19:51:37Z",
            "published": "2023-10-25T19:51:37Z",
            "summary": "Real-world natural language processing systems need to be robust to human\nadversaries. Collecting examples of human adversaries for training is an\neffective but expensive solution. On the other hand, training on synthetic\nattacks with small perturbations - such as word-substitution - does not\nactually improve robustness to human adversaries. In this paper, we propose an\nadversarial training framework that uses limited human adversarial examples to\ngenerate more useful adversarial examples at scale. We demonstrate the\nadvantages of this system on the ANLI and hate speech detection benchmark\ndatasets - both collected via an iterative, adversarial\nhuman-and-model-in-the-loop procedure. Compared to training only on observed\nhuman attacks, also training on our synthetic adversarial examples improves\nmodel robustness to future rounds. In ANLI, we see accuracy gains on the\ncurrent set of attacks (44.1%$\\,\\to\\,$50.1%) and on two future unseen rounds of\nhuman generated attacks (32.5%$\\,\\to\\,$43.4%, and 29.4%$\\,\\to\\,$40.2%). In hate\nspeech detection, we see AUC gains on current attacks (0.76 $\\to$ 0.84) and a\nfuture round (0.77 $\\to$ 0.79). Attacks from methods that do not learn the\ndistribution of existing human adversaries, meanwhile, degrade robustness.",
            "author": [
                "Aradhana Sinha",
                "Ananth Balashankar",
                "Ahmad Beirami",
                "Thi Avrahami",
                "Jilin Chen",
                "Alex Beutel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16955v1",
                "http://arxiv.org/pdf/2310.16955v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16954v1",
            "title": "Improving Performance in Colorectal Cancer Histology Decomposition using\n  Deep and Ensemble Machine Learning",
            "updated": "2023-10-25T19:46:27Z",
            "published": "2023-10-25T19:46:27Z",
            "summary": "In routine colorectal cancer management, histologic samples stained with\nhematoxylin and eosin are commonly used. Nonetheless, their potential for\ndefining objective biomarkers for patient stratification and treatment\nselection is still being explored. The current gold standard relies on\nexpensive and time-consuming genetic tests. However, recent research highlights\nthe potential of convolutional neural networks (CNNs) in facilitating the\nextraction of clinically relevant biomarkers from these readily available\nimages. These CNN-based biomarkers can predict patient outcomes comparably to\ngolden standards, with the added advantages of speed, automation, and minimal\ncost. The predictive potential of CNN-based biomarkers fundamentally relies on\nthe ability of convolutional neural networks (CNNs) to classify diverse tissue\ntypes from whole slide microscope images accurately. Consequently, enhancing\nthe accuracy of tissue class decomposition is critical to amplifying the\nprognostic potential of imaging-based biomarkers. This study introduces a\nhybrid Deep and ensemble machine learning model that surpassed all preceding\nsolutions for this classification task. Our model achieved 96.74% accuracy on\nthe external test set and 99.89% on the internal test set. Recognizing the\npotential of these models in advancing the task, we have made them publicly\navailable for further research and development.",
            "author": [
                "Fabi Prezja",
                "Leevi Annala",
                "Sampsa Kiiskinen",
                "Suvi Lahtinen",
                "Timo Ojala",
                "Pekka Ruusuvuori",
                "Teijo Kuopio"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16954v1",
                "http://arxiv.org/pdf/2310.16954v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16945v4",
            "title": "Causal Q-Aggregation for CATE Model Selection",
            "updated": "2023-11-11T02:24:24Z",
            "published": "2023-10-25T19:27:05Z",
            "summary": "Accurate estimation of conditional average treatment effects (CATE) is at the\ncore of personalized decision making. While there is a plethora of models for\nCATE estimation, model selection is a nontrivial task, due to the fundamental\nproblem of causal inference. Recent empirical work provides evidence in favor\nof proxy loss metrics with double robust properties and in favor of model\nensembling. However, theoretical understanding is lacking. Direct application\nof prior theoretical work leads to suboptimal oracle model selection rates due\nto the non-convexity of the model selection problem. We provide regret rates\nfor the major existing CATE ensembling approaches and propose a new CATE model\nensembling approach based on Q-aggregation using the doubly robust loss. Our\nmain result shows that causal Q-aggregation achieves statistically optimal\noracle model selection regret rates of $\\frac{\\log(M)}{n}$ (with $M$ models and\n$n$ samples), with the addition of higher-order estimation error terms related\nto products of errors in the nuisance functions. Crucially, our regret rate\ndoes not require that any of the candidate CATE models be close to the truth.\nWe validate our new method on many semi-synthetic datasets and also provide\nextensions of our work to CATE model selection with instrumental variables and\nunobserved confounding.",
            "author": [
                "Hui Lan",
                "Vasilis Syrgkanis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16945v4",
                "http://arxiv.org/pdf/2310.16945v4"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "econ.EM",
                "math.ST",
                "stat.TH",
                "62F07(Primary), 62D20(Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16944v1",
            "title": "Zephyr: Direct Distillation of LM Alignment",
            "updated": "2023-10-25T19:25:16Z",
            "published": "2023-10-25T19:25:16Z",
            "summary": "We aim to produce a smaller language model that is aligned to user intent.\nPrevious research has shown that applying distilled supervised fine-tuning\n(dSFT) on larger models significantly improves task accuracy; however, these\nmodels are unaligned, i.e. they do not respond well to natural prompts. To\ndistill this property, we experiment with the use of preference data from AI\nFeedback (AIF). Starting from a dataset of outputs ranked by a teacher model,\nwe apply distilled direct preference optimization (dDPO) to learn a chat model\nwith significantly improved intent alignment. The approach requires only a few\nhours of training without any additional sampling during fine-tuning. The final\nresult, Zephyr-7B, sets the state-of-the-art on chat benchmarks for 7B\nparameter models, and requires no human annotation. In particular, results on\nMT-Bench show that Zephyr-7B surpasses Llama2-Chat-70B, the best open-access\nRLHF-based model. Code, models, data, and tutorials for the system are\navailable at https://github.com/huggingface/alignment-handbook.",
            "author": [
                "Lewis Tunstall",
                "Edward Beeching",
                "Nathan Lambert",
                "Nazneen Rajani",
                "Kashif Rasul",
                "Younes Belkada",
                "Shengyi Huang",
                "Leandro von Werra",
                "Cl\u00e9mentine Fourrier",
                "Nathan Habib",
                "Nathan Sarrazin",
                "Omar Sanseviero",
                "Alexander M. Rush",
                "Thomas Wolf"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16944v1",
                "http://arxiv.org/pdf/2310.16944v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16941v1",
            "title": "Exploring Behavior Discovery Methods for Heterogeneous Swarms of\n  Limited-Capability Robots",
            "updated": "2023-10-25T19:20:32Z",
            "published": "2023-10-25T19:20:32Z",
            "summary": "We study the problem of determining the emergent behaviors that are possible\ngiven a functionally heterogeneous swarm of robots with limited capabilities.\nPrior work has considered behavior search for homogeneous swarms and proposed\nthe use of novelty search over either a hand-specified or learned behavior\nspace followed by clustering to return a taxonomy of emergent behaviors to the\nuser. In this paper, we seek to better understand the role of novelty search\nand the efficacy of using clustering to discover novel emergent behaviors.\nThrough a large set of experiments and ablations, we analyze the effect of\nrepresentations, evolutionary search, and various clustering methods in the\nsearch for novel behaviors in a heterogeneous swarm. Our results indicate that\nprior methods fail to discover many interesting behaviors and that an iterative\nhuman-in-the-loop discovery process discovers more behaviors than random\nsearch, swarm chemistry, and automated behavior discovery. The combined\ndiscoveries of our experiments uncover 23 emergent behaviors, 18 of which are\nnovel discoveries. To the best of our knowledge, these are the first known\nemergent behaviors for heterogeneous swarms of computation-free agents. Videos,\ncode, and appendix are available at the project website:\nhttps://sites.google.com/view/heterogeneous-bd-methods",
            "author": [
                "Connor Mattson",
                "Jeremy C. Clark",
                "Daniel S. Brown"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16941v1",
                "http://arxiv.org/pdf/2310.16941v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16937v1",
            "title": "Learning Transfers over Several Programming Languages",
            "updated": "2023-10-25T19:04:33Z",
            "published": "2023-10-25T19:04:33Z",
            "summary": "Large language models (LLMs) have recently become remarkably good at\nimproving developer productivity for high-resource programming languages. These\nmodels use two kinds of data: large amounts of unlabeled code samples for\npretraining and relatively smaller amounts of labeled code samples for\nfine-tuning or in-context learning. Unfortunately, many programming languages\nare low-resource, lacking labeled samples for most tasks and often even lacking\nunlabeled samples. Therefore, users of low-resource languages (e.g., legacy or\nnew languages) miss out on the benefits of LLMs. Cross-lingual transfer\nlearning uses data from a source language to improve model performance on a\ntarget language. It has been well-studied for natural languages, but has\nreceived little attention for programming languages. This paper reports\nextensive experiments on four tasks using a transformer-based LLM and 11 to 41\nprogramming languages to explore the following questions. First, how well\ncross-lingual transfer works for a given task across different language pairs.\nSecond, given a task and target language, how to best choose a source language.\nThird, the characteristics of a language pair that are predictive of transfer\nperformance, and fourth, how that depends on the given task.",
            "author": [
                "Razan Baltaji",
                "Saurabh Pujar",
                "Louis Mandel",
                "Martin Hirzel",
                "Luca Buratti",
                "Lav Varshney"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16937v1",
                "http://arxiv.org/pdf/2310.16937v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "I.2.7; I.2.5"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16936v2",
            "title": "Diagnosing Alzheimer's Disease using Early-Late Multimodal Data Fusion\n  with Jacobian Maps",
            "updated": "2023-10-27T18:02:42Z",
            "published": "2023-10-25T19:02:57Z",
            "summary": "Alzheimer's disease (AD) is a prevalent and debilitating neurodegenerative\ndisorder impacting a large aging population. Detecting AD in all its\npresymptomatic and symptomatic stages is crucial for early intervention and\ntreatment. An active research direction is to explore machine learning methods\nthat harness multimodal data fusion to outperform human inspection of medical\nscans. However, existing multimodal fusion models have limitations, including\nredundant computation, complex architecture, and simplistic handling of missing\ndata. Moreover, the preprocessing pipelines of medical scans remain\ninadequately detailed and are seldom optimized for individual subjects. In this\npaper, we propose an efficient early-late fusion (ELF) approach, which\nleverages a convolutional neural network for automated feature extraction and\nrandom forests for their competitive performance on small datasets.\nAdditionally, we introduce a robust preprocessing pipeline that adapts to the\nunique characteristics of individual subjects and makes use of whole brain\nimages rather than slices or patches. Moreover, to tackle the challenge of\ndetecting subtle changes in brain volume, we transform images into the Jacobian\ndomain (JD) to enhance both accuracy and robustness in our classification.\nUsing MRI and CT images from the OASIS-3 dataset, our experiments demonstrate\nthe effectiveness of the ELF approach in classifying AD into four stages with\nan accuracy of 97.19%.",
            "author": [
                "Yasmine Mustafa",
                "Tie Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16936v2",
                "http://arxiv.org/pdf/2310.16936v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16931v1",
            "title": "CL-MASR: A Continual Learning Benchmark for Multilingual ASR",
            "updated": "2023-10-25T18:55:40Z",
            "published": "2023-10-25T18:55:40Z",
            "summary": "Modern multilingual automatic speech recognition (ASR) systems like Whisper\nhave made it possible to transcribe audio in multiple languages with a single\nmodel. However, current state-of-the-art ASR models are typically evaluated on\nindividual languages or in a multi-task setting, overlooking the challenge of\ncontinually learning new languages. There is insufficient research on how to\nadd new languages without losing valuable information from previous data.\nFurthermore, existing continual learning benchmarks focus mostly on vision and\nlanguage tasks, leaving continual learning for multilingual ASR largely\nunexplored. To bridge this gap, we propose CL-MASR, a benchmark designed for\nstudying multilingual ASR in a continual learning setting. CL-MASR provides a\ndiverse set of continual learning methods implemented on top of large-scale\npretrained ASR models, along with common metrics to assess the effectiveness of\nlearning new languages while addressing the issue of catastrophic forgetting.\nTo the best of our knowledge, CL-MASR is the first continual learning benchmark\nfor the multilingual ASR task. The code is available at\nhttps://github.com/speechbrain/benchmarks.",
            "author": [
                "Luca Della Libera",
                "Pooneh Mousavi",
                "Salah Zaiem",
                "Cem Subakan",
                "Mirco Ravanelli"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16931v1",
                "http://arxiv.org/pdf/2310.16931v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16921v1",
            "title": "On the connection between least squares, regularization, and classical\n  shadows",
            "updated": "2023-10-25T18:39:08Z",
            "published": "2023-10-25T18:39:08Z",
            "summary": "Classical shadows (CS) offer a resource-efficient means to estimate quantum\nobservables, circumventing the need for exhaustive state tomography. Here, we\nclarify and explore the connection between CS techniques and least squares (LS)\nand regularized least squares (RLS) methods commonly used in machine learning\nand data analysis. By formal identification of LS and RLS ``shadows''\ncompletely analogous to those in CS -- namely, point estimators calculated from\nthe empirical frequencies of single measurements -- we show that both RLS and\nCS can be viewed as regularizers for the underdetermined regime, replacing the\npseudoinverse with invertible alternatives. Through numerical simulations, we\nevaluate RLS and CS from three distinct angles: the tradeoff in bias and\nvariance, mismatch between the expected and actual measurement distributions,\nand the interplay between the number of measurements and number of shots per\nmeasurement. Compared to CS, RLS attains lower variance at the expense of bias,\nis robust to distribution mismatch, and is more sensitive to the number of\nshots for a fixed number of state copies -- differences that can be understood\nfrom the distinct approaches taken to regularization. Conceptually, our\nintegration of LS, RLS, and CS under a unifying ``shadow'' umbrella aids in\nadvancing the overall picture of CS techniques, while practically our results\nhighlight the tradeoffs intrinsic to these measurement approaches, illuminating\nthe circumstances under which either RLS or CS would be preferred, such as\nunverified randomness for the former or unbiased estimation for the latter.",
            "author": [
                "Zhihui Zhu",
                "Joseph M. Lukens",
                "Brian T. Kirby"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16921v1",
                "http://arxiv.org/pdf/2310.16921v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16920v1",
            "title": "Smoothed Gradient Clipping and Error Feedback for Distributed\n  Optimization under Heavy-Tailed Noise",
            "updated": "2023-10-25T18:38:38Z",
            "published": "2023-10-25T18:38:38Z",
            "summary": "Motivated by understanding and analysis of large-scale machine learning under\nheavy-tailed gradient noise, we study distributed optimization with smoothed\ngradient clipping, i.e., in which certain smoothed clipping operators are\napplied to the gradients or gradient estimates computed from local clients\nprior to further processing. While vanilla gradient clipping has proven\neffective in mitigating the impact of heavy-tailed gradient noises in\nnon-distributed setups, it incurs bias that causes convergence issues in\nheterogeneous distributed settings. To address the inherent bias introduced by\ngradient clipping, we develop a smoothed clipping operator, and propose a\ndistributed gradient method equipped with an error feedback mechanism, i.e.,\nthe clipping operator is applied on the difference between some local gradient\nestimator and local stochastic gradient. We establish that, for the first time\nin the strongly convex setting with heavy-tailed gradient noises that may not\nhave finite moments of order greater than one, the proposed distributed\ngradient method's mean square error (MSE) converges to zero at a rate\n$O(1/t^\\iota)$, $\\iota \\in (0, 0.4)$, where the exponent $\\iota$ stays bounded\naway from zero as a function of the problem condition number and the first\nabsolute moment of the noise. Numerical experiments validate our theoretical\nfindings.",
            "author": [
                "Shuhua Yu",
                "Dusan Jakovetic",
                "Soummya Kar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16920v1",
                "http://arxiv.org/pdf/2310.16920v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16917v2",
            "title": "MimicTouch: Learning Human's Control Strategy with Multi-Modal Tactile\n  Feedback",
            "updated": "2023-11-01T22:42:20Z",
            "published": "2023-10-25T18:34:06Z",
            "summary": "In robotics and artificial intelligence, the integration of tactile\nprocessing is becoming increasingly pivotal, especially in learning to execute\nintricate tasks like alignment and insertion. However, existing works focusing\non tactile methods for insertion tasks predominantly rely on robot\nteleoperation data and reinforcement learning, which do not utilize the rich\ninsights provided by human's control strategy guided by tactile feedback. For\nutilizing human sensations, methodologies related to learning from humans\npredominantly leverage visual feedback, often overlooking the invaluable\ntactile feedback that humans inherently employ to finish complex manipulations.\nAddressing this gap, we introduce \"MimicTouch\", a novel framework that mimics\nhuman's tactile-guided control strategy. In this framework, we initially\ncollect multi-modal tactile datasets from human demonstrators, incorporating\nhuman tactile-guided control strategies for task completion. The subsequent\nstep involves instructing robots through imitation learning using multi-modal\nsensor data and retargeted human motions. To further mitigate the embodiment\ngap between humans and robots, we employ online residual reinforcement learning\non the physical robot. Through comprehensive experiments, we validate the\nsafety of MimicTouch in transferring a latent policy learned through imitation\nlearning from human to robot. This ongoing work will pave the way for a broader\nspectrum of tactile-guided robotic applications.",
            "author": [
                "Kelin Yu",
                "Yunhai Han",
                "Matthew Zhu",
                "Ye Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16917v2",
                "http://arxiv.org/pdf/2310.16917v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16912v1",
            "title": "Transformer-based Atmospheric Density Forecasting",
            "updated": "2023-10-25T18:23:41Z",
            "published": "2023-10-25T18:23:41Z",
            "summary": "As the peak of the solar cycle approaches in 2025 and the ability of a single\ngeomagnetic storm to significantly alter the orbit of Resident Space Objects\n(RSOs), techniques for atmospheric density forecasting are vital for space\nsituational awareness. While linear data-driven methods, such as dynamic mode\ndecomposition with control (DMDc), have been used previously for forecasting\natmospheric density, deep learning-based forecasting has the ability to capture\nnonlinearities in data. By learning multiple layer weights from historical\natmospheric density data, long-term dependencies in the dataset are captured in\nthe mapping between the current atmospheric density state and control input to\nthe atmospheric density state at the next timestep. This work improves upon\nprevious linear propagation methods for atmospheric density forecasting, by\ndeveloping a nonlinear transformer-based architecture for atmospheric density\nforecasting. Empirical NRLMSISE-00 and JB2008, as well as physics-based TIEGCM\natmospheric density models are compared for forecasting with DMDc and with the\ntransformer-based propagator.",
            "author": [
                "Julia Briden",
                "Peng Mun Siew",
                "Victor Rodriguez-Fernandez",
                "Richard Linares"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16912v1",
                "http://arxiv.org/pdf/2310.16912v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.LG",
                "physics.space-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18367v1",
            "title": "Unsupervised Learning of Molecular Embeddings for Enhanced Clustering\n  and Emergent Properties for Chemical Compounds",
            "updated": "2023-10-25T18:00:24Z",
            "published": "2023-10-25T18:00:24Z",
            "summary": "The detailed analysis of molecular structures and properties holds great\npotential for drug development discovery through machine learning. Developing\nan emergent property in the model to understand molecules would broaden the\nhorizons for development with a new computational tool. We introduce various\nmethods to detect and cluster chemical compounds based on their SMILES data.\nOur first method, analyzing the graphical structures of chemical compounds\nusing embedding data, employs vector search to meet our threshold value. The\nresults yielded pronounced, concentrated clusters, and the method produced\nfavorable results in querying and understanding the compounds. We also used\nnatural language description embeddings stored in a vector database with\nGPT3.5, which outperforms the base model. Thus, we introduce a similarity\nsearch and clustering algorithm to aid in searching for and interacting with\nmolecules, enhancing efficiency in chemical exploration and enabling future\ndevelopment of emergent properties in molecular property prediction models.",
            "author": [
                "Jaiveer Gill",
                "Ratul Chakraborty",
                "Reetham Gubba",
                "Amy Liu",
                "Shrey Jain",
                "Chirag Iyer",
                "Obaid Khwaja",
                "Saurav Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18367v1",
                "http://arxiv.org/pdf/2310.18367v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16838v1",
            "title": "SparseDFF: Sparse-View Feature Distillation for One-Shot Dexterous\n  Manipulation",
            "updated": "2023-10-25T17:59:41Z",
            "published": "2023-10-25T17:59:41Z",
            "summary": "Humans excel at transferring manipulation skills across diverse object\nshapes, poses, and appearances due to their understanding of semantic\ncorrespondences between different instances. To endow robots with a similar\nhigh-level understanding, we develop a Distilled Feature Field (DFF) for 3D\nscenes, leveraging large 2D vision models to distill semantic features from\nmultiview images. While current research demonstrates advanced performance in\nreconstructing DFFs from dense views, the development of learning a DFF from\nsparse views is relatively nascent, despite its prevalence in numerous\nmanipulation tasks with fixed cameras. In this work, we introduce SparseDFF, a\nnovel method for acquiring view-consistent 3D DFFs from sparse RGBD\nobservations, enabling one-shot learning of dexterous manipulations that are\ntransferable to novel scenes. Specifically, we map the image features to the 3D\npoint cloud, allowing for propagation across the 3D space to establish a dense\nfeature field. At the core of SparseDFF is a lightweight feature refinement\nnetwork, optimized with a contrastive loss between pairwise views after\nback-projecting the image features onto the 3D point cloud. Additionally, we\nimplement a point-pruning mechanism to augment feature continuity within each\nlocal neighborhood. By establishing coherent feature fields on both source and\ntarget scenes, we devise an energy function that facilitates the minimization\nof feature discrepancies w.r.t. the end-effector parameters between the\ndemonstration and the target manipulation. We evaluate our approach using a\ndexterous hand, mastering real-world manipulations on both rigid and deformable\nobjects, and showcase robust generalization in the face of object and\nscene-context variations.",
            "author": [
                "Qianxu Wang",
                "Haotong Zhang",
                "Congyue Deng",
                "Yang You",
                "Hao Dong",
                "Yixin Zhu",
                "Leonidas Guibas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16838v1",
                "http://arxiv.org/pdf/2310.16838v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16837v2",
            "title": "RDBench: ML Benchmark for Relational Databases",
            "updated": "2023-10-30T16:51:30Z",
            "published": "2023-10-25T17:59:34Z",
            "summary": "Benefiting from high-quality datasets and standardized evaluation metrics,\nmachine learning (ML) has achieved sustained progress and widespread\napplications. However, while applying machine learning to relational databases\n(RDBs), the absence of a well-established benchmark remains a significant\nobstacle to the development of ML. To address this issue, we introduce ML\nBenchmark For Relational Databases (RDBench), a standardized benchmark that\naims to promote reproducible ML research on RDBs that include multiple tables.\nRDBench offers diverse RDB datasets of varying scales, domains, and relational\nstructures, organized into 4 levels. Notably, to simplify the adoption of\nRDBench for diverse ML domains, for any given database, RDBench exposes three\ntypes of interfaces including tabular data, homogeneous graphs, and\nheterogeneous graphs, sharing the same underlying task definition. For the\nfirst time, RDBench enables meaningful comparisons between ML methods from\ndiverse domains, ranging from XGBoost to Graph Neural Networks, under RDB\nprediction tasks. We design multiple classification and regression tasks for\neach RDB dataset and report averaged results over the same dataset, further\nenhancing the robustness of the experimental findings. RDBench is implemented\nwith DBGym, a user-friendly platform for ML research and application on\ndatabases, enabling benchmarking new ML methods with RDBench at ease.",
            "author": [
                "Zizhao Zhang",
                "Yi Yang",
                "Lutong Zou",
                "He Wen",
                "Tao Feng",
                "Jiaxuan You"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16837v2",
                "http://arxiv.org/pdf/2310.16837v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DB",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16835v1",
            "title": "Proposal-Contrastive Pretraining for Object Detection from Fewer Data",
            "updated": "2023-10-25T17:59:26Z",
            "published": "2023-10-25T17:59:26Z",
            "summary": "The use of pretrained deep neural networks represents an attractive way to\nachieve strong results with few data available. When specialized in dense\nproblems such as object detection, learning local rather than global\ninformation in images has proven to be more efficient. However, for\nunsupervised pretraining, the popular contrastive learning requires a large\nbatch size and, therefore, a lot of resources. To address this problem, we are\ninterested in transformer-based object detectors that have recently gained\ntraction in the community with good performance and with the particularity of\ngenerating many diverse object proposals.\n  In this work, we present Proposal Selection Contrast (ProSeCo), a novel\nunsupervised overall pretraining approach that leverages this property. ProSeCo\nuses the large number of object proposals generated by the detector for\ncontrastive learning, which allows the use of a smaller batch size, combined\nwith object-level features to learn local information in the images. To improve\nthe effectiveness of the contrastive loss, we introduce the object location\ninformation in the selection of positive examples to take into account multiple\noverlapping object proposals. When reusing pretrained backbone, we advocate for\nconsistency in learning local information between the backbone and the\ndetection head.\n  We show that our method outperforms state of the art in unsupervised\npretraining for object detection on standard and novel benchmarks in learning\nwith fewer data.",
            "author": [
                "Quentin Bouniot",
                "Romaric Audigier",
                "Ang\u00e9lique Loesch",
                "Amaury Habrard"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16835v1",
                "http://arxiv.org/pdf/2310.16835v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16834v1",
            "title": "Discrete Diffusion Language Modeling by Estimating the Ratios of the\n  Data Distribution",
            "updated": "2023-10-25T17:59:12Z",
            "published": "2023-10-25T17:59:12Z",
            "summary": "Despite their groundbreaking performance for many generative modeling tasks,\ndiffusion models have fallen short on discrete data domains such as natural\nlanguage. Crucially, standard diffusion models rely on the well-established\ntheory of score matching, but efforts to generalize this to discrete structures\nhave not yielded the same empirical gains. In this work, we bridge this gap by\nproposing score entropy, a novel discrete score matching loss that is more\nstable than existing methods, forms an ELBO for maximum likelihood training,\nand can be efficiently optimized with a denoising variant. We scale our Score\nEntropy Discrete Diffusion models (SEDD) to the experimental setting of GPT-2,\nachieving highly competitive likelihoods while also introducing distinct\nalgorithmic advantages. In particular, when comparing similarly sized SEDD and\nGPT-2 models, SEDD attains comparable perplexities (normally within $+10\\%$ of\nand sometimes outperforming the baseline). Furthermore, SEDD models learn a\nmore faithful sequence distribution (around $4\\times$ better compared to GPT-2\nmodels with ancestral sampling as measured by large models), can trade off\ncompute for generation quality (needing only $16\\times$ fewer network\nevaluations to match GPT-2), and enables arbitrary infilling beyond the\nstandard left to right prompting.",
            "author": [
                "Aaron Lou",
                "Chenlin Meng",
                "Stefano Ermon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16834v1",
                "http://arxiv.org/pdf/2310.16834v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16832v2",
            "title": "LightSpeed: Light and Fast Neural Light Fields on Mobile Devices",
            "updated": "2023-10-26T20:02:03Z",
            "published": "2023-10-25T17:59:05Z",
            "summary": "Real-time novel-view image synthesis on mobile devices is prohibitive due to\nthe limited computational power and storage. Using volumetric rendering\nmethods, such as NeRF and its derivatives, on mobile devices is not suitable\ndue to the high computational cost of volumetric rendering. On the other hand,\nrecent advances in neural light field representations have shown promising\nreal-time view synthesis results on mobile devices. Neural light field methods\nlearn a direct mapping from a ray representation to the pixel color. The\ncurrent choice of ray representation is either stratified ray sampling or\nPlucker coordinates, overlooking the classic light slab (two-plane)\nrepresentation, the preferred representation to interpolate between light field\nviews. In this work, we find that using the light slab representation is an\nefficient representation for learning a neural light field. More importantly,\nit is a lower-dimensional ray representation enabling us to learn the 4D ray\nspace using feature grids which are significantly faster to train and render.\nAlthough mostly designed for frontal views, we show that the light-slab\nrepresentation can be further extended to non-frontal scenes using a\ndivide-and-conquer strategy. Our method offers superior rendering quality\ncompared to previous light field methods and achieves a significantly improved\ntrade-off between rendering quality and speed.",
            "author": [
                "Aarush Gupta",
                "Junli Cao",
                "Chaoyang Wang",
                "Ju Hu",
                "Sergey Tulyakov",
                "Jian Ren",
                "L\u00e1szl\u00f3 A Jeni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16832v2",
                "http://arxiv.org/pdf/2310.16832v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16831v2",
            "title": "PERF: Panoramic Neural Radiance Field from a Single Panorama",
            "updated": "2023-10-28T16:50:41Z",
            "published": "2023-10-25T17:59:01Z",
            "summary": "Neural Radiance Field (NeRF) has achieved substantial progress in novel view\nsynthesis given multi-view images. Recently, some works have attempted to train\na NeRF from a single image with 3D priors. They mainly focus on a limited field\nof view with a few occlusions, which greatly limits their scalability to\nreal-world 360-degree panoramic scenarios with large-size occlusions. In this\npaper, we present PERF, a 360-degree novel view synthesis framework that trains\na panoramic neural radiance field from a single panorama. Notably, PERF allows\n3D roaming in a complex scene without expensive and tedious image collection.\nTo achieve this goal, we propose a novel collaborative RGBD inpainting method\nand a progressive inpainting-and-erasing method to lift up a 360-degree 2D\nscene to a 3D scene. Specifically, we first predict a panoramic depth map as\ninitialization given a single panorama and reconstruct visible 3D regions with\nvolume rendering. Then we introduce a collaborative RGBD inpainting approach\ninto a NeRF for completing RGB images and depth maps from random views, which\nis derived from an RGB Stable Diffusion model and a monocular depth estimator.\nFinally, we introduce an inpainting-and-erasing strategy to avoid inconsistent\ngeometry between a newly-sampled view and reference views. The two components\nare integrated into the learning of NeRFs in a unified optimization framework\nand achieve promising results. Extensive experiments on Replica and a new\ndataset PERF-in-the-wild demonstrate the superiority of our PERF over\nstate-of-the-art methods. Our PERF can be widely used for real-world\napplications, such as panorama-to-3D, text-to-3D, and 3D scene stylization\napplications. Project page and code are available at\nhttps://perf-project.github.io/ and https://github.com/perf-project/PeRF.",
            "author": [
                "Guangcong Wang",
                "Peng Wang",
                "Zhaoxi Chen",
                "Wenping Wang",
                "Chen Change Loy",
                "Ziwei Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16831v2",
                "http://arxiv.org/pdf/2310.16831v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16828v1",
            "title": "TD-MPC2: Scalable, Robust World Models for Continuous Control",
            "updated": "2023-10-25T17:57:07Z",
            "published": "2023-10-25T17:57:07Z",
            "summary": "TD-MPC is a model-based reinforcement learning (RL) algorithm that performs\nlocal trajectory optimization in the latent space of a learned implicit\n(decoder-free) world model. In this work, we present TD-MPC2: a series of\nimprovements upon the TD-MPC algorithm. We demonstrate that TD-MPC2 improves\nsignificantly over baselines across 104 online RL tasks spanning 4 diverse task\ndomains, achieving consistently strong results with a single set of\nhyperparameters. We further show that agent capabilities increase with model\nand data size, and successfully train a single 317M parameter agent to perform\n80 tasks across multiple task domains, embodiments, and action spaces. We\nconclude with an account of lessons, opportunities, and risks associated with\nlarge TD-MPC2 agents. Explore videos, models, data, code, and more at\nhttps://nicklashansen.github.io/td-mpc2",
            "author": [
                "Nicklas Hansen",
                "Hao Su",
                "Xiaolong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16828v1",
                "http://arxiv.org/pdf/2310.16828v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16826v2",
            "title": "Deep machine learning for meteor monitoring: advances with transfer\n  learning and gradient-weighted class activation mapping",
            "updated": "2023-10-26T10:49:13Z",
            "published": "2023-10-25T17:56:28Z",
            "summary": "In recent decades, the use of optical detection systems for meteor studies\nhas increased dramatically, resulting in huge amounts of data being analyzed.\nAutomated meteor detection tools are essential for studying the continuous\nmeteoroid incoming flux, recovering fresh meteorites, and achieving a better\nunderstanding of our Solar System. Concerning meteor detection, distinguishing\nfalse positives between meteor and non-meteor images has traditionally been\nperformed by hand, which is significantly time-consuming. To address this\nissue, we developed a fully automated pipeline that uses Convolutional Neural\nNetworks (CNNs) to classify candidate meteor detections. Our new method is able\nto detect meteors even in images that contain static elements such as clouds,\nthe Moon, and buildings. To accurately locate the meteor within each frame, we\nemploy the Gradient-weighted Class Activation Mapping (Grad-CAM) technique.\nThis method facilitates the identification of the region of interest by\nmultiplying the activations from the last convolutional layer with the average\nof the gradients across the feature map of that layer. By combining these\nfindings with the activation map derived from the first convolutional layer, we\neffectively pinpoint the most probable pixel location of the meteor. We trained\nand evaluated our model on a large dataset collected by the Spanish Meteor\nNetwork (SPMN) and achieved a precision of 98\\%. Our new methodology presented\nhere has the potential to reduce the workload of meteor scientists and station\noperators and improve the accuracy of meteor tracking and classification.",
            "author": [
                "Eloy Pe\u00f1a-Asensio",
                "Josep M. Trigo-Rodr\u00edguez",
                "Pau Gr\u00e8bol-Tom\u00e0s",
                "David Regordosa-Avellana",
                "Albert Rimola"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16826v2",
                "http://arxiv.org/pdf/2310.16826v2"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.IM",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16825v1",
            "title": "CommonCanvas: An Open Diffusion Model Trained with Creative-Commons\n  Images",
            "updated": "2023-10-25T17:56:07Z",
            "published": "2023-10-25T17:56:07Z",
            "summary": "We assemble a dataset of Creative-Commons-licensed (CC) images, which we use\nto train a set of open diffusion models that are qualitatively competitive with\nStable Diffusion 2 (SD2). This task presents two challenges: (1)\nhigh-resolution CC images lack the captions necessary to train text-to-image\ngenerative models; (2) CC images are relatively scarce. In turn, to address\nthese challenges, we use an intuitive transfer learning technique to produce a\nset of high-quality synthetic captions paired with curated CC images. We then\ndevelop a data- and compute-efficient training recipe that requires as little\nas 3% of the LAION-2B data needed to train existing SD2 models, but obtains\ncomparable quality. These results indicate that we have a sufficient number of\nCC images (~70 million) for training high-quality models. Our training recipe\nalso implements a variety of optimizations that achieve ~3X training speed-ups,\nenabling rapid model iteration. We leverage this recipe to train several\nhigh-quality text-to-image models, which we dub the CommonCanvas family. Our\nlargest model achieves comparable performance to SD2 on a human evaluation,\ndespite being trained on our CC dataset that is significantly smaller than\nLAION and using synthetic captions for training. We release our models, data,\nand code at\nhttps://github.com/mosaicml/diffusion/blob/main/assets/common-canvas.md",
            "author": [
                "Aaron Gokaslan",
                "A. Feder Cooper",
                "Jasmine Collins",
                "Landan Seguin",
                "Austin Jacobson",
                "Mihir Patel",
                "Jonathan Frankle",
                "Cory Stephenson",
                "Volodymyr Kuleshov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16825v1",
                "http://arxiv.org/pdf/2310.16825v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16819v1",
            "title": "CATE Lasso: Conditional Average Treatment Effect Estimation with\n  High-Dimensional Linear Regression",
            "updated": "2023-10-25T17:51:07Z",
            "published": "2023-10-25T17:51:07Z",
            "summary": "In causal inference about two treatments, Conditional Average Treatment\nEffects (CATEs) play an important role as a quantity representing an\nindividualized causal effect, defined as a difference between the expected\noutcomes of the two treatments conditioned on covariates. This study assumes\ntwo linear regression models between a potential outcome and covariates of the\ntwo treatments and defines CATEs as a difference between the linear regression\nmodels. Then, we propose a method for consistently estimating CATEs even under\nhigh-dimensional and non-sparse parameters. In our study, we demonstrate that\ndesirable theoretical properties, such as consistency, remain attainable even\nwithout assuming sparsity explicitly if we assume a weaker assumption called\nimplicit sparsity originating from the definition of CATEs. In this assumption,\nwe suppose that parameters of linear models in potential outcomes can be\ndivided into treatment-specific and common parameters, where the\ntreatment-specific parameters take difference values between each linear\nregression model, while the common parameters remain identical. Thus, in a\ndifference between two linear regression models, the common parameters\ndisappear, leaving only differences in the treatment-specific parameters.\nConsequently, the non-zero parameters in CATEs correspond to the differences in\nthe treatment-specific parameters. Leveraging this assumption, we develop a\nLasso regression method specialized for CATE estimation and present that the\nestimator is consistent. Finally, we confirm the soundness of the proposed\nmethod by simulation studies.",
            "author": [
                "Masahiro Kato",
                "Masaaki Imaizumi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16819v1",
                "http://arxiv.org/pdf/2310.16819v1"
            ],
            "primary_category": "econ.EM",
            "category": [
                "econ.EM",
                "cs.LG",
                "stat.AP",
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16812v1",
            "title": "Accurate Crop Spraying with RTK and Machine Learning on an Autonomous\n  Field Robot",
            "updated": "2023-10-25T17:40:36Z",
            "published": "2023-10-25T17:40:36Z",
            "summary": "The agriculture sector requires a lot of labor and resources. Hence, farmers\nare constantly being pressed for technology and automation to be\ncost-effective. In this context, autonomous robots can play a very important\nrole in carrying out agricultural tasks such as spraying, sowing, inspection,\nand even harvesting. This paper presents one such autonomous robot that is able\nto identify plants and spray agro-chemicals precisely. The robot uses machine\nvision technologies to find plants and RTK-GPS technology to navigate the robot\nalong a predetermined path. The experiments were conducted in a field of potted\nplants in which successful results have been obtained.",
            "author": [
                "W. M. T. D. Wijesundara",
                "T. D. Wanigathunga",
                "M. N. C. Waas",
                "R. T. Hithanadura",
                "S. R. Munasinghe"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16812v1",
                "http://arxiv.org/pdf/2310.16812v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16804v2",
            "title": "Learning COVID-19 Regional Transmission Using Universal Differential\n  Equations in a SIR model",
            "updated": "2023-11-03T12:21:05Z",
            "published": "2023-10-25T17:35:01Z",
            "summary": "Highly-interconnected societies difficult to model the spread of infectious\ndiseases such as COVID-19. Single-region SIR models fail to account for\nincoming forces of infection and expanding them to a large number of\ninteracting regions involves many assumptions that do not hold in the real\nworld. We propose using Universal Differential Equations (UDEs) to capture the\ninfluence of neighboring regions and improve the model's predictions in a\ncombined SIR+UDE model. UDEs are differential equations totally or partially\ndefined by a deep neural network (DNN). We include an additive term to the SIR\nequations composed by a DNN that learns the incoming force of infection from\nthe other regions. The learning is performed using automatic differentiation\nand gradient descent to approach the change in the target system caused by the\nstate of the neighboring regions. We compared the proposed model using a\nsimulated COVID-19 outbreak against a single-region SIR and a fully data-driven\nmodel composed only of a DNN. The proposed UDE+SIR model generates predictions\nthat capture the outbreak dynamic more accurately, but a decay in performance\nis observed at the last stages of the outbreak. The single-area SIR and the\nfully data-driven approach do not capture the proper dynamics accurately. Once\nthe predictions were obtained, we employed the SINDy algorithm to substitute\nthe DNN with a regression, removing the black box element of the model with no\nconsiderable increase in the error levels.",
            "author": [
                "Adrian Rojas-Campos",
                "Lukas Stelz",
                "Pascal Nieters"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16804v2",
                "http://arxiv.org/pdf/2310.16804v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16803v1",
            "title": "Language Agnostic Code Embeddings",
            "updated": "2023-10-25T17:34:52Z",
            "published": "2023-10-25T17:34:52Z",
            "summary": "Recently, code language models have achieved notable advancements in\naddressing a diverse array of essential code comprehension and generation\ntasks. Yet, the field lacks a comprehensive deep dive and understanding of the\ncode embeddings of multilingual code models. In this paper, we present a\ncomprehensive study on multilingual code embeddings, focusing on the\ncross-lingual capabilities of these embeddings across different programming\nlanguages. Through probing experiments, we demonstrate that code embeddings\ncomprise two distinct components: one deeply tied to the nuances and syntax of\na specific language, and the other remaining agnostic to these details,\nprimarily focusing on semantics. Further, we show that when we isolate and\neliminate this language-specific component, we witness significant improvements\nin downstream code retrieval tasks, leading to an absolute increase of up to\n+17 in the Mean Reciprocal Rank (MRR).",
            "author": [
                "Saiteja Utpala",
                "Alex Gu",
                "Pin Yu Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16803v1",
                "http://arxiv.org/pdf/2310.16803v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16802v1",
            "title": "From Molecules to Materials: Pre-training Large Generalizable Models for\n  Atomic Property Prediction",
            "updated": "2023-10-25T17:32:23Z",
            "published": "2023-10-25T17:32:23Z",
            "summary": "Foundation models have been transformational in machine learning fields such\nas natural language processing and computer vision. Similar success in atomic\nproperty prediction has been limited due to the challenges of training\neffective models across multiple chemical domains. To address this, we\nintroduce Joint Multi-domain Pre-training (JMP), a supervised pre-training\nstrategy that simultaneously trains on multiple datasets from different\nchemical domains, treating each dataset as a unique pre-training task within a\nmulti-task framework. Our combined training dataset consists of $\\sim$120M\nsystems from OC20, OC22, ANI-1x, and Transition-1x. We evaluate performance and\ngeneralization by fine-tuning over a diverse set of downstream tasks and\ndatasets including: QM9, rMD17, MatBench, QMOF, SPICE, and MD22. JMP\ndemonstrates an average improvement of 59% over training from scratch, and\nmatches or sets state-of-the-art on 34 out of 40 tasks. Our work highlights the\npotential of pre-training strategies that utilize diverse data to advance\nproperty prediction across chemical domains, especially for low-data tasks.",
            "author": [
                "Nima Shoghi",
                "Adeesh Kolluru",
                "John R. Kitchin",
                "Zachary W. Ulissi",
                "C. Lawrence Zitnick",
                "Brandon M. Wood"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16802v1",
                "http://arxiv.org/pdf/2310.16802v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16795v1",
            "title": "QMoE: Practical Sub-1-Bit Compression of Trillion-Parameter Models",
            "updated": "2023-10-25T17:24:53Z",
            "published": "2023-10-25T17:24:53Z",
            "summary": "Mixture-of-Experts (MoE) architectures offer a general solution to the high\ninference costs of large language models (LLMs) via sparse routing, bringing\nfaster and more accurate models, at the cost of massive parameter counts. For\nexample, the SwitchTransformer-c2048 model has 1.6 trillion parameters,\nrequiring 3.2TB of accelerator memory to run efficiently, which makes practical\ndeployment challenging and expensive. In this paper, we present a solution to\nthis memory problem, in form of a new compression and execution framework\ncalled QMoE. Specifically, QMoE consists of a scalable algorithm which\naccurately compresses trillion-parameter MoEs to less than 1 bit per parameter,\nin a custom format co-designed with bespoke GPU decoding kernels to facilitate\nefficient end-to-end compressed inference, with minor runtime overheads\nrelative to uncompressed execution. Concretely, QMoE can compress the 1.6\ntrillion parameter SwitchTransformer-c2048 model to less than 160GB (20x\ncompression, 0.8 bits per parameter) at only minor accuracy loss, in less than\na day on a single GPU. This enables, for the first time, the execution of a\ntrillion-parameter model on affordable commodity hardware, like a single server\nwith 4x NVIDIA A6000 or 8x NVIDIA 3090 GPUs, at less than 5% runtime overhead\nrelative to ideal uncompressed inference. The source code and compressed models\nare available at github.com/IST-DASLab/qmoe.",
            "author": [
                "Elias Frantar",
                "Dan Alistarh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16795v1",
                "http://arxiv.org/pdf/2310.16795v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16792v1",
            "title": "Learning Independent Program and Architecture Representations for\n  Generalizable Performance Modeling",
            "updated": "2023-10-25T17:24:01Z",
            "published": "2023-10-25T17:24:01Z",
            "summary": "This paper proposes PerfVec, a novel deep learning-based performance modeling\nframework that learns high-dimensional, independent/orthogonal program and\nmicroarchitecture representations. Once learned, a program representation can\nbe used to predict its performance on any microarchitecture, and likewise, a\nmicroarchitecture representation can be applied in the performance prediction\nof any program. Additionally, PerfVec yields a foundation model that captures\nthe performance essence of instructions, which can be directly used by\ndevelopers in numerous performance modeling related tasks without incurring its\ntraining cost. The evaluation demonstrates that PerfVec is more general,\nefficient, and accurate than previous approaches.",
            "author": [
                "Lingda Li",
                "Thomas Flynn",
                "Adolfy Hoisie"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16792v1",
                "http://arxiv.org/pdf/2310.16792v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16791v2",
            "title": "Covert Planning against Imperfect Observers",
            "updated": "2023-11-01T17:44:46Z",
            "published": "2023-10-25T17:23:57Z",
            "summary": "Covert planning refers to a class of constrained planning problems where an\nagent aims to accomplish a task with minimal information leaked to a passive\nobserver to avoid detection. However, existing methods of covert planning often\nconsider deterministic environments or do not exploit the observer's imperfect\ninformation. This paper studies how covert planning can leverage the coupling\nof stochastic dynamics and the observer's imperfect observation to achieve\noptimal task performance without being detected. Specifically, we employ a\nMarkov decision process to model the interaction between the agent and its\nstochastic environment, and a partial observation function to capture the\nleaked information to a passive observer. Assuming the observer employs\nhypothesis testing to detect if the observation deviates from a nominal policy,\nthe covert planning agent aims to maximize the total discounted reward while\nkeeping the probability of being detected as an adversary below a given\nthreshold. We prove that finite-memory policies are more powerful than\nMarkovian policies in covert planning. Then, we develop a primal-dual proximal\npolicy gradient method with a two-time-scale update to compute a (locally)\noptimal covert policy. We demonstrate the effectiveness of our methods using a\nstochastic gridworld example. Our experimental results illustrate that the\nproposed method computes a policy that maximizes the adversary's expected\nreward without violating the detection constraint, and empirically demonstrates\nhow the environmental noises can influence the performance of the covert\npolicies.",
            "author": [
                "Haoxiang Ma",
                "Chongyang Shi",
                "Shuo Han",
                "Michael R. Dorothy",
                "Jie Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16791v2",
                "http://arxiv.org/pdf/2310.16791v2"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16790v1",
            "title": "Improving a Named Entity Recognizer Trained on Noisy Data with a Few\n  Clean Instances",
            "updated": "2023-10-25T17:23:37Z",
            "published": "2023-10-25T17:23:37Z",
            "summary": "To achieve state-of-the-art performance, one still needs to train NER models\non large-scale, high-quality annotated data, an asset that is both costly and\ntime-intensive to accumulate. In contrast, real-world applications often resort\nto massive low-quality labeled data through non-expert annotators via\ncrowdsourcing and external knowledge bases via distant supervision as a\ncost-effective alternative. However, these annotation methods result in noisy\nlabels, which in turn lead to a notable decline in performance. Hence, we\npropose to denoise the noisy NER data with guidance from a small set of clean\ninstances. Along with the main NER model we train a discriminator model and use\nits outputs to recalibrate the sample weights. The discriminator is capable of\ndetecting both span and category errors with different discriminative prompts.\nResults on public crowdsourcing and distant supervision datasets show that the\nproposed method can consistently improve performance with a small guidance set.",
            "author": [
                "Zhendong Chu",
                "Ruiyi Zhang",
                "Tong Yu",
                "Rajiv Jain",
                "Vlad I Morariu",
                "Jiuxiang Gu",
                "Ani Nenkova"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16790v1",
                "http://arxiv.org/pdf/2310.16790v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16789v2",
            "title": "Detecting Pretraining Data from Large Language Models",
            "updated": "2023-11-03T05:27:37Z",
            "published": "2023-10-25T17:21:23Z",
            "summary": "Although large language models (LLMs) are widely deployed, the data used to\ntrain them is rarely disclosed. Given the incredible scale of this data, up to\ntrillions of tokens, it is all but certain that it includes potentially\nproblematic text such as copyrighted materials, personally identifiable\ninformation, and test data for widely reported reference benchmarks. However,\nwe currently have no way to know which data of these types is included or in\nwhat proportions. In this paper, we study the pretraining data detection\nproblem: given a piece of text and black-box access to an LLM without knowing\nthe pretraining data, can we determine if the model was trained on the provided\ntext? To facilitate this study, we introduce a dynamic benchmark WIKIMIA that\nuses data created before and after model training to support gold truth\ndetection. We also introduce a new detection method Min-K% Prob based on a\nsimple hypothesis: an unseen example is likely to contain a few outlier words\nwith low probabilities under the LLM, while a seen example is less likely to\nhave words with such low probabilities. Min-K% Prob can be applied without any\nknowledge about the pretraining corpus or any additional training, departing\nfrom previous detection methods that require training a reference model on data\nthat is similar to the pretraining data. Moreover, our experiments demonstrate\nthat Min-K% Prob achieves a 7.4% improvement on WIKIMIA over these previous\nmethods. We apply Min-K% Prob to three real-world scenarios, copyrighted book\ndetection, contaminated downstream example detection and privacy auditing of\nmachine unlearning, and find it a consistently effective solution.",
            "author": [
                "Weijia Shi",
                "Anirudh Ajith",
                "Mengzhou Xia",
                "Yangsibo Huang",
                "Daogao Liu",
                "Terra Blevins",
                "Danqi Chen",
                "Luke Zettlemoyer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16789v2",
                "http://arxiv.org/pdf/2310.16789v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16788v1",
            "title": "The GOOSE Dataset for Perception in Unstructured Environments",
            "updated": "2023-10-25T17:20:38Z",
            "published": "2023-10-25T17:20:38Z",
            "summary": "The potential for deploying autonomous systems can be significantly increased\nby improving the perception and interpretation of the environment. However, the\ndevelopment of deep learning-based techniques for autonomous systems in\nunstructured outdoor environments poses challenges due to limited data\navailability for training and testing. To address this gap, we present the\nGerman Outdoor and Offroad Dataset (GOOSE), a comprehensive dataset\nspecifically designed for unstructured outdoor environments. The GOOSE dataset\nincorporates 10 000 labeled pairs of images and point clouds, which are\nutilized to train a range of state-of-the-art segmentation models on both image\nand point cloud data. We open source the dataset, along with an ontology for\nunstructured terrain, as well as dataset standards and guidelines. This\ninitiative aims to establish a common framework, enabling the seamless\ninclusion of existing datasets and a fast way to enhance the perception\ncapabilities of various robots operating in unstructured environments. The\ndataset, pre-trained models for offroad perception, and additional\ndocumentation can be found at https://goose-dataset.de/.",
            "author": [
                "Peter Mortimer",
                "Raphael Hagmanns",
                "Miguel Granero",
                "Thorsten Luettel",
                "Janko Petereit",
                "Hans-Joachim Wuensche"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16788v1",
                "http://arxiv.org/pdf/2310.16788v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16787v3",
            "title": "The Data Provenance Initiative: A Large Scale Audit of Dataset Licensing\n  & Attribution in AI",
            "updated": "2023-11-04T19:10:06Z",
            "published": "2023-10-25T17:20:26Z",
            "summary": "The race to train language models on vast, diverse, and inconsistently\ndocumented datasets has raised pressing concerns about the legal and ethical\nrisks for practitioners. To remedy these practices threatening data\ntransparency and understanding, we convene a multi-disciplinary effort between\nlegal and machine learning experts to systematically audit and trace 1800+ text\ndatasets. We develop tools and standards to trace the lineage of these\ndatasets, from their source, creators, series of license conditions,\nproperties, and subsequent use. Our landscape analysis highlights the sharp\ndivides in composition and focus of commercially open vs closed datasets, with\nclosed datasets monopolizing important categories: lower resource languages,\nmore creative tasks, richer topic variety, newer and more synthetic training\ndata. This points to a deepening divide in the types of data that are made\navailable under different license conditions, and heightened implications for\njurisdictional legal interpretations of copyright and fair use. We also observe\nfrequent miscategorization of licenses on widely used dataset hosting sites,\nwith license omission of 70%+ and error rates of 50%+. This points to a crisis\nin misattribution and informed use of the most popular datasets driving many\nrecent breakthroughs. As a contribution to ongoing improvements in dataset\ntransparency and responsible use, we release our entire audit, with an\ninteractive UI, the Data Provenance Explorer, which allows practitioners to\ntrace and filter on data provenance for the most popular open source finetuning\ndata collections: www.dataprovenance.org.",
            "author": [
                "Shayne Longpre",
                "Robert Mahari",
                "Anthony Chen",
                "Naana Obeng-Marnu",
                "Damien Sileo",
                "William Brannon",
                "Niklas Muennighoff",
                "Nathan Khazam",
                "Jad Kabbara",
                "Kartik Perisetla",
                "Xinyi Wu",
                "Enrico Shippole",
                "Kurt Bollacker",
                "Tongshuang Wu",
                "Luis Villa",
                "Sandy Pentland",
                "Sara Hooker"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16787v3",
                "http://arxiv.org/pdf/2310.16787v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16786v1",
            "title": "The Simplest Inflationary Potentials",
            "updated": "2023-10-25T17:20:19Z",
            "published": "2023-10-25T17:20:19Z",
            "summary": "Inflation is a highly favoured theory for the early Universe. It is\ncompatible with current observations of the cosmic microwave background and\nlarge scale structure and is a driver in the quest to detect primordial\ngravitational waves. It is also, given the current quality of the data, highly\nunder-determined with a large number of candidate implementations. We use a new\nmethod in symbolic regression to generate all possible simple scalar field\npotentials for one of two possible basis sets of operators. Treating these as\nsingle-field, slow-roll inflationary models we then score them with an\ninformation-theoretic metric (\"minimum description length\") that quantifies\ntheir efficiency in compressing the information in the Planck data. We explore\ntwo possible priors on the parameter space of potentials, one related to the\nfunctions' structural complexity and one that uses a Katz back-off language\nmodel to prefer functions that may be theoretically motivated. This enables us\nto identify the inflaton potentials that optimally balance simplicity with\naccuracy at explaining the Planck data, which may subsequently find theoretical\nmotivation. Our exploratory study opens the door to extraction of fundamental\nphysics directly from data, and may be augmented with more refined theoretical\npriors in the quest for a complete understanding of the early Universe.",
            "author": [
                "Tom\u00e1s Sousa",
                "Deaglan J. Bartlett",
                "Harry Desmond",
                "Pedro G. Ferreira"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16786v1",
                "http://arxiv.org/pdf/2310.16786v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "cs.LG",
                "gr-qc",
                "hep-ph",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16783v1",
            "title": "S$^3$-TTA: Scale-Style Selection for Test-Time Augmentation in\n  Biomedical Image Segmentation",
            "updated": "2023-10-25T17:19:14Z",
            "published": "2023-10-25T17:19:14Z",
            "summary": "Deep-learning models have been successful in biomedical image segmentation.\nTo generalize for real-world deployment, test-time augmentation (TTA) methods\nare often used to transform the test image into different versions that are\nhopefully closer to the training domain. Unfortunately, due to the vast\ndiversity of instance scale and image styles, many augmented test images\nproduce undesirable results, thus lowering the overall performance. This work\nproposes a new TTA framework, S$^3$-TTA, which selects the suitable image scale\nand style for each test image based on a transformation consistency metric. In\naddition, S$^3$-TTA constructs an end-to-end augmentation-segmentation\njoint-training pipeline to ensure a task-oriented augmentation. On public\nbenchmarks for cell and lung segmentation, S$^3$-TTA demonstrates improvements\nover the prior art by 3.4% and 1.3%, respectively, by simply augmenting the\ninput data in testing phase.",
            "author": [
                "Kangxian Xie",
                "Siyu Huang",
                "Sebastian Cajas Ordone",
                "Hanspeter Pfister",
                "Donglai Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16783v1",
                "http://arxiv.org/pdf/2310.16783v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16781v1",
            "title": "Kiki or Bouba? Sound Symbolism in Vision-and-Language Models",
            "updated": "2023-10-25T17:15:55Z",
            "published": "2023-10-25T17:15:55Z",
            "summary": "Although the mapping between sound and meaning in human language is assumed\nto be largely arbitrary, research in cognitive science has shown that there are\nnon-trivial correlations between particular sounds and meanings across\nlanguages and demographic groups, a phenomenon known as sound symbolism. Among\nthe many dimensions of meaning, sound symbolism is particularly salient and\nwell-demonstrated with regards to cross-modal associations between language and\nthe visual domain. In this work, we address the question of whether sound\nsymbolism is reflected in vision-and-language models such as CLIP and Stable\nDiffusion. Using zero-shot knowledge probing to investigate the inherent\nknowledge of these models, we find strong evidence that they do show this\npattern, paralleling the well-known kiki-bouba effect in psycholinguistics. Our\nwork provides a novel method for demonstrating sound symbolism and\nunderstanding its nature using computational tools. Our code will be made\npublicly available.",
            "author": [
                "Morris Alper",
                "Hadar Averbuch-Elor"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16781v1",
                "http://arxiv.org/pdf/2310.16781v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16779v3",
            "title": "Multi-scale Diffusion Denoised Smoothing",
            "updated": "2023-10-27T17:51:17Z",
            "published": "2023-10-25T17:11:21Z",
            "summary": "Along with recent diffusion models, randomized smoothing has become one of a\nfew tangible approaches that offers adversarial robustness to models at scale,\ne.g., those of large pre-trained models. Specifically, one can perform\nrandomized smoothing on any classifier via a simple \"denoise-and-classify\"\npipeline, so-called denoised smoothing, given that an accurate denoiser is\navailable - such as diffusion model. In this paper, we present scalable methods\nto address the current trade-off between certified robustness and accuracy in\ndenoised smoothing. Our key idea is to \"selectively\" apply smoothing among\nmultiple noise scales, coined multi-scale smoothing, which can be efficiently\nimplemented with a single diffusion model. This approach also suggests a new\nobjective to compare the collective robustness of multi-scale smoothed\nclassifiers, and questions which representation of diffusion model would\nmaximize the objective. To address this, we propose to further fine-tune\ndiffusion model (a) to perform consistent denoising whenever the original image\nis recoverable, but (b) to generate rather diverse outputs otherwise. Our\nexperiments show that the proposed multi-scale smoothing scheme combined with\ndiffusion fine-tuning enables strong certified robustness available with high\nnoise level while maintaining its accuracy close to non-smoothed classifiers.",
            "author": [
                "Jongheon Jeong",
                "Jinwoo Shin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16779v3",
                "http://arxiv.org/pdf/2310.16779v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16778v1",
            "title": "Navigating Socio-Emotional Risk through Comfort-Building in a Physics\n  Teaching Community of Practice: A Case Study",
            "updated": "2023-10-25T17:10:46Z",
            "published": "2023-10-25T17:10:46Z",
            "summary": "In teacher professional development (PD), grouping teachers with varying\nlevels of experience can be a productive and empowering way to stimulate the\nexchange and co-generation of content and pedagogical knowledge. However, less\nexperienced teachers can face socio-emotional risks when engaging in\ncollaborative science content reasoning tasks with more experienced colleagues\n(Finkelstein, Jaber, & Dini, 2018), and these risks may impact the\ncollaborative experience of both parties and the learning environment in\nteacher PD. This descriptive case study examines the process of productively\nnavigating socio-emotional risks and interpersonal tensions encountered by a\nveteran and pre-service physics teacher during one episode of discussing\nphysics content. We use a single term, comfort-building, to encapsulate\ndiscursive moves that result in increased feelings of comfort and safety by the\nparticipants. Comfort-building includes moves that serve to mitigate social\nrisk, ease tension, and avoid discomfort, as well as those geared toward\nfinding common ground and co-navigating challenges. These moves can carve out\nconversational space for teachers to more confidently face risks associated\nwith being accountable to the physics content knowledge and engage in\ndiscipline-based conversations more deeply. The presented episode in this study\nwas followed by video-stimulated individual interviews to determine how\nconsciously the teachers connected their participation to explicit risk and\ncomfort. This case study highlights an affective dimension for consideration in\nthe continued study and facilitation of science teaching communities of\npractice, especially ones that bring together teachers with a variety of\nbackgrounds and skill sets.",
            "author": [
                "Maggie Mahmood",
                "Hamideh Talafian",
                "Devyn Shafer",
                "Morten Lundsgaard",
                "Eric Kuo",
                "Tim Stelzer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16778v1",
                "http://arxiv.org/pdf/2310.16778v1"
            ],
            "primary_category": "physics.ed-ph",
            "category": [
                "physics.ed-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16777v1",
            "title": "MixerFlow for Image Modelling",
            "updated": "2023-10-25T17:10:37Z",
            "published": "2023-10-25T17:10:37Z",
            "summary": "Normalising flows are statistical models that transform a complex density\ninto a simpler density through the use of bijective transformations enabling\nboth density estimation and data generation from a single model. In the context\nof image modelling, the predominant choice has been the Glow-based\narchitecture, whereas alternative architectures remain largely unexplored in\nthe research community. In this work, we propose a novel architecture called\nMixerFlow, based on the MLP-Mixer architecture, further unifying the generative\nand discriminative modelling architectures. MixerFlow offers an effective\nmechanism for weight sharing for flow-based models. Our results demonstrate\nbetter density estimation on image datasets under a fixed computational budget\nand scales well as the image resolution increases, making MixeFlow a powerful\nyet simple alternative to the Glow-based architectures. We also show that\nMixerFlow provides more informative embeddings than Glow-based architectures.",
            "author": [
                "Eshant English",
                "Matthias Kirchler",
                "Christoph Lippert"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16777v1",
                "http://arxiv.org/pdf/2310.16777v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16772v2",
            "title": "AI Agent as Urban Planner: Steering Stakeholder Dynamics in Urban\n  Planning via Consensus-based Multi-Agent Reinforcement Learning",
            "updated": "2023-11-09T15:18:20Z",
            "published": "2023-10-25T17:04:11Z",
            "summary": "In urban planning, land use readjustment plays a pivotal role in aligning\nland use configurations with the current demands for sustainable urban\ndevelopment. However, present-day urban planning practices face two main\nissues. Firstly, land use decisions are predominantly dependent on human\nexperts. Besides, while resident engagement in urban planning can promote urban\nsustainability and livability, it is challenging to reconcile the diverse\ninterests of stakeholders. To address these challenges, we introduce a\nConsensus-based Multi-Agent Reinforcement Learning framework for real-world\nland use readjustment. This framework serves participatory urban planning,\nallowing diverse intelligent agents as stakeholder representatives to vote for\npreferred land use types. Within this framework, we propose a novel consensus\nmechanism in reward design to optimize land utilization through collective\ndecision making. To abstract the structure of the complex urban system, the\ngeographic information of cities is transformed into a spatial graph structure\nand then processed by graph neural networks. Comprehensive experiments on both\ntraditional top-down planning and participatory planning methods from\nreal-world communities indicate that our computational framework enhances\nglobal benefits and accommodates diverse interests, leading to improved\nsatisfaction across different demographic groups. By integrating Multi-Agent\nReinforcement Learning, our framework ensures that participatory urban planning\ndecisions are more dynamic and adaptive to evolving community needs and\nprovides a robust platform for automating complex real-world urban planning\nprocesses.",
            "author": [
                "Kejiang Qian",
                "Lingjun Mao",
                "Xin Liang",
                "Yimin Ding",
                "Jin Gao",
                "Xinran Wei",
                "Ziyi Guo",
                "Jiajie Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16772v2",
                "http://arxiv.org/pdf/2310.16772v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16764v1",
            "title": "ConvNets Match Vision Transformers at Scale",
            "updated": "2023-10-25T16:52:13Z",
            "published": "2023-10-25T16:52:13Z",
            "summary": "Many researchers believe that ConvNets perform well on small or moderately\nsized datasets, but are not competitive with Vision Transformers when given\naccess to datasets on the web-scale. We challenge this belief by evaluating a\nperformant ConvNet architecture pre-trained on JFT-4B, a large labelled dataset\nof images often used for training foundation models. We consider pre-training\ncompute budgets between 0.4k and 110k TPU-v4 core compute hours, and train a\nseries of networks of increasing depth and width from the NFNet model family.\nWe observe a log-log scaling law between held out loss and compute budget.\nAfter fine-tuning on ImageNet, NFNets match the reported performance of Vision\nTransformers with comparable compute budgets. Our strongest fine-tuned model\nachieves a Top-1 accuracy of 90.4%.",
            "author": [
                "Samuel L. Smith",
                "Andrew Brock",
                "Leonard Berrada",
                "Soham De"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16764v1",
                "http://arxiv.org/pdf/2310.16764v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16763v1",
            "title": "SuperHF: Supervised Iterative Learning from Human Feedback",
            "updated": "2023-10-25T16:52:00Z",
            "published": "2023-10-25T16:52:00Z",
            "summary": "While large language models demonstrate remarkable capabilities, they often\npresent challenges in terms of safety, alignment with human values, and\nstability during training. Here, we focus on two prevalent methods used to\nalign these models, Supervised Fine-Tuning (SFT) and Reinforcement Learning\nfrom Human Feedback (RLHF). SFT is simple and robust, powering a host of\nopen-source models, while RLHF is a more sophisticated method used in top-tier\nmodels like ChatGPT but also suffers from instability and susceptibility to\nreward hacking. We propose a novel approach, Supervised Iterative Learning from\nHuman Feedback (SuperHF), which seeks to leverage the strengths of both\nmethods. Our hypothesis is two-fold: that the reward model used in RLHF is\ncritical for efficient data use and model generalization and that the use of\nProximal Policy Optimization (PPO) in RLHF may not be necessary and could\ncontribute to instability issues. SuperHF replaces PPO with a simple supervised\nloss and a Kullback-Leibler (KL) divergence prior. It creates its own training\ndata by repeatedly sampling a batch of model outputs and filtering them through\nthe reward model in an online learning regime. We then break down the reward\noptimization problem into three components: robustly optimizing the training\nrewards themselves, preventing reward hacking-exploitation of the reward model\nthat degrades model performance-as measured by a novel METEOR similarity\nmetric, and maintaining good performance on downstream evaluations. Our\nexperimental results show SuperHF exceeds PPO-based RLHF on the training\nobjective, easily and favorably trades off high reward with low reward hacking,\nimproves downstream calibration, and performs the same on our GPT-4 based\nqualitative evaluation scheme all the while being significantly simpler to\nimplement, highlighting SuperHF's potential as a competitive language model\nalignment technique.",
            "author": [
                "Gabriel Mukobi",
                "Peter Chatain",
                "Su Fong",
                "Robert Windesheim",
                "Gitta Kutyniok",
                "Kush Bhatia",
                "Silas Alberti"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16763v1",
                "http://arxiv.org/pdf/2310.16763v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16761v1",
            "title": "IntenDD: A Unified Contrastive Learning Approach for Intent Detection\n  and Discovery",
            "updated": "2023-10-25T16:50:24Z",
            "published": "2023-10-25T16:50:24Z",
            "summary": "Identifying intents from dialogue utterances forms an integral component of\ntask-oriented dialogue systems. Intent-related tasks are typically formulated\neither as a classification task, where the utterances are classified into\npredefined categories or as a clustering task when new and previously unknown\nintent categories need to be discovered from these utterances. Further, the\nintent classification may be modeled in a multiclass (MC) or multilabel (ML)\nsetup. While typically these tasks are modeled as separate tasks, we propose\nIntenDD, a unified approach leveraging a shared utterance encoding backbone.\nIntenDD uses an entirely unsupervised contrastive learning strategy for\nrepresentation learning, where pseudo-labels for the unlabeled utterances are\ngenerated based on their lexical features. Additionally, we introduce a\ntwo-step post-processing setup for the classification tasks using modified\nadsorption. Here, first, the residuals in the training data are propagated\nfollowed by smoothing the labels both modeled in a transductive setting.\nThrough extensive evaluations on various benchmark datasets, we find that our\napproach consistently outperforms competitive baselines across all three tasks.\nOn average, IntenDD reports percentage improvements of 2.32%, 1.26%, and 1.52%\nin their respective metrics for few-shot MC, few-shot ML, and the intent\ndiscovery tasks respectively.",
            "author": [
                "Bhavuk Singhal",
                "Ashim Gupta",
                "Shivasankaran V P",
                "Amrith Krishna"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16761v1",
                "http://arxiv.org/pdf/2310.16761v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16753v1",
            "title": "PROMINET: Prototype-based Multi-View Network for Interpretable Email\n  Response Prediction",
            "updated": "2023-10-25T16:39:00Z",
            "published": "2023-10-25T16:39:00Z",
            "summary": "Email is a widely used tool for business communication, and email marketing\nhas emerged as a cost-effective strategy for enterprises. While previous\nstudies have examined factors affecting email marketing performance, limited\nresearch has focused on understanding email response behavior by considering\nemail content and metadata. This study proposes a Prototype-based Multi-view\nNetwork (PROMINET) that incorporates semantic and structural information from\nemail data. By utilizing prototype learning, the PROMINET model generates\nlatent exemplars, enabling interpretable email response prediction. The model\nmaps learned semantic and structural exemplars to observed samples in the\ntraining data at different levels of granularity, such as document, sentence,\nor phrase. The approach is evaluated on two real-world email datasets: the\nEnron corpus and an in-house Email Marketing corpus. Experimental results\ndemonstrate that the PROMINET model outperforms baseline models, achieving a\n~3% improvement in F1 score on both datasets. Additionally, the model provides\ninterpretability through prototypes at different granularity levels while\nmaintaining comparable performance to non-interpretable models. The learned\nprototypes also show potential for generating suggestions to enhance email text\nediting and improve the likelihood of effective email responses. This research\ncontributes to enhancing sender-receiver communication and customer engagement\nin email interactions.",
            "author": [
                "Yuqing Wang",
                "Prashanth Vijayaraghavan",
                "Ehsan Degan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16753v1",
                "http://arxiv.org/pdf/2310.16753v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16752v1",
            "title": "Simple, Scalable and Effective Clustering via One-Dimensional\n  Projections",
            "updated": "2023-10-25T16:37:45Z",
            "published": "2023-10-25T16:37:45Z",
            "summary": "Clustering is a fundamental problem in unsupervised machine learning with\nmany applications in data analysis. Popular clustering algorithms such as\nLloyd's algorithm and $k$-means++ can take $\\Omega(ndk)$ time when clustering\n$n$ points in a $d$-dimensional space (represented by an $n\\times d$ matrix\n$X$) into $k$ clusters. In applications with moderate to large $k$, the\nmultiplicative $k$ factor can become very expensive. We introduce a simple\nrandomized clustering algorithm that provably runs in expected time\n$O(\\mathrm{nnz}(X) + n\\log n)$ for arbitrary $k$. Here $\\mathrm{nnz}(X)$ is the\ntotal number of non-zero entries in the input dataset $X$, which is upper\nbounded by $nd$ and can be significantly smaller for sparse datasets. We prove\nthat our algorithm achieves approximation ratio $\\smash{\\widetilde{O}(k^4)}$ on\nany input dataset for the $k$-means objective. We also believe that our\ntheoretical analysis is of independent interest, as we show that the\napproximation ratio of a $k$-means algorithm is approximately preserved under a\nclass of projections and that $k$-means++ seeding can be implemented in\nexpected $O(n \\log n)$ time in one dimension. Finally, we show experimentally\nthat our clustering algorithm gives a new tradeoff between running time and\ncluster quality compared to previous state-of-the-art methods for these tasks.",
            "author": [
                "Moses Charikar",
                "Monika Henzinger",
                "Lunjia Hu",
                "Maxmilian V\u00f6tsch",
                "Erik Waingarten"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16752v1",
                "http://arxiv.org/pdf/2310.16752v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16750v1",
            "title": "Metrically Scaled Monocular Depth Estimation through Sparse Priors for\n  Underwater Robots",
            "updated": "2023-10-25T16:32:31Z",
            "published": "2023-10-25T16:32:31Z",
            "summary": "In this work, we address the problem of real-time dense depth estimation from\nmonocular images for mobile underwater vehicles. We formulate a deep learning\nmodel that fuses sparse depth measurements from triangulated features to\nimprove the depth predictions and solve the problem of scale ambiguity. To\nallow prior inputs of arbitrary sparsity, we apply a dense parameterization\nmethod. Our model extends recent state-of-the-art approaches to monocular image\nbased depth estimation, using an efficient encoder-decoder backbone and modern\nlightweight transformer optimization stage to encode global context. The\nnetwork is trained in a supervised fashion on the forward-looking underwater\ndataset, FLSea. Evaluation results on this dataset demonstrate significant\nimprovement in depth prediction accuracy by the fusion of the sparse feature\npriors. In addition, without any retraining, our method achieves similar depth\nprediction accuracy on a downward looking dataset we collected with a diver\noperated camera rig, conducting a survey of a coral reef. The method achieves\nreal-time performance, running at 160 FPS on a laptop GPU and 7 FPS on a single\nCPU core and is suitable for direct deployment on embedded systems. The\nimplementation of this work is made publicly available at\nhttps://github.com/ebnerluca/uw_depth.",
            "author": [
                "Luca Ebner",
                "Gideon Billings",
                "Stefan Williams"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16750v1",
                "http://arxiv.org/pdf/2310.16750v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16748v1",
            "title": "Integrated Freeway and Arterial Traffic Control to Improve Freeway\n  Mobility without Compromising Arterial Traffic Conditions Using Q-Learning",
            "updated": "2023-10-25T16:29:28Z",
            "published": "2023-10-25T16:29:28Z",
            "summary": "Freeway and arterial transportation networks are operated individually in\nmost cities nowadays. The lack of coordination between the two increases the\nseverity of traffic congestion when they are heavily loaded. To address the\nissue, we propose an integrated traffic control strategy that coordinates\nfreeway traffic control (variable speed limit control, lane change\nrecommendations, ramp metering) and arterial signal timing using Q-learning.\nThe agent is trained offline in a single-section road network first, and then\nimplemented online in a large simulation network with real-world traffic\ndemands. The online data are collected to further improve the agent's\nperformance via continuous learning. We observe significant reductions in\nfreeway travel time and number of stops and a slight increase in on-ramp queue\nlengths by implementing the proposed approach in scenarios with traffic\ncongestion. Meanwhile, the queue lengths of adjacent arterial intersections are\nmaintained at the same level. The benefits of the coordination mechanism is\nverified by comparing the proposed approach with an uncoordinated Q-learning\nalgorithm and a decentralized feedback control strategy.",
            "author": [
                "Tianchen Yuan",
                "Petros A. Ioannou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16748v1",
                "http://arxiv.org/pdf/2310.16748v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16745v1",
            "title": "Design Space Exploration of Sparsity-Aware Application-Specific Spiking\n  Neural Network Accelerators",
            "updated": "2023-10-25T16:22:03Z",
            "published": "2023-10-25T16:22:03Z",
            "summary": "Spiking Neural Networks (SNNs) offer a promising alternative to Artificial\nNeural Networks (ANNs) for deep learning applications, particularly in\nresource-constrained systems. This is largely due to their inherent sparsity,\ninfluenced by factors such as the input dataset, the length of the spike train,\nand the network topology. While a few prior works have demonstrated the\nadvantages of incorporating sparsity into the hardware design, especially in\nterms of reducing energy consumption, the impact on hardware resources has not\nyet been explored. This is where design space exploration (DSE) becomes\ncrucial, as it allows for the optimization of hardware performance by tailoring\nboth the hardware and model parameters to suit specific application needs.\nHowever, DSE can be extremely challenging given the potentially large design\nspace and the interplay of hardware architecture design choices and\napplication-specific model parameters.\n  In this paper, we propose a flexible hardware design that leverages the\nsparsity of SNNs to identify highly efficient, application-specific accelerator\ndesigns. We develop a high-level, cycle-accurate simulation framework for this\nhardware and demonstrate the framework's benefits in enabling detailed and\nfine-grained exploration of SNN design choices, such as the layer-wise\nlogical-to-hardware ratio (LHR). Our experimental results show that our design\ncan (i) achieve up to $76\\%$ reduction in hardware resources and (ii) deliver a\nspeed increase of up to $31.25\\times$, while requiring $27\\%$ fewer hardware\nresources compared to sparsity-oblivious designs. We further showcase the\nrobustness of our framework by varying spike train lengths with different\nneuron population sizes to find the optimal trade-off points between accuracy\nand hardware latency.",
            "author": [
                "Ilkin Aliyev. Kama Svoboda",
                "Tosiron Adegbija"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16745v1",
                "http://arxiv.org/pdf/2310.16745v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16742v1",
            "title": "Interferometric Neural Networks",
            "updated": "2023-10-25T16:17:47Z",
            "published": "2023-10-25T16:17:47Z",
            "summary": "On the one hand, artificial neural networks have many successful applications\nin the field of machine learning and optimization. On the other hand,\ninterferometers are integral parts of any field that deals with waves such as\noptics, astronomy, and quantum physics. Here, we introduce neural networks\ncomposed of interferometers and then build generative adversarial networks from\nthem. Our networks do not have any classical layer and can be realized on\nquantum computers or photonic chips. We demonstrate their applicability for\ncombinatorial optimization, image classification, and image generation. For\ncombinatorial optimization, our network consistently converges to the global\noptimum or remains within a narrow range of it. In multi-class image\nclassification tasks, our networks achieve accuracies of 93% and 83%. Lastly,\nwe show their capability to generate images of digits from 0 to 9 as well as\nhuman faces.",
            "author": [
                "Arun Sehrawat"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16742v1",
                "http://arxiv.org/pdf/2310.16742v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16741v1",
            "title": "Stochastic Latent Transformer: Efficient Modelling of Stochastically\n  Forced Zonal Jets",
            "updated": "2023-10-25T16:17:00Z",
            "published": "2023-10-25T16:17:00Z",
            "summary": "We introduce the 'Stochastic Latent Transformer', a probabilistic deep\nlearning approach for efficient reduced-order modelling of stochastic partial\ndifferential equations (SPDEs). Despite recent advances in deep learning for\nfluid mechanics, limited research has explored modelling stochastically driven\nflows - which play a crucial role in understanding a broad spectrum of\nphenomena, from jets on giant planets to ocean circulation and the variability\nof midlatitude weather. The model architecture consists of a\nstochastically-forced transformer, paired with a translation-equivariant\nautoencoder, that we demonstrate is capable of reproducing system dynamics\nacross various integration periods. We demonstrate its effectiveness applied to\na well-researched zonal jet system, with the neural network achieving a\nfive-order-of-magnitude speedup compared to numerical integration. This\nfacilitates the cost-effective generation of large ensembles, enabling the\nexploration of statistical questions concerning probabilities of spontaneous\ntransition events.",
            "author": [
                "Ira J. S. Shokar",
                "Rich R. Kerswell",
                "Peter H. Haynes"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16741v1",
                "http://arxiv.org/pdf/2310.16741v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.ao-ph",
                "physics.flu-dyn",
                "68T07, 37N10, 35R60"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16730v1",
            "title": "MultiPrompter: Cooperative Prompt Optimization with Multi-Agent\n  Reinforcement Learning",
            "updated": "2023-10-25T15:58:51Z",
            "published": "2023-10-25T15:58:51Z",
            "summary": "Recently, there has been an increasing interest in automated prompt\noptimization based on reinforcement learning (RL). This approach offers\nimportant advantages, such as generating interpretable prompts and being\ncompatible with black-box foundation models. However, the substantial prompt\nspace size poses challenges for RL-based methods, often leading to suboptimal\npolicy convergence. This paper introduces MultiPrompter, a new framework that\nviews prompt optimization as a cooperative game between prompters which take\nturns composing a prompt together. Our cooperative prompt optimization\neffectively reduces the problem size and helps prompters learn optimal prompts.\nWe test our method on the text-to-image task and show its ability to generate\nhigher-quality images than baselines.",
            "author": [
                "Dong-Ki Kim",
                "Sungryull Sohn",
                "Lajanugen Logeswaran",
                "Dongsub Shim",
                "Honglak Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16730v1",
                "http://arxiv.org/pdf/2310.16730v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16728v1",
            "title": "A Finely Segmented Semi-Monolithic Detector tailored for High Resolution\n  PET",
            "updated": "2023-10-25T15:56:36Z",
            "published": "2023-10-25T15:56:36Z",
            "summary": "Preclinical research and organ-dedicated applications require high-resolution\npositron emission tomography (PET) detectors to visualize small structures and\nunderstand biological processes at a finer level of detail. Current commercial\nsystems often employ finely pixelated or monolithic scintillators, each with\nits limitations. We present a semi-monolithic detector, tailored for\nhigh-resolution PET applications, and merging concepts of monolithic and\npixelated crystals. The detector features slabs measuring (24 x 10 x 1) sq. mm,\ncoupled to a 12 x 12 readout channel photosensor with 4 mm pitch. The slabs are\ngrouped in two arrays of 44 slabs each to achieve a higher optical photon\ndensity. We employ a fan beam collimator for fast calibration to train\nmachine-learning-based positioning models for all three dimensions, including\nslab identification and depth-of-interaction (DOI), utilizing gradient tree\nboosting (GTB). Energy calculation was based on a position-dependent energy\ncalibration. Using an analytical timing calibration, time skews were corrected\nfor coincidence timing resolution (CTR) estimation. Leveraging\nmachine-learning-based calibration in all three dimensions, we achieved high\ndetector spatial resolution: down to 1.18 mm full width at half maximum (FWHM)\ndetector spatial resolution and 0.75 mm mean absolute error (MAE) in the\nplanar-monolithic direction along the slabs, and 2.14 mm FWHM and 1.03 mm MAE\nfor depth-of-interaction (DOI) at an energy window of (435-585) keV. Correct\nslab interaction identification exceeded 80%, alongside an energy resolution of\n13.8% and a CTR of 450 ps FWHM. Therewith, the introduced finely segmented,\nhigh-resolution slab detector demonstrates an appealing performance suitable\nfor high-resolution PET applications. The current benchtop-based detector\ncalibration routine allows these detectors to be used in PET systems.",
            "author": [
                "Yannick Kuhl",
                "Florian Mueller",
                "Stephan Naunheim",
                "Matthias Bovelett",
                "Janko Lambertus",
                "David Schug",
                "Bjoern Weissler",
                "Eike Gegenmantel",
                "Pierre Gebhardt",
                "Volkmar Schulz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16728v1",
                "http://arxiv.org/pdf/2310.16728v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16727v1",
            "title": "AI Hazard Management: A framework for the systematic management of root\n  causes for AI risks",
            "updated": "2023-10-25T15:55:50Z",
            "published": "2023-10-25T15:55:50Z",
            "summary": "Recent advancements in the field of Artificial Intelligence (AI) establish\nthe basis to address challenging tasks. However, with the integration of AI,\nnew risks arise. Therefore, to benefit from its advantages, it is essential to\nadequately handle the risks associated with AI. Existing risk management\nprocesses in related fields, such as software systems, need to sufficiently\nconsider the specifics of AI. A key challenge is to systematically and\ntransparently identify and address AI risks' root causes - also called AI\nhazards. This paper introduces the AI Hazard Management (AIHM) framework, which\nprovides a structured process to systematically identify, assess, and treat AI\nhazards. The proposed process is conducted in parallel with the development to\nensure that any AI hazard is captured at the earliest possible stage of the AI\nsystem's life cycle. In addition, to ensure the AI system's auditability, the\nproposed framework systematically documents evidence that the potential impact\nof identified AI hazards could be reduced to a tolerable level. The framework\nbuilds upon an AI hazard list from a comprehensive state-of-the-art analysis.\nAlso, we provide a taxonomy that supports the optimal treatment of the\nidentified AI hazards. Additionally, we illustrate how the AIHM framework can\nincrease the overall quality of a power grid AI use case by systematically\nreducing the impact of identified hazards to an acceptable level.",
            "author": [
                "Ronald Schnitzer",
                "Andreas Hapfelmeier",
                "Sven Gaube",
                "Sonja Zillner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16727v1",
                "http://arxiv.org/pdf/2310.16727v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16717v2",
            "title": "Rebuild City Buildings from Off-Nadir Aerial Images with Offset-Building\n  Model (OBM)",
            "updated": "2023-11-03T13:34:00Z",
            "published": "2023-10-25T15:44:50Z",
            "summary": "Accurate measurement of the offset from roof-to-footprint in\nvery-high-resolution remote sensing imagery is crucial for urban information\nextraction tasks. With the help of deep learning, existing methods typically\nrely on two-stage CNN models to extract regions of interest on building feature\nmaps. At the first stage, a Region Proposal Network (RPN) is applied to extract\nthousands of ROIs (Region of Interests) which will post-imported into a\nRegion-based Convolutional Neural Networks (RCNN) to extract wanted\ninformation. However, because of inflexible RPN, these methods often lack\neffective user interaction, encounter difficulties in instance correspondence,\nand struggle to keep up with the advancements in general artificial\nintelligence. This paper introduces an interactive Transformer model combined\nwith a prompt encoder to precisely extract building segmentation as well as the\noffset vectors from roofs to footprints. In our model, a powerful module,\nnamely ROAM, was tailored for common problems in predicting roof-to-footprint\noffsets. We tested our model's feasibility on the publicly available BONAI\ndataset, achieving a significant reduction in Prompt-Instance-Level offset\nerrors ranging from 14.6% to 16.3%. Additionally, we developed a Distance-NMS\nalgorithm tailored for large-scale building offsets, significantly enhancing\nthe accuracy of predicted building offset angles and lengths in a\nstraightforward and efficient manner. To further validate the model's\nrobustness, we created a new test set using 0.5m remote sensing imagery from\nHuizhou, China, for inference testing. Our code, training methods, and the\nupdated dataset will be accessable at https://github.com/likaiucas.",
            "author": [
                "Kai Li",
                "Yupeng Deng",
                "Yunlong Kong",
                "Diyou Liu",
                "Jingbo Chen",
                "Yu Meng",
                "Junxian Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16717v2",
                "http://arxiv.org/pdf/2310.16717v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "I.4.6; I.4.7; I.3.5; I.5.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16705v1",
            "title": "Wasserstein Gradient Flow over Variational Parameter Space for\n  Variational Inference",
            "updated": "2023-10-25T15:20:53Z",
            "published": "2023-10-25T15:20:53Z",
            "summary": "Variational inference (VI) can be cast as an optimization problem in which\nthe variational parameters are tuned to closely align a variational\ndistribution with the true posterior. The optimization task can be approached\nthrough vanilla gradient descent in black-box VI or natural-gradient descent in\nnatural-gradient VI. In this work, we reframe VI as the optimization of an\nobjective that concerns probability distributions defined over a\n\\textit{variational parameter space}. Subsequently, we propose Wasserstein\ngradient descent for tackling this optimization problem. Notably, the\noptimization techniques, namely black-box VI and natural-gradient VI, can be\nreinterpreted as specific instances of the proposed Wasserstein gradient\ndescent. To enhance the efficiency of optimization, we develop practical\nmethods for numerically solving the discrete gradient flows. We validate the\neffectiveness of the proposed methods through empirical experiments on a\nsynthetic dataset, supplemented by theoretical analyses.",
            "author": [
                "Dai Hai Nguyen",
                "Tetsuya Sakurai",
                "Hiroshi Mamitsuka"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16705v1",
                "http://arxiv.org/pdf/2310.16705v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16698v1",
            "title": "Causal Discovery with Generalized Linear Models through Peeling\n  Algorithms",
            "updated": "2023-10-25T15:12:24Z",
            "published": "2023-10-25T15:12:24Z",
            "summary": "This article presents a novel method for causal discovery with generalized\nstructural equation models suited for analyzing diverse types of outcomes,\nincluding discrete, continuous, and mixed data. Causal discovery often faces\nchallenges due to unmeasured confounders that hinder the identification of\ncausal relationships. The proposed approach addresses this issue by developing\ntwo peeling algorithms (bottom-up and top-down) to ascertain causal\nrelationships and valid instruments. This approach first reconstructs a\nsuper-graph to represent ancestral relationships between variables, using a\npeeling algorithm based on nodewise GLM regressions that exploit relationships\nbetween primary and instrumental variables. Then, it estimates parent-child\neffects from the ancestral relationships using another peeling algorithm while\ndeconfounding a child's model with information borrowed from its parents'\nmodels. The article offers a theoretical analysis of the proposed approach,\nwhich establishes conditions for model identifiability and provides statistical\nguarantees for accurately discovering parent-child relationships via the\npeeling algorithms. Furthermore, the article presents numerical experiments\nshowcasing the effectiveness of our approach in comparison to state-of-the-art\nstructure learning methods without confounders. Lastly, it demonstrates an\napplication to Alzheimer's disease (AD), highlighting the utility of the method\nin constructing gene-to-gene and gene-to-disease regulatory networks involving\nSingle Nucleotide Polymorphisms (SNPs) for healthy and AD subjects.",
            "author": [
                "Minjie Wang",
                "Xiaotong Shen",
                "Wei Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16698v1",
                "http://arxiv.org/pdf/2310.16698v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16696v1",
            "title": "Interpretable time series neural representation for classification\n  purposes",
            "updated": "2023-10-25T15:06:57Z",
            "published": "2023-10-25T15:06:57Z",
            "summary": "Deep learning has made significant advances in creating efficient\nrepresentations of time series data by automatically identifying complex\npatterns. However, these approaches lack interpretability, as the time series\nis transformed into a latent vector that is not easily interpretable. On the\nother hand, Symbolic Aggregate approximation (SAX) methods allow the creation\nof symbolic representations that can be interpreted but do not capture complex\npatterns effectively. In this work, we propose a set of requirements for a\nneural representation of univariate time series to be interpretable. We propose\na new unsupervised neural architecture that meets these requirements. The\nproposed model produces consistent, discrete, interpretable, and visualizable\nrepresentations. The model is learned independently of any downstream tasks in\nan unsupervised setting to ensure robustness. As a demonstration of the\neffectiveness of the proposed model, we propose experiments on classification\ntasks using UCR archive datasets. The obtained results are extensively compared\nto other interpretable models and state-of-the-art neural representation\nlearning models. The experiments show that the proposed model yields, on\naverage better results than other interpretable approaches on multiple\ndatasets. We also present qualitative experiments to asses the interpretability\nof the approach.",
            "author": [
                "Etienne Le Naour",
                "Ghislain Agoua",
                "Nicolas Baskiotis",
                "Vincent Guigue"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16696v1",
                "http://arxiv.org/pdf/2310.16696v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16695v1",
            "title": "From Pointwise to Powerhouse: Initialising Neural Networks with\n  Generative Models",
            "updated": "2023-10-25T15:06:32Z",
            "published": "2023-10-25T15:06:32Z",
            "summary": "Traditional initialisation methods, e.g. He and Xavier, have been effective\nin avoiding the problem of vanishing or exploding gradients in neural networks.\nHowever, they only use simple pointwise distributions, which model\none-dimensional variables. Moreover, they ignore most information about the\narchitecture and disregard past training experiences. These limitations can be\novercome by employing generative models for initialisation. In this paper, we\nintroduce two groups of new initialisation methods. First, we locally\ninitialise weight groups by employing variational autoencoders. Secondly, we\nglobally initialise full weight sets by employing graph hypernetworks. We\nthoroughly evaluate the impact of the employed generative models on\nstate-of-the-art neural networks in terms of accuracy, convergence speed and\nensembling. Our results show that global initialisations result in higher\naccuracy and faster initial convergence speed. However, the implementation\nthrough graph hypernetworks leads to diminished ensemble performance on out of\ndistribution data. To counteract, we propose a modification called noise graph\nhypernetwork, which encourages diversity in the produced ensemble members.\nFurthermore, our approach might be able to transfer learned knowledge to\ndifferent image distributions. Our work provides insights into the potential,\nthe trade-offs and possible modifications of these new initialisation methods.",
            "author": [
                "Christian Harder",
                "Moritz Fuchs",
                "Yuri Tolkach",
                "Anirban Mukhopadhyay"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16695v1",
                "http://arxiv.org/pdf/2310.16695v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "J.3; I.5.1; I.5.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16694v1",
            "title": "DSAM-GN:Graph Network based on Dynamic Similarity Adjacency Matrices for\n  Vehicle Re-identification",
            "updated": "2023-10-25T15:04:57Z",
            "published": "2023-10-25T15:04:57Z",
            "summary": "In recent years, vehicle re-identification (Re-ID) has gained increasing\nimportance in various applications such as assisted driving systems, traffic\nflow management, and vehicle tracking, due to the growth of intelligent\ntransportation systems. However, the presence of extraneous background\ninformation and occlusions can interfere with the learning of discriminative\nfeatures, leading to significant variations in the same vehicle image across\ndifferent scenarios. This paper proposes a method, named graph network based on\ndynamic similarity adjacency matrices (DSAM-GN), which incorporates a novel\napproach for constructing adjacency matrices to capture spatial relationships\nof local features and reduce background noise. Specifically, the proposed\nmethod divides the extracted vehicle features into different patches as nodes\nwithin the graph network. A spatial attention-based similarity adjacency matrix\ngeneration (SASAMG) module is employed to compute similarity matrices of nodes,\nand a dynamic erasure operation is applied to disconnect nodes with low\nsimilarity, resulting in similarity adjacency matrices. Finally, the nodes and\nsimilarity adjacency matrices are fed into graph networks to extract more\ndiscriminative features for vehicle Re-ID. Experimental results on public\ndatasets VeRi-776 and VehicleID demonstrate the effectiveness of the proposed\nmethod compared with recent works.",
            "author": [
                "Yuejun Jiao",
                "Song Qiu",
                "Mingsong Chen",
                "Dingding Han",
                "Qingli Li",
                "Yue Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16694v1",
                "http://arxiv.org/pdf/2310.16694v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17816v1",
            "title": "Local Discovery by Partitioning: Polynomial-Time Causal Discovery Around\n  Exposure-Outcome Pairs",
            "updated": "2023-10-25T14:53:10Z",
            "published": "2023-10-25T14:53:10Z",
            "summary": "This work addresses the problem of automated covariate selection under\nlimited prior knowledge. Given an exposure-outcome pair {X,Y} and a variable\nset Z of unknown causal structure, the Local Discovery by Partitioning (LDP)\nalgorithm partitions Z into subsets defined by their relation to {X,Y}. We\nenumerate eight exhaustive and mutually exclusive partitions of any arbitrary Z\nand leverage this taxonomy to differentiate confounders from other variable\ntypes. LDP is motivated by valid adjustment set identification, but avoids the\npretreatment assumption commonly made by automated covariate selection methods.\nWe provide theoretical guarantees that LDP returns a valid adjustment set for\nany Z that meets sufficient graphical conditions. Under stronger conditions, we\nprove that partition labels are asymptotically correct. Total independence\ntests is worst-case quadratic in |Z|, with sub-quadratic runtimes observed\nempirically. We numerically validate our theoretical guarantees on synthetic\nand semi-synthetic graphs. Adjustment sets from LDP yield less biased and more\nprecise average treatment effect estimates than baselines, with LDP\noutperforming on confounder recall, test count, and runtime for valid\nadjustment set discovery.",
            "author": [
                "Jacqueline Maasch",
                "Weishen Pan",
                "Shantanu Gupta",
                "Volodymyr Kuleshov",
                "Kyra Gan",
                "Fei Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17816v1",
                "http://arxiv.org/pdf/2310.17816v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16688v1",
            "title": "Learning-based adaption of robotic friction models",
            "updated": "2023-10-25T14:50:15Z",
            "published": "2023-10-25T14:50:15Z",
            "summary": "In the Fourth Industrial Revolution, wherein artificial intelligence and the\nautomation of machines occupy a central role, the deployment of robots is\nindispensable. However, the manufacturing process using robots, especially in\ncollaboration with humans, is highly intricate. In particular, modeling the\nfriction torque in robotic joints is a longstanding problem due to the lack of\na good mathematical description. This motivates the usage of data-driven\nmethods in recent works. However, model-based and data-driven models often\nexhibit limitations in their ability to generalize beyond the specific dynamics\nthey were trained on, as we demonstrate in this paper. To address this\nchallenge, we introduce a novel approach based on residual learning, which aims\nto adapt an existing friction model to new dynamics using as little data as\npossible. We validate our approach by training a base neural network on a\nsymmetric friction data set to learn an accurate relation between the velocity\nand the friction torque. Subsequently, to adapt to more complex asymmetric\nsettings, we train a second network on a small dataset, focusing on predicting\nthe residual of the initial network's output. By combining the output of both\nnetworks in a suitable manner, our proposed estimator outperforms the\nconventional model-based approach and the base neural network significantly.\nFurthermore, we evaluate our method on trajectories involving external loads\nand still observe a substantial improvement, approximately 60-70\\%, over the\nconventional approach. Our method does not rely on data with external load\nduring training, eliminating the need for external torque sensors. This\ndemonstrates the generalization capability of our approach, even with a small\namount of data-only 43 seconds of a robot movement-enabling adaptation to\ndiverse scenarios based on prior knowledge about friction in different\nsettings.",
            "author": [
                "Philipp Scholl",
                "Maged Iskandar",
                "Sebastian Wolf",
                "Jinoh Lee",
                "Aras Bacho",
                "Alexander Dietrich",
                "Alin Albu-Sch\u00e4ffer",
                "Gitta Kutyniok"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16688v1",
                "http://arxiv.org/pdf/2310.16688v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16686v1",
            "title": "Dynamics Generalisation in Reinforcement Learning via Adaptive\n  Context-Aware Policies",
            "updated": "2023-10-25T14:50:05Z",
            "published": "2023-10-25T14:50:05Z",
            "summary": "While reinforcement learning has achieved remarkable successes in several\ndomains, its real-world application is limited due to many methods failing to\ngeneralise to unfamiliar conditions. In this work, we consider the problem of\ngeneralising to new transition dynamics, corresponding to cases in which the\nenvironment's response to the agent's actions differs. For example, the\ngravitational force exerted on a robot depends on its mass and changes the\nrobot's mobility. Consequently, in such cases, it is necessary to condition an\nagent's actions on extrinsic state information and pertinent contextual\ninformation reflecting how the environment responds. While the need for\ncontext-sensitive policies has been established, the manner in which context is\nincorporated architecturally has received less attention. Thus, in this work,\nwe present an investigation into how context information should be incorporated\ninto behaviour learning to improve generalisation. To this end, we introduce a\nneural network architecture, the Decision Adapter, which generates the weights\nof an adapter module and conditions the behaviour of an agent on the context\ninformation. We show that the Decision Adapter is a useful generalisation of a\npreviously proposed architecture and empirically demonstrate that it results in\nsuperior generalisation performance compared to previous approaches in several\nenvironments. Beyond this, the Decision Adapter is more robust to irrelevant\ndistractor variables than several alternative methods.",
            "author": [
                "Michael Beukman",
                "Devon Jarvis",
                "Richard Klein",
                "Steven James",
                "Benjamin Rosman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16686v1",
                "http://arxiv.org/pdf/2310.16686v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16684v1",
            "title": "Local Statistics for Generative Image Detection",
            "updated": "2023-10-25T14:47:32Z",
            "published": "2023-10-25T14:47:32Z",
            "summary": "Diffusion models (DMs) are generative models that learn to synthesize images\nfrom Gaussian noise. DMs can be trained to do a variety of tasks such as image\ngeneration and image super-resolution. Researchers have made significant\nimprovement in the capability of synthesizing photorealistic images in the past\nfew years. These successes also hasten the need to address the potential misuse\nof synthesized images. In this paper, we highlight the effectiveness of\ncomputing local statistics, as opposed to global statistics, in distinguishing\ndigital camera images from DM-generated images. We hypothesized that local\nstatistics should be used to address the spatial non-stationarity problem in\nimages. We show that our approach produced promising results and it is also\nrobust to various perturbations such as image resizing and JPEG compression.",
            "author": [
                "Yung Jer Wong",
                "Teck Khim Ng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16684v1",
                "http://arxiv.org/pdf/2310.16684v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16681v1",
            "title": "BabyStories: Can Reinforcement Learning Teach Baby Language Models to\n  Write Better Stories?",
            "updated": "2023-10-25T14:45:48Z",
            "published": "2023-10-25T14:45:48Z",
            "summary": "Language models have seen significant growth in the size of their corpus,\nleading to notable performance improvements. Yet, there has been limited\nprogress in developing models that handle smaller, more human-like datasets. As\npart of the BabyLM shared task, this study explores the impact of reinforcement\nlearning from human feedback (RLHF) on language models pretrained from scratch\nwith a limited training corpus. Comparing two GPT-2 variants, the larger model\nperforms better in storytelling tasks after RLHF fine-tuning. These findings\nsuggest that RLHF techniques may be more advantageous for larger models due to\ntheir higher learning and adaptation capacity, though more experiments are\nneeded to confirm this finding. These insights highlight the potential benefits\nof RLHF fine-tuning for language models within limited data, enhancing their\nability to maintain narrative focus and coherence while adhering better to\ninitial instructions in storytelling tasks. The code for this work is publicly\nat https://github.com/Zephyr1022/BabyStories-UTSA.",
            "author": [
                "Xingmeng Zhao",
                "Tongnian Wang",
                "Sheri Osborn",
                "Anthony Rios"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16681v1",
                "http://arxiv.org/pdf/2310.16681v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16678v1",
            "title": "Robust and Actively Secure Serverless Collaborative Learning",
            "updated": "2023-10-25T14:43:03Z",
            "published": "2023-10-25T14:43:03Z",
            "summary": "Collaborative machine learning (ML) is widely used to enable institutions to\nlearn better models from distributed data. While collaborative approaches to\nlearning intuitively protect user data, they remain vulnerable to either the\nserver, the clients, or both, deviating from the protocol. Indeed, because the\nprotocol is asymmetric, a malicious server can abuse its power to reconstruct\nclient data points. Conversely, malicious clients can corrupt learning with\nmalicious updates. Thus, both clients and servers require a guarantee when the\nother cannot be trusted to fully cooperate. In this work, we propose a\npeer-to-peer (P2P) learning scheme that is secure against malicious servers and\nrobust to malicious clients. Our core contribution is a generic framework that\ntransforms any (compatible) algorithm for robust aggregation of model updates\nto the setting where servers and clients can act maliciously. Finally, we\ndemonstrate the computational efficiency of our approach even with 1-million\nparameter models trained by 100s of peers on standard datasets.",
            "author": [
                "Olive Franzese",
                "Adam Dziedzic",
                "Christopher A. Choquette-Choo",
                "Mark R. Thomas",
                "Muhammad Ahmad Kaleem",
                "Stephan Rabanser",
                "Congyu Fang",
                "Somesh Jha",
                "Nicolas Papernot",
                "Xiao Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16678v1",
                "http://arxiv.org/pdf/2310.16678v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16677v1",
            "title": "Machine Learning Approaches for Fine-Grained Symptom Estimation in\n  Schizophrenia: A Comprehensive Review",
            "updated": "2023-10-25T14:42:58Z",
            "published": "2023-10-25T14:42:58Z",
            "summary": "Schizophrenia is a severe yet treatable mental disorder, it is diagnosed\nusing a multitude of primary and secondary symptoms. Diagnosis and treatment\nfor each individual depends on the severity of the symptoms, therefore there is\na need for accurate, personalised assessments. However, the process can be both\ntime-consuming and subjective; hence, there is a motivation to explore\nautomated methods that can offer consistent diagnosis and precise symptom\nassessments, thereby complementing the work of healthcare practitioners.\nMachine Learning has demonstrated impressive capabilities across numerous\ndomains, including medicine; the use of Machine Learning in patient assessment\nholds great promise for healthcare professionals and patients alike, as it can\nlead to more consistent and accurate symptom estimation.This survey aims to\nreview methodologies that utilise Machine Learning for diagnosis and assessment\nof schizophrenia. Contrary to previous reviews that primarily focused on binary\nclassification, this work recognises the complexity of the condition and\ninstead, offers an overview of Machine Learning methods designed for\nfine-grained symptom estimation. We cover multiple modalities, namely Medical\nImaging, Electroencephalograms and Audio-Visual, as the illness symptoms can\nmanifest themselves both in a patient's pathology and behaviour. Finally, we\nanalyse the datasets and methodologies used in the studies and identify trends,\ngaps as well as opportunities for future research.",
            "author": [
                "Niki Maria Foteinopoulou",
                "Ioannis Patras"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16677v1",
                "http://arxiv.org/pdf/2310.16677v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16676v2",
            "title": "SSLCL: An Efficient Model-Agnostic Supervised Contrastive Learning\n  Framework for Emotion Recognition in Conversations",
            "updated": "2023-11-18T11:50:52Z",
            "published": "2023-10-25T14:41:14Z",
            "summary": "Emotion recognition in conversations (ERC) is a rapidly evolving task within\nthe natural language processing community, which aims to detect the emotions\nexpressed by speakers during a conversation. Recently, a growing number of ERC\nmethods have focused on leveraging supervised contrastive learning (SCL) to\nenhance the robustness and generalizability of learned features. However,\ncurrent SCL-based approaches in ERC are impeded by the constraint of large\nbatch sizes and the lack of compatibility with most existing ERC models. To\naddress these challenges, we propose an efficient and model-agnostic SCL\nframework named Supervised Sample-Label Contrastive Learning with Soft-HGR\nMaximal Correlation (SSLCL), which eliminates the need for a large batch size\nand can be seamlessly integrated with existing ERC models without introducing\nany model-specific assumptions. Specifically, we introduce a novel perspective\non utilizing label representations by projecting discrete labels into dense\nembeddings through a shallow multilayer perceptron, and formulate the training\nobjective to maximize the similarity between sample features and their\ncorresponding ground-truth label embeddings, while minimizing the similarity\nbetween sample features and label embeddings of disparate classes. Moreover, we\ninnovatively adopt the Soft-HGR maximal correlation as a measure of similarity\nbetween sample features and label embeddings, leading to significant\nperformance improvements over conventional similarity measures. Additionally,\nmultimodal cues of utterances are effectively leveraged by SSLCL as data\naugmentations to boost model performances. Extensive experiments on two ERC\nbenchmark datasets, IEMOCAP and MELD, demonstrate the compatibility and\nsuperiority of our proposed SSLCL framework compared to existing\nstate-of-the-art SCL methods. Our code is available at\n\\url{https://github.com/TaoShi1998/SSLCL}.",
            "author": [
                "Tao Shi",
                "Xiao Liang",
                "Yaoyuan Liang",
                "Xinyi Tong",
                "Shao-Lun Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16676v2",
                "http://arxiv.org/pdf/2310.16676v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16667v1",
            "title": "CoDet: Co-Occurrence Guided Region-Word Alignment for Open-Vocabulary\n  Object Detection",
            "updated": "2023-10-25T14:31:02Z",
            "published": "2023-10-25T14:31:02Z",
            "summary": "Deriving reliable region-word alignment from image-text pairs is critical to\nlearn object-level vision-language representations for open-vocabulary object\ndetection. Existing methods typically rely on pre-trained or self-trained\nvision-language models for alignment, which are prone to limitations in\nlocalization accuracy or generalization capabilities. In this paper, we propose\nCoDet, a novel approach that overcomes the reliance on pre-aligned\nvision-language space by reformulating region-word alignment as a co-occurring\nobject discovery problem. Intuitively, by grouping images that mention a shared\nconcept in their captions, objects corresponding to the shared concept shall\nexhibit high co-occurrence among the group. CoDet then leverages visual\nsimilarities to discover the co-occurring objects and align them with the\nshared concept. Extensive experiments demonstrate that CoDet has superior\nperformances and compelling scalability in open-vocabulary detection, e.g., by\nscaling up the visual backbone, CoDet achieves 37.0 $\\text{AP}^m_{novel}$ and\n44.7 $\\text{AP}^m_{all}$ on OV-LVIS, surpassing the previous SoTA by 4.2\n$\\text{AP}^m_{novel}$ and 9.8 $\\text{AP}^m_{all}$. Code is available at\nhttps://github.com/CVMI-Lab/CoDet.",
            "author": [
                "Chuofan Ma",
                "Yi Jiang",
                "Xin Wen",
                "Zehuan Yuan",
                "Xiaojuan Qi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16667v1",
                "http://arxiv.org/pdf/2310.16667v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16665v1",
            "title": "Robust Source-Free Domain Adaptation for Fundus Image Segmentation",
            "updated": "2023-10-25T14:25:18Z",
            "published": "2023-10-25T14:25:18Z",
            "summary": "Unsupervised Domain Adaptation (UDA) is a learning technique that transfers\nknowledge learned in the source domain from labelled training data to the\ntarget domain with only unlabelled data. It is of significant importance to\nmedical image segmentation because of the usual lack of labelled training data.\nAlthough extensive efforts have been made to optimize UDA techniques to improve\nthe accuracy of segmentation models in the target domain, few studies have\naddressed the robustness of these models under UDA. In this study, we propose a\ntwo-stage training strategy for robust domain adaptation. In the source\ntraining stage, we utilize adversarial sample augmentation to enhance the\nrobustness and generalization capability of the source model. And in the target\ntraining stage, we propose a novel robust pseudo-label and pseudo-boundary\n(PLPB) method, which effectively utilizes unlabeled target data to generate\npseudo labels and pseudo boundaries that enable model self-adaptation without\nrequiring source data. Extensive experimental results on cross-domain fundus\nimage segmentation confirm the effectiveness and versatility of our method.\nSource code of this study is openly accessible at\nhttps://github.com/LinGrayy/PLPB.",
            "author": [
                "Lingrui Li",
                "Yanfeng Zhou",
                "Ge Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16665v1",
                "http://arxiv.org/pdf/2310.16665v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16870v2",
            "title": "MACP: Efficient Model Adaptation for Cooperative Perception",
            "updated": "2023-11-07T05:42:48Z",
            "published": "2023-10-25T14:24:42Z",
            "summary": "Vehicle-to-vehicle (V2V) communications have greatly enhanced the perception\ncapabilities of connected and automated vehicles (CAVs) by enabling information\nsharing to \"see through the occlusions\", resulting in significant performance\nimprovements. However, developing and training complex multi-agent perception\nmodels from scratch can be expensive and unnecessary when existing single-agent\nmodels show remarkable generalization capabilities. In this paper, we propose a\nnew framework termed MACP, which equips a single-agent pre-trained model with\ncooperation capabilities. We approach this objective by identifying the key\nchallenges of shifting from single-agent to cooperative settings, adapting the\nmodel by freezing most of its parameters and adding a few lightweight modules.\nWe demonstrate in our experiments that the proposed framework can effectively\nutilize cooperative observations and outperform other state-of-the-art\napproaches in both simulated and real-world cooperative perception benchmarks\nwhile requiring substantially fewer tunable parameters with reduced\ncommunication costs. Our source code is available at\nhttps://github.com/PurdueDigitalTwin/MACP.",
            "author": [
                "Yunsheng Ma",
                "Juanwu Lu",
                "Can Cui",
                "Sicheng Zhao",
                "Xu Cao",
                "Wenqian Ye",
                "Ziran Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16870v2",
                "http://arxiv.org/pdf/2310.16870v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16662v1",
            "title": "Deep Learning Techniques for Cervical Cancer Diagnosis based on\n  Pathology and Colposcopy Images",
            "updated": "2023-10-25T14:23:40Z",
            "published": "2023-10-25T14:23:40Z",
            "summary": "Cervical cancer is a prevalent disease affecting millions of women worldwide\nevery year. It requires significant attention, as early detection during the\nprecancerous stage provides an opportunity for a cure. The screening and\ndiagnosis of cervical cancer rely on cytology and colposcopy methods. Deep\nlearning, a promising technology in computer vision, has emerged as a potential\nsolution to improve the accuracy and efficiency of cervical cancer screening\ncompared to traditional clinical inspection methods that are prone to human\nerror. This review article discusses cervical cancer and its screening\nprocesses, followed by the Deep Learning training process and the\nclassification, segmentation, and detection tasks for cervical cancer\ndiagnosis. Additionally, we explored the most common public datasets used in\nboth cytology and colposcopy and highlighted the popular and most utilized\narchitectures that researchers have applied to both cytology and colposcopy. We\nreviewed 24 selected practical papers in this study and summarized them. This\narticle highlights the remarkable efficiency in enhancing the precision and\nspeed of cervical cancer analysis by Deep Learning, bringing us closer to early\ndiagnosis and saving lives.",
            "author": [
                "Hana Ahmadzadeh Sarhangi",
                "Dorsa Beigifard",
                "Elahe Farmani",
                "Hamidreza Bolhasani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16662v1",
                "http://arxiv.org/pdf/2310.16662v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16659v1",
            "title": "UAV Pathfinding in Dynamic Obstacle Avoidance with Multi-agent\n  Reinforcement Learning",
            "updated": "2023-10-25T14:21:22Z",
            "published": "2023-10-25T14:21:22Z",
            "summary": "Multi-agent reinforcement learning based methods are significant for online\nplanning of feasible and safe paths for agents in dynamic and uncertain\nscenarios. Although some methods like fully centralized and fully decentralized\nmethods achieve a certain measure of success, they also encounter problems such\nas dimension explosion and poor convergence, respectively. In this paper, we\npropose a novel centralized training with decentralized execution method based\non multi-agent reinforcement learning to solve the dynamic obstacle avoidance\nproblem online. In this approach, each agent communicates only with the central\nplanner or only with its neighbors, respectively, to plan feasible and safe\npaths online. We improve our methods based on the idea of model predictive\ncontrol to increase the training efficiency and sample utilization of agents.\nThe experimental results in both simulation, indoor, and outdoor environments\nvalidate the effectiveness of our method. The video is available at\nhttps://www.bilibili.com/video/BV1gw41197hV/?vd_source=9de61aecdd9fb684e546d032ef7fe7bf",
            "author": [
                "Qizhen Wu",
                "Lei Chen",
                "Kexin Liu",
                "Jinhu Lv"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16659v1",
                "http://arxiv.org/pdf/2310.16659v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16656v1",
            "title": "A Picture is Worth a Thousand Words: Principled Recaptioning Improves\n  Image Generation",
            "updated": "2023-10-25T14:10:08Z",
            "published": "2023-10-25T14:10:08Z",
            "summary": "Text-to-image diffusion models achieved a remarkable leap in capabilities\nover the last few years, enabling high-quality and diverse synthesis of images\nfrom a textual prompt. However, even the most advanced models often struggle to\nprecisely follow all of the directions in their prompts. The vast majority of\nthese models are trained on datasets consisting of (image, caption) pairs where\nthe images often come from the web, and the captions are their HTML alternate\ntext. A notable example is the LAION dataset, used by Stable Diffusion and\nother models. In this work we observe that these captions are often of low\nquality, and argue that this significantly affects the model's capability to\nunderstand nuanced semantics in the textual prompts. We show that by relabeling\nthe corpus with a specialized automatic captioning model and training a\ntext-to-image model on the recaptioned dataset, the model benefits\nsubstantially across the board. First, in overall image quality: e.g. FID 14.84\nvs. the baseline of 17.87, and 64.3% improvement in faithful image generation\naccording to human evaluation. Second, in semantic alignment, e.g. semantic\nobject accuracy 84.34 vs. 78.90, counting alignment errors 1.32 vs. 1.44 and\npositional alignment 62.42 vs. 57.60. We analyze various ways to relabel the\ncorpus and provide evidence that this technique, which we call RECAP, both\nreduces the train-inference discrepancy and provides the model with more\ninformation per example, increasing sample efficiency and allowing the model to\nbetter understand the relations between captions and images.",
            "author": [
                "Eyal Segalis",
                "Dani Valevski",
                "Danny Lumen",
                "Yossi Matias",
                "Yaniv Leviathan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16656v1",
                "http://arxiv.org/pdf/2310.16656v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16655v2",
            "title": "Towards Control-Centric Representations in Reinforcement Learning from\n  Images",
            "updated": "2023-10-27T10:14:16Z",
            "published": "2023-10-25T14:09:53Z",
            "summary": "Image-based Reinforcement Learning is a practical yet challenging task. A\nmajor hurdle lies in extracting control-centric representations while\ndisregarding irrelevant information. While approaches that follow the\nbisimulation principle exhibit the potential in learning state representations\nto address this issue, they still grapple with the limited expressive capacity\nof latent dynamics and the inadaptability to sparse reward environments. To\naddress these limitations, we introduce ReBis, which aims to capture\ncontrol-centric information by integrating reward-free control information\nalongside reward-specific knowledge. ReBis utilizes a transformer architecture\nto implicitly model the dynamics and incorporates block-wise masking to\neliminate spatiotemporal redundancy. Moreover, ReBis combines\nbisimulation-based loss with asymmetric reconstruction loss to prevent feature\ncollapse in environments with sparse rewards. Empirical studies on two large\nbenchmarks, including Atari games and DeepMind Control Suit, demonstrate that\nReBis has superior performance compared to existing methods, proving its\neffectiveness.",
            "author": [
                "Chen Liu",
                "Hongyu Zang",
                "Xin Li",
                "Yong Heng",
                "Yifei Wang",
                "Zhen Fang",
                "Yisen Wang",
                "Mingzhong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16655v2",
                "http://arxiv.org/pdf/2310.16655v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16653v1",
            "title": "Adaptive importance sampling for heavy-tailed distributions via\n  $\u03b1$-divergence minimization",
            "updated": "2023-10-25T14:07:08Z",
            "published": "2023-10-25T14:07:08Z",
            "summary": "Adaptive importance sampling (AIS) algorithms are widely used to approximate\nexpectations with respect to complicated target probability distributions. When\nthe target has heavy tails, existing AIS algorithms can provide inconsistent\nestimators or exhibit slow convergence, as they often neglect the target's tail\nbehaviour. To avoid this pitfall, we propose an AIS algorithm that approximates\nthe target by Student-t proposal distributions. We adapt location and scale\nparameters by matching the escort moments - which are defined even for\nheavy-tailed distributions - of the target and the proposal. These updates\nminimize the $\\alpha$-divergence between the target and the proposal, thereby\nconnecting with variational inference. We then show that the\n$\\alpha$-divergence can be approximated by a generalized notion of effective\nsample size and leverage this new perspective to adapt the tail parameter with\nBayesian optimization. We demonstrate the efficacy of our approach through\napplications to synthetic targets and a Bayesian Student-t regression task on a\nreal example with clinical trial data.",
            "author": [
                "Thomas Guilmeau",
                "Nicola Branchini",
                "Emilie Chouzenoux",
                "V\u00edctor Elvira"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16653v1",
                "http://arxiv.org/pdf/2310.16653v1"
            ],
            "primary_category": "stat.CO",
            "category": [
                "stat.CO",
                "stat.ME",
                "stat.ML",
                "62-08"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16652v1",
            "title": "How Robust is Federated Learning to Communication Error? A Comparison\n  Study Between Uplink and Downlink Channels",
            "updated": "2023-10-25T14:03:11Z",
            "published": "2023-10-25T14:03:11Z",
            "summary": "Because of its privacy-preserving capability, federated learning (FL) has\nattracted significant attention from both academia and industry. However, when\nbeing implemented over wireless networks, it is not clear how much\ncommunication error can be tolerated by FL. This paper investigates the\nrobustness of FL to the uplink and downlink communication error. Our\ntheoretical analysis reveals that the robustness depends on two critical\nparameters, namely the number of clients and the numerical range of model\nparameters. It is also shown that the uplink communication in FL can tolerate a\nhigher bit error rate (BER) than downlink communication, and this difference is\nquantified by a proposed formula. The findings and theoretical analyses are\nfurther validated by extensive experiments.",
            "author": [
                "Linping Qu",
                "Shenghui Song",
                "Chi-Ying Tsui",
                "Yuyi Mao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16652v1",
                "http://arxiv.org/pdf/2310.16652v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16648v1",
            "title": "Posterior Consistency for Missing Data in Variational Autoencoders",
            "updated": "2023-10-25T13:56:02Z",
            "published": "2023-10-25T13:56:02Z",
            "summary": "We consider the problem of learning Variational Autoencoders (VAEs), i.e., a\ntype of deep generative model, from data with missing values. Such data is\nomnipresent in real-world applications of machine learning because complete\ndata is often impossible or too costly to obtain. We particularly focus on\nimproving a VAE's amortized posterior inference, i.e., the encoder, which in\nthe case of missing data can be susceptible to learning inconsistent posterior\ndistributions regarding the missingness. To this end, we provide a formal\ndefinition of posterior consistency and propose an approach for regularizing an\nencoder's posterior distribution which promotes this consistency. We observe\nthat the proposed regularization suggests a different training objective than\nthat typically considered in the literature when facing missing values.\nFurthermore, we empirically demonstrate that our regularization leads to\nimproved performance in missing value settings in terms of reconstruction\nquality and downstream tasks utilizing uncertainty in the latent space. This\nimproved performance can be observed for many classes of VAEs including VAEs\nequipped with normalizing flows.",
            "author": [
                "Timur Sudak",
                "Sebastian Tschiatschek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16648v1",
                "http://arxiv.org/pdf/2310.16648v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16647v1",
            "title": "Achieving Constraints in Neural Networks: A Stochastic Augmented\n  Lagrangian Approach",
            "updated": "2023-10-25T13:55:35Z",
            "published": "2023-10-25T13:55:35Z",
            "summary": "Regularizing Deep Neural Networks (DNNs) is essential for improving\ngeneralizability and preventing overfitting. Fixed penalty methods, though\ncommon, lack adaptability and suffer from hyperparameter sensitivity. In this\npaper, we propose a novel approach to DNN regularization by framing the\ntraining process as a constrained optimization problem. Where the data fidelity\nterm is the minimization objective and the regularization terms serve as\nconstraints. Then, we employ the Stochastic Augmented Lagrangian (SAL) method\nto achieve a more flexible and efficient regularization mechanism. Our approach\nextends beyond black-box regularization, demonstrating significant improvements\nin white-box models, where weights are often subject to hard constraints to\nensure interpretability. Experimental results on image-based classification on\nMNIST, CIFAR10, and CIFAR100 datasets validate the effectiveness of our\napproach. SAL consistently achieves higher Accuracy while also achieving better\nconstraint satisfaction, thus showcasing its potential for optimizing DNNs\nunder constrained settings.",
            "author": [
                "Diogo Lavado",
                "Cl\u00e1udia Soares",
                "Alessandra Micheletti"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16647v1",
                "http://arxiv.org/pdf/2310.16647v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16646v1",
            "title": "Model predictive control-based value estimation for efficient\n  reinforcement learning",
            "updated": "2023-10-25T13:55:14Z",
            "published": "2023-10-25T13:55:14Z",
            "summary": "Reinforcement learning suffers from limitations in real practices primarily\ndue to the numbers of required interactions with virtual environments. It\nresults in a challenging problem that we are implausible to obtain an optimal\nstrategy only with a few attempts for many learning method. Hereby, we design\nan improved reinforcement learning method based on model predictive control\nthat models the environment through a data-driven approach. Based on learned\nenvironmental model, it performs multi-step prediction to estimate the value\nfunction and optimize the policy. The method demonstrates higher learning\nefficiency, faster convergent speed of strategies tending to the optimal value,\nand fewer sample capacity space required by experience replay buffers.\nExperimental results, both in classic databases and in a dynamic obstacle\navoidance scenario for unmanned aerial vehicle, validate the proposed\napproaches.",
            "author": [
                "Qizhen Wu",
                "Kexin Liu",
                "Lei Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16646v1",
                "http://arxiv.org/pdf/2310.16646v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16640v1",
            "title": "EmoCLIP: A Vision-Language Method for Zero-Shot Video Facial Expression\n  Recognition",
            "updated": "2023-10-25T13:43:36Z",
            "published": "2023-10-25T13:43:36Z",
            "summary": "Facial Expression Recognition (FER) is a crucial task in affective computing,\nbut its conventional focus on the seven basic emotions limits its applicability\nto the complex and expanding emotional spectrum. To address the issue of new\nand unseen emotions present in dynamic in-the-wild FER, we propose a novel\nvision-language model that utilises sample-level text descriptions (i.e.\ncaptions of the context, expressions or emotional cues) as natural language\nsupervision, aiming to enhance the learning of rich latent representations, for\nzero-shot classification. To test this, we evaluate using zero-shot\nclassification of the model trained on sample-level descriptions on four\npopular dynamic FER datasets. Our findings show that this approach yields\nsignificant improvements when compared to baseline methods. Specifically, for\nzero-shot video FER, we outperform CLIP by over 10\\% in terms of Weighted\nAverage Recall and 5\\% in terms of Unweighted Average Recall on several\ndatasets. Furthermore, we evaluate the representations obtained from the\nnetwork trained using sample-level descriptions on the downstream task of\nmental health symptom estimation, achieving performance comparable or superior\nto state-of-the-art methods and strong agreement with human experts. Namely, we\nachieve a Pearson's Correlation Coefficient of up to 0.85 on schizophrenia\nsymptom severity estimation, which is comparable to human experts' agreement.\nThe code is publicly available at: https://github.com/NickyFot/EmoCLIP.",
            "author": [
                "Niki Maria Foteinopoulou",
                "Ioannis Patras"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16640v1",
                "http://arxiv.org/pdf/2310.16640v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16639v2",
            "title": "Driving through the Concept Gridlock: Unraveling Explainability\n  Bottlenecks in Automated Driving",
            "updated": "2023-10-26T15:15:39Z",
            "published": "2023-10-25T13:39:04Z",
            "summary": "Concept bottleneck models have been successfully used for explainable machine\nlearning by encoding information within the model with a set of human-defined\nconcepts. In the context of human-assisted or autonomous driving,\nexplainability models can help user acceptance and understanding of decisions\nmade by the autonomous vehicle, which can be used to rationalize and explain\ndriver or vehicle behavior. We propose a new approach using concept bottlenecks\nas visual features for control command predictions and explanations of user and\nvehicle behavior. We learn a human-understandable concept layer that we use to\nexplain sequential driving scenes while learning vehicle control commands. This\napproach can then be used to determine whether a change in a preferred gap or\nsteering commands from a human (or autonomous vehicle) is led by an external\nstimulus or change in preferences. We achieve competitive performance to latent\nvisual features while gaining interpretability within our model setup.",
            "author": [
                "Jessica Echterhoff",
                "An Yan",
                "Kyungtae Han",
                "Amr Abdelraouf",
                "Rohit Gupta",
                "Julian McAuley"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16639v2",
                "http://arxiv.org/pdf/2310.16639v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16638v2",
            "title": "Robust Covariate Shift Adaptation for Density-Ratio Estimation",
            "updated": "2023-10-26T02:53:20Z",
            "published": "2023-10-25T13:38:29Z",
            "summary": "Consider a scenario where we have access to train data with both covariates\nand outcomes while test data only contains covariates. In this scenario, our\nprimary aim is to predict the missing outcomes of the test data. With this\nobjective in mind, we train parametric regression models under a covariate\nshift, where covariate distributions are different between the train and test\ndata. For this problem, existing studies have proposed covariate shift\nadaptation via importance weighting using the density ratio. This approach\naverages the train data losses, each weighted by an estimated ratio of the\ncovariate densities between the train and test data, to approximate the\ntest-data risk. Although it allows us to obtain a test-data risk minimizer, its\nperformance heavily relies on the accuracy of the density ratio estimation.\nMoreover, even if the density ratio can be consistently estimated, the\nestimation errors of the density ratio also yield bias in the estimators of the\nregression model's parameters of interest. To mitigate these challenges, we\nintroduce a doubly robust estimator for covariate shift adaptation via\nimportance weighting, which incorporates an additional estimator for the\nregression function. Leveraging double machine learning techniques, our\nestimator reduces the bias arising from the density ratio estimation errors. We\ndemonstrate the asymptotic distribution of the regression parameter estimator.\nNotably, our estimator remains consistent if either the density ratio estimator\nor the regression function is consistent, showcasing its robustness against\npotential errors in density ratio estimation. Finally, we confirm the soundness\nof our proposed method via simulation studies.",
            "author": [
                "Masahiro Kato"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16638v2",
                "http://arxiv.org/pdf/2310.16638v2"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG",
                "econ.EM",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16869v2",
            "title": "Single-pixel imaging based on deep learning",
            "updated": "2023-11-17T03:33:15Z",
            "published": "2023-10-25T13:35:25Z",
            "summary": "Single-pixel imaging can collect images at the wavelengths outside the reach\nof conventional focal plane array detectors. However, the limited image quality\nand lengthy computational times for iterative reconstruction still impede the\npractical application of single-pixel imaging. Recently, deep learning has been\nintroduced into single-pixel imaging, which has attracted a lot of attention\ndue to its exceptional reconstruction quality, fast reconstruction speed, and\nthe potential to complete advanced sensing tasks without reconstructing images.\nHere, this advance is discussed and some opinions are offered. Firstly, based\non the fundamental principles of single-pixel imaging and deep learning, the\nprinciples and algorithms of single-pixel imaging based on deep learning are\ndescribed and analyzed. Subsequently, the implementation technologies of\nsingle-pixel imaging based on deep learning are reviewed. They are divided into\nsuper-resolution single-pixel imaging, single-pixel imaging through scattering\nmedia, photon-level single-pixel imaging, optical encryption based on\nsingle-pixel imaging, color single-pixel imaging, and image-free sensing\naccording to diverse application fields. Finally, major challenges and\ncorresponding feasible approaches are discussed, as well as more possible\napplications in the future.",
            "author": [
                "Kai Song",
                "Yaoxing Bian",
                "Ku Wu",
                "Hongrui Liu",
                "Shuangping Han",
                "Jiaming Li",
                "Jiazhao Tian",
                "Chengbin Qin",
                "Jianyong Hu",
                "Liantuan Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16869v2",
                "http://arxiv.org/pdf/2310.16869v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16633v1",
            "title": "Photometric Redshifts with Copula Entropy",
            "updated": "2023-10-25T13:33:40Z",
            "published": "2023-10-25T13:33:40Z",
            "summary": "In this paper we propose to apply copula entropy (CE) to photometric\nredshifts. CE is used to measure the correlations between photometric\nmeasurements and redshifts and then the measurements associated with high CEs\nare selected for predicting redshifts. We verified the proposed method on the\nSDSS quasar data. Experimental results show that the accuracy of photometric\nredshifts is improved with the selected measurements compared to the results\nwith all the measurements used in the experiments, especially for the samples\nwith high redshifts. The measurements selected with CE include luminosity\nmagnitude, the brightness in ultraviolet band with standard deviation, and the\nbrightness of the other four bands. Since CE is a rigorously defined\nmathematical concept, the models such derived is interpretable.",
            "author": [
                "Jian Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16633v1",
                "http://arxiv.org/pdf/2310.16633v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "astro-ph.CO",
                "astro-ph.IM",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16626v1",
            "title": "Scalable Causal Structure Learning via Amortized Conditional\n  Independence Testing",
            "updated": "2023-10-25T13:23:40Z",
            "published": "2023-10-25T13:23:40Z",
            "summary": "Controlling false positives (Type I errors) through statistical hypothesis\ntesting is a foundation of modern scientific data analysis. Existing causal\nstructure discovery algorithms either do not provide Type I error control or\ncannot scale to the size of modern scientific datasets. We consider a variant\nof the causal discovery problem with two sets of nodes, where the only edges of\ninterest form a bipartite causal subgraph between the sets. We develop Scalable\nCausal Structure Learning (SCSL), a method for causal structure discovery on\nbipartite subgraphs that provides Type I error control. SCSL recasts the\ndiscovery problem as a simultaneous hypothesis testing problem and uses\ndiscrete optimization over the set of possible confounders to obtain an upper\nbound on the test statistic for each edge. Semi-synthetic simulations\ndemonstrate that SCSL scales to handle graphs with hundreds of nodes while\nmaintaining error control and good power. We demonstrate the practical\napplicability of the method by applying it to a cancer dataset to reveal\nconnections between somatic gene mutations and metastases to different tissues.",
            "author": [
                "James Leiner",
                "Brian Manzo",
                "Aaditya Ramdas",
                "Wesley Tansey"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16626v1",
                "http://arxiv.org/pdf/2310.16626v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16624v1",
            "title": "Free-form Flows: Make Any Architecture a Normalizing Flow",
            "updated": "2023-10-25T13:23:08Z",
            "published": "2023-10-25T13:23:08Z",
            "summary": "Normalizing Flows are generative models that directly maximize the\nlikelihood. Previously, the design of normalizing flows was largely constrained\nby the need for analytical invertibility. We overcome this constraint by a\ntraining procedure that uses an efficient estimator for the gradient of the\nchange of variables formula. This enables any dimension-preserving neural\nnetwork to serve as a generative model through maximum likelihood training. Our\napproach allows placing the emphasis on tailoring inductive biases precisely to\nthe task at hand. Specifically, we achieve excellent results in molecule\ngeneration benchmarks utilizing $E(n)$-equivariant networks. Moreover, our\nmethod is competitive in an inverse problem benchmark, while employing\noff-the-shelf ResNet architectures.",
            "author": [
                "Felix Draxler",
                "Peter Sorrenson",
                "Lea Zimmermann",
                "Armand Rousselot",
                "Ullrich K\u00f6the"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16624v1",
                "http://arxiv.org/pdf/2310.16624v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16620v1",
            "title": "SpikingJelly: An open-source machine learning infrastructure platform\n  for spike-based intelligence",
            "updated": "2023-10-25T13:15:17Z",
            "published": "2023-10-25T13:15:17Z",
            "summary": "Spiking neural networks (SNNs) aim to realize brain-inspired intelligence on\nneuromorphic chips with high energy efficiency by introducing neural dynamics\nand spike properties. As the emerging spiking deep learning paradigm attracts\nincreasing interest, traditional programming frameworks cannot meet the demands\nof the automatic differentiation, parallel computation acceleration, and high\nintegration of processing neuromorphic datasets and deployment. In this work,\nwe present the SpikingJelly framework to address the aforementioned dilemma. We\ncontribute a full-stack toolkit for pre-processing neuromorphic datasets,\nbuilding deep SNNs, optimizing their parameters, and deploying SNNs on\nneuromorphic chips. Compared to existing methods, the training of deep SNNs can\nbe accelerated $11\\times$, and the superior extensibility and flexibility of\nSpikingJelly enable users to accelerate custom models at low costs through\nmultilevel inheritance and semiautomatic code generation. SpikingJelly paves\nthe way for synthesizing truly energy-efficient SNN-based machine intelligence\nsystems, which will enrich the ecology of neuromorphic computing.",
            "author": [
                "Wei Fang",
                "Yanqi Chen",
                "Jianhao Ding",
                "Zhaofei Yu",
                "Timoth\u00e9e Masquelier",
                "Ding Chen",
                "Liwei Huang",
                "Huihui Zhou",
                "Guoqi Li",
                "Yonghong Tian"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16620v1",
                "http://arxiv.org/pdf/2310.16620v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16616v1",
            "title": "Context Does Matter: End-to-end Panoptic Narrative Grounding with\n  Deformable Attention Refined Matching Network",
            "updated": "2023-10-25T13:12:39Z",
            "published": "2023-10-25T13:12:39Z",
            "summary": "Panoramic Narrative Grounding (PNG) is an emerging visual grounding task that\naims to segment visual objects in images based on dense narrative captions. The\ncurrent state-of-the-art methods first refine the representation of phrase by\naggregating the most similar $k$ image pixels, and then match the refined text\nrepresentations with the pixels of the image feature map to generate\nsegmentation results. However, simply aggregating sampled image features\nignores the contextual information, which can lead to phrase-to-pixel\nmis-match. In this paper, we propose a novel learning framework called\nDeformable Attention Refined Matching Network (DRMN), whose main idea is to\nbring deformable attention in the iterative process of feature learning to\nincorporate essential context information of different scales of pixels. DRMN\niteratively re-encodes pixels with the deformable attention network after\nupdating the feature representation of the top-$k$ most similar pixels. As\nsuch, DRMN can lead to accurate yet discriminative pixel representations,\npurify the top-$k$ most similar pixels, and consequently alleviate the\nphrase-to-pixel mis-match substantially.Experimental results show that our\nnovel design significantly improves the matching results between text phrases\nand image pixels. Concretely, DRMN achieves new state-of-the-art performance on\nthe PNG benchmark with an average recall improvement 3.5%. The codes are\navailable in: https://github.com/JaMesLiMers/DRMN.",
            "author": [
                "Yiming Lin",
                "Xiao-Bo Jin",
                "Qiufeng Wang",
                "Kaizhu Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16616v1",
                "http://arxiv.org/pdf/2310.16616v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16608v1",
            "title": "Performative Prediction: Past and Future",
            "updated": "2023-10-25T13:02:45Z",
            "published": "2023-10-25T13:02:45Z",
            "summary": "Predictions in the social world generally influence the target of prediction,\na phenomenon known as performativity. Self-fulfilling and self-negating\npredictions are examples of performativity. Of fundamental importance to\neconomics, finance, and the social sciences, the notion has been absent from\nthe development of machine learning. In machine learning applications,\nperformativity often surfaces as distribution shift. A predictive model\ndeployed on a digital platform, for example, influences consumption and thereby\nchanges the data-generating distribution. We survey the recently founded area\nof performative prediction that provides a definition and conceptual framework\nto study performativity in machine learning. A consequence of performative\nprediction is a natural equilibrium notion that gives rise to new optimization\nchallenges. Another consequence is a distinction between learning and steering,\ntwo mechanisms at play in performative prediction. The notion of steering is in\nturn intimately related to questions of power in digital markets. We review the\nnotion of performative power that gives an answer to the question how much a\nplatform can steer participants through its predictions. We end on a discussion\nof future directions, such as the role that performativity plays in contesting\nalgorithmic systems.",
            "author": [
                "Moritz Hardt",
                "Celestine Mendler-D\u00fcnner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16608v1",
                "http://arxiv.org/pdf/2310.16608v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16867v1",
            "title": "An Explainable Deep Learning-Based Method For Schizophrenia Diagnosis\n  Using Generative Data-Augmentation",
            "updated": "2023-10-25T12:55:16Z",
            "published": "2023-10-25T12:55:16Z",
            "summary": "In this study, we leverage a deep learning-based method for the automatic\ndiagnosis of schizophrenia using EEG brain recordings. This approach utilizes\ngenerative data augmentation, a powerful technique that enhances the accuracy\nof the diagnosis. To enable the utilization of time-frequency features,\nspectrograms were extracted from the raw signals. After exploring several\nneural network architectural setups, a proper convolutional neural network\n(CNN) was used for the initial diagnosis. Subsequently, using Wasserstein GAN\nwith Gradient Penalty (WGAN-GP) and Variational Autoencoder (VAE), two\ndifferent synthetic datasets were generated in order to augment the initial\ndataset and address the over-fitting issue. The augmented dataset using VAE\nachieved a 3.0\\% improvement in accuracy reaching up to 99.0\\% and yielded a\nlower loss value as well as a faster convergence. Finally, we addressed the\nlack of trust in black-box models using the Local Interpretable Model-agnostic\nExplanations (LIME) algorithm to determine the most important superpixels\n(frequencies) in the diagnosis process.",
            "author": [
                "Mehrshad Saadatinia",
                "Armin Salimi-Badr"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16867v1",
                "http://arxiv.org/pdf/2310.16867v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16606v2",
            "title": "AirFL-Mem: Improving Communication-Learning Trade-Off by Long-Term\n  Memory",
            "updated": "2023-10-28T02:44:22Z",
            "published": "2023-10-25T12:51:38Z",
            "summary": "Addressing the communication bottleneck inherent in federated learning (FL),\nover-the-air FL (AirFL) has emerged as a promising solution, which is, however,\nhampered by deep fading conditions. In this paper, we propose AirFL-Mem, a\nnovel scheme designed to mitigate the impact of deep fading by implementing a\n\\emph{long-term} memory mechanism. Convergence bounds are provided that account\nfor long-term memory, as well as for existing AirFL variants with short-term\nmemory, for general non-convex objectives. The theory demonstrates that\nAirFL-Mem exhibits the same convergence rate of federated averaging (FedAvg)\nwith ideal communication, while the performance of existing schemes is\ngenerally limited by error floors. The theoretical results are also leveraged\nto propose a novel convex optimization strategy for the truncation threshold\nused for power control in the presence of Rayleigh fading channels.\nExperimental results validate the analysis, confirming the advantages of a\nlong-term memory mechanism for the mitigation of deep fading.",
            "author": [
                "Haifeng Wen",
                "Hong Xing",
                "Osvaldo Simeone"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16606v2",
                "http://arxiv.org/pdf/2310.16606v2"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16602v1",
            "title": "Parcel loss prediction in last-mile delivery: deep and non-deep\n  approaches with insights from Explainable AI",
            "updated": "2023-10-25T12:46:34Z",
            "published": "2023-10-25T12:46:34Z",
            "summary": "Within the domain of e-commerce retail, an important objective is the\nreduction of parcel loss during the last-mile delivery phase. The\never-increasing availability of data, including product, customer, and order\ninformation, has made it possible for the application of machine learning in\nparcel loss prediction. However, a significant challenge arises from the\ninherent imbalance in the data, i.e., only a very low percentage of parcels are\nlost. In this paper, we propose two machine learning approaches, namely, Data\nBalance with Supervised Learning (DBSL) and Deep Hybrid Ensemble Learning\n(DHEL), to accurately predict parcel loss. The practical implication of such\npredictions is their value in aiding e-commerce retailers in optimizing\ninsurance-related decision-making policies. We conduct a comprehensive\nevaluation of the proposed machine learning models using one year data from\nBelgian shipments. The findings show that the DHEL model, which combines a\nfeed-forward autoencoder with a random forest, achieves the highest\nclassification performance. Furthermore, we use the techniques from Explainable\nAI (XAI) to illustrate how prediction models can be used in enhancing business\nprocesses and augmenting the overall value proposition for e-commerce retailers\nin the last mile delivery.",
            "author": [
                "Jan de Leeuw",
                "Zaharah Bukhsh",
                "Yingqian Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16602v1",
                "http://arxiv.org/pdf/2310.16602v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16600v2",
            "title": "Balancing central and marginal rejection when combining independent\n  significance tests",
            "updated": "2023-11-13T20:22:03Z",
            "published": "2023-10-25T12:45:49Z",
            "summary": "A common approach to evaluating the significance of a collection of\n$p$-values combines them with a pooling function, in particular when the\noriginal data are not available. These pooled $p$-values convert a sample of\n$p$-values into a single number which behaves like a univariate $p$-value. To\nclarify discussion of these functions, a telescoping series of alternative\nhypotheses are introduced that communicate the strength and prevalence of\nnon-null evidence in the $p$-values before general pooling formulae are\ndiscussed. A pattern noticed in the UMP pooled $p$-value for a particular\nalternative motivates the definition and discussion of central and marginal\nrejection levels at $\\alpha$. It is proven that central rejection is always\ngreater than or equal to marginal rejection, motivating a quotient to measure\nthe balance between the two for pooled $p$-values. A combining function based\non the $\\chi^2_{\\kappa}$ quantile transformation is proposed to control this\nquotient and shown to be robust to mis-specified parameters relative to the\nUMP. Different powers for different parameter settings motivate a map of\nplausible alternatives based on where this pooled $p$-value is minimized.",
            "author": [
                "Chris Salahub",
                "Wayne Oldford"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16600v2",
                "http://arxiv.org/pdf/2310.16600v2"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.AI",
                "cs.LG",
                "62-02",
                "G.3; I.2.m; J.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16597v2",
            "title": "Beyond IID weights: sparse and low-rank deep Neural Networks are also\n  Gaussian Processes",
            "updated": "2023-11-19T18:30:35Z",
            "published": "2023-10-25T12:38:36Z",
            "summary": "The infinitely wide neural network has been proven a useful and manageable\nmathematical model that enables the understanding of many phenomena appearing\nin deep learning. One example is the convergence of random deep networks to\nGaussian processes that allows a rigorous analysis of the way the choice of\nactivation function and network weights impacts the training dynamics. In this\npaper, we extend the seminal proof of Matthews et al. (2018) to a larger class\nof initial weight distributions (which we call PSEUDO-IID), including the\nestablished cases of IID and orthogonal weights, as well as the emerging\nlow-rank and structured sparse settings celebrated for their computational\nspeed-up benefits. We show that fully-connected and convolutional networks\ninitialized with PSEUDO-IID distributions are all effectively equivalent up to\ntheir variance. Using our results, one can identify the Edge-of-Chaos for a\nbroader class of neural networks and tune them at criticality in order to\nenhance their training.",
            "author": [
                "Thiziri Nait-Saada",
                "Alireza Naderi",
                "Jared Tanner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16597v2",
                "http://arxiv.org/pdf/2310.16597v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16592v1",
            "title": "Over-the-air Federated Policy Gradient",
            "updated": "2023-10-25T12:28:20Z",
            "published": "2023-10-25T12:28:20Z",
            "summary": "In recent years, over-the-air aggregation has been widely considered in\nlarge-scale distributed learning, optimization, and sensing. In this paper, we\npropose the over-the-air federated policy gradient algorithm, where all agents\nsimultaneously broadcast an analog signal carrying local information to a\ncommon wireless channel, and a central controller uses the received aggregated\nwaveform to update the policy parameters. We investigate the effect of noise\nand channel distortion on the convergence of the proposed algorithm, and\nestablish the complexities of communication and sampling for finding an\n$\\epsilon$-approximate stationary point. Finally, we present some simulation\nresults to show the effectiveness of the algorithm.",
            "author": [
                "Huiwen Yang",
                "Lingying Huang",
                "Subhrakanti Dey",
                "Ling Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16592v1",
                "http://arxiv.org/pdf/2310.16592v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16588v1",
            "title": "Multi-parallel-task Time-delay Reservoir Computing combining a Silicon\n  Microring with WDM",
            "updated": "2023-10-25T12:24:56Z",
            "published": "2023-10-25T12:24:56Z",
            "summary": "We numerically demonstrate a microring-based time-delay reservoir computing\nscheme that simultaneously solves three tasks involving time-series prediction,\nclassification, and wireless channel equalization. Each task performed on a\nwavelength-multiplexed channel achieves state-of-the-art performance with\noptimized power and frequency detuning.",
            "author": [
                "Bernard J. Giron Castro",
                "Christophe Peucheret",
                "Darko Zibar",
                "Francesco Da Ros"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16588v1",
                "http://arxiv.org/pdf/2310.16588v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.ET",
                "cs.LG",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16587v1",
            "title": "Adaptive Uncertainty Estimation via High-Dimensional Testing on Latent\n  Representations",
            "updated": "2023-10-25T12:22:18Z",
            "published": "2023-10-25T12:22:18Z",
            "summary": "Uncertainty estimation aims to evaluate the confidence of a trained deep\nneural network. However, existing uncertainty estimation approaches rely on\nlow-dimensional distributional assumptions and thus suffer from the high\ndimensionality of latent features. Existing approaches tend to focus on\nuncertainty on discrete classification probabilities, which leads to poor\ngeneralizability to uncertainty estimation for other tasks. Moreover, most of\nthe literature requires seeing the out-of-distribution (OOD) data in the\ntraining for better estimation of uncertainty, which limits the uncertainty\nestimation performance in practice because the OOD data are typically unseen.\nTo overcome these limitations, we propose a new framework using data-adaptive\nhigh-dimensional hypothesis testing for uncertainty estimation, which leverages\nthe statistical properties of the feature representations. Our method directly\noperates on latent representations and thus does not require retraining the\nfeature encoder under a modified objective. The test statistic relaxes the\nfeature distribution assumptions to high dimensionality, and it is more\ndiscriminative to uncertainties in the latent representations. We demonstrate\nthat encoding features with Bayesian neural networks can enhance testing\nperformance and lead to more accurate uncertainty estimation. We further\nintroduce a family-wise testing procedure to determine the optimal threshold of\nOOD detection, which minimizes the false discovery rate (FDR). Extensive\nexperiments validate the satisfactory performance of our framework on\nuncertainty estimation and task-specific prediction over a variety of\ncompetitors. The experiments on the OOD detection task also show satisfactory\nperformance of our method when the OOD data are unseen in the training. Codes\nare available at https://github.com/HKU-MedAI/bnn_uncertainty.",
            "author": [
                "Tsai Hor Chan",
                "Kin Wai Lau",
                "Jiajun Shen",
                "Guosheng Yin",
                "Lequan Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16587v1",
                "http://arxiv.org/pdf/2310.16587v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16584v1",
            "title": "Learning to Explain: A Model-Agnostic Framework for Explaining Black Box\n  Models",
            "updated": "2023-10-25T12:18:00Z",
            "published": "2023-10-25T12:18:00Z",
            "summary": "We present Learning to Explain (LTX), a model-agnostic framework designed for\nproviding post-hoc explanations for vision models. The LTX framework introduces\nan \"explainer\" model that generates explanation maps, highlighting the crucial\nregions that justify the predictions made by the model being explained. To\ntrain the explainer, we employ a two-stage process consisting of initial\npretraining followed by per-instance finetuning. During both stages of\ntraining, we utilize a unique configuration where we compare the explained\nmodel's prediction for a masked input with its original prediction for the\nunmasked input. This approach enables the use of a novel counterfactual\nobjective, which aims to anticipate the model's output using masked versions of\nthe input image. Importantly, the LTX framework is not restricted to a specific\nmodel architecture and can provide explanations for both Transformer-based and\nconvolutional models. Through our evaluations, we demonstrate that LTX\nsignificantly outperforms the current state-of-the-art in explainability across\nvarious metrics.",
            "author": [
                "Oren Barkan",
                "Yuval Asher",
                "Amit Eshel",
                "Yehonatan Elisha",
                "Noam Koenigstein"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16584v1",
                "http://arxiv.org/pdf/2310.16584v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16581v1",
            "title": "Hybrid Minimax-MCTS and Difficulty Adjustment for General Game Playing",
            "updated": "2023-10-25T12:13:40Z",
            "published": "2023-10-25T12:13:40Z",
            "summary": "Board games are a great source of entertainment for all ages, as they create\na competitive and engaging environment, as well as stimulating learning and\nstrategic thinking. It is common for digital versions of board games, as any\nother type of digital games, to offer the option to select the difficulty of\nthe game. This is usually done by customizing the search parameters of the AI\nalgorithm. However, this approach cannot be extended to General Game Playing\nagents, as different games might require different parametrization for each\ndifficulty level. In this paper, we present a general approach to implement an\nartificial intelligence opponent with difficulty levels for zero-sum games,\ntogether with a propose of a Minimax-MCTS hybrid algorithm, which combines the\nminimax search process with GGP aspects of MCTS. This approach was tested in\nour mobile application LoBoGames, an extensible board games platform, that is\nintended to have an broad catalog of games, with an emphasis on accessibility:\nthe platform is friendly to visually-impaired users, and is compatible with\nmore than 92\\% of Android devices. The tests in this work indicate that both\nthe hybrid Minimax-MCTS and the new difficulty adjustment system are promising\nGGP approaches that could be expanded in future work.",
            "author": [
                "Marco Ant\u00f4nio Athayde de Aguiar Vieira",
                "Anderson Rocha Tavares",
                "Renato Perez Ribas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16581v1",
                "http://arxiv.org/pdf/2310.16581v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16579v1",
            "title": "WSDMS: Debunk Fake News via Weakly Supervised Detection of Misinforming\n  Sentences with Contextualized Social Wisdom",
            "updated": "2023-10-25T12:06:55Z",
            "published": "2023-10-25T12:06:55Z",
            "summary": "In recent years, we witness the explosion of false and unconfirmed\ninformation (i.e., rumors) that went viral on social media and shocked the\npublic. Rumors can trigger versatile, mostly controversial stance expressions\namong social media users. Rumor verification and stance detection are different\nyet relevant tasks. Fake news debunking primarily focuses on determining the\ntruthfulness of news articles, which oversimplifies the issue as fake news\noften combines elements of both truth and falsehood. Thus, it becomes crucial\nto identify specific instances of misinformation within the articles. In this\nresearch, we investigate a novel task in the field of fake news debunking,\nwhich involves detecting sentence-level misinformation. One of the major\nchallenges in this task is the absence of a training dataset with\nsentence-level annotations regarding veracity. Inspired by the Multiple\nInstance Learning (MIL) approach, we propose a model called Weakly Supervised\nDetection of Misinforming Sentences (WSDMS). This model only requires bag-level\nlabels for training but is capable of inferring both sentence-level\nmisinformation and article-level veracity, aided by relevant social media\nconversations that are attentively contextualized with news sentences. We\nevaluate WSDMS on three real-world benchmarks and demonstrate that it\noutperforms existing state-of-the-art baselines in debunking fake news at both\nthe sentence and article levels.",
            "author": [
                "Ruichao Yang",
                "Wei Gao",
                "Jing Ma",
                "Hongzhan Lin",
                "Zhiwei Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16579v1",
                "http://arxiv.org/pdf/2310.16579v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16577v1",
            "title": "Mapping the magnetic field using a magnetometer array with noisy input\n  Gaussian process regression",
            "updated": "2023-10-25T12:00:45Z",
            "published": "2023-10-25T12:00:45Z",
            "summary": "Ferromagnetic materials in indoor environments give rise to disturbances in\nthe ambient magnetic field. Maps of these magnetic disturbances can be used for\nindoor localisation. A Gaussian process can be used to learn the spatially\nvarying magnitude of the magnetic field using magnetometer measurements and\ninformation about the position of the magnetometer. The position of the\nmagnetometer, however, is frequently only approximately known. This negatively\naffects the quality of the magnetic field map. In this paper, we investigate\nhow an array of magnetometers can be used to improve the quality of the\nmagnetic field map. The position of the array is approximately known, but the\nrelative locations of the magnetometers on the array are known. We include this\ninformation in a novel method to make a map of the ambient magnetic field. We\nstudy the properties of our method in simulation and show that our method\nimproves the map quality. We also demonstrate the efficacy of our method with\nexperimental data for the mapping of the magnetic field using an array of 30\nmagnetometers.",
            "author": [
                "Thomas Edridge",
                "Manon Kok"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16577v1",
                "http://arxiv.org/pdf/2310.16577v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16574v1",
            "title": "Large-scale magnetic field maps using structured kernel interpolation\n  for Gaussian process regression",
            "updated": "2023-10-25T11:58:18Z",
            "published": "2023-10-25T11:58:18Z",
            "summary": "We present a mapping algorithm to compute large-scale magnetic field maps in\nindoor environments with approximate Gaussian process (GP) regression. Mapping\nthe spatial variations in the ambient magnetic field can be used for\nlocalization algorithms in indoor areas. To compute such a map, GP regression\nis a suitable tool because it provides predictions of the magnetic field at new\nlocations along with uncertainty quantification. Because full GP regression has\na complexity that grows cubically with the number of data points,\napproximations for GPs have been extensively studied. In this paper, we build\non the structured kernel interpolation (SKI) framework, speeding up inference\nby exploiting efficient Krylov subspace methods. More specifically, we\nincorporate SKI with derivatives (D-SKI) into the scalar potential model for\nmagnetic field modeling and compute both predictive mean and covariance with a\ncomplexity that is linear in the data points. In our simulations, we show that\nour method achieves better accuracy than current state-of-the-art methods on\nmagnetic field maps with a growing mapping area. In our large-scale\nexperiments, we construct magnetic field maps from up to 40000\nthree-dimensional magnetic field measurements in less than two minutes on a\nstandard laptop.",
            "author": [
                "Clara Menzen",
                "Marnix Fetter",
                "Manon Kok"
            ],
            "link": [
                "http://dx.doi.org/10.23919/FUSION52260.2023.10224210",
                "http://arxiv.org/abs/2310.16574v1",
                "http://arxiv.org/pdf/2310.16574v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16573v1",
            "title": "Adapt Anything: Tailor Any Image Classifiers across Domains And\n  Categories Using Text-to-Image Diffusion Models",
            "updated": "2023-10-25T11:58:14Z",
            "published": "2023-10-25T11:58:14Z",
            "summary": "We do not pursue a novel method in this paper, but aim to study if a modern\ntext-to-image diffusion model can tailor any task-adaptive image classifier\nacross domains and categories. Existing domain adaptive image classification\nworks exploit both source and target data for domain alignment so as to\ntransfer the knowledge learned from the labeled source data to the unlabeled\ntarget data. However, as the development of the text-to-image diffusion model,\nwe wonder if the high-fidelity synthetic data from the text-to-image generator\ncan serve as a surrogate of the source data in real world. In this way, we do\nnot need to collect and annotate the source data for each domain adaptation\ntask in a one-for-one manner. Instead, we utilize only one off-the-shelf\ntext-to-image model to synthesize images with category labels derived from the\ncorresponding text prompts, and then leverage the surrogate data as a bridge to\ntransfer the knowledge embedded in the task-agnostic text-to-image generator to\nthe task-oriented image classifier via domain adaptation. Such a one-for-all\nadaptation paradigm allows us to adapt anything in the world using only one\ntext-to-image generator as well as the corresponding unlabeled target data.\nExtensive experiments validate the feasibility of the proposed idea, which even\nsurpasses the state-of-the-art domain adaptation works using the source data\ncollected and annotated in real world.",
            "author": [
                "Weijie Chen",
                "Haoyu Wang",
                "Shicai Yang",
                "Lei Zhang",
                "Wei Wei",
                "Yanning Zhang",
                "Luojun Lin",
                "Di Xie",
                "Yueting Zhuang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16573v1",
                "http://arxiv.org/pdf/2310.16573v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16569v1",
            "title": "Flow-Attention-based Spatio-Temporal Aggregation Network for 3D Mask\n  Detection",
            "updated": "2023-10-25T11:54:21Z",
            "published": "2023-10-25T11:54:21Z",
            "summary": "Anti-spoofing detection has become a necessity for face recognition systems\ndue to the security threat posed by spoofing attacks. Despite great success in\ntraditional attacks, most deep-learning-based methods perform poorly in 3D\nmasks, which can highly simulate real faces in appearance and structure,\nsuffering generalizability insufficiency while focusing only on the spatial\ndomain with single frame input. This has been mitigated by the recent\nintroduction of a biomedical technology called rPPG (remote\nphotoplethysmography). However, rPPG-based methods are sensitive to noisy\ninterference and require at least one second (> 25 frames) of observation time,\nwhich induces high computational overhead. To address these challenges, we\npropose a novel 3D mask detection framework, called FASTEN\n(Flow-Attention-based Spatio-Temporal aggrEgation Network). We tailor the\nnetwork for focusing more on fine-grained details in large movements, which can\neliminate redundant spatio-temporal feature interference and quickly capture\nsplicing traces of 3D masks in fewer frames. Our proposed network contains\nthree key modules: 1) a facial optical flow network to obtain non-RGB\ninter-frame flow information; 2) flow attention to assign different\nsignificance to each frame; 3) spatio-temporal aggregation to aggregate\nhigh-level spatial features and temporal transition features. Through extensive\nexperiments, FASTEN only requires five frames of input and outperforms eight\ncompetitors for both intra-dataset and cross-dataset evaluations in terms of\nmultiple detection metrics. Moreover, FASTEN has been deployed in real-world\nmobile devices for practical 3D mask detection.",
            "author": [
                "Yuxin Cao",
                "Yian Li",
                "Yumeng Zhu",
                "Derui Wang",
                "Minhui Xue"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16569v1",
                "http://arxiv.org/pdf/2310.16569v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16566v1",
            "title": "Model-enhanced Contrastive Reinforcement Learning for Sequential\n  Recommendation",
            "updated": "2023-10-25T11:43:29Z",
            "published": "2023-10-25T11:43:29Z",
            "summary": "Reinforcement learning (RL) has been widely applied in recommendation systems\ndue to its potential in optimizing the long-term engagement of users. From the\nperspective of RL, recommendation can be formulated as a Markov decision\nprocess (MDP), where recommendation system (agent) can interact with users\n(environment) and acquire feedback (reward signals).However, it is impractical\nto conduct online interactions with the concern on user experience and\nimplementation complexity, and we can only train RL recommenders with offline\ndatasets containing limited reward signals and state transitions. Therefore,\nthe data sparsity issue of reward signals and state transitions is very severe,\nwhile it has long been overlooked by existing RL recommenders.Worse still, RL\nmethods learn through the trial-and-error mode, but negative feedback cannot be\nobtained in implicit feedback recommendation tasks, which aggravates the\noverestimation problem of offline RL recommender. To address these challenges,\nwe propose a novel RL recommender named model-enhanced contrastive\nreinforcement learning (MCRL). On the one hand, we learn a value function to\nestimate the long-term engagement of users, together with a conservative value\nlearning mechanism to alleviate the overestimation problem.On the other hand,\nwe construct some positive and negative state-action pairs to model the reward\nfunction and state transition function with contrastive learning to exploit the\ninternal structure information of MDP. Experiments demonstrate that the\nproposed method significantly outperforms existing offline RL and\nself-supervised RL methods with different representative backbone networks on\ntwo real-world datasets.",
            "author": [
                "Chengpeng Li",
                "Zhengyi Yang",
                "Jizhi Zhang",
                "Jiancan Wu",
                "Dingxian Wang",
                "Xiangnan He",
                "Xiang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16566v1",
                "http://arxiv.org/pdf/2310.16566v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16560v1",
            "title": "Label Propagation for Graph Label Noise",
            "updated": "2023-10-25T11:28:26Z",
            "published": "2023-10-25T11:28:26Z",
            "summary": "Label noise is a common challenge in large datasets, as it can significantly\ndegrade the generalization ability of deep neural networks. Most existing\nstudies focus on noisy labels in computer vision; however, graph models\nencompass both node features and graph topology as input, and become more\nsusceptible to label noise through message-passing mechanisms. Recently, only a\nfew works have been proposed to tackle the label noise on graphs. One major\nlimitation is that they assume the graph is homophilous and the labels are\nsmoothly distributed. Nevertheless, real-world graphs may contain varying\ndegrees of heterophily or even be heterophily-dominated, leading to the\ninadequacy of current methods. In this paper, we study graph label noise in the\ncontext of arbitrary heterophily, with the aim of rectifying noisy labels and\nassigning labels to previously unlabeled nodes. We begin by conducting two\nempirical analyses to explore the impact of graph homophily on graph label\nnoise. Following observations, we propose a simple yet efficient algorithm,\ndenoted as LP4GLN. Specifically, LP4GLN is an iterative algorithm with three\nsteps: (1) reconstruct the graph to recover the homophily property, (2) utilize\nlabel propagation to rectify the noisy labels, (3) select high-confidence\nlabels to retain for the next iteration. By iterating these steps, we obtain a\nset of correct labels, ultimately achieving high accuracy in the node\nclassification task. The theoretical analysis is also provided to demonstrate\nits remarkable denoising \"effect\". Finally, we conduct experiments on 10\nbenchmark datasets under varying graph heterophily levels and noise types,\ncomparing the performance of LP4GLN with 7 typical baselines. Our results\nillustrate the superior performance of the proposed LP4GLN.",
            "author": [
                "Yao Cheng",
                "Caihua Shan",
                "Yifei Shen",
                "Xiang Li",
                "Siqiang Luo",
                "Dongsheng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16560v1",
                "http://arxiv.org/pdf/2310.16560v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16555v2",
            "title": "Towards Information Theory-Based Discovery of Equivariances",
            "updated": "2023-11-14T11:37:40Z",
            "published": "2023-10-25T11:19:40Z",
            "summary": "The presence of symmetries imposes a stringent set of constraints on a\nsystem. This constrained structure allows intelligent agents interacting with\nsuch a system to drastically improve the efficiency of learning and\ngeneralization, through the internalisation of the system's symmetries into\ntheir information-processing. In parallel, principled models of\ncomplexity-constrained learning and behaviour make increasing use of\ninformation-theoretic methods. Here, we wish to marry these two perspectives\nand understand whether and in which form the information-theoretic lens can\n\"see\" the effect of symmetries of a system. For this purpose, we propose a\nnovel variant of the Information Bottleneck principle, which has served as a\nproductive basis for many principled studies of learning and\ninformation-constrained adaptive behaviour. We show (in the discrete case) that\nour approach formalises a certain duality between symmetry and information\nparsimony: namely, channel equivariances can be characterised by the optimal\nmutual information-preserving joint compression of the channel's input and\noutput. This information-theoretic treatment furthermore suggests a principled\nnotion of \"soft\" equivariance, whose \"coarseness\" is measured by the amount of\ninput-output mutual information preserved by the corresponding optimal\ncompression. This new notion offers a bridge between the field of bounded\nrationality and the study of symmetries in neural representations. The\nframework may also allow (exact and soft) equivariances to be automatically\ndiscovered.",
            "author": [
                "Hippolyte Charvin",
                "Nicola Catenacci Volpi",
                "Daniel Polani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16555v2",
                "http://arxiv.org/pdf/2310.16555v2"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.NE",
                "math.GR",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16552v1",
            "title": "DECWA : Density-Based Clustering using Wasserstein Distance",
            "updated": "2023-10-25T11:10:08Z",
            "published": "2023-10-25T11:10:08Z",
            "summary": "Clustering is a data analysis method for extracting knowledge by discovering\ngroups of data called clusters. Among these methods, state-of-the-art\ndensity-based clustering methods have proven to be effective for\narbitrary-shaped clusters. Despite their encouraging results, they suffer to\nfind low-density clusters, near clusters with similar densities, and\nhigh-dimensional data. Our proposals are a new characterization of clusters and\na new clustering algorithm based on spatial density and probabilistic approach.\nFirst of all, sub-clusters are built using spatial density represented as\nprobability density function ($p.d.f$) of pairwise distances between points. A\nmethod is then proposed to agglomerate similar sub-clusters by using both their\ndensity ($p.d.f$) and their spatial distance. The key idea we propose is to use\nthe Wasserstein metric, a powerful tool to measure the distance between $p.d.f$\nof sub-clusters. We show that our approach outperforms other state-of-the-art\ndensity-based clustering methods on a wide variety of datasets.",
            "author": [
                "Nabil El Malki",
                "Robin Cugny",
                "Olivier Teste",
                "Franck Ravat"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3340531.3412125",
                "http://arxiv.org/abs/2310.16552v1",
                "http://arxiv.org/pdf/2310.16552v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16550v1",
            "title": "Dynamic Processing Neural Network Architecture For Hearing Loss\n  Compensation",
            "updated": "2023-10-25T11:04:32Z",
            "published": "2023-10-25T11:04:32Z",
            "summary": "This paper proposes neural networks for compensating sensorineural hearing\nloss. The aim of the hearing loss compensation task is to transform a speech\nsignal to increase speech intelligibility after further processing by a person\nwith a hearing impairment, which is modeled by a hearing loss model. We propose\nan interpretable model called dynamic processing network, which has a structure\nsimilar to band-wise dynamic compressor. The network is differentiable, and\ntherefore allows to learn its parameters to maximize speech intelligibility.\nMore generic models based on convolutional layers were tested as well. The\nperformance of the tested architectures was assessed using spectro-temporal\nobjective index (STOI) with hearing-threshold noise and hearing aid speech\nintelligibility (HASPI) metrics. The dynamic processing network gave a\nsignificant improvement of STOI and HASPI in comparison to popular compressive\ngain prescription rule Camfit. A large enough convolutional network could\noutperform the interpretable model with the cost of larger computational load.\nFinally, a combination of the dynamic processing network with convolutional\nneural network gave the best results in terms of STOI and HASPI.",
            "author": [
                "Szymon Drgas",
                "Lars Bramsl\u00f8w",
                "Archontis Politis",
                "Gaurav Naithani",
                "Tuomas Virtanen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16550v1",
                "http://arxiv.org/pdf/2310.16550v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16547v1",
            "title": "AdaMEC: Towards a Context-Adaptive and Dynamically-Combinable DNN\n  Deployment Framework for Mobile Edge Computing",
            "updated": "2023-10-25T10:53:53Z",
            "published": "2023-10-25T10:53:53Z",
            "summary": "With the rapid development of deep learning, recent research on intelligent\nand interactive mobile applications (e.g., health monitoring, speech\nrecognition) has attracted extensive attention. And these applications\nnecessitate the mobile edge computing scheme, i.e., offloading partial\ncomputation from mobile devices to edge devices for inference acceleration and\ntransmission load reduction. The current practices have relied on collaborative\nDNN partition and offloading to satisfy the predefined latency requirements,\nwhich is intractable to adapt to the dynamic deployment context at runtime.\nAdaMEC, a context-adaptive and dynamically-combinable DNN deployment framework\nis proposed to meet these requirements for mobile edge computing, which\nconsists of three novel techniques. First, once-for-all DNN pre-partition\ndivides DNN at the primitive operator level and stores partitioned modules into\nexecutable files, defined as pre-partitioned DNN atoms. Second,\ncontext-adaptive DNN atom combination and offloading introduces a graph-based\ndecision algorithm to quickly search the suitable combination of atoms and\nadaptively make the offloading plan under dynamic deployment contexts. Third,\nruntime latency predictor provides timely latency feedback for DNN deployment\nconsidering both DNN configurations and dynamic contexts. Extensive experiments\ndemonstrate that AdaMEC outperforms state-of-the-art baselines in terms of\nlatency reduction by up to 62.14% and average memory saving by 55.21%.",
            "author": [
                "Bowen Pang",
                "Sicong Liu",
                "Hongli Wang",
                "Bin Guo",
                "Yuzhan Wang",
                "Hao Wang",
                "Zhenli Sheng",
                "Zhongyi Wang",
                "Zhiwen Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16547v1",
                "http://arxiv.org/pdf/2310.16547v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16546v3",
            "title": "Pitfall of Optimism: Distributional Reinforcement Learning by\n  Randomizing Risk Criterion",
            "updated": "2023-12-05T05:14:37Z",
            "published": "2023-10-25T10:53:04Z",
            "summary": "Distributional reinforcement learning algorithms have attempted to utilize\nestimated uncertainty for exploration, such as optimism in the face of\nuncertainty. However, using the estimated variance for optimistic exploration\nmay cause biased data collection and hinder convergence or performance. In this\npaper, we present a novel distributional reinforcement learning algorithm that\nselects actions by randomizing risk criterion to avoid one-sided tendency on\nrisk. We provide a perturbed distributional Bellman optimality operator by\ndistorting the risk measure and prove the convergence and optimality of the\nproposed method with the weaker contraction property. Our theoretical results\nsupport that the proposed method does not fall into biased exploration and is\nguaranteed to converge to an optimal return. Finally, we empirically show that\nour method outperforms other existing distribution-based algorithms in various\nenvironments including Atari 55 games.",
            "author": [
                "Taehyun Cho",
                "Seungyub Han",
                "Heesoo Lee",
                "Kyungjae Lee",
                "Jungwoo Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16546v3",
                "http://arxiv.org/pdf/2310.16546v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18366v1",
            "title": "A Multilingual Virtual Guide for Self-Attachment Technique",
            "updated": "2023-10-25T10:50:18Z",
            "published": "2023-10-25T10:50:18Z",
            "summary": "In this work, we propose a computational framework that leverages existing\nout-of-language data to create a conversational agent for the delivery of\nSelf-Attachment Technique (SAT) in Mandarin. Our framework does not require\nlarge-scale human translations, yet it achieves a comparable performance whilst\nalso maintaining safety and reliability. We propose two different methods of\naugmenting available response data through empathetic rewriting. We evaluate\nour chatbot against a previous, English-only SAT chatbot through non-clinical\nhuman trials (N=42), each lasting five days, and quantitatively show that we\nare able to attain a comparable level of performance to the English SAT\nchatbot. We provide qualitative analysis on the limitations of our study and\nsuggestions with the aim of guiding future improvements.",
            "author": [
                "Alicia Jiayun Law",
                "Ruoyu Hu",
                "Lisa Alazraki",
                "Anandha Gopalan",
                "Neophytos Polydorou",
                "Abbas Edalat"
            ],
            "link": [
                "http://dx.doi.org/10.1109/CogMI56440.2022.00025",
                "http://arxiv.org/abs/2310.18366v1",
                "http://arxiv.org/pdf/2310.18366v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16540v1",
            "title": "Dual Defense: Adversarial, Traceable, and Invisible Robust Watermarking\n  against Face Swapping",
            "updated": "2023-10-25T10:39:51Z",
            "published": "2023-10-25T10:39:51Z",
            "summary": "The malicious applications of deep forgery, represented by face swapping,\nhave introduced security threats such as misinformation dissemination and\nidentity fraud. While some research has proposed the use of robust watermarking\nmethods to trace the copyright of facial images for post-event traceability,\nthese methods cannot effectively prevent the generation of forgeries at the\nsource and curb their dissemination. To address this problem, we propose a\nnovel comprehensive active defense mechanism that combines traceability and\nadversariality, called Dual Defense. Dual Defense invisibly embeds a single\nrobust watermark within the target face to actively respond to sudden cases of\nmalicious face swapping. It disrupts the output of the face swapping model\nwhile maintaining the integrity of watermark information throughout the entire\ndissemination process. This allows for watermark extraction at any stage of\nimage tracking for traceability. Specifically, we introduce a watermark\nembedding network based on original-domain feature impersonation attack. This\nnetwork learns robust adversarial features of target facial images and embeds\nwatermarks, seeking a well-balanced trade-off between watermark invisibility,\nadversariality, and traceability through perceptual adversarial encoding\nstrategies. Extensive experiments demonstrate that Dual Defense achieves\noptimal overall defense success rates and exhibits promising universality in\nanti-face swapping tasks and dataset generalization ability. It maintains\nimpressive adversariality and traceability in both original and robust\nsettings, surpassing current forgery defense methods that possess only one of\nthese capabilities, including CMUA-Watermark, Anti-Forgery, FakeTagger, or PGD\nmethods.",
            "author": [
                "Yunming Zhang",
                "Dengpan Ye",
                "Caiyun Xie",
                "Long Tang",
                "Chuanxi Chen",
                "Ziyi Liu",
                "Jiacheng Deng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16540v1",
                "http://arxiv.org/pdf/2310.16540v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16538v1",
            "title": "FedTherapist: Mental Health Monitoring with User-Generated Linguistic\n  Expressions on Smartphones via Federated Learning",
            "updated": "2023-10-25T10:35:09Z",
            "published": "2023-10-25T10:35:09Z",
            "summary": "Psychiatrists diagnose mental disorders via the linguistic use of patients.\nStill, due to data privacy, existing passive mental health monitoring systems\nuse alternative features such as activity, app usage, and location via mobile\ndevices. We propose FedTherapist, a mobile mental health monitoring system that\nutilizes continuous speech and keyboard input in a privacy-preserving way via\nfederated learning. We explore multiple model designs by comparing their\nperformance and overhead for FedTherapist to overcome the complex nature of\non-device language model training on smartphones. We further propose a\nContext-Aware Language Learning (CALL) methodology to effectively utilize\nsmartphones' large and noisy text for mental health signal sensing. Our\nIRB-approved evaluation of the prediction of self-reported depression, stress,\nanxiety, and mood from 46 participants shows higher accuracy of FedTherapist\ncompared with the performance with non-language features, achieving 0.15 AUROC\nimprovement and 8.21% MAE reduction.",
            "author": [
                "Jaemin Shin",
                "Hyungjun Yoon",
                "Seungjoo Lee",
                "Sungjoon Park",
                "Yunxin Liu",
                "Jinho D. Choi",
                "Sung-Ju Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16538v1",
                "http://arxiv.org/pdf/2310.16538v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16532v1",
            "title": "Learning Robust Deep Visual Representations from EEG Brain Recordings",
            "updated": "2023-10-25T10:26:07Z",
            "published": "2023-10-25T10:26:07Z",
            "summary": "Decoding the human brain has been a hallmark of neuroscientists and\nArtificial Intelligence researchers alike. Reconstruction of visual images from\nbrain Electroencephalography (EEG) signals has garnered a lot of interest due\nto its applications in brain-computer interfacing. This study proposes a\ntwo-stage method where the first step is to obtain EEG-derived features for\nrobust learning of deep representations and subsequently utilize the learned\nrepresentation for image generation and classification. We demonstrate the\ngeneralizability of our feature extraction pipeline across three different\ndatasets using deep-learning architectures with supervised and contrastive\nlearning methods. We have performed the zero-shot EEG classification task to\nsupport the generalizability claim further. We observed that a subject\ninvariant linearly separable visual representation was learned using EEG data\nalone in an unimodal setting that gives better k-means accuracy as compared to\na joint representation learning between EEG and images. Finally, we propose a\nnovel framework to transform unseen images into the EEG space and reconstruct\nthem with approximation, showcasing the potential for image reconstruction from\nEEG signals. Our proposed image synthesis method from EEG shows 62.9% and\n36.13% inception score improvement on the EEGCVPR40 and the Thoughtviz\ndatasets, which is better than state-of-the-art performance in GAN.",
            "author": [
                "Prajwal Singh",
                "Dwip Dalal",
                "Gautam Vashishtha",
                "Krishna Miyapuram",
                "Shanmuganathan Raman"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16532v1",
                "http://arxiv.org/pdf/2310.16532v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16527v1",
            "title": "Enhancing Document Information Analysis with Multi-Task Pre-training: A\n  Robust Approach for Information Extraction in Visually-Rich Documents",
            "updated": "2023-10-25T10:22:30Z",
            "published": "2023-10-25T10:22:30Z",
            "summary": "This paper introduces a deep learning model tailored for document information\nanalysis, emphasizing document classification, entity relation extraction, and\ndocument visual question answering. The proposed model leverages\ntransformer-based models to encode all the information present in a document\nimage, including textual, visual, and layout information. The model is\npre-trained and subsequently fine-tuned for various document image analysis\ntasks. The proposed model incorporates three additional tasks during the\npre-training phase, including reading order identification of different layout\nsegments in a document image, layout segments categorization as per PubLayNet,\nand generation of the text sequence within a given layout segment (text block).\nThe model also incorporates a collective pre-training scheme where losses of\nall the tasks under consideration, including pre-training and fine-tuning tasks\nwith all datasets, are considered. Additional encoder and decoder blocks are\nadded to the RoBERTa network to generate results for all tasks. The proposed\nmodel achieved impressive results across all tasks, with an accuracy of 95.87%\non the RVL-CDIP dataset for document classification, F1 scores of 0.9306,\n0.9804, 0.9794, and 0.8742 on the FUNSD, CORD, SROIE, and Kleister-NDA datasets\nrespectively for entity relation extraction, and an ANLS score of 0.8468 on the\nDocVQA dataset for visual question answering. The results highlight the\neffectiveness of the proposed model in understanding and interpreting complex\ndocument layouts and content, making it a promising tool for document analysis\ntasks.",
            "author": [
                "Tofik Ali",
                "Partha Pratim Roy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16527v1",
                "http://arxiv.org/pdf/2310.16527v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16525v1",
            "title": "Cyclic Directed Probabilistic Graphical Model: A Proposal Based on\n  Structured Outcomes",
            "updated": "2023-10-25T10:19:03Z",
            "published": "2023-10-25T10:19:03Z",
            "summary": "In the process of building (structural learning) a probabilistic graphical\nmodel from a set of observed data, the directional, cyclic dependencies between\nthe random variables of the model are often found. Existing graphical models\nsuch as Bayesian and Markov networks can reflect such dependencies. However,\nthis requires complicating those models, such as adding additional variables or\ndividing the model graph into separate subgraphs. Herein, we describe a\nprobabilistic graphical model - probabilistic relation network - that allows\nthe direct capture of directional cyclic dependencies during structural\nlearning. This model is based on the simple idea that each sample of the\nobserved data can be represented by an arbitrary graph (structured outcome),\nwhich reflects the structure of the dependencies of the variables included in\nthe sample. Each of the outcomes contains only a part of the graphical model\nstructure; however, a complete graph of the probabilistic model is obtained by\ncombining different outcomes. Such a graph, unlike Bayesian and Markov\nnetworks, can be directed and can have cycles. We explored the full joint\ndistribution and conditional distribution and conditional independence\nproperties of variables in the proposed model. We defined the algorithms for\nconstructing of the model from the dataset and for calculating the conditional\nand full joint distributions. We also performed a numerical comparison with\nBayesian and Markov networks. This model does not violate the probability\naxioms, and it supports learning from observed data. Notably, it supports\nprobabilistic inference, making it a prospective tool in data analysis and in\nexpert and design-making applications.",
            "author": [
                "Oleksii Sirotkin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16525v1",
                "http://arxiv.org/pdf/2310.16525v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "62H22 (Primary) 05C38, 62H11 (Secondary)",
                "G.3; H.1.0"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16524v1",
            "title": "Can You Rely on Your Model Evaluation? Improving Model Evaluation with\n  Synthetic Test Data",
            "updated": "2023-10-25T10:18:44Z",
            "published": "2023-10-25T10:18:44Z",
            "summary": "Evaluating the performance of machine learning models on diverse and\nunderrepresented subgroups is essential for ensuring fairness and reliability\nin real-world applications. However, accurately assessing model performance\nbecomes challenging due to two main issues: (1) a scarcity of test data,\nespecially for small subgroups, and (2) possible distributional shifts in the\nmodel's deployment setting, which may not align with the available test data.\nIn this work, we introduce 3S Testing, a deep generative modeling framework to\nfacilitate model evaluation by generating synthetic test sets for small\nsubgroups and simulating distributional shifts. Our experiments demonstrate\nthat 3S Testing outperforms traditional baselines -- including real test data\nalone -- in estimating model performance on minority subgroups and under\nplausible distributional shifts. In addition, 3S offers intervals around its\nperformance estimates, exhibiting superior coverage of the ground truth\ncompared to existing approaches. Overall, these results raise the question of\nwhether we need a paradigm shift away from limited real test data towards\nsynthetic test data.",
            "author": [
                "Boris van Breugel",
                "Nabeel Seedat",
                "Fergus Imrie",
                "Mihaela van der Schaar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16524v1",
                "http://arxiv.org/pdf/2310.16524v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16520v1",
            "title": "Towards Self-Interpretable Graph-Level Anomaly Detection",
            "updated": "2023-10-25T10:10:07Z",
            "published": "2023-10-25T10:10:07Z",
            "summary": "Graph-level anomaly detection (GLAD) aims to identify graphs that exhibit\nnotable dissimilarity compared to the majority in a collection. However,\ncurrent works primarily focus on evaluating graph-level abnormality while\nfailing to provide meaningful explanations for the predictions, which largely\nlimits their reliability and application scope. In this paper, we investigate a\nnew challenging problem, explainable GLAD, where the learning objective is to\npredict the abnormality of each graph sample with corresponding explanations,\ni.e., the vital subgraph that leads to the predictions. To address this\nchallenging problem, we propose a Self-Interpretable Graph aNomaly dETection\nmodel (SIGNET for short) that detects anomalous graphs as well as generates\ninformative explanations simultaneously. Specifically, we first introduce the\nmulti-view subgraph information bottleneck (MSIB) framework, serving as the\ndesign basis of our self-interpretable GLAD approach. This way SIGNET is able\nto not only measure the abnormality of each graph based on cross-view mutual\ninformation but also provide informative graph rationales by extracting\nbottleneck subgraphs from the input graph and its dual hypergraph in a\nself-supervised way. Extensive experiments on 16 datasets demonstrate the\nanomaly detection capability and self-interpretability of SIGNET.",
            "author": [
                "Yixin Liu",
                "Kaize Ding",
                "Qinghua Lu",
                "Fuyi Li",
                "Leo Yu Zhang",
                "Shirui Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16520v1",
                "http://arxiv.org/pdf/2310.16520v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16516v1",
            "title": "Particle-based Variational Inference with Generalized Wasserstein\n  Gradient Flow",
            "updated": "2023-10-25T10:05:42Z",
            "published": "2023-10-25T10:05:42Z",
            "summary": "Particle-based variational inference methods (ParVIs) such as Stein\nvariational gradient descent (SVGD) update the particles based on the\nkernelized Wasserstein gradient flow for the Kullback-Leibler (KL) divergence.\nHowever, the design of kernels is often non-trivial and can be restrictive for\nthe flexibility of the method. Recent works show that functional gradient flow\napproximations with quadratic form regularization terms can improve\nperformance. In this paper, we propose a ParVI framework, called generalized\nWasserstein gradient descent (GWG), based on a generalized Wasserstein gradient\nflow of the KL divergence, which can be viewed as a functional gradient method\nwith a broader class of regularizers induced by convex functions. We show that\nGWG exhibits strong convergence guarantees. We also provide an adaptive version\nthat automatically chooses Wasserstein metric to accelerate convergence. In\nexperiments, we demonstrate the effectiveness and efficiency of the proposed\nframework on both simulated and real data problems.",
            "author": [
                "Ziheng Cheng",
                "Shiyue Zhang",
                "Longlin Yu",
                "Cheng Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16516v1",
                "http://arxiv.org/pdf/2310.16516v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16506v2",
            "title": "Identifying Reasons for Bias: An Argumentation-Based Approach",
            "updated": "2023-10-26T21:35:42Z",
            "published": "2023-10-25T09:47:15Z",
            "summary": "As algorithmic decision-making systems become more prevalent in society,\nensuring the fairness of these systems is becoming increasingly important.\nWhilst there has been substantial research in building fair algorithmic\ndecision-making systems, the majority of these methods require access to the\ntraining data, including personal characteristics, and are not transparent\nregarding which individuals are classified unfairly. In this paper, we propose\na novel model-agnostic argumentation-based method to determine why an\nindividual is classified differently in comparison to similar individuals. Our\nmethod uses a quantitative argumentation framework to represent attribute-value\npairs of an individual and of those similar to them, and uses a well-known\nsemantics to identify the attribute-value pairs in the individual contributing\nmost to their different classification. We evaluate our method on two datasets\ncommonly used in the fairness literature and illustrate its effectiveness in\nthe identification of bias.",
            "author": [
                "Madeleine Waller",
                "Odinaldo Rodrigues",
                "Oana Cocarascu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16506v2",
                "http://arxiv.org/pdf/2310.16506v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16502v2",
            "title": "Assessing the overall and partial causal well-specification of nonlinear\n  additive noise models",
            "updated": "2023-10-26T12:29:40Z",
            "published": "2023-10-25T09:44:16Z",
            "summary": "We propose a method to detect model misspecifications in nonlinear causal\nadditive and potentially heteroscedastic noise models. We aim to identify\npredictor variables for which we can infer the causal effect even in cases of\nsuch misspecification. We develop a general framework based on knowledge of the\nmultivariate observational data distribution and we then propose an algorithm\nfor finite sample data, discuss its asymptotic properties, and illustrate its\nperformance on simulated and real data.",
            "author": [
                "Christoph Schultheiss",
                "Peter B\u00fchlmann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16502v2",
                "http://arxiv.org/pdf/2310.16502v2"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12861v1",
            "title": "A versatile circuit for emulating active biological dendrites applied to\n  sound localisation and neuron imitation",
            "updated": "2023-10-25T09:42:24Z",
            "published": "2023-10-25T09:42:24Z",
            "summary": "Sophisticated machine learning struggles to transition onto battery-operated\ndevices due to the high-power consumption of neural networks. Researchers have\nturned to neuromorphic engineering, inspired by biological neural networks, for\nmore efficient solutions. While previous research focused on artificial neurons\nand synapses, an essential component has been overlooked: dendrites. Dendrites\ntransmit inputs from synapses to the neuron's soma, applying both passive and\nactive transformations. However, neuromorphic circuits replace these\nsophisticated computational channels with metallic interconnects. In this\nstudy, we introduce a versatile circuit that emulates a segment of a dendrite\nwhich exhibits gain, introduces delays, and performs integration. We show how\nsound localisation - a biological example of dendritic computation - is not\npossible with the existing passive dendrite circuits but can be achieved using\nthis proposed circuit. We also find that dendrites can form bursting neurons.\nThis significant discovery suggests the potential to fabricate neural networks\nsolely comprised of dendrite circuits.",
            "author": [
                "Daniel John Mannion"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12861v1",
                "http://arxiv.org/pdf/2311.12861v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.AI",
                "cs.ET",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16499v1",
            "title": "Data Optimization in Deep Learning: A Survey",
            "updated": "2023-10-25T09:33:57Z",
            "published": "2023-10-25T09:33:57Z",
            "summary": "Large-scale, high-quality data are considered an essential factor for the\nsuccessful application of many deep learning techniques. Meanwhile, numerous\nreal-world deep learning tasks still have to contend with the lack of\nsufficient amounts of high-quality data. Additionally, issues such as model\nrobustness, fairness, and trustworthiness are also closely related to training\ndata. Consequently, a huge number of studies in the existing literature have\nfocused on the data aspect in deep learning tasks. Some typical data\noptimization techniques include data augmentation, logit perturbation, sample\nweighting, and data condensation. These techniques usually come from different\ndeep learning divisions and their theoretical inspirations or heuristic\nmotivations may seem unrelated to each other. This study aims to organize a\nwide range of existing data optimization methodologies for deep learning from\nthe previous literature, and makes the effort to construct a comprehensive\ntaxonomy for them. The constructed taxonomy considers the diversity of split\ndimensions, and deep sub-taxonomies are constructed for each dimension. On the\nbasis of the taxonomy, connections among the extensive data optimization\nmethods for deep learning are built in terms of four aspects. We probe into\nrendering several promising and interesting future directions. The constructed\ntaxonomy and the revealed connections will enlighten the better understanding\nof existing methods and the design of novel data optimization techniques.\nFurthermore, our aspiration for this survey is to promote data optimization as\nan independent subdivision of deep learning. A curated, up-to-date list of\nresources related to data optimization in deep learning is available at\n\\url{https://github.com/YaoRujing/Data-Optimization}.",
            "author": [
                "Ou Wu",
                "Rujing Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16499v1",
                "http://arxiv.org/pdf/2310.16499v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16496v1",
            "title": "Citizen participation: crowd-sensed sustainable indoor location services",
            "updated": "2023-10-25T09:30:22Z",
            "published": "2023-10-25T09:30:22Z",
            "summary": "In the present era of sustainable innovation, the circular economy paradigm\ndictates the optimal use and exploitation of existing finite resources. At the\nsame time, the transition to smart infrastructures requires considerable\ninvestment in capital, resources and people. In this work, we present a general\nmachine learning approach for offering indoor location awareness without the\nneed to invest in additional and specialised hardware. We explore use cases\nwhere visitors equipped with their smart phone would interact with the\navailable WiFi infrastructure to estimate their location, since the indoor\nrequirement poses a limitation to standard GPS solutions. Results have shown\nthat the proposed approach achieves a less than 2m accuracy and the model is\nresilient even in the case where a substantial number of BSSIDs are dropped.",
            "author": [
                "Ioannis Nasios",
                "Konstantinos Vogklis",
                "Avleen Malhi",
                "Anastasia Vayona",
                "Panos Chatziadam",
                "Vasilis Katos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16496v1",
                "http://arxiv.org/pdf/2310.16496v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16494v1",
            "title": "Lang3DSG: Language-based contrastive pre-training for 3D Scene Graph\n  prediction",
            "updated": "2023-10-25T09:26:16Z",
            "published": "2023-10-25T09:26:16Z",
            "summary": "D scene graphs are an emerging 3D scene representation, that models both the\nobjects present in the scene as well as their relationships. However, learning\n3D scene graphs is a challenging task because it requires not only object\nlabels but also relationship annotations, which are very scarce in datasets.\nWhile it is widely accepted that pre-training is an effective approach to\nimprove model performance in low data regimes, in this paper, we find that\nexisting pre-training methods are ill-suited for 3D scene graphs. To solve this\nissue, we present the first language-based pre-training approach for 3D scene\ngraphs, whereby we exploit the strong relationship between scene graphs and\nlanguage. To this end, we leverage the language encoder of CLIP, a popular\nvision-language model, to distill its knowledge into our graph-based network.\nWe formulate a contrastive pre-training, which aligns text embeddings of\nrelationships (subject-predicate-object triplets) and predicted 3D graph\nfeatures. Our method achieves state-of-the-art results on the main semantic 3D\nscene graph benchmark by showing improved effectiveness over pre-training\nbaselines and outperforming all the existing fully supervised scene graph\nprediction methods by a significant margin. Furthermore, since our scene graph\nfeatures are language-aligned, it allows us to query the language space of the\nfeatures in a zero-shot manner. In this paper, we show an example of utilizing\nthis property of the features to predict the room type of a scene without\nfurther training.",
            "author": [
                "Sebastian Koch",
                "Pedro Hermosilla",
                "Narunas Vaskevicius",
                "Mirco Colosi",
                "Timo Ropinski"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16494v1",
                "http://arxiv.org/pdf/2310.16494v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16492v1",
            "title": "On the Powerfulness of Textual Outlier Exposure for Visual OoD Detection",
            "updated": "2023-10-25T09:19:45Z",
            "published": "2023-10-25T09:19:45Z",
            "summary": "Successful detection of Out-of-Distribution (OoD) data is becoming\nincreasingly important to ensure safe deployment of neural networks. One of the\nmain challenges in OoD detection is that neural networks output overconfident\npredictions on OoD data, make it difficult to determine OoD-ness of data solely\nbased on their predictions. Outlier exposure addresses this issue by\nintroducing an additional loss that encourages low-confidence predictions on\nOoD data during training. While outlier exposure has shown promising potential\nin improving OoD detection performance, all previous studies on outlier\nexposure have been limited to utilizing visual outliers. Drawing inspiration\nfrom the recent advancements in vision-language pre-training, this paper\nventure out to the uncharted territory of textual outlier exposure. First, we\nuncover the benefits of using textual outliers by replacing real or virtual\noutliers in the image-domain with textual equivalents. Then, we propose various\nways of generating preferable textual outliers. Our extensive experiments\ndemonstrate that generated textual outliers achieve competitive performance on\nlarge-scale OoD and hard OoD benchmarks. Furthermore, we conduct empirical\nanalyses of textual outliers to provide primary criteria for designing\nadvantageous textual outliers: near-distribution, descriptiveness, and\ninclusion of visual semantics.",
            "author": [
                "Sangha Park",
                "Jisoo Mok",
                "Dahuin Jung",
                "Saehyung Lee",
                "Sungroh Yoon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16492v1",
                "http://arxiv.org/pdf/2310.16492v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16491v1",
            "title": "TSONN: Time-stepping-oriented neural network for solving partial\n  differential equations",
            "updated": "2023-10-25T09:19:40Z",
            "published": "2023-10-25T09:19:40Z",
            "summary": "Deep neural networks (DNNs), especially physics-informed neural networks\n(PINNs), have recently become a new popular method for solving forward and\ninverse problems governed by partial differential equations (PDEs). However,\nthese methods still face challenges in achieving stable training and obtaining\ncorrect results in many problems, since minimizing PDE residuals with PDE-based\nsoft constraint make the problem ill-conditioned. Different from all existing\nmethods that directly minimize PDE residuals, this work integrates\ntime-stepping method with deep learning, and transforms the original\nill-conditioned optimization problem into a series of well-conditioned\nsub-problems over given pseudo time intervals. The convergence of model\ntraining is significantly improved by following the trajectory of the pseudo\ntime-stepping process, yielding a robust optimization-based PDE solver. Our\nresults show that the proposed method achieves stable training and correct\nresults in many problems that standard PINNs fail to solve, requiring only a\nsimple modification on the loss function. In addition, we demonstrate several\nnovel properties and advantages of time-stepping methods within the framework\nof neural network-based optimization approach, in comparison to traditional\ngrid-based numerical method. Specifically, explicit scheme allows significantly\nlarger time step, while implicit scheme can be implemented as straightforwardly\nas explicit scheme.",
            "author": [
                "Wenbo Cao",
                "Weiwei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16491v1",
                "http://arxiv.org/pdf/2310.16491v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16487v1",
            "title": "Hyperparameter Optimization for Multi-Objective Reinforcement Learning",
            "updated": "2023-10-25T09:17:25Z",
            "published": "2023-10-25T09:17:25Z",
            "summary": "Reinforcement learning (RL) has emerged as a powerful approach for tackling\ncomplex problems. The recent introduction of multi-objective reinforcement\nlearning (MORL) has further expanded the scope of RL by enabling agents to make\ntrade-offs among multiple objectives. This advancement not only has broadened\nthe range of problems that can be tackled but also created numerous\nopportunities for exploration and advancement. Yet, the effectiveness of RL\nagents heavily relies on appropriately setting their hyperparameters. In\npractice, this task often proves to be challenging, leading to unsuccessful\ndeployments of these techniques in various instances. Hence, prior research has\nexplored hyperparameter optimization in RL to address this concern.\n  This paper presents an initial investigation into the challenge of\nhyperparameter optimization specifically for MORL. We formalize the problem,\nhighlight its distinctive challenges, and propose a systematic methodology to\naddress it. The proposed methodology is applied to a well-known environment\nusing a state-of-the-art MORL algorithm, and preliminary results are reported.\nOur findings indicate that the proposed methodology can effectively provide\nhyperparameter configurations that significantly enhance the performance of\nMORL agents. Furthermore, this study identifies various future research\nopportunities to further advance the field of hyperparameter optimization for\nMORL.",
            "author": [
                "Florian Felten",
                "Daniel Gareev",
                "El-Ghazali Talbi",
                "Gr\u00e9goire Danoy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16487v1",
                "http://arxiv.org/pdf/2310.16487v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16485v1",
            "title": "A Comprehensive Python Library for Deep Learning-Based Event Detection\n  in Multivariate Time Series Data and Information Retrieval in NLP",
            "updated": "2023-10-25T09:13:19Z",
            "published": "2023-10-25T09:13:19Z",
            "summary": "Event detection in time series data is crucial in various domains, including\nfinance, healthcare, cybersecurity, and science. Accurately identifying events\nin time series data is vital for making informed decisions, detecting\nanomalies, and predicting future trends. Despite extensive research exploring\ndiverse methods for event detection in time series, with deep learning\napproaches being among the most advanced, there is still room for improvement\nand innovation in this field. In this paper, we present a new deep learning\nsupervised method for detecting events in multivariate time series data. Our\nmethod combines four distinct novelties compared to existing deep-learning\nsupervised methods. Firstly, it is based on regression instead of binary\nclassification. Secondly, it does not require labeled datasets where each point\nis labeled; instead, it only requires reference events defined as time points\nor intervals of time. Thirdly, it is designed to be robust by using a stacked\nensemble learning meta-model that combines deep learning models, ranging from\nclassic feed-forward neural networks (FFNs) to state-of-the-art architectures\nlike transformers. This ensemble approach can mitigate individual model\nweaknesses and biases, resulting in more robust predictions. Finally, to\nfacilitate practical implementation, we have developed a Python package to\naccompany our proposed method. The package, called eventdetector-ts, can be\ninstalled through the Python Package Index (PyPI). In this paper, we present\nour method and provide a comprehensive guide on the usage of the package. We\nshowcase its versatility and effectiveness through different real-world use\ncases from natural language processing (NLP) to financial security domains.",
            "author": [
                "Menouar Azib",
                "Benjamin Renard",
                "Philippe Garnier",
                "Vincent G\u00e9not",
                "Nicolas Andr\u00e9"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16485v1",
                "http://arxiv.org/pdf/2310.16485v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17671v1",
            "title": "Transfer of Reinforcement Learning-Based Controllers from Model- to\n  Hardware-in-the-Loop",
            "updated": "2023-10-25T09:13:12Z",
            "published": "2023-10-25T09:13:12Z",
            "summary": "The process of developing control functions for embedded systems is\nresource-, time-, and data-intensive, often resulting in sub-optimal cost and\nsolutions approaches. Reinforcement Learning (RL) has great potential for\nautonomously training agents to perform complex control tasks with minimal\nhuman intervention. Due to costly data generation and safety constraints,\nhowever, its application is mostly limited to purely simulated domains. To use\nRL effectively in embedded system function development, the generated agents\nmust be able to handle real-world applications. In this context, this work\nfocuses on accelerating the training process of RL agents by combining Transfer\nLearning (TL) and X-in-the-Loop (XiL) simulation. For the use case of transient\nexhaust gas re-circulation control for an internal combustion engine, use of a\ncomputationally cheap Model-in-the-Loop (MiL) simulation is made to select a\nsuitable algorithm, fine-tune hyperparameters, and finally train candidate\nagents for the transfer. These pre-trained RL agents are then fine-tuned in a\nHardware-in-the-Loop (HiL) system via TL. The transfer revealed the need for\nadjusting the reward parameters when advancing to real hardware. Further, the\ncomparison between a purely HiL-trained and a transferred agent showed a\nreduction of training time by a factor of 5.9. The results emphasize the\nnecessity to train RL agents with real hardware, and demonstrate that the\nmaturity of the transferred policies affects both training time and\nperformance, highlighting the strong synergies between TL and XiL simulation.",
            "author": [
                "Mario Picerno",
                "Lucas Koch",
                "Kevin Badalian",
                "Marius Wegener",
                "Joschka Schaub",
                "Charles Robert Koch",
                "Jakob Andert"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17671v1",
                "http://arxiv.org/pdf/2310.17671v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16484v1",
            "title": "Subspace Chronicles: How Linguistic Information Emerges, Shifts and\n  Interacts during Language Model Training",
            "updated": "2023-10-25T09:09:55Z",
            "published": "2023-10-25T09:09:55Z",
            "summary": "Representational spaces learned via language modeling are fundamental to\nNatural Language Processing (NLP), however there has been limited understanding\nregarding how and when during training various types of linguistic information\nemerge and interact. Leveraging a novel information theoretic probing suite,\nwhich enables direct comparisons of not just task performance, but their\nrepresentational subspaces, we analyze nine tasks covering syntax, semantics\nand reasoning, across 2M pre-training steps and five seeds. We identify\ncritical learning phases across tasks and time, during which subspaces emerge,\nshare information, and later disentangle to specialize. Across these phases,\nsyntactic knowledge is acquired rapidly after 0.5% of full training. Continued\nperformance improvements primarily stem from the acquisition of open-domain\nknowledge, while semantics and reasoning tasks benefit from later boosts to\nlong-range contextualization and higher specialization. Measuring cross-task\nsimilarity further reveals that linguistically related tasks share information\nthroughout training, and do so more during the critical phase of learning than\nbefore or after. Our findings have implications for model interpretability,\nmulti-task learning, and learning from limited data.",
            "author": [
                "Max M\u00fcller-Eberstein",
                "Rob van der Goot",
                "Barbara Plank",
                "Ivan Titov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16484v1",
                "http://arxiv.org/pdf/2310.16484v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16483v1",
            "title": "Gramian Attention Heads are Strong yet Efficient Vision Learners",
            "updated": "2023-10-25T09:08:58Z",
            "published": "2023-10-25T09:08:58Z",
            "summary": "We introduce a novel architecture design that enhances expressiveness by\nincorporating multiple head classifiers (\\ie, classification heads) instead of\nrelying on channel expansion or additional building blocks. Our approach\nemploys attention-based aggregation, utilizing pairwise feature similarity to\nenhance multiple lightweight heads with minimal resource overhead. We compute\nthe Gramian matrices to reinforce class tokens in an attention layer for each\nhead. This enables the heads to learn more discriminative representations,\nenhancing their aggregation capabilities. Furthermore, we propose a learning\nalgorithm that encourages heads to complement each other by reducing\ncorrelation for aggregation. Our models eventually surpass state-of-the-art\nCNNs and ViTs regarding the accuracy-throughput trade-off on ImageNet-1K and\ndeliver remarkable performance across various downstream tasks, such as COCO\nobject instance segmentation, ADE20k semantic segmentation, and fine-grained\nvisual classification datasets. The effectiveness of our framework is\nsubstantiated by practical experimental results and further underpinned by\ngeneralization error bound. We release the code publicly at:\nhttps://github.com/Lab-LVM/imagenet-models.",
            "author": [
                "Jongbin Ryu",
                "Dongyoon Han",
                "Jongwoo Lim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16483v1",
                "http://arxiv.org/pdf/2310.16483v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12860v1",
            "title": "On the stability, correctness and plausibility of visual explanation\n  methods based on feature importance",
            "updated": "2023-10-25T08:59:21Z",
            "published": "2023-10-25T08:59:21Z",
            "summary": "In the field of Explainable AI, multiples evaluation metrics have been\nproposed in order to assess the quality of explanation methods w.r.t. a set of\ndesired properties. In this work, we study the articulation between the\nstability, correctness and plausibility of explanations based on feature\nimportance for image classifiers. We show that the existing metrics for\nevaluating these properties do not always agree, raising the issue of what\nconstitutes a good evaluation metric for explanations. Finally, in the\nparticular case of stability and correctness, we show the possible limitations\nof some evaluation metrics and propose new ones that take into account the\nlocal behaviour of the model under test.",
            "author": [
                "Romain Xu-Darme",
                "Jenny Benois-Pineau",
                "Romain Giot",
                "Georges Qu\u00e9not",
                "Zakaria Chihani",
                "Marie-Christine Rousset",
                "Alexey Zhukov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12860v1",
                "http://arxiv.org/pdf/2311.12860v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16477v1",
            "title": "Show from Tell: Audio-Visual Modelling in Clinical Settings",
            "updated": "2023-10-25T08:55:48Z",
            "published": "2023-10-25T08:55:48Z",
            "summary": "Auditory and visual signals usually present together and correlate with each\nother, not only in natural environments but also in clinical settings. However,\nthe audio-visual modelling in the latter case can be more challenging, due to\nthe different sources of audio/video signals and the noise (both signal-level\nand semantic-level) in auditory signals -- usually speech. In this paper, we\nconsider audio-visual modelling in a clinical setting, providing a solution to\nlearn medical representations that benefit various clinical tasks, without\nhuman expert annotation. A simple yet effective multi-modal self-supervised\nlearning framework is proposed for this purpose. The proposed approach is able\nto localise anatomical regions of interest during ultrasound imaging, with only\nspeech audio as a reference. Experimental evaluations on a large-scale clinical\nmulti-modal ultrasound video dataset show that the proposed self-supervised\nmethod learns good transferable anatomical representations that boost the\nperformance of automated downstream clinical tasks, even outperforming\nfully-supervised solutions.",
            "author": [
                "Jianbo Jiao",
                "Mohammad Alsharid",
                "Lior Drukker",
                "Aris T. Papageorghiou",
                "Andrew Zisserman",
                "J. Alison Noble"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16477v1",
                "http://arxiv.org/pdf/2310.16477v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16473v1",
            "title": "Symphony of experts: orchestration with adversarial insights in\n  reinforcement learning",
            "updated": "2023-10-25T08:53:51Z",
            "published": "2023-10-25T08:53:51Z",
            "summary": "Structured reinforcement learning leverages policies with advantageous\nproperties to reach better performance, particularly in scenarios where\nexploration poses challenges. We explore this field through the concept of\norchestration, where a (small) set of expert policies guides decision-making;\nthe modeling thereof constitutes our first contribution. We then establish\nvalue-functions regret bounds for orchestration in the tabular setting by\ntransferring regret-bound results from adversarial settings. We generalize and\nextend the analysis of natural policy gradient in Agarwal et al. [2021, Section\n5.3] to arbitrary adversarial aggregation strategies. We also extend it to the\ncase of estimated advantage functions, providing insights into sample\ncomplexity both in expectation and high probability. A key point of our\napproach lies in its arguably more transparent proofs compared to existing\nmethods. Finally, we present simulations for a stochastic matching toy model.",
            "author": [
                "Matthieu Jonckheere",
                "Chiara Mignacco",
                "Gilles Stoltz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16473v1",
                "http://arxiv.org/pdf/2310.16473v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16466v1",
            "title": "Learning Continuous Network Emerging Dynamics from Scarce Observations\n  via Data-Adaptive Stochastic Processes",
            "updated": "2023-10-25T08:44:05Z",
            "published": "2023-10-25T08:44:05Z",
            "summary": "Learning network dynamics from the empirical structure and spatio-temporal\nobservation data is crucial to revealing the interaction mechanisms of complex\nnetworks in a wide range of domains. However, most existing methods only aim at\nlearning network dynamic behaviors generated by a specific ordinary\ndifferential equation instance, resulting in ineffectiveness for new ones, and\ngenerally require dense observations. The observed data, especially from\nnetwork emerging dynamics, are usually difficult to obtain, which brings\ntrouble to model learning. Therefore, how to learn accurate network dynamics\nwith sparse, irregularly-sampled, partial, and noisy observations remains a\nfundamental challenge. We introduce Neural ODE Processes for Network Dynamics\n(NDP4ND), a new class of stochastic processes governed by stochastic\ndata-adaptive network dynamics, to overcome the challenge and learn continuous\nnetwork dynamics from scarce observations. Intensive experiments conducted on\nvarious network dynamics in ecological population evolution, phototaxis\nmovement, brain activity, epidemic spreading, and real-world empirical systems,\ndemonstrate that the proposed method has excellent data adaptability and\ncomputational efficiency, and can adapt to unseen network emerging dynamics,\nproducing accurate interpolation and extrapolation with reducing the ratio of\nrequired observation data to only about 6\\% and improving the learning speed\nfor new dynamics by three orders of magnitude.",
            "author": [
                "Jiaxu Cui",
                "Bingyi Sun",
                "Jiming Liu",
                "Bo Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16466v1",
                "http://arxiv.org/pdf/2310.16466v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16459v1",
            "title": "DualMatch: Robust Semi-Supervised Learning with Dual-Level Interaction",
            "updated": "2023-10-25T08:34:05Z",
            "published": "2023-10-25T08:34:05Z",
            "summary": "Semi-supervised learning provides an expressive framework for exploiting\nunlabeled data when labels are insufficient. Previous semi-supervised learning\nmethods typically match model predictions of different data-augmented views in\na single-level interaction manner, which highly relies on the quality of\npseudo-labels and results in semi-supervised learning not robust. In this\npaper, we propose a novel SSL method called DualMatch, in which the class\nprediction jointly invokes feature embedding in a dual-level interaction\nmanner. DualMatch requires consistent regularizations for data augmentation,\nspecifically, 1) ensuring that different augmented views are regulated with\nconsistent class predictions, and 2) ensuring that different data of one class\nare regulated with similar feature embeddings. Extensive experiments\ndemonstrate the effectiveness of DualMatch. In the standard SSL setting, the\nproposal achieves 9% error reduction compared with SOTA methods, even in a more\nchallenging class-imbalanced setting, the proposal can still achieve 6% error\nreduction. Code is available at https://github.com/CWangAI/DualMatch",
            "author": [
                "Cong Wang",
                "Xiaofeng Cao",
                "Lanzhe Guo2",
                "Zenglin Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16459v1",
                "http://arxiv.org/pdf/2310.16459v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16457v1",
            "title": "Towards Explainability in Monocular Depth Estimation",
            "updated": "2023-10-25T08:31:04Z",
            "published": "2023-10-25T08:31:04Z",
            "summary": "The estimation of depth in two-dimensional images has long been a challenging\nand extensively studied subject in computer vision. Recently, significant\nprogress has been made with the emergence of Deep Learning-based approaches,\nwhich have proven highly successful. This paper focuses on the explainability\nin monocular depth estimation methods, in terms of how humans perceive depth.\nThis preliminary study emphasizes on one of the most significant visual cues,\nthe relative size, which is prominent in almost all viewed images. We designed\na specific experiment to mimic the experiments in humans and have tested\nstate-of-the-art methods to indirectly assess the explainability in the context\ndefined. In addition, we observed that measuring the accuracy required further\nattention and a particular approach is proposed to this end. The results show\nthat a mean accuracy of around 77% across methods is achieved, with some of the\nmethods performing markedly better, thus, indirectly revealing their\ncorresponding potential to uncover monocular depth cues, like relative size.",
            "author": [
                "Vasileios Arampatzakis",
                "George Pavlidis",
                "Kyriakos Pantoglou",
                "Nikolaos Mitianoudis",
                "Nikos Papamarkos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16457v1",
                "http://arxiv.org/pdf/2310.16457v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17670v1",
            "title": "Unknown Health States Recognition With Collective Decision Based Deep\n  Learning Networks In Predictive Maintenance Applications",
            "updated": "2023-10-25T08:24:48Z",
            "published": "2023-10-25T08:24:48Z",
            "summary": "At present, decision making solutions developed based on deep learning (DL)\nmodels have received extensive attention in predictive maintenance (PM)\napplications along with the rapid improvement of computing power. Relying on\nthe superior properties of shared weights and spatial pooling, Convolutional\nNeural Network (CNN) can learn effective representations of health states from\nindustrial data. Many developed CNN-based schemes, such as advanced CNNs that\nintroduce residual learning and multi-scale learning, have shown good\nperformance in health state recognition tasks under the assumption that all the\nclasses are known. However, these schemes have no ability to deal with new\nabnormal samples that belong to state classes not part of the training set. In\nthis paper, a collective decision framework for different CNNs is proposed. It\nis based on a One-vs-Rest network (OVRN) to simultaneously achieve\nclassification of known and unknown health states. OVRN learn state-specific\ndiscriminative features and enhance the ability to reject new abnormal samples\nincorporated to different CNNs. According to the validation results on the\npublic dataset of Tennessee Eastman Process (TEP), the proposed CNN-based\ndecision schemes incorporating OVRN have outstanding recognition ability for\nsamples of unknown heath states, while maintaining satisfactory accuracy on\nknown states. The results show that the new DL framework outperforms\nconventional CNNs, and the one based on residual and multi-scale learning has\nthe best overall performance.",
            "author": [
                "Chuyue Lou",
                "M. Amine Atoui"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17670v1",
                "http://arxiv.org/pdf/2310.17670v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12859v1",
            "title": "Joint Multi-View Collaborative Clustering",
            "updated": "2023-10-25T08:23:45Z",
            "published": "2023-10-25T08:23:45Z",
            "summary": "Data is increasingly being collected from multiple sources and described by\nmultiple views. These multi-view data provide richer information than\ntraditional single-view data. Fusing the former for specific tasks is an\nessential component of multi-view clustering. Since the goal of multi-view\nclustering algorithms is to discover the common latent structure shared by\nmultiple views, the majority of proposed solutions overlook the advantages of\nincorporating knowledge derived from horizontal collaboration between\nmulti-view data and the final consensus. To fill this gap, we propose the Joint\nMulti-View Collaborative Clustering (JMVCC) solution, which involves the\ngeneration of basic partitions using Non-negative Matrix Factorization (NMF)\nand the horizontal collaboration principle, followed by the fusion of these\nlocal partitions using ensemble clustering. Furthermore, we propose a weighting\nmethod to reduce the risk of negative collaboration (i.e., views with low\nquality) during the generation and fusion of local partitions. The experimental\nresults, which were obtained using a variety of data sets, demonstrate that\nJMVCC outperforms other multi-view clustering algorithms and is robust to noisy\nviews.",
            "author": [
                "Yasser Khalafaoui",
                "Basarab Matei",
                "Nistor Grozavu",
                "Martino Lovisetto"
            ],
            "link": [
                "http://dx.doi.org/10.1109/IJCNN54540.2023.10192014",
                "http://arxiv.org/abs/2311.12859v1",
                "http://arxiv.org/pdf/2311.12859v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16453v1",
            "title": "ClearMark: Intuitive and Robust Model Watermarking via Transposed Model\n  Training",
            "updated": "2023-10-25T08:16:55Z",
            "published": "2023-10-25T08:16:55Z",
            "summary": "Due to costly efforts during data acquisition and model training, Deep Neural\nNetworks (DNNs) belong to the intellectual property of the model creator.\nHence, unauthorized use, theft, or modification may lead to legal\nrepercussions. Existing DNN watermarking methods for ownership proof are often\nnon-intuitive, embed human-invisible marks, require trust in algorithmic\nassessment that lacks human-understandable attributes, and rely on rigid\nthresholds, making it susceptible to failure in cases of partial watermark\nerasure.\n  This paper introduces ClearMark, the first DNN watermarking method designed\nfor intuitive human assessment. ClearMark embeds visible watermarks, enabling\nhuman decision-making without rigid value thresholds while allowing\ntechnology-assisted evaluations. ClearMark defines a transposed model\narchitecture allowing to use of the model in a backward fashion to interwove\nthe watermark with the main task within all model parameters. Compared to\nexisting watermarking methods, ClearMark produces visual watermarks that are\neasy for humans to understand without requiring complex verification algorithms\nor strict thresholds. The watermark is embedded within all model parameters and\nentangled with the main task, exhibiting superior robustness. It shows an\n8,544-bit watermark capacity comparable to the strongest existing work.\nCrucially, ClearMark's effectiveness is model and dataset-agnostic, and\nresilient against adversarial model manipulations, as demonstrated in a\ncomprehensive study performed with four datasets and seven architectures.",
            "author": [
                "Torsten Krau\u00df",
                "Jasper Stang",
                "Alexandra Dmitrienko"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16453v1",
                "http://arxiv.org/pdf/2310.16453v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16452v2",
            "title": "Faithful Path Language Modelling for Explainable Recommendation over\n  Knowledge Graph",
            "updated": "2023-11-12T22:38:04Z",
            "published": "2023-10-25T08:14:49Z",
            "summary": "Path reasoning methods over knowledge graphs have gained popularity for their\npotential to improve transparency in recommender systems. However, the\nresulting models still rely on pre-trained knowledge graph embeddings, fail to\nfully exploit the interdependence between entities and relations in the KG for\nrecommendation, and may generate inaccurate explanations. In this paper, we\nintroduce PEARLM, a novel approach that efficiently captures user behaviour and\nproduct-side knowledge through language modelling. With our approach, knowledge\ngraph embeddings are directly learned from paths over the KG by the language\nmodel, which also unifies entities and relations in the same optimisation\nspace. Constraints on the sequence decoding additionally guarantee path\nfaithfulness with respect to the KG. Experiments on two datasets show the\neffectiveness of our approach compared to state-of-the-art baselines. Source\ncode and datasets: AVAILABLE AFTER GETTING ACCEPTED.",
            "author": [
                "Giacomo Balloccu",
                "Ludovico Boratto",
                "Christian Cancedda",
                "Gianni Fenu",
                "Mirko Marras"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16452v2",
                "http://arxiv.org/pdf/2310.16452v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16446v1",
            "title": "Diversity Enhanced Narrative Question Generation for Storybooks",
            "updated": "2023-10-25T08:10:04Z",
            "published": "2023-10-25T08:10:04Z",
            "summary": "Question generation (QG) from a given context can enhance comprehension,\nengagement, assessment, and overall efficacy in learning or conversational\nenvironments. Despite recent advancements in QG, the challenge of enhancing or\nmeasuring the diversity of generated questions often remains unaddressed. In\nthis paper, we introduce a multi-question generation model (mQG), which is\ncapable of generating multiple, diverse, and answerable questions by focusing\non context and questions. To validate the answerability of the generated\nquestions, we employ a SQuAD2.0 fine-tuned question answering model,\nclassifying the questions as answerable or not. We train and evaluate mQG on\nthe FairytaleQA dataset, a well-structured QA dataset based on storybooks, with\nnarrative questions. We further apply a zero-shot adaptation on the TellMeWhy\nand SQuAD1.1 datasets. mQG shows promising results across various evaluation\nmetrics, among strong baselines.",
            "author": [
                "Hokeun Yoon",
                "JinYeong Bak"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16446v1",
                "http://arxiv.org/pdf/2310.16446v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16444v1",
            "title": "How can neuromorphic hardware attain brain-like functional capabilities?",
            "updated": "2023-10-25T08:09:52Z",
            "published": "2023-10-25T08:09:52Z",
            "summary": "Research on neuromorphic computing is driven by the vision that we can\nemulate brain-like computing capability, learning capability, and\nenergy-efficiency in novel hardware. Unfortunately, this vision has so far been\npursued in a half-hearted manner. Most current neuromorphic hardware (NMHW)\nemploys brain-like spiking neurons instead of standard artificial neurons. This\nis a good first step, which does improve the energy-efficiency of some\ncomputations, see \\citep{rao2022long} for one of many examples. But current\narchitectures and training methods for networks of spiking neurons in NMHW are\nlargely copied from artificial neural networks. Hence it is not surprising that\nthey inherit many deficiencies of artificial neural networks, rather than\nattaining brain-like functional capabilities.\n  Of course, the brain is very complex, and we cannot implement all its details\nin NMHW. Instead, we need to focus on principles that are both easy to\nimplement in NMHW and are likely to support brain-like functionality. The goal\nof this article is to highlight some of them.",
            "author": [
                "Wolfgang Maass"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16444v1",
                "http://arxiv.org/pdf/2310.16444v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16441v1",
            "title": "Grokking in Linear Estimators -- A Solvable Model that Groks without\n  Understanding",
            "updated": "2023-10-25T08:08:44Z",
            "published": "2023-10-25T08:08:44Z",
            "summary": "Grokking is the intriguing phenomenon where a model learns to generalize long\nafter it has fit the training data. We show both analytically and numerically\nthat grokking can surprisingly occur in linear networks performing linear tasks\nin a simple teacher-student setup with Gaussian inputs. In this setting, the\nfull training dynamics is derived in terms of the training and generalization\ndata covariance matrix. We present exact predictions on how the grokking time\ndepends on input and output dimensionality, train sample size, regularization,\nand network initialization. We demonstrate that the sharp increase in\ngeneralization accuracy may not imply a transition from \"memorization\" to\n\"understanding\", but can simply be an artifact of the accuracy measure. We\nprovide empirical verification for our calculations, along with preliminary\nresults indicating that some predictions also hold for deeper networks, with\nnon-linear activations.",
            "author": [
                "Noam Levi",
                "Alon Beck",
                "Yohai Bar-Sinai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16441v1",
                "http://arxiv.org/pdf/2310.16441v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cond-mat.dis-nn",
                "cs.LG",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17669v1",
            "title": "An Approach for Efficient Neural Architecture Search Space Definition",
            "updated": "2023-10-25T08:07:29Z",
            "published": "2023-10-25T08:07:29Z",
            "summary": "As we advance in the fast-growing era of Machine Learning, various new and\nmore complex neural architectures are arising to tackle problem more\nefficiently. On the one hand their efficient usage requires advanced knowledge\nand expertise, which is most of the time difficult to find on the labor market.\nOn the other hand, searching for an optimized neural architecture is a\ntime-consuming task when it is performed manually using a trial and error\napproach. Hence, a method and a tool support is needed to assist users of\nneural architectures, leading to an eagerness in the field of Automatic Machine\nLearning (AutoML). When it comes to Deep Learning, an important part of AutoML\nis the Neural Architecture Search (NAS). In this paper, we propose a novel\ncell-based hierarchical search space, easy to comprehend and manipulate. The\nobjectives of the proposed approach are to optimize the search-time and to be\ngeneral enough to handle most of state of the art Convolutional Neural Networks\n(CNN) architectures.",
            "author": [
                "L\u00e9o Pouy",
                "Fouad Khenfri",
                "Patrick Leserf",
                "Chokri Mraidha",
                "Cherif Larouci"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17669v1",
                "http://arxiv.org/pdf/2310.17669v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16437v1",
            "title": "Non-isotropic Persistent Homology: Leveraging the Metric Dependency of\n  PH",
            "updated": "2023-10-25T08:03:17Z",
            "published": "2023-10-25T08:03:17Z",
            "summary": "Persistent Homology is a widely used topological data analysis tool that\ncreates a concise description of the topological properties of a point cloud\nbased on a specified filtration. Most filtrations used for persistent homology\ndepend (implicitly) on a chosen metric, which is typically agnostically chosen\nas the standard Euclidean metric on $\\mathbb{R}^n$. Recent work has tried to\nuncover the 'true' metric on the point cloud using distance-to-measure\nfunctions, in order to obtain more meaningful persistent homology results. Here\nwe propose an alternative look at this problem: we posit that information on\nthe point cloud is lost when restricting persistent homology to a single\n(correct) distance function. Instead, we show how by varying the distance\nfunction on the underlying space and analysing the corresponding shifts in the\npersistence diagrams, we can extract additional topological and geometrical\ninformation. Finally, we numerically show that non-isotropic persistent\nhomology can extract information on orientation, orientational variance, and\nscaling of randomly generated point clouds with good accuracy and conduct some\nexperiments on real-world data.",
            "author": [
                "Vincent P. Grande",
                "Michael T. Schaub"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16437v1",
                "http://arxiv.org/pdf/2310.16437v1"
            ],
            "primary_category": "math.AT",
            "category": [
                "math.AT",
                "cs.CG",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16436v2",
            "title": "DDCoT: Duty-Distinct Chain-of-Thought Prompting for Multimodal Reasoning\n  in Language Models",
            "updated": "2023-10-26T04:16:52Z",
            "published": "2023-10-25T08:03:10Z",
            "summary": "A long-standing goal of AI systems is to perform complex multimodal reasoning\nlike humans. Recently, large language models (LLMs) have made remarkable\nstrides in such multi-step reasoning on the language modality solely by\nleveraging the chain of thought (CoT) to mimic human thinking. However, the\ntransfer of these advancements to multimodal contexts introduces heightened\nchallenges, including but not limited to the impractical need for\nlabor-intensive annotation and the limitations in terms of flexibility,\ngeneralizability, and explainability. To evoke CoT reasoning in multimodality,\nthis work first conducts an in-depth analysis of these challenges posed by\nmultimodality and presents two key insights: \"keeping critical thinking\" and\n\"letting everyone do their jobs\" in multimodal CoT reasoning. Furthermore, this\nstudy proposes a novel DDCoT prompting that maintains a critical attitude\nthrough negative-space prompting and incorporates multimodality into reasoning\nby first dividing the reasoning responsibility of LLMs into reasoning and\nrecognition and then integrating the visual recognition capability of visual\nmodels into the joint reasoning process. The rationales generated by DDCoT not\nonly improve the reasoning abilities of both large and small language models in\nzero-shot prompting and fine-tuning learning, significantly outperforming\nstate-of-the-art methods but also exhibit impressive generalizability and\nexplainability.",
            "author": [
                "Ge Zheng",
                "Bin Yang",
                "Jiajin Tang",
                "Hong-Yu Zhou",
                "Sibei Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16436v2",
                "http://arxiv.org/pdf/2310.16436v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16430v1",
            "title": "An Integrative Paradigm for Enhanced Stroke Prediction: Synergizing\n  XGBoost and xDeepFM Algorithms",
            "updated": "2023-10-25T07:55:02Z",
            "published": "2023-10-25T07:55:02Z",
            "summary": "Stroke prediction plays a crucial role in preventing and managing this\ndebilitating condition. In this study, we address the challenge of stroke\nprediction using a comprehensive dataset, and propose an ensemble model that\ncombines the power of XGBoost and xDeepFM algorithms. Our work aims to improve\nupon existing stroke prediction models by achieving higher accuracy and\nrobustness. Through rigorous experimentation, we validate the effectiveness of\nour ensemble model using the AUC metric. Through comparing our findings with\nthose of other models in the field, we gain valuable insights into the merits\nand drawbacks of various approaches. This, in turn, contributes significantly\nto the progress of machine learning and deep learning techniques specifically\nin the domain of stroke prediction.",
            "author": [
                "Weinan Dai",
                "Yifeng Jiang",
                "Chengjie Mou",
                "Chongyu Zhang"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3627377.3627382",
                "http://arxiv.org/abs/2310.16430v1",
                "http://arxiv.org/pdf/2310.16430v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16419v1",
            "title": "Open Knowledge Base Canonicalization with Multi-task Unlearning",
            "updated": "2023-10-25T07:13:06Z",
            "published": "2023-10-25T07:13:06Z",
            "summary": "The construction of large open knowledge bases (OKBs) is integral to many\napplications in the field of mobile computing. Noun phrases and relational\nphrases in OKBs often suffer from redundancy and ambiguity, which calls for the\ninvestigation on OKB canonicalization. However, in order to meet the\nrequirements of some privacy protection regulations and to ensure the\ntimeliness of the data, the canonicalized OKB often needs to remove some\nsensitive information or outdated data. The machine unlearning in OKB\ncanonicalization is an excellent solution to the above problem. Current\nsolutions address OKB canonicalization by devising advanced clustering\nalgorithms and using knowledge graph embedding (KGE) to further facilitate the\ncanonicalization process. Effective schemes are urgently needed to fully\nsynergise machine unlearning with clustering and KGE learning. To this end, we\nput forward a multi-task unlearning framework, namely MulCanon, to tackle\nmachine unlearning problem in OKB canonicalization. Specifically, the noise\ncharacteristics in the diffusion model are utilized to achieve the effect of\nmachine unlearning for data in OKB. MulCanon unifies the learning objectives of\ndiffusion model, KGE and clustering algorithms, and adopts a two-step\nmulti-task learning paradigm for training. A thorough experimental study on\npopular OKB canonicalization datasets validates that MulCanon achieves advanced\nmachine unlearning effects.",
            "author": [
                "Bingchen Liu",
                "Shihao Hou",
                "Weixin Zeng",
                "Xiang Zhao",
                "Shijun Liu",
                "Li Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16419v1",
                "http://arxiv.org/pdf/2310.16419v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16412v1",
            "title": "FlatMatch: Bridging Labeled Data and Unlabeled Data with Cross-Sharpness\n  for Semi-Supervised Learning",
            "updated": "2023-10-25T06:57:59Z",
            "published": "2023-10-25T06:57:59Z",
            "summary": "Semi-Supervised Learning (SSL) has been an effective way to leverage abundant\nunlabeled data with extremely scarce labeled data. However, most SSL methods\nare commonly based on instance-wise consistency between different data\ntransformations. Therefore, the label guidance on labeled data is hard to be\npropagated to unlabeled data. Consequently, the learning process on labeled\ndata is much faster than on unlabeled data which is likely to fall into a local\nminima that does not favor unlabeled data, leading to sub-optimal\ngeneralization performance. In this paper, we propose FlatMatch which minimizes\na cross-sharpness measure to ensure consistent learning performance between the\ntwo datasets. Specifically, we increase the empirical risk on labeled data to\nobtain a worst-case model which is a failure case that needs to be enhanced.\nThen, by leveraging the richness of unlabeled data, we penalize the prediction\ndifference (i.e., cross-sharpness) between the worst-case model and the\noriginal model so that the learning direction is beneficial to generalization\non unlabeled data. Therefore, we can calibrate the learning process without\nbeing limited to insufficient label information. As a result, the mismatched\nlearning performance can be mitigated, further enabling the effective\nexploitation of unlabeled data and improving SSL performance. Through\ncomprehensive validation, we show FlatMatch achieves state-of-the-art results\nin many SSL settings.",
            "author": [
                "Zhuo Huang",
                "Li Shen",
                "Jun Yu",
                "Bo Han",
                "Tongliang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16412v1",
                "http://arxiv.org/pdf/2310.16412v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "Machine Learning"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16410v1",
            "title": "Bridging the Human-AI Knowledge Gap: Concept Discovery and Transfer in\n  AlphaZero",
            "updated": "2023-10-25T06:49:26Z",
            "published": "2023-10-25T06:49:26Z",
            "summary": "Artificial Intelligence (AI) systems have made remarkable progress, attaining\nsuper-human performance across various domains. This presents us with an\nopportunity to further human knowledge and improve human expert performance by\nleveraging the hidden knowledge encoded within these highly performant AI\nsystems. Yet, this knowledge is often hard to extract, and may be hard to\nunderstand or learn from. Here, we show that this is possible by proposing a\nnew method that allows us to extract new chess concepts in AlphaZero, an AI\nsystem that mastered the game of chess via self-play without human supervision.\nOur analysis indicates that AlphaZero may encode knowledge that extends beyond\nthe existing human knowledge, but knowledge that is ultimately not beyond human\ngrasp, and can be successfully learned from. In a human study, we show that\nthese concepts are learnable by top human experts, as four top chess\ngrandmasters show improvements in solving the presented concept prototype\npositions. This marks an important first milestone in advancing the frontier of\nhuman knowledge by leveraging AI; a development that could bear profound\nimplications and help us shape how we interact with AI systems across many AI\napplications.",
            "author": [
                "Lisa Schut",
                "Nenad Tomasev",
                "Tom McGrath",
                "Demis Hassabis",
                "Ulrich Paquet",
                "Been Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16410v1",
                "http://arxiv.org/pdf/2310.16410v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.HC",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16409v1",
            "title": "Multiple Key-value Strategy in Recommendation Systems Incorporating\n  Large Language Model",
            "updated": "2023-10-25T06:49:19Z",
            "published": "2023-10-25T06:49:19Z",
            "summary": "Recommendation system (RS) plays significant roles in matching users\ninformation needs for Internet applications, and it usually utilizes the\nvanilla neural network as the backbone to handle embedding details. Recently,\nthe large language model (LLM) has exhibited emergent abilities and achieved\ngreat breakthroughs both in the CV and NLP communities. Thus, it is logical to\nincorporate RS with LLM better, which has become an emerging research\ndirection. Although some existing works have made their contributions to this\nissue, they mainly consider the single key situation (e.g. historical\ninteractions), especially in sequential recommendation. The situation of\nmultiple key-value data is simply neglected. This significant scenario is\nmainstream in real practical applications, where the information of users (e.g.\nage, occupation, etc) and items (e.g. title, category, etc) has more than one\nkey. Therefore, we aim to implement sequential recommendations based on\nmultiple key-value data by incorporating RS with LLM. In particular, we\ninstruct tuning a prevalent open-source LLM (Llama 7B) in order to inject\ndomain knowledge of RS into the pre-trained LLM. Since we adopt multiple\nkey-value strategies, LLM is hard to learn well among these keys. Thus the\ngeneral and innovative shuffle and mask strategies, as an innovative manner of\ndata argument, are designed. To demonstrate the effectiveness of our approach,\nextensive experiments are conducted on the popular and suitable dataset\nMovieLens which contains multiple keys-value. The experimental results\ndemonstrate that our approach can nicely and effectively complete this\nchallenging issue.",
            "author": [
                "Dui Wang",
                "Xiangyu Hou",
                "Xiaohui Yang",
                "Bo Zhang",
                "Renbing Chen",
                "Daiyue Xue"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16409v1",
                "http://arxiv.org/pdf/2310.16409v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16407v1",
            "title": "Information-Theoretic Generalization Analysis for Topology-aware\n  Heterogeneous Federated Edge Learning over Noisy Channels",
            "updated": "2023-10-25T06:46:48Z",
            "published": "2023-10-25T06:46:48Z",
            "summary": "With the rapid growth of edge intelligence, the deployment of federated\nlearning (FL) over wireless networks has garnered increasing attention, which\nis called Federated Edge Learning (FEEL). In FEEL, both mobile devices\ntransmitting model parameters over noisy channels and collecting data in\ndiverse environments pose challenges to the generalization of trained models.\nMoreover, devices can engage in decentralized FL via Device-to-Device\ncommunication while the communication topology of connected devices also\nimpacts the generalization of models. Most recent theoretical studies overlook\nthe incorporation of all these effects into FEEL when developing generalization\nanalyses. In contrast, our work presents an information-theoretic\ngeneralization analysis for topology-aware FEEL in the presence of data\nheterogeneity and noisy channels. Additionally, we propose a novel\nregularization method called Federated Global Mutual Information Reduction\n(FedGMIR) to enhance the performance of models based on our analysis. Numerical\nresults validate our theoretical findings and provide evidence for the\neffectiveness of the proposed method.",
            "author": [
                "Zheshun Wu",
                "Zenglin Xu",
                "Hongfang Yu",
                "Jie Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16407v1",
                "http://arxiv.org/pdf/2310.16407v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16406v1",
            "title": "Challenges of Radio Frequency Fingerprinting: From Data Collection to\n  Deployment",
            "updated": "2023-10-25T06:45:49Z",
            "published": "2023-10-25T06:45:49Z",
            "summary": "Radio Frequency Fingerprinting (RFF) techniques promise to authenticate\nwireless devices at the physical layer based on inherent hardware imperfections\nintroduced during manufacturing. Such RF transmitter imperfections are\nreflected into over-the-air signals, allowing receivers to accurately identify\nthe RF transmitting source. Recent advances in Machine Learning, particularly\nin Deep Learning (DL), have improved the ability of RFF systems to extract and\nlearn complex features that make up the device-specific fingerprint. However,\nintegrating DL techniques with RFF and operating the system in real-world\nscenarios presents numerous challenges. This article identifies and analyzes\nthese challenges while considering the three reference phases of any DL-based\nRFF system: (i) data collection and preprocessing, (ii) training, and finally,\n(iii) deployment. Our investigation points out the current open problems that\nprevent real deployment of RFF while discussing promising future directions,\nthus paving the way for further research in the area.",
            "author": [
                "Saeif Alhazbi",
                "Ahmed Hussain",
                "Savio Sciancalepore",
                "Gabriele Oligeri",
                "Panos Papadimitratos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16406v1",
                "http://arxiv.org/pdf/2310.16406v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16405v1",
            "title": "Binary State Recognition by Robots using Visual Question Answering of\n  Pre-Trained Vision-Language Model",
            "updated": "2023-10-25T06:44:22Z",
            "published": "2023-10-25T06:44:22Z",
            "summary": "Recognition of the current state is indispensable for the operation of a\nrobot. There are various states to be recognized, such as whether an elevator\ndoor is open or closed, whether an object has been grasped correctly, and\nwhether the TV is turned on or off. Until now, these states have been\nrecognized by programmatically describing the state of a point cloud or raw\nimage, by annotating and learning images, by using special sensors, etc. In\ncontrast to these methods, we apply Visual Question Answering (VQA) from a\nPre-Trained Vision-Language Model (PTVLM) trained on a large-scale dataset, to\nsuch binary state recognition. This idea allows us to intuitively describe\nstate recognition in language without any re-training, thereby improving the\nrecognition ability of robots in a simple and general way. We summarize various\ntechniques in questioning methods and image processing, and clarify their\nproperties through experiments.",
            "author": [
                "Kento Kawaharazuka",
                "Yoshiki Obinata",
                "Naoaki Kanazawa",
                "Kei Okada",
                "Masayuki Inaba"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16405v1",
                "http://arxiv.org/pdf/2310.16405v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16401v2",
            "title": "Graph Neural Networks with a Distribution of Parametrized Graphs",
            "updated": "2023-10-28T14:14:19Z",
            "published": "2023-10-25T06:38:24Z",
            "summary": "Traditionally, graph neural networks have been trained using a single\nobserved graph. However, the observed graph represents only one possible\nrealization. In many applications, the graph may encounter uncertainties, such\nas having erroneous or missing edges, as well as edge weights that provide\nlittle informative value. To address these challenges and capture additional\ninformation previously absent in the observed graph, we introduce latent\nvariables to parameterize and generate multiple graphs. We obtain the maximum\nlikelihood estimate of the network parameters in an Expectation-Maximization\n(EM) framework based on the multiple graphs. Specifically, we iteratively\ndetermine the distribution of the graphs using a Markov Chain Monte Carlo\n(MCMC) method, incorporating the principles of PAC-Bayesian theory. Numerical\nexperiments demonstrate improvements in performance against baseline models on\nnode classification for heterogeneous graphs and graph regression on chemistry\ndatasets.",
            "author": [
                "See Hian Lee",
                "Feng Ji",
                "Kelin Xia",
                "Wee Peng Tay"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16401v2",
                "http://arxiv.org/pdf/2310.16401v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16397v1",
            "title": "Learning Efficient Surrogate Dynamic Models with Graph Spline Networks",
            "updated": "2023-10-25T06:32:47Z",
            "published": "2023-10-25T06:32:47Z",
            "summary": "While complex simulations of physical systems have been widely used in\nengineering and scientific computing, lowering their often prohibitive\ncomputational requirements has only recently been tackled by deep learning\napproaches. In this paper, we present GraphSplineNets, a novel deep-learning\nmethod to speed up the forecasting of physical systems by reducing the grid\nsize and number of iteration steps of deep surrogate models. Our method uses\ntwo differentiable orthogonal spline collocation methods to efficiently predict\nresponse at any location in time and space. Additionally, we introduce an\nadaptive collocation strategy in space to prioritize sampling from the most\nimportant regions. GraphSplineNets improve the accuracy-speedup tradeoff in\nforecasting various dynamical systems with increasing complexity, including the\nheat equation, damped wave propagation, Navier-Stokes equations, and real-world\nocean currents in both regular and irregular domains.",
            "author": [
                "Chuanbo Hua",
                "Federico Berto",
                "Michael Poli",
                "Stefano Massaroli",
                "Jinkyoo Park"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16397v1",
                "http://arxiv.org/pdf/2310.16397v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.LG",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16391v1",
            "title": "Winning Prize Comes from Losing Tickets: Improve Invariant Learning by\n  Exploring Variant Parameters for Out-of-Distribution Generalization",
            "updated": "2023-10-25T06:10:57Z",
            "published": "2023-10-25T06:10:57Z",
            "summary": "Out-of-Distribution (OOD) Generalization aims to learn robust models that\ngeneralize well to various environments without fitting to\ndistribution-specific features. Recent studies based on Lottery Ticket\nHypothesis (LTH) address this problem by minimizing the learning target to find\nsome of the parameters that are critical to the task. However, in OOD problems,\nsuch solutions are suboptimal as the learning task contains severe distribution\nnoises, which can mislead the optimization process. Therefore, apart from\nfinding the task-related parameters (i.e., invariant parameters), we propose\nExploring Variant parameters for Invariant Learning (EVIL) which also leverages\nthe distribution knowledge to find the parameters that are sensitive to\ndistribution shift (i.e., variant parameters). Once the variant parameters are\nleft out of invariant learning, a robust subnetwork that is resistant to\ndistribution shift can be found. Additionally, the parameters that are\nrelatively stable across distributions can be considered invariant ones to\nimprove invariant learning. By fully exploring both variant and invariant\nparameters, our EVIL can effectively identify a robust subnetwork to improve\nOOD generalization. In extensive experiments on integrated testbed: DomainBed,\nEVIL can effectively and efficiently enhance many popular methods, such as ERM,\nIRM, SAM, etc.",
            "author": [
                "Zhuo Huang",
                "Muyang Li",
                "Li Shen",
                "Jun Yu",
                "Chen Gong",
                "Bo Han",
                "Tongliang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16391v1",
                "http://arxiv.org/pdf/2310.16391v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "Computer Vision and Pattern Recognition"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16390v1",
            "title": "Evaluating Pre-trained Language Models for Repairing API Misuses",
            "updated": "2023-10-25T06:10:22Z",
            "published": "2023-10-25T06:10:22Z",
            "summary": "API misuses often lead to software bugs, crashes, and vulnerabilities. While\nseveral API misuse detectors have been proposed, there are no automatic repair\ntools specifically designed for this purpose. In a recent study,\ntest-suite-based automatic program repair (APR) tools were found to be\nineffective in repairing API misuses. Still, since the study focused on\nnon-learning-aided APR tools, it remains unknown whether learning-aided APR\ntools are capable of fixing API misuses. In recent years, pre-trained language\nmodels (PLMs) have succeeded greatly in many natural language processing tasks.\nThere is a rising interest in applying PLMs to APR. However, there has not been\nany study that investigates the effectiveness of PLMs in repairing API misuse.\n  To fill this gap, we conduct a comprehensive empirical study on 11\nlearning-aided APR tools, which include 9 of the state-of-the-art\ngeneral-purpose PLMs and two APR tools. We evaluate these models with an\nAPI-misuse repair dataset, consisting of two variants. Our results show that\nPLMs perform better than the studied APR tools in repairing API misuses. Among\nthe 9 pre-trained models tested, CodeT5 is the best performer in the exact\nmatch. We also offer insights and potential exploration directions for future\nresearch.",
            "author": [
                "Ting Zhang",
                "Ivana Clairine Irsan",
                "Ferdian Thung",
                "David Lo",
                "Asankhaya Sharma",
                "Lingxiao Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16390v1",
                "http://arxiv.org/pdf/2310.16390v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16389v1",
            "title": "MVFAN: Multi-View Feature Assisted Network for 4D Radar Object Detection",
            "updated": "2023-10-25T06:10:07Z",
            "published": "2023-10-25T06:10:07Z",
            "summary": "4D radar is recognized for its resilience and cost-effectiveness under\nadverse weather conditions, thus playing a pivotal role in autonomous driving.\nWhile cameras and LiDAR are typically the primary sensors used in perception\nmodules for autonomous vehicles, radar serves as a valuable supplementary\nsensor. Unlike LiDAR and cameras, radar remains unimpaired by harsh weather\nconditions, thereby offering a dependable alternative in challenging\nenvironments. Developing radar-based 3D object detection not only augments the\ncompetency of autonomous vehicles but also provides economic benefits. In\nresponse, we propose the Multi-View Feature Assisted Network (\\textit{MVFAN}),\nan end-to-end, anchor-free, and single-stage framework for 4D-radar-based 3D\nobject detection for autonomous vehicles. We tackle the issue of insufficient\nfeature utilization by introducing a novel Position Map Generation module to\nenhance feature learning by reweighing foreground and background points, and\ntheir features, considering the irregular distribution of radar point clouds.\nAdditionally, we propose a pioneering backbone, the Radar Feature Assisted\nbackbone, explicitly crafted to fully exploit the valuable Doppler velocity and\nreflectivity data provided by the 4D radar sensor. Comprehensive experiments\nand ablation studies carried out on Astyx and VoD datasets attest to the\nefficacy of our framework. The incorporation of Doppler velocity and RCS\nreflectivity dramatically improves the detection performance for small moving\nobjects such as pedestrians and cyclists. Consequently, our approach culminates\nin a highly optimized 4D-radar-based 3D object detection capability for\nautonomous driving systems, setting a new standard in the field.",
            "author": [
                "Qiao Yan",
                "Yihan Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16389v1",
                "http://arxiv.org/pdf/2310.16389v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16861v1",
            "title": "General Point Model with Autoencoding and Autoregressive",
            "updated": "2023-10-25T06:08:24Z",
            "published": "2023-10-25T06:08:24Z",
            "summary": "The pre-training architectures of large language models encompass various\ntypes, including autoencoding models, autoregressive models, and\nencoder-decoder models. We posit that any modality can potentially benefit from\na large language model, as long as it undergoes vector quantization to become\ndiscrete tokens. Inspired by GLM, we propose a General Point Model (GPM) which\nseamlessly integrates autoencoding and autoregressive tasks in point cloud\ntransformer. This model is versatile, allowing fine-tuning for downstream point\ncloud representation tasks, as well as unconditional and conditional generation\ntasks. GPM enhances masked prediction in autoencoding through various forms of\nmask padding tasks, leading to improved performance in point cloud\nunderstanding. Additionally, GPM demonstrates highly competitive results in\nunconditional point cloud generation tasks, even exhibiting the potential for\nconditional generation tasks by modifying the input's conditional information.\nCompared to models like Point-BERT, MaskPoint and PointMAE, our GPM achieves\nsuperior performance in point cloud understanding tasks. Furthermore, the\nintegration of autoregressive and autoencoding within the same transformer\nunderscores its versatility across different downstream tasks.",
            "author": [
                "Zhe Li",
                "Zhangyang Gao",
                "Cheng Tan",
                "Stan Z. Li",
                "Laurence T. Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16861v1",
                "http://arxiv.org/pdf/2310.16861v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16387v1",
            "title": "Frequency-Aware Transformer for Learned Image Compression",
            "updated": "2023-10-25T05:59:25Z",
            "published": "2023-10-25T05:59:25Z",
            "summary": "Learned image compression (LIC) has gained traction as an effective solution\nfor image storage and transmission in recent years. However, existing LIC\nmethods are redundant in latent representation due to limitations in capturing\nanisotropic frequency components and preserving directional details. To\novercome these challenges, we propose a novel frequency-aware transformer (FAT)\nblock that for the first time achieves multiscale directional ananlysis for\nLIC. The FAT block comprises frequency-decomposition window attention (FDWA)\nmodules to capture multiscale and directional frequency components of natural\nimages. Additionally, we introduce frequency-modulation feed-forward network\n(FMFFN) to adaptively modulate different frequency components, improving\nrate-distortion performance. Furthermore, we present a transformer-based\nchannel-wise autoregressive (T-CA) model that effectively exploits channel\ndependencies. Experiments show that our method achieves state-of-the-art\nrate-distortion performance compared to existing LIC methods, and evidently\noutperforms latest standardized codec VTM-12.1 by 14.5%, 15.1%, 13.0% in\nBD-rate on the Kodak, Tecnick, and CLIC datasets.",
            "author": [
                "Han Li",
                "Shaohui Li",
                "Wenrui Dai",
                "Chenglin Li",
                "Junni Zou",
                "Hongkai Xiong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16387v1",
                "http://arxiv.org/pdf/2310.16387v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16384v1",
            "title": "Distributed Uncertainty Quantification of Kernel Interpolation on\n  Spheres",
            "updated": "2023-10-25T05:52:02Z",
            "published": "2023-10-25T05:52:02Z",
            "summary": "For radial basis function (RBF) kernel interpolation of scattered data,\nSchaback in 1995 proved that the attainable approximation error and the\ncondition number of the underlying interpolation matrix cannot be made small\nsimultaneously. He referred to this finding as an \"uncertainty relation\", an\nundesirable consequence of which is that RBF kernel interpolation is\nsusceptible to noisy data. In this paper, we propose and study a distributed\ninterpolation method to manage and quantify the uncertainty brought on by\ninterpolating noisy spherical data of non-negligible magnitude. We also present\nnumerical simulation results showing that our method is practical and robust in\nterms of handling noisy data from challenging computing environments.",
            "author": [
                "Shao-Bo Lin",
                "Xingping Sun",
                "Di Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16384v1",
                "http://arxiv.org/pdf/2310.16384v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.LG",
                "cs.NA",
                "math.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16380v1",
            "title": "A model for multi-attack classification to improve intrusion detection\n  performance using deep learning approaches",
            "updated": "2023-10-25T05:38:44Z",
            "published": "2023-10-25T05:38:44Z",
            "summary": "This proposed model introduces novel deep learning methodologies. The\nobjective here is to create a reliable intrusion detection mechanism to help\nidentify malicious attacks. Deep learning based solution framework is developed\nconsisting of three approaches. The first approach is Long-Short Term Memory\nRecurrent Neural Network (LSTM-RNN) with seven optimizer functions such as\nadamax, SGD, adagrad, adam, RMSprop, nadam and adadelta. The model is evaluated\non NSL-KDD dataset and classified multi attack classification. The model has\noutperformed with adamax optimizer in terms of accuracy, detection rate and low\nfalse alarm rate. The results of LSTM-RNN with adamax optimizer is compared\nwith existing shallow machine and deep learning models in terms of accuracy,\ndetection rate and low false alarm rate. The multi model methodology consisting\nof Recurrent Neural Network (RNN), Long-Short Term Memory Recurrent Neural\nNetwork (LSTM-RNN), and Deep Neural Network (DNN). The multi models are\nevaluated on bench mark datasets such as KDD99, NSL-KDD, and UNSWNB15 datasets.\nThe models self-learnt the features and classifies the attack classes as\nmulti-attack classification. The models RNN, and LSTM-RNN provide considerable\nperformance compared to other existing methods on KDD99 and NSL-KDD dataset",
            "author": [
                "Arun Kumar Silivery",
                "Ram Mohan Rao Kovvur"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.measen.2023.100924",
                "http://arxiv.org/abs/2310.16380v1",
                "http://arxiv.org/pdf/2310.16380v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16376v1",
            "title": "GADY: Unsupervised Anomaly Detection on Dynamic Graphs",
            "updated": "2023-10-25T05:27:45Z",
            "published": "2023-10-25T05:27:45Z",
            "summary": "Anomaly detection on dynamic graphs refers to detecting entities whose\nbehaviors obviously deviate from the norms observed within graphs and their\ntemporal information. This field has drawn increasing attention due to its\napplication in finance, network security, social networks, and more. However,\nexisting methods face two challenges: dynamic structure constructing challenge\n- difficulties in capturing graph structure with complex time information and\nnegative sampling challenge - unable to construct excellent negative samples\nfor unsupervised learning. To address these challenges, we propose Unsupervised\nGenerative Anomaly Detection on Dynamic Graphs (GADY). To tackle the first\nchallenge, we propose a continuous dynamic graph model to capture the\nfine-grained information, which breaks the limit of existing discrete methods.\nSpecifically, we employ a message-passing framework combined with positional\nfeatures to get edge embeddings, which are decoded to identify anomalies. For\nthe second challenge, we pioneer the use of Generative Adversarial Networks to\ngenerate negative interactions. Moreover, we design a loss function to alter\nthe training goal of the generator while ensuring the diversity and quality of\ngenerated samples. Extensive experiments demonstrate that our proposed GADY\nsignificantly outperforms the previous state-of-the-art method on three\nreal-world datasets. Supplementary experiments further validate the\neffectiveness of our model design and the necessity of each module.",
            "author": [
                "Shiqi Lou",
                "Qingyue Zhang",
                "Shujie Yang",
                "Yuyang Tian",
                "Zhaoxuan Tan",
                "Minnan Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16376v1",
                "http://arxiv.org/pdf/2310.16376v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16375v1",
            "title": "DyExplainer: Explainable Dynamic Graph Neural Networks",
            "updated": "2023-10-25T05:26:33Z",
            "published": "2023-10-25T05:26:33Z",
            "summary": "Graph Neural Networks (GNNs) resurge as a trending research subject owing to\ntheir impressive ability to capture representations from graph-structured data.\nHowever, the black-box nature of GNNs presents a significant challenge in terms\nof comprehending and trusting these models, thereby limiting their practical\napplications in mission-critical scenarios. Although there has been substantial\nprogress in the field of explaining GNNs in recent years, the majority of these\nstudies are centered on static graphs, leaving the explanation of dynamic GNNs\nlargely unexplored. Dynamic GNNs, with their ever-evolving graph structures,\npose a unique challenge and require additional efforts to effectively capture\ntemporal dependencies and structural relationships. To address this challenge,\nwe present DyExplainer, a novel approach to explaining dynamic GNNs on the fly.\nDyExplainer trains a dynamic GNN backbone to extract representations of the\ngraph at each snapshot, while simultaneously exploring structural relationships\nand temporal dependencies through a sparse attention technique. To preserve the\ndesired properties of the explanation, such as structural consistency and\ntemporal continuity, we augment our approach with contrastive learning\ntechniques to provide priori-guided regularization. To model longer-term\ntemporal dependencies, we develop a buffer-based live-updating scheme for\ntraining. The results of our extensive experiments on various datasets\ndemonstrate the superiority of DyExplainer, not only providing faithful\nexplainability of the model predictions but also significantly improving the\nmodel prediction accuracy, as evidenced in the link prediction task.",
            "author": [
                "Tianchun Wang",
                "Dongsheng Luo",
                "Wei Cheng",
                "Haifeng Chen",
                "Xiang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16375v1",
                "http://arxiv.org/pdf/2310.16375v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16374v1",
            "title": "Joint Distributional Learning via Cramer-Wold Distance",
            "updated": "2023-10-25T05:24:23Z",
            "published": "2023-10-25T05:24:23Z",
            "summary": "The assumption of conditional independence among observed variables,\nprimarily used in the Variational Autoencoder (VAE) decoder modeling, has\nlimitations when dealing with high-dimensional datasets or complex correlation\nstructures among observed variables. To address this issue, we introduced the\nCramer-Wold distance regularization, which can be computed in a closed-form, to\nfacilitate joint distributional learning for high-dimensional datasets.\nAdditionally, we introduced a two-step learning method to enable flexible prior\nmodeling and improve the alignment between the aggregated posterior and the\nprior distribution. Furthermore, we provide theoretical distinctions from\nexisting methods within this category. To evaluate the synthetic data\ngeneration performance of our proposed approach, we conducted experiments on\nhigh-dimensional datasets with multiple categorical variables. Given that many\nreadily available datasets and data science applications involve such datasets,\nour experiments demonstrate the effectiveness of our proposed methodology.",
            "author": [
                "Seunghwan An",
                "Jong-June Jeon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16374v1",
                "http://arxiv.org/pdf/2310.16374v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16364v1",
            "title": "Towards Large-scale Masked Face Recognition",
            "updated": "2023-10-25T05:04:47Z",
            "published": "2023-10-25T05:04:47Z",
            "summary": "During the COVID-19 coronavirus epidemic, almost everyone is wearing masks,\nwhich poses a huge challenge for deep learning-based face recognition\nalgorithms. In this paper, we will present our \\textbf{championship} solutions\nin ICCV MFR WebFace260M and InsightFace unconstrained tracks. We will focus on\nfour challenges in large-scale masked face recognition, i.e., super-large scale\ntraining, data noise handling, masked and non-masked face recognition accuracy\nbalancing, and how to design inference-friendly model architecture. We hope\nthat the discussion on these four aspects can guide future research towards\nmore robust masked face recognition systems.",
            "author": [
                "Manyuan Zhang",
                "Bingqi Ma",
                "Guanglu Song",
                "Yunxiao Wang",
                "Hongsheng Li",
                "Yu Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16364v1",
                "http://arxiv.org/pdf/2310.16364v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16363v1",
            "title": "Finite Time Analysis of Constrained Actor Critic and Constrained Natural\n  Actor Critic Algorithms",
            "updated": "2023-10-25T05:04:00Z",
            "published": "2023-10-25T05:04:00Z",
            "summary": "Actor Critic methods have found immense applications on a wide range of\nReinforcement Learning tasks especially when the state-action space is large.\nIn this paper, we consider actor critic and natural actor critic algorithms\nwith function approximation for constrained Markov decision processes (C-MDP)\ninvolving inequality constraints and carry out a non-asymptotic analysis for\nboth of these algorithms in a non-i.i.d (Markovian) setting. We consider the\nlong-run average cost criterion where both the objective and the constraint\nfunctions are suitable policy-dependent long-run averages of certain prescribed\ncost functions. We handle the inequality constraints using the Lagrange\nmultiplier method. We prove that these algorithms are guaranteed to find a\nfirst-order stationary point (i.e., $\\Vert \\nabla L(\\theta,\\gamma)\\Vert_2^2\n\\leq \\epsilon$) of the performance (Lagrange) function $L(\\theta,\\gamma)$, with\na sample complexity of $\\mathcal{\\tilde{O}}(\\epsilon^{-2.5})$ in the case of\nboth Constrained Actor Critic (C-AC) and Constrained Natural Actor Critic\n(C-NAC) algorithms.We also show the results of experiments on a few different\ngrid world settings and observe good empirical performance using both of these\nalgorithms. In particular, for large grid sizes, Constrained Natural Actor\nCritic shows slightly better results than Constrained Actor Critic while the\nlatter is slightly better for a small grid size.",
            "author": [
                "Prashansa Panda",
                "Shalabh Bhatnagar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16363v1",
                "http://arxiv.org/pdf/2310.16363v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16362v1",
            "title": "Neural Potential Field for Obstacle-Aware Local Motion Planning",
            "updated": "2023-10-25T05:00:21Z",
            "published": "2023-10-25T05:00:21Z",
            "summary": "Model predictive control (MPC) may provide local motion planning for mobile\nrobotic platforms. The challenging aspect is the analytic representation of\ncollision cost for the case when both the obstacle map and robot footprint are\narbitrary. We propose a Neural Potential Field: a neural network model that\nreturns a differentiable collision cost based on robot pose, obstacle map, and\nrobot footprint. The differentiability of our model allows its usage within the\nMPC solver. It is computationally hard to solve problems with a very high\nnumber of parameters. Therefore, our architecture includes neural image\nencoders, which transform obstacle maps and robot footprints into embeddings,\nwhich reduce problem dimensionality by two orders of magnitude. The reference\ndata for network training are generated based on algorithmic calculation of a\nsigned distance function. Comparative experiments showed that the proposed\napproach is comparable with existing local planners: it provides trajectories\nwith outperforming smoothness, comparable path length, and safe distance from\nobstacles. Experiment on Husky UGV mobile robot showed that our approach allows\nreal-time and safe local planning. The code for our approach is presented at\nhttps://github.com/cog-isa/NPField together with demo video.",
            "author": [
                "Muhammad Alhaddad",
                "Konstantin Mironov",
                "Aleksey Staroverov",
                "Aleksandr Panov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16362v1",
                "http://arxiv.org/pdf/2310.16362v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16355v1",
            "title": "Redco: A Lightweight Tool to Automate Distributed Training of LLMs on\n  Any GPU/TPUs",
            "updated": "2023-10-25T04:32:35Z",
            "published": "2023-10-25T04:32:35Z",
            "summary": "The recent progress of AI can be largely attributed to large language models\n(LLMs). However, their escalating memory requirements introduce challenges for\nmachine learning (ML) researchers and engineers. Addressing this requires\ndevelopers to partition a large model to distribute it across multiple GPUs or\nTPUs. This necessitates considerable coding and intricate configuration efforts\nwith existing model parallel tools, such as Megatron-LM, DeepSpeed, and Alpa.\nThese tools require users' expertise in machine learning systems (MLSys),\ncreating a bottleneck in LLM development, particularly for developers without\nMLSys background. In this work, we present Redco, a lightweight and\nuser-friendly tool crafted to automate distributed training and inference for\nLLMs, as well as to simplify ML pipeline development. The design of Redco\nemphasizes two key aspects. Firstly, to automate model parallism, our study\nidentifies two straightforward rules to generate tensor parallel strategies for\nany given LLM. Integrating these rules into Redco facilitates effortless\ndistributed LLM training and inference, eliminating the need of additional\ncoding or complex configurations. We demonstrate the effectiveness by applying\nRedco on a set of LLM architectures, such as GPT-J, LLaMA, T5, and OPT, up to\nthe size of 66B. Secondly, we propose a mechanism that allows for the\ncustomization of diverse ML pipelines through the definition of merely three\nfunctions, eliminating redundant and formulaic code like multi-host related\nprocessing. This mechanism proves adaptable across a spectrum of ML algorithms,\nfrom foundational language modeling to complex algorithms like meta-learning\nand reinforcement learning. Consequently, Redco implementations exhibit much\nfewer code lines compared to their official counterparts.",
            "author": [
                "Bowen Tan",
                "Yun Zhu",
                "Lijuan Liu",
                "Hongyi Wang",
                "Yonghao Zhuang",
                "Jindong Chen",
                "Eric Xing",
                "Zhiting Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16355v1",
                "http://arxiv.org/pdf/2310.16355v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16350v2",
            "title": "Unraveling Feature Extraction Mechanisms in Neural Networks",
            "updated": "2023-10-26T03:26:30Z",
            "published": "2023-10-25T04:22:40Z",
            "summary": "The underlying mechanism of neural networks in capturing precise knowledge\nhas been the subject of consistent research efforts. In this work, we propose a\ntheoretical approach based on Neural Tangent Kernels (NTKs) to investigate such\nmechanisms. Specifically, considering the infinite network width, we\nhypothesize the learning dynamics of target models may intuitively unravel the\nfeatures they acquire from training data, deepening our insights into their\ninternal mechanisms. We apply our approach to several fundamental models and\nreveal how these models leverage statistical features during gradient descent\nand how they are integrated into final decisions. We also discovered that the\nchoice of activation function can affect feature extraction. For instance, the\nuse of the \\textit{ReLU} activation function could potentially introduce a bias\nin features, providing a plausible explanation for its replacement with\nalternative functions in recent pre-trained language models. Additionally, we\nfind that while self-attention and CNN models may exhibit limitations in\nlearning n-grams, multiplication-based models seem to excel in this area. We\nverify these theoretical findings through experiments and find that they can be\napplied to analyze language modeling tasks, which can be regarded as a special\nvariant of classification. Our contributions offer insights into the roles and\ncapacities of fundamental components within large language models, thereby\naiding the broader understanding of these complex systems.",
            "author": [
                "Xiaobing Sun",
                "Jiaxi Li",
                "Wei Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16350v2",
                "http://arxiv.org/pdf/2310.16350v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16338v1",
            "title": "Generative Pre-training for Speech with Flow Matching",
            "updated": "2023-10-25T03:40:50Z",
            "published": "2023-10-25T03:40:50Z",
            "summary": "Generative models have gained more and more attention in recent years for\ntheir remarkable success in tasks that required estimating and sampling data\ndistribution to generate high-fidelity synthetic data. In speech,\ntext-to-speech synthesis and neural vocoder are good examples where generative\nmodels have shined. While generative models have been applied to different\napplications in speech, there exists no general-purpose generative model that\nmodels speech directly. In this work, we take a step toward this direction by\nshowing a single pre-trained generative model can be adapted to different\ndownstream tasks with strong performance. Specifically, we pre-trained a\ngenerative model, named SpeechFlow, on 60k hours of untranscribed speech with\nFlow Matching and masked conditions. Experiment results show the pre-trained\ngenerative model can be fine-tuned with task-specific data to match or surpass\nexisting expert models on speech enhancement, separation, and synthesis. Our\nwork suggested a foundational model for generation tasks in speech can be built\nwith generative pre-training.",
            "author": [
                "Alexander H. Liu",
                "Matt Le",
                "Apoorv Vyas",
                "Bowen Shi",
                "Andros Tjandra",
                "Wei-Ning Hsu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16338v1",
                "http://arxiv.org/pdf/2310.16338v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.CL",
                "cs.LG",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16336v1",
            "title": "SMURF-THP: Score Matching-based UnceRtainty quantiFication for\n  Transformer Hawkes Process",
            "updated": "2023-10-25T03:33:45Z",
            "published": "2023-10-25T03:33:45Z",
            "summary": "Transformer Hawkes process models have shown to be successful in modeling\nevent sequence data. However, most of the existing training methods rely on\nmaximizing the likelihood of event sequences, which involves calculating some\nintractable integral. Moreover, the existing methods fail to provide\nuncertainty quantification for model predictions, e.g., confidence intervals\nfor the predicted event's arrival time. To address these issues, we propose\nSMURF-THP, a score-based method for learning Transformer Hawkes process and\nquantifying prediction uncertainty. Specifically, SMURF-THP learns the score\nfunction of events' arrival time based on a score-matching objective that\navoids the intractable computation. With such a learned score function, we can\nsample arrival time of events from the predictive distribution. This naturally\nallows for the quantification of uncertainty by computing confidence intervals\nover the generated samples. We conduct extensive experiments in both event type\nprediction and uncertainty quantification of arrival time. In all the\nexperiments, SMURF-THP outperforms existing likelihood-based methods in\nconfidence calibration while exhibiting comparable prediction accuracy.",
            "author": [
                "Zichong Li",
                "Yanbo Xu",
                "Simiao Zuo",
                "Haoming Jiang",
                "Chao Zhang",
                "Tuo Zhao",
                "Hongyuan Zha"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16336v1",
                "http://arxiv.org/pdf/2310.16336v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16335v1",
            "title": "Defense Against Model Extraction Attacks on Recommender Systems",
            "updated": "2023-10-25T03:30:42Z",
            "published": "2023-10-25T03:30:42Z",
            "summary": "The robustness of recommender systems has become a prominent topic within the\nresearch community. Numerous adversarial attacks have been proposed, but most\nof them rely on extensive prior knowledge, such as all the white-box attacks or\nmost of the black-box attacks which assume that certain external knowledge is\navailable. Among these attacks, the model extraction attack stands out as a\npromising and practical method, involving training a surrogate model by\nrepeatedly querying the target model. However, there is a significant gap in\nthe existing literature when it comes to defending against model extraction\nattacks on recommender systems. In this paper, we introduce Gradient-based\nRanking Optimization (GRO), which is the first defense strategy designed to\ncounter such attacks. We formalize the defense as an optimization problem,\naiming to minimize the loss of the protected target model while maximizing the\nloss of the attacker's surrogate model. Since top-k ranking lists are\nnon-differentiable, we transform them into swap matrices which are instead\ndifferentiable. These swap matrices serve as input to a student model that\nemulates the surrogate model's behavior. By back-propagating the loss of the\nstudent model, we obtain gradients for the swap matrices. These gradients are\nused to compute a swap loss, which maximizes the loss of the student model. We\nconducted experiments on three benchmark datasets to evaluate the performance\nof GRO, and the results demonstrate its superior effectiveness in defending\nagainst model extraction attacks.",
            "author": [
                "Sixiao Zhang",
                "Hongzhi Yin",
                "Hongxu Chen",
                "Cheng Long"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16335v1",
                "http://arxiv.org/pdf/2310.16335v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16334v1",
            "title": "AccoMontage-3: Full-Band Accompaniment Arrangement via Sequential Style\n  Transfer and Multi-Track Function Prior",
            "updated": "2023-10-25T03:30:37Z",
            "published": "2023-10-25T03:30:37Z",
            "summary": "We propose AccoMontage-3, a symbolic music automation system capable of\ngenerating multi-track, full-band accompaniment based on the input of a lead\nmelody with chords (i.e., a lead sheet). The system contains three modular\ncomponents, each modelling a vital aspect of full-band composition. The first\ncomponent is a piano arranger that generates piano accompaniment for the lead\nsheet by transferring texture styles to the chords using latent chord-texture\ndisentanglement and heuristic retrieval of texture donors. The second component\norchestrates the piano accompaniment score into full-band arrangement according\nto the orchestration style encoded by individual track functions. The third\ncomponent, which connects the previous two, is a prior model characterizing the\nglobal structure of orchestration style over the whole piece of music. From end\nto end, the system learns to generate full-band accompaniment in a\nself-supervised fashion, applying style transfer at two levels of polyphonic\ncomposition: texture and orchestration. Experiments show that our system\noutperforms the baselines significantly, and the modular design offers\neffective controls in a musically meaningful way.",
            "author": [
                "Jingwei Zhao",
                "Gus Xia",
                "Ye Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16334v1",
                "http://arxiv.org/pdf/2310.16334v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.AI",
                "cs.MM",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16332v1",
            "title": "Corrupting Neuron Explanations of Deep Visual Features",
            "updated": "2023-10-25T03:28:37Z",
            "published": "2023-10-25T03:28:37Z",
            "summary": "The inability of DNNs to explain their black-box behavior has led to a recent\nsurge of explainability methods. However, there are growing concerns that these\nexplainability methods are not robust and trustworthy. In this work, we perform\nthe first robustness analysis of Neuron Explanation Methods under a unified\npipeline and show that these explanations can be significantly corrupted by\nrandom noises and well-designed perturbations added to their probing data. We\nfind that even adding small random noise with a standard deviation of 0.02 can\nalready change the assigned concepts of up to 28% neurons in the deeper layers.\nFurthermore, we devise a novel corruption algorithm and show that our algorithm\ncan manipulate the explanation of more than 80% neurons by poisoning less than\n10% of probing data. This raises the concern of trusting Neuron Explanation\nMethods in real-life safety and fairness critical applications.",
            "author": [
                "Divyansh Srivastava",
                "Tuomas Oikarinen",
                "Tsui-Wei Weng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16332v1",
                "http://arxiv.org/pdf/2310.16332v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16331v1",
            "title": "Brain-Inspired Reservoir Computing Using Memristors with Tunable\n  Dynamics and Short-Term Plasticity",
            "updated": "2023-10-25T03:27:43Z",
            "published": "2023-10-25T03:27:43Z",
            "summary": "Recent advancements in reservoir computing research have created a demand for\nanalog devices with dynamics that can facilitate the physical implementation of\nreservoirs, promising faster information processing while consuming less energy\nand occupying a smaller area footprint. Studies have demonstrated that dynamic\nmemristors, with nonlinear and short-term memory dynamics, are excellent\ncandidates as information-processing devices or reservoirs for temporal\nclassification and prediction tasks. Previous implementations relied on\nnominally identical memristors that applied the same nonlinear transformation\nto the input data, which is not enough to achieve a rich state space. To\naddress this limitation, researchers either diversified the data encoding\nacross multiple memristors or harnessed the stochastic device-to-device\nvariability among the memristors. However, this approach requires additional\npre-processing steps and leads to synchronization issues. Instead, it is\npreferable to encode the data once and pass it through a reservoir layer\nconsisting of memristors with distinct dynamics. Here, we demonstrate that\nion-channel-based memristors with voltage-dependent dynamics can be\ncontrollably and predictively tuned through voltage or adjustment of the ion\nchannel concentration to exhibit diverse dynamic properties. We show, through\nexperiments and simulations, that reservoir layers constructed with a small\nnumber of distinct memristors exhibit significantly higher predictive and\nclassification accuracies with a single data encoding. We found that for a\nsecond-order nonlinear dynamical system prediction task, the varied memristor\nreservoir experimentally achieved a normalized mean square error of 0.0015\nusing only five distinct memristors. Moreover, in a neural activity\nclassification task, a reservoir of just three distinct memristors\nexperimentally attained an accuracy of 96.5%.",
            "author": [
                "Nicholas X. Armendarez",
                "Ahmed S. Mohamed",
                "Anurag Dhungel",
                "Md Razuan Hossain",
                "Md Sakib Hasan",
                "Joseph S. Najem"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16331v1",
                "http://arxiv.org/pdf/2310.16331v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16326v1",
            "title": "Reinforcement Learning for SBM Graphon Games with Re-Sampling",
            "updated": "2023-10-25T03:14:48Z",
            "published": "2023-10-25T03:14:48Z",
            "summary": "The Mean-Field approximation is a tractable approach for studying large\npopulation dynamics. However, its assumption on homogeneity and universal\nconnections among all agents limits its applicability in many real-world\nscenarios. Multi-Population Mean-Field Game (MP-MFG) models have been\nintroduced in the literature to address these limitations. When the underlying\nStochastic Block Model is known, we show that a Policy Mirror Ascent algorithm\nfinds the MP-MFG Nash Equilibrium. In more realistic scenarios where the block\nmodel is unknown, we propose a re-sampling scheme from a graphon integrated\nwith the finite N-player MP-MFG model. We develop a novel learning framework\nbased on a Graphon Game with Re-Sampling (GGR-S) model, which captures the\ncomplex network structures of agents' connections. We analyze GGR-S dynamics\nand establish the convergence to dynamics of MP-MFG. Leveraging this result, we\npropose an efficient sample-based N-player Reinforcement Learning algorithm for\nGGR-S without population manipulation, and provide a rigorous convergence\nanalysis with finite sample guarantee.",
            "author": [
                "Peihan Huo",
                "Oscar Peralta",
                "Junyu Guo",
                "Qiaomin Xie",
                "Andreea Minca"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16326v1",
                "http://arxiv.org/pdf/2310.16326v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16324v1",
            "title": "Extracting Design Knowledge from Optimization Data: Enhancing\n  Engineering Design in Fluid Based Thermal Management Systems",
            "updated": "2023-10-25T03:13:52Z",
            "published": "2023-10-25T03:13:52Z",
            "summary": "As mechanical systems become more complex and technological advances\naccelerate, the traditional reliance on heritage designs for engineering\nendeavors is being diminished in its effectiveness. Considering the dynamic\nnature of the design industry where new challenges are continually emerging,\nalternative sources of knowledge need to be sought to guide future design\nefforts. One promising avenue lies in the analysis of design optimization data,\nwhich has the potential to offer valuable insights and overcome the limitations\nof heritage designs. This paper presents a step toward extracting knowledge\nfrom optimization data in multi-split fluid-based thermal management systems\nusing different classification machine learning methods, so that designers can\nuse it to guide decisions in future design efforts. This approach offers\nseveral advantages over traditional design heritage methods, including\napplicability in cases where there is no design heritage and the ability to\nderive optimal designs. We showcase our framework through four case studies\nwith varying levels of complexity. These studies demonstrate its effectiveness\nin enhancing the design of complex thermal management systems. Our results show\nthat the knowledge extracted from the configuration design optimization data\nprovides a good basis for more general design of complex thermal management\nsystems. It is shown that the objective value of the estimated optimal\nconfiguration closely approximates the true optimal configuration with less\nthan 1 percent error, achieved using basic features based on the system heat\nloads without involving the corresponding optimal open loop control (OLOC)\nfeatures. This eliminates the need to solve the OLOC problem, leading to\nreduced computation costs.",
            "author": [
                "Saeid Bayat",
                "Nastaran Shahmansouri",
                "Satya RT Peddada",
                "Alex Tessier",
                "Adrian Butscher",
                "James T Allison"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16324v1",
                "http://arxiv.org/pdf/2310.16324v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16323v1",
            "title": "Personalized Federated X -armed Bandit",
            "updated": "2023-10-25T03:11:32Z",
            "published": "2023-10-25T03:11:32Z",
            "summary": "In this work, we study the personalized federated $\\mathcal{X}$-armed bandit\nproblem, where the heterogeneous local objectives of the clients are optimized\nsimultaneously in the federated learning paradigm. We propose the\n\\texttt{PF-PNE} algorithm with a unique double elimination strategy, which\nsafely eliminates the non-optimal regions while encouraging federated\ncollaboration through biased but effective evaluations of the local objectives.\nThe proposed \\texttt{PF-PNE} algorithm is able to optimize local objectives\nwith arbitrary levels of heterogeneity, and its limited communications protects\nthe confidentiality of the client-wise reward data. Our theoretical analysis\nshows the benefit of the proposed algorithm over single-client algorithms.\nExperimentally, \\texttt{PF-PNE} outperforms multiple baselines on both\nsynthetic and real life datasets.",
            "author": [
                "Wenjie Li",
                "Qifan Song",
                "Jean Honorio"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16323v1",
                "http://arxiv.org/pdf/2310.16323v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16321v1",
            "title": "Neuromorphic cameras for Atmospheric Cherenkov Telescopes and fast\n  optical astronomy: new paradigm, challenges and opportunities",
            "updated": "2023-10-25T03:10:44Z",
            "published": "2023-10-25T03:10:44Z",
            "summary": "The astronomy community has witnessed an explosive growth in the use of\ndeep-learning techniques based on neural networks since the mid-2010s. The\nwidespread adoption of these nature-inspired technologies has helped\nastronomers tackle previously insurmountable problems and provided an\nunprecedented opportunity for new discoveries. However, one of the primary\ntools of today's optical astronomy is neither natural nor efficient: their\nphoto-sensing devices. Specifically, the modern CCD camera - like that of the\ncutting-edge Rubin Observatory - requires an internal clock to regularly expose\nthe sensor to light, consumes a large amount of energy and information\nbandwidth, and has a limited dynamic range. On the contrary, biological eyes\nlack an internal clock and a shutter, have much higher pixel density but\nconsume significantly less energy and bandwidth, and can adapt to bright and\nlow light conditions. Inspired by the nature of the eyes, M. Mahowald and C.\nMead introduced the revolutionary concept of a silicon retina sensor in 1991.\nAlso known as event-based cameras (EBCs), these types of devices operate in a\nvastly different way compared to conventional CCD-based imaging sensors. EBCs\nmimic the operating principles of optic nerves and continuously produce a\nstream of events, with each event generated only when a pixel detects a change\nin light intensity. EBCs do not have fixed exposure times, have high dynamic\nrange, require low power for operation, and can capture high-speed phenomena.\nThese properties are important requirements for Cherenkov telescopes as well as\nother high-speed optical astronomy. This work presents the opportunities and\nchallenges of using EBCs in those cases, and proposes a low-cost approach to\nexperimentally assess the feasibility of this innovative technique.",
            "author": [
                "John Hoang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16321v1",
                "http://arxiv.org/pdf/2310.16321v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16320v1",
            "title": "Enhancing Low-Precision Sampling via Stochastic Gradient Hamiltonian\n  Monte Carlo",
            "updated": "2023-10-25T03:06:48Z",
            "published": "2023-10-25T03:06:48Z",
            "summary": "Low-precision training has emerged as a promising low-cost technique to\nenhance the training efficiency of deep neural networks without sacrificing\nmuch accuracy. Its Bayesian counterpart can further provide uncertainty\nquantification and improved generalization accuracy. This paper investigates\nlow-precision sampling via Stochastic Gradient Hamiltonian Monte Carlo (SGHMC)\nwith low-precision and full-precision gradient accumulators for both strongly\nlog-concave and non-log-concave distributions. Theoretically, our results show\nthat, to achieve $\\epsilon$-error in the 2-Wasserstein distance for\nnon-log-concave distributions, low-precision SGHMC achieves quadratic\nimprovement\n($\\widetilde{\\mathbf{O}}\\left({\\epsilon^{-2}{\\mu^*}^{-2}\\log^2\\left({\\epsilon^{-1}}\\right)}\\right)$)\ncompared to the state-of-the-art low-precision sampler, Stochastic Gradient\nLangevin Dynamics (SGLD)\n($\\widetilde{\\mathbf{O}}\\left({{\\epsilon}^{-4}{\\lambda^{*}}^{-1}\\log^5\\left({\\epsilon^{-1}}\\right)}\\right)$).\nMoreover, we prove that low-precision SGHMC is more robust to the quantization\nerror compared to low-precision SGLD due to the robustness of the\nmomentum-based update w.r.t. gradient noise. Empirically, we conduct\nexperiments on synthetic data, and {MNIST, CIFAR-10 \\& CIFAR-100} datasets,\nwhich validate our theoretical findings. Our study highlights the potential of\nlow-precision SGHMC as an efficient and accurate sampling method for\nlarge-scale and resource-limited machine learning.",
            "author": [
                "Ziyi Wang",
                "Yujie Chen",
                "Qifan Song",
                "Ruqi Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16320v1",
                "http://arxiv.org/pdf/2310.16320v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16318v1",
            "title": "Modality-Agnostic Self-Supervised Learning with Meta-Learned Masked\n  Auto-Encoder",
            "updated": "2023-10-25T03:03:34Z",
            "published": "2023-10-25T03:03:34Z",
            "summary": "Despite its practical importance across a wide range of modalities, recent\nadvances in self-supervised learning (SSL) have been primarily focused on a few\nwell-curated domains, e.g., vision and language, often relying on their\ndomain-specific knowledge. For example, Masked Auto-Encoder (MAE) has become\none of the popular architectures in these domains, but less has explored its\npotential in other modalities. In this paper, we develop MAE as a unified,\nmodality-agnostic SSL framework. In turn, we argue meta-learning as a key to\ninterpreting MAE as a modality-agnostic learner, and propose enhancements to\nMAE from the motivation to jointly improve its SSL across diverse modalities,\ncoined MetaMAE as a result. Our key idea is to view the mask reconstruction of\nMAE as a meta-learning task: masked tokens are predicted by adapting the\nTransformer meta-learner through the amortization of unmasked tokens. Based on\nthis novel interpretation, we propose to integrate two advanced meta-learning\ntechniques. First, we adapt the amortized latent of the Transformer encoder\nusing gradient-based meta-learning to enhance the reconstruction. Then, we\nmaximize the alignment between amortized and adapted latents through task\ncontrastive learning which guides the Transformer encoder to better encode the\ntask-specific knowledge. Our experiment demonstrates the superiority of MetaMAE\nin the modality-agnostic SSL benchmark (called DABS), significantly\noutperforming prior baselines. Code is available at\nhttps://github.com/alinlab/MetaMAE.",
            "author": [
                "Huiwon Jang",
                "Jihoon Tack",
                "Daewon Choi",
                "Jongheon Jeong",
                "Jinwoo Shin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16318v1",
                "http://arxiv.org/pdf/2310.16318v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16316v1",
            "title": "Sum-of-Parts Models: Faithful Attributions for Groups of Features",
            "updated": "2023-10-25T02:50:10Z",
            "published": "2023-10-25T02:50:10Z",
            "summary": "An explanation of a machine learning model is considered \"faithful\" if it\naccurately reflects the model's decision-making process. However, explanations\nsuch as feature attributions for deep learning are not guaranteed to be\nfaithful, and can produce potentially misleading interpretations. In this work,\nwe develop Sum-of-Parts (SOP), a class of models whose predictions come with\ngrouped feature attributions that are faithful-by-construction. This model\ndecomposes a prediction into an interpretable sum of scores, each of which is\ndirectly attributable to a sparse group of features. We evaluate SOP on\nbenchmarks with standard interpretability metrics, and in a case study, we use\nthe faithful explanations from SOP to help astrophysicists discover new\nknowledge about galaxy formation.",
            "author": [
                "Weiqiu You",
                "Helen Qu",
                "Marco Gatti",
                "Bhuvnesh Jain",
                "Eric Wong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16316v1",
                "http://arxiv.org/pdf/2310.16316v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16314v2",
            "title": "Understanding Code Semantics: An Evaluation of Transformer Models in\n  Summarization",
            "updated": "2023-10-27T01:22:52Z",
            "published": "2023-10-25T02:41:50Z",
            "summary": "This paper delves into the intricacies of code summarization using advanced\ntransformer-based language models. Through empirical studies, we evaluate the\nefficacy of code summarization by altering function and variable names to\nexplore whether models truly understand code semantics or merely rely on\ntextual cues. We have also introduced adversaries like dead code and commented\ncode across three programming languages (Python, Javascript, and Java) to\nfurther scrutinize the model's understanding. Ultimately, our research aims to\noffer valuable insights into the inner workings of transformer-based LMs,\nenhancing their ability to understand code and contributing to more efficient\nsoftware development practices and maintenance workflows.",
            "author": [
                "Debanjan Mondal",
                "Abhilasha Lodha",
                "Ankita Sahoo",
                "Beena Kumari"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16314v2",
                "http://arxiv.org/pdf/2310.16314v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16310v1",
            "title": "Score Matching-based Pseudolikelihood Estimation of Neural Marked\n  Spatio-Temporal Point Process with Uncertainty Quantification",
            "updated": "2023-10-25T02:37:51Z",
            "published": "2023-10-25T02:37:51Z",
            "summary": "Spatio-temporal point processes (STPPs) are potent mathematical tools for\nmodeling and predicting events with both temporal and spatial features. Despite\ntheir versatility, most existing methods for learning STPPs either assume a\nrestricted form of the spatio-temporal distribution, or suffer from inaccurate\napproximations of the intractable integral in the likelihood training\nobjective. These issues typically arise from the normalization term of the\nprobability density function. Moreover, current techniques fail to provide\nuncertainty quantification for model predictions, such as confidence intervals\nfor the predicted event's arrival time and confidence regions for the event's\nlocation, which is crucial given the considerable randomness of the data. To\ntackle these challenges, we introduce SMASH: a Score MAtching-based\npSeudolikeliHood estimator for learning marked STPPs with uncertainty\nquantification. Specifically, our framework adopts a normalization-free\nobjective by estimating the pseudolikelihood of marked STPPs through\nscore-matching and offers uncertainty quantification for the predicted event\ntime, location and mark by computing confidence regions over the generated\nsamples. The superior performance of our proposed framework is demonstrated\nthrough extensive experiments in both event prediction and uncertainty\nquantification.",
            "author": [
                "Zichong Li",
                "Qunzhi Xu",
                "Zhenghao Xu",
                "Yajun Mei",
                "Tuo Zhao",
                "Hongyuan Zha"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16310v1",
                "http://arxiv.org/pdf/2310.16310v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16308v1",
            "title": "Diffusion model approach to simulating electron-proton scattering events",
            "updated": "2023-10-25T02:29:06Z",
            "published": "2023-10-25T02:29:06Z",
            "summary": "Generative AI is a fast-growing area of research offering various avenues for\nexploration in high-energy nuclear physics. In this work, we explore the use of\ngenerative models for simulating electron-proton collisions relevant to\nexperiments like CEBAF and the future Electron-Ion Collider (EIC). These\nexperiments play a critical role in advancing our understanding of nucleons and\nnuclei in terms of quark and gluon degrees of freedom. The use of generative\nmodels for simulating collider events faces several challenges such as the\nsparsity of the data, the presence of global or event-wide constraints, and\nsteeply falling particle distributions. In this work, we focus on the\nimplementation of diffusion models for the simulation of electron-proton\nscattering events at EIC energies. Our results demonstrate that diffusion\nmodels can accurately reproduce relevant observables such as momentum\ndistributions and correlations of particles, momentum sum rules, and the\nleading electron kinematics, all of which are of particular interest in\nelectron-proton collisions. Although the sampling process is relatively slow\ncompared to other machine learning architectures, we find diffusion models can\ngenerate high-quality samples. We foresee various applications of our work\nincluding inference for nuclear structure, interpretable generative machine\nlearning, and searches of physics beyond the Standard Model.",
            "author": [
                "Peter Devlin",
                "Jian-Wei Qiu",
                "Felix Ringer",
                "Nobuo Sato"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16308v1",
                "http://arxiv.org/pdf/2310.16308v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex",
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16305v1",
            "title": "Dolfin: Diffusion Layout Transformers without Autoencoder",
            "updated": "2023-10-25T02:26:04Z",
            "published": "2023-10-25T02:26:04Z",
            "summary": "In this paper, we introduce a novel generative model, Diffusion Layout\nTransformers without Autoencoder (Dolfin), which significantly improves the\nmodeling capability with reduced complexity compared to existing methods.\nDolfin employs a Transformer-based diffusion process to model layout\ngeneration. In addition to an efficient bi-directional (non-causal joint)\nsequence representation, we further propose an autoregressive diffusion model\n(Dolfin-AR) that is especially adept at capturing rich semantic correlations\nfor the neighboring objects, such as alignment, size, and overlap. When\nevaluated against standard generative layout benchmarks, Dolfin notably\nimproves performance across various metrics (fid, alignment, overlap, MaxIoU\nand DocSim scores), enhancing transparency and interoperability in the process.\nMoreover, Dolfin's applications extend beyond layout generation, making it\nsuitable for modeling geometric structures, such as line segments. Our\nexperiments present both qualitative and quantitative results to demonstrate\nthe advantages of Dolfin.",
            "author": [
                "Yilin Wang",
                "Zeyuan Chen",
                "Liangjun Zhong",
                "Zheng Ding",
                "Zhizhou Sha",
                "Zhuowen Tu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16305v1",
                "http://arxiv.org/pdf/2310.16305v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16304v1",
            "title": "Deep Learning Approach to Photometric Redshift Estimation",
            "updated": "2023-10-25T02:24:37Z",
            "published": "2023-10-25T02:24:37Z",
            "summary": "Photometric redshift estimation, an essential process in astronomy for\ndistance estimation, obtains the redshift of celestial structures by utilizing\nthe magnitude of objects in varying wavelength filters. This research\ncapitalized on a dataset of 50,000 objects from the Sloan Digital Sky Survey,\ncomprising 5 bands of magnitudes and their corresponding redshift labels.\nTypically, studies use spectral distribution templates (SED) for redshift\nprediction. However, these templates are expensive and hard to obtain,\nespecially with larger datasets. The paper explores approaches for Data-Driven\nmethodology instead of template based prediction. Adopting both a decision tree\nregression model and a Fully Connected Neural Network (FCN) for analysis, the\nFCN significantly outperformed the decision tree regressor, achieving an\nimpressive root mean square error (RMSE) of 0.009 compared to the decision\ntree's RMSE above 0.16. The strong performance of the FCN highlights its\nability to capture intricate relationships in astronomical data, holding the\npotential for data-driven redshift estimation, which will help advance next\ngeneration surveys.",
            "author": [
                "Krishna Chunduri",
                "Mithun Mahesh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16304v1",
                "http://arxiv.org/pdf/2310.16304v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16303v1",
            "title": "URL-BERT: Training Webpage Representations via Social Media Engagements",
            "updated": "2023-10-25T02:22:50Z",
            "published": "2023-10-25T02:22:50Z",
            "summary": "Understanding and representing webpages is crucial to online social networks\nwhere users may share and engage with URLs. Common language model (LM) encoders\nsuch as BERT can be used to understand and represent the textual content of\nwebpages. However, these representations may not model thematic information of\nweb domains and URLs or accurately capture their appeal to social media users.\nIn this work, we introduce a new pre-training objective that can be used to\nadapt LMs to understand URLs and webpages. Our proposed framework consists of\ntwo steps: (1) scalable graph embeddings to learn shallow representations of\nURLs based on user engagement on social media and (2) a contrastive objective\nthat aligns LM representations with the aforementioned graph-based\nrepresentation. We apply our framework to the multilingual version of BERT to\nobtain the model URL-BERT. We experimentally demonstrate that our continued\npre-training approach improves webpage understanding on a variety of tasks and\nTwitter internal and external benchmarks.",
            "author": [
                "Ayesha Qamar",
                "Chetan Verma",
                "Ahmed El-Kishky",
                "Sumit Binnani",
                "Sneha Mehta",
                "Taylor Berg-Kirkpatrick"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16303v1",
                "http://arxiv.org/pdf/2310.16303v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16302v1",
            "title": "Imperfect Digital Twin Assisted Low Cost Reinforcement Training for\n  Multi-UAV Networks",
            "updated": "2023-10-25T02:19:19Z",
            "published": "2023-10-25T02:19:19Z",
            "summary": "Deep Reinforcement Learning (DRL) is widely used to optimize the performance\nof multi-UAV networks. However, the training of DRL relies on the frequent\ninteractions between the UAVs and the environment, which consumes lots of\nenergy due to the flying and communication of UAVs in practical experiments.\nInspired by the growing digital twin (DT) technology, which can simulate the\nperformance of algorithms in the digital space constructed by coping features\nof the physical space, the DT is introduced to reduce the costs of practical\ntraining, e.g., energy and hardware purchases. Different from previous\nDT-assisted works with an assumption of perfect reflecting real physics by\nvirtual digital, we consider an imperfect DT model with deviations for\nassisting the training of multi-UAV networks. Remarkably, to trade off the\ntraining cost, DT construction cost, and the impact of deviations of DT on\ntraining, the natural and virtually generated UAV mixing deployment method is\nproposed. Two cascade neural networks (NN) are used to optimize the joint\nnumber of virtually generated UAVs, the DT construction cost, and the\nperformance of multi-UAV networks. These two NNs are trained by unsupervised\nand reinforcement learning, both low-cost label-free training methods.\nSimulation results show the training cost can significantly decrease while\nguaranteeing the training performance. This implies that an efficient decision\ncan be made with imperfect DTs in multi-UAV networks.",
            "author": [
                "Xiucheng Wang",
                "Nan Cheng",
                "Longfei Ma",
                "Zhisheng Yin",
                "Tom. Luan",
                "Ning Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16302v1",
                "http://arxiv.org/pdf/2310.16302v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16301v1",
            "title": "Is ChatGPT a Good Multi-Party Conversation Solver?",
            "updated": "2023-10-25T02:18:40Z",
            "published": "2023-10-25T02:18:40Z",
            "summary": "Large Language Models (LLMs) have emerged as influential instruments within\nthe realm of natural language processing; nevertheless, their capacity to\nhandle multi-party conversations (MPCs) -- a scenario marked by the presence of\nmultiple interlocutors involved in intricate information exchanges -- remains\nuncharted. In this paper, we delve into the potential of generative LLMs such\nas ChatGPT and GPT-4 within the context of MPCs. An empirical analysis is\nconducted to assess the zero-shot learning capabilities of ChatGPT and GPT-4 by\nsubjecting them to evaluation across three MPC datasets that encompass five\nrepresentative tasks. The findings reveal that ChatGPT's performance on a\nnumber of evaluated MPC tasks leaves much to be desired, whilst GPT-4's results\nportend a promising future. Additionally, we endeavor to bolster performance\nthrough the incorporation of MPC structures, encompassing both speaker and\naddressee architecture. This study provides an exhaustive evaluation and\nanalysis of applying generative LLMs to MPCs, casting a light upon the\nconception and creation of increasingly effective and robust MPC agents.\nConcurrently, this work underscores the challenges implicit in the utilization\nof LLMs for MPCs, such as deciphering graphical information flows and\ngenerating stylistically consistent responses.",
            "author": [
                "Chao-Hong Tan",
                "Jia-Chen Gu",
                "Zhen-Hua Ling"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16301v1",
                "http://arxiv.org/pdf/2310.16301v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19822v1",
            "title": "FuXi-Extreme: Improving extreme rainfall and wind forecasts with\n  diffusion model",
            "updated": "2023-10-25T02:16:02Z",
            "published": "2023-10-25T02:16:02Z",
            "summary": "Significant advancements in the development of machine learning (ML) models\nfor weather forecasting have produced remarkable results. State-of-the-art\nML-based weather forecast models, such as FuXi, have demonstrated superior\nstatistical forecast performance in comparison to the high-resolution forecasts\n(HRES) of the European Centre for Medium-Range Weather Forecasts (ECMWF).\nHowever, ML models face a common challenge: as forecast lead times increase,\nthey tend to generate increasingly smooth predictions, leading to an\nunderestimation of the intensity of extreme weather events. To address this\nchallenge, we developed the FuXi-Extreme model, which employs a denoising\ndiffusion probabilistic model (DDPM) to restore finer-scale details in the\nsurface forecast data generated by the FuXi model in 5-day forecasts. An\nevaluation of extreme total precipitation ($\\textrm{TP}$), 10-meter wind speed\n($\\textrm{WS10}$), and 2-meter temperature ($\\textrm{T2M}$) illustrates the\nsuperior performance of FuXi-Extreme over both FuXi and HRES. Moreover, when\nevaluating tropical cyclone (TC) forecasts based on International Best Track\nArchive for Climate Stewardship (IBTrACS) dataset, both FuXi and FuXi-Extreme\nshows superior performance in TC track forecasts compared to HRES, but they\nshow inferior performance in TC intensity forecasts in comparison to HRES.",
            "author": [
                "Xiaohui Zhong",
                "Lei Chen",
                "Jun Liu",
                "Chensen Lin",
                "Yuan Qi",
                "Hao Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19822v1",
                "http://arxiv.org/pdf/2310.19822v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.ao-ph",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16295v1",
            "title": "Instance-wise Linearization of Neural Network for Model Interpretation",
            "updated": "2023-10-25T02:07:39Z",
            "published": "2023-10-25T02:07:39Z",
            "summary": "Neural network have achieved remarkable successes in many scientific fields.\nHowever, the interpretability of the neural network model is still a major\nbottlenecks to deploy such technique into our daily life. The challenge can\ndive into the non-linear behavior of the neural network, which rises a critical\nquestion that how a model use input feature to make a decision. The classical\napproach to address this challenge is feature attribution, which assigns an\nimportant score to each input feature and reveal its importance of current\nprediction. However, current feature attribution approaches often indicate the\nimportance of each input feature without detail of how they are actually\nprocessed by a model internally. These attribution approaches often raise a\nconcern that whether they highlight correct features for a model prediction.\n  For a neural network model, the non-linear behavior is often caused by\nnon-linear activation units of a model. However, the computation behavior of a\nprediction from a neural network model is locally linear, because one\nprediction has only one activation pattern. Base on the observation, we propose\nan instance-wise linearization approach to reformulates the forward computation\nprocess of a neural network prediction. This approach reformulates different\nlayers of convolution neural networks into linear matrix multiplication.\nAggregating all layers' computation, a prediction complex convolution neural\nnetwork operations can be described as a linear matrix multiplication $F(x) = W\n\\cdot x + b$. This equation can not only provides a feature attribution map\nthat highlights the important of the input features but also tells how each\ninput feature contributes to a prediction exactly. Furthermore, we discuss the\napplication of this technique in both supervise classification and unsupervised\nneural network learning parametric t-SNE dimension reduction.",
            "author": [
                "Zhimin Li",
                "Shusen Liu",
                "Kailkhura Bhavya",
                "Timo Bremer",
                "Valerio Pascucci"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16295v1",
                "http://arxiv.org/pdf/2310.16295v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16293v1",
            "title": "Crowd-Certain: Label Aggregation in Crowdsourced and Ensemble Learning\n  Classification",
            "updated": "2023-10-25T01:58:37Z",
            "published": "2023-10-25T01:58:37Z",
            "summary": "Crowdsourcing systems have been used to accumulate massive amounts of labeled\ndata for applications such as computer vision and natural language processing.\nHowever, because crowdsourced labeling is inherently dynamic and uncertain,\ndeveloping a technique that can work in most situations is extremely\nchallenging. In this paper, we introduce Crowd-Certain, a novel approach for\nlabel aggregation in crowdsourced and ensemble learning classification tasks\nthat offers improved performance and computational efficiency for different\nnumbers of annotators and a variety of datasets. The proposed method uses the\nconsistency of the annotators versus a trained classifier to determine a\nreliability score for each annotator. Furthermore, Crowd-Certain leverages\npredicted probabilities, enabling the reuse of trained classifiers on future\nsample data, thereby eliminating the need for recurrent simulation processes\ninherent in existing methods. We extensively evaluated our approach against ten\nexisting techniques across ten different datasets, each labeled by varying\nnumbers of annotators. The findings demonstrate that Crowd-Certain outperforms\nthe existing methods (Tao, Sheng, KOS, MACE, MajorityVote, MMSR, Wawa,\nZero-Based Skill, GLAD, and Dawid Skene), in nearly all scenarios, delivering\nhigher average accuracy, F1 scores, and AUC rates. Additionally, we introduce a\nvariation of two existing confidence score measurement techniques. Finally we\nevaluate these two confidence score techniques using two evaluation metrics:\nExpected Calibration Error (ECE) and Brier Score Loss. Our results show that\nCrowd-Certain achieves higher Brier Score, and lower ECE across the majority of\nthe examined datasets, suggesting better calibrated results.",
            "author": [
                "Mohammad S. Majdi",
                "Jeffrey J. Rodriguez"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16293v1",
                "http://arxiv.org/pdf/2310.16293v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16290v1",
            "title": "Fair Adaptive Experiments",
            "updated": "2023-10-25T01:52:41Z",
            "published": "2023-10-25T01:52:41Z",
            "summary": "Randomized experiments have been the gold standard for assessing the\neffectiveness of a treatment or policy. The classical complete randomization\napproach assigns treatments based on a prespecified probability and may lead to\ninefficient use of data. Adaptive experiments improve upon complete\nrandomization by sequentially learning and updating treatment assignment\nprobabilities. However, their application can also raise fairness and equity\nconcerns, as assignment probabilities may vary drastically across groups of\nparticipants. Furthermore, when treatment is expected to be extremely\nbeneficial to certain groups of participants, it is more appropriate to expose\nmany of these participants to favorable treatment. In response to these\nchallenges, we propose a fair adaptive experiment strategy that simultaneously\nenhances data use efficiency, achieves an envy-free treatment assignment\nguarantee, and improves the overall welfare of participants. An important\nfeature of our proposed strategy is that we do not impose parametric modeling\nassumptions on the outcome variables, making it more versatile and applicable\nto a wider array of applications. Through our theoretical investigation, we\ncharacterize the convergence rate of the estimated treatment effects and the\nassociated standard deviations at the group level and further prove that our\nadaptive treatment assignment algorithm, despite not having a closed-form\nexpression, approaches the optimal allocation rule asymptotically. Our proof\nstrategy takes into account the fact that the allocation decisions in our\ndesign depend on sequentially accumulated data, which poses a significant\nchallenge in characterizing the properties and conducting statistical inference\nof our method. We further provide simulation evidence to showcase the\nperformance of our fair adaptive experiment strategy.",
            "author": [
                "Waverly Wei",
                "Xinwei Ma",
                "Jingshen Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16290v1",
                "http://arxiv.org/pdf/2310.16290v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "econ.EM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12858v1",
            "title": "RAEDiff: Denoising Diffusion Probabilistic Models Based Reversible\n  Adversarial Examples Self-Generation and Self-Recovery",
            "updated": "2023-10-25T01:49:29Z",
            "published": "2023-10-25T01:49:29Z",
            "summary": "Collected and annotated datasets, which are obtained through extensive\nefforts, are effective for training Deep Neural Network (DNN) models. However,\nthese datasets are susceptible to be misused by unauthorized users, resulting\nin infringement of Intellectual Property (IP) rights owned by the dataset\ncreators. Reversible Adversarial Exsamples (RAE) can help to solve the issues\nof IP protection for datasets. RAEs are adversarial perturbed images that can\nbe restored to the original. As a cutting-edge approach, RAE scheme can serve\nthe purposes of preventing unauthorized users from engaging in malicious model\ntraining, as well as ensuring the legitimate usage of authorized users.\nNevertheless, in the existing work, RAEs still rely on the embedded auxiliary\ninformation for restoration, which may compromise their adversarial abilities.\nIn this paper, a novel self-generation and self-recovery method, named as\nRAEDiff, is introduced for generating RAEs based on a Denoising Diffusion\nProbabilistic Models (DDPM). It diffuses datasets into a Biased Gaussian\nDistribution (BGD) and utilizes the prior knowledge of the DDPM for generating\nand recovering RAEs. The experimental results demonstrate that RAEDiff\neffectively self-generates adversarial perturbations for DNN models, including\nArtificial Intelligence Generated Content (AIGC) models, while also exhibiting\nsignificant self-recovery capabilities.",
            "author": [
                "Fan Xing",
                "Xiaoyi Zhou",
                "Xuefeng Fan",
                "Zhuo Tian",
                "Yan Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12858v1",
                "http://arxiv.org/pdf/2311.12858v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16288v1",
            "title": "MotionAGFormer: Enhancing 3D Human Pose Estimation with a\n  Transformer-GCNFormer Network",
            "updated": "2023-10-25T01:46:35Z",
            "published": "2023-10-25T01:46:35Z",
            "summary": "Recent transformer-based approaches have demonstrated excellent performance\nin 3D human pose estimation. However, they have a holistic view and by encoding\nglobal relationships between all the joints, they do not capture the local\ndependencies precisely. In this paper, we present a novel Attention-GCNFormer\n(AGFormer) block that divides the number of channels by using two parallel\ntransformer and GCNFormer streams. Our proposed GCNFormer module exploits the\nlocal relationship between adjacent joints, outputting a new representation\nthat is complementary to the transformer output. By fusing these two\nrepresentation in an adaptive way, AGFormer exhibits the ability to better\nlearn the underlying 3D structure. By stacking multiple AGFormer blocks, we\npropose MotionAGFormer in four different variants, which can be chosen based on\nthe speed-accuracy trade-off. We evaluate our model on two popular benchmark\ndatasets: Human3.6M and MPI-INF-3DHP. MotionAGFormer-B achieves\nstate-of-the-art results, with P1 errors of 38.4mm and 16.2mm, respectively.\nRemarkably, it uses a quarter of the parameters and is three times more\ncomputationally efficient than the previous leading model on Human3.6M dataset.\nCode and models are available at https://github.com/TaatiTeam/MotionAGFormer.",
            "author": [
                "Soroush Mehraban",
                "Vida Adeli",
                "Babak Taati"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16288v1",
                "http://arxiv.org/pdf/2310.16288v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16285v1",
            "title": "Removing Dust from CMB Observations with Diffusion Models",
            "updated": "2023-10-25T01:36:48Z",
            "published": "2023-10-25T01:36:48Z",
            "summary": "In cosmology, the quest for primordial $B$-modes in cosmic microwave\nbackground (CMB) observations has highlighted the critical need for a refined\nmodel of the Galactic dust foreground. We investigate diffusion-based modeling\nof the dust foreground and its interest for component separation. Under the\nassumption of a Gaussian CMB with known cosmology (or covariance matrix), we\nshow that diffusion models can be trained on examples of dust emission maps\nsuch that their sampling process directly coincides with posterior sampling in\nthe context of component separation. We illustrate this on simulated mixtures\nof dust emission and CMB. We show that common summary statistics (power\nspectrum, Minkowski functionals) of the components are well recovered by this\nprocess. We also introduce a model conditioned by the CMB cosmology that\noutperforms models trained using a single cosmology on component separation.\nSuch a model will be used in future work for diffusion-based cosmological\ninference.",
            "author": [
                "David Heurtel-Depeiges",
                "Blakesley Burkhart",
                "Ruben Ohana",
                "Bruno R\u00e9galdo-Saint Blancard"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16285v1",
                "http://arxiv.org/pdf/2310.16285v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.GA",
                "astro-ph.IM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16857v1",
            "title": "Improvement in Alzheimer's Disease MRI Images Analysis by Convolutional\n  Neural Networks Via Topological Optimization",
            "updated": "2023-10-25T01:36:00Z",
            "published": "2023-10-25T01:36:00Z",
            "summary": "This research underscores the efficacy of Fourier topological optimization in\nrefining MRI imagery, thereby bolstering the classification precision of\nAlzheimer's Disease through convolutional neural networks. Recognizing that MRI\nscans are indispensable for neurological assessments, but frequently grapple\nwith issues like blurriness and contrast irregularities, the deployment of\nFourier topological optimization offered enhanced delineation of brain\nstructures, ameliorated noise, and superior contrast. The applied techniques\nprioritized boundary enhancement, contrast and brightness adjustments, and\noverall image lucidity. Employing CNN architectures VGG16, ResNet50,\nInceptionV3, and Xception, the post-optimization analysis revealed a marked\nelevation in performance. Conclusively, the amalgamation of Fourier topological\noptimization with CNNs delineates a promising trajectory for the nuanced\nclassification of Alzheimer's Disease, portending a transformative impact on\nits diagnostic paradigms.",
            "author": [
                "Peiwen Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16857v1",
                "http://arxiv.org/pdf/2310.16857v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.03707v1",
            "title": "Multi-label Text Classification using GloVe and Neural Network Models",
            "updated": "2023-10-25T01:30:26Z",
            "published": "2023-10-25T01:30:26Z",
            "summary": "This study addresses the challenges of multi-label text classification. The\ndifficulties arise from imbalanced data sets, varied text lengths, and numerous\nsubjective feature labels. Existing solutions include traditional machine\nlearning and deep neural networks for predictions. However, both approaches\nhave their limitations. Traditional machine learning often overlooks the\nassociations between words, while deep neural networks, despite their better\nclassification performance, come with increased training complexity and time.\nThis paper proposes a method utilizing the bag-of-words model approach based on\nthe GloVe model and the CNN-BiLSTM network. The principle is to use the word\nvector matrix trained by the GloVe model as the input for the text embedding\nlayer. Given that the GloVe model requires no further training, the neural\nnetwork model can be trained more efficiently. The method achieves an accuracy\nrate of 87.26% on the test set and an F1 score of 0.8737, showcasing promising\nresults.",
            "author": [
                "Hongren Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2312.03707v1",
                "http://arxiv.org/pdf/2312.03707v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16279v1",
            "title": "TransPose: 6D Object Pose Estimation with Geometry-Aware Transformer",
            "updated": "2023-10-25T01:24:12Z",
            "published": "2023-10-25T01:24:12Z",
            "summary": "Estimating the 6D object pose is an essential task in many applications. Due\nto the lack of depth information, existing RGB-based methods are sensitive to\nocclusion and illumination changes. How to extract and utilize the geometry\nfeatures in depth information is crucial to achieve accurate predictions. To\nthis end, we propose TransPose, a novel 6D pose framework that exploits\nTransformer Encoder with geometry-aware module to develop better learning of\npoint cloud feature representations. Specifically, we first uniformly sample\npoint cloud and extract local geometry features with the designed local feature\nextractor base on graph convolution network. To improve robustness to\nocclusion, we adopt Transformer to perform the exchange of global information,\nmaking each local feature contains global information. Finally, we introduce\ngeometry-aware module in Transformer Encoder, which to form an effective\nconstrain for point cloud feature learning and makes the global information\nexchange more tightly coupled with point cloud tasks. Extensive experiments\nindicate the effectiveness of TransPose, our pose estimation pipeline achieves\ncompetitive results on three benchmark datasets.",
            "author": [
                "Xiao Lin",
                "Deming Wang",
                "Guangliang Zhou",
                "Chengju Liu",
                "Qijun Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16279v1",
                "http://arxiv.org/pdf/2310.16279v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16278v1",
            "title": "XFEVER: Exploring Fact Verification across Languages",
            "updated": "2023-10-25T01:20:17Z",
            "published": "2023-10-25T01:20:17Z",
            "summary": "This paper introduces the Cross-lingual Fact Extraction and VERification\n(XFEVER) dataset designed for benchmarking the fact verification models across\ndifferent languages. We constructed it by translating the claim and evidence\ntexts of the Fact Extraction and VERification (FEVER) dataset into six\nlanguages. The training and development sets were translated using machine\ntranslation, whereas the test set includes texts translated by professional\ntranslators and machine-translated texts. Using the XFEVER dataset, two\ncross-lingual fact verification scenarios, zero-shot learning and\ntranslate-train learning, are defined, and baseline models for each scenario\nare also proposed in this paper. Experimental results show that the\nmultilingual language model can be used to build fact verification models in\ndifferent languages efficiently. However, the performance varies by language\nand is somewhat inferior to the English case. We also found that we can\neffectively mitigate model miscalibration by considering the prediction\nsimilarity between the English and target languages. The XFEVER dataset, code,\nand model checkpoints are available at\nhttps://github.com/nii-yamagishilab/xfever.",
            "author": [
                "Yi-Chen Chang",
                "Canasai Kruengkrai",
                "Junichi Yamagishi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16278v1",
                "http://arxiv.org/pdf/2310.16278v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16277v1",
            "title": "Bayesian Domain Invariant Learning via Posterior Generalization of\n  Parameter Distributions",
            "updated": "2023-10-25T01:17:08Z",
            "published": "2023-10-25T01:17:08Z",
            "summary": "Domain invariant learning aims to learn models that extract invariant\nfeatures over various training domains, resulting in better generalization to\nunseen target domains. Recently, Bayesian Neural Networks have achieved\npromising results in domain invariant learning, but most works concentrate on\naligning features distributions rather than parameter distributions. Inspired\nby the principle of Bayesian Neural Network, we attempt to directly learn the\ndomain invariant posterior distribution of network parameters. We first propose\na theorem to show that the invariant posterior of parameters can be implicitly\ninferred by aggregating posteriors on different training domains. Our\nassumption is more relaxed and allows us to extract more domain invariant\ninformation. We also propose a simple yet effective method, named PosTerior\nGeneralization (PTG), that can be used to estimate the invariant parameter\ndistribution. PTG fully exploits variational inference to approximate parameter\ndistributions, including the invariant posterior and the posteriors on training\ndomains. Furthermore, we develop a lite version of PTG for widespread\napplications. PTG shows competitive performance on various domain\ngeneralization benchmarks on DomainBed. Additionally, PTG can use any existing\ndomain generalization methods as its prior, and combined with previous\nstate-of-the-art method the performance can be further improved. Code will be\nmade public.",
            "author": [
                "Shiyu Shen",
                "Bin Pan",
                "Tianyang Shi",
                "Tao Li",
                "Zhenwei Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16277v1",
                "http://arxiv.org/pdf/2310.16277v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12857v1",
            "title": "Adversarial sample generation and training using geometric masks for\n  accurate and resilient license plate character recognition",
            "updated": "2023-10-25T01:17:07Z",
            "published": "2023-10-25T01:17:07Z",
            "summary": "Reading dirty license plates accurately in moving vehicles is challenging for\nautomatic license plate recognition systems. Moreover, license plates are often\nintentionally tampered with a malicious intent to avoid police apprehension.\nUsually, such groups and individuals know how to fool the existing recognition\nsystems by making minor unnoticeable plate changes. Designing and developing\ndeep learning methods resilient to such real-world 'attack' practices remains\nan active research problem. As a solution, this work develops a resilient\nmethod to recognize license plate characters. Extracting 1057 character images\nfrom 160 Nepalese vehicles, as the first step, we trained several standard deep\nconvolutional neural networks to obtain 99.5% character classification\naccuracy. On adversarial images generated to simulate malicious tampering,\nhowever, our model's accuracy dropped to 25%. Next, we enriched our dataset by\ngenerating and adding geometrically masked images, retrained our models, and\ninvestigated the models' predictions. The proposed approach of training with\ngenerated adversarial images helped our adversarial attack-aware license plate\ncharacter recognition (AA-LPCR) model achieves an accuracy of 99.7%. This\nnear-perfect accuracy demonstrates that the proposed idea of random geometric\nmasking is highly effective for improving the accuracy of license plate\nrecognition models. Furthermore, by performing interpretability studies to\nunderstand why our models work, we identify and highlight attack-prone regions\nin the input character images. In sum, although Nepal's embossed license plate\ndetection systems are vulnerable to malicious attacks, our findings suggest\nthat these systems can be upgraded to close to 100% resilience.",
            "author": [
                "Bishal Shrestha",
                "Griwan Khakurel",
                "Kritika Simkhada",
                "Badri Adhikari"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12857v1",
                "http://arxiv.org/pdf/2311.12857v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18365v2",
            "title": "Using GPT-4 to Augment Unbalanced Data for Automatic Scoring",
            "updated": "2023-11-18T02:05:27Z",
            "published": "2023-10-25T01:07:50Z",
            "summary": "Machine learning-based automatic scoring can be challenging if students'\nresponses are unbalanced across scoring categories, as it introduces\nuncertainty in the machine training process. To meet this challenge, we\nintroduce a novel text data augmentation framework using GPT-4, a generative\nlarge language model, specifically tailored for unbalanced datasets in\nautomatic scoring. Our experimental dataset comprised student-written responses\nto two science items. We crafted prompts for GPT-4 to generate responses\nresembling student-written answers, particularly for the minority scoring\nclasses, to augment the data. We then finetuned DistillBERT for automatic\nscoring based on the augmented and original datasets. Model performance was\nassessed using accuracy, precision, recall, and F1 score. We incorporate varied\namounts of augmented data to examine scoring performance, and our findings\nrevealed remarkedly improved model performance. The average maximum increase\nobserved across two items is: 3.5% for accuracy, 30.6% for precision, 21.1% for\nrecall, and 24.2% for F1 score. Notably, using just 5% of the augmented data\nled to substantial improvements: 2.6%, 29.2%, 15.1%, and 19.6%. Interestingly,\nthe extent of improvement varied depending on specific datasets. Moreover, we\nfound that a varying amount of augmented data (5%-40%) was needed to obtain a\nstable improvement. We also compare models trained with GPT-4 augmented data\nand those trained with additional student-written responses. The findings\nindicate that former ones match or even exceed the performance of the latter.\nSpecifically, there is an average difference of 1.7%, 1.9%, 11.0%, and 7.8% for\nfour metrics separately. This research underscores the potential and\neffectiveness of data augmentation techniques utilizing GPT-4 in addressing\nunbalanced datasets within automated assessment.",
            "author": [
                "Luyang Fang",
                "Gyeong-Geon Lee",
                "Xiaoming Zhai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18365v2",
                "http://arxiv.org/pdf/2310.18365v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16273v1",
            "title": "Deep Learning for Plant Identification and Disease Classification from\n  Leaf Images: Multi-prediction Approaches",
            "updated": "2023-10-25T01:06:18Z",
            "published": "2023-10-25T01:06:18Z",
            "summary": "Deep learning plays an important role in modern agriculture, especially in\nplant pathology using leaf images where convolutional neural networks (CNN) are\nattracting a lot of attention. While numerous reviews have explored the\napplications of deep learning within this research domain, there remains a\nnotable absence of an empirical study to offer insightful comparisons due to\nthe employment of varied datasets in the evaluation. Furthermore, a majority of\nthese approaches tend to address the problem as a singular prediction task,\noverlooking the multifaceted nature of predicting various aspects of plant\nspecies and disease types. Lastly, there is an evident need for a more profound\nconsideration of the semantic relationships that underlie plant species and\ndisease types. In this paper, we start our study by surveying current deep\nlearning approaches for plant identification and disease classification. We\ncategorise the approaches into multi-model, multi-label, multi-output, and\nmulti-task, in which different backbone CNNs can be employed. Furthermore,\nbased on the survey of existing approaches in plant pathology and the study of\navailable approaches in machine learning, we propose a new model named\nGeneralised Stacking Multi-output CNN (GSMo-CNN). To investigate the\neffectiveness of different backbone CNNs and learning approaches, we conduct an\nintensive experiment on three benchmark datasets Plant Village, Plant Leaves,\nand PlantDoc. The experimental results demonstrate that InceptionV3 can be a\ngood choice for a backbone CNN as its performance is better than AlexNet,\nVGG16, ResNet101, EfficientNet, MobileNet, and a custom CNN developed by us.\nInterestingly, empirical results support the hypothesis that using a single\nmodel can be comparable or better than using two models. Finally, we show that\nthe proposed GSMo-CNN achieves state-of-the-art performance on three benchmark\ndatasets.",
            "author": [
                "Jianping Yao",
                "Son N. Tran",
                "Saurabh Garg",
                "Samantha Sawyer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16273v1",
                "http://arxiv.org/pdf/2310.16273v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16271v1",
            "title": "CycleAlign: Iterative Distillation from Black-box LLM to White-box\n  Models for Better Human Alignment",
            "updated": "2023-10-25T01:05:03Z",
            "published": "2023-10-25T01:05:03Z",
            "summary": "Language models trained on large-scale corpus often generate content that is\nharmful, toxic, or contrary to human preferences, making their alignment with\nhuman values a critical concern. Reinforcement learning from human feedback\n(RLHF) with algorithms like PPO is a prevalent approach for alignment but is\noften complex, unstable, and resource-intensive. Recently, ranking-based\nalignment methods have emerged, offering stability and effectiveness by\nreplacing the RL framework with supervised fine-tuning, but they are costly due\nto the need for annotated data. Considering that existing large language models\n(LLMs) like ChatGPT are already relatively well-aligned and cost-friendly,\nresearchers have begun to align the language model with human preference from\nAI feedback. The common practices, which unidirectionally distill the\ninstruction-following responses from LLMs, are constrained by their bottleneck.\nThus we introduce CycleAlign to distill alignment capabilities from\nparameter-invisible LLMs (black-box) to a parameter-visible model (white-box)\nin an iterative manner. With in-context learning (ICL) as the core of the\ncycle, the black-box models are able to rank the model-generated responses\nguided by human-craft instruction and demonstrations about their preferences.\nDuring iterative interaction, the white-box models also have a judgment about\nresponses generated by them. Consequently, the agreement ranking could be\nviewed as a pseudo label to dynamically update the in-context demonstrations\nand improve the preference ranking ability of black-box models. Through\nmultiple interactions, the CycleAlign framework could align the white-box model\nwith the black-box model effectively in a low-resource way. Empirical results\nillustrate that the model fine-tuned by CycleAlign remarkably exceeds existing\nmethods, and achieves the state-of-the-art performance in alignment with human\nvalue.",
            "author": [
                "Jixiang Hong",
                "Quan Tu",
                "Changyu Chen",
                "Xing Gao",
                "Ji Zhang",
                "Rui Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16271v1",
                "http://arxiv.org/pdf/2310.16271v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16270v1",
            "title": "Attention Lens: A Tool for Mechanistically Interpreting the Attention\n  Head Information Retrieval Mechanism",
            "updated": "2023-10-25T01:03:35Z",
            "published": "2023-10-25T01:03:35Z",
            "summary": "Transformer-based Large Language Models (LLMs) are the state-of-the-art for\nnatural language tasks. Recent work has attempted to decode, by reverse\nengineering the role of linear layers, the internal mechanisms by which LLMs\narrive at their final predictions for text completion tasks. Yet little is\nknown about the specific role of attention heads in producing the final token\nprediction. We propose Attention Lens, a tool that enables researchers to\ntranslate the outputs of attention heads into vocabulary tokens via learned\nattention-head-specific transformations called lenses. Preliminary findings\nfrom our trained lenses indicate that attention heads play highly specialized\nroles in language models. The code for Attention Lens is available at\ngithub.com/msakarvadia/AttentionLens.",
            "author": [
                "Mansi Sakarvadia",
                "Arham Khan",
                "Aswathy Ajith",
                "Daniel Grzenda",
                "Nathaniel Hudson",
                "Andr\u00e9 Bauer",
                "Kyle Chard",
                "Ian Foster"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16270v1",
                "http://arxiv.org/pdf/2310.16270v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16267v3",
            "title": "Student Classroom Behavior Detection based on Spatio-Temporal Network\n  and Multi-Model Fusion",
            "updated": "2023-12-04T15:21:32Z",
            "published": "2023-10-25T00:46:26Z",
            "summary": "Using deep learning methods to detect students' classroom behavior\nautomatically is a promising approach for analyzing their class performance and\nimproving teaching effectiveness. However, the lack of publicly available\nspatio-temporal datasets on student behavior, as well as the high cost of\nmanually labeling such datasets, pose significant challenges for researchers in\nthis field. To address this issue, we proposed a method for extending the\nspatio-temporal behavior dataset in Student Classroom Scenarios\n(SCB-ST-Dataset4) through image dataset. Our SCB-ST-Dataset4 comprises 757265\nimages with 25810 labels, focusing on 3 behaviors: hand-raising, reading,\nwriting. Our proposed method can rapidly generate spatio-temporal behavior\ndatasets without requiring extra manual labeling. Furthermore, we proposed a\nBehavior Similarity Index (BSI) to explore the similarity of behaviors. We\nevaluated the dataset using the YOLOv5, YOLOv7, YOLOv8, and SlowFast\nalgorithms, achieving a mean average precision (map) of up to 82.3%. Last, we\nfused multiple models to generate student behavior-related data from various\nperspectives. The experiment further demonstrates the effectiveness of our\nmethod. And SCB-ST-Dataset4 provides a robust foundation for future research in\nstudent behavior detection, potentially contributing to advancements in this\nfield. The SCB-ST-Dataset4 is available for download at:\nhttps://github.com/Whiffe/SCB-dataset.",
            "author": [
                "Fan Yang",
                "Xiaofei Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16267v3",
                "http://arxiv.org/pdf/2310.16267v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16256v1",
            "title": "A Causal Disentangled Multi-Granularity Graph Classification Method",
            "updated": "2023-10-25T00:20:50Z",
            "published": "2023-10-25T00:20:50Z",
            "summary": "Graph data widely exists in real life, with large amounts of data and complex\nstructures. It is necessary to map graph data to low-dimensional embedding.\nGraph classification, a critical graph task, mainly relies on identifying the\nimportant substructures within the graph. At present, some graph classification\nmethods do not combine the multi-granularity characteristics of graph data.\nThis lack of granularity distinction in modeling leads to a conflation of key\ninformation and false correlations within the model. So, achieving the desired\ngoal of a credible and interpretable model becomes challenging. This paper\nproposes a causal disentangled multi-granularity graph representation learning\nmethod (CDM-GNN) to solve this challenge. The CDM-GNN model disentangles the\nimportant substructures and bias parts within the graph from a\nmulti-granularity perspective. The disentanglement of the CDM-GNN model reveals\nimportant and bias parts, forming the foundation for its classification task,\nspecifically, model interpretations. The CDM-GNN model exhibits strong\nclassification performance and generates explanatory outcomes aligning with\nhuman cognitive patterns. In order to verify the effectiveness of the model,\nthis paper compares the three real-world datasets MUTAG, PTC, and IMDM-M. Six\nstate-of-the-art models, namely GCN, GAT, Top-k, ASAPool, SUGAR, and SAT are\nemployed for comparison purposes. Additionally, a qualitative analysis of the\ninterpretation results is conducted.",
            "author": [
                "Yuan Li",
                "Li Liu",
                "Penggang Chen",
                "Youmin Zhang",
                "Guoyin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16256v1",
                "http://arxiv.org/pdf/2310.16256v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16255v1",
            "title": "UAV-Sim: NeRF-based Synthetic Data Generation for UAV-based Perception",
            "updated": "2023-10-25T00:20:37Z",
            "published": "2023-10-25T00:20:37Z",
            "summary": "Tremendous variations coupled with large degrees of freedom in UAV-based\nimaging conditions lead to a significant lack of data in adequately learning\nUAV-based perception models. Using various synthetic renderers in conjunction\nwith perception models is prevalent to create synthetic data to augment the\nlearning in the ground-based imaging domain. However, severe challenges in the\naustere UAV-based domain require distinctive solutions to image synthesis for\ndata augmentation. In this work, we leverage recent advancements in neural\nrendering to improve static and dynamic novelview UAV-based image synthesis,\nespecially from high altitudes, capturing salient scene attributes. Finally, we\ndemonstrate a considerable performance boost is achieved when a state-ofthe-art\ndetection model is optimized primarily on hybrid sets of real and synthetic\ndata instead of the real or synthetic data separately.",
            "author": [
                "Christopher Maxey",
                "Jaehoon Choi",
                "Hyungtae Lee",
                "Dinesh Manocha",
                "Heesung Kwon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16255v1",
                "http://arxiv.org/pdf/2310.16255v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16856v1",
            "title": "GraFT: Gradual Fusion Transformer for Multimodal Re-Identification",
            "updated": "2023-10-25T00:15:40Z",
            "published": "2023-10-25T00:15:40Z",
            "summary": "Object Re-Identification (ReID) is pivotal in computer vision, witnessing an\nescalating demand for adept multimodal representation learning. Current models,\nalthough promising, reveal scalability limitations with increasing modalities\nas they rely heavily on late fusion, which postpones the integration of\nspecific modality insights. Addressing this, we introduce the \\textbf{Gradual\nFusion Transformer (GraFT)} for multimodal ReID. At its core, GraFT employs\nlearnable fusion tokens that guide self-attention across encoders, adeptly\ncapturing both modality-specific and object-specific features. Further\nbolstering its efficacy, we introduce a novel training paradigm combined with\nan augmented triplet loss, optimizing the ReID feature embedding space. We\ndemonstrate these enhancements through extensive ablation studies and show that\nGraFT consistently surpasses established multimodal ReID benchmarks.\nAdditionally, aiming for deployment versatility, we've integrated neural\nnetwork pruning into GraFT, offering a balance between model size and\nperformance.",
            "author": [
                "Haoli Yin",
                "Jiayao Li",
                "Eva Schiller",
                "Luke McDermott",
                "Daniel Cummings"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16856v1",
                "http://arxiv.org/pdf/2310.16856v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16252v2",
            "title": "Near-Optimal Pure Exploration in Matrix Games: A Generalization of\n  Stochastic Bandits & Dueling Bandits",
            "updated": "2023-11-27T21:33:05Z",
            "published": "2023-10-25T00:05:37Z",
            "summary": "We study the sample complexity of identifying the pure strategy Nash\nequilibrium (PSNE) in a two-player zero-sum matrix game with noise. Formally,\nwe are given a stochastic model where any learner can sample an entry $(i,j)$\nof the input matrix $A\\in[-1,1]^{n\\times m}$ and observe $A_{i,j}+\\eta$ where\n$\\eta$ is a zero-mean 1-sub-Gaussian noise. The aim of the learner is to\nidentify the PSNE of $A$, whenever it exists, with high probability while\ntaking as few samples as possible. Zhou et al. (2017) presents an\ninstance-dependent sample complexity lower bound that depends only on the\nentries in the row and column in which the PSNE lies. We design a near-optimal\nalgorithm whose sample complexity matches the lower bound, up to log factors.\nThe problem of identifying the PSNE also generalizes the problem of pure\nexploration in stochastic multi-armed bandits and dueling bandits, and our\nresult matches the optimal bounds, up to log factors, in both the settings.",
            "author": [
                "Arnab Maiti",
                "Ross Boczar",
                "Kevin Jamieson",
                "Lillian J. Ratliff"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16252v2",
                "http://arxiv.org/pdf/2310.16252v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16249v1",
            "title": "A clustering tool for interrogating finite element models based on\n  eigenvectors of graph adjacency",
            "updated": "2023-10-24T23:49:27Z",
            "published": "2023-10-24T23:49:27Z",
            "summary": "This note introduces an unsupervised learning algorithm to debug errors in\nfinite element (FE) simulation models and details how it was productionised.\nThe algorithm clusters degrees of freedom in the FE model using numerical\nproperties of the adjacency of its stiffness matrix. The algorithm has been\ndeployed as a tool called `Model Stability Analysis' tool within the commercial\nstructural FE suite Oasys GSA (www.oasys-software.com/gsa). It has been used\nsuccessfully by end-users for debugging real world FE models and we present\nexamples of the tool in action.",
            "author": [
                "Ramaseshan Kannan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16249v1",
                "http://arxiv.org/pdf/2310.16249v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE",
                "cs.AI",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16242v1",
            "title": "ZzzGPT: An Interactive GPT Approach to Enhance Sleep Quality",
            "updated": "2023-10-24T23:30:17Z",
            "published": "2023-10-24T23:30:17Z",
            "summary": "In today's world, sleep quality is pivotal for overall well-being. While\nwearable sensors offer real-time monitoring, they often lack actionable\ninsights, leading to user abandonment. This paper delves into the role of\ntechnology in understanding sleep patterns. We introduce a two-stage framework,\nutilizing Large Language Models (LLMs), aiming to provide accurate sleep\npredictions with actionable feedback. Leveraging the GLOBEM dataset and\nsynthetic data from LLMs, we highlight enhanced results with models like\nXGBoost. Our approach merges advanced machine learning with user-centric\ndesign, blending scientific accuracy with practicality.",
            "author": [
                "Yonchanok Khaokaew",
                "Thuc Hanh Nguyen",
                "Kaixin Ji",
                "Hiruni Kegalle",
                "Marwah Alaofi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16242v1",
                "http://arxiv.org/pdf/2310.16242v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16241v1",
            "title": "Task Grouping for Automated Multi-Task Machine Learning via Task\n  Affinity Prediction",
            "updated": "2023-10-24T23:29:46Z",
            "published": "2023-10-24T23:29:46Z",
            "summary": "When a number of similar tasks have to be learned simultaneously, multi-task\nlearning (MTL) models can attain significantly higher accuracy than single-task\nlearning (STL) models. However, the advantage of MTL depends on various\nfactors, such as the similarity of the tasks, the sizes of the datasets, and so\non; in fact, some tasks might not benefit from MTL and may even incur a loss of\naccuracy compared to STL. Hence, the question arises: which tasks should be\nlearned together? Domain experts can attempt to group tasks together following\nintuition, experience, and best practices, but manual grouping can be\nlabor-intensive and far from optimal. In this paper, we propose a novel\nautomated approach for task grouping. First, we study the affinity of tasks for\nMTL using four benchmark datasets that have been used extensively in the MTL\nliterature, focusing on neural network-based MTL models. We identify inherent\ntask features and STL characteristics that can help us to predict whether a\ngroup of tasks should be learned together using MTL or if they should be\nlearned independently using STL. Building on this predictor, we introduce a\nrandomized search algorithm, which employs the predictor to minimize the number\nof MTL trainings performed during the search for task groups. We demonstrate on\nthe four benchmark datasets that our predictor-driven search approach can find\nbetter task groupings than existing baseline approaches.",
            "author": [
                "Afiya Ayman",
                "Ayan Mukhopadhyay",
                "Aron Laszka"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16241v1",
                "http://arxiv.org/pdf/2310.16241v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16231v1",
            "title": "Attention-Based Ensemble Pooling for Time Series Forecasting",
            "updated": "2023-10-24T22:59:56Z",
            "published": "2023-10-24T22:59:56Z",
            "summary": "A common technique to reduce model bias in time-series forecasting is to use\nan ensemble of predictive models and pool their output into an ensemble\nforecast. In cases where each predictive model has different biases, however,\nit is not always clear exactly how each model forecast should be weighed during\nthis pooling. We propose a method for pooling that performs a weighted average\nover candidate model forecasts, where the weights are learned by an\nattention-based ensemble pooling model. We test this method on two time-series\nforecasting problems: multi-step forecasting of the dynamics of the\nnon-stationary Lorenz `63 equation, and one-step forecasting of the weekly\nincident deaths due to COVID-19. We find that while our model achieves\nexcellent valid times when forecasting the non-stationary Lorenz `63 equation,\nit does not consistently perform better than the existing ensemble pooling when\nforecasting COVID-19 weekly incident deaths.",
            "author": [
                "Dhruvit Patel",
                "Alexander Wikner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16231v1",
                "http://arxiv.org/pdf/2310.16231v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "nlin.CD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16228v1",
            "title": "On the Foundations of Shortcut Learning",
            "updated": "2023-10-24T22:54:05Z",
            "published": "2023-10-24T22:54:05Z",
            "summary": "Deep-learning models can extract a rich assortment of features from data.\nWhich features a model uses depends not only on predictivity-how reliably a\nfeature indicates train-set labels-but also on availability-how easily the\nfeature can be extracted, or leveraged, from inputs. The literature on shortcut\nlearning has noted examples in which models privilege one feature over another,\nfor example texture over shape and image backgrounds over foreground objects.\nHere, we test hypotheses about which input properties are more available to a\nmodel, and systematically study how predictivity and availability interact to\nshape models' feature use. We construct a minimal, explicit generative\nframework for synthesizing classification datasets with two latent features\nthat vary in predictivity and in factors we hypothesize to relate to\navailability, and quantify a model's shortcut bias-its over-reliance on the\nshortcut (more available, less predictive) feature at the expense of the core\n(less available, more predictive) feature. We find that linear models are\nrelatively unbiased, but introducing a single hidden layer with ReLU or Tanh\nunits yields a bias. Our empirical findings are consistent with a theoretical\naccount based on Neural Tangent Kernels. Finally, we study how models used in\npractice trade off predictivity and availability in naturalistic datasets,\ndiscovering availability manipulations which increase models' degree of\nshortcut bias. Taken together, these findings suggest that the propensity to\nlearn shortcut features is a fundamental characteristic of deep nonlinear\narchitectures warranting systematic study given its role in shaping how models\nsolve tasks.",
            "author": [
                "Katherine L. Hermann",
                "Hossein Mobahi",
                "Thomas Fel",
                "Michael C. Mozer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16228v1",
                "http://arxiv.org/pdf/2310.16228v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16226v1",
            "title": "TiC-CLIP: Continual Training of CLIP Models",
            "updated": "2023-10-24T22:41:14Z",
            "published": "2023-10-24T22:41:14Z",
            "summary": "Keeping large foundation models up to date on latest data is inherently\nexpensive. To avoid the prohibitive costs of constantly retraining, it is\nimperative to continually train these models. This problem is exacerbated by\nthe lack of any large scale continual learning benchmarks or baselines. We\nintroduce the first set of web-scale Time-Continual (TiC) benchmarks for\ntraining vision-language models: TiC-DataCompt, TiC-YFCC, and TiC-RedCaps with\nover 12.7B timestamped image-text pairs spanning 9 years (2014--2022). We first\nuse our benchmarks to curate various dynamic evaluations to measure temporal\nrobustness of existing models. We show OpenAI's CLIP (trained on data up to\n2020) loses $\\approx 8\\%$ zero-shot accuracy on our curated retrieval task from\n2021--2022 compared with more recently trained models in OpenCLIP repository.\nWe then study how to efficiently train models on time-continuous data. We\ndemonstrate that a simple rehearsal-based approach that continues training from\nthe last checkpoint and replays old data reduces compute by $2.5\\times$ when\ncompared to the standard practice of retraining from scratch.",
            "author": [
                "Saurabh Garg",
                "Mehrdad Farajtabar",
                "Hadi Pouransari",
                "Raviteja Vemulapalli",
                "Sachin Mehta",
                "Oncel Tuzel",
                "Vaishaal Shankar",
                "Fartash Faghri"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16226v1",
                "http://arxiv.org/pdf/2310.16226v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16225v1",
            "title": "CleanCoNLL: A Nearly Noise-Free Named Entity Recognition Dataset",
            "updated": "2023-10-24T22:34:43Z",
            "published": "2023-10-24T22:34:43Z",
            "summary": "The CoNLL-03 corpus is arguably the most well-known and utilized benchmark\ndataset for named entity recognition (NER). However, prior works found\nsignificant numbers of annotation errors, incompleteness, and inconsistencies\nin the data. This poses challenges to objectively comparing NER approaches and\nanalyzing their errors, as current state-of-the-art models achieve F1-scores\nthat are comparable to or even exceed the estimated noise level in CoNLL-03. To\naddress this issue, we present a comprehensive relabeling effort assisted by\nautomatic consistency checking that corrects 7.0% of all labels in the English\nCoNLL-03. Our effort adds a layer of entity linking annotation both for better\nexplainability of NER labels and as additional safeguard of annotation quality.\nOur experimental evaluation finds not only that state-of-the-art approaches\nreach significantly higher F1-scores (97.1%) on our data, but crucially that\nthe share of correct predictions falsely counted as errors due to annotation\nnoise drops from 47% to 6%. This indicates that our resource is well suited to\nanalyze the remaining errors made by state-of-the-art models, and that the\ntheoretical upper bound even on high resource, coarse-grained NER is not yet\nreached. To facilitate such analysis, we make CleanCoNLL publicly available to\nthe research community.",
            "author": [
                "Susanna R\u00fccker",
                "Alan Akbik"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16225v1",
                "http://arxiv.org/pdf/2310.16225v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16224v1",
            "title": "Poison is Not Traceless: Fully-Agnostic Detection of Poisoning Attacks",
            "updated": "2023-10-24T22:27:44Z",
            "published": "2023-10-24T22:27:44Z",
            "summary": "The performance of machine learning models depends on the quality of the\nunderlying data. Malicious actors can attack the model by poisoning the\ntraining data. Current detectors are tied to either specific data types,\nmodels, or attacks, and therefore have limited applicability in real-world\nscenarios. This paper presents a novel fully-agnostic framework, DIVA\n(Detecting InVisible Attacks), that detects attacks solely relying on analyzing\nthe potentially poisoned data set. DIVA is based on the idea that poisoning\nattacks can be detected by comparing the classifier's accuracy on poisoned and\nclean data and pre-trains a meta-learner using Complexity Measures to estimate\nthe otherwise unknown accuracy on a hypothetical clean dataset. The framework\napplies to generic poisoning attacks. For evaluation purposes, in this paper,\nwe test DIVA on label-flipping attacks.",
            "author": [
                "Xinglong Chang",
                "Katharina Dost",
                "Gillian Dobbie",
                "J\u00f6rg Wicker"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16224v1",
                "http://arxiv.org/pdf/2310.16224v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG",
                "53-06"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16221v1",
            "title": "Hierarchical Randomized Smoothing",
            "updated": "2023-10-24T22:24:44Z",
            "published": "2023-10-24T22:24:44Z",
            "summary": "Real-world data is complex and often consists of objects that can be\ndecomposed into multiple entities (e.g. images into pixels, graphs into\ninterconnected nodes). Randomized smoothing is a powerful framework for making\nmodels provably robust against small changes to their inputs - by guaranteeing\nrobustness of the majority vote when randomly adding noise before\nclassification. Yet, certifying robustness on such complex data via randomized\nsmoothing is challenging when adversaries do not arbitrarily perturb entire\nobjects (e.g. images) but only a subset of their entities (e.g. pixels). As a\nsolution, we introduce hierarchical randomized smoothing: We partially smooth\nobjects by adding random noise only on a randomly selected subset of their\nentities. By adding noise in a more targeted manner than existing methods we\nobtain stronger robustness guarantees while maintaining high accuracy. We\ninitialize hierarchical smoothing using different noising distributions,\nyielding novel robustness certificates for discrete and continuous domains. We\nexperimentally demonstrate the importance of hierarchical smoothing in image\nand node classification, where it yields superior robustness-accuracy\ntrade-offs. Overall, hierarchical smoothing is an important contribution\ntowards models that are both - certifiably robust to perturbations and\naccurate.",
            "author": [
                "Yan Scholten",
                "Jan Schuchardt",
                "Aleksandar Bojchevski",
                "Stephan G\u00fcnnemann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16221v1",
                "http://arxiv.org/pdf/2310.16221v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16214v1",
            "title": "Performance Tuning for GPU-Embedded Systems: Machine-Learning-based and\n  Analytical Model-driven Tuning Methodologies",
            "updated": "2023-10-24T22:09:03Z",
            "published": "2023-10-24T22:09:03Z",
            "summary": "GPU-embedded systems have gained popularity across various domains due to\ntheir efficient power consumption. However, in order to meet the demands of\nreal-time or time-consuming applications running on these systems, it is\ncrucial for them to be tuned to exhibit high performance. This paper addresses\nthe issue by developing and comparing two tuning methodologies on GPU-embedded\nsystems, and also provides performance insights for developers and researchers\nseeking to optimize applications running on these architectures. We focus on\nparallel prefix operations, such as FFT, scan primitives, and tridiagonal\nsystem solvers, which are performance-critical components in many applications.\nThe study introduces an analytical model-driven tuning methodology and a\nMachine Learning (ML)-based tuning methodology. We evaluate the performance of\nthe two tuning methodologies for different parallel prefix implementations of\nthe BPLG library in an NVIDIA Jetson system, and compare their performance to\nthe ones achieved through an exhaustive search. The findings shed light on the\nbest strategies for handling the open challenge of performance portability for\nmajor computational patterns among server and embedded devices, providing\npractical guidance for offline and online tuning. We also address the existing\ngap in performance studies for parallel computational patterns in GPU-embedded\nsystems by comparing the BPLG performance against other state-of-the-art\nlibraries, including CUSPARSE, CUB, and CUFFT.",
            "author": [
                "Adrian Perez Dieguez",
                "Margarita Amor Lopez"
            ],
            "link": [
                "http://dx.doi.org/10.1109/SBAC-PAD59825.2023.00022.",
                "http://arxiv.org/abs/2310.16214v1",
                "http://arxiv.org/pdf/2310.16214v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.LG",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16210v1",
            "title": "Sea-Land-Cloud Segmentation in Satellite Hyperspectral Imagery by Deep\n  Learning",
            "updated": "2023-10-24T21:57:59Z",
            "published": "2023-10-24T21:57:59Z",
            "summary": "Satellites are increasingly adopting on-board Artificial Intelligence (AI)\ntechniques to enhance platforms' autonomy through edge inference. In this\ncontext, the utilization of deep learning (DL) techniques for segmentation in\nHS satellite imagery offers advantages for remote sensing applications, and\ntherefore, we train 16 different models, whose codes are made available through\nour study, which we consider to be relevant for on-board multi-class\nsegmentation of HS imagery, focusing on classifying oceanic (sea), terrestrial\n(land), and cloud formations. We employ the HYPSO-1 mission as an illustrative\ncase for sea-land-cloud segmentation, and to demonstrate the utility of the\nsegments, we introduce a novel sea-land-cloud ranking application scenario. Our\nsystem prioritizes HS image downlink based on sea, land, and cloud coverage\nlevels from the segmented images. We comparatively evaluate the models for\nin-orbit deployment, considering performance, parameter count, and inference\ntime. The models include both shallow and deep models, and after we propose\nfour new DL models, we demonstrate that segmenting single spectral signatures\n(1D) outperforms 3D data processing comprising both spectral (1D) and spatial\n(2D) contexts. We conclude that our lightweight DL model, called\n1D-Justo-LiuNet, consistently surpasses state-of-the-art models for\nsea-land-cloud segmentation, such as U-Net and its variations, in terms of\nperformance (0.93 accuracy) and parameter count (4,563). However, the 1D models\npresent longer inference time (15s) in the tested processing architecture,\nwhich is clearly suboptimal. Finally, after demonstrating that in-orbit image\nsegmentation should occur post L1b radiance calibration rather than on raw\ndata, we additionally show that reducing spectral channels down to 3 lowers\nmodels' parameters and inference time, at the cost of weaker segmentation\nperformance.",
            "author": [
                "Jon Alvarez Justo",
                "Joseph Landon Garrett",
                "Mariana-Iuliana Georgescu",
                "Jesus Gonzalez-Llorente",
                "Radu Tudor Ionescu",
                "Tor Arne Johansen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16210v1",
                "http://arxiv.org/pdf/2310.16210v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16209v1",
            "title": "ELM Ridge Regression Boosting",
            "updated": "2023-10-24T21:53:50Z",
            "published": "2023-10-24T21:53:50Z",
            "summary": "We discuss a boosting approach for the Ridge Regression (RR) method, with\napplications to the Extreme Learning Machine (ELM), and we show that the\nproposed method significantly improves the classification performance and\nrobustness of ELMs.",
            "author": [
                "M. Andrecut"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16209v1",
                "http://arxiv.org/pdf/2310.16209v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16203v1",
            "title": "Multivariate Dynamic Mediation Analysis under a Reinforcement Learning\n  Framework",
            "updated": "2023-10-24T21:43:31Z",
            "published": "2023-10-24T21:43:31Z",
            "summary": "Mediation analysis is an important analytic tool commonly used in a broad\nrange of scientific applications. In this article, we study the problem of\nmediation analysis when there are multivariate and conditionally dependent\nmediators, and when the variables are observed over multiple time points. The\nproblem is challenging, because the effect of a mediator involves not only the\npath from the treatment to this mediator itself at the current time point, but\nalso all possible paths pointed to this mediator from its upstream mediators,\nas well as the carryover effects from all previous time points. We propose a\nnovel multivariate dynamic mediation analysis approach. Drawing inspiration\nfrom the Markov decision process model that is frequently employed in\nreinforcement learning, we introduce a Markov mediation process paired with a\nsystem of time-varying linear structural equation models to formulate the\nproblem. We then formally define the individual mediation effect, built upon\nthe idea of simultaneous interventions and intervention calculus. We next\nderive the closed-form expression and propose an iterative estimation procedure\nunder the Markov mediation process model. We study both the asymptotic property\nand the empirical performance of the proposed estimator, and further illustrate\nour method with a mobile health application.",
            "author": [
                "Lan Luo",
                "Chengchun Shi",
                "Jitao Wang",
                "Zhenke Wu",
                "Lexin Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16203v1",
                "http://arxiv.org/pdf/2310.16203v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16194v1",
            "title": "Learning Low-Rank Latent Spaces with Simple Deterministic Autoencoder:\n  Theoretical and Empirical Insights",
            "updated": "2023-10-24T21:24:27Z",
            "published": "2023-10-24T21:24:27Z",
            "summary": "The autoencoder is an unsupervised learning paradigm that aims to create a\ncompact latent representation of data by minimizing the reconstruction loss.\nHowever, it tends to overlook the fact that most data (images) are embedded in\na lower-dimensional space, which is crucial for effective data representation.\nTo address this limitation, we propose a novel approach called Low-Rank\nAutoencoder (LoRAE). In LoRAE, we incorporated a low-rank regularizer to\nadaptively reconstruct a low-dimensional latent space while preserving the\nbasic objective of an autoencoder. This helps embed the data in a\nlower-dimensional space while preserving important information. It is a simple\nautoencoder extension that learns low-rank latent space. Theoretically, we\nestablish a tighter error bound for our model. Empirically, our model's\nsuperiority shines through various tasks such as image generation and\ndownstream classification. Both theoretical and practical outcomes highlight\nthe importance of acquiring low-dimensional embeddings.",
            "author": [
                "Alokendu Mazumder",
                "Tirthajit Baruah",
                "Bhartendu Kumar",
                "Rishab Sharma",
                "Vishwajeet Pattanaik",
                "Punit Rathore"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16194v1",
                "http://arxiv.org/pdf/2310.16194v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16193v1",
            "title": "Length is a Curse and a Blessing for Document-level Semantics",
            "updated": "2023-10-24T21:23:53Z",
            "published": "2023-10-24T21:23:53Z",
            "summary": "In recent years, contrastive learning (CL) has been extensively utilized to\nrecover sentence and document-level encoding capability from pre-trained\nlanguage models. In this work, we question the length generalizability of\nCL-based models, i.e., their vulnerability towards length-induced semantic\nshift. We verify not only that length vulnerability is a significant yet\noverlooked research gap, but we can devise unsupervised CL methods solely\ndepending on the semantic signal provided by document length. We first derive\nthe theoretical foundations underlying length attacks, showing that elongating\na document would intensify the high intra-document similarity that is already\nbrought by CL. Moreover, we found that isotropy promised by CL is highly\ndependent on the length range of text exposed in training. Inspired by these\nfindings, we introduce a simple yet universal document representation learning\nframework, LA(SER)$^{3}$: length-agnostic self-reference for semantically\nrobust sentence representation learning, achieving state-of-the-art\nunsupervised performance on the standard information retrieval benchmark.",
            "author": [
                "Chenghao Xiao",
                "Yizhi Li",
                "G Thomas Hudson",
                "Chenghua Lin",
                "Noura Al Moubayed"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16193v1",
                "http://arxiv.org/pdf/2310.16193v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16187v1",
            "title": "Efficient deep data assimilation with sparse observations and\n  time-varying sensors",
            "updated": "2023-10-24T21:13:59Z",
            "published": "2023-10-24T21:13:59Z",
            "summary": "Variational Data Assimilation (DA) has been broadly used in engineering\nproblems for field reconstruction and prediction by performing a weighted\ncombination of multiple sources of noisy data. In recent years, the integration\nof deep learning (DL) techniques in DA has shown promise in improving the\nefficiency and accuracy in high-dimensional dynamical systems. Nevertheless,\nexisting deep DA approaches face difficulties in dealing with unstructured\nobservation data, especially when the placement and number of sensors are\ndynamic over time. We introduce a novel variational DA scheme, named\nVoronoi-tessellation Inverse operator for VariatIonal Data assimilation\n(VIVID), that incorporates a DL inverse operator into the assimilation\nobjective function. By leveraging the capabilities of the Voronoi-tessellation\nand convolutional neural networks, VIVID is adept at handling sparse,\nunstructured, and time-varying sensor data. Furthermore, the incorporation of\nthe DL inverse operator establishes a direct link between observation and state\nspace, leading to a reduction in the number of minimization steps required for\nDA. Additionally, VIVID can be seamlessly integrated with Proper Orthogonal\nDecomposition (POD) to develop an end-to-end reduced-order DA scheme, which can\nfurther expedite field reconstruction. Numerical experiments in a fluid\ndynamics system demonstrate that VIVID can significantly outperform existing DA\nand DL algorithms. The robustness of VIVID is also accessed through the\napplication of various levels of prior error, the utilization of varying\nnumbers of sensors, and the misspecification of error covariance in DA.",
            "author": [
                "Sibo Cheng",
                "Che Liu",
                "Yike Guo",
                "Rossella Arcucci"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16187v1",
                "http://arxiv.org/pdf/2310.16187v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16186v1",
            "title": "Image Segmentation using U-Net Architecture for Powder X-ray Diffraction\n  Images",
            "updated": "2023-10-24T21:11:09Z",
            "published": "2023-10-24T21:11:09Z",
            "summary": "Scientific researchers frequently use the in situ synchrotron high-energy\npowder X-ray diffraction (XRD) technique to examine the crystallographic\nstructures of materials in functional devices such as rechargeable battery\nmaterials. We propose a method for identifying artifacts in experimental XRD\nimages. The proposed method uses deep learning convolutional neural network\narchitectures, such as tunable U-Nets to identify the artifacts. In particular,\nthe predicted artifacts are evaluated against the corresponding ground truth\n(manually implemented) using the overall true positive rate or recall. The\nresult demonstrates that the U-Nets can consistently produce great recall\nperformance at 92.4% on the test dataset, which is not included in the\ntraining, with a 34% reduction in average false positives in comparison to the\nconventional method. The U-Nets also reduce the time required to identify and\nseparate artifacts by more than 50%. Furthermore, the exclusion of the\nartifacts shows major changes in the integrated 1D XRD pattern, enhancing\nfurther analysis of the post-processing XRD data.",
            "author": [
                "Howard Yanxon",
                "Eric Roberts",
                "Hannah Parraga",
                "James Weng",
                "Wenqian Xu",
                "Uta Ruett",
                "Alexander Hexemer",
                "Petrus Zwart",
                "Nickolas Schwarz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16186v1",
                "http://arxiv.org/pdf/2310.16186v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16183v1",
            "title": "BLP 2023 Task 2: Sentiment Analysis",
            "updated": "2023-10-24T21:00:41Z",
            "published": "2023-10-24T21:00:41Z",
            "summary": "We present an overview of the BLP Sentiment Shared Task, organized as part of\nthe inaugural BLP 2023 workshop, co-located with EMNLP 2023. The task is\ndefined as the detection of sentiment in a given piece of social media text.\nThis task attracted interest from 71 participants, among whom 29 and 30 teams\nsubmitted systems during the development and evaluation phases, respectively.\nIn total, participants submitted 597 runs. However, a total of 15 teams\nsubmitted system description papers. The range of approaches in the submitted\nsystems spans from classical machine learning models, fine-tuning pre-trained\nmodels, to leveraging Large Language Model (LLMs) in zero- and few-shot\nsettings. In this paper, we provide a detailed account of the task setup,\nincluding dataset development and evaluation setup. Additionally, we provide a\nbrief overview of the systems submitted by the participants. All datasets and\nevaluation scripts from the shared task have been made publicly available for\nthe research community, to foster further research in this domain",
            "author": [
                "Md. Arid Hasan",
                "Firoj Alam",
                "Anika Anjum",
                "Shudipta Das",
                "Afiyat Anjum"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16183v1",
                "http://arxiv.org/pdf/2310.16183v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16181v1",
            "title": "Hidden Citations Obscure True Impact in Science",
            "updated": "2023-10-24T20:58:07Z",
            "published": "2023-10-24T20:58:07Z",
            "summary": "References, the mechanism scientists rely on to signal previous knowledge,\nlately have turned into widely used and misused measures of scientific impact.\nYet, when a discovery becomes common knowledge, citations suffer from\nobliteration by incorporation. This leads to the concept of hidden citation,\nrepresenting a clear textual credit to a discovery without a reference to the\npublication embodying it. Here, we rely on unsupervised interpretable machine\nlearning applied to the full text of each paper to systematically identify\nhidden citations. We find that for influential discoveries hidden citations\noutnumber citation counts, emerging regardless of publishing venue and\ndiscipline. We show that the prevalence of hidden citations is not driven by\ncitation counts, but rather by the degree of the discourse on the topic within\nthe text of the manuscripts, indicating that the more discussed is a discovery,\nthe less visible it is to standard bibliometric analysis. Hidden citations\nindicate that bibliometric measures offer a limited perspective on quantifying\nthe true impact of a discovery, raising the need to extract knowledge from the\nfull text of the scientific corpus.",
            "author": [
                "Xiangyi Meng",
                "Onur Varol",
                "Albert-L\u00e1szl\u00f3 Barab\u00e1si"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16181v1",
                "http://arxiv.org/pdf/2310.16181v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.DL",
                "cs.SI",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16175v1",
            "title": "G-CASCADE: Efficient Cascaded Graph Convolutional Decoding for 2D\n  Medical Image Segmentation",
            "updated": "2023-10-24T20:41:04Z",
            "published": "2023-10-24T20:41:04Z",
            "summary": "In recent years, medical image segmentation has become an important\napplication in the field of computer-aided diagnosis. In this paper, we are the\nfirst to propose a new graph convolution-based decoder namely, Cascaded Graph\nConvolutional Attention Decoder (G-CASCADE), for 2D medical image segmentation.\nG-CASCADE progressively refines multi-stage feature maps generated by\nhierarchical transformer encoders with an efficient graph convolution block.\nThe encoder utilizes the self-attention mechanism to capture long-range\ndependencies, while the decoder refines the feature maps preserving long-range\ninformation due to the global receptive fields of the graph convolution block.\nRigorous evaluations of our decoder with multiple transformer encoders on five\nmedical image segmentation tasks (i.e., Abdomen organs, Cardiac organs, Polyp\nlesions, Skin lesions, and Retinal vessels) show that our model outperforms\nother state-of-the-art (SOTA) methods. We also demonstrate that our decoder\nachieves better DICE scores than the SOTA CASCADE decoder with 80.8% fewer\nparameters and 82.3% fewer FLOPs. Our decoder can easily be used with other\nhierarchical encoders for general-purpose semantic and medical image\nsegmentation tasks.",
            "author": [
                "Md Mostafijur Rahman",
                "Radu Marculescu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16175v1",
                "http://arxiv.org/pdf/2310.16175v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "I.4; J.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16173v1",
            "title": "On the Convergence and Sample Complexity Analysis of Deep Q-Networks\n  with $\u03b5$-Greedy Exploration",
            "updated": "2023-10-24T20:37:02Z",
            "published": "2023-10-24T20:37:02Z",
            "summary": "This paper provides a theoretical understanding of Deep Q-Network (DQN) with\nthe $\\varepsilon$-greedy exploration in deep reinforcement learning. Despite\nthe tremendous empirical achievement of the DQN, its theoretical\ncharacterization remains underexplored. First, the exploration strategy is\neither impractical or ignored in the existing analysis. Second, in contrast to\nconventional Q-learning algorithms, the DQN employs the target network and\nexperience replay to acquire an unbiased estimation of the mean-square Bellman\nerror (MSBE) utilized in training the Q-network. However, the existing\ntheoretical analysis of DQNs lacks convergence analysis or bypasses the\ntechnical challenges by deploying a significantly overparameterized neural\nnetwork, which is not computationally efficient. This paper provides the first\ntheoretical convergence and sample complexity analysis of the practical setting\nof DQNs with $\\epsilon$-greedy policy. We prove an iterative procedure with\ndecaying $\\epsilon$ converges to the optimal Q-value function geometrically.\nMoreover, a higher level of $\\epsilon$ values enlarges the region of\nconvergence but slows down the convergence, while the opposite holds for a\nlower level of $\\epsilon$ values. Experiments justify our established\ntheoretical insights on DQNs.",
            "author": [
                "Shuai Zhang",
                "Hongkang Li",
                "Meng Wang",
                "Miao Liu",
                "Pin-Yu Chen",
                "Songtao Lu",
                "Sijia Liu",
                "Keerthiram Murugesan",
                "Subhajit Chaudhury"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16173v1",
                "http://arxiv.org/pdf/2310.16173v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16168v1",
            "title": "Role of Multifidelity Data in Sequential Active Learning Materials\n  Discovery Campaigns: Case Study of Electronic Bandgap",
            "updated": "2023-10-24T20:33:44Z",
            "published": "2023-10-24T20:33:44Z",
            "summary": "Materials discovery and design typically proceeds through iterative\nevaluation (both experimental and computational) to obtain data, generally\ntargeting improvement of one or more properties under one or more constraints\n(e.g., time or budget). However, there can be great variation in the quality\nand cost of different data, and when they are mixed together in what we here\ncall multifidelity data the optimal approaches to their utilization are not\nestablished. It is therefore important to develop strategies to acquire and use\nmultifidelity data to realize the most efficient iterative materials\nexploration. In this work, we assess the impact of using multifidelity data\nthrough mock demonstration of designing solar cell materials, using the\nelectronic bandgap as the target property. We propose a new approach of using\nmultifidelity data through leveraging machine learning models of both low- and\nhigh-fidelity data, where using predicted low-fidelity data as an input feature\nin the high-fidelity model can improve the impact of a multifidelity data\napproach. We show how tradeoffs of low- versus high-fidelity measurement cost\nand acquisition can impact the materials discovery process, and find that the\nuse of multifidelity data has maximal impact on the materials discovery\ncampaign when approximately five low-fidelity measurements per high-fidelity\nmeasurement are performed, and when the cost of low-fidelity measurements is\napproximately 5% or less than that of high-fidelity measurements. This work\nprovides practical guidance and useful qualitative measures for improving\nmaterials discovery campaigns that involve multifidelity data.",
            "author": [
                "Ryan Jacobs",
                "Philip E. Goins",
                "Dane Morgan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16168v1",
                "http://arxiv.org/pdf/2310.16168v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16167v1",
            "title": "iNVS: Repurposing Diffusion Inpainters for Novel View Synthesis",
            "updated": "2023-10-24T20:33:19Z",
            "published": "2023-10-24T20:33:19Z",
            "summary": "We present a method for generating consistent novel views from a single\nsource image. Our approach focuses on maximizing the reuse of visible pixels\nfrom the source image. To achieve this, we use a monocular depth estimator that\ntransfers visible pixels from the source view to the target view. Starting from\na pre-trained 2D inpainting diffusion model, we train our method on the\nlarge-scale Objaverse dataset to learn 3D object priors. While training we use\na novel masking mechanism based on epipolar lines to further improve the\nquality of our approach. This allows our framework to perform zero-shot novel\nview synthesis on a variety of objects. We evaluate the zero-shot abilities of\nour framework on three challenging datasets: Google Scanned Objects, Ray Traced\nMultiview, and Common Objects in 3D. See our webpage for more details:\nhttps://yashkant.github.io/invs/",
            "author": [
                "Yash Kant",
                "Aliaksandr Siarohin",
                "Michael Vasilkovsky",
                "Riza Alp Guler",
                "Jian Ren",
                "Sergey Tulyakov",
                "Igor Gilitschenski"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16167v1",
                "http://arxiv.org/pdf/2310.16167v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17668v1",
            "title": "Fine tuning Pre trained Models for Robustness Under Noisy Labels",
            "updated": "2023-10-24T20:28:59Z",
            "published": "2023-10-24T20:28:59Z",
            "summary": "The presence of noisy labels in a training dataset can significantly impact\nthe performance of machine learning models. To tackle this issue, researchers\nhave explored methods for Learning with Noisy Labels to identify clean samples\nand reduce the influence of noisy labels. However, constraining the influence\nof a certain portion of the training dataset can result in a reduction in\noverall generalization performance. To alleviate this, recent studies have\nconsidered the careful utilization of noisy labels by leveraging huge\ncomputational resources. Therefore, the increasing training cost necessitates a\nreevaluation of efficiency. In other areas of research, there has been a focus\non developing fine-tuning techniques for large pre-trained models that aim to\nachieve both high generalization performance and efficiency. However, these\nmethods have mainly concentrated on clean datasets, and there has been limited\nexploration of the noisy label scenario. In this research, our aim is to find\nan appropriate way to fine-tune pre-trained models for noisy labeled datasets.\nTo achieve this goal, we investigate the characteristics of pre-trained models\nwhen they encounter noisy datasets. Through empirical analysis, we introduce a\nnovel algorithm called TURN, which robustly and efficiently transfers the prior\nknowledge of pre-trained models. The algorithm consists of two main steps: (1)\nindependently tuning the linear classifier to protect the feature extractor\nfrom being distorted by noisy labels, and (2) reducing the noisy label ratio\nand fine-tuning the entire model based on the noise-reduced dataset to adapt it\nto the target dataset. The proposed algorithm has been extensively tested and\ndemonstrates efficient yet improved denoising performance on various benchmarks\ncompared to previous methods.",
            "author": [
                "Sumyeong Ahn",
                "Sihyeon Kim",
                "Jongwoo Ko",
                "Se-Young Yun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17668v1",
                "http://arxiv.org/pdf/2310.17668v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "Computer Science, Artificial Intelligence"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16162v1",
            "title": "Brainchop: Next Generation Web-Based Neuroimaging Application",
            "updated": "2023-10-24T20:17:06Z",
            "published": "2023-10-24T20:17:06Z",
            "summary": "Performing volumetric image processing directly within the browser,\nparticularly with medical data, presents unprecedented challenges compared to\nconventional backend tools. These challenges arise from limitations inherent in\nbrowser environments, such as constrained computational resources and the\navailability of frontend machine learning libraries. Consequently, there is a\nshortage of neuroimaging frontend tools capable of providing comprehensive\nend-to-end solutions for whole brain preprocessing and segmentation while\npreserving end-user data privacy and residency. In light of this context, we\nintroduce Brainchop (http://www.brainchop.org) as a groundbreaking in-browser\nneuroimaging tool that enables volumetric analysis of structural MRI using\npre-trained full-brain deep learning models, all without requiring technical\nexpertise or intricate setup procedures. Beyond its commitment to data privacy,\nthis frontend tool offers multiple features, including scalability, low\nlatency, user-friendly operation, cross-platform compatibility, and enhanced\naccessibility. This paper outlines the processing pipeline of Brainchop and\nevaluates the performance of models across various software and hardware\nconfigurations. The results demonstrate the practicality of client-side\nprocessing for volumetric data, owing to the robust MeshNet architecture, even\nwithin the resource-constrained environment of web browsers.",
            "author": [
                "Mohamed Masoud",
                "Pratyush Reddy",
                "Farfalla Hu",
                "Sergey Plis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16162v1",
                "http://arxiv.org/pdf/2310.16162v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16161v1",
            "title": "MyriadAL: Active Few Shot Learning for Histopathology",
            "updated": "2023-10-24T20:08:15Z",
            "published": "2023-10-24T20:08:15Z",
            "summary": "Active Learning (AL) and Few Shot Learning (FSL) are two label-efficient\nmethods which have achieved excellent results recently. However, most prior\narts in both learning paradigms fail to explore the wealth of the vast\nunlabelled data. In this study, we address this issue in the scenario where the\nannotation budget is very limited, yet a large amount of unlabelled data for\nthe target task is available. We frame this work in the context of\nhistopathology where labelling is prohibitively expensive. To this end, we\nintroduce an active few shot learning framework, Myriad Active Learning (MAL),\nincluding a contrastive-learning encoder, pseudo-label generation, and novel\nquery sample selection in the loop. Specifically, we propose to massage\nunlabelled data in a self-supervised manner, where the obtained data\nrepresentations and clustering knowledge form the basis to activate the AL\nloop. With feedback from the oracle in each AL cycle, the pseudo-labels of the\nunlabelled data are refined by optimizing a shallow task-specific net on top of\nthe encoder. These updated pseudo-labels serve to inform and improve the active\nlearning query selection process. Furthermore, we introduce a novel recipe to\ncombine existing uncertainty measures and utilize the entire uncertainty list\nto reduce sample redundancy in AL. Extensive experiments on two public\nhistopathology datasets show that MAL has superior test accuracy, macro\nF1-score, and label efficiency compared to prior works, and can achieve a\ncomparable test accuracy to a fully supervised algorithm while labelling only\n5% of the dataset.",
            "author": [
                "Nico Schiavone",
                "Jingyi Wang",
                "Shuangzhi Li",
                "Roger Zemp",
                "Xingyu Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16161v1",
                "http://arxiv.org/pdf/2310.16161v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16157v1",
            "title": "Context-aware feature attribution through argumentation",
            "updated": "2023-10-24T20:02:02Z",
            "published": "2023-10-24T20:02:02Z",
            "summary": "Feature attribution is a fundamental task in both machine learning and data\nanalysis, which involves determining the contribution of individual features or\nvariables to a model's output. This process helps identify the most important\nfeatures for predicting an outcome. The history of feature attribution methods\ncan be traced back to General Additive Models (GAMs), which extend linear\nregression models by incorporating non-linear relationships between dependent\nand independent variables. In recent years, gradient-based methods and\nsurrogate models have been applied to unravel complex Artificial Intelligence\n(AI) systems, but these methods have limitations. GAMs tend to achieve lower\naccuracy, gradient-based methods can be difficult to interpret, and surrogate\nmodels often suffer from stability and fidelity issues. Furthermore, most\nexisting methods do not consider users' contexts, which can significantly\ninfluence their preferences. To address these limitations and advance the\ncurrent state-of-the-art, we define a novel feature attribution framework\ncalled Context-Aware Feature Attribution Through Argumentation (CA-FATA). Our\nframework harnesses the power of argumentation by treating each feature as an\nargument that can either support, attack or neutralize a prediction.\nAdditionally, CA-FATA formulates feature attribution as an argumentation\nprocedure, and each computation has explicit semantics, which makes it\ninherently interpretable. CA-FATA also easily integrates side information, such\nas users' contexts, resulting in more accurate predictions.",
            "author": [
                "Jinfeng Zhong",
                "Elsa Negre"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16157v1",
                "http://arxiv.org/pdf/2310.16157v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.IR",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16154v1",
            "title": "Breaking the Curse of Dimensionality in Deep Neural Networks by Learning\n  Invariant Representations",
            "updated": "2023-10-24T19:50:41Z",
            "published": "2023-10-24T19:50:41Z",
            "summary": "Artificial intelligence, particularly the subfield of machine learning, has\nseen a paradigm shift towards data-driven models that learn from and adapt to\ndata. This has resulted in unprecedented advancements in various domains such\nas natural language processing and computer vision, largely attributed to deep\nlearning, a special class of machine learning models. Deep learning arguably\nsurpasses traditional approaches by learning the relevant features from raw\ndata through a series of computational layers.\n  This thesis explores the theoretical foundations of deep learning by studying\nthe relationship between the architecture of these models and the inherent\nstructures found within the data they process. In particular, we ask What\ndrives the efficacy of deep learning algorithms and allows them to beat the\nso-called curse of dimensionality-i.e. the difficulty of generally learning\nfunctions in high dimensions due to the exponentially increasing need for data\npoints with increased dimensionality? Is it their ability to learn relevant\nrepresentations of the data by exploiting their structure? How do different\narchitectures exploit different data structures? In order to address these\nquestions, we push forward the idea that the structure of the data can be\neffectively characterized by its invariances-i.e. aspects that are irrelevant\nfor the task at hand.\n  Our methodology takes an empirical approach to deep learning, combining\nexperimental studies with physics-inspired toy models. These simplified models\nallow us to investigate and interpret the complex behaviors we observe in deep\nlearning systems, offering insights into their inner workings, with the\nfar-reaching goal of bridging the gap between theory and practice.",
            "author": [
                "Leonardo Petrini"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16154v1",
                "http://arxiv.org/pdf/2310.16154v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16152v1",
            "title": "FLTrojan: Privacy Leakage Attacks against Federated Language Models\n  Through Selective Weight Tampering",
            "updated": "2023-10-24T19:50:01Z",
            "published": "2023-10-24T19:50:01Z",
            "summary": "Federated learning (FL) is becoming a key component in many technology-based\napplications including language modeling -- where individual FL participants\noften have privacy-sensitive text data in their local datasets. However,\nrealizing the extent of privacy leakage in federated language models is not\nstraightforward and the existing attacks only intend to extract data regardless\nof how sensitive or naive it is. To fill this gap, in this paper, we introduce\ntwo novel findings with regard to leaking privacy-sensitive user data from\nfederated language models. Firstly, we make a key observation that model\nsnapshots from the intermediate rounds in FL can cause greater privacy leakage\nthan the final trained model. Secondly, we identify that privacy leakage can be\naggravated by tampering with a model's selective weights that are specifically\nresponsible for memorizing the sensitive training data. We show how a malicious\nclient can leak the privacy-sensitive data of some other user in FL even\nwithout any cooperation from the server. Our best-performing method improves\nthe membership inference recall by 29% and achieves up to 70% private data\nreconstruction, evidently outperforming existing attacks with stronger\nassumptions of adversary capabilities.",
            "author": [
                "Md Rafi Ur Rashid",
                "Vishnu Asutosh Dasu",
                "Kang Gu",
                "Najrin Sultana",
                "Shagufta Mehnaz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16152v1",
                "http://arxiv.org/pdf/2310.16152v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18364v1",
            "title": "From Heuristic to Analytic: Cognitively Motivated Strategies for\n  Coherent Physical Commonsense Reasoning",
            "updated": "2023-10-24T19:46:04Z",
            "published": "2023-10-24T19:46:04Z",
            "summary": "Pre-trained language models (PLMs) have shown impressive performance in\nvarious language tasks. However, they are prone to spurious correlations, and\noften generate illusory information. In real-world applications, PLMs should\njustify decisions with formalized, coherent reasoning chains, but this\nchallenge remains under-explored. Cognitive psychology theorizes that humans\nare capable of utilizing fast and intuitive heuristic thinking to make\ndecisions based on past experience, then rationalizing the decisions through\nslower and deliberative analytic reasoning. We incorporate these interlinked\ndual processes in fine-tuning and in-context learning with PLMs, applying them\nto two language understanding tasks that require coherent physical commonsense\nreasoning. We show that our proposed Heuristic-Analytic Reasoning (HAR)\nstrategies drastically improve the coherence of rationalizations for model\ndecisions, yielding state-of-the-art results on Tiered Reasoning for Intuitive\nPhysics (TRIP). We also find that this improved coherence is a direct result of\nmore faithful attention to relevant language context in each step of reasoning.\nOur findings suggest that human-like reasoning strategies can effectively\nimprove the coherence and reliability of PLM reasoning.",
            "author": [
                "Zheyuan Zhang",
                "Shane Storks",
                "Fengyuan Hu",
                "Sungryull Sohn",
                "Moontae Lee",
                "Honglak Lee",
                "Joyce Chai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18364v1",
                "http://arxiv.org/pdf/2310.18364v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16142v1",
            "title": "A Language Model with Limited Memory Capacity Captures Interference in\n  Human Sentence Processing",
            "updated": "2023-10-24T19:33:27Z",
            "published": "2023-10-24T19:33:27Z",
            "summary": "Two of the central factors believed to underpin human sentence processing\ndifficulty are expectations and retrieval from working memory. A recent attempt\nto create a unified cognitive model integrating these two factors relied on the\nparallels between the self-attention mechanism of transformer language models\nand cue-based retrieval theories of working memory in human sentence processing\n(Ryu and Lewis 2021). While Ryu and Lewis show that attention patterns in\nspecialized attention heads of GPT-2 are consistent with similarity-based\ninterference, a key prediction of cue-based retrieval models, their method\nrequires identifying syntactically specialized attention heads, and makes the\ncognitively implausible assumption that hundreds of memory retrieval operations\ntake place in parallel. In the present work, we develop a recurrent neural\nlanguage model with a single self-attention head, which more closely parallels\nthe memory system assumed by cognitive theories. We show that our model's\nsingle attention head captures semantic and syntactic interference effects\nobserved in human experiments.",
            "author": [
                "William Timkey",
                "Tal Linzen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16142v1",
                "http://arxiv.org/pdf/2310.16142v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19821v1",
            "title": "A Risk-Averse Framework for Non-Stationary Stochastic Multi-Armed\n  Bandits",
            "updated": "2023-10-24T19:29:13Z",
            "published": "2023-10-24T19:29:13Z",
            "summary": "In a typical stochastic multi-armed bandit problem, the objective is often to\nmaximize the expected sum of rewards over some time horizon $T$. While the\nchoice of a strategy that accomplishes that is optimal with no additional\ninformation, it is no longer the case when provided additional\nenvironment-specific knowledge. In particular, in areas of high volatility like\nhealthcare or finance, a naive reward maximization approach often does not\naccurately capture the complexity of the learning problem and results in\nunreliable solutions. To tackle problems of this nature, we propose a framework\nof adaptive risk-aware strategies that operate in non-stationary environments.\nOur framework incorporates various risk measures prevalent in the literature to\nmap multiple families of multi-armed bandit algorithms into a risk-sensitive\nsetting. In addition, we equip the resulting algorithms with the Restarted\nBayesian Online Change-Point Detection (R-BOCPD) algorithm and impose a\n(tunable) forced exploration strategy to detect local (per-arm) switches. We\nprovide finite-time theoretical guarantees and an asymptotic regret bound of\norder $\\tilde O(\\sqrt{K_T T})$ up to time horizon $T$ with $K_T$ the total\nnumber of change-points. In practice, our framework compares favorably to the\nstate-of-the-art in both synthetic and real-world environments and manages to\nperform efficiently with respect to both risk-sensitivity and non-stationarity.",
            "author": [
                "Reda Alami",
                "Mohammed Mahfoud",
                "Mastane Achab"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19821v1",
                "http://arxiv.org/pdf/2310.19821v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16140v1",
            "title": "IA Para el Mantenimiento Predictivo en Canteras: Modelado",
            "updated": "2023-10-24T19:27:50Z",
            "published": "2023-10-24T19:27:50Z",
            "summary": "Dependence on raw materials, especially in the mining sector, is a key part\nof today's economy. Aggregates are vital, being the second most used raw\nmaterial after water. Digitally transforming this sector is key to optimizing\noperations. However, supervision and maintenance (predictive and corrective)\nare challenges little explored in this sector, due to the particularities of\nthe sector, machinery and environmental conditions. All this, despite the\nsuccesses achieved in other scenarios in monitoring with acoustic and contact\nsensors. We present an unsupervised learning scheme that trains a variational\nautoencoder model on a set of sound records. This is the first such dataset\ncollected during processing plant operations, containing information from\ndifferent points of the processing line. Our results demonstrate the model's\nability to reconstruct and represent in latent space the recorded sounds, the\ndifferences in operating conditions and between different equipment. In the\nfuture, this should facilitate the classification of sounds, as well as the\ndetection of anomalies and degradation patterns in the operation of the\nmachinery.",
            "author": [
                "Fernando Marcos",
                "Rodrigo Tamaki",
                "Mateo C\u00e1mara",
                "Virginia Yag\u00fce",
                "Jos\u00e9 Luis Blanco"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16140v1",
                "http://arxiv.org/pdf/2310.16140v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16139v1",
            "title": "Pix2HDR -- A pixel-wise acquisition and deep learning-based synthesis\n  approach for high-speed HDR videos",
            "updated": "2023-10-24T19:27:35Z",
            "published": "2023-10-24T19:27:35Z",
            "summary": "Accurately capturing dynamic scenes with wide-ranging motion and light\nintensity is crucial for many vision applications. However, acquiring\nhigh-speed high dynamic range (HDR) video is challenging because the camera's\nframe rate restricts its dynamic range. Existing methods sacrifice speed to\nacquire multi-exposure frames. Yet, misaligned motion in these frames can still\npose complications for HDR fusion algorithms, resulting in artifacts. Instead\nof frame-based exposures, we sample the videos using individual pixels at\nvarying exposures and phase offsets. Implemented on a pixel-wise programmable\nimage sensor, our sampling pattern simultaneously captures fast motion at a\nhigh dynamic range. We then transform pixel-wise outputs into an HDR video\nusing end-to-end learned weights from deep neural networks, achieving high\nspatiotemporal resolution with minimized motion blurring. We demonstrate\naliasing-free HDR video acquisition at 1000 FPS, resolving fast motion under\nlow-light conditions and against bright backgrounds - both challenging\nconditions for conventional cameras. By combining the versatility of pixel-wise\nsampling patterns with the strength of deep neural networks at decoding complex\nscenes, our method greatly enhances the vision system's adaptability and\nperformance in dynamic conditions.",
            "author": [
                "Caixin Wang",
                "Jie Zhang",
                "Matthew A. Wilson",
                "Ralph Etienne-Cummings"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16139v1",
                "http://arxiv.org/pdf/2310.16139v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16138v1",
            "title": "Subtle Signals: Video-based Detection of Infant Non-nutritive Sucking as\n  a Neurodevelopmental Cue",
            "updated": "2023-10-24T19:26:07Z",
            "published": "2023-10-24T19:26:07Z",
            "summary": "Non-nutritive sucking (NNS), which refers to the act of sucking on a\npacifier, finger, or similar object without nutrient intake, plays a crucial\nrole in assessing healthy early development. In the case of preterm infants,\nNNS behavior is a key component in determining their readiness for feeding. In\nolder infants, the characteristics of NNS behavior offer valuable insights into\nneural and motor development. Additionally, NNS activity has been proposed as a\npotential safeguard against sudden infant death syndrome (SIDS). However, the\nclinical application of NNS assessment is currently hindered by labor-intensive\nand subjective finger-in-mouth evaluations. Consequently, researchers often\nresort to expensive pressure transducers for objective NNS signal measurement.\nTo enhance the accessibility and reliability of NNS signal monitoring for both\nclinicians and researchers, we introduce a vision-based algorithm designed for\nnon-contact detection of NNS activity using baby monitor footage in natural\nsettings. Our approach involves a comprehensive exploration of optical flow and\ntemporal convolutional networks, enabling the detection and amplification of\nsubtle infant-sucking signals. We successfully classify short video clips of\nuniform length into NNS and non-NNS periods. Furthermore, we investigate manual\nand learning-based techniques to piece together local classification results,\nfacilitating the segmentation of longer mixed-activity videos into NNS and\nnon-NNS segments of varying duration. Our research introduces two novel\ndatasets of annotated infant videos, including one sourced from our clinical\nstudy featuring 19 infant subjects and 183 hours of overnight baby monitor\nfootage.",
            "author": [
                "Shaotong Zhu",
                "Michael Wan",
                "Sai Kumar Reddy Manne",
                "Emily Zimmerman",
                "Sarah Ostadabbas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16138v1",
                "http://arxiv.org/pdf/2310.16138v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16125v2",
            "title": "Online Two-stage Thermal History Prediction Method for Metal Additive\n  Manufacturing of Thin Walls",
            "updated": "2023-11-17T19:46:15Z",
            "published": "2023-10-24T18:58:36Z",
            "summary": "This paper aims to propose an online two-stage thermal history prediction\nmethod, which could be integrated into a metal AM process for performance\ncontrol. Based on the similarity of temperature curves (curve segments of a\ntemperature profile of one point) between any two successive layers, the first\nstage of the proposed method designs a layer-to-layer prediction model to\nestimate the temperature curves of the yet-to-print layer from measured\ntemperatures of certain points on the previously printed layer. With\nmeasured/predicted temperature profiles of several points on the same layer,\nthe second stage proposes a reduced order model (ROM) (intra-layer prediction\nmodel) to decompose and construct the temperature profiles of all points on the\nsame layer, which could be used to build the temperature field of the entire\nlayer. The training of ROM is performed with an extreme learning machine (ELM)\nfor computational efficiency. Fifteen wire arc AM experiments and nine\nsimulations are designed for thin walls with a fixed length and unidirectional\nprinting of each layer. The test results indicate that the proposed prediction\nmethod could construct the thermal history of a yet-to-print layer within 0.1\nseconds on a low-cost desktop computer. Meanwhile, the method has acceptable\ngeneralization capability in most cases from lower layers to higher layers in\nthe same simulation, as well as from one simulation to a new simulation on\ndifferent AM process parameters. More importantly, after fine-tuning the\nproposed method with limited experimental data, the relative errors of all\npredicted temperature profiles on a new experiment are smaller than 0.09, which\ndemonstrates the applicability and generalization of the proposed two-stage\nthermal history prediction method in online applications for metal AM.",
            "author": [
                "Yifan Tang",
                "M. Rahmani Dehaghani",
                "Pouyan Sajadi",
                "Shahriar Bakrani Balani",
                "Akshay Dhalpe",
                "Suraj Panicker",
                "Di Wu",
                "Eric Coatanea",
                "G. Gary Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16125v2",
                "http://arxiv.org/pdf/2310.16125v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16123v1",
            "title": "Anchor Space Optimal Transport: Accelerating Batch Processing of\n  Multiple OT Problems",
            "updated": "2023-10-24T18:55:12Z",
            "published": "2023-10-24T18:55:12Z",
            "summary": "The optimal transport (OT) theory provides an effective way to compare\nprobability distributions on a defined metric space, but it suffers from cubic\ncomputational complexity. Although the Sinkhorn's algorithm greatly reduces the\ncomputational complexity of OT solutions, the solutions of multiple OT problems\nare still time-consuming and memory-comsuming in practice. However, many works\non the computational acceleration of OT are usually based on the premise of a\nsingle OT problem, ignoring the potential common characteristics of the\ndistributions in a mini-batch. Therefore, we propose a translated OT problem\ndesignated as the anchor space optimal transport (ASOT) problem, which is\nspecially designed for batch processing of multiple OT problem solutions. For\nthe proposed ASOT problem, the distributions will be mapped into a shared\nanchor point space, which learns the potential common characteristics and thus\nhelp accelerate OT batch processing. Based on the proposed ASOT, the\nWasserstein distance error to the original OT problem is proven to be bounded\nby ground cost errors. Building upon this, we propose three methods to learn an\nanchor space minimizing the distance error, each of which has its application\nbackground. Numerical experiments on real-world datasets show that our proposed\nmethods can greatly reduce computational time while maintaining reasonable\napproximation performance.",
            "author": [
                "Jianming Huang",
                "Xun Su",
                "Zhongxi Fang",
                "Hiroyuki Kasai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16123v1",
                "http://arxiv.org/pdf/2310.16123v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16121v2",
            "title": "19 Parameters Is All You Need: Tiny Neural Networks for Particle Physics",
            "updated": "2023-11-29T22:13:24Z",
            "published": "2023-10-24T18:51:22Z",
            "summary": "As particle accelerators increase their collision rates, and deep learning\nsolutions prove their viability, there is a growing need for lightweight and\nfast neural network architectures for low-latency tasks such as triggering. We\nexamine the potential of one recent Lorentz- and permutation-symmetric\narchitecture, PELICAN, and present its instances with as few as 19 trainable\nparameters that outperform generic architectures with tens of thousands of\nparameters when compared on the binary classification task of top quark jet\ntagging.",
            "author": [
                "Alexander Bogatskiy",
                "Timothy Hoffman",
                "Jan T. Offermann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16121v2",
                "http://arxiv.org/pdf/2310.16121v2"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "cs.LG",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16119v1",
            "title": "Alquist 5.0: Dialogue Trees Meet Generative Models. A Novel Approach for\n  Enhancing SocialBot Conversations",
            "updated": "2023-10-24T18:47:13Z",
            "published": "2023-10-24T18:47:13Z",
            "summary": "We present our SocialBot -- Alquist~5.0 -- developed for the Alexa Prize\nSocialBot Grand Challenge~5. Building upon previous versions of our system, we\nintroduce the NRG Barista and outline several innovative approaches for\nintegrating Barista into our SocialBot, improving the overall conversational\nexperience. Additionally, we extend our SocialBot to support multimodal\ndevices. This paper offers insights into the development of Alquist~5.0, which\nmeets evolving user expectations while maintaining empathetic and knowledgeable\nconversational abilities across diverse topics.",
            "author": [
                "Ond\u0159ej Kobza",
                "Jan \u010cuhel",
                "Tommaso Gargiani",
                "David Herel",
                "Petr Marek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16119v1",
                "http://arxiv.org/pdf/2310.16119v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16115v1",
            "title": "Wakening Past Concepts without Past Data: Class-Incremental Learning\n  from Online Placebos",
            "updated": "2023-10-24T18:32:46Z",
            "published": "2023-10-24T18:32:46Z",
            "summary": "Not forgetting old class knowledge is a key challenge for class-incremental\nlearning (CIL) when the model continuously adapts to new classes. A common\ntechnique to address this is knowledge distillation (KD), which penalizes\nprediction inconsistencies between old and new models. Such prediction is made\nwith almost new class data, as old class data is extremely scarce due to the\nstrict memory limitation in CIL. In this paper, we take a deep dive into KD\nlosses and find that \"using new class data for KD\" not only hinders the model\nadaption (for learning new classes) but also results in low efficiency for\npreserving old class knowledge. We address this by \"using the placebos of old\nclasses for KD\", where the placebos are chosen from a free image stream, such\nas Google Images, in an automatical and economical fashion. To this end, we\ntrain an online placebo selection policy to quickly evaluate the quality of\nstreaming images (good or bad placebos) and use only good ones for one-time\nfeed-forward computation of KD. We formulate the policy training process as an\nonline Markov Decision Process (MDP), and introduce an online learning\nalgorithm to solve this MDP problem without causing much computation costs. In\nexperiments, we show that our method 1) is surprisingly effective even when\nthere is no class overlap between placebos and original old class data, 2) does\nnot require any additional supervision or memory budget, and 3) significantly\noutperforms a number of top-performing CIL methods, in particular when using\nlower memory budgets for old class exemplars, e.g., five exemplars per class.",
            "author": [
                "Yaoyao Liu",
                "Yingying Li",
                "Bernt Schiele",
                "Qianru Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16115v1",
                "http://arxiv.org/pdf/2310.16115v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16855v1",
            "title": "Stock Market Directional Bias Prediction Using ML Algorithms",
            "updated": "2023-10-24T18:26:57Z",
            "published": "2023-10-24T18:26:57Z",
            "summary": "The stock market has been established since the 13th century, but in the\ncurrent epoch of time, it is substantially more practicable to anticipate the\nstock market than it was at any other point in time due to the tools and data\nthat are available for both traditional and algorithmic trading. There are many\ndifferent machine learning models that can do time-series forecasting in the\ncontext of machine learning. These models can be used to anticipate the future\nprices of assets and/or the directional bias of assets. In this study, we\nexamine and contrast the effectiveness of three different machine learning\nalgorithms, namely, logistic regression, decision tree, and random forest to\nforecast the movement of the assets traded on the Japanese stock market. In\naddition, the models are compared to a feed forward deep neural network, and it\nis found that all of the models consistently reach above 50% in directional\nbias forecasting for the stock market. The results of our study contribute to a\nbetter understanding of the complexity involved in stock market forecasting and\ngive insight on the possible role that machine learning could play in this\ncontext.",
            "author": [
                "Ryan Chipwanya"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16855v1",
                "http://arxiv.org/pdf/2310.16855v1"
            ],
            "primary_category": "q-fin.ST",
            "category": [
                "q-fin.ST",
                "ACM-class: F.2.2, I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16113v1",
            "title": "Compressed representation of brain genetic transcription",
            "updated": "2023-10-24T18:26:43Z",
            "published": "2023-10-24T18:26:43Z",
            "summary": "The architecture of the brain is too complex to be intuitively surveyable\nwithout the use of compressed representations that project its variation into a\ncompact, navigable space. The task is especially challenging with\nhigh-dimensional data, such as gene expression, where the joint complexity of\nanatomical and transcriptional patterns demands maximum compression.\nEstablished practice is to use standard principal component analysis (PCA),\nwhose computational felicity is offset by limited expressivity, especially at\ngreat compression ratios. Employing whole-brain, voxel-wise Allen Brain Atlas\ntranscription data, here we systematically compare compressed representations\nbased on the most widely supported linear and non-linear methods-PCA, kernel\nPCA, non-negative matrix factorization (NMF), t-stochastic neighbour embedding\n(t-SNE), uniform manifold approximation and projection (UMAP), and deep\nauto-encoding-quantifying reconstruction fidelity, anatomical coherence, and\npredictive utility with respect to signalling, microstructural, and metabolic\ntargets. We show that deep auto-encoders yield superior representations across\nall metrics of performance and target domains, supporting their use as the\nreference standard for representing transcription patterns in the human brain.",
            "author": [
                "James K Ruffle",
                "Henry Watkins",
                "Robert J Gray",
                "Harpreet Hyare",
                "Michel Thiebaut de Schotten",
                "Parashkev Nachev"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16113v1",
                "http://arxiv.org/pdf/2310.16113v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.GN",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16112v1",
            "title": "Towards long-tailed, multi-label disease classification from chest\n  X-ray: Overview of the CXR-LT challenge",
            "updated": "2023-10-24T18:26:22Z",
            "published": "2023-10-24T18:26:22Z",
            "summary": "Many real-world image recognition problems, such as diagnostic medical\nimaging exams, are \"long-tailed\" $\\unicode{x2013}$ there are a few common\nfindings followed by many more relatively rare conditions. In chest\nradiography, diagnosis is both a long-tailed and multi-label problem, as\npatients often present with multiple findings simultaneously. While researchers\nhave begun to study the problem of long-tailed learning in medical image\nrecognition, few have studied the interaction of label imbalance and label\nco-occurrence posed by long-tailed, multi-label disease classification. To\nengage with the research community on this emerging topic, we conducted an open\nchallenge, CXR-LT, on long-tailed, multi-label thorax disease classification\nfrom chest X-rays (CXRs). We publicly release a large-scale benchmark dataset\nof over 350,000 CXRs, each labeled with at least one of 26 clinical findings\nfollowing a long-tailed distribution. We synthesize common themes of\ntop-performing solutions, providing practical recommendations for long-tailed,\nmulti-label medical image classification. Finally, we use these insights to\npropose a path forward involving vision-language foundation models for few- and\nzero-shot disease classification.",
            "author": [
                "Gregory Holste",
                "Yiliang Zhou",
                "Song Wang",
                "Ajay Jaiswal",
                "Mingquan Lin",
                "Sherry Zhuge",
                "Yuzhe Yang",
                "Dongkyun Kim",
                "Trong-Hieu Nguyen-Mau",
                "Minh-Triet Tran",
                "Jaehyup Jeong",
                "Wongi Park",
                "Jongbin Ryu",
                "Feng Hong",
                "Arsh Verma",
                "Yosuke Yamagishi",
                "Changhyun Kim",
                "Hyeryeong Seo",
                "Myungjoo Kang",
                "Leo Anthony Celi",
                "Zhiyong Lu",
                "Ronald M. Summers",
                "George Shih",
                "Zhangyang Wang",
                "Yifan Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16112v1",
                "http://arxiv.org/pdf/2310.16112v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16111v2",
            "title": "Locally Differentially Private Document Generation Using Zero Shot\n  Prompting",
            "updated": "2023-11-30T18:13:01Z",
            "published": "2023-10-24T18:25:13Z",
            "summary": "Numerous studies have highlighted the privacy risks associated with\npretrained large language models. In contrast, our research offers a unique\nperspective by demonstrating that pretrained large language models can\neffectively contribute to privacy preservation. We propose a locally\ndifferentially private mechanism called DP-Prompt, which leverages the power of\npretrained large language models and zero-shot prompting to counter author\nde-anonymization attacks while minimizing the impact on downstream utility.\nWhen DP-Prompt is used with a powerful language model like ChatGPT (gpt-3.5),\nwe observe a notable reduction in the success rate of de-anonymization attacks,\nshowing that it surpasses existing approaches by a considerable margin despite\nits simpler design. For instance, in the case of the IMDB dataset, DP-Prompt\n(with ChatGPT) perfectly recovers the clean sentiment F1 score while achieving\na 46\\% reduction in author identification F1 score against static attackers and\na 26\\% reduction against adaptive attackers. We conduct extensive experiments\nacross six open-source large language models, ranging up to 7 billion\nparameters, to analyze various effects of the privacy-utility tradeoff.",
            "author": [
                "Saiteja Utpala",
                "Sara Hooker",
                "Pin Yu Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16111v2",
                "http://arxiv.org/pdf/2310.16111v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16106v1",
            "title": "Decentralized Learning over Wireless Networks with Broadcast-Based\n  Subgraph Sampling",
            "updated": "2023-10-24T18:15:52Z",
            "published": "2023-10-24T18:15:52Z",
            "summary": "This work centers on the communication aspects of decentralized learning over\nwireless networks, using consensus-based decentralized stochastic gradient\ndescent (D-SGD). Considering the actual communication cost or delay caused by\nin-network information exchange in an iterative process, our goal is to achieve\nfast convergence of the algorithm measured by improvement per transmission\nslot. We propose BASS, an efficient communication framework for D-SGD over\nwireless networks with broadcast transmission and probabilistic subgraph\nsampling. In each iteration, we activate multiple subsets of non-interfering\nnodes to broadcast model updates to their neighbors. These subsets are randomly\nactivated over time, with probabilities reflecting their importance in network\nconnectivity and subject to a communication cost constraint (e.g., the average\nnumber of transmission slots per iteration). During the consensus update step,\nonly bi-directional links are effectively preserved to maintain communication\nsymmetry. In comparison to existing link-based scheduling methods, the inherent\nbroadcasting nature of wireless channels offers intrinsic advantages in\nspeeding up convergence of decentralized learning by creating more communicated\nlinks with the same number of transmission slots.",
            "author": [
                "Daniel P\u00e9rez Herrera",
                "Zheng Chen",
                "Erik G. Larsson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16106v1",
                "http://arxiv.org/pdf/2310.16106v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "cs.IT",
                "cs.SY",
                "eess.SY",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16105v2",
            "title": "Locally Differentially Private Gradient Tracking for Distributed Online\n  Learning over Directed Graphs",
            "updated": "2023-10-29T17:34:15Z",
            "published": "2023-10-24T18:15:25Z",
            "summary": "Distributed online learning has been proven extremely effective in solving\nlarge-scale machine learning problems over streaming data. However, information\nsharing between learners in distributed learning also raises concerns about the\npotential leakage of individual learners' sensitive data. To mitigate this\nrisk, differential privacy, which is widely regarded as the \"gold standard\" for\nprivacy protection, has been widely employed in many existing results on\ndistributed online learning. However, these results often face a fundamental\ntradeoff between learning accuracy and privacy. In this paper, we propose a\nlocally differentially private gradient tracking based distributed online\nlearning algorithm that successfully circumvents this tradeoff. We prove that\nthe proposed algorithm converges in mean square to the exact optimal solution\nwhile ensuring rigorous local differential privacy, with the cumulative privacy\nbudget guaranteed to be finite even when the number of iterations tends to\ninfinity. The algorithm is applicable even when the communication graph among\nlearners is directed. To the best of our knowledge, this is the first result\nthat simultaneously ensures learning accuracy and rigorous local differential\nprivacy in distributed online learning over directed graphs. We evaluate our\nalgorithm's performance by using multiple benchmark machine-learning\napplications, including logistic regression of the \"Mushrooms\" dataset and\nCNN-based image classification of the \"MNIST\" and \"CIFAR-10\" datasets,\nrespectively. The experimental results confirm that the proposed algorithm\noutperforms existing counterparts in both training and testing accuracies.",
            "author": [
                "Ziqin Chen",
                "Yongqiang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16105v2",
                "http://arxiv.org/pdf/2310.16105v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16103v1",
            "title": "LaksNet: an end-to-end deep learning model for self-driving cars in\n  Udacity simulator",
            "updated": "2023-10-24T18:11:25Z",
            "published": "2023-10-24T18:11:25Z",
            "summary": "The majority of road accidents occur because of human errors, including\ndistraction, recklessness, and drunken driving. One of the effective ways to\novercome this dangerous situation is by implementing self-driving technologies\nin vehicles. In this paper, we focus on building an efficient deep-learning\nmodel for self-driving cars. We propose a new and effective convolutional\nneural network model called `LaksNet' consisting of four convolutional layers\nand two fully connected layers. We conduct extensive experiments using our\nLaksNet model with the training data generated from the Udacity simulator. Our\nmodel outperforms many existing pre-trained ImageNet and NVIDIA models in terms\nof the duration of the car for which it drives without going off the track on\nthe simulator.",
            "author": [
                "Lakshmikar R. Polamreddy",
                "Youshan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16103v1",
                "http://arxiv.org/pdf/2310.16103v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16102v1",
            "title": "Learned, Uncertainty-driven Adaptive Acquisition for Photon-Efficient\n  Multiphoton Microscopy",
            "updated": "2023-10-24T18:06:03Z",
            "published": "2023-10-24T18:06:03Z",
            "summary": "Multiphoton microscopy (MPM) is a powerful imaging tool that has been a\ncritical enabler for live tissue imaging. However, since most multiphoton\nmicroscopy platforms rely on point scanning, there is an inherent trade-off\nbetween acquisition time, field of view (FOV), phototoxicity, and image\nquality, often resulting in noisy measurements when fast, large FOV, and/or\ngentle imaging is needed. Deep learning could be used to denoise multiphoton\nmicroscopy measurements, but these algorithms can be prone to hallucination,\nwhich can be disastrous for medical and scientific applications. We propose a\nmethod to simultaneously denoise and predict pixel-wise uncertainty for\nmultiphoton imaging measurements, improving algorithm trustworthiness and\nproviding statistical guarantees for the deep learning predictions.\nFurthermore, we propose to leverage this learned, pixel-wise uncertainty to\ndrive an adaptive acquisition technique that rescans only the most uncertain\nregions of a sample. We demonstrate our method on experimental noisy MPM\nmeasurements of human endometrium tissues, showing that we can maintain fine\nfeatures and outperform other denoising methods while predicting uncertainty at\neach pixel. Finally, with our adaptive acquisition technique, we demonstrate a\n120X reduction in acquisition time and total light dose while successfully\nrecovering fine features in the sample. We are the first to demonstrate\ndistribution-free uncertainty quantification for a denoising task with real\nexperimental data and the first to propose adaptive acquisition based on\nreconstruction uncertainty",
            "author": [
                "Cassandra Tong Ye",
                "Jiashu Han",
                "Kunzan Liu",
                "Anastasios Angelopoulos",
                "Linda Griffith",
                "Kristina Monakhova",
                "Sixian You"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16102v1",
                "http://arxiv.org/pdf/2310.16102v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16099v1",
            "title": "Anatomically-aware Uncertainty for Semi-supervised Image Segmentation",
            "updated": "2023-10-24T18:03:07Z",
            "published": "2023-10-24T18:03:07Z",
            "summary": "Semi-supervised learning relaxes the need of large pixel-wise labeled\ndatasets for image segmentation by leveraging unlabeled data. A prominent way\nto exploit unlabeled data is to regularize model predictions. Since the\npredictions of unlabeled data can be unreliable, uncertainty-aware schemes are\ntypically employed to gradually learn from meaningful and reliable predictions.\nUncertainty estimation methods, however, rely on multiple inferences from the\nmodel predictions that must be computed for each training step, which is\ncomputationally expensive. Moreover, these uncertainty maps capture pixel-wise\ndisparities and do not consider global information. This work proposes a novel\nmethod to estimate segmentation uncertainty by leveraging global information\nfrom the segmentation masks. More precisely, an anatomically-aware\nrepresentation is first learnt to model the available segmentation masks. The\nlearnt representation thereupon maps the prediction of a new segmentation into\nan anatomically-plausible segmentation. The deviation from the plausible\nsegmentation aids in estimating the underlying pixel-level uncertainty in order\nto further guide the segmentation network. The proposed method consequently\nestimates the uncertainty using a single inference from our representation,\nthereby reducing the total computation. We evaluate our method on two publicly\navailable segmentation datasets of left atria in cardiac MRIs and of multiple\norgans in abdominal CTs. Our anatomically-aware method improves the\nsegmentation accuracy over the state-of-the-art semi-supervised methods in\nterms of two commonly used evaluation metrics.",
            "author": [
                "Sukesh Adiga V",
                "Jose Dolz",
                "Herve Lombaert"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16099v1",
                "http://arxiv.org/pdf/2310.16099v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16095v1",
            "title": "CR-COPEC: Causal Rationale of Corporate Performance Changes to Learn\n  from Financial Reports",
            "updated": "2023-10-24T18:00:40Z",
            "published": "2023-10-24T18:00:40Z",
            "summary": "In this paper, we introduce CR-COPEC called Causal Rationale of Corporate\nPerformance Changes from financial reports. This is a comprehensive large-scale\ndomain-adaptation causal sentence dataset to detect financial performance\nchanges of corporate. CR-COPEC contributes to two major achievements. First, it\ndetects causal rationale from 10-K annual reports of the U.S. companies, which\ncontain experts' causal analysis following accounting standards in a formal\nmanner. This dataset can be widely used by both individual investors and\nanalysts as material information resources for investing and decision making\nwithout tremendous effort to read through all the documents. Second, it\ncarefully considers different characteristics which affect the financial\nperformance of companies in twelve industries. As a result, CR-COPEC can\ndistinguish causal sentences in various industries by taking unique narratives\nin each industry into consideration. We also provide an extensive analysis of\nhow well CR-COPEC dataset is constructed and suited for classifying target\nsentences as causal ones with respect to industry characteristics. Our dataset\nand experimental codes are publicly available.",
            "author": [
                "Ye Eun Chun",
                "Sunjae Kwon",
                "Kyunghwan Sohn",
                "Nakwon Sung",
                "Junyoup Lee",
                "Byungki Seo",
                "Kevin Compher",
                "Seung-won Hwang",
                "Jaesik Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16095v1",
                "http://arxiv.org/pdf/2310.16095v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16096v1",
            "title": "Contextual Bandits for Evaluating and Improving Inventory Control\n  Policies",
            "updated": "2023-10-24T18:00:40Z",
            "published": "2023-10-24T18:00:40Z",
            "summary": "Solutions to address the periodic review inventory control problem with\nnonstationary random demand, lost sales, and stochastic vendor lead times\ntypically involve making strong assumptions on the dynamics for either\napproximation or simulation, and applying methods such as optimization, dynamic\nprogramming, or reinforcement learning. Therefore, it is important to analyze\nand evaluate any inventory control policy, in particular to see if there is\nroom for improvement. We introduce the concept of an equilibrium policy, a\ndesirable property of a policy that intuitively means that, in hindsight,\nchanging only a small fraction of actions does not result in materially more\nreward. We provide a light-weight contextual bandit-based algorithm to evaluate\nand occasionally tweak policies, and show that this method achieves favorable\nguarantees, both theoretically and in empirical studies.",
            "author": [
                "Dean Foster",
                "Randy Jia",
                "Dhruv Madeka"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16096v1",
                "http://arxiv.org/pdf/2310.16096v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16088v1",
            "title": "Physical Properties of 5,000 Cool LMC Supergiants with Gaia XP Spectra:\n  A Detailed Portrait of the Upper HR Diagram Hints at Missing Supernova\n  Progenitors",
            "updated": "2023-10-24T18:00:02Z",
            "published": "2023-10-24T18:00:02Z",
            "summary": "Characterizing the physical properties of cool supergiants allows us to probe\nthe final stages of a massive star's evolution before it undergoes core\ncollapse. Despite their importance, the fundamental properties for these stars\n-- $T_{\\rm eff}$ and $\\log L/L_\\odot$ -- are only known for a limited number of\nobjects. The third data release of the Gaia mission contains precise photometry\nand low-resolution spectroscopy of hundreds of cool supergiants in the LMC with\nwell-constrained properties. Using these data, we train a simple and\neasily-interpretable machine learning model to regress effective temperatures\nand luminosities with high accuracy and precision comparable to the training\ndata. We then apply our model to 5000 cool supergiants, many of which have no\npreviously-published $T_{\\rm eff}$ or $L$ estimates. The resulting\nHertzprung-Russell diagram is well-populated, allowing us to study the\ndistribution of cool supergiants in great detail. Examining the luminosity\nfunctions of our sample, we find a notable flattening in the luminosity\nfunction of yellow supergiants above $\\log L/L_\\odot=5$, and a corresponding\nsteepening of the red supergiant luminosity function. We place this finding in\ncontext with previous results, and present its implications for the infamous\nred supergiant problem.",
            "author": [
                "Trevor Z. Dorn-Wallenstein",
                "Kathryn F. Neugent",
                "Emily M. Levesque"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16088v1",
                "http://arxiv.org/pdf/2310.16088v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16052v1",
            "title": "Synthetic Data as Validation",
            "updated": "2023-10-24T17:59:55Z",
            "published": "2023-10-24T17:59:55Z",
            "summary": "This study leverages synthetic data as a validation set to reduce overfitting\nand ease the selection of the best model in AI development. While synthetic\ndata have been used for augmenting the training set, we find that synthetic\ndata can also significantly diversify the validation set, offering marked\nadvantages in domains like healthcare, where data are typically limited,\nsensitive, and from out-domain sources (i.e., hospitals). In this study, we\nillustrate the effectiveness of synthetic data for early cancer detection in\ncomputed tomography (CT) volumes, where synthetic tumors are generated and\nsuperimposed onto healthy organs, thereby creating an extensive dataset for\nrigorous validation. Using synthetic data as validation can improve AI\nrobustness in both in-domain and out-domain test sets. Furthermore, we\nestablish a new continual learning framework that continuously trains AI models\non a stream of out-domain data with synthetic tumors. The AI model trained and\nvalidated in dynamically expanding synthetic data can consistently outperform\nmodels trained and validated exclusively on real-world data. Specifically, the\nDSC score for liver tumor segmentation improves from 26.7% (95% CI:\n22.6%-30.9%) to 34.5% (30.8%-38.2%) when evaluated on an in-domain dataset and\nfrom 31.1% (26.0%-36.2%) to 35.4% (32.1%-38.7%) on an out-domain dataset.\nImportantly, the performance gain is particularly significant in identifying\nvery tiny liver tumors (radius < 5mm) in CT volumes, with Sensitivity improving\nfrom 33.1% to 55.4% on an in-domain dataset and 33.9% to 52.3% on an out-domain\ndataset, justifying the efficacy in early detection of cancer. The application\nof synthetic data, from both training and validation perspectives, underlines a\npromising avenue to enhance AI robustness when dealing with data from varying\ndomains.",
            "author": [
                "Qixin Hu",
                "Alan Yuille",
                "Zongwei Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16052v1",
                "http://arxiv.org/pdf/2310.16052v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16050v1",
            "title": "EquivAct: SIM(3)-Equivariant Visuomotor Policies beyond Rigid Object\n  Manipulation",
            "updated": "2023-10-24T17:59:48Z",
            "published": "2023-10-24T17:59:48Z",
            "summary": "If a robot masters folding a kitchen towel, we would also expect it to master\nfolding a beach towel. However, existing works for policy learning that rely on\ndata set augmentations are still limited in achieving this level of\ngeneralization. Our insight is to add equivariance to both the visual object\nrepresentation and policy architecture. We propose EquivAct which utilizes\nSIM(3)-equivariant network structures that guarantee generalization across all\npossible object translations, 3D rotations, and scales by construction.\nTraining of EquivAct is done in two phases. We first pre-train a\nSIM(3)-equivariant visual representation on simulated scene point clouds. Then,\nwe learn a SIM(3)-equivariant visuomotor policy on top of the pre-trained\nvisual representation using a small amount of source task demonstrations. We\ndemonstrate that after training, the learned policy directly transfers to\nobjects that substantially differ in scale, position and orientation from the\nsource demonstrations. In simulation, we evaluate our method in three\nmanipulation tasks involving deformable and articulated objects thereby going\nbeyond the typical rigid object manipulation tasks that prior works considered.\nWe show that our method outperforms prior works that do not use equivariant\narchitectures or do not use our contrastive pre-training procedure. We also\nshow quantitative and qualitative experiments on three real robot tasks, where\nthe robot watches twenty demonstrations of a tabletop task and transfers\nzero-shot to a mobile manipulation task in a much larger setup. Project\nwebsite: https://equivact.github.io",
            "author": [
                "Jingyun Yang",
                "Congyue Deng",
                "Jimmy Wu",
                "Rika Antonova",
                "Leonidas Guibas",
                "Jeannette Bohg"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16050v1",
                "http://arxiv.org/pdf/2310.16050v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16048v1",
            "title": "AI Alignment and Social Choice: Fundamental Limitations and Policy\n  Implications",
            "updated": "2023-10-24T17:59:04Z",
            "published": "2023-10-24T17:59:04Z",
            "summary": "Aligning AI agents to human intentions and values is a key bottleneck in\nbuilding safe and deployable AI applications. But whose values should AI agents\nbe aligned with? Reinforcement learning with human feedback (RLHF) has emerged\nas the key framework for AI alignment. RLHF uses feedback from human\nreinforcers to fine-tune outputs; all widely deployed large language models\n(LLMs) use RLHF to align their outputs to human values. It is critical to\nunderstand the limitations of RLHF and consider policy challenges arising from\nthese limitations. In this paper, we investigate a specific challenge in\nbuilding RLHF systems that respect democratic norms. Building on impossibility\nresults in social choice theory, we show that, under fairly broad assumptions,\nthere is no unique voting protocol to universally align AI systems using RLHF\nthrough democratic processes. Further, we show that aligning AI agents with the\nvalues of all individuals will always violate certain private ethical\npreferences of an individual user i.e., universal AI alignment using RLHF is\nimpossible. We discuss policy implications for the governance of AI systems\nbuilt using RLHF: first, the need for mandating transparent voting rules to\nhold model builders accountable. Second, the need for model builders to focus\non developing AI agents that are narrowly aligned to specific user groups.",
            "author": [
                "Abhilash Mishra"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16048v1",
                "http://arxiv.org/pdf/2310.16048v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.CY",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16047v1",
            "title": "From Posterior Sampling to Meaningful Diversity in Image Restoration",
            "updated": "2023-10-24T17:58:54Z",
            "published": "2023-10-24T17:58:54Z",
            "summary": "Image restoration problems are typically ill-posed in the sense that each\ndegraded image can be restored in infinitely many valid ways. To accommodate\nthis, many works generate a diverse set of outputs by attempting to randomly\nsample from the posterior distribution of natural images given the degraded\ninput. Here we argue that this strategy is commonly of limited practical value\nbecause of the heavy tail of the posterior distribution. Consider for example\ninpainting a missing region of the sky in an image. Since there is a high\nprobability that the missing region contains no object but clouds, any set of\nsamples from the posterior would be entirely dominated by (practically\nidentical) completions of sky. However, arguably, presenting users with only\none clear sky completion, along with several alternative solutions such as\nairships, birds, and balloons, would better outline the set of possibilities.\nIn this paper, we initiate the study of meaningfully diverse image restoration.\nWe explore several post-processing approaches that can be combined with any\ndiverse image restoration method to yield semantically meaningful diversity.\nMoreover, we propose a practical approach for allowing diffusion based image\nrestoration methods to generate meaningfully diverse outputs, while incurring\nonly negligent computational overhead. We conduct extensive user studies to\nanalyze the proposed techniques, and find the strategy of reducing similarity\nbetween outputs to be significantly favorable over posterior sampling. Code and\nexamples are available in https://noa-cohen.github.io/MeaningfulDiversityInIR",
            "author": [
                "Noa Cohen",
                "Hila Manor",
                "Yuval Bahat",
                "Tomer Michaeli"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16047v1",
                "http://arxiv.org/pdf/2310.16047v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16046v1",
            "title": "A Unified, Scalable Framework for Neural Population Decoding",
            "updated": "2023-10-24T17:58:26Z",
            "published": "2023-10-24T17:58:26Z",
            "summary": "Our ability to use deep learning approaches to decipher neural activity would\nlikely benefit from greater scale, in terms of both model size and datasets.\nHowever, the integration of many neural recordings into one unified model is\nchallenging, as each recording contains the activity of different neurons from\ndifferent individual animals. In this paper, we introduce a training framework\nand architecture designed to model the population dynamics of neural activity\nacross diverse, large-scale neural recordings. Our method first tokenizes\nindividual spikes within the dataset to build an efficient representation of\nneural events that captures the fine temporal structure of neural activity. We\nthen employ cross-attention and a PerceiverIO backbone to further construct a\nlatent tokenization of neural population activities. Utilizing this\narchitecture and training framework, we construct a large-scale multi-session\nmodel trained on large datasets from seven nonhuman primates, spanning over 158\ndifferent sessions of recording from over 27,373 neural units and over 100\nhours of recordings. In a number of different tasks, we demonstrate that our\npretrained model can be rapidly adapted to new, unseen sessions with\nunspecified neuron correspondence, enabling few-shot performance with minimal\nlabels. This work presents a powerful new approach for building deep learning\ntools to analyze neural data and stakes out a clear path to training at scale.",
            "author": [
                "Mehdi Azabou",
                "Vinam Arora",
                "Venkataramana Ganesh",
                "Ximeng Mao",
                "Santosh Nachimuthu",
                "Michael J. Mendelson",
                "Blake Richards",
                "Matthew G. Perich",
                "Guillaume Lajoie",
                "Eva L. Dyer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16046v1",
                "http://arxiv.org/pdf/2310.16046v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16045v1",
            "title": "Woodpecker: Hallucination Correction for Multimodal Large Language\n  Models",
            "updated": "2023-10-24T17:58:07Z",
            "published": "2023-10-24T17:58:07Z",
            "summary": "Hallucination is a big shadow hanging over the rapidly evolving Multimodal\nLarge Language Models (MLLMs), referring to the phenomenon that the generated\ntext is inconsistent with the image content. In order to mitigate\nhallucinations, existing studies mainly resort to an instruction-tuning manner\nthat requires retraining the models with specific data. In this paper, we pave\na different way, introducing a training-free method named Woodpecker. Like a\nwoodpecker heals trees, it picks out and corrects hallucinations from the\ngenerated text. Concretely, Woodpecker consists of five stages: key concept\nextraction, question formulation, visual knowledge validation, visual claim\ngeneration, and hallucination correction. Implemented in a post-remedy manner,\nWoodpecker can easily serve different MLLMs, while being interpretable by\naccessing intermediate outputs of the five stages. We evaluate Woodpecker both\nquantitatively and qualitatively and show the huge potential of this new\nparadigm. On the POPE benchmark, our method obtains a 30.66%/24.33% improvement\nin accuracy over the baseline MiniGPT-4/mPLUG-Owl. The source code is released\nat https://github.com/BradyFU/Woodpecker.",
            "author": [
                "Shukang Yin",
                "Chaoyou Fu",
                "Sirui Zhao",
                "Tong Xu",
                "Hao Wang",
                "Dianbo Sui",
                "Yunhang Shen",
                "Ke Li",
                "Xing Sun",
                "Enhong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16045v1",
                "http://arxiv.org/pdf/2310.16045v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16042v2",
            "title": "WebWISE: Web Interface Control and Sequential Exploration with Large\n  Language Models",
            "updated": "2023-10-25T03:54:11Z",
            "published": "2023-10-24T17:57:03Z",
            "summary": "The paper investigates using a Large Language Model (LLM) to automatically\nperform web software tasks using click, scroll, and text input operations.\nPrevious approaches, such as reinforcement learning (RL) or imitation learning,\nare inefficient to train and task-specific. Our method uses filtered Document\nObject Model (DOM) elements as observations and performs tasks step-by-step,\nsequentially generating small programs based on the current observations. We\nuse in-context learning, either benefiting from a single manually provided\nexample, or an automatically generated example based on a successful zero-shot\ntrial. We evaluate the proposed method on the MiniWob++ benchmark. With only\none in-context example, our WebWISE method achieves similar or better\nperformance than other methods that require many demonstrations or trials.",
            "author": [
                "Heyi Tao",
                "Sethuraman T V",
                "Michal Shlapentokh-Rothman",
                "Derek Hoiem"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16042v2",
                "http://arxiv.org/pdf/2310.16042v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16035v1",
            "title": "What's Left? Concept Grounding with Logic-Enhanced Foundation Models",
            "updated": "2023-10-24T17:50:20Z",
            "published": "2023-10-24T17:50:20Z",
            "summary": "Recent works such as VisProg and ViperGPT have smartly composed foundation\nmodels for visual reasoning-using large language models (LLMs) to produce\nprograms that can be executed by pre-trained vision-language models. However,\nthey operate in limited domains, such as 2D images, not fully exploiting the\ngeneralization of language: abstract concepts like \"left\" can also be grounded\nin 3D, temporal, and action data, as in moving to your left. This limited\ngeneralization stems from these inference-only methods' inability to learn or\nadapt pre-trained models to a new domain. We propose the Logic-Enhanced\nFoundation Model (LEFT), a unified framework that learns to ground and reason\nwith concepts across domains with a differentiable, domain-independent,\nfirst-order logic-based program executor. LEFT has an LLM interpreter that\noutputs a program represented in a general, logic-based reasoning language,\nwhich is shared across all domains and tasks. LEFT's executor then executes the\nprogram with trainable domain-specific grounding modules. We show that LEFT\nflexibly learns concepts in four domains: 2D images, 3D scenes, human motions,\nand robotic manipulation. It exhibits strong reasoning ability in a wide\nvariety of tasks, including those that are complex and not seen during\ntraining, and can be easily applied to new domains.",
            "author": [
                "Joy Hsu",
                "Jiayuan Mao",
                "Joshua B. Tenenbaum",
                "Jiajun Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16035v1",
                "http://arxiv.org/pdf/2310.16035v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16029v1",
            "title": "Finetuning Offline World Models in the Real World",
            "updated": "2023-10-24T17:46:12Z",
            "published": "2023-10-24T17:46:12Z",
            "summary": "Reinforcement Learning (RL) is notoriously data-inefficient, which makes\ntraining on a real robot difficult. While model-based RL algorithms (world\nmodels) improve data-efficiency to some extent, they still require hours or\ndays of interaction to learn skills. Recently, offline RL has been proposed as\na framework for training RL policies on pre-existing datasets without any\nonline interaction. However, constraining an algorithm to a fixed dataset\ninduces a state-action distribution shift between training and inference, and\nlimits its applicability to new tasks. In this work, we seek to get the best of\nboth worlds: we consider the problem of pretraining a world model with offline\ndata collected on a real robot, and then finetuning the model on online data\ncollected by planning with the learned model. To mitigate extrapolation errors\nduring online interaction, we propose to regularize the planner at test-time by\nbalancing estimated returns and (epistemic) model uncertainty. We evaluate our\nmethod on a variety of visuo-motor control tasks in simulation and on a real\nrobot, and find that our method enables few-shot finetuning to seen and unseen\ntasks even when offline data is limited. Videos, code, and data are available\nat https://yunhaifeng.com/FOWM .",
            "author": [
                "Yunhai Feng",
                "Nicklas Hansen",
                "Ziyan Xiong",
                "Chandramouli Rajagopalan",
                "Xiaolong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16029v1",
                "http://arxiv.org/pdf/2310.16029v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16028v1",
            "title": "What Algorithms can Transformers Learn? A Study in Length Generalization",
            "updated": "2023-10-24T17:43:29Z",
            "published": "2023-10-24T17:43:29Z",
            "summary": "Large language models exhibit surprising emergent generalization properties,\nyet also struggle on many simple reasoning tasks such as arithmetic and parity.\nThis raises the question of if and when Transformer models can learn the true\nalgorithm for solving a task. We study the scope of Transformers' abilities in\nthe specific setting of length generalization on algorithmic tasks. Here, we\npropose a unifying framework to understand when and how Transformers can\nexhibit strong length generalization on a given task. Specifically, we leverage\nRASP (Weiss et al., 2021) -- a programming language designed for the\ncomputational model of a Transformer -- and introduce the RASP-Generalization\nConjecture: Transformers tend to length generalize on a task if the task can be\nsolved by a short RASP program which works for all input lengths. This simple\nconjecture remarkably captures most known instances of length generalization on\nalgorithmic tasks. Moreover, we leverage our insights to drastically improve\ngeneralization performance on traditionally hard tasks (such as parity and\naddition). On the theoretical side, we give a simple example where the\n\"min-degree-interpolator\" model of learning from Abbe et al. (2023) does not\ncorrectly predict Transformers' out-of-distribution behavior, but our\nconjecture does. Overall, our work provides a novel perspective on the\nmechanisms of compositional generalization and the algorithmic capabilities of\nTransformers.",
            "author": [
                "Hattie Zhou",
                "Arwen Bradley",
                "Etai Littwin",
                "Noam Razin",
                "Omid Saremi",
                "Josh Susskind",
                "Samy Bengio",
                "Preetum Nakkiran"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16028v1",
                "http://arxiv.org/pdf/2310.16028v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16027v1",
            "title": "TimewarpVAE: Simultaneous Time-Warping and Representation Learning of\n  Trajectories",
            "updated": "2023-10-24T17:43:16Z",
            "published": "2023-10-24T17:43:16Z",
            "summary": "Human demonstrations of trajectories are an important source of training data\nfor many machine learning problems. However, the difficulty of collecting human\ndemonstration data for complex tasks makes learning efficient representations\nof those trajectories challenging. For many problems, such as for handwriting\nor for quasistatic dexterous manipulation, the exact timings of the\ntrajectories should be factored from their spatial path characteristics. In\nthis work, we propose TimewarpVAE, a fully differentiable manifold-learning\nalgorithm that incorporates Dynamic Time Warping (DTW) to simultaneously learn\nboth timing variations and latent factors of spatial variation. We show how the\nTimewarpVAE algorithm learns appropriate time alignments and meaningful\nrepresentations of spatial variations in small handwriting and fork\nmanipulation datasets. Our results have lower spatial reconstruction test error\nthan baseline approaches and the learned low-dimensional representations can be\nused to efficiently generate semantically meaningful novel trajectories.",
            "author": [
                "Travers Rhodes",
                "Daniel D. Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16027v1",
                "http://arxiv.org/pdf/2310.16027v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16020v2",
            "title": "ConvBKI: Real-Time Probabilistic Semantic Mapping Network with\n  Quantifiable Uncertainty",
            "updated": "2023-10-26T12:37:00Z",
            "published": "2023-10-24T17:30:26Z",
            "summary": "In this paper, we develop a modular neural network for real-time semantic\nmapping in uncertain environments, which explicitly updates per-voxel\nprobabilistic distributions within a neural network layer. Our approach\ncombines the reliability of classical probabilistic algorithms with the\nperformance and efficiency of modern neural networks. Although robotic\nperception is often divided between modern differentiable methods and classical\nexplicit methods, a union of both is necessary for real-time and trustworthy\nperformance. We introduce a novel Convolutional Bayesian Kernel Inference\n(ConvBKI) layer which incorporates semantic segmentation predictions online\ninto a 3D map through a depthwise convolution layer by leveraging conjugate\npriors. We compare ConvBKI against state-of-the-art deep learning approaches\nand probabilistic algorithms for mapping to evaluate reliability and\nperformance. We also create a Robot Operating System (ROS) package of ConvBKI\nand test it on real-world perceptually challenging off-road driving data.",
            "author": [
                "Joey Wilson",
                "Yuewei Fu",
                "Joshua Friesen",
                "Parker Ewen",
                "Andrew Capodieci",
                "Paramsothy Jayakumar",
                "Kira Barton",
                "Maani Ghaffari"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16020v2",
                "http://arxiv.org/pdf/2310.16020v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16015v1",
            "title": "Physically Explainable Deep Learning for Convective Initiation\n  Nowcasting Using GOES-16 Satellite Observations",
            "updated": "2023-10-24T17:18:44Z",
            "published": "2023-10-24T17:18:44Z",
            "summary": "Convection initiation (CI) nowcasting remains a challenging problem for both\nnumerical weather prediction models and existing nowcasting algorithms. In this\nstudy, object-based probabilistic deep learning models are developed to predict\nCI based on multichannel infrared GOES-R satellite observations. The data come\nfrom patches surrounding potential CI events identified in Multi-Radar\nMulti-Sensor Doppler weather radar products over the Great Plains region from\nJune and July 2020 and June 2021. An objective radar-based approach is used to\nidentify these events. The deep learning models significantly outperform the\nclassical logistic model at lead times up to 1 hour, especially on the false\nalarm ratio. Through case studies, the deep learning model exhibits the\ndependence on the characteristics of clouds and moisture at multiple levels.\nModel explanation further reveals the model's decision-making process with\ndifferent baselines. The explanation results highlight the importance of\nmoisture and cloud features at different levels depending on the choice of\nbaseline. Our study demonstrates the advantage of using different baselines in\nfurther understanding model behavior and gaining scientific insights.",
            "author": [
                "Da Fan",
                "Steven J. Greybush",
                "David John Gagne II",
                "Eugene E. Clothiaux"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16015v1",
                "http://arxiv.org/pdf/2310.16015v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16076v1",
            "title": "Practical Computational Power of Linear Transformers and Their Recurrent\n  and Self-Referential Extensions",
            "updated": "2023-10-24T17:17:01Z",
            "published": "2023-10-24T17:17:01Z",
            "summary": "Recent studies of the computational power of recurrent neural networks (RNNs)\nreveal a hierarchy of RNN architectures, given real-time and finite-precision\nassumptions. Here we study auto-regressive Transformers with linearised\nattention, a.k.a. linear Transformers (LTs) or Fast Weight Programmers (FWPs).\nLTs are special in the sense that they are equivalent to RNN-like sequence\nprocessors with a fixed-size state, while they can also be expressed as the\nnow-popular self-attention networks. We show that many well-known results for\nthe standard Transformer directly transfer to LTs/FWPs. Our formal language\nrecognition experiments demonstrate how recently proposed FWP extensions such\nas recurrent FWPs and self-referential weight matrices successfully overcome\ncertain limitations of the LT, e.g., allowing for generalisation on the parity\nproblem. Our code is public.",
            "author": [
                "Kazuki Irie",
                "R\u00f3bert Csord\u00e1s",
                "J\u00fcrgen Schmidhuber"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16076v1",
                "http://arxiv.org/pdf/2310.16076v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.17817v1",
            "title": "Bayesian imaging inverse problem with SA-Roundtrip prior via HMC-pCN\n  sampler",
            "updated": "2023-10-24T17:16:45Z",
            "published": "2023-10-24T17:16:45Z",
            "summary": "Bayesian inference with deep generative prior has received considerable\ninterest for solving imaging inverse problems in many scientific and\nengineering fields. The selection of the prior distribution is learned from,\nand therefore an important representation learning of, available prior\nmeasurements. The SA-Roundtrip, a novel deep generative prior, is introduced to\nenable controlled sampling generation and identify the data's intrinsic\ndimension. This prior incorporates a self-attention structure within a\nbidirectional generative adversarial network. Subsequently, Bayesian inference\nis applied to the posterior distribution in the low-dimensional latent space\nusing the Hamiltonian Monte Carlo with preconditioned Crank-Nicolson (HMC-pCN)\nalgorithm, which is proven to be ergodic under specific conditions. Experiments\nconducted on computed tomography (CT) reconstruction with the MNIST and\nTomoPhantom datasets reveal that the proposed method outperforms\nstate-of-the-art comparisons, consistently yielding a robust and superior point\nestimator along with precise uncertainty quantification.",
            "author": [
                "Jiayu Qian",
                "Yuanyuan Liu",
                "Jingya Yang",
                "Qingping Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.17817v1",
                "http://arxiv.org/pdf/2310.17817v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16014v1",
            "title": "Human-in-the-Loop Task and Motion Planning for Imitation Learning",
            "updated": "2023-10-24T17:15:16Z",
            "published": "2023-10-24T17:15:16Z",
            "summary": "Imitation learning from human demonstrations can teach robots complex\nmanipulation skills, but is time-consuming and labor intensive. In contrast,\nTask and Motion Planning (TAMP) systems are automated and excel at solving\nlong-horizon tasks, but they are difficult to apply to contact-rich tasks. In\nthis paper, we present Human-in-the-Loop Task and Motion Planning (HITL-TAMP),\na novel system that leverages the benefits of both approaches. The system\nemploys a TAMP-gated control mechanism, which selectively gives and takes\ncontrol to and from a human teleoperator. This enables the human teleoperator\nto manage a fleet of robots, maximizing data collection efficiency. The\ncollected human data is then combined with an imitation learning framework to\ntrain a TAMP-gated policy, leading to superior performance compared to training\non full task demonstrations. We compared HITL-TAMP to a conventional\nteleoperation system -- users gathered more than 3x the number of demos given\nthe same time budget. Furthermore, proficient agents (75\\%+ success) could be\ntrained from just 10 minutes of non-expert teleoperation data. Finally, we\ncollected 2.1K demos with HITL-TAMP across 12 contact-rich, long-horizon tasks\nand show that the system often produces near-perfect agents. Videos and\nadditional results at https://hitltamp.github.io .",
            "author": [
                "Ajay Mandlekar",
                "Caelan Garrett",
                "Danfei Xu",
                "Dieter Fox"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16014v1",
                "http://arxiv.org/pdf/2310.16014v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16009v1",
            "title": "Spatio-temporal reconstruction of drop impact dynamics by means of\n  color-coded glare points and deep learning",
            "updated": "2023-10-24T17:03:42Z",
            "published": "2023-10-24T17:03:42Z",
            "summary": "The present work introduces a deep learning approach for the\nthree-dimensional reconstruction of the spatio-temporal dynamics of the\ngas-liquid interface in two-phase flows on the basis of monocular images\nobtained via optical measurement techniques. The dynamics of liquid droplets\nimpacting onto structured solid substrates are captured through high-speed\nimaging in an extended shadowgraphy setup with additional reflective glare\npoints from lateral light sources that encode further three-dimensional\ninformation of the gas-liquid interface in the images. A neural network is\nlearned for the physically correct reconstruction of the droplet dynamics on a\nlabelled dataset generated by synthetic image rendering on the basis of\ngas-liquid interface shapes obtained from direct numerical simulation. The\nemployment of synthetic image rendering allows for the efficient generation of\ntraining data and circumvents the introduction of errors resulting from the\ninherent discrepancy of the droplet shapes between experiment and simulation.\nThe accurate reconstruction of the gas-liquid interface during droplet\nimpingement on the basis of images obtained in the experiment demonstrates the\npracticality of the presented approach based on neural networks and synthetic\ntraining data generation. The introduction of glare points from lateral light\nsources in the experiments is shown to improve the reconstruction accuracy,\nwhich indicates that the neural network learns to leverage the additional\nthree-dimensional information encoded in the images for a more accurate depth\nestimation. Furthermore, the physically reasonable reconstruction of unknown\ngas-liquid interface shapes indicates that the neural network learned a\nversatile model of the involved two-phase flow phenomena during droplet\nimpingement.",
            "author": [
                "Maximilian Dreisbach",
                "Jochen Kriegseis",
                "Alexander Stroh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16009v1",
                "http://arxiv.org/pdf/2310.16009v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16006v1",
            "title": "Machine-learning the phase diagram of a strongly-interacting Fermi gas",
            "updated": "2023-10-24T17:00:05Z",
            "published": "2023-10-24T17:00:05Z",
            "summary": "We determine the phase diagram of strongly correlated fermions in the\ncrossover from Bose-Einstein condensates of molecules (BEC) to Cooper pairs of\nfermions (BCS) utilizing an artificial neural network. By applying advanced\nimage recognition techniques to the momentum distribution of the fermions, a\nquantity which has been widely considered as featureless for providing\ninformation about the condensed state, we measure the critical temperature and\nshow that it exhibits a maximum on the bosonic side of the crossover.\nAdditionally, we back-analyze the trained neural network and demonstrate that\nit interprets physically relevant quantities.",
            "author": [
                "M. Link",
                "K. Gao",
                "A. Kell",
                "M. Breyer",
                "D. Eberz",
                "B. Rauf",
                "M. K\u00f6hl"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16006v1",
                "http://arxiv.org/pdf/2310.16006v1"
            ],
            "primary_category": "cond-mat.quant-gas",
            "category": [
                "cond-mat.quant-gas"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16005v1",
            "title": "MLFMF: Data Sets for Machine Learning for Mathematical Formalization",
            "updated": "2023-10-24T17:00:00Z",
            "published": "2023-10-24T17:00:00Z",
            "summary": "We introduce MLFMF, a collection of data sets for benchmarking recommendation\nsystems used to support formalization of mathematics with proof assistants.\nThese systems help humans identify which previous entries (theorems,\nconstructions, datatypes, and postulates) are relevant in proving a new theorem\nor carrying out a new construction. Each data set is derived from a library of\nformalized mathematics written in proof assistants Agda or Lean. The collection\nincludes the largest Lean~4 library Mathlib, and some of the largest Agda\nlibraries: the standard library, the library of univalent mathematics\nAgda-unimath, and the TypeTopology library. Each data set represents the\ncorresponding library in two ways: as a heterogeneous network, and as a list of\ns-expressions representing the syntax trees of all the entries in the library.\nThe network contains the (modular) structure of the library and the references\nbetween entries, while the s-expressions give complete and easily parsed\ninformation about every entry. We report baseline results using standard graph\nand word embeddings, tree ensembles, and instance-based learning algorithms.\nThe MLFMF data sets provide solid benchmarking support for further\ninvestigation of the numerous machine learning approaches to formalized\nmathematics. The methodology used to extract the networks and the s-expressions\nreadily applies to other libraries, and is applicable to other proof\nassistants. With more than $250\\,000$ entries in total, this is currently the\nlargest collection of formalized mathematical knowledge in machine learnable\nformat.",
            "author": [
                "Andrej Bauer",
                "Matej Petkovi\u0107",
                "Ljup\u010do Todorovski"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16005v1",
                "http://arxiv.org/pdf/2310.16005v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15999v1",
            "title": "Transitivity Recovering Decompositions: Interpretable and Robust\n  Fine-Grained Relationships",
            "updated": "2023-10-24T16:48:56Z",
            "published": "2023-10-24T16:48:56Z",
            "summary": "Recent advances in fine-grained representation learning leverage\nlocal-to-global (emergent) relationships for achieving state-of-the-art\nresults. The relational representations relied upon by such methods, however,\nare abstract. We aim to deconstruct this abstraction by expressing them as\ninterpretable graphs over image views. We begin by theoretically showing that\nabstract relational representations are nothing but a way of recovering\ntransitive relationships among local views. Based on this, we design\nTransitivity Recovering Decompositions (TRD), a graph-space search algorithm\nthat identifies interpretable equivalents of abstract emergent relationships at\nboth instance and class levels, and with no post-hoc computations. We\nadditionally show that TRD is provably robust to noisy views, with empirical\nevidence also supporting this finding. The latter allows TRD to perform at par\nor even better than the state-of-the-art, while being fully interpretable.\nImplementation is available at https://github.com/abhrac/trd.",
            "author": [
                "Abhra Chaudhuri",
                "Massimiliano Mancini",
                "Zeynep Akata",
                "Anjan Dutta"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15999v1",
                "http://arxiv.org/pdf/2310.15999v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15994v1",
            "title": "Training models using forces computed by stochastic electronic structure\n  methods",
            "updated": "2023-10-24T16:40:43Z",
            "published": "2023-10-24T16:40:43Z",
            "summary": "Quantum Monte Carlo (QMC) can play a very important role in generating\naccurate data needed for constructing potential energy surfaces. We argue that\nQMC has advantages in terms of a smaller systematic bias and an ability to\ncover phase space more completely. The stochastic noise can ease the training\nof the machine learning model. We discuss how stochastic errors affect the\ngeneration of effective models by analyzing the errors within a linear least\nsquares procedure, finding that there is an advantage to having many relatively\nimprecise data points for constructing models. We then analyze the effect of\nnoise on a model of many-body silicon finding that noise in some situations\nimproves the resulting model. We then study the effect of QMC noise on two\nmachine learning models of dense hydrogen used in a recent study of its phase\ndiagram. The noise enable us to estimate the errors in the model. We conclude\nwith a discussion of future research problems.",
            "author": [
                "David M. Ceperley",
                "Scott Jensen",
                "Yubo Yang",
                "Hongwei Niu",
                "Carlo Pierleoni",
                "Markus Holzmann"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15994v1",
                "http://arxiv.org/pdf/2310.15994v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15991v1",
            "title": "White-box Compiler Fuzzing Empowered by Large Language Models",
            "updated": "2023-10-24T16:39:06Z",
            "published": "2023-10-24T16:39:06Z",
            "summary": "Compiler correctness is crucial, as miscompilation falsifying the program\nbehaviors can lead to serious consequences. In the literature, fuzzing has been\nextensively studied to uncover compiler defects. However, compiler fuzzing\nremains challenging: Existing arts focus on black- and grey-box fuzzing, which\ngenerates tests without sufficient understanding of internal compiler\nbehaviors. As such, they often fail to construct programs to exercise\nconditions of intricate optimizations. Meanwhile, traditional white-box\ntechniques are computationally inapplicable to the giant codebase of compilers.\nRecent advances demonstrate that Large Language Models (LLMs) excel in code\ngeneration/understanding tasks and have achieved state-of-the-art performance\nin black-box fuzzing. Nonetheless, prompting LLMs with compiler source-code\ninformation remains a missing piece of research in compiler testing.\n  To this end, we propose WhiteFox, the first white-box compiler fuzzer using\nLLMs with source-code information to test compiler optimization. WhiteFox\nadopts a dual-model framework: (i) an analysis LLM examines the low-level\noptimization source code and produces requirements on the high-level test\nprograms that can trigger the optimization; (ii) a generation LLM produces test\nprograms based on the summarized requirements. Additionally,\noptimization-triggering tests are used as feedback to further enhance the test\ngeneration on the fly. Our evaluation on four popular compilers shows that\nWhiteFox can generate high-quality tests to exercise deep optimizations\nrequiring intricate conditions, practicing up to 80 more optimizations than\nstate-of-the-art fuzzers. To date, WhiteFox has found in total 96 bugs, with 80\nconfirmed as previously unknown and 51 already fixed. Beyond compiler testing,\nWhiteFox can also be adapted for white-box fuzzing of other complex, real-world\nsoftware systems in general.",
            "author": [
                "Chenyuan Yang",
                "Yinlin Deng",
                "Runyu Lu",
                "Jiayi Yao",
                "Jiawei Liu",
                "Reyhaneh Jabbarvand",
                "Lingming Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15991v1",
                "http://arxiv.org/pdf/2310.15991v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.LG",
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15989v1",
            "title": "Detecting the phase transition in a strongly-interacting Fermi gas by\n  unsupervised machine learning",
            "updated": "2023-10-24T16:38:09Z",
            "published": "2023-10-24T16:38:09Z",
            "summary": "We study the critical temperature of the superfluid phase transition of\nstrongly-interacting fermions in the crossover regime between a\nBardeen-Cooper-Schrieffer (BCS) superconductor and a Bose-Einstein condensate\n(BEC) of dimers. To this end, we employ the technique of unsupervised machine\nlearning using an autoencoder neural network which we directly apply to\ntime-of-flight images of the fermions. We extract the critical temperature of\nthe phase transition from trend changes in the data distribution revealed in\nthe latent space of the autoencoder bottleneck.",
            "author": [
                "D. Eberz",
                "M. Link",
                "A. Kell",
                "M. Breyer",
                "K. Gao",
                "M. K\u00f6hl"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15989v1",
                "http://arxiv.org/pdf/2310.15989v1"
            ],
            "primary_category": "cond-mat.quant-gas",
            "category": [
                "cond-mat.quant-gas"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15987v1",
            "title": "Dissecting In-Context Learning of Translations in GPTs",
            "updated": "2023-10-24T16:37:18Z",
            "published": "2023-10-24T16:37:18Z",
            "summary": "Most of the recent work in leveraging Large Language Models (LLMs) such as\nGPT-3 for Machine Translation (MT) has focused on selecting the few-shot\nsamples for prompting. In this work, we try to better understand the role of\ndemonstration attributes for the in-context learning of translations through\nperturbations of high-quality, in-domain demonstrations. We find that\nasymmetric perturbation of the source-target mappings yield vastly different\nresults. We show that the perturbation of the source side has surprisingly\nlittle impact, while target perturbation can drastically reduce translation\nquality, suggesting that it is the output text distribution that provides the\nmost important learning signal during in-context learning of translations. We\npropose a method named Zero-Shot-Context to add this signal automatically in\nZero-Shot prompting. We demonstrate that it improves upon the zero-shot\ntranslation performance of GPT-3, even making it competitive with few-shot\nprompted translations.",
            "author": [
                "Vikas Raunak",
                "Hany Hassan Awadalla",
                "Arul Menezes"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15987v1",
                "http://arxiv.org/pdf/2310.15987v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15985v1",
            "title": "Vision-Language Pseudo-Labels for Single-Positive Multi-Label Learning",
            "updated": "2023-10-24T16:36:51Z",
            "published": "2023-10-24T16:36:51Z",
            "summary": "This paper presents a novel approach to Single-Positive Multi-label Learning.\nIn general multi-label learning, a model learns to predict multiple labels or\ncategories for a single input image. This is in contrast with standard\nmulti-class image classification, where the task is predicting a single label\nfrom many possible labels for an image. Single-Positive Multi-label Learning\n(SPML) specifically considers learning to predict multiple labels when there is\nonly a single annotation per image in the training data. Multi-label learning\nis in many ways a more realistic task than single-label learning as real-world\ndata often involves instances belonging to multiple categories simultaneously;\nhowever, most common computer vision datasets predominantly contain single\nlabels due to the inherent complexity and cost of collecting multiple high\nquality annotations for each instance. We propose a novel approach called\nVision-Language Pseudo-Labeling (VLPL), which uses a vision-language model to\nsuggest strong positive and negative pseudo-labels, and outperforms the current\nSOTA methods by 5.5% on Pascal VOC, 18.4% on MS-COCO, 15.2% on NUS-WIDE, and\n8.4% on CUB-Birds. Our code and data are available at\nhttps://github.com/mvrl/VLPL.",
            "author": [
                "Xin Xing",
                "Zhexiao Xiong",
                "Abby Stylianou",
                "Srikumar Sastry",
                "Liyu Gong",
                "Nathan Jacobs"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15985v1",
                "http://arxiv.org/pdf/2310.15985v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15978v1",
            "title": "Graph Deep Learning for Time Series Forecasting",
            "updated": "2023-10-24T16:26:38Z",
            "published": "2023-10-24T16:26:38Z",
            "summary": "Graph-based deep learning methods have become popular tools to process\ncollections of correlated time series. Differently from traditional\nmultivariate forecasting methods, neural graph-based predictors take advantage\nof pairwise relationships by conditioning forecasts on a (possibly dynamic)\ngraph spanning the time series collection. The conditioning can take the form\nof an architectural inductive bias on the neural forecasting architecture,\nresulting in a family of deep learning models called spatiotemporal graph\nneural networks. Such relational inductive biases enable the training of global\nforecasting models on large time-series collections, while at the same time\nlocalizing predictions w.r.t. each element in the set (i.e., graph nodes) by\naccounting for local correlations among them (i.e., graph edges). Indeed,\nrecent theoretical and practical advances in graph neural networks and deep\nlearning for time series forecasting make the adoption of such processing\nframeworks appealing and timely. However, most of the studies in the literature\nfocus on proposing variations of existing neural architectures by taking\nadvantage of modern deep learning practices, while foundational and\nmethodological aspects have not been subject to systematic investigation. To\nfill the gap, this paper aims to introduce a comprehensive methodological\nframework that formalizes the forecasting problem and provides design\nprinciples for graph-based predictive models and methods to assess their\nperformance. At the same time, together with an overview of the field, we\nprovide design guidelines, recommendations, and best practices, as well as an\nin-depth discussion of open challenges and future research directions.",
            "author": [
                "Andrea Cini",
                "Ivan Marisca",
                "Daniele Zambon",
                "Cesare Alippi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15978v1",
                "http://arxiv.org/pdf/2310.15978v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15975v2",
            "title": "Data-driven Traffic Simulation: A Comprehensive Review",
            "updated": "2023-11-23T07:15:23Z",
            "published": "2023-10-24T16:25:13Z",
            "summary": "Autonomous vehicles (AVs) have the potential to significantly revolutionize\nsociety by providing a secure and efficient mode of transportation. Recent\nyears have witnessed notable advancements in autonomous driving perception and\nprediction, but the challenge of validating the performance of AVs remains\nlargely unresolved. Data-driven microscopic traffic simulation has become an\nimportant tool for autonomous driving testing due to 1) availability of\nhigh-fidelity traffic data; 2) its advantages of enabling large-scale testing\nand scenario reproducibility; and 3) its potential in reactive and realistic\ntraffic simulation. However, a comprehensive review of this topic is currently\nlacking. This paper aims to fill this gap by summarizing relevant studies. The\nprimary objective of this paper is to review current research efforts and\nprovide a futuristic perspective that will benefit future developments in the\nfield. It introduces the general issues of data-driven traffic simulation and\noutlines key concepts and terms. After overviewing traffic simulation, various\ndatasets and evaluation metrics commonly used are reviewed. The paper then\noffers a comprehensive evaluation of imitation learning, reinforcement\nlearning, deep generative and deep learning methods, summarizing each and\nanalyzing their advantages and disadvantages in detail. Moreover, it evaluates\nthe state-of-the-art, existing challenges, and future research directions.",
            "author": [
                "Di Chen",
                "Meixin Zhu",
                "Hao Yang",
                "Xuesong Wang",
                "Yinhai Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15975v2",
                "http://arxiv.org/pdf/2310.15975v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15976v1",
            "title": "Convergence of Sign-based Random Reshuffling Algorithms for Nonconvex\n  Optimization",
            "updated": "2023-10-24T16:25:13Z",
            "published": "2023-10-24T16:25:13Z",
            "summary": "signSGD is popular in nonconvex optimization due to its communication\nefficiency. Yet, existing analyses of signSGD rely on assuming that data are\nsampled with replacement in each iteration, contradicting the practical\nimplementation where data are randomly reshuffled and sequentially fed into the\nalgorithm. We bridge this gap by proving the first convergence result of\nsignSGD with random reshuffling (SignRR) for nonconvex optimization. Given the\ndataset size $n$, the number of epochs of data passes $T$, and the variance\nbound of a stochastic gradient $\\sigma^2$, we show that SignRR has the same\nconvergence rate $O(\\log(nT)/\\sqrt{nT} + \\|\\sigma\\|_1)$ as signSGD\n\\citep{bernstein2018signsgd}. We then present SignRVR and SignRVM, which\nleverage variance-reduced gradients and momentum updates respectively, both\nconverging at $O(\\log(nT)/\\sqrt{nT})$. In contrast with the analysis of\nsignSGD, our results do not require an extremely large batch size in each\niteration to be of the same order as the total number of iterations\n\\citep{bernstein2018signsgd} or the signs of stochastic and true gradients\nmatch element-wise with a minimum probability of 1/2\n\\citep{safaryan2021stochastic}. We also extend our algorithms to cases where\ndata are distributed across different machines, yielding dist-SignRVR and\ndist-SignRVM, both converging at $O(\\log(n_0T)/\\sqrt{n_0T})$, where $n_0$ is\nthe dataset size of a single machine. We back up our theoretical findings\nthrough experiments on simulated and real-world problems, verifying that\nrandomly reshuffled sign methods match or surpass existing baselines.",
            "author": [
                "Zhen Qin",
                "Zhishuai Liu",
                "Pan Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15976v1",
                "http://arxiv.org/pdf/2310.15976v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15974v1",
            "title": "Minimax Forward and Backward Learning of Evolving Tasks with Performance\n  Guarantees",
            "updated": "2023-10-24T16:21:41Z",
            "published": "2023-10-24T16:21:41Z",
            "summary": "For a sequence of classification tasks that arrive over time, it is common\nthat tasks are evolving in the sense that consecutive tasks often have a higher\nsimilarity. The incremental learning of a growing sequence of tasks holds\npromise to enable accurate classification even with few samples per task by\nleveraging information from all the tasks in the sequence (forward and backward\nlearning). However, existing techniques developed for continual learning and\nconcept drift adaptation are either designed for tasks with time-independent\nsimilarities or only aim to learn the last task in the sequence. This paper\npresents incremental minimax risk classifiers (IMRCs) that effectively exploit\nforward and backward learning and account for evolving tasks. In addition, we\nanalytically characterize the performance improvement provided by forward and\nbackward learning in terms of the tasks' expected quadratic change and the\nnumber of tasks. The experimental evaluation shows that IMRCs can result in a\nsignificant performance improvement, especially for reduced sample sizes.",
            "author": [
                "Ver\u00f3nica \u00c1lvarez",
                "Santiago Mazuelas",
                "Jose A. Lozano"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15974v1",
                "http://arxiv.org/pdf/2310.15974v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15970v3",
            "title": "Accented Speech Recognition With Accent-specific Codebooks",
            "updated": "2023-10-27T02:54:29Z",
            "published": "2023-10-24T16:10:58Z",
            "summary": "Speech accents pose a significant challenge to state-of-the-art automatic\nspeech recognition (ASR) systems. Degradation in performance across\nunderrepresented accents is a severe deterrent to the inclusive adoption of\nASR. In this work, we propose a novel accent adaptation approach for end-to-end\nASR systems using cross-attention with a trainable set of codebooks. These\nlearnable codebooks capture accent-specific information and are integrated\nwithin the ASR encoder layers. The model is trained on accented English speech,\nwhile the test data also contained accents which were not seen during training.\nOn the Mozilla Common Voice multi-accented dataset, we show that our proposed\napproach yields significant performance gains not only on the seen English\naccents (up to $37\\%$ relative improvement in word error rate) but also on the\nunseen accents (up to $5\\%$ relative improvement in WER). Further, we\nillustrate benefits for a zero-shot transfer setup on the L2Artic dataset. We\nalso compare the performance with other approaches based on accent adversarial\ntraining.",
            "author": [
                "Darshan Prabhu",
                "Preethi Jyothi",
                "Sriram Ganapathy",
                "Vinit Unni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15970v3",
                "http://arxiv.org/pdf/2310.15970v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15966v1",
            "title": "Constructing and Machine Learning Calabi-Yau Five-folds",
            "updated": "2023-10-24T16:07:08Z",
            "published": "2023-10-24T16:07:08Z",
            "summary": "We construct all possible complete intersection Calabi-Yau five-folds in a\nproduct of four or less complex projective spaces, with up to four constraints.\nWe obtain $27068$ spaces, which are not related by permutations of rows and\ncolumns of the configuration matrix, and determine the Euler number for all of\nthem. Excluding the $3909$ product manifolds among those, we calculate the\ncohomological data for $12433$ cases, i.e. $53.7 \\%$ of the non-product spaces,\nobtaining $2375$ different Hodge diamonds. The dataset containing all the above\ninformation is available at\nhttps://www.dropbox.com/scl/fo/z7ii5idt6qxu36e0b8azq/h?rlkey=0qfhx3tykytduobpld510gsfy&dl=0\n. The distributions of the invariants are presented, and a comparison with the\nlower-dimensional analogues is discussed. Supervised machine learning is\nperformed on the cohomological data, via classifier and regressor (both fully\nconnected and convolutional) neural networks. We find that $h^{1,1}$ can be\nlearnt very efficiently, with very high $R^2$ score and an accuracy of $96\\%$,\ni.e. $96 \\%$ of the predictions exactly match the correct values. For\n$h^{1,4},h^{2,3}, \\eta$, we also find very high $R^2$ scores, but the accuracy\nis lower, due to the large ranges of possible values.",
            "author": [
                "R. Alawadhi",
                "D. Angella",
                "A. Leonardo",
                "T. Schettini Gherardini"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15966v1",
                "http://arxiv.org/pdf/2310.15966v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "cs.LG",
                "math.AG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15961v1",
            "title": "Mixture of Tokens: Efficient LLMs through Cross-Example Aggregation",
            "updated": "2023-10-24T16:03:57Z",
            "published": "2023-10-24T16:03:57Z",
            "summary": "Despite the promise of Mixture of Experts (MoE) models in increasing\nparameter counts of Transformer models while maintaining training and inference\ncosts, their application carries notable drawbacks. The key strategy of these\nmodels is to, for each processed token, activate at most a few experts -\nsubsets of an extensive feed-forward layer. But this approach is not without\nits challenges. The operation of matching experts and tokens is discrete, which\nmakes MoE models prone to issues like training instability and uneven expert\nutilization. Existing techniques designed to address these concerns, such as\nauxiliary losses or balance-aware matching, result either in lower model\nperformance or are more difficult to train. In response to these issues, we\npropose Mixture of Tokens, a fully-differentiable model that retains the\nbenefits of MoE architectures while avoiding the aforementioned difficulties.\nRather than routing tokens to experts, this approach mixes tokens from\ndifferent examples prior to feeding them to experts, enabling the model to\nlearn from all token-expert combinations. Importantly, this mixing can be\ndisabled to avoid mixing of different sequences during inference. Crucially,\nthis method is fully compatible with both masked and causal Large Language\nModel training and inference.",
            "author": [
                "Szymon Antoniak",
                "Sebastian Jaszczur",
                "Micha\u0142 Krutul",
                "Maciej Pi\u00f3ro",
                "Jakub Krajewski",
                "Jan Ludziejewski",
                "Tomasz Odrzyg\u00f3\u017ad\u017a",
                "Marek Cygan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15961v1",
                "http://arxiv.org/pdf/2310.15961v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02088v1",
            "title": "Combining Deep Learning on Order Books with Reinforcement Learning for\n  Profitable Trading",
            "updated": "2023-10-24T15:58:58Z",
            "published": "2023-10-24T15:58:58Z",
            "summary": "High-frequency trading is prevalent, where automated decisions must be made\nquickly to take advantage of price imbalances and patterns in price action that\nforecast near-future movements. While many algorithms have been explored and\ntested, analytical methods fail to harness the whole nature of the market\nenvironment by focusing on a limited domain. With the evergrowing machine\nlearning field, many large-scale end-to-end studies on raw data have been\nsuccessfully employed to increase the domain scope for profitable trading but\nare very difficult to replicate. Combining deep learning on the order books\nwith reinforcement learning is one way of breaking down large-scale end-to-end\nlearning into more manageable and lightweight components for reproducibility,\nsuitable for retail trading.\n  The following work focuses on forecasting returns across multiple horizons\nusing order flow imbalance and training three temporal-difference learning\nmodels for five financial instruments to provide trading signals. The\ninstruments used are two foreign exchange pairs (GBPUSD and EURUSD), two\nindices (DE40 and FTSE100), and one commodity (XAUUSD). The performances of\nthese 15 agents are evaluated through backtesting simulation, and successful\nmodels proceed through to forward testing on a retail trading platform. The\nresults prove potential but require further minimal modifications for\nconsistently profitable trading to fully handle retail trading costs, slippage,\nand spread fluctuation.",
            "author": [
                "Koti S. Jaddu",
                "Paul A. Bilokon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02088v1",
                "http://arxiv.org/pdf/2311.02088v1"
            ],
            "primary_category": "q-fin.CP",
            "category": [
                "q-fin.CP",
                "cs.AI",
                "cs.LG",
                "q-fin.PM",
                "q-fin.TR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15955v1",
            "title": "Decoupled DETR: Spatially Disentangling Localization and Classification\n  for Improved End-to-End Object Detection",
            "updated": "2023-10-24T15:54:11Z",
            "published": "2023-10-24T15:54:11Z",
            "summary": "The introduction of DETR represents a new paradigm for object detection.\nHowever, its decoder conducts classification and box localization using shared\nqueries and cross-attention layers, leading to suboptimal results. We observe\nthat different regions of interest in the visual feature map are suitable for\nperforming query classification and box localization tasks, even for the same\nobject. Salient regions provide vital information for classification, while the\nboundaries around them are more favorable for box regression. Unfortunately,\nsuch spatial misalignment between these two tasks greatly hinders DETR's\ntraining. Therefore, in this work, we focus on decoupling localization and\nclassification tasks in DETR. To achieve this, we introduce a new design scheme\ncalled spatially decoupled DETR (SD-DETR), which includes a task-aware query\ngeneration module and a disentangled feature learning process. We elaborately\ndesign the task-aware query initialization process and divide the\ncross-attention block in the decoder to allow the task-aware queries to match\ndifferent visual regions. Meanwhile, we also observe that the prediction\nmisalignment problem for high classification confidence and precise\nlocalization exists, so we propose an alignment loss to further guide the\nspatially decoupled DETR training. Through extensive experiments, we\ndemonstrate that our approach achieves a significant improvement in MSCOCO\ndatasets compared to previous work. For instance, we improve the performance of\nConditional DETR by 4.5 AP. By spatially disentangling the two tasks, our\nmethod overcomes the misalignment problem and greatly improves the performance\nof DETR for object detection.",
            "author": [
                "Manyuan Zhang",
                "Guanglu Song",
                "Yu Liu",
                "Hongsheng Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15955v1",
                "http://arxiv.org/pdf/2310.15955v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15952v3",
            "title": "Improving Robustness and Reliability in Medical Image Classification\n  with Latent-Guided Diffusion and Nested-Ensembles",
            "updated": "2023-11-10T09:52:03Z",
            "published": "2023-10-24T15:53:07Z",
            "summary": "While deep learning models have achieved remarkable success across a range of\nmedical image analysis tasks, deployment of these models in real clinical\ncontexts requires that they be robust to variability in the acquired images.\nWhile many methods apply predefined transformations to augment the training\ndata to enhance test-time robustness, these transformations may not ensure the\nmodel's robustness to the diverse variability seen in patient images. In this\npaper, we introduce a novel three-stage approach based on transformers coupled\nwith conditional diffusion models, with the goal of improving model robustness\nto the kinds of imaging variability commonly encountered in practice without\nthe need for pre-determined data augmentation strategies. To this end, multiple\nimage encoders first learn hierarchical feature representations to build\ndiscriminative latent spaces. Next, a reverse diffusion process, guided by the\nlatent code, acts on an informative prior and proposes prediction candidates in\na generative manner. Finally, several prediction candidates are aggregated in a\nbi-level aggregation protocol to produce the final output. Through extensive\nexperiments on medical imaging benchmark datasets, we show that our method\nimproves upon state-of-the-art methods in terms of robustness and confidence\ncalibration. Additionally, we introduce a strategy to quantify the prediction\nuncertainty at the instance level, increasing their trustworthiness to\nclinicians using them in clinical practice.",
            "author": [
                "Xing Shen",
                "Hengguan Huang",
                "Brennan Nichyporuk",
                "Tal Arbel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15952v3",
                "http://arxiv.org/pdf/2310.15952v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15951v1",
            "title": "Weighted Distance Nearest Neighbor Condensing",
            "updated": "2023-10-24T15:51:20Z",
            "published": "2023-10-24T15:51:20Z",
            "summary": "The problem of nearest neighbor condensing has enjoyed a long history of\nstudy, both in its theoretical and practical aspects. In this paper, we\nintroduce the problem of weighted distance nearest neighbor condensing, where\none assigns weights to each point of the condensed set, and then new points are\nlabeled based on their weighted distance nearest neighbor in the condensed set.\n  We study the theoretical properties of this new model, and show that it can\nproduce dramatically better condensing than the standard nearest neighbor rule,\nyet is characterized by generalization bounds almost identical to the latter.\nWe then suggest a condensing heuristic for our new problem. We demonstrate\nBayes consistency for this heuristic, and also show promising empirical\nresults.",
            "author": [
                "Lee-Ad Gottlieb",
                "Timor Sharabi",
                "Roi Weiss"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15951v1",
                "http://arxiv.org/pdf/2310.15951v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15950v1",
            "title": "Representation Learning with Large Language Models for Recommendation",
            "updated": "2023-10-24T15:51:13Z",
            "published": "2023-10-24T15:51:13Z",
            "summary": "Recommender systems have seen significant advancements with the influence of\ndeep learning and graph neural networks, particularly in capturing complex\nuser-item relationships. However, these graph-based recommenders heavily depend\non ID-based data, potentially disregarding valuable textual information\nassociated with users and items, resulting in less informative learned\nrepresentations. Moreover, the utilization of implicit feedback data introduces\npotential noise and bias, posing challenges for the effectiveness of user\npreference learning. While the integration of large language models (LLMs) into\ntraditional ID-based recommenders has gained attention, challenges such as\nscalability issues, limitations in text-only reliance, and prompt input\nconstraints need to be addressed for effective implementation in practical\nrecommender systems. To address these challenges, we propose a model-agnostic\nframework RLMRec that aims to enhance existing recommenders with LLM-empowered\nrepresentation learning. It proposes a recommendation paradigm that integrates\nrepresentation learning with LLMs to capture intricate semantic aspects of user\nbehaviors and preferences. RLMRec incorporates auxiliary textual signals,\ndevelops a user/item profiling paradigm empowered by LLMs, and aligns the\nsemantic space of LLMs with the representation space of collaborative\nrelational signals through a cross-view alignment framework. This work further\nestablish a theoretical foundation demonstrating that incorporating textual\nsignals through mutual information maximization enhances the quality of\nrepresentations. In our evaluation, we integrate RLMRec with state-of-the-art\nrecommender models, while also analyzing its efficiency and robustness to noise\ndata. Our implementation codes are available at\nhttps://github.com/HKUDS/RLMRec.",
            "author": [
                "Xubin Ren",
                "Wei Wei",
                "Lianghao Xia",
                "Lixin Su",
                "Suqi Cheng",
                "Junfeng Wang",
                "Dawei Yin",
                "Chao Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15950v1",
                "http://arxiv.org/pdf/2310.15950v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15940v1",
            "title": "Combining Behaviors with the Successor Features Keyboard",
            "updated": "2023-10-24T15:35:54Z",
            "published": "2023-10-24T15:35:54Z",
            "summary": "The Option Keyboard (OK) was recently proposed as a method for transferring\nbehavioral knowledge across tasks. OK transfers knowledge by adaptively\ncombining subsets of known behaviors using Successor Features (SFs) and\nGeneralized Policy Improvement (GPI). However, it relies on hand-designed\nstate-features and task encodings which are cumbersome to design for every new\nenvironment. In this work, we propose the \"Successor Features Keyboard\" (SFK),\nwhich enables transfer with discovered state-features and task encodings. To\nenable discovery, we propose the \"Categorical Successor Feature Approximator\"\n(CSFA), a novel learning algorithm for estimating SFs while jointly discovering\nstate-features and task encodings. With SFK and CSFA, we achieve the first\ndemonstration of transfer with SFs in a challenging 3D environment where all\nthe necessary representations are discovered. We first compare CSFA against\nother methods for approximating SFs and show that only CSFA discovers\nrepresentations compatible with SF&GPI at this scale. We then compare SFK\nagainst transfer learning baselines and show that it transfers most quickly to\nlong-horizon tasks.",
            "author": [
                "Wilka Carvalho",
                "Andre Saraiva",
                "Angelos Filos",
                "Andrew Kyle Lampinen",
                "Loic Matthey",
                "Richard L. Lewis",
                "Honglak Lee",
                "Satinder Singh",
                "Danilo J. Rezende",
                "Daniel Zoran"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15940v1",
                "http://arxiv.org/pdf/2310.15940v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15939v1",
            "title": "Blip-Up Blip-Down Circular EPI (BUDA-cEPI) for Distortion-Free dMRI with\n  Rapid Unrolled Deep Learning Reconstruction",
            "updated": "2023-10-24T15:35:00Z",
            "published": "2023-10-24T15:35:00Z",
            "summary": "Purpose: We implemented the blip-up, blip-down circular echo planar imaging\n(BUDA-cEPI) sequence with readout and phase partial Fourier to reduced\noff-resonance effect and T2* blurring. BUDA-cEPI reconstruction with S-based\nlow-rank modeling of local k-space neighborhoods (S-LORAKS) is shown to be\neffective at reconstructing the highly under-sampled BUDA-cEPI data, but it is\ncomputationally intensive. Thus, we developed an ML-based reconstruction\ntechnique termed \"BUDA-cEPI RUN-UP\" to enable fast reconstruction.\n  Methods: BUDA-cEPI RUN-UP - a model-based framework that incorporates\noff-resonance and eddy current effects was unrolled through an artificial\nneural network with only six gradient updates. The unrolled network alternates\nbetween data consistency (i.e., forward BUDA-cEPI and its adjoint) and\nregularization steps where U-Net plays a role as the regularizer. To handle the\npartial Fourier effect, the virtual coil concept was also incorporated into the\nreconstruction to effectively take advantage of the smooth phase prior, and\ntrained to predict the ground-truth images obtained by BUDA-cEPI with S-LORAKS.\n  Results: BUDA-cEPI with S-LORAKS reconstruction enabled the management of\noff-resonance, partial Fourier, and residual aliasing artifacts. However, the\nreconstruction time is approximately 225 seconds per slice, which may not be\npractical in a clinical setting. In contrast, the proposed BUDA-cEPI RUN-UP\nyielded similar results to BUDA-cEPI with S-LORAKS, with less than a 5%\nnormalized root mean square error detected, while the reconstruction time is\napproximately 3 seconds.\n  Conclusion: BUDA-cEPI RUN-UP was shown to reduce the reconstruction time by\n~88x when compared to the state-of-the-art technique, while preserving imaging\ndetails as demonstrated through DTI application.",
            "author": [
                "Uten Yarach",
                "Itthi Chatnuntawech",
                "Congyu Liao",
                "Surat Teerapittayanon",
                "Siddharth Srinivasan Iyer",
                "Tae Hyung Kim",
                "Justin Haldar",
                "Jaejin Cho",
                "Berkin Bilgic",
                "Yuxin Hu",
                "Brian Hargreaves",
                "Kawin Setsompop"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15939v1",
                "http://arxiv.org/pdf/2310.15939v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15938v1",
            "title": "ABKD: Graph Neural Network Compression with Attention-Based Knowledge\n  Distillation",
            "updated": "2023-10-24T15:34:30Z",
            "published": "2023-10-24T15:34:30Z",
            "summary": "Graph Neural Networks (GNNs) have proven to be quite versatile for a variety\nof applications, including recommendation systems, fake news detection, drug\ndiscovery, and even computer vision. Due to the expanding size of\ngraph-structured data, GNN models have also increased in complexity, leading to\nsubstantial latency issues. This is primarily attributed to the irregular\nstructure of graph data and its access pattern into memory. The natural\nsolution to reduce latency is to compress large GNNs into small GNNs. One way\nto do this is via knowledge distillation (KD). However, most KD approaches for\nGNNs only consider the outputs of the last layers and do not consider the\noutputs of the intermediate layers of the GNNs; these layers may contain\nimportant inductive biases indicated by the graph structure. To address this\nshortcoming, we propose a novel KD approach to GNN compression that we call\nAttention-Based Knowledge Distillation (ABKD). ABKD is a KD approach that uses\nattention to identify important intermediate teacher-student layer pairs and\nfocuses on aligning their outputs. ABKD enables higher compression of GNNs with\na smaller accuracy dropoff compared to existing KD approaches. On average, we\nachieve a 1.79% increase in accuracy with a 32.3x compression ratio on\nOGBN-Mag, a large graph dataset, compared to state-of-the-art approaches.",
            "author": [
                "Anshul Ahluwalia",
                "Rohit Das",
                "Payman Behnam",
                "Alind Khare",
                "Pan Li",
                "Alexey Tumanov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15938v1",
                "http://arxiv.org/pdf/2310.15938v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15935v1",
            "title": "Mediator Interpretation and Faster Learning Algorithms for Linear\n  Correlated Equilibria in General Extensive-Form Games",
            "updated": "2023-10-24T15:32:54Z",
            "published": "2023-10-24T15:32:54Z",
            "summary": "A recent paper by Farina & Pipis (2023) established the existence of\nuncoupled no-linear-swap regret dynamics with polynomial-time iterations in\nextensive-form games. The equilibrium points reached by these dynamics, known\nas linear correlated equilibria, are currently the tightest known relaxation of\ncorrelated equilibrium that can be learned in polynomial time in any finite\nextensive-form game. However, their properties remain vastly unexplored, and\ntheir computation is onerous. In this paper, we provide several contributions\nshedding light on the fundamental nature of linear-swap regret. First, we show\na connection between linear deviations and a generalization of communication\ndeviations in which the player can make queries to a \"mediator\" who replies\nwith action recommendations, and, critically, the player is not constrained to\nmatch the timing of the game as would be the case for communication deviations.\nWe coin this latter set the untimed communication (UTC) deviations. We show\nthat the UTC deviations coincide precisely with the linear deviations, and\ntherefore that any player minimizing UTC regret also minimizes linear-swap\nregret. We then leverage this connection to develop state-of-the-art no-regret\nalgorithms for computing linear correlated equilibria, both in theory and in\npractice. In theory, our algorithms achieve polynomially better per-iteration\nruntimes; in practice, our algorithms represent the state of the art by several\norders of magnitude.",
            "author": [
                "Brian Hu Zhang",
                "Gabriele Farina",
                "Tuomas Sandholm"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15935v1",
                "http://arxiv.org/pdf/2310.15935v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15932v1",
            "title": "Online Robust Mean Estimation",
            "updated": "2023-10-24T15:28:43Z",
            "published": "2023-10-24T15:28:43Z",
            "summary": "We study the problem of high-dimensional robust mean estimation in an online\nsetting. Specifically, we consider a scenario where $n$ sensors are measuring\nsome common, ongoing phenomenon. At each time step $t=1,2,\\ldots,T$, the\n$i^{th}$ sensor reports its readings $x^{(i)}_t$ for that time step. The\nalgorithm must then commit to its estimate $\\mu_t$ for the true mean value of\nthe process at time $t$. We assume that most of the sensors observe independent\nsamples from some common distribution $X$, but an $\\epsilon$-fraction of them\nmay instead behave maliciously. The algorithm wishes to compute a good\napproximation $\\mu$ to the true mean $\\mu^\\ast := \\mathbf{E}[X]$. We note that\nif the algorithm is allowed to wait until time $T$ to report its estimate, this\nreduces to the well-studied problem of robust mean estimation. However, the\nrequirement that our algorithm produces partial estimates as the data is coming\nin substantially complicates the situation.\n  We prove two main results about online robust mean estimation in this model.\nFirst, if the uncorrupted samples satisfy the standard condition of\n$(\\epsilon,\\delta)$-stability, we give an efficient online algorithm that\noutputs estimates $\\mu_t$, $t \\in [T],$ such that with high probability it\nholds that $\\|\\mu-\\mu^\\ast\\|_2 = O(\\delta \\log(T))$, where $\\mu = (\\mu_t)_{t\n\\in [T]}$. We note that this error bound is nearly competitive with the best\noffline algorithms, which would achieve $\\ell_2$-error of $O(\\delta)$. Our\nsecond main result shows that with additional assumptions on the input (most\nnotably that $X$ is a product distribution) there are inefficient algorithms\nwhose error does not depend on $T$ at all.",
            "author": [
                "Daniel M. Kane",
                "Ilias Diakonikolas",
                "Hanshen Xiao",
                "Sihan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15932v1",
                "http://arxiv.org/pdf/2310.15932v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15929v1",
            "title": "E-Sparse: Boosting the Large Language Model Inference through\n  Entropy-based N:M Sparsity",
            "updated": "2023-10-24T15:27:15Z",
            "published": "2023-10-24T15:27:15Z",
            "summary": "Traditional pruning methods are known to be challenging to work in Large\nLanguage Models (LLMs) for Generative AI because of their unaffordable training\nprocess and large computational demands. For the first time, we introduce the\ninformation entropy of hidden state features into a pruning metric design,\nnamely E-Sparse, to improve the accuracy of N:M sparsity on LLM. E-Sparse\nemploys the information richness to leverage the channel importance, and\nfurther incorporates several novel techniques to put it into effect: (1) it\nintroduces information entropy to enhance the significance of parameter weights\nand input feature norms as a novel pruning metric, and performs N:M sparsity\nwithout modifying the remaining weights. (2) it designs global naive shuffle\nand local block shuffle to quickly optimize the information distribution and\nadequately cope with the impact of N:M sparsity on LLMs' accuracy. E-Sparse is\nimplemented as a Sparse-GEMM on FasterTransformer and runs on NVIDIA Ampere\nGPUs. Extensive experiments on the LLaMA family and OPT models show that\nE-Sparse can significantly speed up the model inference over the dense model\n(up to 1.53X) and obtain significant memory saving (up to 43.52%), with\nacceptable accuracy loss.",
            "author": [
                "Yun Li",
                "Lin Niu",
                "Xipeng Zhang",
                "Kai Liu",
                "Jianchen Zhu",
                "Zhanhui Kang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15929v1",
                "http://arxiv.org/pdf/2310.15929v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15921v1",
            "title": "Contrastive Learning-based Sentence Encoders Implicitly Weight\n  Informative Words",
            "updated": "2023-10-24T15:22:04Z",
            "published": "2023-10-24T15:22:04Z",
            "summary": "The performance of sentence encoders can be significantly improved through\nthe simple practice of fine-tuning using contrastive loss. A natural question\narises: what characteristics do models acquire during contrastive learning?\nThis paper theoretically and experimentally shows that contrastive-based\nsentence encoders implicitly weight words based on information-theoretic\nquantities; that is, more informative words receive greater weight, while\nothers receive less. The theory states that, in the lower bound of the optimal\nvalue of the contrastive learning objective, the norm of word embedding\nreflects the information gain associated with the distribution of surrounding\nwords. We also conduct comprehensive experiments using various models, multiple\ndatasets, two methods to measure the implicit weighting of models (Integrated\nGradients and SHAP), and two information-theoretic quantities (information gain\nand self-information). The results provide empirical evidence that contrastive\nfine-tuning emphasizes informative words.",
            "author": [
                "Hiroto Kurita",
                "Goro Kobayashi",
                "Sho Yokoi",
                "Kentaro Inui"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15921v1",
                "http://arxiv.org/pdf/2310.15921v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15916v1",
            "title": "In-Context Learning Creates Task Vectors",
            "updated": "2023-10-24T15:17:14Z",
            "published": "2023-10-24T15:17:14Z",
            "summary": "In-context learning (ICL) in Large Language Models (LLMs) has emerged as a\npowerful new learning paradigm. However, its underlying mechanism is still not\nwell understood. In particular, it is challenging to map it to the \"standard\"\nmachine learning framework, where one uses a training set $S$ to find a\nbest-fitting function $f(x)$ in some hypothesis class. Here we make progress on\nthis problem by showing that the functions learned by ICL often have a very\nsimple structure: they correspond to the transformer LLM whose only inputs are\nthe query $x$ and a single \"task vector\" calculated from the training set.\nThus, ICL can be seen as compressing $S$ into a single task vector\n$\\boldsymbol{\\theta}(S)$ and then using this task vector to modulate the\ntransformer to produce the output. We support the above claim via comprehensive\nexperiments across a range of models and tasks.",
            "author": [
                "Roee Hendel",
                "Mor Geva",
                "Amir Globerson"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15916v1",
                "http://arxiv.org/pdf/2310.15916v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16074v1",
            "title": "RePoseDM: Recurrent Pose Alignment and Gradient Guidance for Pose Guided\n  Image Synthesis",
            "updated": "2023-10-24T15:16:19Z",
            "published": "2023-10-24T15:16:19Z",
            "summary": "Pose-guided person image synthesis task requires re-rendering a reference\nimage, which should have a photorealistic appearance and flawless pose\ntransfer. Since person images are highly structured, existing approaches\nrequire dense connections for complex deformations and occlusions because these\nare generally handled through multi-level warping and masking in latent space.\nBut the feature maps generated by convolutional neural networks do not have\nequivariance, and hence even the multi-level warping does not have a perfect\npose alignment. Inspired by the ability of the diffusion model to generate\nphotorealistic images from the given conditional guidance, we propose recurrent\npose alignment to provide pose-aligned texture features as conditional\nguidance. Moreover, we propose gradient guidance from pose interaction fields,\nwhich output the distance from the valid pose manifold given a target pose as\ninput. This helps in learning plausible pose transfer trajectories that result\nin photorealism and undistorted texture details. Extensive results on two\nlarge-scale benchmarks and a user study demonstrate the ability of our proposed\napproach to generate photorealistic pose transfer under challenging scenarios.\nAdditionally, we prove the efficiency of gradient guidance in pose-guided image\ngeneration on the HumanArt dataset with fine-tuned stable diffusion.",
            "author": [
                "Anant Khandelwal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16074v1",
                "http://arxiv.org/pdf/2310.16074v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15913v1",
            "title": "Mitigate Domain Shift by Primary-Auxiliary Objectives Association for\n  Generalizing Person ReID",
            "updated": "2023-10-24T15:15:57Z",
            "published": "2023-10-24T15:15:57Z",
            "summary": "While deep learning has significantly improved ReID model accuracy under the\nindependent and identical distribution (IID) assumption, it has also become\nclear that such models degrade notably when applied to an unseen novel domain\ndue to unpredictable/unknown domain shift. Contemporary domain generalization\n(DG) ReID models struggle in learning domain-invariant representation solely\nthrough training on an instance classification objective. We consider that a\ndeep learning model is heavily influenced and therefore biased towards\ndomain-specific characteristics, e.g., background clutter, scale and viewpoint\nvariations, limiting the generalizability of the learned model, and hypothesize\nthat the pedestrians are domain invariant owning they share the same structural\ncharacteristics. To enable the ReID model to be less domain-specific from these\npure pedestrians, we introduce a method that guides model learning of the\nprimary ReID instance classification objective by a concurrent auxiliary\nlearning objective on weakly labeled pedestrian saliency detection. To solve\nthe problem of conflicting optimization criteria in the model parameter space\nbetween the two learning objectives, we introduce a Primary-Auxiliary\nObjectives Association (PAOA) mechanism to calibrate the loss gradients of the\nauxiliary task towards the primary learning task gradients. Benefiting from the\nharmonious multitask learning design, our model can be extended with the recent\ntest-time diagram to form the PAOA+, which performs on-the-fly optimization\nagainst the auxiliary objective in order to maximize the model's generative\ncapacity in the test target domain. Experiments demonstrate the superiority of\nthe proposed PAOA model.",
            "author": [
                "Qilei Li",
                "Shaogang Gong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15913v1",
                "http://arxiv.org/pdf/2310.15913v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15912v1",
            "title": "Climate Change Impact on Agricultural Land Suitability: An Interpretable\n  Machine Learning-Based Eurasia Case Study",
            "updated": "2023-10-24T15:15:28Z",
            "published": "2023-10-24T15:15:28Z",
            "summary": "The United Nations has identified improving food security and reducing hunger\nas essential components of its sustainable development goals. As of 2021,\napproximately 828 million people worldwide are experiencing hunger and\nmalnutrition, with numerous fatalities reported. Climate change significantly\nimpacts agricultural land suitability, potentially leading to severe food\nshortages and subsequent social and political conflicts. To address this\npressing issue, we have developed a machine learning-based approach to predict\nthe risk of substantial land suitability degradation and changes in irrigation\npatterns. Our study focuses on Central Eurasia, a region burdened with economic\nand social challenges.\n  This study represents a pioneering effort in utilizing machine learning\nmethods to assess the impact of climate change on agricultural land suitability\nunder various carbon emissions scenarios. Through comprehensive feature\nimportance analysis, we unveil specific climate and terrain characteristics\nthat exert influence on land suitability. Our approach achieves remarkable\naccuracy, offering policymakers invaluable insights to facilitate informed\ndecisions aimed at averting a humanitarian crisis, including strategies such as\nthe provision of additional water and fertilizers. This research underscores\nthe tremendous potential of machine learning in addressing global challenges,\nwith a particular emphasis on mitigating hunger and malnutrition.",
            "author": [
                "Valeriy Shevchenko",
                "Daria Taniushkina",
                "Aleksander Lukashevich",
                "Aleksandr Bulkin",
                "Roland Grinis",
                "Kirill Kovalev",
                "Veronika Narozhnaia",
                "Nazar Sotiriadi",
                "Alexander Krenke",
                "Yury Maximov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15912v1",
                "http://arxiv.org/pdf/2310.15912v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15910v1",
            "title": "Characterizing Mechanisms for Factual Recall in Language Models",
            "updated": "2023-10-24T15:15:18Z",
            "published": "2023-10-24T15:15:18Z",
            "summary": "Language Models (LMs) often must integrate facts they memorized in\npretraining with new information that appears in a given context. These two\nsources can disagree, causing competition within the model, and it is unclear\nhow an LM will resolve the conflict. On a dataset that queries for knowledge of\nworld capitals, we investigate both distributional and mechanistic determinants\nof LM behavior in such situations. Specifically, we measure the proportion of\nthe time an LM will use a counterfactual prefix (e.g., \"The capital of Poland\nis London\") to overwrite what it learned in pretraining (\"Warsaw\"). On Pythia\nand GPT2, the training frequency of both the query country (\"Poland\") and the\nin-context city (\"London\") highly affect the models' likelihood of using the\ncounterfactual. We then use head attribution to identify individual attention\nheads that either promote the memorized answer or the in-context answer in the\nlogits. By scaling up or down the value vector of these heads, we can control\nthe likelihood of using the in-context answer on new data. This method can\nincrease the rate of generating the in-context answer to 88\\% of the time\nsimply by scaling a single head at runtime. Our work contributes to a body of\nevidence showing that we can often localize model behaviors to specific\ncomponents and provides a proof of concept for how future methods might control\nmodel behavior dynamically at runtime.",
            "author": [
                "Qinan Yu",
                "Jack Merullo",
                "Ellie Pavlick"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15910v1",
                "http://arxiv.org/pdf/2310.15910v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15905v1",
            "title": "Is Probing All You Need? Indicator Tasks as an Alternative to Probing\n  Embedding Spaces",
            "updated": "2023-10-24T15:08:12Z",
            "published": "2023-10-24T15:08:12Z",
            "summary": "The ability to identify and control different kinds of linguistic information\nencoded in vector representations of words has many use cases, especially for\nexplainability and bias removal. This is usually done via a set of simple\nclassification tasks, termed probes, to evaluate the information encoded in the\nembedding space. However, the involvement of a trainable classifier leads to\nentanglement between the probe's results and the classifier's nature. As a\nresult, contemporary works on probing include tasks that do not involve\ntraining of auxiliary models. In this work we introduce the term indicator\ntasks for non-trainable tasks which are used to query embedding spaces for the\nexistence of certain properties, and claim that this kind of tasks may point to\na direction opposite to probes, and that this contradiction complicates the\ndecision on whether a property exists in an embedding space. We demonstrate our\nclaims with two test cases, one dealing with gender debiasing and another with\nthe erasure of morphological information from embedding spaces. We show that\nthe application of a suitable indicator provides a more accurate picture of the\ninformation captured and removed compared to probes. We thus conclude that\nindicator tasks should be implemented and taken into consideration when\neliciting information from embedded representations.",
            "author": [
                "Tal Levy",
                "Omer Goldman",
                "Reut Tsarfaty"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15905v1",
                "http://arxiv.org/pdf/2310.15905v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15904v1",
            "title": "Do Stochastic Parrots have Feelings Too? Improving Neural Detection of\n  Synthetic Text via Emotion Recognition",
            "updated": "2023-10-24T15:07:35Z",
            "published": "2023-10-24T15:07:35Z",
            "summary": "Recent developments in generative AI have shone a spotlight on\nhigh-performance synthetic text generation technologies. The now wide\navailability and ease of use of such models highlights the urgent need to\nprovide equally powerful technologies capable of identifying synthetic text.\nWith this in mind, we draw inspiration from psychological studies which suggest\nthat people can be driven by emotion and encode emotion in the text they\ncompose. We hypothesize that pretrained language models (PLMs) have an\naffective deficit because they lack such an emotional driver when generating\ntext and consequently may generate synthetic text which has affective\nincoherence i.e. lacking the kind of emotional coherence present in\nhuman-authored text. We subsequently develop an emotionally aware detector by\nfine-tuning a PLM on emotion. Experiment results indicate that our\nemotionally-aware detector achieves improvements across a range of synthetic\ntext generators, various sized models, datasets, and domains. Finally, we\ncompare our emotionally-aware synthetic text detector to ChatGPT in the task of\nidentification of its own output and show substantial gains, reinforcing the\npotential of emotion as a signal to identify synthetic text. Code, models, and\ndatasets are available at https: //github.com/alanagiasi/emoPLMsynth",
            "author": [
                "Alan Cowap",
                "Yvette Graham",
                "Jennifer Foster"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15904v1",
                "http://arxiv.org/pdf/2310.15904v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15903v2",
            "title": "Neural Collapse in Multi-label Learning with Pick-all-label Loss",
            "updated": "2023-11-01T03:59:09Z",
            "published": "2023-10-24T15:07:16Z",
            "summary": "We study deep neural networks for the multi-label classification (MLab) task\nthrough the lens of neural collapse (NC). Previous works have been restricted\nto the multi-class classification setting and discovered a prevalent NC\nphenomenon comprising of the following properties for the last-layer features:\n(i) the variability of features within every class collapses to zero, (ii) the\nset of feature means form an equi-angular tight frame (ETF), and (iii) the last\nlayer classifiers collapse to the feature mean upon some scaling. We generalize\nthe study to multi-label learning, and prove for the first time that a\ngeneralized NC phenomenon holds with the \"pick-all-label\" formulation. Under\nthe natural analog of the unconstrained feature model (UFM), we establish that\nthe only global classifier of the pick-all-label cross entropy loss display the\nsame ETF geometry which further collapse to multiplicity-1 feature class means.\nBesides, we discover a combinatorial property in generalized NC which is unique\nfor multi-label learning that we call \"tag-wise average\" property, where the\nfeature class-means of samples with multiple labels are scaled average of the\nfeature class-means of single label tags. Theoretically, we establish global\noptimality result for the pick-all-label cross-entropy risk for the UFM.\nAdditionally, We also provide empirical evidence to support our investigation\ninto training deep neural networks on multi-label datasets, resulting in\nimproved training efficiency.",
            "author": [
                "Pengyu Li",
                "Yutong Wang",
                "Xiao Li",
                "Qing Qu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15903v2",
                "http://arxiv.org/pdf/2310.15903v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16073v1",
            "title": "Correlation Debiasing for Unbiased Scene Graph Generation in Videos",
            "updated": "2023-10-24T14:59:51Z",
            "published": "2023-10-24T14:59:51Z",
            "summary": "Dynamic scene graph generation (SGG) from videos requires not only\ncomprehensive understanding of objects across the scenes that are prone to\ntemporal fluctuations but also a model the temporal motions and interactions\nwith different objects. Moreover, the long-tailed distribution of visual\nrelationships is the crucial bottleneck of most dynamic SGG methods, since most\nof them focus on capturing spatio-temporal context using complex architectures,\nwhich leads to the generation of biased scene graphs. To address these\nchallenges, we propose FloCoDe: Flow-aware temporal consistency and Correlation\nDebiasing with uncertainty attenuation for unbiased dynamic scene graphs.\nFloCoDe employs feature warping using flow to detect temporally consistent\nobjects across the frames. In addition, it uses correlation debiasing to learn\nthe unbiased relation representation for long-tailed classes. Moreover, to\nattenuate the predictive uncertainties, it uses a mixture of sigmoidal\ncross-entropy loss and contrastive loss to incorporate label correlations to\nidentify the commonly co-occurring relations and help debias the long-tailed\nones. Extensive experimental evaluation shows a performance gain as high as\n4.1% showing the superiority of generating more unbiased scene graphs.",
            "author": [
                "Anant Khandelwal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16073v1",
                "http://arxiv.org/pdf/2310.16073v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15890v3",
            "title": "Cross-feature Contrastive Loss for Decentralized Deep Learning on\n  Heterogeneous Data",
            "updated": "2023-12-05T20:31:51Z",
            "published": "2023-10-24T14:48:23Z",
            "summary": "The current state-of-the-art decentralized learning algorithms mostly assume\nthe data distribution to be Independent and Identically Distributed (IID).\nHowever, in practical scenarios, the distributed datasets can have\nsignificantly heterogeneous data distributions across the agents. In this work,\nwe present a novel approach for decentralized learning on heterogeneous data,\nwhere data-free knowledge distillation through contrastive loss on\ncross-features is utilized to improve performance. Cross-features for a pair of\nneighboring agents are the features (i.e., last hidden layer activations)\nobtained from the data of an agent with respect to the model parameters of the\nother agent. We demonstrate the effectiveness of the proposed technique through\nan exhaustive set of experiments on various Computer Vision datasets (CIFAR-10,\nCIFAR-100, Fashion MNIST, Imagenette, and ImageNet), model architectures, and\nnetwork topologies. Our experiments show that the proposed method achieves\nsuperior performance (0.2-4% improvement in test accuracy) compared to other\nexisting techniques for decentralized learning on heterogeneous data.",
            "author": [
                "Sai Aparna Aketi",
                "Kaushik Roy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15890v3",
                "http://arxiv.org/pdf/2310.15890v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15888v1",
            "title": "State Sequences Prediction via Fourier Transform for Representation\n  Learning",
            "updated": "2023-10-24T14:47:02Z",
            "published": "2023-10-24T14:47:02Z",
            "summary": "While deep reinforcement learning (RL) has been demonstrated effective in\nsolving complex control tasks, sample efficiency remains a key challenge due to\nthe large amounts of data required for remarkable performance. Existing\nresearch explores the application of representation learning for data-efficient\nRL, e.g., learning predictive representations by predicting long-term future\nstates. However, many existing methods do not fully exploit the structural\ninformation inherent in sequential state signals, which can potentially improve\nthe quality of long-term decision-making but is difficult to discern in the\ntime domain. To tackle this problem, we propose State Sequences Prediction via\nFourier Transform (SPF), a novel method that exploits the frequency domain of\nstate sequences to extract the underlying patterns in time series data for\nlearning expressive representations efficiently. Specifically, we theoretically\nanalyze the existence of structural information in state sequences, which is\nclosely related to policy performance and signal regularity, and then propose\nto predict the Fourier transform of infinite-step future state sequences to\nextract such information. One of the appealing features of SPF is that it is\nsimple to implement while not requiring storage of infinite-step future states\nas prediction targets. Experiments demonstrate that the proposed method\noutperforms several state-of-the-art algorithms in terms of both sample\nefficiency and performance.",
            "author": [
                "Mingxuan Ye",
                "Yufei Kuang",
                "Jie Wang",
                "Rui Yang",
                "Wengang Zhou",
                "Houqiang Li",
                "Feng Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15888v1",
                "http://arxiv.org/pdf/2310.15888v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.02087v1",
            "title": "Design Of Rubble Analyzer Probe Using ML For Earthquake",
            "updated": "2023-10-24T14:43:42Z",
            "published": "2023-10-24T14:43:42Z",
            "summary": "The earthquake rubble analyzer uses machine learning to detect human presence\nvia ambient sounds, achieving 97.45% accuracy. It also provides real-time\nenvironmental data, aiding in assessing survival prospects for trapped\nindividuals, crucial for post-earthquake rescue efforts",
            "author": [
                "Abhishek Sebastian",
                "R Pragna",
                "K Vishal Vythianathan",
                "Dasaraju Sohan Sai",
                "U Shiva Sri Hari Al",
                "R Anirudh",
                "Apurv Choudhary"
            ],
            "link": [
                "http://arxiv.org/abs/2311.02087v1",
                "http://arxiv.org/pdf/2311.02087v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.AI",
                "cs.LG",
                "eess.AS",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15883v1",
            "title": "Attitude Takeover Control for Noncooperative Space Targets Based on\n  Gaussian Processes with Online Model Learning",
            "updated": "2023-10-24T14:38:11Z",
            "published": "2023-10-24T14:38:11Z",
            "summary": "One major challenge for autonomous attitude takeover control for on-orbit\nservicing of spacecraft is that an accurate dynamic motion model of the\ncombined vehicles is highly nonlinear, complex and often costly to identify\nonline, which makes traditional model-based control impractical for this task.\nTo address this issue, a recursive online sparse Gaussian Process (GP)-based\nlearning strategy for attitude takeover control of noncooperative targets with\nmaneuverability is proposed, where the unknown dynamics are online compensated\nbased on the learnt GP model in a semi-feedforward manner. The method enables\nthe continuous use of on-orbit data to successively improve the learnt model\nduring online operation and has reduced computational load compared to standard\nGP regression. Next to the GP-based feedforward, a feedback controller is\nproposed that varies its gains based on the predicted model confidence,\nensuring robustness of the overall scheme. Moreover, rigorous theoretical\nproofs of Lyapunov stability and boundedness guarantees of the proposed\nmethod-driven closed-loop system are provided in the probabilistic sense. A\nsimulation study based on a high-fidelity simulator is used to show the\neffectiveness of the proposed strategy and demonstrate its high performance.",
            "author": [
                "Yuhan Liu",
                "Pengyu Wang",
                "Chang-Hun Lee",
                "Roland T\u00f3th"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15883v1",
                "http://arxiv.org/pdf/2310.15883v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18363v1",
            "title": "A Contextualized Real-Time Multimodal Emotion Recognition for\n  Conversational Agents using Graph Convolutional Networks in Reinforcement\n  Learning",
            "updated": "2023-10-24T14:31:17Z",
            "published": "2023-10-24T14:31:17Z",
            "summary": "Owing to the recent developments in Generative Artificial Intelligence\n(GenAI) and Large Language Models (LLM), conversational agents are becoming\nincreasingly popular and accepted. They provide a human touch by interacting in\nways familiar to us and by providing support as virtual companions. Therefore,\nit is important to understand the user's emotions in order to respond\nconsiderately. Compared to the standard problem of emotion recognition,\nconversational agents face an additional constraint in that recognition must be\nreal-time. Studies on model architectures using audio, visual, and textual\nmodalities have mainly focused on emotion classification using full video\nsequences that do not provide online features. In this work, we present a novel\nparadigm for contextualized Emotion Recognition using Graph Convolutional\nNetwork with Reinforcement Learning (conER-GRL). Conversations are partitioned\ninto smaller groups of utterances for effective extraction of contextual\ninformation. The system uses Gated Recurrent Units (GRU) to extract multimodal\nfeatures from these groups of utterances. More importantly, Graph Convolutional\nNetworks (GCN) and Reinforcement Learning (RL) agents are cascade trained to\ncapture the complex dependencies of emotion features in interactive scenarios.\nComparing the results of the conER-GRL model with other state-of-the-art models\non the benchmark dataset IEMOCAP demonstrates the advantageous capabilities of\nthe conER-GRL architecture in recognizing emotions in real-time from multimodal\nconversational signals.",
            "author": [
                "Fathima Abdul Rahman",
                "Guang Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18363v1",
                "http://arxiv.org/pdf/2310.18363v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.HC",
                "cs.LG",
                "I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15872v1",
            "title": "KirchhoffNet: A Circuit Bridging Message Passing and Continuous-Depth\n  Models",
            "updated": "2023-10-24T14:28:00Z",
            "published": "2023-10-24T14:28:00Z",
            "summary": "In this paper, we exploit a fundamental principle of analog electronic\ncircuitry, Kirchhoff's current law, to introduce a unique class of neural\nnetwork models that we refer to as KirchhoffNet. KirchhoffNet establishes close\nconnections with message passing neural networks and continuous-depth networks.\nWe demonstrate that even in the absence of any traditional layers (such as\nconvolution, pooling, or linear layers), KirchhoffNet attains 98.86% test\naccuracy on the MNIST dataset, comparable with state of the art (SOTA) results.\nWhat makes KirchhoffNet more intriguing is its potential in the realm of\nhardware. Contemporary deep neural networks are conventionally deployed on\nGPUs. In contrast, KirchhoffNet can be physically realized by an analog\nelectronic circuit. Moreover, we justify that irrespective of the number of\nparameters within a KirchhoffNet, its forward calculation can always be\ncompleted within 1/f seconds, with f representing the hardware's clock\nfrequency. This characteristic introduces a promising technology for\nimplementing ultra-large-scale neural networks.",
            "author": [
                "Zhengqi Gao",
                "Fan-Keng Sun",
                "Duane S. Boning"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15872v1",
                "http://arxiv.org/pdf/2310.15872v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18362v1",
            "title": "SoK: Memorization in General-Purpose Large Language Models",
            "updated": "2023-10-24T14:25:53Z",
            "published": "2023-10-24T14:25:53Z",
            "summary": "Large Language Models (LLMs) are advancing at a remarkable pace, with myriad\napplications under development. Unlike most earlier machine learning models,\nthey are no longer built for one specific application but are designed to excel\nin a wide range of tasks. A major part of this success is due to their huge\ntraining datasets and the unprecedented number of model parameters, which allow\nthem to memorize large amounts of information contained in the training data.\nThis memorization goes beyond mere language, and encompasses information only\npresent in a few documents. This is often desirable since it is necessary for\nperforming tasks such as question answering, and therefore an important part of\nlearning, but also brings a whole array of issues, from privacy and security to\ncopyright and beyond. LLMs can memorize short secrets in the training data, but\ncan also memorize concepts like facts or writing styles that can be expressed\nin text in many different ways. We propose a taxonomy for memorization in LLMs\nthat covers verbatim text, facts, ideas and algorithms, writing styles,\ndistributional properties, and alignment goals. We describe the implications of\neach type of memorization - both positive and negative - for model performance,\nprivacy, security and confidentiality, copyright, and auditing, and ways to\ndetect and prevent memorization. We further highlight the challenges that arise\nfrom the predominant way of defining memorization with respect to model\nbehavior instead of model weights, due to LLM-specific phenomena such as\nreasoning capabilities or differences between decoding algorithms. Throughout\nthe paper, we describe potential risks and opportunities arising from\nmemorization in LLMs that we hope will motivate new research directions.",
            "author": [
                "Valentin Hartmann",
                "Anshuman Suri",
                "Vincent Bindschaedler",
                "David Evans",
                "Shruti Tople",
                "Robert West"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18362v1",
                "http://arxiv.org/pdf/2310.18362v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15865v1",
            "title": "Using Causality-Aware Graph Neural Networks to Predict Temporal\n  Centralities in Dynamic Graphs",
            "updated": "2023-10-24T14:23:10Z",
            "published": "2023-10-24T14:23:10Z",
            "summary": "Node centralities play a pivotal role in network science, social network\nanalysis, and recommender systems. In temporal data, static path-based\ncentralities like closeness or betweenness can give misleading results about\nthe true importance of nodes in a temporal graph. To address this issue,\ntemporal generalizations of betweenness and closeness have been defined that\nare based on the shortest time-respecting paths between pairs of nodes.\nHowever, a major issue of those generalizations is that the calculation of such\npaths is computationally expensive. Addressing this issue, we study the\napplication of De Bruijn Graph Neural Networks (DBGNN), a causality-aware graph\nneural network architecture, to predict temporal path-based centralities in\ntime series data. We experimentally evaluate our approach in 13 temporal graphs\nfrom biological and social systems and show that it considerably improves the\nprediction of both betweenness and closeness centrality compared to a static\nGraph Convolutional Neural Network.",
            "author": [
                "Franziska Heeg",
                "Ingo Scholtes"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15865v1",
                "http://arxiv.org/pdf/2310.15865v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15861v1",
            "title": "Social Learning of General Rules",
            "updated": "2023-10-24T14:21:52Z",
            "published": "2023-10-24T14:21:52Z",
            "summary": "Why do agents adopt a particular general behavioral rule among a collection\nof possible alternatives? To address this question, we introduce a dynamic\nsocial learning framework, where agents rely on general rules of thumb and\nimitate the behavioral rules of successful peers. We find the social learning\noutcome can be characterized independent of the initial rule distribution. When\none dominant general rule consistently yields superior problem-specific\noutcomes, social learning almost surely leads all agents to adopt this dominant\nrule; otherwise, provided the population is sufficiently large, the better rule\nfor the more frequent problem becomes the consensus rule with arbitrarily high\nprobability. As a result, the behavioral rule selected by the social learning\nprocess need not maximize social welfare. We complement our theoretical\nanalysis with an application to the market sentiment selection in a stochastic\nproduction market.",
            "author": [
                "Enrique Urbano Arellano",
                "Xinyang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15861v1",
                "http://arxiv.org/pdf/2310.15861v1"
            ],
            "primary_category": "econ.TH",
            "category": [
                "econ.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16853v1",
            "title": "CP-BCS: Binary Code Summarization Guided by Control Flow Graph and\n  Pseudo Code",
            "updated": "2023-10-24T14:20:39Z",
            "published": "2023-10-24T14:20:39Z",
            "summary": "Automatically generating function summaries for binaries is an extremely\nvaluable but challenging task, since it involves translating the execution\nbehavior and semantics of the low-level language (assembly code) into\nhuman-readable natural language. However, most current works on understanding\nassembly code are oriented towards generating function names, which involve\nnumerous abbreviations that make them still confusing. To bridge this gap, we\nfocus on generating complete summaries for binary functions, especially for\nstripped binary (no symbol table and debug information in reality). To fully\nexploit the semantics of assembly code, we present a control flow graph and\npseudo code guided binary code summarization framework called CP-BCS. CP-BCS\nutilizes a bidirectional instruction-level control flow graph and pseudo code\nthat incorporates expert knowledge to learn the comprehensive binary function\nexecution behavior and logic semantics. We evaluate CP-BCS on 3 different\nbinary optimization levels (O1, O2, and O3) for 3 different computer\narchitectures (X86, X64, and ARM). The evaluation results demonstrate CP-BCS is\nsuperior and significantly improves the efficiency of reverse engineering.",
            "author": [
                "Tong Ye",
                "Lingfei Wu",
                "Tengfei Ma",
                "Xuhong Zhang",
                "Yangkai Du",
                "Peiyu Liu",
                "Shouling Ji",
                "Wenhai Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16853v1",
                "http://arxiv.org/pdf/2310.16853v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15858v1",
            "title": "Topology-aware Debiased Self-supervised Graph Learning for\n  Recommendation",
            "updated": "2023-10-24T14:16:19Z",
            "published": "2023-10-24T14:16:19Z",
            "summary": "In recommendation, graph-based Collaborative Filtering (CF) methods mitigate\nthe data sparsity by introducing Graph Contrastive Learning (GCL). However, the\nrandom negative sampling strategy in these GCL-based CF models neglects the\nsemantic structure of users (items), which not only introduces false negatives\n(negatives that are similar to anchor user (item)) but also ignores the\npotential positive samples. To tackle the above issues, we propose\nTopology-aware Debiased Self-supervised Graph Learning (TDSGL) for\nrecommendation, which constructs contrastive pairs according to the semantic\nsimilarity between users (items). Specifically, since the original user-item\ninteraction data commendably reflects the purchasing intent of users and\ncertain characteristics of items, we calculate the semantic similarity between\nusers (items) on interaction data. Then, given a user (item), we construct its\nnegative pairs by selecting users (items) which embed different semantic\nstructures to ensure the semantic difference between the given user (item) and\nits negatives. Moreover, for a user (item), we design a feature extraction\nmodule that converts other semantically similar users (items) into an auxiliary\npositive sample to acquire a more informative representation. Experimental\nresults show that the proposed model outperforms the state-of-the-art models\nsignificantly on three public datasets. Our model implementation codes are\navailable at https://github.com/malajikuai/TDSGL.",
            "author": [
                "Lei Han",
                "Hui Yan",
                "Zhicheng Qiao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15858v1",
                "http://arxiv.org/pdf/2310.15858v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15853v1",
            "title": "Improving Event Time Prediction by Learning to Partition the Event Time\n  Space",
            "updated": "2023-10-24T14:11:40Z",
            "published": "2023-10-24T14:11:40Z",
            "summary": "Recently developed survival analysis methods improve upon existing approaches\nby predicting the probability of event occurrence in each of a number\npre-specified (discrete) time intervals. By avoiding placing strong parametric\nassumptions on the event density, this approach tends to improve prediction\nperformance, particularly when data are plentiful. However, in clinical\nsettings with limited available data, it is often preferable to judiciously\npartition the event time space into a limited number of intervals well suited\nto the prediction task at hand. In this work, we develop a method to learn from\ndata a set of cut points defining such a partition. We show that in two\nsimulated datasets, we are able to recover intervals that match the underlying\ngenerative model. We then demonstrate improved prediction performance on three\nreal-world observational datasets, including a large, newly harmonized stroke\nrisk prediction dataset. Finally, we argue that our approach facilitates\nclinical decision-making by suggesting time intervals that are most appropriate\nfor each task, in the sense that they facilitate more accurate risk prediction.",
            "author": [
                "Jimmy Hickey",
                "Ricardo Henao",
                "Daniel Wojdyla",
                "Michael Pencina",
                "Matthew M. Engelhard"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15853v1",
                "http://arxiv.org/pdf/2310.15853v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15852v1",
            "title": "Using Artificial French Data to Understand the Emergence of Gender Bias\n  in Transformer Language Models",
            "updated": "2023-10-24T14:08:37Z",
            "published": "2023-10-24T14:08:37Z",
            "summary": "Numerous studies have demonstrated the ability of neural language models to\nlearn various linguistic properties without direct supervision. This work takes\nan initial step towards exploring the less researched topic of how neural\nmodels discover linguistic properties of words, such as gender, as well as the\nrules governing their usage. We propose to use an artificial corpus generated\nby a PCFG based on French to precisely control the gender distribution in the\ntraining data and determine under which conditions a model correctly captures\ngender information or, on the contrary, appears gender-biased.",
            "author": [
                "Lina Conti",
                "Guillaume Wisniewski"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15852v1",
                "http://arxiv.org/pdf/2310.15852v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15850v1",
            "title": "Posterior Estimation for Dynamic PET imaging using Conditional\n  Variational Inference",
            "updated": "2023-10-24T14:05:30Z",
            "published": "2023-10-24T14:05:30Z",
            "summary": "This work aims efficiently estimating the posterior distribution of kinetic\nparameters for dynamic positron emission tomography (PET) imaging given a\nmeasurement of time of activity curve. Considering the inherent information\nloss from parametric imaging to measurement space with the forward kinetic\nmodel, the inverse mapping is ambiguous. The conventional (but expensive)\nsolution can be the Markov Chain Monte Carlo (MCMC) sampling, which is known to\nproduce unbiased asymptotical estimation. We propose a deep-learning-based\nframework for efficient posterior estimation. Specifically, we counteract the\ninformation loss in the forward process by introducing latent variables. Then,\nwe use a conditional variational autoencoder (CVAE) and optimize its evidence\nlower bound. The well-trained decoder is able to infer the posterior with a\ngiven measurement and the sampled latent variables following a simple\nmultivariate Gaussian distribution. We validate our CVAE-based method using\nunbiased MCMC as the reference for low-dimensional data (a single brain region)\nwith the simplified reference tissue model.",
            "author": [
                "Xiaofeng Liu",
                "Thibault Marin",
                "Tiss Amal",
                "Jonghye Woo",
                "Georges El Fakhri",
                "Jinsong Ouyang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15850v1",
                "http://arxiv.org/pdf/2310.15850v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph",
                "cs.AI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15848v3",
            "title": "On Responsible Machine Learning Datasets with Fairness, Privacy, and\n  Regulatory Norms",
            "updated": "2023-11-25T04:02:29Z",
            "published": "2023-10-24T14:01:53Z",
            "summary": "Artificial Intelligence (AI) has made its way into various scientific fields,\nproviding astonishing improvements over existing algorithms for a wide variety\nof tasks. In recent years, there have been severe concerns over the\ntrustworthiness of AI technologies. The scientific community has focused on the\ndevelopment of trustworthy AI algorithms. However, machine and deep learning\nalgorithms, popular in the AI community today, depend heavily on the data used\nduring their development. These learning algorithms identify patterns in the\ndata, learning the behavioral objective. Any flaws in the data have the\npotential to translate directly into algorithms. In this study, we discuss the\nimportance of Responsible Machine Learning Datasets and propose a framework to\nevaluate the datasets through a responsible rubric. While existing work focuses\non the post-hoc evaluation of algorithms for their trustworthiness, we provide\na framework that considers the data component separately to understand its role\nin the algorithm. We discuss responsible datasets through the lens of fairness,\nprivacy, and regulatory compliance and provide recommendations for constructing\nfuture datasets. After surveying over 100 datasets, we use 60 datasets for\nanalysis and demonstrate that none of these datasets is immune to issues of\nfairness, privacy preservation, and regulatory compliance. We provide\nmodifications to the ``datasheets for datasets\" with important additions for\nimproved dataset documentation. With governments around the world regularizing\ndata protection laws, the method for the creation of datasets in the scientific\ncommunity requires revision. We believe this study is timely and relevant in\ntoday's era of AI.",
            "author": [
                "Surbhi Mittal",
                "Kartik Thakral",
                "Richa Singh",
                "Mayank Vatsa",
                "Tamar Glaser",
                "Cristian Canton Ferrer",
                "Tal Hassner"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15848v3",
                "http://arxiv.org/pdf/2310.15848v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15845v1",
            "title": "Pre-training Music Classification Models via Music Source Separation",
            "updated": "2023-10-24T13:57:55Z",
            "published": "2023-10-24T13:57:55Z",
            "summary": "In this paper, we study whether music source separation can be used as a\npre-training strategy for music representation learning, targeted at music\nclassification tasks. To this end, we first pre-train U-Net networks under\nvarious music source separation objectives, such as the isolation of vocal or\ninstrumental sources from a musical piece; afterwards, we attach a\nconvolutional tail network to the pre-trained U-Net and jointly finetune the\nwhole network. The features learned by the separation network are also\npropagated to the tail network through skip connections. Experimental results\nin two widely used and publicly available datasets indicate that pre-training\nthe U-Nets with a music source separation objective can improve performance\ncompared to both training the whole network from scratch and using the tail\nnetwork as a standalone in two music classification tasks: music auto-tagging,\nwhen vocal separation is used, and music genre classification for the case of\nmulti-source separation.",
            "author": [
                "Christos Garoufis",
                "Athanasia Zlatintsi",
                "Petros Maragos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15845v1",
                "http://arxiv.org/pdf/2310.15845v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16071v1",
            "title": "Grid Frequency Forecasting in University Campuses using Convolutional\n  LSTM",
            "updated": "2023-10-24T13:53:51Z",
            "published": "2023-10-24T13:53:51Z",
            "summary": "The modern power grid is facing increasing complexities, primarily stemming\nfrom the integration of renewable energy sources and evolving consumption\npatterns. This paper introduces an innovative methodology that harnesses\nConvolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) networks\nto establish robust time series forecasting models for grid frequency. These\nmodels effectively capture the spatiotemporal intricacies inherent in grid\nfrequency data, significantly enhancing prediction accuracy and bolstering\npower grid reliability. The research explores the potential and development of\nindividualized Convolutional LSTM (ConvLSTM) models for buildings within a\nuniversity campus, enabling them to be independently trained and evaluated for\neach building. Individual ConvLSTM models are trained on power consumption data\nfor each campus building and forecast the grid frequency based on historical\ntrends. The results convincingly demonstrate the superiority of the proposed\nmodels over traditional forecasting techniques, as evidenced by performance\nmetrics such as Mean Square Error (MSE), Mean Absolute Error (MAE), and Mean\nAbsolute Percentage Error (MAPE). Additionally, an Ensemble Model is formulated\nto aggregate insights from the building-specific models, delivering\ncomprehensive forecasts for the entire campus. This approach ensures the\nprivacy and security of power consumption data specific to each building.",
            "author": [
                "Aneesh Sathe",
                "Wen Ren Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16071v1",
                "http://arxiv.org/pdf/2310.16071v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18361v1",
            "title": "Clinical Decision Support System for Unani Medicine Practitioners",
            "updated": "2023-10-24T13:49:18Z",
            "published": "2023-10-24T13:49:18Z",
            "summary": "Like other fields of Traditional Medicines, Unani Medicines have been found\nas an effective medical practice for ages. It is still widely used in the\nsubcontinent, particularly in Pakistan and India. However, Unani Medicines\nPractitioners are lacking modern IT applications in their everyday clinical\npractices. An Online Clinical Decision Support System may address this\nchallenge to assist apprentice Unani Medicines practitioners in their\ndiagnostic processes. The proposed system provides a web-based interface to\nenter the patient's symptoms, which are then automatically analyzed by our\nsystem to generate a list of probable diseases. The system allows practitioners\nto choose the most likely disease and inform patients about the associated\ntreatment options remotely. The system consists of three modules: an Online\nClinical Decision Support System, an Artificial Intelligence Inference Engine,\nand a comprehensive Unani Medicines Database. The system employs advanced AI\ntechniques such as Decision Trees, Deep Learning, and Natural Language\nProcessing. For system development, the project team used a technology stack\nthat includes React, FastAPI, and MySQL. Data and functionality of the\napplication is exposed using APIs for integration and extension with similar\ndomain applications. The novelty of the project is that it addresses the\nchallenge of diagnosing diseases accurately and efficiently in the context of\nUnani Medicines principles. By leveraging the power of technology, the proposed\nClinical Decision Support System has the potential to ease access to healthcare\nservices and information, reduce cost, boost practitioner and patient\nsatisfaction, improve speed and accuracy of the diagnostic process, and provide\neffective treatments remotely. The application will be useful for Unani\nMedicines Practitioners, Patients, Government Drug Regulators, Software\nDevelopers, and Medical Researchers.",
            "author": [
                "Haider Sultan",
                "Hafiza Farwa Mahmood",
                "Noor Fatima",
                "Marriyam Nadeem",
                "Talha Waheed"
            ],
            "link": [
                "http://dx.doi.org/10.13140/RG.2.2.15161.54887/1",
                "http://arxiv.org/abs/2310.18361v1",
                "http://arxiv.org/pdf/2310.18361v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16070v1",
            "title": "Spatial-Temporal Hypergraph Neural Network for Traffic Forecasting",
            "updated": "2023-10-24T13:49:13Z",
            "published": "2023-10-24T13:49:13Z",
            "summary": "Traffic forecasting, which benefits from mobile Internet development and\nposition technologies, plays a critical role in Intelligent Transportation\nSystems. It helps to implement rich and varied transportation applications and\nbring convenient transportation services to people based on collected traffic\ndata. Most existing methods usually leverage graph-based deep learning networks\nto model the complex road network for traffic forecasting shallowly. Despite\ntheir effectiveness, these methods are generally limited in fully capturing\nhigh-order spatial dependencies caused by road network topology and high-order\ntemporal dependencies caused by traffic dynamics. To tackle the above issues,\nwe focus on the essence of traffic system and propose STHODE: Spatio-Temporal\nHypergraph Neural Ordinary Differential Equation Network, which combines road\nnetwork topology and traffic dynamics to capture high-order spatio-temporal\ndependencies in traffic data. Technically, STHODE consists of a spatial module\nand a temporal module. On the one hand, we construct a spatial hypergraph and\nleverage an adaptive MixHop hypergraph ODE network to capture high-order\nspatial dependencies. On the other hand, we utilize a temporal hypergraph and\nemploy a hyperedge evolving ODE network to capture high-order temporal\ndependencies. Finally, we aggregate the outputs of stacked STHODE layers to\nmutually enhance the prediction performance. Extensive experiments conducted on\nfour real-world traffic datasets demonstrate the superior performance of our\nproposed model compared to various baselines.",
            "author": [
                "Chengzhi Yao",
                "Zhi Li",
                "Junbo Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16070v1",
                "http://arxiv.org/pdf/2310.16070v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12856v2",
            "title": "Density of States Prediction of Crystalline Materials via Prompt-guided\n  Multi-Modal Transformer",
            "updated": "2023-11-23T02:00:09Z",
            "published": "2023-10-24T13:43:17Z",
            "summary": "The density of states (DOS) is a spectral property of crystalline materials,\nwhich provides fundamental insights into various characteristics of the\nmaterials. While previous works mainly focus on obtaining high-quality\nrepresentations of crystalline materials for DOS prediction, we focus on\npredicting the DOS from the obtained representations by reflecting the nature\nof DOS: DOS determines the general distribution of states as a function of\nenergy. That is, DOS is not solely determined by the crystalline material but\nalso by the energy levels, which has been neglected in previous works. In this\npaper, we propose to integrate heterogeneous information obtained from the\ncrystalline materials and the energies via a multi-modal transformer, thereby\nmodeling the complex relationships between the atoms in the crystalline\nmaterials and various energy levels for DOS prediction. Moreover, we propose to\nutilize prompts to guide the model to learn the crystal structural\nsystem-specific interactions between crystalline materials and energies.\nExtensive experiments on two types of DOS, i.e., Phonon DOS and Electron DOS,\nwith various real-world scenarios demonstrate the superiority of\nDOSTransformer. The source code for DOSTransformer is available at\nhttps://github.com/HeewoongNoh/DOSTransformer.",
            "author": [
                "Namkyeong Lee",
                "Heewoong Noh",
                "Sungwon Kim",
                "Dongmin Hyun",
                "Gyoung S. Na",
                "Chanyoung Park"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12856v2",
                "http://arxiv.org/pdf/2311.12856v2"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15836v1",
            "title": "A Diffusion Weighted Graph Framework for New Intent Discovery",
            "updated": "2023-10-24T13:43:01Z",
            "published": "2023-10-24T13:43:01Z",
            "summary": "New Intent Discovery (NID) aims to recognize both new and known intents from\nunlabeled data with the aid of limited labeled data containing only known\nintents. Without considering structure relationships between samples, previous\nmethods generate noisy supervisory signals which cannot strike a balance\nbetween quantity and quality, hindering the formation of new intent clusters\nand effective transfer of the pre-training knowledge. To mitigate this\nlimitation, we propose a novel Diffusion Weighted Graph Framework (DWGF) to\ncapture both semantic similarities and structure relationships inherent in\ndata, enabling more sufficient and reliable supervisory signals. Specifically,\nfor each sample, we diffuse neighborhood relationships along semantic paths\nguided by the nearest neighbors for multiple hops to characterize its local\nstructure discriminately. Then, we sample its positive keys and weigh them\nbased on semantic similarities and local structures for contrastive learning.\nDuring inference, we further propose Graph Smoothing Filter (GSF) to explicitly\nutilize the structure relationships to filter high-frequency noise embodied in\nsemantically ambiguous samples on the cluster boundary. Extensive experiments\nshow that our method outperforms state-of-the-art models on all evaluation\nmetrics across multiple benchmark datasets. Code and data are available at\nhttps://github.com/yibai-shi/DWGF.",
            "author": [
                "Wenkai Shi",
                "Wenbin An",
                "Feng Tian",
                "Qinghua Zheng",
                "QianYing Wang",
                "Ping Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15836v1",
                "http://arxiv.org/pdf/2310.15836v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15831v2",
            "title": "A Comparative Study of Variational Autoencoders, Normalizing Flows, and\n  Score-based Diffusion Models for Electrical Impedance Tomography",
            "updated": "2023-11-29T11:39:34Z",
            "published": "2023-10-24T13:36:44Z",
            "summary": "Electrical Impedance Tomography (EIT) is a widely employed imaging technique\nin industrial inspection, geophysical prospecting, and medical imaging.\nHowever, the inherent nonlinearity and ill-posedness of EIT image\nreconstruction present challenges for classical regularization techniques, such\nas the critical selection of regularization terms and the lack of prior\nknowledge. Deep generative models (DGMs) have been shown to play a crucial role\nin learning implicit regularizers and prior knowledge. This study aims to\ninvestigate the potential of three DGMs-variational autoencoder networks,\nnormalizing flow, and score-based diffusion model-to learn implicit\nregularizers in learning-based EIT imaging. We first introduce background\ninformation on EIT imaging and its inverse problem formulation. Next, we\npropose three algorithms for performing EIT inverse problems based on\ncorresponding DGMs. Finally, we present numerical and visual experiments, which\nreveal that (1) no single method consistently outperforms the others across all\nsettings, and (2) when reconstructing an object with 2 anomalies using a\nwell-trained model based on a training dataset containing 4 anomalies, the\nconditional normalizing flow model (CNF) exhibits the best generalization in\nlow-level noise, while the conditional score-based diffusion model (CSD*)\ndemonstrates the best generalization in high-level noise settings. We hope our\npreliminary efforts will encourage other researchers to assess their DGMs in\nEIT and other nonlinear inverse problems.",
            "author": [
                "Huihui Wang",
                "Guixian Xu",
                "Qingping Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15831v2",
                "http://arxiv.org/pdf/2310.15831v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15830v1",
            "title": "Localization of Small Leakages in Water Distribution Networks using\n  Concept Drift Explanation Methods",
            "updated": "2023-10-24T13:33:19Z",
            "published": "2023-10-24T13:33:19Z",
            "summary": "Facing climate change the already limited availability of drinking water will\ndecrease in the future rendering drinking water an increasingly scarce\nresource. Considerable amounts of it are lost through leakages in water\ntransportation and distribution networks. Leakage detection and localization\nare challenging problems due to the complex interactions and changing demands\nin water distribution networks. Especially small leakages are hard to pinpoint\nyet their localization is vital to avoid water loss over long periods of time.\nWhile there exist different approaches to solving the tasks of leakage\ndetection and localization, they are relying on various information about the\nsystem, e.g. real-time demand measurements and the precise network topology,\nwhich is an unrealistic assumption in many real-world scenarios. In contrast,\nthis work attempts leakage localization using pressure measurements only. For\nthis purpose, first, leakages in the water distribution network are modeled\nemploying Bayesian networks, and the system dynamics are analyzed. We then show\nhow the problem is connected to and can be considered through the lens of\nconcept drift. In particular, we argue that model-based explanations of concept\ndrift are a promising tool for localizing leakages given limited information\nabout the network. The methodology is experimentally evaluated using realistic\nbenchmark scenarios.",
            "author": [
                "Valerie Vaquet",
                "Fabian Hinder",
                "Kathrin Lammers",
                "Jonas Vaquet",
                "Barbara Hammer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15830v1",
                "http://arxiv.org/pdf/2310.15830v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15827v1",
            "title": "Automatic Aorta Segmentation with Heavily Augmented, High-Resolution 3-D\n  ResUNet: Contribution to the SEG.A Challenge",
            "updated": "2023-10-24T13:28:46Z",
            "published": "2023-10-24T13:28:46Z",
            "summary": "Automatic aorta segmentation from 3-D medical volumes is an important yet\ndifficult task. Several factors make the problem challenging, e.g. the\npossibility of aortic dissection or the difficulty with segmenting and\nannotating the small branches. This work presents a contribution by the MedGIFT\nteam to the SEG.A challenge organized during the MICCAI 2023 conference. We\npropose a fully automated algorithm based on deep encoder-decoder architecture.\nThe main assumption behind our work is that data preprocessing and augmentation\nare much more important than the deep architecture, especially in low data\nregimes. Therefore, the solution is based on a variant of traditional\nconvolutional U-Net. The proposed solution achieved a Dice score above 0.9 for\nall testing cases with the highest stability among all participants. The method\nscored 1st, 4th, and 3rd in terms of the clinical evaluation, quantitative\nresults, and volumetric meshing quality, respectively. We freely release the\nsource code, pretrained model, and provide access to the algorithm on the\nGrand-Challenge platform.",
            "author": [
                "Marek Wodzinski",
                "Henning M\u00fcller"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15827v1",
                "http://arxiv.org/pdf/2310.15827v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15826v1",
            "title": "One or Two Things We know about Concept Drift -- A Survey on Monitoring\n  Evolving Environments",
            "updated": "2023-10-24T13:25:19Z",
            "published": "2023-10-24T13:25:19Z",
            "summary": "The world surrounding us is subject to constant change. These changes,\nfrequently described as concept drift, influence many industrial and technical\nprocesses. As they can lead to malfunctions and other anomalous behavior, which\nmay be safety-critical in many scenarios, detecting and analyzing concept drift\nis crucial. In this paper, we provide a literature review focusing on concept\ndrift in unsupervised data streams. While many surveys focus on supervised data\nstreams, so far, there is no work reviewing the unsupervised setting. However,\nthis setting is of particular relevance for monitoring and anomaly detection\nwhich are directly applicable to many tasks and challenges in engineering. This\nsurvey provides a taxonomy of existing work on drift detection. Besides, it\ncovers the current state of research on drift localization in a systematic way.\nIn addition to providing a systematic literature review, this work provides\nprecise mathematical definitions of the considered problems and contains\nstandardized experiments on parametric artificial datasets allowing for a\ndirect comparison of different strategies for detection and localization.\nThereby, the suitability of different schemes can be analyzed systematically\nand guidelines for their usage in real-world scenarios can be provided.\nFinally, there is a section on the emerging topic of explaining concept drift.",
            "author": [
                "Fabian Hinder",
                "Valerie Vaquet",
                "Barbara Hammer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15826v1",
                "http://arxiv.org/pdf/2310.15826v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.03370v1",
            "title": "CMIP X-MOS: Improving Climate Models with Extreme Model Output\n  Statistics",
            "updated": "2023-10-24T13:18:53Z",
            "published": "2023-10-24T13:18:53Z",
            "summary": "Climate models are essential for assessing the impact of greenhouse gas\nemissions on our changing climate and the resulting increase in the frequency\nand severity of natural disasters. Despite the widespread acceptance of climate\nmodels produced by the Coupled Model Intercomparison Project (CMIP), they still\nface challenges in accurately predicting climate extremes, which pose most\nsignificant threats to both people and the environment. To address this\nlimitation and improve predictions of natural disaster risks, we introduce\nExtreme Model Output Statistics (X-MOS). This approach utilizes deep regression\ntechniques to precisely map CMIP model outputs to real measurements obtained\nfrom weather stations, which results in a more accurate analysis of the XXI\nclimate extremes. In contrast to previous research, our study places a strong\nemphasis on enhancing the estimation of the tails of future climate parameter\ndistributions. The latter supports decision-makers, enabling them to better\nassess climate-related risks across the globe.",
            "author": [
                "Vsevolod Morozov",
                "Artem Galliamov",
                "Aleksandr Lukashevich",
                "Antonina Kurdukova",
                "Yury Maximov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.03370v1",
                "http://arxiv.org/pdf/2311.03370v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph",
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15819v1",
            "title": "Generative Language Models Exhibit Social Identity Biases",
            "updated": "2023-10-24T13:17:40Z",
            "published": "2023-10-24T13:17:40Z",
            "summary": "The surge in popularity of large language models has given rise to concerns\nabout biases that these models could learn from humans. In this study, we\ninvestigate whether ingroup solidarity and outgroup hostility, fundamental\nsocial biases known from social science, are present in 51 large language\nmodels. We find that almost all foundational language models and some\ninstruction fine-tuned models exhibit clear ingroup-positive and\noutgroup-negative biases when prompted to complete sentences (e.g., \"We\nare...\"). A comparison of LLM-generated sentences with human-written sentences\non the internet reveals that these models exhibit similar level, if not\ngreater, levels of bias than human text. To investigate where these biases stem\nfrom, we experimentally varied the amount of ingroup-positive or\noutgroup-negative sentences the model was exposed to during fine-tuning in the\ncontext of the United States Democrat-Republican divide. Doing so resulted in\nthe models exhibiting a marked increase in ingroup solidarity and an even\ngreater increase in outgroup hostility. Furthermore, removing either\ningroup-positive or outgroup-negative sentences (or both) from the fine-tuning\ndata leads to a significant reduction in both ingroup solidarity and outgroup\nhostility, suggesting that biases can be reduced by removing biased training\ndata. Our findings suggest that modern language models exhibit fundamental\nsocial identity biases and that such biases can be mitigated by curating\ntraining data. Our results have practical implications for creating less biased\nlarge-language models and further underscore the need for more research into\nuser interactions with LLMs to prevent potential bias reinforcement in humans.",
            "author": [
                "Tiancheng Hu",
                "Yara Kyrychenko",
                "Steve Rathje",
                "Nigel Collier",
                "Sander van der Linden",
                "Jon Roozenbeek"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15819v1",
                "http://arxiv.org/pdf/2310.15819v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15817v1",
            "title": "Discriminator Guidance for Autoregressive Diffusion Models",
            "updated": "2023-10-24T13:14:22Z",
            "published": "2023-10-24T13:14:22Z",
            "summary": "We introduce discriminator guidance in the setting of Autoregressive\nDiffusion Models. The use of a discriminator to guide a diffusion process has\npreviously been used for continuous diffusion models, and in this work we\nderive ways of using a discriminator together with a pretrained generative\nmodel in the discrete case. First, we show that using an optimal discriminator\nwill correct the pretrained model and enable exact sampling from the underlying\ndata distribution. Second, to account for the realistic scenario of using a\nsub-optimal discriminator, we derive a sequential Monte Carlo algorithm which\niteratively takes the predictions from the discrimiator into account during the\ngeneration process. We test these approaches on the task of generating\nmolecular graphs and show how the discriminator improves the generative\nperformance over using only the pretrained model.",
            "author": [
                "Filip Ekstr\u00f6m Kelvinius",
                "Fredrik Lindsten"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15817v1",
                "http://arxiv.org/pdf/2310.15817v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15816v1",
            "title": "Nonlinear dimensionality reduction then and now: AIMs for dissipative\n  PDEs in the ML era",
            "updated": "2023-10-24T13:10:43Z",
            "published": "2023-10-24T13:10:43Z",
            "summary": "This study presents a collection of purely data-driven workflows for\nconstructing reduced-order models (ROMs) for distributed dynamical systems. The\nROMs we focus on, are data-assisted models inspired by, and templated upon, the\ntheory of Approximate Inertial Manifolds (AIMs); the particular motivation is\nthe so-called post-processing Galerkin method of Garcia-Archilla, Novo and\nTiti. Its applicability can be extended: the need for accurate truncated\nGalerkin projections and for deriving closed-formed corrections can be\ncircumvented using machine learning tools. When the right latent variables are\nnot a priori known, we illustrate how autoencoders as well as Diffusion Maps (a\nmanifold learning scheme) can be used to discover good sets of latent variables\nand test their explainability. The proposed methodology can express the ROMs in\nterms of (a) theoretical (Fourier coefficients), (b) linear data-driven (POD\nmodes) and/or (c) nonlinear data-driven (Diffusion Maps) coordinates. Both\nBlack-Box and (theoretically-informed and data-corrected) Gray-Box models are\ndescribed; the necessity for the latter arises when truncated Galerkin\nprojections are so inaccurate as to not be amenable to post-processing. We use\nthe Chafee-Infante reaction-diffusion and the Kuramoto-Sivashinsky dissipative\npartial differential equations to illustrate and successfully test the overall\nframework.",
            "author": [
                "Eleni D. Koronaki",
                "Nikolaos Evangelou",
                "Cristina P. Martin-Linares",
                "Edriss S. Titi",
                "Ioannis G. Kevrekidis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15816v1",
                "http://arxiv.org/pdf/2310.15816v1"
            ],
            "primary_category": "math.DS",
            "category": [
                "math.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15815v1",
            "title": "Good Better Best: Self-Motivated Imitation Learning for noisy\n  Demonstrations",
            "updated": "2023-10-24T13:09:56Z",
            "published": "2023-10-24T13:09:56Z",
            "summary": "Imitation Learning (IL) aims to discover a policy by minimizing the\ndiscrepancy between the agent's behavior and expert demonstrations. However, IL\nis susceptible to limitations imposed by noisy demonstrations from non-expert\nbehaviors, presenting a significant challenge due to the lack of supplementary\ninformation to assess their expertise. In this paper, we introduce\nSelf-Motivated Imitation LEarning (SMILE), a method capable of progressively\nfiltering out demonstrations collected by policies deemed inferior to the\ncurrent policy, eliminating the need for additional information. We utilize the\nforward and reverse processes of Diffusion Models to emulate the shift in\ndemonstration expertise from low to high and vice versa, thereby extracting the\nnoise information that diffuses expertise. Then, the noise information is\nleveraged to predict the diffusion steps between the current policy and\ndemonstrators, which we theoretically demonstrate its equivalence to their\nexpertise gap. We further explain in detail how the predicted diffusion steps\nare applied to filter out noisy demonstrations in a self-motivated manner and\nprovide its theoretical grounds. Through empirical evaluations on MuJoCo tasks,\nwe demonstrate that our method is proficient in learning the expert policy\namidst noisy demonstrations, and effectively filters out demonstrations with\nexpertise inferior to the current policy.",
            "author": [
                "Ye Yuan",
                "Xin Li",
                "Yong Heng",
                "Leiji Zhang",
                "MingZhong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15815v1",
                "http://arxiv.org/pdf/2310.15815v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15797v1",
            "title": "Random Entity Quantization for Parameter-Efficient Compositional\n  Knowledge Graph Representation",
            "updated": "2023-10-24T12:48:52Z",
            "published": "2023-10-24T12:48:52Z",
            "summary": "Representation Learning on Knowledge Graphs (KGs) is essential for downstream\ntasks. The dominant approach, KG Embedding (KGE), represents entities with\nindependent vectors and faces the scalability challenge. Recent studies propose\nan alternative way for parameter efficiency, which represents entities by\ncomposing entity-corresponding codewords matched from predefined small-scale\ncodebooks. We refer to the process of obtaining corresponding codewords of each\nentity as entity quantization, for which previous works have designed\ncomplicated strategies. Surprisingly, this paper shows that simple random\nentity quantization can achieve similar results to current strategies. We\nanalyze this phenomenon and reveal that entity codes, the quantization outcomes\nfor expressing entities, have higher entropy at the code level and Jaccard\ndistance at the codeword level under random entity quantization. Therefore,\ndifferent entities become more easily distinguished, facilitating effective KG\nrepresentation. The above results show that current quantization strategies are\nnot critical for KG representation, and there is still room for improvement in\nentity distinguishability beyond current strategies. The code to reproduce our\nresults is available at https://github.com/JiaangL/RandomQuantization.",
            "author": [
                "Jiaang Li",
                "Quan Wang",
                "Yi Liu",
                "Licheng Zhang",
                "Zhendong Mao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15797v1",
                "http://arxiv.org/pdf/2310.15797v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15793v1",
            "title": "Improving generalization in large language models by learning prefix\n  subspaces",
            "updated": "2023-10-24T12:44:09Z",
            "published": "2023-10-24T12:44:09Z",
            "summary": "This article focuses on large language models (LLMs) fine-tuning in the\nscarce data regime (also known as the \"few-shot\" learning setting). We propose\na method to increase the generalization capabilities of LLMs based on neural\nnetwork subspaces. This optimization method, recently introduced in computer\nvision, aims to improve model generalization by identifying wider local optima\nthrough the joint optimization of an entire simplex of models in parameter\nspace. Its adaptation to massive, pretrained transformers, however, poses some\nchallenges. First, their considerable number of parameters makes it difficult\nto train several models jointly, and second, their deterministic parameter\ninitialization schemes make them unfit for the subspace method as originally\nproposed. We show in this paper that \"Parameter Efficient Fine-Tuning\" (PEFT)\nmethods, however, are perfectly compatible with this original approach, and\npropose to learn entire simplex of continuous prefixes. We test our method on a\nvariant of the GLUE benchmark adapted to the few-shot learning setting, and\nshow that both our contributions jointly lead to a gain in average performances\ncompared to sota methods. The implementation can be found at the following\nlink: https://github.com/Liloulou/prefix_subspace",
            "author": [
                "Louis Falissard",
                "Vincent Guigue",
                "Laure Soulier"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15793v1",
                "http://arxiv.org/pdf/2310.15793v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15788v1",
            "title": "qPOTS: Efficient batch multiobjective Bayesian optimization via Pareto\n  optimal Thompson sampling",
            "updated": "2023-10-24T12:35:15Z",
            "published": "2023-10-24T12:35:15Z",
            "summary": "Classical evolutionary approaches for multiobjective optimization are quite\neffective but incur a lot of queries to the objectives; this can be prohibitive\nwhen objectives are expensive oracles. A sample-efficient approach to solving\nmultiobjective optimization is via Gaussian process (GP) surrogates and\nBayesian optimization (BO). Multiobjective Bayesian optimization (MOBO)\ninvolves the construction of an acquisition function which is optimized to\nacquire new observation candidates. This ``inner'' optimization can be hard due\nto various reasons: acquisition functions being nonconvex, nondifferentiable\nand/or unavailable in analytical form; the success of MOBO heavily relies on\nthis inner optimization. We do away with this hard acquisition function\noptimization step and propose a simple, but effective, Thompson sampling based\napproach ($q\\texttt{POTS}$) where new candidate(s) are chosen from the Pareto\nfrontier of random GP posterior sample paths obtained by solving a much cheaper\nmultiobjective optimization problem. To further improve computational\ntractability in higher dimensions we propose an automated active set of\ncandidates selection combined with a Nystr\\\"{o}m approximation. Our approach\napplies to arbitrary GP prior assumptions and demonstrates strong empirical\nperformance over the state of the art, both in terms of accuracy and\ncomputational efficiency, on synthetic as well as real-world experiments.",
            "author": [
                "S. Ashwin Renganathan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15788v1",
                "http://arxiv.org/pdf/2310.15788v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15787v1",
            "title": "SequenceMatch: Revisiting the design of weak-strong augmentations for\n  Semi-supervised learning",
            "updated": "2023-10-24T12:34:58Z",
            "published": "2023-10-24T12:34:58Z",
            "summary": "Semi-supervised learning (SSL) has become popular in recent years because it\nallows the training of a model using a large amount of unlabeled data. However,\none issue that many SSL methods face is the confirmation bias, which occurs\nwhen the model is overfitted to the small labeled training dataset and produces\noverconfident, incorrect predictions. To address this issue, we propose\nSequenceMatch, an efficient SSL method that utilizes multiple data\naugmentations. The key element of SequenceMatch is the inclusion of a medium\naugmentation for unlabeled data. By taking advantage of different augmentations\nand the consistency constraints between each pair of augmented examples,\nSequenceMatch helps reduce the divergence between the prediction distribution\nof the model for weakly and strongly augmented examples. In addition,\nSequenceMatch defines two different consistency constraints for high and\nlow-confidence predictions. As a result, SequenceMatch is more data-efficient\nthan ReMixMatch, and more time-efficient than both ReMixMatch ($\\times4$) and\nCoMatch ($\\times2$) while having higher accuracy. Despite its simplicity,\nSequenceMatch consistently outperforms prior methods on standard benchmarks,\nsuch as CIFAR-10/100, SVHN, and STL-10. It also surpasses prior\nstate-of-the-art methods by a large margin on large-scale datasets such as\nImageNet, with a 38.46\\% error rate. Code is available at\nhttps://github.com/beandkay/SequenceMatch.",
            "author": [
                "Khanh-Binh Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15787v1",
                "http://arxiv.org/pdf/2310.15787v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15786v1",
            "title": "Amortised Inference in Neural Networks for Small-Scale Probabilistic\n  Meta-Learning",
            "updated": "2023-10-24T12:34:25Z",
            "published": "2023-10-24T12:34:25Z",
            "summary": "The global inducing point variational approximation for BNNs is based on\nusing a set of inducing inputs to construct a series of conditional\ndistributions that accurately approximate the conditionals of the true\nposterior distribution. Our key insight is that these inducing inputs can be\nreplaced by the actual data, such that the variational distribution consists of\na set of approximate likelihoods for each datapoint. This structure lends\nitself to amortised inference, in which the parameters of each approximate\nlikelihood are obtained by passing each datapoint through a meta-model known as\nthe inference network. By training this inference network across related\ndatasets, we can meta-learn Bayesian inference over task-specific BNNs.",
            "author": [
                "Matthew Ashman",
                "Tommy Rochussen",
                "Adrian Weller"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15786v1",
                "http://arxiv.org/pdf/2310.15786v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15780v1",
            "title": "Make LLM a Testing Expert: Bringing Human-like Interaction to Mobile GUI\n  Testing via Functionality-aware Decisions",
            "updated": "2023-10-24T12:30:26Z",
            "published": "2023-10-24T12:30:26Z",
            "summary": "Automated Graphical User Interface (GUI) testing plays a crucial role in\nensuring app quality, especially as mobile applications have become an integral\npart of our daily lives. Despite the growing popularity of learning-based\ntechniques in automated GUI testing due to their ability to generate human-like\ninteractions, they still suffer from several limitations, such as low testing\ncoverage, inadequate generalization capabilities, and heavy reliance on\ntraining data. Inspired by the success of Large Language Models (LLMs) like\nChatGPT in natural language understanding and question answering, we formulate\nthe mobile GUI testing problem as a Q&A task. We propose GPTDroid, asking LLM\nto chat with the mobile apps by passing the GUI page information to LLM to\nelicit testing scripts, and executing them to keep passing the app feedback to\nLLM, iterating the whole process. Within this framework, we have also\nintroduced a functionality-aware memory prompting mechanism that equips the LLM\nwith the ability to retain testing knowledge of the whole process and conduct\nlong-term, functionality-based reasoning to guide exploration. We evaluate it\non 93 apps from Google Play and demonstrate that it outperforms the best\nbaseline by 32% in activity coverage, and detects 31% more bugs at a faster\nrate. Moreover, GPTDroid identify 53 new bugs on Google Play, of which 35 have\nbeen confirmed and fixed.",
            "author": [
                "Zhe Liu",
                "Chunyang Chen",
                "Junjie Wang",
                "Mengzhuo Chen",
                "Boyu Wu",
                "Xing Che",
                "Dandan Wang",
                "Qing Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15780v1",
                "http://arxiv.org/pdf/2310.15780v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15771v1",
            "title": "Control problems on infinite horizon subject to time-dependent pure\n  state constraints",
            "updated": "2023-10-24T12:17:23Z",
            "published": "2023-10-24T12:17:23Z",
            "summary": "In the last decades, control problems with infinite horizons and discount\nfactors have become increasingly central not only for economics but also for\napplications in artificial intelligence and machine learning. The strong links\nbetween reinforcement learning and control theory have led to major efforts\ntowards the development of algorithms to learn how to solve constrained control\nproblems. In particular, discount plays a role in addressing the challenges\nthat come with models that have unbounded disturbances. Although algorithms\nhave been extensively explored, few results take into account time-dependent\nstate constraints, which are imposed in most real-world control applications.\nFor this purpose, here we investigate feasibility and sufficient conditions for\nLipschitz regularity of the value function for a class of discounted infinite\nhorizon optimal control problems subject to time-dependent constraints. We\nfocus on problems with data that allow nonautonomous dynamics, and Lagrangian\nand state constraints that can be unbounded with possibly nonsmooth boundaries.",
            "author": [
                "Vincenzo Basco"
            ],
            "link": [
                "http://dx.doi.org/10.1007/s00498-023-00372-3",
                "http://arxiv.org/abs/2310.15771v1",
                "http://arxiv.org/pdf/2310.15771v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15767v2",
            "title": "Unpaired MRI Super Resolution with Self-Supervised Contrastive Learning",
            "updated": "2023-11-09T10:40:54Z",
            "published": "2023-10-24T12:13:51Z",
            "summary": "High-resolution (HR) magnetic resonance imaging (MRI) is crucial for\nenhancing diagnostic accuracy in clinical settings. Nonetheless, the inherent\nlimitation of MRI resolution restricts its widespread applicability. Deep\nlearning-based image super-resolution (SR) methods exhibit promise in improving\nMRI resolution without additional cost. However, these methods frequently\nrequire a substantial number of HR MRI images for training, which can be\nchallenging to acquire. In this paper, we propose an unpaired MRI SR approach\nthat employs self-supervised contrastive learning to enhance SR performance\nwith limited training data. Our approach leverages both authentic HR images and\nsynthetically generated SR images to construct positive and negative sample\npairs, thus facilitating the learning of discriminative features. Empirical\nresults presented in this study underscore significant enhancements in the peak\nsignal-to-noise ratio and structural similarity index, even when a paucity of\nHR images is available. These findings accentuate the potential of our approach\nin addressing the challenge of limited training data, thereby contributing to\nthe advancement of high-resolution MRI in clinical applications.",
            "author": [
                "Hao Li",
                "Quanwei Liu",
                "Jianan Liu",
                "Xiling Liu",
                "Yanni Dong",
                "Tao Huang",
                "Zhihan Lv"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15767v2",
                "http://arxiv.org/pdf/2310.15767v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15766v1",
            "title": "Robust Learning via Conditional Prevalence Adjustment",
            "updated": "2023-10-24T12:13:49Z",
            "published": "2023-10-24T12:13:49Z",
            "summary": "Healthcare data often come from multiple sites in which the correlations\nbetween confounding variables can vary widely. If deep learning models exploit\nthese unstable correlations, they might fail catastrophically in unseen sites.\nAlthough many methods have been proposed to tackle unstable correlations, each\nhas its limitations. For example, adversarial training forces models to\ncompletely ignore unstable correlations, but doing so may lead to poor\npredictive performance. Other methods (e.g. Invariant risk minimization [4])\ntry to learn domain-invariant representations that rely only on stable\nassociations by assuming a causal data-generating process (input X causes class\nlabel Y ). Thus, they may be ineffective for anti-causal tasks (Y causes X),\nwhich are common in computer vision. We propose a method called CoPA\n(Conditional Prevalence-Adjustment) for anti-causal tasks. CoPA assumes that\n(1) generation mechanism is stable, i.e. label Y and confounding variable(s) Z\ngenerate X, and (2) the unstable conditional prevalence in each site E fully\naccounts for the unstable correlations between X and Y . Our crucial\nobservation is that confounding variables are routinely recorded in healthcare\nsettings and the prevalence can be readily estimated, for example, from a set\nof (Y, Z) samples (no need for corresponding samples of X). CoPA can work even\nif there is a single training site, a scenario which is often overlooked by\nexisting methods. Our experiments on synthetic and real data show CoPA beating\ncompetitive baselines.",
            "author": [
                "Minh Nguyen",
                "Alan Q. Wang",
                "Heejong Kim",
                "Mert R. Sabuncu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15766v1",
                "http://arxiv.org/pdf/2310.15766v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15764v1",
            "title": "Debiasing, calibrating, and improving Semi-supervised Learning\n  performance via simple Ensemble Projector",
            "updated": "2023-10-24T12:11:19Z",
            "published": "2023-10-24T12:11:19Z",
            "summary": "Recent studies on semi-supervised learning (SSL) have achieved great success.\nDespite their promising performance, current state-of-the-art methods tend\ntoward increasingly complex designs at the cost of introducing more network\ncomponents and additional training procedures. In this paper, we propose a\nsimple method named Ensemble Projectors Aided for Semi-supervised Learning\n(EPASS), which focuses mainly on improving the learned embeddings to boost the\nperformance of the existing contrastive joint-training semi-supervised learning\nframeworks. Unlike standard methods, where the learned embeddings from one\nprojector are stored in memory banks to be used with contrastive learning,\nEPASS stores the ensemble embeddings from multiple projectors in memory banks.\nAs a result, EPASS improves generalization, strengthens feature representation,\nand boosts performance. For instance, EPASS improves strong baselines for\nsemi-supervised learning by 39.47\\%/31.39\\%/24.70\\% top-1 error rate, while\nusing only 100k/1\\%/10\\% of labeled data for SimMatch, and achieves\n40.24\\%/32.64\\%/25.90\\% top-1 error rate for CoMatch on the ImageNet dataset.\nThese improvements are consistent across methods, network architectures, and\ndatasets, proving the general effectiveness of the proposed methods. Code is\navailable at https://github.com/beandkay/EPASS.",
            "author": [
                "Khanh-Binh Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15764v1",
                "http://arxiv.org/pdf/2310.15764v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15758v1",
            "title": "Learning From Free-Text Human Feedback -- Collect New Datasets Or Extend\n  Existing Ones?",
            "updated": "2023-10-24T12:01:11Z",
            "published": "2023-10-24T12:01:11Z",
            "summary": "Learning from free-text human feedback is essential for dialog systems, but\nannotated data is scarce and usually covers only a small fraction of error\ntypes known in conversational AI. Instead of collecting and annotating new\ndatasets from scratch, recent advances in synthetic dialog generation could be\nused to augment existing dialog datasets with the necessary annotations.\nHowever, to assess the feasibility of such an effort, it is important to know\nthe types and frequency of free-text human feedback included in these datasets.\nIn this work, we investigate this question for a variety of commonly used\ndialog datasets, including MultiWoZ, SGD, BABI, PersonaChat,\nWizards-of-Wikipedia, and the human-bot split of the Self-Feeding Chatbot.\nUsing our observations, we derive new taxonomies for the annotation of\nfree-text human feedback in dialogs and investigate the impact of including\nsuch data in response generation for three SOTA language generation models,\nincluding GPT-2, LLAMA, and Flan-T5. Our findings provide new insights into the\ncomposition of the datasets examined, including error types, user response\ntypes, and the relations between them.",
            "author": [
                "Dominic Petrak",
                "Nafise Sadat Moosavi",
                "Ye Tian",
                "Nikolai Rozanov",
                "Iryna Gurevych"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15758v1",
                "http://arxiv.org/pdf/2310.15758v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15753v1",
            "title": "Efficient CPU-Optimized Parameter Estimation for Modeling Fish Schooling\n  Behavior in Large Particle Systems",
            "updated": "2023-10-24T11:56:13Z",
            "published": "2023-10-24T11:56:13Z",
            "summary": "The schooling behavior of fish can be studied through simulations involving a\nlarge number of interacting particles. In such systems, each individual\nparticle is guided by behavior rules, which include aggregation towards a\ncentroid, collision avoidance, and direction alignment. The movement vector of\neach particle may be expressed as a linear combination of behaviors, with\nunknown parameters that define a trade-off among several behavioral\nconstraints. A fitness function for collective schooling behavior encompasses\nall individual particle parameters.\n  For a large number of interacting particles in a complex environment,\nheuristic methods, such as evolutionary algorithms, are used to optimize the\nfitness function, ensuring that the resulting decision rule preserves\ncollective behavior. However, these algorithms exhibit slow convergence, making\nthem inefficient in terms of CPU time cost.\n  This paper proposes a CPU-efficient iterative (Cluster, Partition, Refine --\nCPR) algorithm for estimating decision rule parameters for a large number of\ninteracting particles. In the first step, we employ the K-Means (unsupervised\nlearning) algorithm to cluster candidate solutions. Then, we partition the\nsearch space using Voronoi tessellation over the defined clusters. We assess\nthe quality of each cluster based on the fitness function, with the centroid of\ntheir Voronoi cells representing the clusters. Subsequently, we refine the\nsearch space by introducing new cells into a number of identified well-fitting\nVoronoi cells. This process is repeated until convergence.\n  A comparison of the performance of the CPR algorithm with a standard Genetic\nAlgorithm reveals that the former converges faster than the latter. We also\ndemonstrate that the application of the CPR algorithm results in a schooling\nbehavior consistent with empirical observations.",
            "author": [
                "S. Arabeei",
                "S. Subbey"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15753v1",
                "http://arxiv.org/pdf/2310.15753v1"
            ],
            "primary_category": "q-bio.PE",
            "category": [
                "q-bio.PE",
                "92D40, 92C20, 65K05, 68T05",
                "G.1.6; G.4; I.2.8; I.6.5; J.3; D.2.8"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15752v1",
            "title": "Integrating Language Models into Direct Speech Translation: An\n  Inference-Time Solution to Control Gender Inflection",
            "updated": "2023-10-24T11:55:16Z",
            "published": "2023-10-24T11:55:16Z",
            "summary": "When translating words referring to the speaker, speech translation (ST)\nsystems should not resort to default masculine generics nor rely on potentially\nmisleading vocal traits. Rather, they should assign gender according to the\nspeakers' preference. The existing solutions to do so, though effective, are\nhardly feasible in practice as they involve dedicated model re-training on\ngender-labeled ST data. To overcome these limitations, we propose the first\ninference-time solution to control speaker-related gender inflections in ST.\nOur approach partially replaces the (biased) internal language model (LM)\nimplicitly learned by the ST decoder with gender-specific external LMs.\nExperiments on en->es/fr/it show that our solution outperforms the base models\nand the best training-time mitigation strategy by up to 31.0 and 1.6 points in\ngender accuracy, respectively, for feminine forms. The gains are even larger\n(up to 32.0 and 3.4) in the challenging condition where speakers' vocal traits\nconflict with their gender.",
            "author": [
                "Dennis Fucci",
                "Marco Gaido",
                "Sara Papi",
                "Mauro Cettolo",
                "Matteo Negri",
                "Luisa Bentivogli"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15752v1",
                "http://arxiv.org/pdf/2310.15752v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16851v1",
            "title": "Deep Learning Models for Classification of COVID-19 Cases by Medical\n  Images",
            "updated": "2023-10-24T11:48:40Z",
            "published": "2023-10-24T11:48:40Z",
            "summary": "In recent times, the use of chest Computed Tomography (CT) images for\ndetecting coronavirus infections has gained significant attention, owing to\ntheir ability to reveal bilateral changes in affected individuals. However,\nclassifying patients from medical images presents a formidable challenge,\nparticularly in identifying such bilateral changes. To tackle this challenge,\nour study harnesses the power of deep learning models for the precise\nclassification of infected patients. Our research involves a comparative\nanalysis of deep transfer learning-based classification models, including\nDenseNet201, GoogleNet, and AlexNet, against carefully chosen supervised\nlearning models. Additionally, our work encompasses Covid-19 classification,\nwhich involves the identification and differentiation of medical images, such\nas X-rays and electrocardiograms, that exhibit telltale signs of Covid-19\ninfection. This comprehensive approach ensures that our models can handle a\nwide range of medical image types and effectively identify characteristic\npatterns indicative of Covid-19. By conducting meticulous research and\nemploying advanced deep learning techniques, we have made significant strides\nin enhancing the accuracy and speed of Covid-19 diagnosis. Our results\ndemonstrate the effectiveness of these models and their potential to make\nsubstantial contributions to the global effort to combat COVID-19.",
            "author": [
                "Amir Ali"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16851v1",
                "http://arxiv.org/pdf/2310.16851v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15746v1",
            "title": "Failures Pave the Way: Enhancing Large Language Models through\n  Tuning-free Rule Accumulation",
            "updated": "2023-10-24T11:40:34Z",
            "published": "2023-10-24T11:40:34Z",
            "summary": "Large Language Models (LLMs) have showcased impressive performance. However,\ndue to their inability to capture relationships among samples, these frozen\nLLMs inevitably keep repeating similar mistakes. In this work, we propose our\nTuning-free Rule Accumulation (TRAN) framework, which guides LLMs in improving\ntheir performance by learning from previous mistakes. Considering data arrives\nsequentially, LLMs gradually accumulate rules from incorrect cases, forming a\nrule collection. These rules are then utilized by the LLMs to avoid making\nsimilar mistakes when processing subsequent inputs. Moreover, the rules remain\nindependent of the primary prompts, seamlessly complementing prompt design\nstrategies. Experimentally, we show that TRAN improves over recent baselines by\na large margin.",
            "author": [
                "Zeyuan Yang",
                "Peng Li",
                "Yang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15746v1",
                "http://arxiv.org/pdf/2310.15746v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15744v1",
            "title": "Analyzing Single Cell RNA Sequencing with Topological Nonnegative Matrix\n  Factorization",
            "updated": "2023-10-24T11:36:41Z",
            "published": "2023-10-24T11:36:41Z",
            "summary": "Single-cell RNA sequencing (scRNA-seq) is a relatively new technology that\nhas stimulated enormous interest in statistics, data science, and computational\nbiology due to the high dimensionality, complexity, and large scale associated\nwith scRNA-seq data. Nonnegative matrix factorization (NMF) offers a unique\napproach due to its meta-gene interpretation of resulting low-dimensional\ncomponents. However, NMF approaches suffer from the lack of multiscale\nanalysis. This work introduces two persistent Laplacian regularized NMF\nmethods, namely, topological NMF (TNMF) and robust topological NMF (rTNMF). By\nemploying a total of 12 datasets, we demonstrate that the proposed TNMF and\nrTNMF significantly outperform all other NMF-based methods. We have also\nutilized TNMF and rTNMF for the visualization of popular Uniform Manifold\nApproximation and Projection (UMAP) and t-distributed stochastic neighbor\nembedding (t-SNE).",
            "author": [
                "Yuta Hozumi",
                "Guo-Wei Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15744v1",
                "http://arxiv.org/pdf/2310.15744v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.AT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15743v1",
            "title": "RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot\n  Document-Level Relation Extraction",
            "updated": "2023-10-24T11:35:23Z",
            "published": "2023-10-24T11:35:23Z",
            "summary": "How to identify semantic relations among entities in a document when only a\nfew labeled documents are available? Few-shot document-level relation\nextraction (FSDLRE) is crucial for addressing the pervasive data scarcity\nproblem in real-world scenarios. Metric-based meta-learning is an effective\nframework widely adopted for FSDLRE, which constructs class prototypes for\nclassification. However, existing works often struggle to obtain class\nprototypes with accurate relational semantics: 1) To build prototype for a\ntarget relation type, they aggregate the representations of all entity pairs\nholding that relation, while these entity pairs may also hold other relations,\nthus disturbing the prototype. 2) They use a set of generic NOTA\n(none-of-the-above) prototypes across all tasks, neglecting that the NOTA\nsemantics differs in tasks with different target relation types. In this paper,\nwe propose a relation-aware prototype learning method for FSDLRE to strengthen\nthe relational semantics of prototype representations. By judiciously\nleveraging the relation descriptions and realistic NOTA instances as guidance,\nour method effectively refines the relation prototypes and generates\ntask-specific NOTA prototypes. Extensive experiments demonstrate that our\nmethod outperforms state-of-the-art approaches by average 2.61% $F_1$ across\nvarious settings of two FSDLRE benchmarks.",
            "author": [
                "Shiao Meng",
                "Xuming Hu",
                "Aiwei Liu",
                "Shu'ang Li",
                "Fukun Ma",
                "Yawen Yang",
                "Lijie Wen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15743v1",
                "http://arxiv.org/pdf/2310.15743v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "68T50",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15742v2",
            "title": "Improving Diffusion Models for ECG Imputation with an Augmented Template\n  Prior",
            "updated": "2023-11-14T12:02:43Z",
            "published": "2023-10-24T11:34:15Z",
            "summary": "Pulsative signals such as the electrocardiogram (ECG) are extensively\ncollected as part of routine clinical care. However, noisy and poor-quality\nrecordings are a major issue for signals collected using mobile health systems,\ndecreasing the signal quality, leading to missing values, and affecting\nautomated downstream tasks. Recent studies have explored the imputation of\nmissing values in ECG with probabilistic time-series models. Nevertheless, in\ncomparison with the deterministic models, their performance is still limited,\nas the variations across subjects and heart-beat relationships are not\nexplicitly considered in the training objective. In this work, to improve the\nimputation and forecasting accuracy for ECG with probabilistic models, we\npresent a template-guided denoising diffusion probabilistic model (DDPM),\nPulseDiff, which is conditioned on an informative prior for a range of health\nconditions. Specifically, 1) we first extract a subject-level pulsative\ntemplate from the observed values to use as an informative prior of the missing\nvalues, which personalises the prior; 2) we then add beat-level stochastic\nshift terms to augment the prior, which considers variations in the position\nand amplitude of the prior at each beat; 3) we finally design a confidence\nscore to consider the health condition of the subject, which ensures our prior\nis provided safely. Experiments with the PTBXL dataset reveal that PulseDiff\nimproves the performance of two strong DDPM baseline models, CSDI and\nSSSD$^{S4}$, verifying that our method guides the generation of DDPMs while\nmanaging the uncertainty. When combined with SSSD$^{S4}$, PulseDiff outperforms\nthe leading deterministic model for short-interval missing data and is\ncomparable for long-interval data loss.",
            "author": [
                "Alexander Jenkins",
                "Zehua Chen",
                "Fu Siong Ng",
                "Danilo Mandic"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15742v2",
                "http://arxiv.org/pdf/2310.15742v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16065v1",
            "title": "The Hyperdimensional Transform: a Holographic Representation of\n  Functions",
            "updated": "2023-10-24T11:33:39Z",
            "published": "2023-10-24T11:33:39Z",
            "summary": "Integral transforms are invaluable mathematical tools to map functions into\nspaces where they are easier to characterize. We introduce the hyperdimensional\ntransform as a new kind of integral transform. It converts square-integrable\nfunctions into noise-robust, holographic, high-dimensional representations\ncalled hyperdimensional vectors. The central idea is to approximate a function\nby a linear combination of random functions. We formally introduce a set of\nstochastic, orthogonal basis functions and define the hyperdimensional\ntransform and its inverse. We discuss general transform-related properties such\nas its uniqueness, approximation properties of the inverse transform, and the\nrepresentation of integrals and derivatives. The hyperdimensional transform\noffers a powerful, flexible framework that connects closely with other integral\ntransforms, such as the Fourier, Laplace, and fuzzy transforms. Moreover, it\nprovides theoretical foundations and new insights for the field of\nhyperdimensional computing, a computing paradigm that is rapidly gaining\nattention for efficient and explainable machine learning algorithms, with\npotential applications in statistical modelling and machine learning. In\naddition, we provide straightforward and easily understandable code, which can\nfunction as a tutorial and allows for the reproduction of the demonstrated\nexamples, from computing the transform to solving differential equations.",
            "author": [
                "Pieter Dewulf",
                "Michiel Stock",
                "Bernard De Baets"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16065v1",
                "http://arxiv.org/pdf/2310.16065v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15741v1",
            "title": "Interpretable Medical Image Classification using Prototype Learning and\n  Privileged Information",
            "updated": "2023-10-24T11:28:59Z",
            "published": "2023-10-24T11:28:59Z",
            "summary": "Interpretability is often an essential requirement in medical imaging.\nAdvanced deep learning methods are required to address this need for\nexplainability and high performance. In this work, we investigate whether\nadditional information available during the training process can be used to\ncreate an understandable and powerful model. We propose an innovative solution\ncalled Proto-Caps that leverages the benefits of capsule networks, prototype\nlearning and the use of privileged information. Evaluating the proposed\nsolution on the LIDC-IDRI dataset shows that it combines increased\ninterpretability with above state-of-the-art prediction performance. Compared\nto the explainable baseline model, our method achieves more than 6 % higher\naccuracy in predicting both malignancy (93.0 %) and mean characteristic\nfeatures of lung nodules. Simultaneously, the model provides case-based\nreasoning with prototype representations that allow visual validation of\nradiologist-defined attributes.",
            "author": [
                "Luisa Gallee",
                "Meinrad Beer",
                "Michael Goetz"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-43895-0_41",
                "http://arxiv.org/abs/2310.15741v1",
                "http://arxiv.org/pdf/2310.15741v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15723v1",
            "title": "Data Processing Engine (DPE): Data Analysis Tool for Particle Tracking\n  and Mixed Radiation Field Characterization with Pixel Detectors Timepix",
            "updated": "2023-10-24T10:59:43Z",
            "published": "2023-10-24T10:59:43Z",
            "summary": "Hybrid semiconductor pixelated detectors from the Timepix family are advanced\ndetectors for online particle tracking, offering energy measurement and precise\ntime stamping capabilities for particles of various types and energies. This\ninherent capability makes them highly suitable for various applications,\nincluding imaging, medical fields such as radiotherapy and particle therapy,\nspace-based applications aboard satellites and the International Space Station,\nand industrial applications. The data generated by these detectors is complex,\nnecessitating the development and deployment of various analytical techniques\nto extract essential information. For this purpose, and to aid the Timepix user\ncommunity, it was designed and developed the \"Data Processing Engine\" (DPE) as\nan advanced tool for data processing designed explicitly for Timepix detectors.\nThe functionality of the DPE is structured into three distinct processing\nlevels: i) Pre-processing: This phase involves clusterization and the\napplication of necessary calibrations and corrections. ii) Processing: This\nstage includes particle classification, employing machine learning algorithms,\nand the recognition of radiation fields. iii) Post-processing: Involves various\nanalyses, such as directional analysis, coincidence analysis, frame analysis,\nCompton directional analysis, and the generation of physics products, are\nperformed. The core of the DPE is supported by an extensive experimental\ndatabase containing calibrations and referential radiation fields of typical\nenvironments, including protons, ions, electrons, gamma rays and X-rays, as\nwell as thermal and fast neutrons. To enhance accessibility, the DPE is\nimplemented into various user interface platforms such as a command-line tool,\nan application programming interface, and as a graphical user interface in the\nform of a web portal.",
            "author": [
                "Marek Lukas",
                "Granja Carlos",
                "Jakubek Jan",
                "Ingerle Jan",
                "Turecek Daniel",
                "Vuolo Marco",
                "Oancea Cristina"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15723v1",
                "http://arxiv.org/pdf/2310.15723v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15722v1",
            "title": "Re-Temp: Relation-Aware Temporal Representation Learning for Temporal\n  Knowledge Graph Completion",
            "updated": "2023-10-24T10:58:33Z",
            "published": "2023-10-24T10:58:33Z",
            "summary": "Temporal Knowledge Graph Completion (TKGC) under the extrapolation setting\naims to predict the missing entity from a fact in the future, posing a\nchallenge that aligns more closely with real-world prediction problems.\nExisting research mostly encodes entities and relations using sequential graph\nneural networks applied to recent snapshots. However, these approaches tend to\noverlook the ability to skip irrelevant snapshots according to entity-related\nrelations in the query and disregard the importance of explicit temporal\ninformation. To address this, we propose our model, Re-Temp (Relation-Aware\nTemporal Representation Learning), which leverages explicit temporal embedding\nas input and incorporates skip information flow after each timestamp to skip\nunnecessary information for prediction. Additionally, we introduce a two-phase\nforward propagation method to prevent information leakage. Through the\nevaluation on six TKGC (extrapolation) datasets, we demonstrate that our model\noutperforms all eight recent state-of-the-art models by a significant margin.",
            "author": [
                "Kunze Wang",
                "Soyeon Caren Han",
                "Josiah Poon"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15722v1",
                "http://arxiv.org/pdf/2310.15722v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15720v2",
            "title": "Ensemble of Task-Specific Language Models for Brain Encoding",
            "updated": "2023-11-09T07:03:54Z",
            "published": "2023-10-24T10:52:41Z",
            "summary": "Language models have been shown to be rich enough to encode fMRI activations\nof certain Regions of Interest in our Brains. Previous works have explored\ntransfer learning from representations learned for popular natural language\nprocessing tasks for predicting brain responses. In our work, we improve the\nperformance of such encoders by creating an ensemble model out of 10 popular\nLanguage Models (2 syntactic and 8 semantic). We beat the current baselines by\n10% on average across all ROIs through our ensembling methods.",
            "author": [
                "Arvindh Arun",
                "Jerrin John",
                "Sanjai Kumaran"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15720v2",
                "http://arxiv.org/pdf/2310.15720v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15719v1",
            "title": "Recurrent Linear Transformers",
            "updated": "2023-10-24T10:51:50Z",
            "published": "2023-10-24T10:51:50Z",
            "summary": "The self-attention mechanism in the transformer architecture is capable of\ncapturing long-range dependencies and it is the main reason behind its\neffectiveness in processing sequential data. Nevertheless, despite their\nsuccess, transformers have two significant drawbacks that still limit their\nbroader applicability: (1) In order to remember past information, the\nself-attention mechanism requires access to the whole history to be provided as\ncontext. (2) The inference cost in transformers is expensive. In this paper we\nintroduce recurrent alternatives to the transformer self-attention mechanism\nthat offer a context-independent inference cost, leverage long-range\ndependencies effectively, and perform well in practice. We evaluate our\napproaches in reinforcement learning problems where the aforementioned\ncomputational limitations make the application of transformers nearly\ninfeasible. We quantify the impact of the different components of our\narchitecture in a diagnostic environment and assess performance gains in 2D and\n3D pixel-based partially-observable environments. When compared to a\nstate-of-the-art architecture, GTrXL, inference in our approach is at least 40%\ncheaper while reducing memory use in more than 50%. Our approach either\nperforms similarly or better than GTrXL, improving more than 37% upon GTrXL\nperformance on harder tasks.",
            "author": [
                "Subhojeet Pramanik",
                "Esraa Elelimy",
                "Marlos C. Machado",
                "Adam White"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15719v1",
                "http://arxiv.org/pdf/2310.15719v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15709v1",
            "title": "Causal Representation Learning Made Identifiable by Grouping of\n  Observational Variables",
            "updated": "2023-10-24T10:38:02Z",
            "published": "2023-10-24T10:38:02Z",
            "summary": "A topic of great current interest is Causal Representation Learning (CRL),\nwhose goal is to learn a causal model for hidden features in a data-driven\nmanner. Unfortunately, CRL is severely ill-posed since it is a combination of\nthe two notoriously ill-posed problems of representation learning and causal\ndiscovery. Yet, finding practical identifiability conditions that guarantee a\nunique solution is crucial for its practical applicability. Most approaches so\nfar have been based on assumptions on the latent causal mechanisms, such as\ntemporal causality, or existence of supervision or interventions; these can be\ntoo restrictive in actual applications. Here, we show identifiability based on\nnovel, weak constraints, which requires no temporal structure, intervention,\nnor weak supervision. The approach is based assuming the observational mixing\nexhibits a suitable grouping of the observational variables. We also propose a\nnovel self-supervised estimation framework consistent with the model, prove its\nstatistical consistency, and experimentally show its superior CRL performances\ncompared to the state-of-the-art baselines. We further demonstrate its\nrobustness against latent confounders and causal cycles.",
            "author": [
                "Hiroshi Morioka",
                "Aapo Hyv\u00e4rinen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15709v1",
                "http://arxiv.org/pdf/2310.15709v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10737v1",
            "title": "AI-enhanced Auto-correction of Programming Exercises: How Effective is\n  GPT-3.5?",
            "updated": "2023-10-24T10:35:36Z",
            "published": "2023-10-24T10:35:36Z",
            "summary": "Timely formative feedback is considered as one of the most important drivers\nfor effective learning. Delivering timely and individualized feedback is\nparticularly challenging in large classes in higher education. Recently Large\nLanguage Models such as GPT-3 became available to the public that showed\npromising results on various tasks such as code generation and code\nexplanation. This paper investigates the potential of AI in providing\npersonalized code correction and generating feedback. Based on existing student\nsubmissions of two different real-world assignments, the correctness of the\nAI-aided e-assessment as well as the characteristics such as fault\nlocalization, correctness of hints, and code style suggestions of the generated\nfeedback are investigated. The results show that 73 % of the submissions were\ncorrectly identified as either correct or incorrect. In 59 % of these cases,\nGPT-3.5 also successfully generated effective and high-quality feedback.\nAdditionally, GPT-3.5 exhibited weaknesses in its evaluation, including\nlocalization of errors that were not the actual errors, or even hallucinated\nerrors. Implications and potential new usage scenarios are discussed.",
            "author": [
                "Imen Azaiz",
                "Oliver Deckarm",
                "Sven Strickroth"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10737v1",
                "http://arxiv.org/pdf/2311.10737v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.HC",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15706v1",
            "title": "Solving large flexible job shop scheduling instances by generating a\n  diverse set of scheduling policies with deep reinforcement learning",
            "updated": "2023-10-24T10:35:08Z",
            "published": "2023-10-24T10:35:08Z",
            "summary": "The Flexible Job Shop Scheduling Problem (FJSSP) has been extensively studied\nin the literature, and multiple approaches have been proposed within the\nheuristic, exact, and metaheuristic methods. However, the industry's demand to\nbe able to respond in real-time to disruptive events has generated the\nnecessity to be able to generate new schedules within a few seconds. Among\nthese methods, under this constraint, only dispatching rules (DRs) are capable\nof generating schedules, even though their quality can be improved. To improve\nthe results, recent methods have been proposed for modeling the FJSSP as a\nMarkov Decision Process (MDP) and employing reinforcement learning to create a\npolicy that generates an optimal solution assigning operations to machines.\nNonetheless, there is still room for improvement, particularly in the larger\nFJSSP instances which are common in real-world scenarios. Therefore, the\nobjective of this paper is to propose a method capable of robustly solving\nlarge instances of the FJSSP. To achieve this, we propose a novel way of\nmodeling the FJSSP as an MDP using graph neural networks. We also present two\nmethods to make inference more robust: generating a diverse set of scheduling\npolicies that can be parallelized and limiting them using DRs. We have tested\nour approach on synthetically generated instances and various public benchmarks\nand found that our approach outperforms dispatching rules and achieves better\nresults than three other recent deep reinforcement learning methods on larger\nFJSSP instances.",
            "author": [
                "Imanol Echeverria",
                "Maialen Murua",
                "Roberto Santana"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15706v1",
                "http://arxiv.org/pdf/2310.15706v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15705v1",
            "title": "Learning-based Scheduling for Information Accuracy and Freshness in\n  Wireless Networks",
            "updated": "2023-10-24T10:31:34Z",
            "published": "2023-10-24T10:31:34Z",
            "summary": "We consider a system of multiple sources, a single communication channel, and\na single monitoring station. Each source measures a time-varying quantity with\nvarying levels of accuracy and one of them sends its update to the monitoring\nstation via the channel. The probability of success of each attempted\ncommunication is a function of the source scheduled for transmitting its\nupdate. Both the probability of correct measurement and the probability of\nsuccessful transmission of all the sources are unknown to the scheduler. The\nmetric of interest is the reward received by the system which depends on the\naccuracy of the last update received by the destination and the\nAge-of-Information (AoI) of the system. We model our scheduling problem as a\nvariant of the multi-arm bandit problem with sources as different arms. We\ncompare the performance of all $4$ standard bandit policies, namely, ETC,\n$\\epsilon$-greedy, UCB, and TS suitably adjusted to our system model via\nsimulations. In addition, we provide analytical guarantees of $2$ of these\npolicies, ETC, and $\\epsilon$-greedy. Finally, we characterize the lower bound\non the cumulative regret achievable by any policy.",
            "author": [
                "Hitesh Gudwani"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15705v1",
                "http://arxiv.org/pdf/2310.15705v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15699v2",
            "title": "DACOOP-A: Decentralized Adaptive Cooperative Pursuit via Attention",
            "updated": "2023-10-28T13:47:41Z",
            "published": "2023-10-24T10:15:07Z",
            "summary": "Integrating rule-based policies into reinforcement learning promises to\nimprove data efficiency and generalization in cooperative pursuit problems.\nHowever, most implementations do not properly distinguish the influence of\nneighboring robots in observation embedding or inter-robot interaction rules,\nleading to information loss and inefficient cooperation. This paper proposes a\ncooperative pursuit algorithm named Decentralized Adaptive COOperative Pursuit\nvia Attention (DACOOP-A) by empowering reinforcement learning with artificial\npotential field and attention mechanisms. An attention-based framework is\ndeveloped to emphasize important neighbors by concurrently integrating the\nlearned attention scores into observation embedding and inter-robot interaction\nrules. A KL divergence regularization is introduced to alleviate the resultant\nlearning stability issue. Improvements in data efficiency and generalization\nare demonstrated through numerical simulations. Extensive quantitative analysis\nand ablation studies are performed to illustrate the advantages of the proposed\nmodules. Real-world experiments are performed to justify the feasibility of\ndeploying DACOOP-A in physical systems.",
            "author": [
                "Zheng Zhang",
                "Dengyu Zhang",
                "Qingrui Zhang",
                "Wei Pan",
                "Tianjiang Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15699v2",
                "http://arxiv.org/pdf/2310.15699v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15694v4",
            "title": "COPF: Continual Learning Human Preference through Optimal Policy Fitting",
            "updated": "2023-10-28T02:00:39Z",
            "published": "2023-10-24T10:05:32Z",
            "summary": "The technique of Reinforcement Learning from Human Feedback (RLHF) is a\ncommonly employed method to improve pre-trained Language Models (LM), enhancing\ntheir ability to conform to human preferences. Nevertheless, the current\nRLHF-based LMs necessitate full retraining each time novel queries or feedback\nare introduced, which becomes a challenging task because human preferences can\nvary between different domains or tasks. Retraining LMs poses practical\ndifficulties in many real-world situations due to the significant time and\ncomputational resources required, along with concerns related to data privacy.\nTo address this limitation, we propose a new method called Continual Optimal\nPolicy Fitting (COPF), in which we estimate a series of optimal policies using\nthe Monte Carlo method, and then continually fit the policy sequence with the\nfunction regularization. COPF involves a single learning phase and doesn't\nnecessitate complex reinforcement learning. Importantly, it shares the\ncapability with RLHF to learn from unlabeled data, making it flexible for\ncontinual preference learning. Our experimental results show that COPF\noutperforms strong Continuous learning (CL) baselines when it comes to\nconsistently aligning with human preferences on different tasks and domains.",
            "author": [
                "Han Zhang",
                "Lin Gui",
                "Yuanzhao Zhai",
                "Hui Wang",
                "Yu Lei",
                "Ruifeng Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15694v4",
                "http://arxiv.org/pdf/2310.15694v4"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15693v1",
            "title": "Towards Automated Recipe Genre Classification using Semi-Supervised\n  Learning",
            "updated": "2023-10-24T10:03:27Z",
            "published": "2023-10-24T10:03:27Z",
            "summary": "Sharing cooking recipes is a great way to exchange culinary ideas and provide\ninstructions for food preparation. However, categorizing raw recipes found\nonline into appropriate food genres can be challenging due to a lack of\nadequate labeled data. In this study, we present a dataset named the\n``Assorted, Archetypal, and Annotated Two Million Extended (3A2M+) Cooking\nRecipe Dataset\" that contains two million culinary recipes labeled in\nrespective categories with extended named entities extracted from recipe\ndescriptions. This collection of data includes various features such as title,\nNER, directions, and extended NER, as well as nine different labels\nrepresenting genres including bakery, drinks, non-veg, vegetables, fast food,\ncereals, meals, sides, and fusions. The proposed pipeline named 3A2M+ extends\nthe size of the Named Entity Recognition (NER) list to address missing named\nentities like heat, time or process from the recipe directions using two NER\nextraction tools. 3A2M+ dataset provides a comprehensive solution to the\nvarious challenging recipe-related tasks, including classification, named\nentity recognition, and recipe generation. Furthermore, we have demonstrated\ntraditional machine learning, deep learning and pre-trained language models to\nclassify the recipes into their corresponding genre and achieved an overall\naccuracy of 98.6\\%. Our investigation indicates that the title feature played a\nmore significant role in classifying the genre.",
            "author": [
                "Nazmus Sakib",
                "G. M. Shahariar",
                "Md. Mohsinul Kabir",
                "Md. Kamrul Hasan",
                "Hasan Mahmud"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15693v1",
                "http://arxiv.org/pdf/2310.15693v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15690v1",
            "title": "Physics-Informed with Power-Enhanced Residual Network for Interpolation\n  and Inverse Problems",
            "updated": "2023-10-24T10:01:15Z",
            "published": "2023-10-24T10:01:15Z",
            "summary": "This paper introduces a novel neural network structure called the\nPower-Enhancing residual network, designed to improve interpolation\ncapabilities for both smooth and non-smooth functions in 2D and 3D settings. By\nadding power terms to residual elements, the architecture boosts the network's\nexpressive power. The study explores network depth, width, and optimization\nmethods, showing the architecture's adaptability and performance advantages.\nConsistently, the results emphasize the exceptional accuracy of the proposed\nPower-Enhancing residual network, particularly for non-smooth functions.\nReal-world examples also confirm its superiority over plain neural network in\nterms of accuracy, convergence, and efficiency. The study also looks at the\nimpact of deeper network. Moreover, the proposed architecture is also applied\nto solving the inverse Burgers' equation, demonstrating superior performance.\nIn conclusion, the Power-Enhancing residual network offers a versatile solution\nthat significantly enhances neural network capabilities. The codes implemented\nare available at: \\url{https://github.com/CMMAi/ResNet_for_PINN}.",
            "author": [
                "Amir Noorizadegan",
                "D. L. Young",
                "Y. C. Hon",
                "C. S. Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15690v1",
                "http://arxiv.org/pdf/2310.15690v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "math.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15688v1",
            "title": "Nighttime Thermal Infrared Image Colorization with Feedback-based Object\n  Appearance Learning",
            "updated": "2023-10-24T09:59:55Z",
            "published": "2023-10-24T09:59:55Z",
            "summary": "Stable imaging in adverse environments (e.g., total darkness) makes thermal\ninfrared (TIR) cameras a prevalent option for night scene perception. However,\nthe low contrast and lack of chromaticity of TIR images are detrimental to\nhuman interpretation and subsequent deployment of RGB-based vision algorithms.\nTherefore, it makes sense to colorize the nighttime TIR images by translating\nthem into the corresponding daytime color images (NTIR2DC). Despite the\nimpressive progress made in the NTIR2DC task, how to improve the translation\nperformance of small object classes is under-explored. To address this problem,\nwe propose a generative adversarial network incorporating feedback-based object\nappearance learning (FoalGAN). Specifically, an occlusion-aware mixup module\nand corresponding appearance consistency loss are proposed to reduce the\ncontext dependence of object translation. As a representative example of small\nobjects in nighttime street scenes, we illustrate how to enhance the realism of\ntraffic light by designing a traffic light appearance loss. To further improve\nthe appearance learning of small objects, we devise a dual feedback learning\nstrategy to selectively adjust the learning frequency of different samples. In\naddition, we provide pixel-level annotation for a subset of the Brno dataset,\nwhich can facilitate the research of NTIR image understanding under multiple\nweather conditions. Extensive experiments illustrate that the proposed FoalGAN\nis not only effective for appearance learning of small objects, but also\noutperforms other image translation methods in terms of semantic preservation\nand edge consistency for the NTIR2DC task.",
            "author": [
                "Fu-Ya Luo",
                "Shu-Lin Liu",
                "Yi-Jun Cao",
                "Kai-Fu Yang",
                "Chang-Yong Xie",
                "Yong Liu",
                "Yong-Jie Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15688v1",
                "http://arxiv.org/pdf/2310.15688v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15681v2",
            "title": "Fixed-Budget Real-Valued Combinatorial Pure Exploration of Multi-Armed\n  Bandit",
            "updated": "2023-11-15T11:10:12Z",
            "published": "2023-10-24T09:47:32Z",
            "summary": "We study the real-valued combinatorial pure exploration of the multi-armed\nbandit in the fixed-budget setting. We first introduce the Combinatorial\nSuccessive Asign (CSA) algorithm, which is the first algorithm that can\nidentify the best action even when the size of the action class is\nexponentially large with respect to the number of arms. We show that the upper\nbound of the probability of error of the CSA algorithm matches a lower bound up\nto a logarithmic factor in the exponent. Then, we introduce another algorithm\nnamed the Minimax Combinatorial Successive Accepts and Rejects\n(Minimax-CombSAR) algorithm for the case where the size of the action class is\npolynomial, and show that it is optimal, which matches a lower bound. Finally,\nwe experimentally compare the algorithms with previous methods and show that\nour algorithm performs better.",
            "author": [
                "Shintaro Nakamura",
                "Masashi Sugiyama"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15681v2",
                "http://arxiv.org/pdf/2310.15681v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15679v1",
            "title": "Mechanism of charge transport in lithium thiophosphate",
            "updated": "2023-10-24T09:43:09Z",
            "published": "2023-10-24T09:43:09Z",
            "summary": "Lithium ortho-thiophosphate ($\\textrm{Li}_3\\textrm{PS}_4$) has emerged as a\npromising candidate for solid-state-electrolyte batteries, thanks to its highly\nconductive phases, cheap components, and large electrochemical stability range.\nNonetheless, the microscopic mechanisms of Li-ion transport in\n$\\textrm{Li}_3\\textrm{PS}_4$ are far to be fully understood, the role of\n$\\textrm{PS}_4$ dynamics in charge transport still being controversial. In this\nwork, we build machine learning potentials targeting state-of-the-art DFT\nreferences (PBEsol, r$^2$SCAN, and PBE0) to tackle this problem in all known\nphases of $\\textrm{Li}_3\\textrm{PS}_4$ ($\\alpha$, $\\beta$ and $\\gamma$), for\nlarge system sizes and timescales. We discuss the physical origin of the\nobserved superionic behavior of $\\textrm{Li}_3\\textrm{PS}_4$: the activation of\n$\\textrm{PS}_4$ flipping drives a structural transition to a highly conductive\nphase, characterized by an increase of Li-site availability and by a drastic\nreduction in the activation energy of Li-ion diffusion. We also rule out any\npaddle-wheel effects of $\\textrm{PS}_4$ tetrahedra in the superionic phases --\npreviously claimed to enhance Li-ion diffusion -- due to the\norders-of-magnitude difference between the rate of $\\textrm{PS}_4$ flips and\nLi-ion hops at all temperatures below melting. We finally elucidate the role of\ninter-ionic dynamical correlations in charge transport, by highlighting the\nfailure of the Nernst-Einstein approximation to estimate the electrical\nconductivity. Our results show a strong dependence on the target DFT reference,\nwith PBE0 yielding the best quantitative agreement with experimental\nmeasurements not only for the electronic band-gap but also for the electrical\nconductivity of $\\beta$- and $\\alpha$-$\\textrm{Li}_3\\textrm{PS}_4$.",
            "author": [
                "Lorenzo Gigli",
                "Davide Tisi",
                "Federico Grasselli",
                "Michele Ceriotti"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15679v1",
                "http://arxiv.org/pdf/2310.15679v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15677v1",
            "title": "Robot-Relay : Building-Wide, Calibration-Less Visual Servoing with\n  Learned Sensor Handover Network",
            "updated": "2023-10-24T09:41:23Z",
            "published": "2023-10-24T09:41:23Z",
            "summary": "We present a system which grows and manages a network of remote viewpoints\nduring the natural installation cycle for a newly installed camera network or a\nnewly deployed robot fleet. No explicit notion of camera position or\norientation is required, neither global - i.e. relative to a building plan -\nnor local - i.e. relative to an interesting point in a room. Furthermore, no\nmetric relationship between viewpoints is required. Instead, we leverage our\nprior work in effective remote control without extrinsic or intrinsic\ncalibration and extend it to the multi-camera setting. In this, we memorise,\nfrom simultaneous robot detections in the tracker thread, soft pixel-wise\ntopological connections between viewpoints. We demonstrate our system with\nrepeated autonomous traversals of workspaces connected by a network of six\ncameras across a productive office environment.",
            "author": [
                "Luke Robinson",
                "Matthew Gadd",
                "Paul Newman",
                "Daniele De Martini"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15677v1",
                "http://arxiv.org/pdf/2310.15677v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15674v1",
            "title": "IceCube -- Neutrinos in Deep Ice The Top 3 Solutions from the Public\n  Kaggle Competition",
            "updated": "2023-10-24T09:36:29Z",
            "published": "2023-10-24T09:36:29Z",
            "summary": "During the public Kaggle competition \"IceCube -- Neutrinos in Deep Ice\",\nthousands of reconstruction algorithms were created and submitted, aiming to\nestimate the direction of neutrino events recorded by the IceCube detector.\nHere we describe in detail the three ultimate best, award-winning solutions.\nThe data handling, architecture, and training process of each of these machine\nlearning models is laid out, followed up by an in-depth comparison of the\nperformance on the kaggle datatset. We show that on cascade events in IceCube\nabove 10 TeV, the best kaggle solution is able to achieve an angular resolution\nof better than 5 degrees, and for tracks correspondingly better than 0.5\ndegrees. These performance measures compare favourably to the current\nstate-of-the-art in the field.",
            "author": [
                "Habib Bukhari",
                "Dipam Chakraborty",
                "Philipp Eller",
                "Takuya Ito",
                "Maxim V. Shugaev",
                "Rasmus \u00d8rs\u00f8e"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15674v1",
                "http://arxiv.org/pdf/2310.15674v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "hep-ex",
                "physics.data-an"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15671v2",
            "title": "Quality flags for GSP-Phot Gaia DR3 astrophysical parameters with\n  machine learning: Effective temperatures case study",
            "updated": "2023-11-17T14:32:19Z",
            "published": "2023-10-24T09:30:59Z",
            "summary": "Gaia Data Release 3 (DR3) provides extensive information on the astrophysical\nproperties of stars, such as effective temperature, surface gravity,\nmetallicity, and luminosity, for over 470 million objects. However, as Gaia's\nstellar parameters in GSP-Phot module are derived through model-dependent\nmethods and indirect measurements, it can lead to additional systematic errors\nin the derived parameters. In this study, we compare GSP-Phot effective\ntemperature estimates with two high-resolution and high signal-to-noise\nspectroscopic catalogues: APOGEE DR17 and GALAH DR3, aiming to assess the\nreliability of Gaia's temperatures. We introduce an approach to distinguish\ngood-quality Gaia DR3 effective temperatures using machine-learning methods\nsuch as XGBoost, CatBoost and LightGBM. The models create quality flags, which\ncan help one to distinguish good-quality GSP-Phot effective temperatures. We\ntest our models on three independent datasets, including PASTEL, a compilation\nof spectroscopically derived stellar parameters from different high-resolution\nstudies. The results of the test suggest that with these models it is possible\nto filter effective temperatures as accurate as 250 K with ~ 90 per cent\nprecision even in complex regions, such as the Galactic plane. Consequently,\nthe models developed herein offer a valuable quality assessment tool for\nGSP-Phot effective temperatures in Gaia DR3. Consequently, the developed models\noffer a valuable quality assessment tool for GSP-Phot effective temperatures in\nGaia DR3. The dataset with flags for all GSP-Phot effective temperature\nestimates, is publicly available, as are the models themselves.",
            "author": [
                "Aleksandra S. Avdeeva",
                "Dana A. Kovaleva",
                "Oleg Yu. Malkov",
                "Gang Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15671v2",
                "http://arxiv.org/pdf/2310.15671v2"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.EP",
                "astro-ph.GA",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15664v1",
            "title": "Expression Syntax Information Bottleneck for Math Word Problems",
            "updated": "2023-10-24T09:23:57Z",
            "published": "2023-10-24T09:23:57Z",
            "summary": "Math Word Problems (MWP) aims to automatically solve mathematical questions\ngiven in texts. Previous studies tend to design complex models to capture\nadditional information in the original text so as to enable the model to gain\nmore comprehensive features. In this paper, we turn our attention in the\nopposite direction, and work on how to discard redundant features containing\nspurious correlations for MWP. To this end, we design an Expression Syntax\nInformation Bottleneck method for MWP (called ESIB) based on variational\ninformation bottleneck, which extracts essential features of expression syntax\ntree while filtering latent-specific redundancy containing syntax-irrelevant\nfeatures. The key idea of ESIB is to encourage multiple models to predict the\nsame expression syntax tree for different problem representations of the same\nproblem by mutual learning so as to capture consistent information of\nexpression syntax tree and discard latent-specific redundancy. To improve the\ngeneralization ability of the model and generate more diverse expressions, we\ndesign a self-distillation loss to encourage the model to rely more on the\nexpression syntax information in the latent space. Experimental results on two\nlarge-scale benchmarks show that our model not only achieves state-of-the-art\nresults but also generates more diverse solutions. The code is available.",
            "author": [
                "Jing Xiong",
                "Chengming Li",
                "Min Yang",
                "Xiping Hu",
                "Bin Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15664v1",
                "http://arxiv.org/pdf/2310.15664v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15662v1",
            "title": "Interactive Generalized Additive Model and Its Applications in Electric\n  Load Forecasting",
            "updated": "2023-10-24T09:17:47Z",
            "published": "2023-10-24T09:17:47Z",
            "summary": "Electric load forecasting is an indispensable component of electric power\nsystem planning and management. Inaccurate load forecasting may lead to the\nthreat of outages or a waste of energy. Accurate electric load forecasting is\nchallenging when there is limited data or even no data, such as load\nforecasting in holiday, or under extreme weather conditions. As high-stakes\ndecision-making usually follows after load forecasting, model interpretability\nis crucial for the adoption of forecasting models. In this paper, we propose an\ninteractive GAM which is not only interpretable but also can incorporate\nspecific domain knowledge in electric power industry for improved performance.\nThis boosting-based GAM leverages piecewise linear functions and can be learned\nthrough our efficient algorithm. In both public benchmark and electricity\ndatasets, our interactive GAM outperforms current state-of-the-art methods and\ndemonstrates good generalization ability in the cases of extreme weather\nevents. We launched a user-friendly web-based tool based on interactive GAM and\nalready incorporated it into our eForecaster product, a unified AI platform for\nelectricity forecasting.",
            "author": [
                "Linxiao Yang",
                "Rui Ren",
                "Xinyue Gu",
                "Liang Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15662v1",
                "http://arxiv.org/pdf/2310.15662v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16063v1",
            "title": "Enhancing Traffic Prediction with Learnable Filter Module",
            "updated": "2023-10-24T09:16:13Z",
            "published": "2023-10-24T09:16:13Z",
            "summary": "Modeling future traffic conditions often relies heavily on complex\nspatial-temporal neural networks to capture spatial and temporal correlations,\nwhich can overlook the inherent noise in the data. This noise, often\nmanifesting as unexpected short-term peaks or drops in traffic observation, is\ntypically caused by traffic accidents or inherent sensor vibration. In\npractice, such noise can be challenging to model due to its stochastic nature\nand can lead to overfitting risks if a neural network is designed to learn this\nbehavior. To address this issue, we propose a learnable filter module to filter\nout noise in traffic data adaptively. This module leverages the Fourier\ntransform to convert the data to the frequency domain, where noise is filtered\nbased on its pattern. The denoised data is then recovered to the time domain\nusing the inverse Fourier transform. Our approach focuses on enhancing the\nquality of the input data for traffic prediction models, which is a critical\nyet often overlooked aspect in the field. We demonstrate that the proposed\nmodule is lightweight, easy to integrate with existing models, and can\nsignificantly improve traffic prediction performance. Furthermore, we validate\nour approach with extensive experimental results on real-world datasets,\nshowing that it effectively mitigates noise and enhances prediction accuracy.",
            "author": [
                "Yuanshao Zhu",
                "Yongchao Ye",
                "Xiangyu Zhao",
                "James J. Q. Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16063v1",
                "http://arxiv.org/pdf/2310.16063v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16062v1",
            "title": "Confounder Balancing in Adversarial Domain Adaptation for Pre-Trained\n  Large Models Fine-Tuning",
            "updated": "2023-10-24T09:11:45Z",
            "published": "2023-10-24T09:11:45Z",
            "summary": "The excellent generalization, contextual learning, and emergence abilities in\nthe pre-trained large models (PLMs) handle specific tasks without direct\ntraining data, making them the better foundation models in the adversarial\ndomain adaptation (ADA) methods to transfer knowledge learned from the source\ndomain to target domains. However, existing ADA methods fail to account for the\nconfounder properly, which is the root cause of the source data distribution\nthat differs from the target domains. This study proposes an adversarial domain\nadaptation with confounder balancing for PLMs fine-tuning (ADA-CBF). The\nADA-CBF includes a PLM as the foundation model for a feature extractor, a\ndomain classifier and a confounder classifier, and they are jointly trained\nwith an adversarial loss. This loss is designed to improve the domain-invariant\nrepresentation learning by diluting the discrimination in the domain\nclassifier. At the same time, the adversarial loss also balances the confounder\ndistribution among source and unmeasured domains in training. Compared to\nexisting ADA methods, ADA-CBF can correctly identify confounders in\ndomain-invariant features, thereby eliminating the confounder biases in the\nextracted features from PLMs. The confounder classifier in ADA-CBF is designed\nas a plug-and-play and can be applied in the confounder measurable,\nunmeasurable, or partially measurable environments. Empirical results on\nnatural language processing and computer vision downstream tasks show that\nADA-CBF outperforms the newest GPT-4, LLaMA2, ViT and ADA methods.",
            "author": [
                "Shuoran Jiang",
                "Qingcai Chen",
                "Yang Xiang",
                "Youcheng Pan",
                "Xiangping Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16062v1",
                "http://arxiv.org/pdf/2310.16062v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15657v1",
            "title": "Testing the Limits: Unusual Text Inputs Generation for Mobile App Crash\n  Detection with Large Language Model",
            "updated": "2023-10-24T09:10:51Z",
            "published": "2023-10-24T09:10:51Z",
            "summary": "Mobile applications have become a ubiquitous part of our daily life,\nproviding users with access to various services and utilities. Text input, as\nan important interaction channel between users and applications, plays an\nimportant role in core functionality such as search queries, authentication,\nmessaging, etc. However, certain special text (e.g., -18 for Font Size) can\ncause the app to crash, and generating diversified unusual inputs for fully\ntesting the app is highly demanded. Nevertheless, this is also challenging due\nto the combination of explosion dilemma, high context sensitivity, and complex\nconstraint relations. This paper proposes InputBlaster which leverages the LLM\nto automatically generate unusual text inputs for mobile app crash detection.\nIt formulates the unusual inputs generation problem as a task of producing a\nset of test generators, each of which can yield a batch of unusual text inputs\nunder the same mutation rule. In detail, InputBlaster leverages LLM to produce\nthe test generators together with the mutation rules serving as the reasoning\nchain, and utilizes the in-context learning schema to demonstrate the LLM with\nexamples for boosting the performance. InputBlaster is evaluated on 36 text\ninput widgets with cash bugs involving 31 popular Android apps, and results\nshow that it achieves 78% bug detection rate, with 136% higher than the best\nbaseline. Besides, we integrate it with the automated GUI testing tool and\ndetect 37 unseen crashes in real-world apps from Google Play.",
            "author": [
                "Zhe Liu",
                "Chunyang Chen",
                "Junjie Wang",
                "Mengzhuo Chen",
                "Boyu Wu",
                "Xing Che",
                "Dandan Wang",
                "Qing Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15657v1",
                "http://arxiv.org/pdf/2310.15657v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15656v1",
            "title": "Momentum Gradient-based Untargeted Attack on Hypergraph Neural Networks",
            "updated": "2023-10-24T09:10:45Z",
            "published": "2023-10-24T09:10:45Z",
            "summary": "Hypergraph Neural Networks (HGNNs) have been successfully applied in various\nhypergraph-related tasks due to their excellent higher-order representation\ncapabilities. Recent works have shown that deep learning models are vulnerable\nto adversarial attacks. Most studies on graph adversarial attacks have focused\non Graph Neural Networks (GNNs), and the study of adversarial attacks on HGNNs\nremains largely unexplored. In this paper, we try to reduce this gap. We design\na new HGNNs attack model for the untargeted attack, namely MGHGA, which focuses\non modifying node features. We consider the process of HGNNs training and use a\nsurrogate model to implement the attack before hypergraph modeling.\nSpecifically, MGHGA consists of two parts: feature selection and feature\nmodification. We use a momentum gradient mechanism to choose the attack node\nfeatures in the feature selection module. In the feature modification module,\nwe use two feature generation approaches (direct modification and sign\ngradient) to enable MGHGA to be employed on discrete and continuous datasets.\nWe conduct extensive experiments on five benchmark datasets to validate the\nattack performance of MGHGA in the node and the visual object classification\ntasks. The results show that MGHGA improves performance by an average of 2%\ncompared to the than the baselines.",
            "author": [
                "Yang Chen",
                "Stjepan Picek",
                "Zhonglin Ye",
                "Zhaoyang Wang",
                "Haixing Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15656v1",
                "http://arxiv.org/pdf/2310.15656v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15654v1",
            "title": "A Survey on Detection of LLMs-Generated Content",
            "updated": "2023-10-24T09:10:26Z",
            "published": "2023-10-24T09:10:26Z",
            "summary": "The burgeoning capabilities of advanced large language models (LLMs) such as\nChatGPT have led to an increase in synthetic content generation with\nimplications across a variety of sectors, including media, cybersecurity,\npublic discourse, and education. As such, the ability to detect LLMs-generated\ncontent has become of paramount importance. We aim to provide a detailed\noverview of existing detection strategies and benchmarks, scrutinizing their\ndifferences and identifying key challenges and prospects in the field,\nadvocating for more adaptable and robust models to enhance detection accuracy.\nWe also posit the necessity for a multi-faceted approach to defend against\nvarious attacks to counter the rapidly advancing capabilities of LLMs. To the\nbest of our knowledge, this work is the first comprehensive survey on the\ndetection in the era of LLMs. We hope it will provide a broad understanding of\nthe current landscape of LLMs-generated content detection, offering a guiding\nreference for researchers and practitioners striving to uphold the integrity of\ndigital information in an era increasingly dominated by synthetic content. The\nrelevant papers are summarized and will be consistently updated at\nhttps://github.com/Xianjun-Yang/Awesome_papers_on_LLMs_detection.git.",
            "author": [
                "Xianjun Yang",
                "Liangming Pan",
                "Xuandong Zhao",
                "Haifeng Chen",
                "Linda Petzold",
                "William Yang Wang",
                "Wei Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15654v1",
                "http://arxiv.org/pdf/2310.15654v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15653v1",
            "title": "Deceptive Fairness Attacks on Graphs via Meta Learning",
            "updated": "2023-10-24T09:10:14Z",
            "published": "2023-10-24T09:10:14Z",
            "summary": "We study deceptive fairness attacks on graphs to answer the following\nquestion: How can we achieve poisoning attacks on a graph learning model to\nexacerbate the bias deceptively? We answer this question via a bi-level\noptimization problem and propose a meta learning-based framework named FATE.\nFATE is broadly applicable with respect to various fairness definitions and\ngraph learning models, as well as arbitrary choices of manipulation operations.\nWe further instantiate FATE to attack statistical parity and individual\nfairness on graph neural networks. We conduct extensive experimental\nevaluations on real-world datasets in the task of semi-supervised node\nclassification. The experimental results demonstrate that FATE could amplify\nthe bias of graph neural networks with or without fairness consideration while\nmaintaining the utility on the downstream task. We hope this paper provides\ninsights into the adversarial robustness of fair graph learning and can shed\nlight on designing robust and fair graph learning in future studies.",
            "author": [
                "Jian Kang",
                "Yinglong Xia",
                "Ross Maciejewski",
                "Jiebo Luo",
                "Hanghang Tong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15653v1",
                "http://arxiv.org/pdf/2310.15653v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15649v1",
            "title": "Probing nuclear physics with supernova gravitational waves and machine\n  learning",
            "updated": "2023-10-24T09:08:22Z",
            "published": "2023-10-24T09:08:22Z",
            "summary": "Core-collapse supernovae are sources of powerful gravitational waves (GWs).\nWe assess the possibility of extracting information about the equation of state\n(EOS) of high density matter from the GW signal. We use the bounce and early\npost-bounce signals of rapidly rotating supernovae. A large set of GW signals\nis generated using general relativistic hydrodynamics simulations for various\nEOS models. The uncertainty in the electron capture rate is parametrized by\ngenerating signals for six different models. To classify EOSs based on the GW\ndata, we train a convolutional neural network (CNN) model. Even with the\nuncertainty in the electron capture rates, we find that the CNN models can\nclassify the EOSs with an average accuracy of about 87 percent for a set of\nfour distinct EOS models.",
            "author": [
                "Ayan Mitra",
                "Daniil Orel",
                "Y. Sultan Abylkairov",
                "Bekdaulet Shukirgaliyev",
                "Ernazar Abdikamalov"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15649v1",
                "http://arxiv.org/pdf/2310.15649v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15648v1",
            "title": "Dynamic Convolutional Neural Networks as Efficient Pre-trained Audio\n  Models",
            "updated": "2023-10-24T09:08:20Z",
            "published": "2023-10-24T09:08:20Z",
            "summary": "The introduction of large-scale audio datasets, such as AudioSet, paved the\nway for Transformers to conquer the audio domain and replace CNNs as the\nstate-of-the-art neural network architecture for many tasks. Audio Spectrogram\nTransformers are excellent at exploiting large datasets, creating powerful\npre-trained models that surpass CNNs when fine-tuned on downstream tasks.\nHowever, current popular Audio Spectrogram Transformers are demanding in terms\nof computational complexity compared to CNNs. Recently, we have shown that, by\nemploying Transformer-to-CNN Knowledge Distillation, efficient CNNs can catch\nup with and even outperform Transformers on large datasets. In this work, we\nextend this line of research and increase the capacity of efficient CNNs by\nintroducing dynamic CNN blocks, constructed of dynamic non-linearities, dynamic\nconvolutions and attention mechanisms. We show that these dynamic CNNs\noutperform traditional efficient CNNs, in terms of the performance-complexity\ntrade-off and parameter efficiency, at the task of audio tagging on the\nlarge-scale AudioSet. Our experiments further indicate that the introduced\ndynamic CNNs achieve better performance on downstream tasks and scale up well,\nattaining Transformer performance and even outperforming them on AudioSet and\nseveral downstream tasks.",
            "author": [
                "Florian Schmid",
                "Khaled Koutini",
                "Gerhard Widmer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15648v1",
                "http://arxiv.org/pdf/2310.15648v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15645v1",
            "title": "Light up that Droid! On the Effectiveness of Static Analysis Features\n  against App Obfuscation for Android Malware Detection",
            "updated": "2023-10-24T09:07:23Z",
            "published": "2023-10-24T09:07:23Z",
            "summary": "Malware authors have seen obfuscation as the mean to bypass malware detectors\nbased on static analysis features. For Android, several studies have confirmed\nthat many anti-malware products are easily evaded with simple program\ntransformations. As opposed to these works, ML detection proposals for Android\nleveraging static analysis features have also been proposed as\nobfuscation-resilient. Therefore, it needs to be determined to what extent the\nuse of a specific obfuscation strategy or tool poses a risk for the validity of\nML malware detectors for Android based on static analysis features. To shed\nsome light in this regard, in this article we assess the impact of specific\nobfuscation techniques on common features extracted using static analysis and\ndetermine whether the changes are significant enough to undermine the\neffectiveness of ML malware detectors that rely on these features. The\nexperimental results suggest that obfuscation techniques affect all static\nanalysis features to varying degrees across different tools. However, certain\nfeatures retain their validity for ML malware detection even in the presence of\nobfuscation. Based on these findings, we propose a ML malware detector for\nAndroid that is robust against obfuscation and outperforms current\nstate-of-the-art detectors.",
            "author": [
                "Borja Molina-Coronado",
                "Antonio Ruggia",
                "Usue Mori",
                "Alessio Merlo",
                "Alexander Mendiburu",
                "Jose Miguel-Alonso"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15645v1",
                "http://arxiv.org/pdf/2310.15645v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15641v1",
            "title": "Guaranteed Coverage Prediction Intervals with Gaussian Process\n  Regression",
            "updated": "2023-10-24T08:59:40Z",
            "published": "2023-10-24T08:59:40Z",
            "summary": "Gaussian Process Regression (GPR) is a popular regression method, which\nunlike most Machine Learning techniques, provides estimates of uncertainty for\nits predictions. These uncertainty estimates however, are based on the\nassumption that the model is well-specified, an assumption that is violated in\nmost practical applications, since the required knowledge is rarely available.\nAs a result, the produced uncertainty estimates can become very misleading; for\nexample the prediction intervals (PIs) produced for the 95\\% confidence level\nmay cover much less than 95\\% of the true labels. To address this issue, this\npaper introduces an extension of GPR based on a Machine Learning framework\ncalled, Conformal Prediction (CP). This extension guarantees the production of\nPIs with the required coverage even when the model is completely misspecified.\nThe proposed approach combines the advantages of GPR with the valid coverage\nguarantee of CP, while the performed experimental results demonstrate its\nsuperiority over existing methods.",
            "author": [
                "Harris Papadopoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15641v1",
                "http://arxiv.org/pdf/2310.15641v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15636v1",
            "title": "Career Path Prediction using Resume Representation Learning and\n  Skill-based Matching",
            "updated": "2023-10-24T08:56:06Z",
            "published": "2023-10-24T08:56:06Z",
            "summary": "The impact of person-job fit on job satisfaction and performance is widely\nacknowledged, which highlights the importance of providing workers with next\nsteps at the right time in their career. This task of predicting the next step\nin a career is known as career path prediction, and has diverse applications\nsuch as turnover prevention and internal job mobility. Existing methods to\ncareer path prediction rely on large amounts of private career history data to\nmodel the interactions between job titles and companies. We propose leveraging\nthe unexplored textual descriptions that are part of work experience sections\nin resumes. We introduce a structured dataset of 2,164 anonymized career\nhistories, annotated with ESCO occupation labels. Based on this dataset, we\npresent a novel representation learning approach, CareerBERT, specifically\ndesigned for work history data. We develop a skill-based model and a text-based\nmodel for career path prediction, which achieve 35.24% and 39.61% recall@10\nrespectively on our dataset. Finally, we show that both approaches are\ncomplementary as a hybrid approach achieves the strongest result with 43.01%\nrecall@10.",
            "author": [
                "Jens-Joris Decorte",
                "Jeroen Van Hautte",
                "Johannes Deleu",
                "Chris Develder",
                "Thomas Demeester"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15636v1",
                "http://arxiv.org/pdf/2310.15636v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15627v1",
            "title": "Contextual directed acyclic graphs",
            "updated": "2023-10-24T08:52:04Z",
            "published": "2023-10-24T08:52:04Z",
            "summary": "Estimating the structure of directed acyclic graphs (DAGs) from observational\ndata remains a significant challenge in machine learning. Most research in this\narea concentrates on learning a single DAG for the entire population. This\npaper considers an alternative setting where the graph structure varies across\nindividuals based on available \"contextual\" features. We tackle this contextual\nDAG problem via a neural network that maps the contextual features to a DAG,\nrepresented as a weighted adjacency matrix. The neural network is equipped with\na novel projection layer that ensures the output matrices are sparse and\nsatisfy a recently developed characterization of acyclicity. We devise a\nscalable computational framework for learning contextual DAGs and provide a\nconvergence guarantee and an analytical gradient for backpropagating through\nthe projection layer. Our experiments suggest that the new approach can recover\nthe true context-specific graph where existing approaches fail.",
            "author": [
                "Ryan Thompson",
                "Edwin V. Bonilla",
                "Robert Kohn"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15627v1",
                "http://arxiv.org/pdf/2310.15627v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15624v1",
            "title": "GUPNet++: Geometry Uncertainty Propagation Network for Monocular 3D\n  Object Detection",
            "updated": "2023-10-24T08:45:15Z",
            "published": "2023-10-24T08:45:15Z",
            "summary": "Geometry plays a significant role in monocular 3D object detection. It can be\nused to estimate object depth by using the perspective projection between\nobject's physical size and 2D projection in the image plane, which can\nintroduce mathematical priors into deep models. However, this projection\nprocess also introduces error amplification, where the error of the estimated\nheight is amplified and reflected into the projected depth. It leads to\nunreliable depth inferences and also impairs training stability. To tackle this\nproblem, we propose a novel Geometry Uncertainty Propagation Network (GUPNet++)\nby modeling geometry projection in a probabilistic manner. This ensures depth\npredictions are well-bounded and associated with a reasonable uncertainty. The\nsignificance of introducing such geometric uncertainty is two-fold: (1). It\nmodels the uncertainty propagation relationship of the geometry projection\nduring training, improving the stability and efficiency of the end-to-end model\nlearning. (2). It can be derived to a highly reliable confidence to indicate\nthe quality of the 3D detection result, enabling more reliable detection\ninference. Experiments show that the proposed approach not only obtains\n(state-of-the-art) SOTA performance in image-based monocular 3D detection but\nalso demonstrates superiority in efficacy with a simplified framework.",
            "author": [
                "Yan Lu",
                "Xinzhu Ma",
                "Lei Yang",
                "Tianzhu Zhang",
                "Yating Liu",
                "Qi Chu",
                "Tong He",
                "Yonghui Li",
                "Wanli Ouyang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15624v1",
                "http://arxiv.org/pdf/2310.15624v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15615v1",
            "title": "Super-resolved rainfall prediction with physics-aware deep learning",
            "updated": "2023-10-24T08:29:28Z",
            "published": "2023-10-24T08:29:28Z",
            "summary": "Rainfall prediction at the kilometre-scale up to a few hours in the future is\nkey for planning and safety. But it is challenging given the complex influence\nof climate change on cloud processes and the limited skill of weather models at\nthis scale. Following the set-up proposed by the \\emph{weather4cast} challenge\nof NeurIPS, we build a two-step deep-learning solution for predicting rainfall\noccurrence at ground radar high spatial resolution starting from coarser\nresolution weather satellite images. Our approach is designed to predict future\nsatellite images with a physics-aware ConvLSTM network, which is then converted\ninto precipitation maps through a U-Net. We find that our two-step pipeline\noutperforms the baseline model and we quantify the benefits of including\nphysical information. We find that local-scale rainfall predictions with good\naccuracy starting from satellite radiances can be obtained for up to 4 hours in\nthe future.",
            "author": [
                "S. Moran",
                "B. Demir",
                "F. Serva",
                "B. Le Saux"
            ],
            "link": [
                "http://dx.doi.org/10.2760/46796",
                "http://arxiv.org/abs/2310.15615v1",
                "http://arxiv.org/pdf/2310.15615v1"
            ],
            "primary_category": "physics.ao-ph",
            "category": [
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15614v2",
            "title": "Sparse Bayesian neural networks for regression: Tackling overfitting and\n  computational challenges in uncertainty quantification",
            "updated": "2023-10-25T17:29:22Z",
            "published": "2023-10-24T08:29:14Z",
            "summary": "Neural networks (NNs) are primarily developed within the frequentist\nstatistical framework. Nevertheless, frequentist NNs lack the capability to\nprovide uncertainties in the predictions, and hence their robustness can not be\nadequately assessed. Conversely, the Bayesian neural networks (BNNs) naturally\noffer predictive uncertainty by applying Bayes' theorem. However, their\ncomputational requirements pose significant challenges. Moreover, both\nfrequentist NNs and BNNs suffer from overfitting issues when dealing with noisy\nand sparse data, which render their predictions unwieldy away from the\navailable data space. To address both these problems simultaneously, we\nleverage insights from a hierarchical setting in which the parameter priors are\nconditional on hyperparameters to construct a BNN by applying a semi-analytical\nframework known as nonlinear sparse Bayesian learning (NSBL). We call our\nnetwork sparse Bayesian neural network (SBNN) which aims to address the\npractical and computational issues associated with BNNs. Simultaneously,\nimposing a sparsity-inducing prior encourages the automatic pruning of\nredundant parameters based on the automatic relevance determination (ARD)\nconcept. This process involves removing redundant parameters by optimally\nselecting the precision of the parameters prior probability density functions\n(pdfs), resulting in a tractable treatment for overfitting. To demonstrate the\nbenefits of the SBNN algorithm, the study presents an illustrative regression\nproblem and compares the results of a BNN using standard Bayesian inference,\nhierarchical Bayesian inference, and a BNN equipped with the proposed\nalgorithm. Subsequently, we demonstrate the importance of considering the full\nparameter posterior by comparing the results with those obtained using the\nLaplace approximation with and without NSBL.",
            "author": [
                "Nastaran Dabiran",
                "Brandon Robinson",
                "Rimple Sandhu",
                "Mohammad Khalil",
                "Dominique Poirel",
                "Abhijit Sarkar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15614v2",
                "http://arxiv.org/pdf/2310.15614v2"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15612v3",
            "title": "Machine Translation for Nko: Tools, Corpora and Baseline Results",
            "updated": "2023-11-15T08:47:28Z",
            "published": "2023-10-24T08:27:56Z",
            "summary": "Currently, there is no usable machine translation system for Nko, a language\nspoken by tens of millions of people across multiple West African countries,\nwhich holds significant cultural and educational value.\n  To address this issue, we present a set of tools, resources, and baseline\nresults aimed towards the development of usable machine translation systems for\nNko and other languages that do not currently have sufficiently large parallel\ntext corpora available.\n  (1) Fria$\\parallel$el: A novel collaborative parallel text curation software\nthat incorporates quality control through copyedit-based workflows.\n  (2) Expansion of the FLoRes-200 and NLLB-Seed corpora with 2,009 and 6,193\nhigh-quality Nko translations in parallel with 204 and 40 other languages.\n  (3) nicolingua-0005: A collection of trilingual and bilingual corpora with\n130,850 parallel segments and monolingual corpora containing over 3 million Nko\nwords.\n  (4) Baseline bilingual and multilingual neural machine translation results\nwith the best model scoring 30.83 English-Nko chrF++ on FLoRes-devtest.",
            "author": [
                "Moussa Koulako Bala Doumbouya",
                "Baba Mamadi Dian\u00e9",
                "Solo Farabado Ciss\u00e9",
                "Djibrila Dian\u00e9",
                "Abdoulaye Sow",
                "S\u00e9r\u00e9 Moussa Doumbouya",
                "Daouda Bangoura",
                "Fod\u00e9 Moriba Bayo",
                "Ibrahima Sory 2. Cond\u00e9",
                "Kalo Mory Dian\u00e9",
                "Chris Piech",
                "Christopher Manning"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15612v3",
                "http://arxiv.org/pdf/2310.15612v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CY",
                "cs.HC",
                "cs.LG",
                "I.2.6; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15610v1",
            "title": "Using Slisemap to interpret physical data",
            "updated": "2023-10-24T08:25:49Z",
            "published": "2023-10-24T08:25:49Z",
            "summary": "Manifold visualisation techniques are commonly used to visualise\nhigh-dimensional datasets in physical sciences. In this paper we apply a\nrecently introduced manifold visualisation method, called Slise, on datasets\nfrom physics and chemistry. Slisemap combines manifold visualisation with\nexplainable artificial intelligence. Explainable artificial intelligence is\nused to investigate the decision processes of black box machine learning models\nand complex simulators. With Slisemap we find an embedding such that data items\nwith similar local explanations are grouped together. Hence, Slisemap gives us\nan overview of the different behaviours of a black box model. This makes\nSlisemap into a supervised manifold visualisation method, where the patterns in\nthe embedding reflect a target property. In this paper we show how Slisemap can\nbe used and evaluated on physical data and that Slisemap is helpful in finding\nmeaningful information on classification and regression models trained on these\ndatasets.",
            "author": [
                "Lauri Sepp\u00e4l\u00e4inen",
                "Anton Bj\u00f6rklund",
                "Vitus Besel",
                "Kai Puolam\u00e4ki"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15610v1",
                "http://arxiv.org/pdf/2310.15610v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15605v1",
            "title": "tagE: Enabling an Embodied Agent to Understand Human Instructions",
            "updated": "2023-10-24T08:17:48Z",
            "published": "2023-10-24T08:17:48Z",
            "summary": "Natural language serves as the primary mode of communication when an\nintelligent agent with a physical presence engages with human beings. While a\nplethora of research focuses on natural language understanding (NLU),\nencompassing endeavors such as sentiment analysis, intent prediction, question\nanswering, and summarization, the scope of NLU directed at situations\nnecessitating tangible actions by an embodied agent remains limited. The\ninherent ambiguity and incompleteness inherent in natural language present\nchallenges for intelligent agents striving to decipher human intention. To\ntackle this predicament head-on, we introduce a novel system known as task and\nargument grounding for Embodied agents (tagE). At its core, our system employs\nan inventive neural network model designed to extract a series of tasks from\ncomplex task instructions expressed in natural language. Our proposed model\nadopts an encoder-decoder framework enriched with nested decoding to\neffectively extract tasks and their corresponding arguments from these\nintricate instructions. These extracted tasks are then mapped (or grounded) to\nthe robot's established collection of skills, while the arguments find\ngrounding in objects present within the environment. To facilitate the training\nand evaluation of our system, we have curated a dataset featuring complex\ninstructions. The results of our experiments underscore the prowess of our\napproach, as it outperforms robust baseline models.",
            "author": [
                "Chayan Sarkar",
                "Avik Mitra",
                "Pradip Pramanick",
                "Tapas Nayak"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15605v1",
                "http://arxiv.org/pdf/2310.15605v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15597v1",
            "title": "Emergent Communication in Interactive Sketch Question Answering",
            "updated": "2023-10-24T08:00:20Z",
            "published": "2023-10-24T08:00:20Z",
            "summary": "Vision-based emergent communication (EC) aims to learn to communicate through\nsketches and demystify the evolution of human communication. Ironically,\nprevious works neglect multi-round interaction, which is indispensable in human\ncommunication. To fill this gap, we first introduce a novel Interactive Sketch\nQuestion Answering (ISQA) task, where two collaborative players are interacting\nthrough sketches to answer a question about an image in a multi-round manner.\nTo accomplish this task, we design a new and efficient interactive EC system,\nwhich can achieve an effective balance among three evaluation factors,\nincluding the question answering accuracy, drawing complexity and human\ninterpretability. Our experimental results including human evaluation\ndemonstrate that multi-round interactive mechanism facilitates targeted and\nefficient communication between intelligent agents with decent human\ninterpretability.",
            "author": [
                "Zixing Lei",
                "Yiming Zhang",
                "Yuxin Xiong",
                "Siheng Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15597v1",
                "http://arxiv.org/pdf/2310.15597v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15594v1",
            "title": "Retrieval-based Knowledge Transfer: An Effective Approach for Extreme\n  Large Language Model Compression",
            "updated": "2023-10-24T07:58:20Z",
            "published": "2023-10-24T07:58:20Z",
            "summary": "Large-scale pre-trained language models (LLMs) have demonstrated exceptional\nperformance in various natural language processing (NLP) tasks. However, the\nmassive size of these models poses huge challenges for their deployment in\nreal-world applications. While numerous model compression techniques have been\nproposed, most of them are not well-suited for achieving extreme model\ncompression when there is a significant gap in model scale. In this paper, we\nintroduce a novel compression paradigm called Retrieval-based Knowledge\nTransfer (RetriKT), which effectively transfers the knowledge of LLMs to\nextremely small-scale models (e.g., 1%). In particular, our approach extracts\nknowledge from LLMs to construct a knowledge store, from which the small-scale\nmodel can retrieve relevant information and leverage it for effective\ninference. To improve the quality of the model, soft prompt tuning and Proximal\nPolicy Optimization (PPO) reinforcement learning techniques are employed.\nExtensive experiments are conducted on low-resource tasks from SuperGLUE and\nGLUE benchmarks. The results demonstrate that the proposed approach\nsignificantly enhances the performance of small-scale models by leveraging the\nknowledge from LLMs.",
            "author": [
                "Jiduan Liu",
                "Jiahao Liu",
                "Qifan Wang",
                "Jingang Wang",
                "Xunliang Cai",
                "Dongyan Zhao",
                "Ran Lucien Wang",
                "Rui Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15594v1",
                "http://arxiv.org/pdf/2310.15594v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15593v1",
            "title": "RecipeMeta: Metapath-enhanced Recipe Recommendation on Heterogeneous\n  Recipe Network",
            "updated": "2023-10-24T07:58:14Z",
            "published": "2023-10-24T07:58:14Z",
            "summary": "Recipe is a set of instructions that describes how to make food. It can help\npeople from the preparation of ingredients, food cooking process, etc. to\nprepare the food, and increasingly in demand on the Web. To help users find the\nvast amount of recipes on the Web, we address the task of recipe\nrecommendation. Due to multiple data types and relationships in a recipe, we\ncan treat it as a heterogeneous network to describe its information more\naccurately. To effectively utilize the heterogeneous network, metapath was\nproposed to describe the higher-level semantic information between two entities\nby defining a compound path from peer entities. Therefore, we propose a\nmetapath-enhanced recipe recommendation framework, RecipeMeta, that combines\nGNN (Graph Neural Network)-based representation learning and specific\nmetapath-based information in a recipe to predict User-Recipe pairs for\nrecommendation. Through extensive experiments, we demonstrate that the proposed\nmodel, RecipeMeta, outperforms state-of-the-art methods for recipe\nrecommendation.",
            "author": [
                "Jialiang Shi",
                "Takahiro Komamizu",
                "Keisuke Doman",
                "Haruya Kyutoku",
                "Ichiro Ide"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15593v1",
                "http://arxiv.org/pdf/2310.15593v1"
            ],
            "primary_category": "cs.MM",
            "category": [
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15591v1",
            "title": "Machine-Learning-Based Non-Local Kinetic Energy Density Functional for\n  Simple Metals and Alloys",
            "updated": "2023-10-24T07:55:07Z",
            "published": "2023-10-24T07:55:07Z",
            "summary": "Developing an accurate kinetic energy density functional (KEDF) remains a\nmajor hurdle in orbital-free density functional theory. We propose a\nmachine-learning-based physical-constrained non-local (MPN) KEDF and implement\nit with the usage of the bulk-derived local pseudopotentials and plane wave\nbasis sets in the ABACUS package. The MPN KEDF is designed to satisfy three\nexact physical constraints: the scaling law of electron kinetic energy, the\nfree electron gas limit, and the non-negativity of Pauli energy density. The\nMPN KEDF is systematically tested for simple metals, including Li, Mg, Al, and\n59 alloys. We conclude that incorporating non-local information for designing\nnew KEDFs and obeying exact physical constraints are essential to improve the\naccuracy, transferability, and stability of ML-based KEDF. These results shed\nnew light on the construction of ML-based functionals.",
            "author": [
                "Liang Sun",
                "Mohan Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15591v1",
                "http://arxiv.org/pdf/2310.15591v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15587v1",
            "title": "ScanDL: A Diffusion Model for Generating Synthetic Scanpaths on Texts",
            "updated": "2023-10-24T07:52:19Z",
            "published": "2023-10-24T07:52:19Z",
            "summary": "Eye movements in reading play a crucial role in psycholinguistic research\nstudying the cognitive mechanisms underlying human language processing. More\nrecently, the tight coupling between eye movements and cognition has also been\nleveraged for language-related machine learning tasks such as the\ninterpretability, enhancement, and pre-training of language models, as well as\nthe inference of reader- and text-specific properties. However, scarcity of eye\nmovement data and its unavailability at application time poses a major\nchallenge for this line of research. Initially, this problem was tackled by\nresorting to cognitive models for synthesizing eye movement data. However, for\nthe sole purpose of generating human-like scanpaths, purely data-driven\nmachine-learning-based methods have proven to be more suitable. Following\nrecent advances in adapting diffusion processes to discrete data, we propose\nScanDL, a novel discrete sequence-to-sequence diffusion model that generates\nsynthetic scanpaths on texts. By leveraging pre-trained word representations\nand jointly embedding both the stimulus text and the fixation sequence, our\nmodel captures multi-modal interactions between the two inputs. We evaluate\nScanDL within- and across-dataset and demonstrate that it significantly\noutperforms state-of-the-art scanpath generation methods. Finally, we provide\nan extensive psycholinguistic analysis that underlines the model's ability to\nexhibit human-like reading behavior. Our implementation is made available at\nhttps://github.com/DiLi-Lab/ScanDL.",
            "author": [
                "Lena S. Bolliger",
                "David R. Reich",
                "Patrick Haller",
                "Deborah N. Jakobi",
                "Paul Prasse",
                "Lena A. J\u00e4ger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15587v1",
                "http://arxiv.org/pdf/2310.15587v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15586v1",
            "title": "Detecting Intentional AIS Shutdown in Open Sea Maritime Surveillance\n  Using Self-Supervised Deep Learning",
            "updated": "2023-10-24T07:51:29Z",
            "published": "2023-10-24T07:51:29Z",
            "summary": "In maritime traffic surveillance, detecting illegal activities, such as\nillegal fishing or transshipment of illicit products is a crucial task of the\ncoastal administration. In the open sea, one has to rely on Automatic\nIdentification System (AIS) message transmitted by on-board transponders, which\nare captured by surveillance satellites. However, insincere vessels often\nintentionally shut down their AIS transponders to hide illegal activities. In\nthe open sea, it is very challenging to differentiate intentional AIS shutdowns\nfrom missing reception due to protocol limitations, bad weather conditions or\nrestricting satellite positions. This paper presents a novel approach for the\ndetection of abnormal AIS missing reception based on self-supervised deep\nlearning techniques and transformer models. Using historical data, the trained\nmodel predicts if a message should be received in the upcoming minute or not.\nAfterwards, the model reports on detected anomalies by comparing the prediction\nwith what actually happens. Our method can process AIS messages in real-time,\nin particular, more than 500 Millions AIS messages per month, corresponding to\nthe trajectories of more than 60 000 ships. The method is evaluated on 1-year\nof real-world data coming from four Norwegian surveillance satellites. Using\nrelated research results, we validated our method by rediscovering already\ndetected intentional AIS shutdowns.",
            "author": [
                "Pierre Bernab\u00e9",
                "Arnaud Gotlieb",
                "Bruno Legeard",
                "Dusica Marijan",
                "Frank Olaf Sem-Jacobsen",
                "Helge Spieker"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TITS.2023.3322690",
                "http://arxiv.org/abs/2310.15586v1",
                "http://arxiv.org/pdf/2310.15586v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15585v1",
            "title": "Multimodal Representations for Teacher-Guided Compositional Visual\n  Reasoning",
            "updated": "2023-10-24T07:51:08Z",
            "published": "2023-10-24T07:51:08Z",
            "summary": "Neural Module Networks (NMN) are a compelling method for visual question\nanswering, enabling the translation of a question into a program consisting of\na series of reasoning sub-tasks that are sequentially executed on the image to\nproduce an answer. NMNs provide enhanced explainability compared to integrated\nmodels, allowing for a better understanding of the underlying reasoning\nprocess. To improve the effectiveness of NMNs we propose to exploit features\nobtained by a large-scale cross-modal encoder. Also, the current training\napproach of NMNs relies on the propagation of module outputs to subsequent\nmodules, leading to the accumulation of prediction errors and the generation of\nfalse answers. To mitigate this, we introduce an NMN learning strategy\ninvolving scheduled teacher guidance. Initially, the model is fully guided by\nthe ground-truth intermediate outputs, but gradually transitions to an\nautonomous behavior as training progresses. This reduces error accumulation,\nthus improving training efficiency and final performance.We demonstrate that by\nincorporating cross-modal features and employing more effective training\ntechniques for NMN, we achieve a favorable balance between performance and\ntransparency in the reasoning process.",
            "author": [
                "Wafa Aissa",
                "Marin Ferecatu",
                "Michel Crucianu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15585v1",
                "http://arxiv.org/pdf/2310.15585v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15584v1",
            "title": "Accelerating Split Federated Learning over Wireless Communication\n  Networks",
            "updated": "2023-10-24T07:49:56Z",
            "published": "2023-10-24T07:49:56Z",
            "summary": "The development of artificial intelligence (AI) provides opportunities for\nthe promotion of deep neural network (DNN)-based applications. However, the\nlarge amount of parameters and computational complexity of DNN makes it\ndifficult to deploy it on edge devices which are resource-constrained. An\nefficient method to address this challenge is model partition/splitting, in\nwhich DNN is divided into two parts which are deployed on device and server\nrespectively for co-training or co-inference. In this paper, we consider a\nsplit federated learning (SFL) framework that combines the parallel model\ntraining mechanism of federated learning (FL) and the model splitting structure\nof split learning (SL). We consider a practical scenario of heterogeneous\ndevices with individual split points of DNN. We formulate a joint problem of\nsplit point selection and bandwidth allocation to minimize the system latency.\nBy using alternating optimization, we decompose the problem into two\nsub-problems and solve them optimally. Experiment results demonstrate the\nsuperiority of our work in latency reduction and accuracy improvement.",
            "author": [
                "Ce Xu",
                "Jinxuan Li",
                "Yuan Liu",
                "Yushi Ling",
                "Miaowen Wen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15584v1",
                "http://arxiv.org/pdf/2310.15584v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NI",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15583v1",
            "title": "Learning Agility and Adaptive Legged Locomotion via Curricular Hindsight\n  Reinforcement Learning",
            "updated": "2023-10-24T07:48:40Z",
            "published": "2023-10-24T07:48:40Z",
            "summary": "Agile and adaptive maneuvers such as fall recovery, high-speed turning, and\nsprinting in the wild are challenging for legged systems. We propose a\nCurricular Hindsight Reinforcement Learning (CHRL) that learns an end-to-end\ntracking controller that achieves powerful agility and adaptation for the\nlegged robot. The two key components are (I) a novel automatic curriculum\nstrategy on task difficulty and (ii) a Hindsight Experience Replay strategy\nadapted to legged locomotion tasks. We demonstrated successful agile and\nadaptive locomotion on a real quadruped robot that performed fall recovery\nautonomously, coherent trotting, sustained outdoor speeds up to 3.45 m/s, and\ntuning speeds up to 3.2 rad/s. This system produces adaptive behaviours\nresponding to changing situations and unexpected disturbances on natural\nterrains like grass and dirt.",
            "author": [
                "Sicen Li",
                "Yiming Pang",
                "Panju Bai",
                "Zhaojin Liu",
                "Jiawei Li",
                "Shihao Hu",
                "Liquan Wang",
                "Gang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15583v1",
                "http://arxiv.org/pdf/2310.15583v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15580v1",
            "title": "Identifiable Latent Polynomial Causal Models Through the Lens of Change",
            "updated": "2023-10-24T07:46:10Z",
            "published": "2023-10-24T07:46:10Z",
            "summary": "Causal representation learning aims to unveil latent high-level causal\nrepresentations from observed low-level data. One of its primary tasks is to\nprovide reliable assurance of identifying these latent causal models, known as\nidentifiability. A recent breakthrough explores identifiability by leveraging\nthe change of causal influences among latent causal variables across multiple\nenvironments \\citep{liu2022identifying}. However, this progress rests on the\nassumption that the causal relationships among latent causal variables adhere\nstrictly to linear Gaussian models. In this paper, we extend the scope of\nlatent causal models to involve nonlinear causal relationships, represented by\npolynomial models, and general noise distributions conforming to the\nexponential family. Additionally, we investigate the necessity of imposing\nchanges on all causal parameters and present partial identifiability results\nwhen part of them remains unchanged. Further, we propose a novel empirical\nestimation method, grounded in our theoretical finding, that enables learning\nconsistent latent causal representations. Our experimental results, obtained\nfrom both synthetic and real-world data, validate our theoretical contributions\nconcerning identifiability and consistency.",
            "author": [
                "Yuhang Liu",
                "Zhen Zhang",
                "Dong Gong",
                "Mingming Gong",
                "Biwei Huang",
                "Anton van den Hengel",
                "Kun Zhang",
                "Javen Qinfeng Shi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15580v1",
                "http://arxiv.org/pdf/2310.15580v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15578v3",
            "title": "VMAF Re-implementation on PyTorch: Some Experimental Results",
            "updated": "2023-12-01T10:06:21Z",
            "published": "2023-10-24T07:42:04Z",
            "summary": "Based on the standard VMAF implementation we propose an implementation of\nVMAF using PyTorch framework. For this implementation comparisons with the\nstandard (libvmaf) show the discrepancy $\\lesssim 10^{-2}$ in VMAF units. We\ninvestigate gradients computation when using VMAF as an objective function and\ndemonstrate that training using this function does not result in ill-behaving\ngradients. The implementation is then used to train a preprocessing filter. It\nis demonstrated that its performance is superior to the unsharp masking filter.\nThe resulting filter is also easy for implementation and can be applied in\nvideo processing tasks for video copression improvement. This is confirmed by\nthe results of numerical experiments.",
            "author": [
                "Kirill Aistov",
                "Maxim Koroteev"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15578v3",
                "http://arxiv.org/pdf/2310.15578v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15577v1",
            "title": "CONTRASTE: Supervised Contrastive Pre-training With Aspect-based Prompts\n  For Aspect Sentiment Triplet Extraction",
            "updated": "2023-10-24T07:40:09Z",
            "published": "2023-10-24T07:40:09Z",
            "summary": "Existing works on Aspect Sentiment Triplet Extraction (ASTE) explicitly focus\non developing more efficient fine-tuning techniques for the task. Instead, our\nmotivation is to come up with a generic approach that can improve the\ndownstream performances of multiple ABSA tasks simultaneously. Towards this, we\npresent CONTRASTE, a novel pre-training strategy using CONTRastive learning to\nenhance the ASTE performance. While we primarily focus on ASTE, we also\ndemonstrate the advantage of our proposed technique on other ABSA tasks such as\nACOS, TASD, and AESC. Given a sentence and its associated (aspect, opinion,\nsentiment) triplets, first, we design aspect-based prompts with corresponding\nsentiments masked. We then (pre)train an encoder-decoder model by applying\ncontrastive learning on the decoder-generated aspect-aware sentiment\nrepresentations of the masked terms. For fine-tuning the model weights thus\nobtained, we then propose a novel multi-task approach where the base\nencoder-decoder model is combined with two complementary modules, a\ntagging-based Opinion Term Detector, and a regression-based Triplet Count\nEstimator. Exhaustive experiments on four benchmark datasets and a detailed\nablation study establish the importance of each of our proposed components as\nwe achieve new state-of-the-art ASTE results.",
            "author": [
                "Rajdeep Mukherjee",
                "Nithish Kannen",
                "Saurabh Kumar Pandey",
                "Pawan Goyal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15577v1",
                "http://arxiv.org/pdf/2310.15577v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15576v5",
            "title": "A Near-Quadratic Sample Complexity Reduction for Agnostic Learning via\n  Quantum Algorithms",
            "updated": "2023-11-15T05:27:54Z",
            "published": "2023-10-24T07:39:16Z",
            "summary": "Using quantum algorithms, we obtain, for accuracy $\\epsilon>0$ and confidence\n$1-\\delta,0<\\delta <1,$ a new sample complexity upper bound of\n$O((\\mbox{log}(\\frac{1}{\\delta}))/\\epsilon)$ as $\\epsilon,\\delta\\rightarrow 0$\n(up to a polylogarithmic factor in $\\epsilon^{-1}$) for a general agnostic\nlearning model, provided the hypothesis class is of finite cardinality. This\ngreatly improves upon a corresponding sample complexity of asymptotic order\n$\\Theta((\\mbox{log}(\\frac{1}{\\delta}))/\\epsilon^{2})$ known in the literature\nto be attainable by means of classical (non-quantum) algorithms for an agnostic\nlearning problem also with hypothesis set of finite cardinality (see, for\nexample, Arunachalam and de Wolf (2018) and the classical statistical learning\ntheory references cited there). Thus, for general agnostic learning, the\nquantum speedup in the rate of learning that we achieve is quadratic in\n$\\epsilon^{-1}$ (up to a polylogarithmic factor).",
            "author": [
                "Daniel Z. Zanger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15576v5",
                "http://arxiv.org/pdf/2310.15576v5"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15575v1",
            "title": "POE: Process of Elimination for Multiple Choice Reasoning",
            "updated": "2023-10-24T07:38:43Z",
            "published": "2023-10-24T07:38:43Z",
            "summary": "Language models (LMs) are capable of conducting in-context learning for\nmultiple choice reasoning tasks, but the options in these tasks are treated\nequally. As humans often first eliminate wrong options before picking the final\ncorrect answer, we argue a similar two-step strategy can make LMs better at\nthese tasks. To this end, we present the Process of Elimination (POE), a\ntwo-step scoring method. In the first step, POE scores each option, and\neliminates seemingly wrong options. In the second step, POE masks these wrong\noptions, and makes the final prediction from the remaining options. Zero-shot\nexperiments on 8 reasoning tasks illustrate the effectiveness of POE, and a\nfollowing analysis finds our method to be especially performant on logical\nreasoning tasks. We further analyze the effect of masks, and show that POE\napplies to few-shot settings and large language models (LLMs) like ChatGPT.",
            "author": [
                "Chenkai Ma",
                "Xinya Du"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15575v1",
                "http://arxiv.org/pdf/2310.15575v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15571v1",
            "title": "Visually Grounded Continual Language Learning with Selective\n  Specialization",
            "updated": "2023-10-24T07:35:23Z",
            "published": "2023-10-24T07:35:23Z",
            "summary": "A desirable trait of an artificial agent acting in the visual world is to\ncontinually learn a sequence of language-informed tasks while striking a\nbalance between sufficiently specializing in each task and building a\ngeneralized knowledge for transfer. Selective specialization, i.e., a careful\nselection of model components to specialize in each task, is a strategy to\nprovide control over this trade-off. However, the design of selection\nstrategies requires insights on the role of each model component in learning\nrather specialized or generalizable representations, which poses a gap in\ncurrent research. Thus, our aim with this work is to provide an extensive\nanalysis of selection strategies for visually grounded continual language\nlearning. Due to the lack of suitable benchmarks for this purpose, we introduce\ntwo novel diagnostic datasets that provide enough control and flexibility for a\nthorough model analysis. We assess various heuristics for module specialization\nstrategies as well as quantifiable measures for two different types of model\narchitectures. Finally, we design conceptually simple approaches based on our\nanalysis that outperform common continual learning baselines. Our results\ndemonstrate the need for further efforts towards better aligning continual\nlearning algorithms with the learning behaviors of individual model parts.",
            "author": [
                "Kyra Ahrens",
                "Lennart Bengtson",
                "Jae Hee Lee",
                "Stefan Wermter"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15571v1",
                "http://arxiv.org/pdf/2310.15571v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15568v1",
            "title": "I$^2$MD: 3D Action Representation Learning with Inter- and Intra-modal\n  Mutual Distillation",
            "updated": "2023-10-24T07:22:17Z",
            "published": "2023-10-24T07:22:17Z",
            "summary": "Recent progresses on self-supervised 3D human action representation learning\nare largely attributed to contrastive learning. However, in conventional\ncontrastive frameworks, the rich complementarity between different skeleton\nmodalities remains under-explored. Moreover, optimized with distinguishing\nself-augmented samples, models struggle with numerous similar positive\ninstances in the case of limited action categories. In this work, we tackle the\naforementioned problems by introducing a general Inter- and Intra-modal Mutual\nDistillation (I$^2$MD) framework. In I$^2$MD, we first re-formulate the\ncross-modal interaction as a Cross-modal Mutual Distillation (CMD) process.\nDifferent from existing distillation solutions that transfer the knowledge of a\npre-trained and fixed teacher to the student, in CMD, the knowledge is\ncontinuously updated and bidirectionally distilled between modalities during\npre-training. To alleviate the interference of similar samples and exploit\ntheir underlying contexts, we further design the Intra-modal Mutual\nDistillation (IMD) strategy, In IMD, the Dynamic Neighbors Aggregation (DNA)\nmechanism is first introduced, where an additional cluster-level discrimination\nbranch is instantiated in each modality. It adaptively aggregates\nhighly-correlated neighboring features, forming local cluster-level\ncontrasting. Mutual distillation is then performed between the two branches for\ncross-level knowledge exchange. Extensive experiments on three datasets show\nthat our approach sets a series of new records.",
            "author": [
                "Yunyao Mao",
                "Jiajun Deng",
                "Wengang Zhou",
                "Zhenbo Lu",
                "Wanli Ouyang",
                "Houqiang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15568v1",
                "http://arxiv.org/pdf/2310.15568v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15559v1",
            "title": "From Oja's Algorithm to the Multiplicative Weights Update Method with\n  Applications",
            "updated": "2023-10-24T07:02:47Z",
            "published": "2023-10-24T07:02:47Z",
            "summary": "Oja's algorithm is a well known online algorithm studied mainly in the\ncontext of stochastic principal component analysis. We make a simple\nobservation, yet to the best of our knowledge a novel one, that when applied to\na any (not necessarily stochastic) sequence of symmetric matrices which share\ncommon eigenvectors, the regret of Oja's algorithm could be directly bounded in\nterms of the regret of the well known multiplicative weights update method for\nthe problem of prediction with expert advice. Several applications to\noptimization with quadratic forms over the unit sphere in $\\reals^n$ are\ndiscussed.",
            "author": [
                "Dan Garber"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15559v1",
                "http://arxiv.org/pdf/2310.15559v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15556v2",
            "title": "TCRA-LLM: Token Compression Retrieval Augmented Large Language Model for\n  Inference Cost Reduction",
            "updated": "2023-10-25T07:50:52Z",
            "published": "2023-10-24T06:56:38Z",
            "summary": "Since ChatGPT released its API for public use, the number of applications\nbuilt on top of commercial large language models (LLMs) increase exponentially.\nOne popular usage of such models is leveraging its in-context learning ability\nand generating responses given user queries leveraging knowledge obtained by\nretrieval augmentation. One problem of deploying commercial retrieval-augmented\nLLMs is the cost due to the additionally retrieved context that largely\nincreases the input token size of the LLMs. To mitigate this, we propose a\ntoken compression scheme that includes two methods: summarization compression\nand semantic compression. The first method applies a T5-based model that is\nfine-tuned by datasets generated using self-instruct containing samples with\nvarying lengths and reduce token size by doing summarization. The second method\nfurther compresses the token size by removing words with lower impact on the\nsemantic. In order to adequately evaluate the effectiveness of the proposed\nmethods, we propose and utilize a dataset called Food-Recommendation DB (FRDB)\nfocusing on food recommendation for women around pregnancy period or infants.\nOur summarization compression can reduce 65% of the retrieval token size with\nfurther 0.3% improvement on the accuracy; semantic compression provides a more\nflexible way to trade-off the token size with performance, for which we can\nreduce the token size by 20% with only 1.6% of accuracy drop.",
            "author": [
                "Junyi Liu",
                "Liangzhi Li",
                "Tong Xiang",
                "Bowen Wang",
                "Yiming Qian"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15556v2",
                "http://arxiv.org/pdf/2310.15556v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15555v1",
            "title": "Transfer learning for day-ahead load forecasting: a case study on\n  European national electricity demand time series",
            "updated": "2023-10-24T06:54:50Z",
            "published": "2023-10-24T06:54:50Z",
            "summary": "Short-term load forecasting (STLF) is crucial for the daily operation of\npower grids. However, the non-linearity, non-stationarity, and randomness\ncharacterizing electricity demand time series renders STLF a challenging task.\nVarious forecasting approaches have been proposed for improving STLF, including\nneural network (NN) models which are trained using data from multiple\nelectricity demand series that may not necessary include the target series. In\nthe present study, we investigate the performance of this special case of STLF,\ncalled transfer learning (TL), by considering a set of 27 time series that\nrepresent the national day-ahead electricity demand of indicative European\ncountries. We employ a popular and easy-to-implement NN model and perform a\nclustering analysis to identify similar patterns among the series and assist\nTL. In this context, two different TL approaches, with and without the\nclustering step, are compiled and compared against each other as well as a\ntypical NN training setup. Our results demonstrate that TL can outperform the\nconventional approach, especially when clustering techniques are considered.",
            "author": [
                "Alexandros-Menelaos Tzortzis",
                "Sotiris Pelekis",
                "Evangelos Spiliotis",
                "Spiros Mouzakitis",
                "John Psarras",
                "Dimitris Askounis"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15555v1",
                "http://arxiv.org/pdf/2310.15555v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15552v1",
            "title": "Unveiling Multilinguality in Transformer Models: Exploring Language\n  Specificity in Feed-Forward Networks",
            "updated": "2023-10-24T06:45:00Z",
            "published": "2023-10-24T06:45:00Z",
            "summary": "Recent research suggests that the feed-forward module within Transformers can\nbe viewed as a collection of key-value memories, where the keys learn to\ncapture specific patterns from the input based on the training examples. The\nvalues then combine the output from the 'memories' of the keys to generate\npredictions about the next token. This leads to an incremental process of\nprediction that gradually converges towards the final token choice near the\noutput layers. This interesting perspective raises questions about how\nmultilingual models might leverage this mechanism. Specifically, for\nautoregressive models trained on two or more languages, do all neurons (across\nlayers) respond equally to all languages? No! Our hypothesis centers around the\nnotion that during pretraining, certain model parameters learn strong\nlanguage-specific features, while others learn more language-agnostic (shared\nacross languages) features. To validate this, we conduct experiments utilizing\nparallel corpora of two languages that the model was initially pretrained on.\nOur findings reveal that the layers closest to the network's input or output\ntend to exhibit more language-specific behaviour compared to the layers in the\nmiddle.",
            "author": [
                "Sunit Bhattacharya",
                "Ondrej Bojar"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15552v1",
                "http://arxiv.org/pdf/2310.15552v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15550v1",
            "title": "PET Synthesis via Self-supervised Adaptive Residual Estimation\n  Generative Adversarial Network",
            "updated": "2023-10-24T06:43:56Z",
            "published": "2023-10-24T06:43:56Z",
            "summary": "Positron emission tomography (PET) is a widely used, highly sensitive\nmolecular imaging in clinical diagnosis. There is interest in reducing the\nradiation exposure from PET but also maintaining adequate image quality. Recent\nmethods using convolutional neural networks (CNNs) to generate synthesized\nhigh-quality PET images from low-dose counterparts have been reported to be\nstate-of-the-art for low-to-high image recovery methods. However, these methods\nare prone to exhibiting discrepancies in texture and structure between\nsynthesized and real images. Furthermore, the distribution shift between\nlow-dose PET and standard PET has not been fully investigated. To address these\nissues, we developed a self-supervised adaptive residual estimation generative\nadversarial network (SS-AEGAN). We introduce (1) An adaptive residual\nestimation mapping mechanism, AE-Net, designed to dynamically rectify the\npreliminary synthesized PET images by taking the residual map between the\nlow-dose PET and synthesized output as the input, and (2) A self-supervised\npre-training strategy to enhance the feature representation of the coarse\ngenerator. Our experiments with a public benchmark dataset of total-body PET\nimages show that SS-AEGAN consistently outperformed the state-of-the-art\nsynthesis methods with various dose reduction factors.",
            "author": [
                "Yuxin Xue",
                "Lei Bi",
                "Yige Peng",
                "Michael Fulham",
                "David Dagan Feng",
                "Jinman Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15550v1",
                "http://arxiv.org/pdf/2310.15550v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15549v1",
            "title": "Algorithmic Regularization in Tensor Optimization: Towards a Lifted\n  Approach in Matrix Sensing",
            "updated": "2023-10-24T06:40:26Z",
            "published": "2023-10-24T06:40:26Z",
            "summary": "Gradient descent (GD) is crucial for generalization in machine learning\nmodels, as it induces implicit regularization, promoting compact\nrepresentations. In this work, we examine the role of GD in inducing implicit\nregularization for tensor optimization, particularly within the context of the\nlifted matrix sensing framework. This framework has been recently proposed to\naddress the non-convex matrix sensing problem by transforming spurious\nsolutions into strict saddles when optimizing over symmetric, rank-1 tensors.\nWe show that, with sufficiently small initialization scale, GD applied to this\nlifted problem results in approximate rank-1 tensors and critical points with\nescape directions. Our findings underscore the significance of the tensor\nparametrization of matrix sensing, in combination with first-order methods, in\nachieving global optimality in such problems.",
            "author": [
                "Ziye Ma",
                "Javad Lavaei",
                "Somayeh Sojoudi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15549v1",
                "http://arxiv.org/pdf/2310.15549v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15548v2",
            "title": "Knowledge-driven Meta-learning for CSI Feedback",
            "updated": "2023-10-25T04:15:56Z",
            "published": "2023-10-24T06:40:18Z",
            "summary": "Accurate and effective channel state information (CSI) feedback is a key\ntechnology for massive multiple-input and multiple-output systems. Recently,\ndeep learning (DL) has been introduced for CSI feedback enhancement through\nmassive collected training data and lengthy training time, which is quite\ncostly and impractical for realistic deployment. In this article, a\nknowledge-driven meta-learning approach is proposed, where the DL model\ninitialized by the meta model obtained from meta training phase is able to\nachieve rapid convergence when facing a new scenario during target retraining\nphase. Specifically, instead of training with massive data collected from\nvarious scenarios, the meta task environment is constructed based on the\nintrinsic knowledge of spatial-frequency characteristics of CSI for meta\ntraining. Moreover, the target task dataset is also augmented by exploiting the\nknowledge of statistical characteristics of wireless channel, so that the DL\nmodel can achieve higher performance with small actually collected dataset and\nshort training time. In addition, we provide analyses of rationale for the\nimprovement yielded by the knowledge in both phases. Simulation results\ndemonstrate the superiority of the proposed approach from the perspective of\nfeedback performance and convergence speed.",
            "author": [
                "Han Xiao",
                "Wenqiang Tian",
                "Wendong Liu",
                "Jiajia Guo",
                "Zhi Zhang",
                "Shi Jin",
                "Zhihua Shi",
                "Li Guo",
                "Jia Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15548v2",
                "http://arxiv.org/pdf/2310.15548v2"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16061v1",
            "title": "Segue: Side-information Guided Generative Unlearnable Examples for\n  Facial Privacy Protection in Real World",
            "updated": "2023-10-24T06:22:37Z",
            "published": "2023-10-24T06:22:37Z",
            "summary": "The widespread use of face recognition technology has given rise to privacy\nconcerns, as many individuals are worried about the collection and utilization\nof their facial data. To address these concerns, researchers are actively\nexploring the concept of ``unlearnable examples\", by adding imperceptible\nperturbation to data in the model training stage, which aims to prevent the\nmodel from learning discriminate features of the target face. However, current\nmethods are inefficient and cannot guarantee transferability and robustness at\nthe same time, causing impracticality in the real world. To remedy it, we\npropose a novel method called Segue: Side-information guided generative\nunlearnable examples. Specifically, we leverage a once-trained multiple-used\nmodel to generate the desired perturbation rather than the time-consuming\ngradient-based method. To improve transferability, we introduce side\ninformation such as true labels and pseudo labels, which are inherently\nconsistent across different scenarios. For robustness enhancement, a distortion\nlayer is integrated into the training pipeline. Extensive experiments\ndemonstrate that the proposed Segue is much faster than previous methods\n(1000$\\times$) and achieves transferable effectiveness across different\ndatasets and model architectures. Furthermore, it can resist JPEG compression,\nadversarial training, and some standard data augmentations.",
            "author": [
                "Zhiling Zhang",
                "Jie Zhang",
                "Kui Zhang",
                "Wenbo Zhou",
                "Weiming Zhang",
                "Nenghai Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16061v1",
                "http://arxiv.org/pdf/2310.16061v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15543v2",
            "title": "Symmetry-preserving graph attention network to solve routing problems at\n  multiple resolutions",
            "updated": "2023-11-19T22:24:59Z",
            "published": "2023-10-24T06:22:20Z",
            "summary": "Travelling Salesperson Problems (TSPs) and Vehicle Routing Problems (VRPs)\nhave achieved reasonable improvement in accuracy and computation time with the\nadaptation of Machine Learning (ML) methods. However, none of the previous\nworks completely respects the symmetries arising from TSPs and VRPs including\nrotation, translation, permutation, and scaling. In this work, we introduce the\nfirst-ever completely equivariant model and training to solve combinatorial\nproblems. Furthermore, it is essential to capture the multiscale structure\n(i.e. from local to global information) of the input graph, especially for the\ncases of large and long-range graphs, while previous methods are limited to\nextracting only local information that can lead to a local or sub-optimal\nsolution. To tackle the above limitation, we propose a Multiresolution scheme\nin combination with Equivariant Graph Attention network (mEGAT) architecture,\nwhich can learn the optimal route based on low-level and high-level graph\nresolutions in an efficient way. In particular, our approach constructs a\nhierarchy of coarse-graining graphs from the input graph, in which we try to\nsolve the routing problems on simple low-level graphs first, then utilize that\nknowledge for the more complex high-level graphs. Experimentally, we have shown\nthat our model outperforms existing baselines and proved that symmetry\npreservation and multiresolution are important recipes for solving\ncombinatorial problems in a data-driven manner. Our source code is publicly\navailable at https://github.com/HySonLab/Multires-NP-hard",
            "author": [
                "Cong Dao Tran",
                "Thong Bach",
                "Truong Son Hy"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15543v2",
                "http://arxiv.org/pdf/2310.15543v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18359v1",
            "title": "DeSIQ: Towards an Unbiased, Challenging Benchmark for Social\n  Intelligence Understanding",
            "updated": "2023-10-24T06:21:34Z",
            "published": "2023-10-24T06:21:34Z",
            "summary": "Social intelligence is essential for understanding and reasoning about human\nexpressions, intents and interactions. One representative benchmark for its\nstudy is Social Intelligence Queries (Social-IQ), a dataset of multiple-choice\nquestions on videos of complex social interactions. We define a comprehensive\nmethodology to study the soundness of Social-IQ, as the soundness of such\nbenchmark datasets is crucial to the investigation of the underlying research\nproblem. Our analysis reveals that Social-IQ contains substantial biases, which\ncan be exploited by a moderately strong language model to learn spurious\ncorrelations to achieve perfect performance without being given the context or\neven the question. We introduce DeSIQ, a new challenging dataset, constructed\nby applying simple perturbations to Social-IQ. Our empirical analysis shows\nDeSIQ significantly reduces the biases in the original Social-IQ dataset.\nFurthermore, we examine and shed light on the effect of model size, model\nstyle, learning settings, commonsense knowledge, and multi-modality on the new\nbenchmark performance. Our new dataset, observations and findings open up\nimportant research questions for the study of social intelligence.",
            "author": [
                "Xiao-Yu Guo",
                "Yuan-Fang Li",
                "Gholamreza Haffari"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18359v1",
                "http://arxiv.org/pdf/2310.18359v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15541v1",
            "title": "Improving Language Models Meaning Understanding and Consistency by\n  Learning Conceptual Roles from Dictionary",
            "updated": "2023-10-24T06:15:15Z",
            "published": "2023-10-24T06:15:15Z",
            "summary": "The non-humanlike behaviour of contemporary pre-trained language models\n(PLMs) is a leading cause undermining their trustworthiness. A striking\nphenomenon of such faulty behaviours is the generation of inconsistent\npredictions, which produces logically contradictory results, such as generating\ndifferent predictions for texts delivering the same meaning or violating\nlogical properties. Previous studies exploited data augmentation or implemented\nspecialised loss functions to alleviate the issue. However, their usage is\nlimited, because they consume expensive training resources for large-sized PLMs\nand can only handle a certain consistency type. To this end, we propose a\npractical approach that alleviates the inconsistent behaviour issue by\nfundamentally improving PLMs' meaning awareness. Based on the conceptual role\ntheory, our method allows PLMs to capture accurate meaning by learning precise\ninterrelationships between concepts from word-definition pairs in a dictionary.\nNext, we propose an efficient parameter integration technique that updates only\na few additional parameters to combine the learned interrelationship with PLMs'\npre-trained knowledge. Our experimental results reveal that the approach can\nconcurrently improve multiple types of consistency, enables efficient knowledge\nintegration, and easily applies to other languages.",
            "author": [
                "Myeongjun Erik Jang",
                "Thomas Lukasiewicz"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15541v1",
                "http://arxiv.org/pdf/2310.15541v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15539v1",
            "title": "SteloCoder: a Decoder-Only LLM for Multi-Language to Python Code\n  Translation",
            "updated": "2023-10-24T06:04:28Z",
            "published": "2023-10-24T06:04:28Z",
            "summary": "With the recent focus on Large Language Models (LLMs), both StarCoder (Li et\nal., 2023) and Code Llama (Rozi\\`ere et al., 2023) have demonstrated remarkable\nperformance in code generation. However, there is still a need for improvement\nin code translation functionality with efficient training techniques. In\nresponse to this, we introduce SteloCoder, a decoder-only StarCoder-based LLM\ndesigned specifically for multi-programming language-to-Python code\ntranslation. In particular, SteloCoder achieves C++, C#, JavaScript, Java, or\nPHP-to-Python code translation without specifying the input programming\nlanguage. We modified StarCoder model architecture by incorporating a\nMixture-of-Experts (MoE) technique featuring five experts and a gating network\nfor multi-task handling. Experts are obtained by StarCoder fine-tuning.\nSpecifically, we use a Low-Rank Adaptive Method (LoRA) technique, limiting each\nexpert size as only 0.06% of number of StarCoder's parameters. At the same\ntime, to enhance training efficiency in terms of time, we adopt curriculum\nlearning strategy and use self-instruct data for efficient fine-tuning. As a\nresult, each expert takes only 6 hours to train on one single 80Gb A100 HBM.\nWith experiments on XLCoST datasets, SteloCoder achieves an average of 73.76\nCodeBLEU score in multi-programming language-to-Python translation, surpassing\nthe top performance from the leaderboard by at least 3.5. This accomplishment\nis attributed to only 45M extra parameters with StarCoder as the backbone and\n32 hours of valid training on one 80GB A100 HBM. The source code is release\nhere: https://github.com/sade-adrien/SteloCoder.",
            "author": [
                "Jialing Pan",
                "Adrien Sad\u00e9",
                "Jin Kim",
                "Eric Soriano",
                "Guillem Sole",
                "Sylvain Flamant"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15539v1",
                "http://arxiv.org/pdf/2310.15539v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15533v1",
            "title": "Learning with Noisy Labels Using Collaborative Sample Selection and\n  Contrastive Semi-Supervised Learning",
            "updated": "2023-10-24T05:37:20Z",
            "published": "2023-10-24T05:37:20Z",
            "summary": "Learning with noisy labels (LNL) has been extensively studied, with existing\napproaches typically following a framework that alternates between clean sample\nselection and semi-supervised learning (SSL). However, this approach has a\nlimitation: the clean set selected by the Deep Neural Network (DNN) classifier,\ntrained through self-training, inevitably contains noisy samples. This mixture\nof clean and noisy samples leads to misguidance in DNN training during SSL,\nresulting in impaired generalization performance due to confirmation bias\ncaused by error accumulation in sample selection. To address this issue, we\npropose a method called Collaborative Sample Selection (CSS), which leverages\nthe large-scale pre-trained model CLIP. CSS aims to remove the mixed noisy\nsamples from the identified clean set. We achieve this by training a\n2-Dimensional Gaussian Mixture Model (2D-GMM) that combines the probabilities\nfrom CLIP with the predictions from the DNN classifier. To further enhance the\nadaptation of CLIP to LNL, we introduce a co-training mechanism with a\ncontrastive loss in semi-supervised learning. This allows us to jointly train\nthe prompt of CLIP and the DNN classifier, resulting in improved feature\nrepresentation, boosted classification performance of DNNs, and reciprocal\nbenefits to our Collaborative Sample Selection. By incorporating auxiliary\ninformation from CLIP and utilizing prompt fine-tuning, we effectively\neliminate noisy samples from the clean set and mitigate confirmation bias\nduring training. Experimental results on multiple benchmark datasets\ndemonstrate the effectiveness of our proposed method in comparison with the\nstate-of-the-art approaches.",
            "author": [
                "Qing Miao",
                "Xiaohe Wu",
                "Chao Xu",
                "Yanli Ji",
                "Wangmeng Zuo",
                "Yiwen Guo",
                "Zhaopeng Meng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15533v1",
                "http://arxiv.org/pdf/2310.15533v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15526v1",
            "title": "Privacy Amplification for Matrix Mechanisms",
            "updated": "2023-10-24T05:16:52Z",
            "published": "2023-10-24T05:16:52Z",
            "summary": "Privacy amplification exploits randomness in data selection to provide\ntighter differential privacy (DP) guarantees. This analysis is key to DP-SGD's\nsuccess in machine learning, but, is not readily applicable to the newer\nstate-of-the-art algorithms. This is because these algorithms, known as\nDP-FTRL, use the matrix mechanism to add correlated noise instead of\nindependent noise as in DP-SGD.\n  In this paper, we propose \"MMCC\", the first algorithm to analyze privacy\namplification via sampling for any generic matrix mechanism. MMCC is nearly\ntight in that it approaches a lower bound as $\\epsilon\\to0$. To analyze\ncorrelated outputs in MMCC, we prove that they can be analyzed as if they were\nindependent, by conditioning them on prior outputs. Our \"conditional\ncomposition theorem\" has broad utility: we use it to show that the noise added\nto binary-tree-DP-FTRL can asymptotically match the noise added to DP-SGD with\namplification. Our amplification algorithm also has practical empirical\nutility: we show it leads to significant improvement in the privacy-utility\ntrade-offs for DP-FTRL algorithms on standard benchmarks.",
            "author": [
                "Christopher A. Choquette-Choo",
                "Arun Ganesh",
                "Thomas Steinke",
                "Abhradeep Thakurta"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15526v1",
                "http://arxiv.org/pdf/2310.15526v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15524v1",
            "title": "On the Inherent Privacy Properties of Discrete Denoising Diffusion\n  Models",
            "updated": "2023-10-24T05:07:31Z",
            "published": "2023-10-24T05:07:31Z",
            "summary": "Privacy concerns have led to a surge in the creation of synthetic datasets,\nwith diffusion models emerging as a promising avenue. Although prior studies\nhave performed empirical evaluations on these models, there has been a gap in\nproviding a mathematical characterization of their privacy-preserving\ncapabilities. To address this, we present the pioneering theoretical\nexploration of the privacy preservation inherent in discrete diffusion models\n(DDMs) for discrete dataset generation. Focusing on per-instance differential\nprivacy (pDP), our framework elucidates the potential privacy leakage for each\ndata point in a given training dataset, offering insights into data\npreprocessing to reduce privacy risks of the synthetic dataset generation via\nDDMs. Our bounds also show that training with $s$-sized data points leads to a\nsurge in privacy leakage from $(\\epsilon,\n\\mathcal{O}(\\frac{1}{s^2\\epsilon}))$-pDP to $(\\epsilon,\n\\mathcal{O}(\\frac{1}{s\\epsilon}))$-pDP during the transition from the pure\nnoise to the synthetic clean data phase, and a faster decay in diffusion\ncoefficients amplifies the privacy guarantee. Finally, we empirically verify\nour theoretical findings on both synthetic and real-world datasets.",
            "author": [
                "Rongzhe Wei",
                "Eleonora Krea\u010di\u0107",
                "Haoyu Wang",
                "Haoteng Yin",
                "Eli Chien",
                "Vamsi K. Potluru",
                "Pan Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15524v1",
                "http://arxiv.org/pdf/2310.15524v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15523v1",
            "title": "Generative and Contrastive Paradigms Are Complementary for Graph\n  Self-Supervised Learning",
            "updated": "2023-10-24T05:06:06Z",
            "published": "2023-10-24T05:06:06Z",
            "summary": "For graph self-supervised learning (GSSL), masked autoencoder (MAE) follows\nthe generative paradigm and learns to reconstruct masked graph edges or node\nfeatures. Contrastive Learning (CL) maximizes the similarity between augmented\nviews of the same graph and is widely used for GSSL. However, MAE and CL are\nconsidered separately in existing works for GSSL. We observe that the MAE and\nCL paradigms are complementary and propose the graph contrastive masked\nautoencoder (GCMAE) framework to unify them. Specifically, by focusing on local\nedges or node features, MAE cannot capture global information of the graph and\nis sensitive to particular edges and features. On the contrary, CL excels in\nextracting global information because it considers the relation between graphs.\nAs such, we equip GCMAE with an MAE branch and a CL branch, and the two\nbranches share a common encoder, which allows the MAE branch to exploit the\nglobal information extracted by the CL branch. To force GCMAE to capture global\ngraph structures, we train it to reconstruct the entire adjacency matrix\ninstead of only the masked edges as in existing works. Moreover, a\ndiscrimination loss is proposed for feature reconstruction, which improves the\ndisparity between node embeddings rather than reducing the reconstruction error\nto tackle the feature smoothing problem of MAE. We evaluate GCMAE on four\npopular graph tasks (i.e., node classification, node clustering, link\nprediction, and graph classification) and compare with 14 state-of-the-art\nbaselines. The results show that GCMAE consistently provides good accuracy\nacross these tasks, and the maximum accuracy improvement is up to 3.2% compared\nwith the best-performing baseline.",
            "author": [
                "Yuxiang Wang",
                "Xiao Yan",
                "Chuang Hu",
                "Fangcheng Fu",
                "Wentao Zhang",
                "Hao Wang",
                "Shuo Shang",
                "Jiawei Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15523v1",
                "http://arxiv.org/pdf/2310.15523v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15516v2",
            "title": "Graph Attention-based Deep Reinforcement Learning for solving the\n  Chinese Postman Problem with Load-dependent costs",
            "updated": "2023-11-20T05:06:11Z",
            "published": "2023-10-24T04:50:32Z",
            "summary": "Recently, Deep reinforcement learning (DRL) models have shown promising\nresults in solving routing problems. However, most DRL solvers are commonly\nproposed to solve node routing problems, such as the Traveling Salesman Problem\n(TSP). Meanwhile, there has been limited research on applying neural methods to\narc routing problems, such as the Chinese Postman Problem (CPP), since they\noften feature irregular and complex solution spaces compared to TSP. To fill\nthese gaps, this paper proposes a novel DRL framework to address the CPP with\nload-dependent costs (CPP-LC) (Corberan et al., 2018), which is a complex arc\nrouting problem with load constraints. The novelty of our method is two-fold.\nFirst, we formulate the CPP-LC as a Markov Decision Process (MDP) sequential\nmodel. Subsequently, we introduce an autoregressive model based on DRL, namely\nArc-DRL, consisting of an encoder and decoder to address the CPP-LC challenge\neffectively. Such a framework allows the DRL model to work efficiently and\nscalably to arc routing problems. Furthermore, we propose a new bio-inspired\nmeta-heuristic solution based on Evolutionary Algorithm (EA) for CPP-LC.\nExtensive experiments show that Arc-DRL outperforms existing meta-heuristic\nmethods such as Iterative Local Search (ILS) and Variable Neighborhood Search\n(VNS) proposed by (Corberan et al., 2018) on large benchmark datasets for\nCPP-LC regarding both solution quality and running time; while the EA gives the\nbest solution quality with much more running time. We release our C++\nimplementations for metaheuristics such as EA, ILS and VNS along with the code\nfor data generation and our generated data at\nhttps://github.com/HySonLab/Chinese_Postman_Problem",
            "author": [
                "Truong Son Hy",
                "Cong Dao Tran"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15516v2",
                "http://arxiv.org/pdf/2310.15516v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15513v1",
            "title": "A Joint Matrix Factorization Analysis of Multilingual Representations",
            "updated": "2023-10-24T04:43:45Z",
            "published": "2023-10-24T04:43:45Z",
            "summary": "We present an analysis tool based on joint matrix factorization for comparing\nlatent representations of multilingual and monolingual models. An alternative\nto probing, this tool allows us to analyze multiple sets of representations in\na joint manner. Using this tool, we study to what extent and how\nmorphosyntactic features are reflected in the representations learned by\nmultilingual pre-trained models. We conduct a large-scale empirical study of\nover 33 languages and 17 morphosyntactic categories. Our findings demonstrate\nvariations in the encoding of morphosyntactic information across upper and\nlower layers, with category-specific differences influenced by language\nproperties. Hierarchical clustering of the factorization outputs yields a tree\nstructure that is related to phylogenetic trees manually crafted by linguists.\nMoreover, we find the factorization outputs exhibit strong associations with\nperformance observed across different cross-lingual tasks. We release our code\nto facilitate future research.",
            "author": [
                "Zheng Zhao",
                "Yftah Ziser",
                "Bonnie Webber",
                "Shay B. Cohen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15513v1",
                "http://arxiv.org/pdf/2310.15513v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15511v1",
            "title": "KITAB: Evaluating LLMs on Constraint Satisfaction for Information\n  Retrieval",
            "updated": "2023-10-24T04:40:38Z",
            "published": "2023-10-24T04:40:38Z",
            "summary": "We study the ability of state-of-the art models to answer constraint\nsatisfaction queries for information retrieval (e.g., 'a list of ice cream\nshops in San Diego'). In the past, such queries were considered to be tasks\nthat could only be solved via web-search or knowledge bases. More recently,\nlarge language models (LLMs) have demonstrated initial emergent abilities in\nthis task. However, many current retrieval benchmarks are either saturated or\ndo not measure constraint satisfaction. Motivated by rising concerns around\nfactual incorrectness and hallucinations of LLMs, we present KITAB, a new\ndataset for measuring constraint satisfaction abilities of language models.\nKITAB consists of book-related data across more than 600 authors and 13,000\nqueries, and also offers an associated dynamic data collection and constraint\nverification approach for acquiring similar test data for other authors. Our\nextended experiments on GPT4 and GPT3.5 characterize and decouple common\nfailure modes across dimensions such as information popularity, constraint\ntypes, and context availability. Results show that in the absence of context,\nmodels exhibit severe limitations as measured by irrelevant information,\nfactual errors, and incompleteness, many of which exacerbate as information\npopularity decreases. While context availability mitigates irrelevant\ninformation, it is not helpful for satisfying constraints, identifying\nfundamental barriers to constraint satisfaction. We open source our\ncontributions to foster further research on improving constraint satisfaction\nabilities of future models.",
            "author": [
                "Marah I Abdin",
                "Suriya Gunasekar",
                "Varun Chandrasekaran",
                "Jerry Li",
                "Mert Yuksekgonul",
                "Rahee Ghosh Peshawaria",
                "Ranjita Naik",
                "Besmira Nushi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15511v1",
                "http://arxiv.org/pdf/2310.15511v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "cs.IR",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19820v1",
            "title": "NetDistiller: Empowering Tiny Deep Learning via In-Situ Distillation",
            "updated": "2023-10-24T04:27:51Z",
            "published": "2023-10-24T04:27:51Z",
            "summary": "Boosting the task accuracy of tiny neural networks (TNNs) has become a\nfundamental challenge for enabling the deployments of TNNs on edge devices\nwhich are constrained by strict limitations in terms of memory, computation,\nbandwidth, and power supply. To this end, we propose a framework called\nNetDistiller to boost the achievable accuracy of TNNs by treating them as\nsub-networks of a weight-sharing teacher constructed by expanding the number of\nchannels of the TNN. Specifically, the target TNN model is jointly trained with\nthe weight-sharing teacher model via (1) gradient surgery to tackle the\ngradient conflicts between them and (2) uncertainty-aware distillation to\nmitigate the overfitting of the teacher model. Extensive experiments across\ndiverse tasks validate NetDistiller's effectiveness in boosting TNNs'\nachievable accuracy over state-of-the-art methods. Our code is available at\nhttps://github.com/GATECH-EIC/NetDistiller.",
            "author": [
                "Shunyao Zhang",
                "Yonggan Fu",
                "Shang Wu",
                "Jyotikrishna Dass",
                "Haoran You",
                "Yingyan",
                "Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19820v1",
                "http://arxiv.org/pdf/2310.19820v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15504v1",
            "title": "Cross-view Self-localization from Synthesized Scene-graphs",
            "updated": "2023-10-24T04:16:27Z",
            "published": "2023-10-24T04:16:27Z",
            "summary": "Cross-view self-localization is a challenging scenario of visual place\nrecognition in which database images are provided from sparse viewpoints.\nRecently, an approach for synthesizing database images from unseen viewpoints\nusing NeRF (Neural Radiance Fields) technology has emerged with impressive\nperformance. However, synthesized images provided by these techniques are often\nof lower quality than the original images, and furthermore they significantly\nincrease the storage cost of the database. In this study, we explore a new\nhybrid scene model that combines the advantages of view-invariant appearance\nfeatures computed from raw images and view-dependent spatial-semantic features\ncomputed from synthesized images. These two types of features are then fused\ninto scene graphs, and compressively learned and recognized by a graph neural\nnetwork. The effectiveness of the proposed method was verified using a novel\ncross-view self-localization dataset with many unseen views generated using a\nphotorealistic Habitat simulator.",
            "author": [
                "Ryogo Yamamoto",
                "Kanji Tanaka"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15504v1",
                "http://arxiv.org/pdf/2310.15504v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15497v1",
            "title": "Generalized Box-Cox method to estimate sample mean and standard\n  deviation for Meta-analysis",
            "updated": "2023-10-24T03:54:27Z",
            "published": "2023-10-24T03:54:27Z",
            "summary": "Meta-analysis is the aggregation of data from multiple studies to find\npatterns across a broad range relating to a particular subject. It is becoming\nincreasingly useful to apply meta-analysis to summarize these studies being\ndone across various fields. In meta-analysis, it is common to use the mean and\nstandard deviation from each study to compare for analysis. While many studies\nreported mean and standard deviation for their summary statistics, some report\nother values including the minimum, maximum, median, and first and third\nquantiles. Often, the quantiles and median are reported when the data is skewed\nand does not follow a normal distribution. In order to correctly summarize the\ndata and draw conclusions from multiple studies, it is necessary to estimate\nthe mean and standard deviation from each study, considering variation and\nskewness within each study. In past literature, methods have been proposed to\nestimate the mean and standard deviation, but do not consider negative values.\nData that include negative values are common and would increase the accuracy\nand impact of the me-ta-analysis. We propose a method that implements a\ngeneralized Box-Cox transformation to estimate the mean and standard deviation\naccounting for such negative values while maintaining similar accuracy.",
            "author": [
                "Olivia Xiao",
                "Stacy Wang",
                "Min Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15497v1",
                "http://arxiv.org/pdf/2310.15497v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15495v4",
            "title": "AMG: Automated Efficient Approximate Multiplier Generator for FPGAs via\n  Bayesian Optimization",
            "updated": "2023-10-28T10:52:12Z",
            "published": "2023-10-24T03:44:06Z",
            "summary": "Approximate computing is a promising approach to reduce the power, delay, and\narea in hardware design for many error-resilient applications such as machine\nlearning (ML) and digital signal processing (DSP) systems, in which multipliers\nusually are key arithmetic units. Due to the underlying architectural\ndifferences between ASICs and FPGAs, existing ASIC-based approximate\nmultipliers do not offer symmetrical gains when they are implemented by FPGA\nresources. In this paper, we propose AMG, an open-source automated approximate\nmultiplier generator for FPGAs driven by Bayesian optimization (BO) with\nparallel evaluation. The proposed method simplifies the exact half adders (HAs)\nfor the initial partial product (PP) compression in a multiplier while\npreserving coarse-grained additions for the following accumulation. The\ngenerated multipliers can be effectively mapped to lookup tables (LUTs) and\ncarry chains provided by modern FPGAs, reducing hardware costs with acceptable\nerrors. Compared with 1167 multipliers from previous works, our generated\nmultipliers can form a Pareto front with 28.70%-38.47% improvements in terms of\nthe product of hardware cost and error on average. All source codes, reproduced\nmultipliers, and our generated multipliers are available at\nhttps://github.com/phyzhenli/AMG.",
            "author": [
                "Zhen Li",
                "Hao Zhou",
                "Lingli Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15495v4",
                "http://arxiv.org/pdf/2310.15495v4"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15492v1",
            "title": "Robust Representation Learning for Unified Online Top-K Recommendation",
            "updated": "2023-10-24T03:42:20Z",
            "published": "2023-10-24T03:42:20Z",
            "summary": "In large-scale industrial e-commerce, the efficiency of an online\nrecommendation system is crucial in delivering highly relevant item/content\nadvertising that caters to diverse business scenarios. However, most existing\nstudies focus solely on item advertising, neglecting the significance of\ncontent advertising. This oversight results in inconsistencies within the\nmulti-entity structure and unfair retrieval. Furthermore, the challenge of\nretrieving top-k advertisements from multi-entity advertisements across\ndifferent domains adds to the complexity. Recent research proves that\nuser-entity behaviors within different domains exhibit characteristics of\ndifferentiation and homogeneity. Therefore, the multi-domain matching models\ntypically rely on the hybrid-experts framework with domain-invariant and\ndomain-specific representations. Unfortunately, most approaches primarily focus\non optimizing the combination mode of different experts, failing to address the\ninherent difficulty in optimizing the expert modules themselves. The existence\nof redundant information across different domains introduces interference and\ncompetition among experts, while the distinct learning objectives of each\ndomain lead to varying optimization challenges among experts. To tackle these\nissues, we propose robust representation learning for the unified online top-k\nrecommendation. Our approach constructs unified modeling in entity space to\nensure data fairness. The robust representation learning employs domain\nadversarial learning and multi-view wasserstein distribution learning to learn\nrobust representations. Moreover, the proposed method balances conflicting\nobjectives through the homoscedastic uncertainty weights and orthogonality\nconstraints. Various experiments validate the effectiveness and rationality of\nour proposed method, which has been successfully deployed online to serve real\nbusiness scenarios.",
            "author": [
                "Minfang Lu",
                "Yuchen Jiang",
                "Huihui Dong",
                "Qi Li",
                "Ziru Xu",
                "Yuanlin Liu",
                "Lixia Wu",
                "Haoyuan Hu",
                "Han Zhu",
                "Yuning Jiang",
                "Jian Xu",
                "Bo Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15492v1",
                "http://arxiv.org/pdf/2310.15492v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15479v2",
            "title": "AutoDiff: combining Auto-encoder and Diffusion model for tabular data\n  synthesizing",
            "updated": "2023-11-17T03:24:50Z",
            "published": "2023-10-24T03:15:19Z",
            "summary": "Diffusion model has become a main paradigm for synthetic data generation in\nmany subfields of modern machine learning, including computer vision, language\nmodel, or speech synthesis. In this paper, we leverage the power of diffusion\nmodel for generating synthetic tabular data. The heterogeneous features in\ntabular data have been main obstacles in tabular data synthesis, and we tackle\nthis problem by employing the auto-encoder architecture. When compared with the\nstate-of-the-art tabular synthesizers, the resulting synthetic tables from our\nmodel show nice statistical fidelities to the real data, and perform well in\ndownstream tasks for machine learning utilities. We conducted the experiments\nover $15$ publicly available datasets. Notably, our model adeptly captures the\ncorrelations among features, which has been a long-standing challenge in\ntabular data synthesis. Our code is available at\nhttps://github.com/UCLA-Trustworthy-AI-Lab/AutoDiffusion.",
            "author": [
                "Namjoon Suh",
                "Xiaofeng Lin",
                "Din-Yin Hsieh",
                "Merhdad Honarkhah",
                "Guang Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15479v2",
                "http://arxiv.org/pdf/2310.15479v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15478v3",
            "title": "How to Train Your Neural Control Barrier Function: Learning Safety\n  Filters for Complex Input-Constrained Systems",
            "updated": "2023-12-05T04:31:45Z",
            "published": "2023-10-24T03:15:15Z",
            "summary": "Control barrier functions (CBF) have become popular as a safety filter to\nguarantee the safety of nonlinear dynamical systems for arbitrary inputs.\nHowever, it is difficult to construct functions that satisfy the CBF\nconstraints for high relative degree systems with input constraints. To address\nthese challenges, recent work has explored learning CBFs using neural networks\nvia neural CBF (NCBF). However, such methods face difficulties when scaling to\nhigher dimensional systems under input constraints. In this work, we first\nidentify challenges that NCBFs face during training. Next, to address these\nchallenges, we propose policy neural CBF (PNCBF), a method of constructing CBFs\nby learning the value function of a nominal policy, and show that the value\nfunction of the maximum-over-time cost is a CBF. We demonstrate the\neffectiveness of our method in simulation on a variety of systems ranging from\ntoy linear systems to an F-16 jet with a 16-dimensional state space. Finally,\nwe validate our approach on a two-agent quadcopter system on hardware under\ntight input constraints.",
            "author": [
                "Oswin So",
                "Zachary Serlin",
                "Makai Mann",
                "Jake Gonzales",
                "Kwesi Rutledge",
                "Nicholas Roy",
                "Chuchu Fan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15478v3",
                "http://arxiv.org/pdf/2310.15478v3"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18358v1",
            "title": "A Communication Theory Perspective on Prompting Engineering Methods for\n  Large Language Models",
            "updated": "2023-10-24T03:05:21Z",
            "published": "2023-10-24T03:05:21Z",
            "summary": "The springing up of Large Language Models (LLMs) has shifted the community\nfrom single-task-orientated natural language processing (NLP) research to a\nholistic end-to-end multi-task learning paradigm. Along this line of research\nendeavors in the area, LLM-based prompting methods have attracted much\nattention, partially due to the technological advantages brought by prompt\nengineering (PE) as well as the underlying NLP principles disclosed by various\nprompting methods. Traditional supervised learning usually requires training a\nmodel based on labeled data and then making predictions. In contrast, PE\nmethods directly use the powerful capabilities of existing LLMs (i.e., GPT-3\nand GPT-4) via composing appropriate prompts, especially under few-shot or\nzero-shot scenarios. Facing the abundance of studies related to the prompting\nand the ever-evolving nature of this field, this article aims to (i) illustrate\na novel perspective to review existing PE methods, within the well-established\ncommunication theory framework; (ii) facilitate a better/deeper understanding\nof developing trends of existing PE methods used in four typical tasks; (iii)\nshed light on promising research directions for future PE methods.",
            "author": [
                "Yuanfeng Song",
                "Yuanqin He",
                "Xuefang Zhao",
                "Hanlin Gu",
                "Di Jiang",
                "Haijun Yang",
                "Lixin Fan",
                "Qiang Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18358v1",
                "http://arxiv.org/pdf/2310.18358v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15472v1",
            "title": "Interpretable Survival Analysis for Heart Failure Risk Prediction",
            "updated": "2023-10-24T02:56:05Z",
            "published": "2023-10-24T02:56:05Z",
            "summary": "Survival analysis, or time-to-event analysis, is an important and widespread\nproblem in healthcare research. Medical research has traditionally relied on\nCox models for survival analysis, due to their simplicity and interpretability.\nCox models assume a log-linear hazard function as well as proportional hazards\nover time, and can perform poorly when these assumptions fail. Newer survival\nmodels based on machine learning avoid these assumptions and offer improved\naccuracy, yet sometimes at the expense of model interpretability, which is\nvital for clinical use. We propose a novel survival analysis pipeline that is\nboth interpretable and competitive with state-of-the-art survival models.\nSpecifically, we use an improved version of survival stacking to transform a\nsurvival analysis problem to a classification problem, ControlBurn to perform\nfeature selection, and Explainable Boosting Machines to generate interpretable\npredictions. To evaluate our pipeline, we predict risk of heart failure using a\nlarge-scale EHR database. Our pipeline achieves state-of-the-art performance\nand provides interesting and novel insights about risk factors for heart\nfailure.",
            "author": [
                "Mike Van Ness",
                "Tomas Bosschieter",
                "Natasha Din",
                "Andrew Ambrosy",
                "Alexander Sandhu",
                "Madeleine Udell"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15472v1",
                "http://arxiv.org/pdf/2310.15472v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15470v1",
            "title": "Continual Event Extraction with Semantic Confusion Rectification",
            "updated": "2023-10-24T02:48:50Z",
            "published": "2023-10-24T02:48:50Z",
            "summary": "We study continual event extraction, which aims to extract incessantly\nemerging event information while avoiding forgetting. We observe that the\nsemantic confusion on event types stems from the annotations of the same text\nbeing updated over time. The imbalance between event types even aggravates this\nissue. This paper proposes a novel continual event extraction model with\nsemantic confusion rectification. We mark pseudo labels for each sentence to\nalleviate semantic confusion. We transfer pivotal knowledge between current and\nprevious models to enhance the understanding of event types. Moreover, we\nencourage the model to focus on the semantics of long-tailed event types by\nleveraging other associated types. Experimental results show that our model\noutperforms state-of-the-art baselines and is proficient in imbalanced\ndatasets.",
            "author": [
                "Zitao Wang",
                "Xinyi Wang",
                "Wei Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15470v1",
                "http://arxiv.org/pdf/2310.15470v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15468v1",
            "title": "Empowering Distributed Solutions in Renewable Energy Systems and Grid\n  Optimization",
            "updated": "2023-10-24T02:45:16Z",
            "published": "2023-10-24T02:45:16Z",
            "summary": "This study delves into the shift from centralized to decentralized approaches\nin the electricity industry, with a particular focus on how machine learning\n(ML) advancements play a crucial role in empowering renewable energy sources\nand improving grid management. ML models have become increasingly important in\npredicting renewable energy generation and consumption, utilizing various\ntechniques like artificial neural networks, support vector machines, and\ndecision trees. Furthermore, data preprocessing methods, such as data\nsplitting, normalization, decomposition, and discretization, are employed to\nenhance prediction accuracy.\n  The incorporation of big data and ML into smart grids offers several\nadvantages, including heightened energy efficiency, more effective responses to\ndemand, and better integration of renewable energy sources. Nevertheless,\nchallenges like handling large data volumes, ensuring cybersecurity, and\nobtaining specialized expertise must be addressed. The research investigates\nvarious ML applications within the realms of solar energy, wind energy, and\nelectric distribution and storage, illustrating their potential to optimize\nenergy systems. To sum up, this research demonstrates the evolving landscape of\nthe electricity sector as it shifts from centralized to decentralized solutions\nthrough the application of ML innovations and distributed decision-making,\nultimately shaping a more efficient and sustainable energy future.",
            "author": [
                "Mohammad Mohammadi",
                "Ali Mohammadi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15468v1",
                "http://arxiv.org/pdf/2310.15468v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15467v2",
            "title": "Policy Optimization of Finite-Horizon Kalman Filter with Unknown Noise\n  Covariance",
            "updated": "2023-10-27T15:32:29Z",
            "published": "2023-10-24T02:44:35Z",
            "summary": "This paper is on learning the Kalman gain by policy optimization method.\nFirstly, we reformulate the finite-horizon Kalman filter as a policy\noptimization problem of the dual system. Secondly, we obtain the global linear\nconvergence of exact gradient descent method in the setting of known\nparameters. Thirdly, the gradient estimation and stochastic gradient descent\nmethod are proposed to solve the policy optimization problem, and further the\nglobal linear convergence and sample complexity of stochastic gradient descent\nare provided for the setting of unknown noise covariance matrices and known\nmodel parameters.",
            "author": [
                "Haoran Li",
                "Yuan-Hua Ni"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15467v2",
                "http://arxiv.org/pdf/2310.15467v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15466v1",
            "title": "EKGNet: A 10.96\u03bcW Fully Analog Neural Network for Intra-Patient\n  Arrhythmia Classification",
            "updated": "2023-10-24T02:37:49Z",
            "published": "2023-10-24T02:37:49Z",
            "summary": "We present an integrated approach by combining analog computing and deep\nlearning for electrocardiogram (ECG) arrhythmia classification. We propose\nEKGNet, a hardware-efficient and fully analog arrhythmia classification\narchitecture that archives high accuracy with low power consumption. The\nproposed architecture leverages the energy efficiency of transistors operating\nin the subthreshold region, eliminating the need for analog-to-digital\nconverters (ADC) and static random access memory (SRAM). The system design\nincludes a novel analog sequential Multiply-Accumulate (MAC) circuit that\nmitigates process, supply voltage, and temperature variations. Experimental\nevaluations on PhysioNet's MIT-BIH and PTB Diagnostics datasets demonstrate the\neffectiveness of the proposed method, achieving average balanced accuracy of\n95% and 94.25% for intra-patient arrhythmia classification and myocardial\ninfarction (MI) classification, respectively. This innovative approach presents\na promising avenue for developing low-power arrhythmia classification systems\nwith enhanced accuracy and transferability in biomedical applications.",
            "author": [
                "Benyamin Haghi",
                "Lin Ma",
                "Sahin Lale",
                "Anima Anandkumar",
                "Azita Emami"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15466v1",
                "http://arxiv.org/pdf/2310.15466v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15465v1",
            "title": "A universal meta-heuristic framework for influence maximization in\n  hypergraphs",
            "updated": "2023-10-24T02:27:18Z",
            "published": "2023-10-24T02:27:18Z",
            "summary": "Influence maximization (IM) aims to select a small number of nodes that are\nable to maximize their influence in a network and covers a wide range of\napplications. Despite numerous attempts to provide effective solutions in\nordinary networks, higher-order interactions between entities in various\nreal-world systems are not usually taken into account. In this paper, we\npropose a versatile meta-heuristic approach, hyper genetic algorithm (HGA), to\ntackle the IM problem in hypergraphs, which is based on the concept of genetic\nevolution. Systematic validations in synthetic and empirical hypergraphs under\nboth simple and complex contagion models indicate that HGA achieves universal\nand plausible performance compared to baseline methods. We explore the cause of\nthe excellent performance of HGA through ablation studies and correlation\nanalysis. The findings show that the solution of HGA is distinct from that of\nother prior methods. Moreover, a closer look at the local topological features\nof the seed nodes acquired by different algorithms reveals that the selection\nof seed nodes cannot be based on a single topological characteristic, but\nshould involve a combination of multiple topological features to address the IM\nproblem.",
            "author": [
                "Ming Xie",
                "Xiu-Xiu Zhan",
                "Chuang Liu",
                "Zi-Ke Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15465v1",
                "http://arxiv.org/pdf/2310.15465v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15461v1",
            "title": "Facilitating Self-Guided Mental Health Interventions Through\n  Human-Language Model Interaction: A Case Study of Cognitive Restructuring",
            "updated": "2023-10-24T02:23:34Z",
            "published": "2023-10-24T02:23:34Z",
            "summary": "Self-guided mental health interventions, such as \"do-it-yourself\" tools to\nlearn and practice coping strategies, show great promise to improve access to\nmental health care. However, these interventions are often cognitively\ndemanding and emotionally triggering, creating accessibility barriers that\nlimit their wide-scale implementation and adoption. In this paper, we study how\nhuman-language model interaction can support self-guided mental health\ninterventions. We take cognitive restructuring, an evidence-based therapeutic\ntechnique to overcome negative thinking, as a case study. In an IRB-approved\nrandomized field study on a large mental health website with 15,531\nparticipants, we design and evaluate a system that uses language models to\nsupport people through various steps of cognitive restructuring. Our findings\nreveal that our system positively impacts emotional intensity for 67% of\nparticipants and helps 65% overcome negative thoughts. Although adolescents\nreport relatively worse outcomes, we find that tailored interventions that\nsimplify language model generations improve overall effectiveness and equity.",
            "author": [
                "Ashish Sharma",
                "Kevin Rushton",
                "Inna Wanyin Lin",
                "Theresa Nguyen",
                "Tim Althoff"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15461v1",
                "http://arxiv.org/pdf/2310.15461v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15455v1",
            "title": "UI Layout Generation with LLMs Guided by UI Grammar",
            "updated": "2023-10-24T02:00:12Z",
            "published": "2023-10-24T02:00:12Z",
            "summary": "The recent advances in Large Language Models (LLMs) have stimulated interest\namong researchers and industry professionals, particularly in their application\nto tasks concerning mobile user interfaces (UIs). This position paper\ninvestigates the use of LLMs for UI layout generation. Central to our\nexploration is the introduction of UI grammar -- a novel approach we proposed\nto represent the hierarchical structure inherent in UI screens. The aim of this\napproach is to guide the generative capacities of LLMs more effectively and\nimprove the explainability and controllability of the process. Initial\nexperiments conducted with GPT-4 showed the promising capability of LLMs to\nproduce high-quality user interfaces via in-context learning. Furthermore, our\npreliminary comparative study suggested the potential of the grammar-based\napproach in improving the quality of generative results in specific aspects.",
            "author": [
                "Yuwen Lu",
                "Ziang Tong",
                "Qinyi Zhao",
                "Chengzhi Zhang",
                "Toby Jia-Jun Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15455v1",
                "http://arxiv.org/pdf/2310.15455v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15454v1",
            "title": "Private Learning with Public Features",
            "updated": "2023-10-24T01:59:28Z",
            "published": "2023-10-24T01:59:28Z",
            "summary": "We study a class of private learning problems in which the data is a join of\nprivate and public features. This is often the case in private personalization\ntasks such as recommendation or ad prediction, in which features related to\nindividuals are sensitive, while features related to items (the movies or songs\nto be recommended, or the ads to be shown to users) are publicly available and\ndo not require protection. A natural question is whether private algorithms can\nachieve higher utility in the presence of public features. We give a positive\nanswer for multi-encoder models where one of the encoders operates on public\nfeatures. We develop new algorithms that take advantage of this separation by\nonly protecting certain sufficient statistics (instead of adding noise to the\ngradient). This method has a guaranteed utility improvement for linear\nregression, and importantly, achieves the state of the art on two standard\nprivate recommendation benchmarks, demonstrating the importance of methods that\nadapt to the private-public feature separation.",
            "author": [
                "Walid Krichene",
                "Nicolas Mayoraz",
                "Steffen Rendle",
                "Shuang Song",
                "Abhradeep Thakurta",
                "Li Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15454v1",
                "http://arxiv.org/pdf/2310.15454v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15450v1",
            "title": "General Identifiability and Achievability for Causal Representation\n  Learning",
            "updated": "2023-10-24T01:47:44Z",
            "published": "2023-10-24T01:47:44Z",
            "summary": "This paper focuses on causal representation learning (CRL) under a general\nnonparametric causal latent model and a general transformation model that maps\nthe latent data to the observational data. It establishes\n\\textbf{identifiability} and \\textbf{achievability} results using two hard\n\\textbf{uncoupled} interventions per node in the latent causal graph. Notably,\none does not know which pair of intervention environments have the same node\nintervened (hence, uncoupled environments). For identifiability, the paper\nestablishes that perfect recovery of the latent causal model and variables is\nguaranteed under uncoupled interventions. For achievability, an algorithm is\ndesigned that uses observational and interventional data and recovers the\nlatent causal model and variables with provable guarantees for the algorithm.\nThis algorithm leverages score variations across different environments to\nestimate the inverse of the transformer and, subsequently, the latent\nvariables. The analysis, additionally, recovers the existing identifiability\nresult for two hard \\textbf{coupled} interventions, that is when metadata about\nthe pair of environments that have the same node intervened is known. It is\nnoteworthy that the existing results on non-parametric identifiability require\nassumptions on interventions and additional faithfulness assumptions. This\npaper shows that when observational data is available, additional faithfulness\nassumptions are unnecessary.",
            "author": [
                "Burak Var\u0131c\u0131",
                "Emre Acart\u00fcrk",
                "Karthikeyan Shanmugam",
                "Ali Tajer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15450v1",
                "http://arxiv.org/pdf/2310.15450v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15448v1",
            "title": "An accelerated first-order regularized momentum descent ascent algorithm\n  for stochastic nonconvex-concave minimax problems",
            "updated": "2023-10-24T01:45:11Z",
            "published": "2023-10-24T01:45:11Z",
            "summary": "Stochastic nonconvex minimax problems have attracted wide attention in\nmachine learning, signal processing and many other fields in recent years. In\nthis paper, we propose an accelerated first-order regularized momentum descent\nascent algorithm (FORMDA) for solving stochastic nonconvex-concave minimax\nproblems. The iteration complexity of the algorithm is proved to be\n$\\tilde{\\mathcal{O}}(\\varepsilon ^{-6.5})$ to obtain an\n$\\varepsilon$-stationary point, which achieves the best-known complexity bound\nfor single-loop algorithms to solve the stochastic nonconvex-concave minimax\nproblems under the stationarity of the objective function.",
            "author": [
                "Huiling Zhang",
                "Zi Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15448v1",
                "http://arxiv.org/pdf/2310.15448v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15440v1",
            "title": "Learning Dynamics in Linear VAE: Posterior Collapse Threshold,\n  Superfluous Latent Space Pitfalls, and Speedup with KL Annealing",
            "updated": "2023-10-24T01:20:27Z",
            "published": "2023-10-24T01:20:27Z",
            "summary": "Variational autoencoders (VAEs) face a notorious problem wherein the\nvariational posterior often aligns closely with the prior, a phenomenon known\nas posterior collapse, which hinders the quality of representation learning. To\nmitigate this problem, an adjustable hyperparameter $\\beta$ and a strategy for\nannealing this parameter, called KL annealing, are proposed. This study\npresents a theoretical analysis of the learning dynamics in a minimal VAE. It\nis rigorously proved that the dynamics converge to a deterministic process\nwithin the limit of large input dimensions, thereby enabling a detailed\ndynamical analysis of the generalization error. Furthermore, the analysis shows\nthat the VAE initially learns entangled representations and gradually acquires\ndisentangled representations. A fixed-point analysis of the deterministic\nprocess reveals that when $\\beta$ exceeds a certain threshold, posterior\ncollapse becomes inevitable regardless of the learning period. Additionally,\nthe superfluous latent variables for the data-generative factors lead to\noverfitting of the background noise; this adversely affects both generalization\nand learning convergence. The analysis further unveiled that appropriately\ntuned KL annealing can accelerate convergence.",
            "author": [
                "Yuma Ichikawa",
                "Koji Hukushima"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15440v1",
                "http://arxiv.org/pdf/2310.15440v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cond-mat.dis-nn",
                "cs.LG",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15436v1",
            "title": "VGX: Large-Scale Sample Generation for Boosting Learning-Based Software\n  Vulnerability Analyses",
            "updated": "2023-10-24T01:05:00Z",
            "published": "2023-10-24T01:05:00Z",
            "summary": "Accompanying the successes of learning-based defensive software vulnerability\nanalyses is the lack of large and quality sets of labeled vulnerable program\nsamples, which impedes further advancement of those defenses. Existing\nautomated sample generation approaches have shown potentials yet still fall\nshort of practical expectations due to the high noise in the generated samples.\nThis paper proposes VGX, a new technique aimed for large-scale generation of\nhigh-quality vulnerability datasets. Given a normal program, VGX identifies the\ncode contexts in which vulnerabilities can be injected, using a customized\nTransformer featured with a new value-flowbased position encoding and\npre-trained against new objectives particularly for learning code structure and\ncontext. Then, VGX materializes vulnerability-injection code editing in the\nidentified contexts using patterns of such edits obtained from both historical\nfixes and human knowledge about real-world vulnerabilities. Compared to four\nstate-of-the-art (SOTA) baselines (pattern-, Transformer-, GNN-, and\npattern+Transformer-based), VGX achieved 99.09-890.06% higher F1 and\n22.45%-328.47% higher label accuracy. For in-the-wild sample production, VGX\ngenerated 150,392 vulnerable samples, from which we randomly chose 10% to\nassess how much these samples help vulnerability detection, localization, and\nrepair. Our results show SOTA techniques for these three application tasks\nachieved 19.15-330.80% higher F1, 12.86-19.31% higher top-10 accuracy, and\n85.02-99.30% higher top-50 accuracy, respectively, by adding those samples to\ntheir original training data. These samples also helped a SOTA vulnerability\ndetector discover 13 more real-world vulnerabilities (CVEs) in critical systems\n(e.g., Linux kernel) that would be missed by the original model.",
            "author": [
                "Yu Nong",
                "Richard Fang",
                "Guangbei Yi",
                "Kunsong Zhao",
                "Xiapu Luo",
                "Feng Chen",
                "Haipeng Cai"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15436v1",
                "http://arxiv.org/pdf/2310.15436v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15433v1",
            "title": "Off-Policy Evaluation for Large Action Spaces via Policy Convolution",
            "updated": "2023-10-24T01:00:01Z",
            "published": "2023-10-24T01:00:01Z",
            "summary": "Developing accurate off-policy estimators is crucial for both evaluating and\noptimizing for new policies. The main challenge in off-policy estimation is the\ndistribution shift between the logging policy that generates data and the\ntarget policy that we aim to evaluate. Typically, techniques for correcting\ndistribution shift involve some form of importance sampling. This approach\nresults in unbiased value estimation but often comes with the trade-off of high\nvariance, even in the simpler case of one-step contextual bandits. Furthermore,\nimportance sampling relies on the common support assumption, which becomes\nimpractical when the action space is large. To address these challenges, we\nintroduce the Policy Convolution (PC) family of estimators. These methods\nleverage latent structure within actions -- made available through action\nembeddings -- to strategically convolve the logging and target policies. This\nconvolution introduces a unique bias-variance trade-off, which can be\ncontrolled by adjusting the amount of convolution. Our experiments on synthetic\nand benchmark datasets demonstrate remarkable mean squared error (MSE)\nimprovements when using PC, especially when either the action space or policy\nmismatch becomes large, with gains of up to 5 - 6 orders of magnitude over\nexisting estimators.",
            "author": [
                "Noveen Sachdeva",
                "Lequn Wang",
                "Dawen Liang",
                "Nathan Kallus",
                "Julian McAuley"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15433v1",
                "http://arxiv.org/pdf/2310.15433v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15431v2",
            "title": "What Makes it Ok to Set a Fire? Iterative Self-distillation of Contexts\n  and Rationales for Disambiguating Defeasible Social and Moral Situations",
            "updated": "2023-11-01T04:39:14Z",
            "published": "2023-10-24T00:51:29Z",
            "summary": "Moral or ethical judgments rely heavily on the specific contexts in which\nthey occur. Understanding varying shades of defeasible contextualizations\n(i.e., additional information that strengthens or attenuates the moral\nacceptability of an action) is critical to accurately represent the subtlety\nand intricacy of grounded human moral judgment in real-life scenarios.\n  We introduce defeasible moral reasoning: a task to provide grounded contexts\nthat make an action more or less morally acceptable, along with commonsense\nrationales that justify the reasoning. To elicit high-quality task data, we\ntake an iterative self-distillation approach that starts from a small amount of\nunstructured seed knowledge from GPT-3 and then alternates between (1)\nself-distillation from student models; (2) targeted filtering with a critic\nmodel trained by human judgment (to boost validity) and NLI (to boost\ndiversity); (3) self-imitation learning (to amplify the desired data quality).\nThis process yields a student model that produces defeasible contexts with\nimproved validity, diversity, and defeasibility. From this model we distill a\nhigh-quality dataset, \\delta-Rules-of-Thumb, of 1.2M entries of\ncontextualizations and rationales for 115K defeasible moral actions rated\nhighly by human annotators 85.9% to 99.8% of the time. Using \\delta-RoT we\nobtain a final student model that wins over all intermediate student models by\na notable margin.",
            "author": [
                "Kavel Rao",
                "Liwei Jiang",
                "Valentina Pyatkin",
                "Yuling Gu",
                "Niket Tandon",
                "Nouha Dziri",
                "Faeze Brahman",
                "Yejin Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15431v2",
                "http://arxiv.org/pdf/2310.15431v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18356v2",
            "title": "LoRAShear: Efficient Large Language Model Structured Pruning and\n  Knowledge Recovery",
            "updated": "2023-10-31T04:21:33Z",
            "published": "2023-10-24T00:47:26Z",
            "summary": "Large Language Models (LLMs) have transformed the landscape of artificial\nintelligence, while their enormous size presents significant challenges in\nterms of computational costs. We introduce LoRAShear, a novel efficient\napproach to structurally prune LLMs and recover knowledge. Given general LLMs,\nLoRAShear at first creates the dependency graphs over LoRA modules to discover\nminimally removal structures and analyze the knowledge distribution. It then\nproceeds progressive structured pruning on LoRA adaptors and enables inherent\nknowledge transfer to better preserve the information in the redundant\nstructures. To recover the lost knowledge during pruning, LoRAShear\nmeticulously studies and proposes a dynamic fine-tuning schemes with dynamic\ndata adaptors to effectively narrow down the performance gap to the full\nmodels. Numerical results demonstrate that by only using one GPU within a\ncouple of GPU days, LoRAShear effectively reduced footprint of LLMs by 20% with\nonly 1.0% performance degradation and significantly outperforms\nstate-of-the-arts. The source code will be available at\nhttps://github.com/microsoft/lorashear.",
            "author": [
                "Tianyi Chen",
                "Tianyu Ding",
                "Badal Yadav",
                "Ilya Zharkov",
                "Luming Liang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18356v2",
                "http://arxiv.org/pdf/2310.18356v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15425v1",
            "title": "The Mason-Alberta Phonetic Segmenter: A forced alignment system based on\n  deep neural networks and interpolation",
            "updated": "2023-10-24T00:43:54Z",
            "published": "2023-10-24T00:43:54Z",
            "summary": "Forced alignment systems automatically determine boundaries between segments\nin speech data, given an orthographic transcription. These tools are\ncommonplace in phonetics to facilitate the use of speech data that would be\ninfeasible to manually transcribe and segment. In the present paper, we\ndescribe a new neural network-based forced alignment system, the Mason-Alberta\nPhonetic Segmenter (MAPS). The MAPS aligner serves as a testbed for two\npossible improvements we pursue for forced alignment systems. The first is\ntreating the acoustic model in a forced aligner as a tagging task, rather than\na classification task, motivated by the common understanding that segments in\nspeech are not truly discrete and commonly overlap. The second is an\ninterpolation technique to allow boundaries more precise than the common 10 ms\nlimit in modern forced alignment systems. We compare configurations of our\nsystem to a state-of-the-art system, the Montreal Forced Aligner. The tagging\napproach did not generally yield improved results over the Montreal Forced\nAligner. However, a system with the interpolation technique had a 27.92%\nincrease relative to the Montreal Forced Aligner in the amount of boundaries\nwithin 10 ms of the target on the test set. We also reflect on the task and\ntraining process for acoustic modeling in forced alignment, highlighting how\nthe output targets for these models do not match phoneticians' conception of\nsimilarity between phones and that reconciliation of this tension may require\nrethinking the task and output targets or how speech itself should be\nsegmented.",
            "author": [
                "Matthew C. Kelley",
                "Scott James Perry",
                "Benjamin V. Tucker"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15425v1",
                "http://arxiv.org/pdf/2310.15425v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.CL",
                "cs.LG",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15418v1",
            "title": "Fractal Landscapes in Policy Optimization",
            "updated": "2023-10-24T00:22:19Z",
            "published": "2023-10-24T00:22:19Z",
            "summary": "Policy gradient lies at the core of deep reinforcement learning (RL) in\ncontinuous domains. Despite much success, it is often observed in practice that\nRL training with policy gradient can fail for many reasons, even on standard\ncontrol problems with known solutions. We propose a framework for understanding\none inherent limitation of the policy gradient approach: the optimization\nlandscape in the policy space can be extremely non-smooth or fractal for\ncertain classes of MDPs, such that there does not exist gradient to be\nestimated in the first place. We draw on techniques from chaos theory and\nnon-smooth analysis, and analyze the maximal Lyapunov exponents and H\\\"older\nexponents of the policy optimization objectives. Moreover, we develop a\npractical method that can estimate the local smoothness of objective function\nfrom samples to identify when the training process has encountered fractal\nlandscapes. We show experiments to illustrate how some failure cases of policy\noptimization can be explained by such fractal landscapes.",
            "author": [
                "Tao Wang",
                "Sylvia Herbert",
                "Sicun Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15418v1",
                "http://arxiv.org/pdf/2310.15418v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15416v1",
            "title": "Nominality Score Conditioned Time Series Anomaly Detection by\n  Point/Sequential Reconstruction",
            "updated": "2023-10-24T00:14:57Z",
            "published": "2023-10-24T00:14:57Z",
            "summary": "Time series anomaly detection is challenging due to the complexity and\nvariety of patterns that can occur. One major difficulty arises from modeling\ntime-dependent relationships to find contextual anomalies while maintaining\ndetection accuracy for point anomalies. In this paper, we propose a framework\nfor unsupervised time series anomaly detection that utilizes point-based and\nsequence-based reconstruction models. The point-based model attempts to\nquantify point anomalies, and the sequence-based model attempts to quantify\nboth point and contextual anomalies. Under the formulation that the observed\ntime point is a two-stage deviated value from a nominal time point, we\nintroduce a nominality score calculated from the ratio of a combined value of\nthe reconstruction errors. We derive an induced anomaly score by further\nintegrating the nominality score and anomaly score, then theoretically prove\nthe superiority of the induced anomaly score over the original anomaly score\nunder certain conditions. Extensive studies conducted on several public\ndatasets show that the proposed framework outperforms most state-of-the-art\nbaselines for time series anomaly detection.",
            "author": [
                "Chih-Yu Lai",
                "Fan-Keng Sun",
                "Zhengqi Gao",
                "Jeffrey H. Lang",
                "Duane S. Boning"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15416v1",
                "http://arxiv.org/pdf/2310.15416v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15414v1",
            "title": "Diverse Conventions for Human-AI Collaboration",
            "updated": "2023-10-24T00:07:20Z",
            "published": "2023-10-24T00:07:20Z",
            "summary": "Conventions are crucial for strong performance in cooperative multi-agent\ngames, because they allow players to coordinate on a shared strategy without\nexplicit communication. Unfortunately, standard multi-agent reinforcement\nlearning techniques, such as self-play, converge to conventions that are\narbitrary and non-diverse, leading to poor generalization when interacting with\nnew partners. In this work, we present a technique for generating diverse\nconventions by (1) maximizing their rewards during self-play, while (2)\nminimizing their rewards when playing with previously discovered conventions\n(cross-play), stimulating conventions to be semantically different. To ensure\nthat learned policies act in good faith despite the adversarial optimization of\ncross-play, we introduce \\emph{mixed-play}, where an initial state is randomly\ngenerated by sampling self-play and cross-play transitions and the player\nlearns to maximize the self-play reward from this initial state. We analyze the\nbenefits of our technique on various multi-agent collaborative games, including\nOvercooked, and find that our technique can adapt to the conventions of humans,\nsurpassing human-level performance when paired with real users.",
            "author": [
                "Bidipta Sarkar",
                "Andy Shih",
                "Dorsa Sadigh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15414v1",
                "http://arxiv.org/pdf/2310.15414v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15411v1",
            "title": "Efficient Active Learning Halfspaces with Tsybakov Noise: A Non-convex\n  Optimization Approach",
            "updated": "2023-10-23T23:55:28Z",
            "published": "2023-10-23T23:55:28Z",
            "summary": "We study the problem of computationally and label efficient PAC active\nlearning $d$-dimensional halfspaces with Tsybakov\nNoise~\\citep{tsybakov2004optimal} under structured unlabeled data\ndistributions. Inspired by~\\cite{diakonikolas2020learning}, we prove that any\napproximate first-order stationary point of a smooth nonconvex loss function\nyields a halfspace with a low excess error guarantee. In light of the above\nstructural result, we design a nonconvex optimization-based algorithm with a\nlabel complexity of $\\tilde{O}(d\n(\\frac{1}{\\epsilon})^{\\frac{8-6\\alpha}{3\\alpha-1}})$\\footnote{In the main body\nof this work, we use $\\tilde{O}(\\cdot), \\tilde{\\Theta}(\\cdot)$ to hide factors\nof the form $\\polylog(d, \\frac{1}{\\epsilon}, \\frac{1}{\\delta})$}, under the\nassumption that the Tsybakov noise parameter $\\alpha \\in (\\frac13, 1]$, which\nnarrows down the gap between the label complexities of the previously known\nefficient passive or active\nalgorithms~\\citep{diakonikolas2020polynomial,zhang2021improved} and the\ninformation-theoretic lower bound in this setting.",
            "author": [
                "Yinan Li",
                "Chicheng Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15411v1",
                "http://arxiv.org/pdf/2310.15411v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.16060v1",
            "title": "Adaptive Fuzzy Tracking Control for Nonlinear State Constrained\n  Pure-Feedback Systems With Input Delay via Dynamic Surface Technique",
            "updated": "2023-10-23T23:31:47Z",
            "published": "2023-10-23T23:31:47Z",
            "summary": "This brief constructs the adaptive backstepping control scheme for a class of\npure-feedback systems with input delay and full state constraints. With the\nhelp of Mean Value Theorem, the pure-feedback system is transformed into\nstrict-feedback one. Barrier Lyapunov functions are employed to guarantee all\nof the states remain constrained within predefined sets. By introducing the\nPade approximation method and corresponding intermediate, the impact generated\nby input delay on the output tracking performance of the system can be\neliminated. Furthermore, a low-pass filter driven by a newly-defined control\ninput, is employed to generate the actual control input, which facilitates the\ndesign of backstepping control. To approximate the unknown functions with a\ndesired level of accuracy, the fuzzy logic systems (FLSs) are utilized by\nchoosing appropriate fuzzy rules, logics and so on. The minimal learning\nparameter (MLP) technique is employed to decrease the number of nodes and\nparameters in FLSs, and dynamic surface control (DSC) technique is leveraged to\navoid so-called \"explosion of complexity\". Moreover, smooth robust compensators\nare introduced to circumvent the influences of external disturbance and\napproximation errors. By stability analysis, it is proved that all of signals\nin the closed-loop system are semi-globally ultimately uniform bounded, and the\ntracking error can be within a arbitrary small neighbor of origin via selecting\nappropriate parameters of controllers. Finally, the results of numerical\nillustration are provided to demonstrate the effectiveness of the designed\nmethod.",
            "author": [
                "Ju Wu",
                "Tong Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.16060v1",
                "http://arxiv.org/pdf/2310.16060v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15402v1",
            "title": "Towards contrast-agnostic soft segmentation of the spinal cord",
            "updated": "2023-10-23T23:15:28Z",
            "published": "2023-10-23T23:15:28Z",
            "summary": "Spinal cord segmentation is clinically relevant and is notably used to\ncompute spinal cord cross-sectional area (CSA) for the diagnosis and monitoring\nof cord compression or neurodegenerative diseases such as multiple sclerosis.\nWhile several semi and automatic methods exist, one key limitation remains: the\nsegmentation depends on the MRI contrast, resulting in different CSA across\ncontrasts. This is partly due to the varying appearance of the boundary between\nthe spinal cord and the cerebrospinal fluid that depends on the sequence and\nacquisition parameters. This contrast-sensitive CSA adds variability in\nmulti-center studies where protocols can vary, reducing the sensitivity to\ndetect subtle atrophies. Moreover, existing methods enhance the CSA variability\nby training one model per contrast, while also producing binary masks that do\nnot account for partial volume effects. In this work, we present a deep\nlearning-based method that produces soft segmentations of the spinal cord.\nUsing the Spine Generic Public Database of healthy participants\n($\\text{n}=267$; $\\text{contrasts}=6$), we first generated participant-wise\nsoft ground truth (GT) by averaging the binary segmentations across all 6\ncontrasts. These soft GT, along with a regression-based loss function, were\nthen used to train a UNet model for spinal cord segmentation. We evaluated our\nmodel against state-of-the-art methods and performed ablation studies involving\ndifferent GT mask types, loss functions, and contrast-specific models. Our\nresults show that using the soft average segmentations along with a regression\nloss function reduces CSA variability ($p < 0.05$, Wilcoxon signed-rank test).\nThe proposed spinal cord segmentation model generalizes better than the\nstate-of-the-art contrast-specific methods amongst unseen datasets, vendors,\ncontrasts, and pathologies (compression, lesions), while accounting for partial\nvolume effects.",
            "author": [
                "Sandrine B\u00e9dard",
                "Naga Karthik Enamundram",
                "Charidimos Tsagkas",
                "Emanuele Pravat\u00e0",
                "Cristina Granziera",
                "Andrew Smith",
                "Kenneth Arnold Weber II",
                "Julien Cohen-Adad"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15402v1",
                "http://arxiv.org/pdf/2310.15402v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15393v1",
            "title": "DoGE: Domain Reweighting with Generalization Estimation",
            "updated": "2023-10-23T22:51:58Z",
            "published": "2023-10-23T22:51:58Z",
            "summary": "The coverage and composition of the pretraining data corpus significantly\nimpacts the generalization ability of large language models. Conventionally,\nthe pretraining corpus is composed of various source domains (e.g. CommonCrawl,\nWikipedia, Github etc.) according to certain sampling probabilities (domain\nweights). However, current methods lack a principled way to optimize domain\nweights for ultimate goal for generalization. We propose DOmain reweighting\nwith Generalization Estimation (DoGE), where we reweigh the sampling\nprobability from each domain based on its contribution to the final\ngeneralization objective assessed by a gradient-based generalization estimation\nfunction. First, we train a small-scale proxy model with a min-max optimization\nto obtain the reweighted domain weights. At each step, the domain weights are\nupdated to maximize the overall generalization gain by mirror descent. Finally\nwe use the obtained domain weights to train a larger scale full-size language\nmodel. On SlimPajama-6B dataset, with universal generalization objective, DoGE\nachieves better average perplexity and zero-shot reasoning accuracy. On\nout-of-domain generalization tasks, DoGE reduces perplexity on the target\ndomain by a large margin. We further apply a parameter-selection scheme which\nimproves the efficiency of generalization estimation.",
            "author": [
                "Simin Fan",
                "Matteo Pagliardini",
                "Martin Jaggi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15393v1",
                "http://arxiv.org/pdf/2310.15393v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15390v2",
            "title": "MEMPSEP III. A machine learning-oriented multivariate data set for\n  forecasting the Occurrence and Properties of Solar Energetic Particle Events\n  using a Multivariate Ensemble Approach",
            "updated": "2023-10-26T20:48:52Z",
            "published": "2023-10-23T22:42:23Z",
            "summary": "We introduce a new multivariate data set that utilizes multiple spacecraft\ncollecting in-situ and remote sensing heliospheric measurements shown to be\nlinked to physical processes responsible for generating solar energetic\nparticles (SEPs). Using the Geostationary Operational Environmental Satellites\n(GOES) flare event list from Solar Cycle (SC) 23 and part of SC 24 (1998-2013),\nwe identify 252 solar events (flares) that produce SEPs and 17,542 events that\ndo not. For each identified event, we acquire the local plasma properties at 1\nau, such as energetic proton and electron data, upstream solar wind conditions,\nand the interplanetary magnetic field vector quantities using various\ninstruments onboard GOES and the Advanced Composition Explorer (ACE)\nspacecraft. We also collect remote sensing data from instruments onboard the\nSolar Dynamic Observatory (SDO), Solar and Heliospheric Observatory (SoHO), and\nthe Wind solar radio instrument WAVES. The data set is designed to allow for\nvariations of the inputs and feature sets for machine learning (ML) in\nheliophysics and has a specific purpose for forecasting the occurrence of SEP\nevents and their subsequent properties. This paper describes a dataset created\nfrom multiple publicly available observation sources that is validated,\ncleaned, and carefully curated for our machine-learning pipeline. The dataset\nhas been used to drive the newly-developed Multivariate Ensemble of Models for\nProbabilistic Forecast of Solar Energetic Particles (MEMPSEP; see MEMPSEP I\n(Chatterjee et al., 2023) and MEMPSEP II (Dayeh et al., 2023) for associated\npapers).",
            "author": [
                "Kimberly Moreland",
                "Maher Dayeh",
                "Hazel M. Bain",
                "Subhamoy Chatterjee",
                "Andres Munoz-Jaramillo",
                "Samuel Hart"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15390v2",
                "http://arxiv.org/pdf/2310.15390v2"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "cs.LG",
                "physics.space-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15389v1",
            "title": "Irreducible Curriculum for Language Model Pretraining",
            "updated": "2023-10-23T22:41:33Z",
            "published": "2023-10-23T22:41:33Z",
            "summary": "Automatic data selection and curriculum design for training large language\nmodels is challenging, with only a few existing methods showing improvements\nover standard training. Furthermore, current schemes focus on domain-level\nselection, overlooking the more fine-grained contributions of each individual\ntraining point. It is difficult to apply traditional datapoint selection\nmethods on large language models: most online batch selection methods perform\ntwo-times forward or backward passes, which introduces considerable extra costs\nwith large-scale models. To mitigate these obstacles, we propose irreducible\ncurriculum as a curriculum learning algorithm for language model pretraining,\nwhich prioritizes samples with higher learnability. Specifically, to avoid\nprohibitive extra computation overhead, we simulate the sample loss along the\nmain model's training trajectory using a small-scale proxy model. Our\nexperiments on the RedPajama-1B dataset demonstrate a consistent improvement on\nvalidation perplexity across all 7 domains compared to random uniform baseline\nand the anti-curriculum strategy. Our method also reduces the sharpness of the\nnetwork and illustrates a better 5-shot accuracy on MMLU benchmarks.",
            "author": [
                "Simin Fan",
                "Martin Jaggi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15389v1",
                "http://arxiv.org/pdf/2310.15389v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15388v1",
            "title": "Remote Heart Rate Monitoring in Smart Environments from Videos with\n  Self-supervised Pre-training",
            "updated": "2023-10-23T22:41:04Z",
            "published": "2023-10-23T22:41:04Z",
            "summary": "Recent advances in deep learning have made it increasingly feasible to\nestimate heart rate remotely in smart environments by analyzing videos.\nHowever, a notable limitation of deep learning methods is their heavy reliance\non extensive sets of labeled data for effective training. To address this\nissue, self-supervised learning has emerged as a promising avenue. Building on\nthis, we introduce a solution that utilizes self-supervised contrastive\nlearning for the estimation of remote photoplethysmography (PPG) and heart rate\nmonitoring, thereby reducing the dependence on labeled data and enhancing\nperformance. We propose the use of 3 spatial and 3 temporal augmentations for\ntraining an encoder through a contrastive framework, followed by utilizing the\nlate-intermediate embeddings of the encoder for remote PPG and heart rate\nestimation. Our experiments on two publicly available datasets showcase the\nimprovement of our proposed approach over several related works as well as\nsupervised learning baselines, as our results approach the state-of-the-art. We\nalso perform thorough experiments to showcase the effects of using different\ndesign choices such as the video representation learning method, the\naugmentations used in the pre-training stage, and others. We also demonstrate\nthe robustness of our proposed method over the supervised learning approaches\non reduced amounts of labeled data.",
            "author": [
                "Divij Gupta",
                "Ali Etemad"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15388v1",
                "http://arxiv.org/pdf/2310.15388v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15387v1",
            "title": "Error analysis of generative adversarial network",
            "updated": "2023-10-23T22:39:28Z",
            "published": "2023-10-23T22:39:28Z",
            "summary": "The generative adversarial network (GAN) is an important model developed for\nhigh-dimensional distribution learning in recent years. However, there is a\npressing need for a comprehensive method to understand its error convergence\nrate. In this research, we focus on studying the error convergence rate of the\nGAN model that is based on a class of functions encompassing the discriminator\nand generator neural networks. These functions are VC type with bounded\nenvelope function under our assumptions, enabling the application of the\nTalagrand inequality. By employing the Talagrand inequality and Borel-Cantelli\nlemma, we establish a tight convergence rate for the error of GAN. This method\ncan also be applied on existing error estimations of GAN and yields improved\nconvergence rates. In particular, the error defined with the neural network\ndistance is a special case error in our definition.",
            "author": [
                "Mahmud Hasan",
                "Hailin Sang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15387v1",
                "http://arxiv.org/pdf/2310.15387v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15386v2",
            "title": "Course Correcting Koopman Representations",
            "updated": "2023-11-23T06:32:10Z",
            "published": "2023-10-23T22:36:31Z",
            "summary": "Koopman representations aim to learn features of nonlinear dynamical systems\n(NLDS) which lead to linear dynamics in the latent space. Theoretically, such\nfeatures can be used to simplify many problems in modeling and control of NLDS.\nIn this work we study autoencoder formulations of this problem, and different\nways they can be used to model dynamics, specifically for future state\nprediction over long horizons. We discover several limitations of predicting\nfuture states in the latent space and propose an inference-time mechanism,\nwhich we refer to as Periodic Reencoding, for faithfully capturing long term\ndynamics. We justify this method both analytically and empirically via\nexperiments in low and high dimensional NLDS.",
            "author": [
                "Mahan Fathi",
                "Clement Gehring",
                "Jonathan Pilault",
                "David Kanaa",
                "Pierre-Luc Bacon",
                "Ross Goroshin"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15386v2",
                "http://arxiv.org/pdf/2310.15386v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18355v1",
            "title": "Health Disparities through Generative AI Models: A Comparison Study\n  Using A Domain Specific large language model",
            "updated": "2023-10-23T21:24:05Z",
            "published": "2023-10-23T21:24:05Z",
            "summary": "Health disparities are differences in health outcomes and access to\nhealthcare between different groups, including racial and ethnic minorities,\nlow-income people, and rural residents. An artificial intelligence (AI) program\ncalled large language models (LLMs) can understand and generate human language,\nimproving health communication and reducing health disparities. There are many\nchallenges in using LLMs in human-doctor interaction, including the need for\ndiverse and representative data, privacy concerns, and collaboration between\nhealthcare providers and technology experts. We introduce the comparative\ninvestigation of domain-specific large language models such as SciBERT with a\nmulti-purpose LLMs BERT. We used cosine similarity to analyze text queries\nabout health disparities in exam rooms when factors such as race are used\nalone. Using text queries, SciBERT fails when it doesn't differentiate between\nqueries text: \"race\" alone and \"perpetuates health disparities.\" We believe\nclinicians can use generative AI to create a draft response when communicating\nasynchronously with patients. However, careful attention must be paid to ensure\nthey are developed and implemented ethically and equitably.",
            "author": [
                "Yohn Jairo Parra Bautista",
                "Vinicious Lima",
                "Carlos Theran",
                "Richard Alo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18355v1",
                "http://arxiv.org/pdf/2310.18355v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15371v1",
            "title": "Vicinal Feature Statistics Augmentation for Federated 3D Medical Volume\n  Segmentation",
            "updated": "2023-10-23T21:14:52Z",
            "published": "2023-10-23T21:14:52Z",
            "summary": "Federated learning (FL) enables multiple client medical institutes\ncollaboratively train a deep learning (DL) model with privacy protection.\nHowever, the performance of FL can be constrained by the limited availability\nof labeled data in small institutes and the heterogeneous (i.e., non-i.i.d.)\ndata distribution across institutes. Though data augmentation has been a proven\ntechnique to boost the generalization capabilities of conventional centralized\nDL as a \"free lunch\", its application in FL is largely underexplored. Notably,\nconstrained by costly labeling, 3D medical segmentation generally relies on\ndata augmentation. In this work, we aim to develop a vicinal feature-level data\naugmentation (VFDA) scheme to efficiently alleviate the local feature shift and\nfacilitate collaborative training for privacy-aware FL segmentation. We take\nboth the inner- and inter-institute divergence into consideration, without the\nneed for cross-institute transfer of raw data or their mixup. Specifically, we\nexploit the batch-wise feature statistics (e.g., mean and standard deviation)\nin each institute to abstractly represent the discrepancy of data, and model\neach feature statistic probabilistically via a Gaussian prototype, with the\nmean corresponding to the original statistic and the variance quantifying the\naugmentation scope. From the vicinal risk minimization perspective, novel\nfeature statistics can be drawn from the Gaussian distribution to fulfill\naugmentation. The variance is explicitly derived by the data bias in each\nindividual institute and the underlying feature statistics characterized by all\nparticipating institutes. The added-on VFDA consistently yielded marked\nimprovements over six advanced FL methods on both 3D brain tumor and cardiac\nsegmentation.",
            "author": [
                "Yongsong Huang",
                "Wanqing Xie",
                "Mingzhen Li",
                "Mingmei Cheng",
                "Jinzhou Wu",
                "Weixiao Wang",
                "Jane You",
                "Xiaofeng Liu"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-34048-2_28",
                "http://arxiv.org/abs/2310.15371v1",
                "http://arxiv.org/pdf/2310.15371v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.CV",
                "cs.LG",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15358v1",
            "title": "Learning Fair Representations with High-Confidence Guarantees",
            "updated": "2023-10-23T20:43:03Z",
            "published": "2023-10-23T20:43:03Z",
            "summary": "Representation learning is increasingly employed to generate representations\nthat are predictive across multiple downstream tasks. The development of\nrepresentation learning algorithms that provide strong fairness guarantees is\nthus important because it can prevent unfairness towards disadvantaged groups\nfor all downstream prediction tasks. To prevent unfairness towards\ndisadvantaged groups in all downstream tasks, it is crucial to provide\nrepresentation learning algorithms that provide fairness guarantees. In this\npaper, we formally define the problem of learning representations that are fair\nwith high confidence. We then introduce the Fair Representation learning with\nhigh-confidence Guarantees (FRG) framework, which provides high-confidence\nguarantees for limiting unfairness across all downstream models and tasks, with\nuser-defined upper bounds. After proving that FRG ensures fairness for all\ndownstream models and tasks with high probability, we present empirical\nevaluations that demonstrate FRG's effectiveness at upper bounding unfairness\nfor multiple downstream models and tasks.",
            "author": [
                "Yuhong Luo",
                "Austin Hoag",
                "Philip S. Thomas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15358v1",
                "http://arxiv.org/pdf/2310.15358v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15355v1",
            "title": "Why LLMs Hallucinate, and How to Get (Evidential) Closure: Perceptual,\n  Intensional, and Extensional Learning for Faithful Natural Language\n  Generation",
            "updated": "2023-10-23T20:35:52Z",
            "published": "2023-10-23T20:35:52Z",
            "summary": "We show that LLMs hallucinate because their output is not constrained to be\nsynonymous with claims for which they have evidence: a condition that we call\nevidential closure. Information about the truth or falsity of sentences is not\nstatistically identified in the standard neural probabilistic language model\nsetup, and so cannot be conditioned on to generate new strings. We then show\nhow to constrain LLMs to produce output that does satisfy evidential closure. A\nmultimodal LLM must learn about the external world (perceptual learning); it\nmust learn a mapping from strings to states of the world (extensional\nlearning); and, to achieve fluency when generalizing beyond a body of evidence,\nit must learn mappings from strings to their synonyms (intensional learning).\nThe output of a unimodal LLM must be synonymous with strings in a validated\nevidence set. Finally, we present a heuristic procedure, Learn-Babble-Prune,\nthat yields faithful output from an LLM by rejecting output that is not\nsynonymous with claims for which the LLM has evidence.",
            "author": [
                "Adam Bouyamourn"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15355v1",
                "http://arxiv.org/pdf/2310.15355v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15351v1",
            "title": "Random Exploration in Bayesian Optimization: Order-Optimal Regret and\n  Computational Efficiency",
            "updated": "2023-10-23T20:30:44Z",
            "published": "2023-10-23T20:30:44Z",
            "summary": "We consider Bayesian optimization using Gaussian Process models, also\nreferred to as kernel-based bandit optimization. We study the methodology of\nexploring the domain using random samples drawn from a distribution. We show\nthat this random exploration approach achieves the optimal error rates. Our\nanalysis is based on novel concentration bounds in an infinite dimensional\nHilbert space established in this work, which may be of independent interest.\nWe further develop an algorithm based on random exploration with domain\nshrinking and establish its order-optimal regret guarantees under both\nnoise-free and noisy settings. In the noise-free setting, our analysis closes\nthe existing gap in regret performance and thereby resolves a COLT open\nproblem. The proposed algorithm also enjoys a computational advantage over\nprevailing methods due to the random exploration that obviates the expensive\noptimization of a non-convex acquisition function for choosing the query points\nat each iteration.",
            "author": [
                "Sudeep Salgia",
                "Sattar Vakili",
                "Qing Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15351v1",
                "http://arxiv.org/pdf/2310.15351v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.18354v1",
            "title": "A Review of Reinforcement Learning for Natural Language Processing, and\n  Applications in Healthcare",
            "updated": "2023-10-23T20:26:15Z",
            "published": "2023-10-23T20:26:15Z",
            "summary": "Reinforcement learning (RL) has emerged as a powerful approach for tackling\ncomplex medical decision-making problems such as treatment planning,\npersonalized medicine, and optimizing the scheduling of surgeries and\nappointments. It has gained significant attention in the field of Natural\nLanguage Processing (NLP) due to its ability to learn optimal strategies for\ntasks such as dialogue systems, machine translation, and question-answering.\nThis paper presents a review of the RL techniques in NLP, highlighting key\nadvancements, challenges, and applications in healthcare. The review begins by\nvisualizing a roadmap of machine learning and its applications in healthcare.\nAnd then it explores the integration of RL with NLP tasks. We examined dialogue\nsystems where RL enables the learning of conversational strategies, RL-based\nmachine translation models, question-answering systems, text summarization, and\ninformation extraction. Additionally, ethical considerations and biases in\nRL-NLP systems are addressed.",
            "author": [
                "Ying Liu",
                "Haozhu Wang",
                "Huixue Zhou",
                "Mingchen Li",
                "Yu Hou",
                "Sicheng Zhou",
                "Fang Wang",
                "Rama Hoetzlein",
                "Rui Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.18354v1",
                "http://arxiv.org/pdf/2310.18354v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15349v1",
            "title": "Scalable machine learning-assisted clear-box characterization for\n  optimally controlled photonic circuits",
            "updated": "2023-10-23T20:24:30Z",
            "published": "2023-10-23T20:24:30Z",
            "summary": "Photonic integrated circuits offer a compact and stable platform for\ngenerating, manipulating, and detecting light. They are instrumental for\nclassical and quantum applications. Imperfections stemming from fabrication\nconstraints, tolerances and operation wavelength impose limitations on the\naccuracy and thus utility of current photonic integrated devices. Mitigating\nthese imperfections typically necessitates a model of the underlying physical\nstructure and the estimation of parameters that are challenging to access.\nDirect solutions are currently lacking for mesh configurations extending beyond\ntrivial cases. We introduce a scalable and innovative method to characterize\nphotonic chips through an iterative machine learning-assisted procedure. Our\nmethod is based on a clear-box approach that harnesses a fully modeled virtual\nreplica of the photonic chip to characterize. The process is sample-efficient\nand can be carried out with a continuous-wave laser and powermeters. The model\nestimates individual passive phases, crosstalk, beamsplitter reflectivity\nvalues and relative input/output losses. Building upon the accurate\ncharacterization results, we mitigate imperfections to enable enhanced control\nover the device. We validate our characterization and imperfection mitigation\nmethods on a 12-mode Clements-interferometer equipped with 126 phase shifters,\nachieving beyond state-of-the-art chip control with an average 99.77 %\namplitude fidelity on 100 implemented Haar-random unitary matrices.",
            "author": [
                "Andreas Fyrillas",
                "Olivier Faure",
                "Nicolas Maring",
                "Jean Senellart",
                "Nadia Belabas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15349v1",
                "http://arxiv.org/pdf/2310.15349v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15343v1",
            "title": "Burgers' pinns with implicit euler transfer learning",
            "updated": "2023-10-23T20:15:45Z",
            "published": "2023-10-23T20:15:45Z",
            "summary": "The Burgers equation is a well-established test case in the computational\nmodeling of several phenomena such as fluid dynamics, gas dynamics, shock\ntheory, cosmology, and others. In this work, we present the application of\nPhysics-Informed Neural Networks (PINNs) with an implicit Euler transfer\nlearning approach to solve the Burgers equation. The proposed approach consists\nin seeking a time-discrete solution by a sequence of Artificial Neural Networks\n(ANNs). At each time step, the previous ANN transfers its knowledge to the next\nnetwork model, which learns the current time solution by minimizing a loss\nfunction based on the implicit Euler approximation of the Burgers equation. The\napproach is tested for two benchmark problems: the first with an exact solution\nand the other with an alternative analytical solution. In comparison to the\nusual PINN models, the proposed approach has the advantage of requiring smaller\nneural network architectures with similar accurate results and potentially\ndecreasing computational costs.",
            "author": [
                "Vit\u00f3ria Biesek",
                "Pedro Henrique de Almeida Konzen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15343v1",
                "http://arxiv.org/pdf/2310.15343v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15342v2",
            "title": "Towards Hybrid-grained Feature Interaction Selection for Deep Sparse\n  Network",
            "updated": "2023-10-30T15:01:26Z",
            "published": "2023-10-23T20:15:30Z",
            "summary": "Deep sparse networks are widely investigated as a neural network architecture\nfor prediction tasks with high-dimensional sparse features, with which feature\ninteraction selection is a critical component. While previous methods primarily\nfocus on how to search feature interaction in a coarse-grained space, less\nattention has been given to a finer granularity. In this work, we introduce a\nhybrid-grained feature interaction selection approach that targets both feature\nfield and feature value for deep sparse networks. To explore such expansive\nspace, we propose a decomposed space which is calculated on the fly. We then\ndevelop a selection algorithm called OptFeature, which efficiently selects the\nfeature interaction from both the feature field and the feature value\nsimultaneously. Results from experiments on three large real-world benchmark\ndatasets demonstrate that OptFeature performs well in terms of accuracy and\nefficiency. Additional studies support the feasibility of our method.",
            "author": [
                "Fuyuan Lyu",
                "Xing Tang",
                "Dugang Liu",
                "Chen Ma",
                "Weihong Luo",
                "Liang Chen",
                "Xiuqiang He",
                "Xue Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15342v2",
                "http://arxiv.org/pdf/2310.15342v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15334v1",
            "title": "ADMM Training Algorithms for Residual Networks: Convergence, Complexity\n  and Parallel Training",
            "updated": "2023-10-23T20:01:06Z",
            "published": "2023-10-23T20:01:06Z",
            "summary": "We design a series of serial and parallel proximal point (gradient) ADMMs for\nthe fully connected residual networks (FCResNets) training problem by\nintroducing auxiliary variables. Convergence of the proximal point version is\nproven based on a Kurdyka-Lojasiewicz (KL) property analysis framework, and we\ncan ensure a locally R-linear or sublinear convergence rate depending on the\ndifferent ranges of the Kurdyka-Lojasiewicz (KL) exponent, in which a necessary\nauxiliary function is constructed to realize our goal. Moreover, the advantages\nof the parallel implementation in terms of lower time complexity and less\n(per-node) memory consumption are analyzed theoretically. To the best of our\nknowledge, this is the first work analyzing the convergence, convergence rate,\ntime complexity and (per-node) runtime memory requirement of the ADMM applied\nin the FCResNets training problem theoretically. Experiments are reported to\nshow the high speed, better performance, robustness and potential in the deep\nnetwork training tasks. Finally, we present the advantage and potential of our\nparallel training in large-scale problems.",
            "author": [
                "Jintao Xu",
                "Yifei Li",
                "Wenxun Xing"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15334v1",
                "http://arxiv.org/pdf/2310.15334v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15333v1",
            "title": "Estimating Trustworthy and Safe Optimal Treatment Regimes",
            "updated": "2023-10-23T19:59:10Z",
            "published": "2023-10-23T19:59:10Z",
            "summary": "Recent statistical and reinforcement learning methods have significantly\nadvanced patient care strategies. However, these approaches face substantial\nchallenges in high-stakes contexts, including missing data, inherent\nstochasticity, and the critical requirements for interpretability and patient\nsafety. Our work operationalizes a safe and interpretable framework to identify\noptimal treatment regimes. This approach involves matching patients with\nsimilar medical and pharmacological characteristics, allowing us to construct\nan optimal policy via interpolation. We perform a comprehensive simulation\nstudy to demonstrate the framework's ability to identify optimal policies even\nin complex settings. Ultimately, we operationalize our approach to study\nregimes for treating seizures in critically ill patients. Our findings strongly\nsupport personalized treatment strategies based on a patient's medical history\nand pharmacological features. Notably, we identify that reducing medication\ndoses for patients with mild and brief seizure episodes while adopting\naggressive treatment for patients in intensive care unit experiencing intense\nseizures leads to more favorable outcomes.",
            "author": [
                "Harsh Parikh",
                "Quinn Lanners",
                "Zade Akras",
                "Sahar F. Zafar",
                "M. Brandon Westover",
                "Cynthia Rudin",
                "Alexander Volfovsky"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15333v1",
                "http://arxiv.org/pdf/2310.15333v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.AP",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15330v1",
            "title": "Unsupervised Federated Learning: A Federated Gradient EM Algorithm for\n  Heterogeneous Mixture Models with Robustness against Adversarial Attacks",
            "updated": "2023-10-23T19:53:36Z",
            "published": "2023-10-23T19:53:36Z",
            "summary": "While supervised federated learning approaches have enjoyed significant\nsuccess, the domain of unsupervised federated learning remains relatively\nunderexplored. In this paper, we introduce a novel federated gradient EM\nalgorithm designed for the unsupervised learning of mixture models with\nheterogeneous mixture proportions across tasks. We begin with a comprehensive\nfinite-sample theory that holds for general mixture models, then apply this\ngeneral theory on Gaussian Mixture Models (GMMs) and Mixture of Regressions\n(MoRs) to characterize the explicit estimation error of model parameters and\nmixture proportions. Our proposed federated gradient EM algorithm demonstrates\nseveral key advantages: adaptability to unknown task similarity, resilience\nagainst adversarial attacks on a small fraction of data sources, protection of\nlocal data privacy, and computational and communication efficiency.",
            "author": [
                "Ye Tian",
                "Haolei Weng",
                "Yang Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15330v1",
                "http://arxiv.org/pdf/2310.15330v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15329v1",
            "title": "Serverless Federated Learning with flwr-serverless",
            "updated": "2023-10-23T19:49:59Z",
            "published": "2023-10-23T19:49:59Z",
            "summary": "Federated learning is becoming increasingly relevant and popular as we\nwitness a surge in data collection and storage of personally identifiable\ninformation. Alongside these developments there have been many proposals from\ngovernments around the world to provide more protections for individuals' data\nand a heightened interest in data privacy measures. As deep learning continues\nto become more relevant in new and existing domains, it is vital to develop\nstrategies like federated learning that can effectively train data from\ndifferent sources, such as edge devices, without compromising security and\nprivacy. Recently, the Flower (\\texttt{Flwr}) Python package was introduced to\nprovide a scalable, flexible, and easy-to-use framework for implementing\nfederated learning. However, to date, Flower is only able to run synchronous\nfederated learning which can be costly and time-consuming to run because the\nprocess is bottlenecked by client-side training jobs that are slow or fragile.\nHere, we introduce \\texttt{flwr-serverless}, a wrapper around the Flower\npackage that extends its functionality to allow for both synchronous and\nasynchronous federated learning with minimal modification to Flower's design\nparadigm. Furthermore, our approach to federated learning allows the process to\nrun without a central server, which increases the domains of application and\naccessibility of its use. This paper presents the design details and usage of\nthis approach through a series of experiments that were conducted using public\ndatasets. Overall, we believe that our approach decreases the time and cost to\nrun federated training and provides an easier way to implement and experiment\nwith federated learning systems.",
            "author": [
                "Sanjeev V. Namjoshi",
                "Reese Green",
                "Krishi Sharma",
                "Zhangzhang Si"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15329v1",
                "http://arxiv.org/pdf/2310.15329v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15328v1",
            "title": "DeepVox and SAVE-CT: a contrast- and dose-independent 3D deep learning\n  approach for thoracic aorta segmentation and aneurysm prediction using\n  computed tomography scans",
            "updated": "2023-10-23T19:48:58Z",
            "published": "2023-10-23T19:48:58Z",
            "summary": "Thoracic aortic aneurysm (TAA) is a fatal disease which potentially leads to\ndissection or rupture through progressive enlargement of the aorta. It is\nusually asymptomatic and screening recommendation are limited. The\ngold-standard evaluation is performed by computed tomography angiography (CTA)\nand radiologists time-consuming assessment. Scans for other indications could\nhelp on this screening, however if acquired without contrast enhancement or\nwith low dose protocol, it can make the clinical evaluation difficult, besides\nincreasing the scans quantity for the radiologists. In this study, it was\nselected 587 unique CT scans including control and TAA patients, acquired with\nlow and standard dose protocols, with or without contrast enhancement. A novel\nsegmentation model, DeepVox, exhibited dice score coefficients of 0.932 and\n0.897 for development and test sets, respectively, with faster training speed\nin comparison to models reported in the literature. The novel TAA\nclassification model, SAVE-CT, presented accuracies of 0.930 and 0.922 for\ndevelopment and test sets, respectively, using only the binary segmentation\nmask from DeepVox as input, without hand-engineered features. These two models\ntogether are a potential approach for TAA screening, as they can handle\nvariable number of slices as input, handling thoracic and thoracoabdominal\nsequences, in a fully automated contrast- and dose-independent evaluation. This\nmay assist to decrease TAA mortality and prioritize the evaluation queue of\npatients for radiologists.",
            "author": [
                "Matheus del-Valle",
                "Lariza Laura de Oliveira",
                "Henrique Cursino Vieira",
                "Henrique Min Ho Lee",
                "Lucas Lembran\u00e7a Pinheiro",
                "Maria Fernanda Portugal",
                "Newton Shydeo Brand\u00e3o Miyoshi",
                "Nelson Wolosker"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15328v1",
                "http://arxiv.org/pdf/2310.15328v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "I.2; I.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15325v1",
            "title": "LXMERT Model Compression for Visual Question Answering",
            "updated": "2023-10-23T19:46:41Z",
            "published": "2023-10-23T19:46:41Z",
            "summary": "Large-scale pretrained models such as LXMERT are becoming popular for\nlearning cross-modal representations on text-image pairs for vision-language\ntasks. According to the lottery ticket hypothesis, NLP and computer vision\nmodels contain smaller subnetworks capable of being trained in isolation to\nfull performance. In this paper, we combine these observations to evaluate\nwhether such trainable subnetworks exist in LXMERT when fine-tuned on the VQA\ntask. In addition, we perform a model size cost-benefit analysis by\ninvestigating how much pruning can be done without significant loss in\naccuracy. Our experiment results demonstrate that LXMERT can be effectively\npruned by 40%-60% in size with 3% loss in accuracy.",
            "author": [
                "Maryam Hashemi",
                "Ghazaleh Mahmoudi",
                "Sara Kodeiri",
                "Hadi Sheikhi",
                "Sauleh Eetemadi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15325v1",
                "http://arxiv.org/pdf/2310.15325v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15320v1",
            "title": "Conflating point of interest (POI) data: A systematic review of matching\n  methods",
            "updated": "2023-10-23T19:38:31Z",
            "published": "2023-10-23T19:38:31Z",
            "summary": "Point of interest (POI) data provide digital representations of places in the\nreal world, and have been increasingly used to understand human-place\ninteractions, support urban management, and build smart cities. Many POI\ndatasets have been developed, which often have different geographic coverages,\nattribute focuses, and data quality. From time to time, researchers may need to\nconflate two or more POI datasets in order to build a better representation of\nthe places in the study areas. While various POI conflation methods have been\ndeveloped, there lacks a systematic review, and consequently, it is difficult\nfor researchers new to POI conflation to quickly grasp and use these existing\nmethods. This paper fills such a gap. Following the protocol of Preferred\nReporting Items for Systematic Reviews and Meta-Analyses (PRISMA), we conduct a\nsystematic review by searching through three bibliographic databases using\nreproducible syntax to identify related studies. We then focus on a main step\nof POI conflation, i.e., POI matching, and systematically summarize and\ncategorize the identified methods. Current limitations and future opportunities\nare discussed afterwards. We hope that this review can provide some guidance\nfor researchers interested in conflating POI datasets for their research.",
            "author": [
                "Kai Sun",
                "Yingjie Hu",
                "Yue Ma",
                "Ryan Zhenqi Zhou",
                "Yunqiang Zhu"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.compenvurbsys.2023.101977",
                "http://arxiv.org/abs/2310.15320v1",
                "http://arxiv.org/pdf/2310.15320v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15319v1",
            "title": "Hallucination Detection for Grounded Instruction Generation",
            "updated": "2023-10-23T19:36:28Z",
            "published": "2023-10-23T19:36:28Z",
            "summary": "We investigate the problem of generating instructions to guide humans to\nnavigate in simulated residential environments. A major issue with current\nmodels is hallucination: they generate references to actions or objects that\nare inconsistent with what a human follower would perform or encounter along\nthe described path. We develop a model that detects these hallucinated\nreferences by adopting a model pre-trained on a large corpus of image-text\npairs, and fine-tuning it with a contrastive loss that separates correct\ninstructions from instructions containing synthesized hallucinations. Our final\nmodel outperforms several baselines, including using word probability estimated\nby the instruction-generation model, and supervised models based on LSTM and\nTransformer.",
            "author": [
                "Lingjun Zhao",
                "Khanh Nguyen",
                "Hal Daum\u00e9 III"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15319v1",
                "http://arxiv.org/pdf/2310.15319v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15318v1",
            "title": "HetGPT: Harnessing the Power of Prompt Tuning in Pre-Trained\n  Heterogeneous Graph Neural Networks",
            "updated": "2023-10-23T19:35:57Z",
            "published": "2023-10-23T19:35:57Z",
            "summary": "Graphs have emerged as a natural choice to represent and analyze the\nintricate patterns and rich information of the Web, enabling applications such\nas online page classification and social recommendation. The prevailing\n\"pre-train, fine-tune\" paradigm has been widely adopted in graph machine\nlearning tasks, particularly in scenarios with limited labeled nodes. However,\nthis approach often exhibits a misalignment between the training objectives of\npretext tasks and those of downstream tasks. This gap can result in the\n\"negative transfer\" problem, wherein the knowledge gained from pre-training\nadversely affects performance in the downstream tasks. The surge in\nprompt-based learning within Natural Language Processing (NLP) suggests the\npotential of adapting a \"pre-train, prompt\" paradigm to graphs as an\nalternative. However, existing graph prompting techniques are tailored to\nhomogeneous graphs, neglecting the inherent heterogeneity of Web graphs. To\nbridge this gap, we propose HetGPT, a general post-training prompting framework\nto improve the predictive performance of pre-trained heterogeneous graph neural\nnetworks (HGNNs). The key is the design of a novel prompting function that\nintegrates a virtual class prompt and a heterogeneous feature prompt, with the\naim to reformulate downstream tasks to mirror pretext tasks. Moreover, HetGPT\nintroduces a multi-view neighborhood aggregation mechanism, capturing the\ncomplex neighborhood structure in heterogeneous graphs. Extensive experiments\non three benchmark datasets demonstrate HetGPT's capability to enhance the\nperformance of state-of-the-art HGNNs on semi-supervised node classification.",
            "author": [
                "Yihong Ma",
                "Ning Yan",
                "Jiayu Li",
                "Masood Mortazavi",
                "Nitesh V. Chawla"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15318v1",
                "http://arxiv.org/pdf/2310.15318v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15316v1",
            "title": "Probing Representations for Document-level Event Extraction",
            "updated": "2023-10-23T19:33:04Z",
            "published": "2023-10-23T19:33:04Z",
            "summary": "The probing classifiers framework has been employed for interpreting deep\nneural network models for a variety of natural language processing (NLP)\napplications. Studies, however, have largely focused on sentencelevel NLP\ntasks. This work is the first to apply the probing paradigm to representations\nlearned for document-level information extraction (IE). We designed eight\nembedding probes to analyze surface, semantic, and event-understanding\ncapabilities relevant to document-level event extraction. We apply them to the\nrepresentations acquired by learning models from three different LLM-based\ndocument-level IE approaches on a standard dataset. We found that trained\nencoders from these models yield embeddings that can modestly improve argument\ndetections and labeling but only slightly enhance event-level tasks, albeit\ntrade-offs in information helpful for coherence and event-type prediction. We\nfurther found that encoder models struggle with document length and\ncross-sentence discourse.",
            "author": [
                "Barry Wang",
                "Xinya Du",
                "Claire Cardie"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15316v1",
                "http://arxiv.org/pdf/2310.15316v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15314v1",
            "title": "Combining linear-scaling quantum transport and machine-learning\n  molecular dynamics to study thermal and electronic transports in complex\n  materials",
            "updated": "2023-10-23T19:31:01Z",
            "published": "2023-10-23T19:31:01Z",
            "summary": "We propose an efficient approach for simultaneous prediction of thermal and\nelectronic transport properties in complex materials. Firstly, a highly\nefficient machine-learned neuroevolution potential is trained using reference\ndata from quantum-mechanical density-functional theory calculations. This\ntrained potential is then applied in large-scale molecular dynamics\nsimulations, enabling the generation of realistic structures and accurate\ncharacterization of thermal transport properties. In addition, molecular\ndynamics simulations of atoms and linear-scaling quantum transport calculations\nof electrons are coupled to account for the electron-phonon scattering and\nother disorders that affect the charge carriers governing the electronic\ntransport properties. We demonstrate the usefulness of this unified approach by\nstudying thermoelectric transport properties of a graphene antidot lattice.",
            "author": [
                "Zheyong Fan",
                "Yang Xiao",
                "Yanzhou Wang",
                "Penghua Ying",
                "Shunda Chen",
                "Haikuan Dong"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15314v1",
                "http://arxiv.org/pdf/2310.15314v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15308v2",
            "title": "SAM-CLIP: Merging Vision Foundation Models towards Semantic and Spatial\n  Understanding",
            "updated": "2023-11-20T00:56:15Z",
            "published": "2023-10-23T19:21:57Z",
            "summary": "The landscape of publicly available vision foundation models (VFMs), such as\nCLIP and Segment Anything Model (SAM), is expanding rapidly. VFMs are endowed\nwith distinct capabilities stemming from their pre-training objectives. For\ninstance, CLIP excels in semantic understanding, while SAM specializes in\nspatial understanding for segmentation. In this work, we introduce a simple\nrecipe to efficiently merge VFMs into a unified model that absorbs their\nexpertise. Our method integrates techniques of multi-task learning, continual\nlearning, and distillation. Further, it demands significantly less\ncomputational cost compared to traditional multi-task training from scratch,\nand it only needs a small fraction of the pre-training datasets that were\ninitially used to train individual models. By applying our method to SAM and\nCLIP, we obtain SAM-CLIP: a unified model that combines the capabilities of SAM\nand CLIP into a single vision transformer. Compared with deploying SAM and CLIP\nindependently, our merged model, SAM-CLIP, reduces storage and compute costs\nfor inference, making it well-suited for edge device applications. We show that\nSAM-CLIP not only retains the foundational strengths of SAM and CLIP, but also\nintroduces synergistic functionalities, notably in zero-shot semantic\nsegmentation, where SAM-CLIP establishes new state-of-the-art results on 5\nbenchmarks. It outperforms previous models that are specifically designed for\nthis task by a large margin, including +6.8% and +5.9% mean IoU improvement on\nPascal-VOC and COCO-Stuff datasets, respectively.",
            "author": [
                "Haoxiang Wang",
                "Pavan Kumar Anasosalu Vasu",
                "Fartash Faghri",
                "Raviteja Vemulapalli",
                "Mehrdad Farajtabar",
                "Sachin Mehta",
                "Mohammad Rastegari",
                "Oncel Tuzel",
                "Hadi Pouransari"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15308v2",
                "http://arxiv.org/pdf/2310.15308v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15301v1",
            "title": "ADMarker: A Multi-Modal Federated Learning System for Monitoring Digital\n  Biomarkers of Alzheimer's Disease",
            "updated": "2023-10-23T19:07:33Z",
            "published": "2023-10-23T19:07:33Z",
            "summary": "Alzheimer's Disease (AD) and related dementia are a growing global health\nchallenge due to the aging population. In this paper, we present ADMarker, the\nfirst end-to-end system that integrates multi-modal sensors and new federated\nlearning algorithms for detecting multidimensional AD digital biomarkers in\nnatural living environments. ADMarker features a novel three-stage multi-modal\nfederated learning architecture that can accurately detect digital biomarkers\nin a privacy-preserving manner. Our approach collectively addresses several\nmajor real-world challenges, such as limited data labels, data heterogeneity,\nand limited computing resources. We built a compact multi-modality hardware\nsystem and deployed it in a four-week clinical trial involving 91 elderly\nparticipants. The results indicate that ADMarker can accurately detect a\ncomprehensive set of digital biomarkers with up to 93.8% accuracy and identify\nearly AD with an average of 88.9% accuracy. ADMarker offers a new platform that\ncan allow AD clinicians to characterize and track the complex correlation\nbetween multidimensional interpretable digital biomarkers, demographic factors\nof patients, and AD diagnosis in a longitudinal manner.",
            "author": [
                "Xiaomin Ouyang",
                "Xian Shuai",
                "Yang Li",
                "Li Pan",
                "Xifan Zhang",
                "Heming Fu",
                "Xinyan Wang",
                "Shihua Cao",
                "Jiang Xin",
                "Hazel Mok",
                "Zhenyu Yan",
                "Doris Sau Fung Yu",
                "Timothy Kwok",
                "Guoliang Xing"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15301v1",
                "http://arxiv.org/pdf/2310.15301v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15299v1",
            "title": "Neural Network with Local Converging Input (NNLCI) for Supersonic Flow\n  Problems with Unstructured Grids",
            "updated": "2023-10-23T19:03:37Z",
            "published": "2023-10-23T19:03:37Z",
            "summary": "In recent years, surrogate models based on deep neural networks (DNN) have\nbeen widely used to solve partial differential equations, which were\ntraditionally handled by means of numerical simulations. This kind of surrogate\nmodels, however, focuses on global interpolation of the training dataset, and\nthus requires a large network structure. The process is both time consuming and\ncomputationally costly, thereby restricting their use for high-fidelity\nprediction of complex physical problems. In the present study, we develop a\nneural network with local converging input (NNLCI) for high-fidelity prediction\nusing unstructured data. The framework utilizes the local domain of dependence\nwith converging coarse solutions as input, which greatly reduces computational\nresource and training time. As a validation case, the NNLCI method is applied\nto study inviscid supersonic flows in channels with bumps. Different bump\ngeometries and locations are considered to benchmark the effectiveness and\nversability of the proposed approach. Detailed flow structures, including\nshock-wave interactions, are examined systematically.",
            "author": [
                "Weiming Ding",
                "Haoxiang Huang",
                "Tzu Jung Lee",
                "Yingjie Liu",
                "Vigor Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15299v1",
                "http://arxiv.org/pdf/2310.15299v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.AI",
                "cs.LG",
                "cs.NA",
                "physics.flu-dyn",
                "35Q31"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15294v1",
            "title": "Adaptive End-to-End Metric Learning for Zero-Shot Cross-Domain Slot\n  Filling",
            "updated": "2023-10-23T19:01:16Z",
            "published": "2023-10-23T19:01:16Z",
            "summary": "Recently slot filling has witnessed great development thanks to deep learning\nand the availability of large-scale annotated data. However, it poses a\ncritical challenge to handle a novel domain whose samples are never seen during\ntraining. The recognition performance might be greatly degraded due to severe\ndomain shifts. Most prior works deal with this problem in a two-pass pipeline\nmanner based on metric learning. In practice, these dominant pipeline models\nmay be limited in computational efficiency and generalization capacity because\nof non-parallel inference and context-free discrete label embeddings. To this\nend, we re-examine the typical metric-based methods, and propose a new adaptive\nend-to-end metric learning scheme for the challenging zero-shot slot filling.\nConsidering simplicity, efficiency and generalizability, we present a\ncascade-style joint learning framework coupled with context-aware soft label\nrepresentations and slot-level contrastive representation learning to mitigate\nthe data and label shift problems effectively. Extensive experiments on public\nbenchmarks demonstrate the superiority of the proposed approach over a series\nof competitive baselines.",
            "author": [
                "Yuanjun Shi",
                "Linzhi Wu",
                "Minglai Shao"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15294v1",
                "http://arxiv.org/pdf/2310.15294v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15290v2",
            "title": "Reliable Generation of EHR Time Series via Diffusion Models",
            "updated": "2023-11-21T22:19:09Z",
            "published": "2023-10-23T18:56:01Z",
            "summary": "Electronic Health Records (EHRs) are rich sources of patient-level data,\nincluding laboratory tests, medications, and diagnoses, offering valuable\nresources for medical data analysis. However, concerns about privacy often\nrestrict access to EHRs, hindering downstream analysis. Researchers have\nexplored various methods for generating privacy-preserving EHR data. In this\nstudy, we introduce a new method for generating diverse and realistic synthetic\nEHR time series data using Denoising Diffusion Probabilistic Models (DDPM). We\nconducted experiments on six datasets, comparing our proposed method with eight\nexisting methods. Our results demonstrate that our approach significantly\noutperforms all existing methods in terms of data utility while requiring less\ntraining effort. Our approach also enhances downstream medical data analysis by\nproviding diverse and realistic synthetic EHR data.",
            "author": [
                "Muhang Tian",
                "Bernie Chen",
                "Allan Guo",
                "Shiyi Jiang",
                "Anru R. Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15290v2",
                "http://arxiv.org/pdf/2310.15290v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15288v1",
            "title": "Active teacher selection for reinforcement learning from human feedback",
            "updated": "2023-10-23T18:54:43Z",
            "published": "2023-10-23T18:54:43Z",
            "summary": "Reinforcement learning from human feedback (RLHF) enables machine learning\nsystems to learn objectives from human feedback. A core limitation of these\nsystems is their assumption that all feedback comes from a single human\nteacher, despite querying a range of distinct teachers. We propose the Hidden\nUtility Bandit (HUB) framework to model differences in teacher rationality,\nexpertise, and costliness, formalizing the problem of learning from multiple\nteachers. We develop a variety of solution algorithms and apply them to two\nreal-world domains: paper recommendation systems and COVID-19 vaccine testing.\nWe find that the Active Teacher Selection (ATS) algorithm outperforms baseline\nalgorithms by actively selecting when and which teacher to query. The HUB\nframework and ATS algorithm demonstrate the importance of leveraging\ndifferences between teachers to learn accurate reward models, facilitating\nfuture research on active teacher selection for robust reward modeling.",
            "author": [
                "Rachel Freedman",
                "Justin Svegliato",
                "Kyle Wray",
                "Stuart Russell"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15288v1",
                "http://arxiv.org/pdf/2310.15288v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15286v1",
            "title": "A Doubly Robust Approach to Sparse Reinforcement Learning",
            "updated": "2023-10-23T18:52:17Z",
            "published": "2023-10-23T18:52:17Z",
            "summary": "We propose a new regret minimization algorithm for episodic sparse linear\nMarkov decision process (SMDP) where the state-transition distribution is a\nlinear function of observed features. The only previously known algorithm for\nSMDP requires the knowledge of the sparsity parameter and oracle access to an\nunknown policy. We overcome these limitations by combining the doubly robust\nmethod that allows one to use feature vectors of \\emph{all} actions with a\nnovel analysis technique that enables the algorithm to use data from all\nperiods in all episodes. The regret of the proposed algorithm is\n$\\tilde{O}(\\sigma^{-1}_{\\min} s_{\\star} H \\sqrt{N})$, where $\\sigma_{\\min}$\ndenotes the restrictive the minimum eigenvalue of the average Gram matrix of\nfeature vectors, $s_\\star$ is the sparsity parameter, $H$ is the length of an\nepisode, and $N$ is the number of rounds. We provide a lower regret bound that\nmatches the upper bound up to logarithmic factors on a newly identified\nsubclass of SMDPs. Our numerical experiments support our theoretical results\nand demonstrate the superior performance of our algorithm.",
            "author": [
                "Wonyoung Kim",
                "Garud Iyengar",
                "Assaf Zeevi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15286v1",
                "http://arxiv.org/pdf/2310.15286v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15285v1",
            "title": "On the Dimensionality of Sentence Embeddings",
            "updated": "2023-10-23T18:51:00Z",
            "published": "2023-10-23T18:51:00Z",
            "summary": "Learning sentence embeddings is a fundamental problem in natural language\nprocessing. While existing research primarily focuses on enhancing the quality\nof sentence embeddings, the exploration of sentence embedding dimensions is\nlimited. Here we present a comprehensive and empirical analysis of the\ndimensionality of sentence embeddings. First, we demonstrate that the optimal\ndimension of sentence embeddings is usually smaller than the default value.\nSubsequently, to compress the dimension of sentence embeddings with minimum\nperformance degradation, we identify two components contributing to the overall\nperformance loss: the encoder's performance loss and the pooler's performance\nloss. Therefore, we propose a two-step training method for sentence\nrepresentation learning models, wherein the encoder and the pooler are\noptimized separately to mitigate the overall performance loss in low-dimension\nscenarios. Experimental results on seven STS tasks and seven sentence\nclassification tasks demonstrate that our method significantly improves the\nperformance of low-dimensional sentence embeddings.",
            "author": [
                "Hongwei Wang",
                "Hongming Zhang",
                "Dong Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15285v1",
                "http://arxiv.org/pdf/2310.15285v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15281v1",
            "title": "UncertaintyPlayground: A Fast and Simplified Python Library for\n  Uncertainty Estimation",
            "updated": "2023-10-23T18:36:54Z",
            "published": "2023-10-23T18:36:54Z",
            "summary": "This paper introduces UncertaintyPlayground, a Python library built on\nPyTorch and GPyTorch for uncertainty estimation in supervised learning tasks.\nThe library offers fast training for Gaussian and multi-modal outcome\ndistributions through Sparse and Variational Gaussian Process Regressions\n(SVGPRs) for normally distributed outcomes and Mixed Density Networks (MDN) for\nmixed distributions. In addition to model training with various\nhyperparameters, UncertaintyPlayground can visualize the prediction intervals\nof one or more instances. Due to using tensor operations, the library can be\ntrained both on CPU and GPU and offers various PyTorch-specific techniques for\nspeed optimization. The library contains unit tests for each module and ensures\nmulti-platform continuous integration with GitHub Workflows (online\nintegration) and Tox (local integration). Finally, the code is documented with\nGoogle-style docstrings and offers a documentation website created with MkDocs\nand MkDocStrings.",
            "author": [
                "Ilia Azizi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15281v1",
                "http://arxiv.org/pdf/2310.15281v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15275v1",
            "title": "Triple Simplex Matrix Completion for Expense Forecasting",
            "updated": "2023-10-23T18:25:33Z",
            "published": "2023-10-23T18:25:33Z",
            "summary": "Forecasting project expenses is a crucial step for businesses to avoid budget\noverruns and project failures. Traditionally, this has been done by financial\nanalysts or data science techniques such as time-series analysis. However,\nthese approaches can be uncertain and produce results that differ from the\nplanned budget, especially at the start of a project with limited data points.\nThis paper proposes a constrained non-negative matrix completion model that\npredicts expenses by learning the likelihood of the project correlating with\ncertain expense patterns in the latent space. The model is constrained on three\nprobability simplexes, two of which are on the factor matrices and the third on\nthe missing entries. Additionally, the predicted expense values are guaranteed\nto meet the budget constraint without the need of post-processing. An inexact\nalternating optimization algorithm is developed to solve the associated\noptimization problem and is proven to converge to a stationary point. Results\nfrom two real datasets demonstrate the effectiveness of the proposed method in\ncomparison to state-of-the-art algorithms.",
            "author": [
                "Cheng Qian",
                "Lucas Glass",
                "Nikos Sidiropoulos"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15275v1",
                "http://arxiv.org/pdf/2310.15275v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15274v1",
            "title": "Systematic AI Approach for AGI: Addressing Alignment, Energy, and AGI\n  Grand Challenges",
            "updated": "2023-10-23T18:20:54Z",
            "published": "2023-10-23T18:20:54Z",
            "summary": "AI faces a trifecta of grand challenges the Energy Wall, the Alignment\nProblem and the Leap from Narrow AI to AGI. Contemporary AI solutions consume\nunsustainable amounts of energy during model training and daily\noperations.Making things worse, the amount of computation required to train\neach new AI model has been doubling every 2 months since 2020, directly\ntranslating to increases in energy consumption.The leap from AI to AGI requires\nmultiple functional subsystems operating in a balanced manner, which requires a\nsystem architecture. However, the current approach to artificial intelligence\nlacks system design; even though system characteristics play a key role in the\nhuman brain from the way it processes information to how it makes decisions.\nSimilarly, current alignment and AI ethics approaches largely ignore system\ndesign, yet studies show that the brains system architecture plays a critical\nrole in healthy moral decisions.In this paper, we argue that system design is\ncritically important in overcoming all three grand challenges. We posit that\nsystem design is the missing piece in overcoming the grand challenges.We\npresent a Systematic AI Approach for AGI that utilizes system design principles\nfor AGI, while providing ways to overcome the energy wall and the alignment\nchallenges.",
            "author": [
                "Eren Kurshan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15274v1",
                "http://arxiv.org/pdf/2310.15274v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15269v1",
            "title": "GradSim: Gradient-Based Language Grouping for Effective Multilingual\n  Training",
            "updated": "2023-10-23T18:13:37Z",
            "published": "2023-10-23T18:13:37Z",
            "summary": "Most languages of the world pose low-resource challenges to natural language\nprocessing models. With multilingual training, knowledge can be shared among\nlanguages. However, not all languages positively influence each other and it is\nan open research question how to select the most suitable set of languages for\nmultilingual training and avoid negative interference among languages whose\ncharacteristics or data distributions are not compatible. In this paper, we\npropose GradSim, a language grouping method based on gradient similarity. Our\nexperiments on three diverse multilingual benchmark datasets show that it leads\nto the largest performance gains compared to other similarity measures and it\nis better correlated with cross-lingual model performance. As a result, we set\nthe new state of the art on AfriSenti, a benchmark dataset for sentiment\nanalysis on low-resource African languages. In our extensive analysis, we\nfurther reveal that besides linguistic features, the topics of the datasets\nplay an important role for language grouping and that lower layers of\ntransformer models encode language-specific features while higher layers\ncapture task-specific information.",
            "author": [
                "Mingyang Wang",
                "Heike Adel",
                "Lukas Lange",
                "Jannik Str\u00f6tgen",
                "Hinrich Sch\u00fctze"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15269v1",
                "http://arxiv.org/pdf/2310.15269v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15263v1",
            "title": "One-hot Generalized Linear Model for Switching Brain State Discovery",
            "updated": "2023-10-23T18:10:22Z",
            "published": "2023-10-23T18:10:22Z",
            "summary": "Exposing meaningful and interpretable neural interactions is critical to\nunderstanding neural circuits. Inferred neural interactions from neural signals\nprimarily reflect functional interactions. In a long experiment, subject\nanimals may experience different stages defined by the experiment, stimuli, or\nbehavioral states, and hence functional interactions can change over time. To\nmodel dynamically changing functional interactions, prior work employs\nstate-switching generalized linear models with hidden Markov models (i.e.,\nHMM-GLMs). However, we argue they lack biological plausibility, as functional\ninteractions are shaped and confined by the underlying anatomical connectome.\nHere, we propose a novel prior-informed state-switching GLM. We introduce both\na Gaussian prior and a one-hot prior over the GLM in each state. The priors are\nlearnable. We will show that the learned prior should capture the\nstate-constant interaction, shedding light on the underlying anatomical\nconnectome and revealing more likely physical neuron interactions. The\nstate-dependent interaction modeled by each GLM offers traceability to capture\nfunctional variations across multiple brain states. Our methods effectively\nrecover true interaction structures in simulated data, achieve the highest\npredictive likelihood with real neural datasets, and render interaction\nstructures and hidden states more interpretable when applied to real neural\ndata.",
            "author": [
                "Chengrui Li",
                "Soon Ho Kim",
                "Chris Rodgers",
                "Hannah Choi",
                "Anqi Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15263v1",
                "http://arxiv.org/pdf/2310.15263v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15261v1",
            "title": "Modality Dropout for Multimodal Device Directed Speech Detection using\n  Verbal and Non-Verbal Features",
            "updated": "2023-10-23T18:09:31Z",
            "published": "2023-10-23T18:09:31Z",
            "summary": "Device-directed speech detection (DDSD) is the binary classification task of\ndistinguishing between queries directed at a voice assistant versus side\nconversation or background speech. State-of-the-art DDSD systems use verbal\ncues, e.g acoustic, text and/or automatic speech recognition system (ASR)\nfeatures, to classify speech as device-directed or otherwise, and often have to\ncontend with one or more of these modalities being unavailable when deployed in\nreal-world settings. In this paper, we investigate fusion schemes for DDSD\nsystems that can be made more robust to missing modalities. Concurrently, we\nstudy the use of non-verbal cues, specifically prosody features, in addition to\nverbal cues for DDSD. We present different approaches to combine scores and\nembeddings from prosody with the corresponding verbal cues, finding that\nprosody improves DDSD performance by upto 8.5% in terms of false acceptance\nrate (FA) at a given fixed operating point via non-linear intermediate fusion,\nwhile our use of modality dropout techniques improves the performance of these\nmodels by 7.4% in terms of FA when evaluated with missing modalities during\ninference time.",
            "author": [
                "Gautam Krishna",
                "Sameer Dharur",
                "Oggi Rudovic",
                "Pranay Dighe",
                "Saurabh Adya",
                "Ahmed Hussen Abdelaziz",
                "Ahmed H Tewfik"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15261v1",
                "http://arxiv.org/pdf/2310.15261v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.HC",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15259v1",
            "title": "Reference Free Domain Adaptation for Translation of Noisy Questions with\n  Question Specific Rewards",
            "updated": "2023-10-23T18:08:01Z",
            "published": "2023-10-23T18:08:01Z",
            "summary": "Community Question-Answering (CQA) portals serve as a valuable tool for\nhelping users within an organization. However, making them accessible to\nnon-English-speaking users continues to be a challenge. Translating questions\ncan broaden the community's reach, benefiting individuals with similar\ninquiries in various languages. Translating questions using Neural Machine\nTranslation (NMT) poses more challenges, especially in noisy environments,\nwhere the grammatical correctness of the questions is not monitored. These\nquestions may be phrased as statements by non-native speakers, with incorrect\nsubject-verb order and sometimes even missing question marks. Creating a\nsynthetic parallel corpus from such data is also difficult due to its noisy\nnature. To address this issue, we propose a training methodology that\nfine-tunes the NMT system only using source-side data. Our approach balances\nadequacy and fluency by utilizing a loss function that combines BERTScore and\nMasked Language Model (MLM) Score. Our method surpasses the conventional\nMaximum Likelihood Estimation (MLE) based fine-tuning approach, which relies on\nsynthetic target data, by achieving a 1.9 BLEU score improvement. Our model\nexhibits robustness while we add noise to our baseline, and still achieve 1.1\nBLEU improvement and large improvements on TER and BLEURT metrics. Our proposed\nmethodology is model-agnostic and is only necessary during the training phase.\nWe make the codes and datasets publicly available at\n\\url{https://www.iitp.ac.in/~ai-nlp-ml/resources.html#DomainAdapt} for\nfacilitating further research.",
            "author": [
                "Baban Gain",
                "Ramakrishna Appicharla",
                "Soumya Chennabasavaraj",
                "Nikesh Garera",
                "Asif Ekbal",
                "Muthusamy Chelliah"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15259v1",
                "http://arxiv.org/pdf/2310.15259v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15258v1",
            "title": "Breaking the Language Barrier: Improving Cross-Lingual Reasoning with\n  Structured Self-Attention",
            "updated": "2023-10-23T18:06:38Z",
            "published": "2023-10-23T18:06:38Z",
            "summary": "In this work, we study whether multilingual language models (MultiLMs) can\ntransfer logical reasoning abilities to other languages when they are\nfine-tuned for reasoning in a different language. We evaluate the cross-lingual\nreasoning abilities of MultiLMs in two schemes: (1) where the language of the\ncontext and the question remain the same in the new languages that are tested\n(i.e., the reasoning is still monolingual, but the model must transfer the\nlearned reasoning ability across languages), and (2) where the language of the\ncontext and the question is different (which we term code-switched reasoning).\nOn two logical reasoning datasets, RuleTaker and LeapOfThought, we demonstrate\nthat although MultiLMs can transfer reasoning ability across languages in a\nmonolingual setting, they struggle to transfer reasoning abilities in a\ncode-switched setting. Following this observation, we propose a novel attention\nmechanism that uses a dedicated set of parameters to encourage cross-lingual\nattention in code-switched sequences, which improves the reasoning performance\nby up to 14% and 4% on the RuleTaker and LeapOfThought datasets, respectively.",
            "author": [
                "Negar Foroutan",
                "Mohammadreza Banaei",
                "Karl Aberer",
                "Antoine Bosselut"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15258v1",
                "http://arxiv.org/pdf/2310.15258v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15256v1",
            "title": "SimBIG: Field-level Simulation-Based Inference of Galaxy Clustering",
            "updated": "2023-10-23T18:05:32Z",
            "published": "2023-10-23T18:05:32Z",
            "summary": "We present the first simulation-based inference (SBI) of cosmological\nparameters from field-level analysis of galaxy clustering. Standard galaxy\nclustering analyses rely on analyzing summary statistics, such as the power\nspectrum, $P_\\ell$, with analytic models based on perturbation theory.\nConsequently, they do not fully exploit the non-linear and non-Gaussian\nfeatures of the galaxy distribution. To address these limitations, we use the\n{\\sc SimBIG} forward modelling framework to perform SBI using normalizing\nflows. We apply SimBIG to a subset of the BOSS CMASS galaxy sample using a\nconvolutional neural network with stochastic weight averaging to perform\nmassive data compression of the galaxy field. We infer constraints on $\\Omega_m\n= 0.267^{+0.033}_{-0.029}$ and $\\sigma_8=0.762^{+0.036}_{-0.035}$. While our\nconstraints on $\\Omega_m$ are in-line with standard $P_\\ell$ analyses, those on\n$\\sigma_8$ are $2.65\\times$ tighter. Our analysis also provides constraints on\nthe Hubble constant $H_0=64.5 \\pm 3.8 \\ {\\rm km / s / Mpc}$ from galaxy\nclustering alone. This higher constraining power comes from additional\nnon-Gaussian cosmological information, inaccessible with $P_\\ell$. We\ndemonstrate the robustness of our analysis by showcasing our ability to infer\nunbiased cosmological constraints from a series of test simulations that are\nconstructed using different forward models than the one used in our training\ndataset. This work not only presents competitive cosmological constraints but\nalso introduces novel methods for leveraging additional cosmological\ninformation in upcoming galaxy surveys like DESI, PFS, and Euclid.",
            "author": [
                "Pablo Lemos",
                "Liam Parker",
                "ChangHoon Hahn",
                "Shirley Ho",
                "Michael Eickenberg",
                "Jiamin Hou",
                "Elena Massara",
                "Chirag Modi",
                "Azadeh Moradinezhad Dizgah",
                "Bruno Regaldo-Saint Blancard",
                "David Spergel"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15256v1",
                "http://arxiv.org/pdf/2310.15256v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15247v1",
            "title": "SyncFusion: Multimodal Onset-synchronized Video-to-Audio Foley Synthesis",
            "updated": "2023-10-23T18:01:36Z",
            "published": "2023-10-23T18:01:36Z",
            "summary": "Sound design involves creatively selecting, recording, and editing sound\neffects for various media like cinema, video games, and virtual/augmented\nreality. One of the most time-consuming steps when designing sound is\nsynchronizing audio with video. In some cases, environmental recordings from\nvideo shoots are available, which can aid in the process. However, in video\ngames and animations, no reference audio exists, requiring manual annotation of\nevent timings from the video. We propose a system to extract repetitive actions\nonsets from a video, which are then used - in conjunction with audio or textual\nembeddings - to condition a diffusion model trained to generate a new\nsynchronized sound effects audio track. In this way, we leave complete creative\ncontrol to the sound designer while removing the burden of synchronization with\nvideo. Furthermore, editing the onset track or changing the conditioning\nembedding requires much less effort than editing the audio track itself,\nsimplifying the sonification process. We provide sound examples, source code,\nand pretrained models to faciliate reproducibility",
            "author": [
                "Marco Comunit\u00e0",
                "Riccardo F. Gramaccioni",
                "Emilian Postolache",
                "Emanuele Rodol\u00e0",
                "Danilo Comminiello",
                "Joshua D. Reiss"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15247v1",
                "http://arxiv.org/pdf/2310.15247v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CV",
                "cs.LG",
                "cs.MM",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15234v1",
            "title": "Field-level simulation-based inference with galaxy catalogs: the impact\n  of systematic effects",
            "updated": "2023-10-23T18:00:07Z",
            "published": "2023-10-23T18:00:07Z",
            "summary": "It has been recently shown that a powerful way to constrain cosmological\nparameters from galaxy redshift surveys is to train graph neural networks to\nperform field-level likelihood-free inference without imposing cuts on scale.\nIn particular, de Santi et al. (2023) developed models that could accurately\ninfer the value of $\\Omega_{\\rm m}$ from catalogs that only contain the\npositions and radial velocities of galaxies that are robust to uncertainties in\nastrophysics and subgrid models. However, observations are affected by many\neffects, including 1) masking, 2) uncertainties in peculiar velocities and\nradial distances, and 3) different galaxy selections. Moreover, observations\nonly allow us to measure redshift, intertwining galaxies' radial positions and\nvelocities. In this paper we train and test our models on galaxy catalogs,\ncreated from thousands of state-of-the-art hydrodynamic simulations run with\ndifferent codes from the CAMELS project, that incorporate these observational\neffects. We find that, although the presence of these effects degrades the\nprecision and accuracy of the models, and increases the fraction of catalogs\nwhere the model breaks down, the fraction of galaxy catalogs where the model\nperforms well is over 90 %, demonstrating the potential of these models to\nconstrain cosmological parameters even when applied to real data.",
            "author": [
                "Natal\u00ed S. M. de Santi",
                "Francisco Villaescusa-Navarro",
                "L. Raul Abramo",
                "Helen Shao",
                "Lucia A. Perez",
                "Tiago Castro",
                "Yueying Ni",
                "Christopher C. Lovell",
                "Elena Hernandez-Martinez",
                "Federico Marinacci",
                "David N. Spergel",
                "Klaus Dolag",
                "Lars Hernquist",
                "Mark Vogelsberger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15234v1",
                "http://arxiv.org/pdf/2310.15234v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO",
                "astro-ph.GA",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15233v1",
            "title": "A new approach to template banks of gravitational waves with higher\n  harmonics: reducing matched-filtering cost by over an order of magnitude",
            "updated": "2023-10-23T18:00:06Z",
            "published": "2023-10-23T18:00:06Z",
            "summary": "Searches for gravitational wave events use models, or templates, for the\nsignals of interest. The templates used in current searches in the\nLIGO-Virgo-Kagra (LVK) data model the dominant quadrupole mode $(\\ell,m)=(2,2)$\nof the signals, and omit sub-dominant higher-order modes (HM) such as\n$(\\ell,m)=(3,3)$, $(4,4)$, which are predicted by general relativity. Hence,\nthese searches could lose sensitivity to black hole mergers in interesting\nparts of parameter space, such as systems with high-masses and asymmetric mass\nratios. We develop a new strategy to include HM in template banks that exploits\nthe natural connection between the modes. We use a combination of\npost-Newtonian formulae and machine learning tools to model aligned-spin\n$(3,3)$, $(4,4)$ waveforms corresponding to a given $(2,2)$ waveform. Each of\nthese modes can be individually filtered against the data to yield separate\ntimeseries of signal-to-noise ratios (SNR), which can be combined in a\nrelatively inexpensive way to marginalize over extrinsic parameters of the\nsignals. This leads to a HM search pipeline whose matched-filtering cost is\njust $\\approx 3\\times$ that of a quadrupole-only search (in contrast to being\n$\\approx\\! 100 \\times$, as in previously proposed HM search methods). Our\nmethod is effectual and is generally applicable for template banks constructed\nwith either stochastic or geometric placement techniques. Additionally, we\ndiscuss compression of $(2,2)$-only geometric-placement template banks using\nmachine learning algorithms.",
            "author": [
                "Digvijay Wadekar",
                "Tejaswi Venumadhav",
                "Ajit Kumar Mehta",
                "Javier Roulet",
                "Seth Olsen",
                "Jonathan Mushkin",
                "Barak Zackay",
                "Matias Zaldarriaga"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15233v1",
                "http://arxiv.org/pdf/2310.15233v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "astro-ph.HE",
                "astro-ph.IM",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15227v1",
            "title": "Machine Learning Classification of Sphalerons and Black Holes at the LHC",
            "updated": "2023-10-23T18:00:03Z",
            "published": "2023-10-23T18:00:03Z",
            "summary": "In models with large extra dimensions, \"miniature\" black holes (BHs) might be\nproduced in high-energy proton-proton collisions at the Large Hadron Collider\n(LHC). In the semi-classical regime, those BHs thermally decay, giving rise to\nlarge-multiplicity final states with jets and leptons. On the other hand,\nsimilar final states are also expected in the production of electroweak\nsphaleron/instanton-induced processes. We investigate whether one can\ndiscriminate these scenarios when BH or sphaleron-like events are observed in\nthe LHC using Machine Learning (ML) methods. Classification among several BH\nscenarios with different numbers of extra dimensions and the minimal BH masses\nis also examined. In this study we consider three ML models: XGBoost algorithms\nwith (1) high- and (2) low-level inputs, and (3) a Residual Convolutional\nNeural Network. In the latter case, the low-level detector information is\nconverted into an input format of three-layer binned event images, where the\nvalue of each bin corresponds to the energy deposited in various detector\nsubsystems. We demonstrate that only a few detected events are sufficient to\neffectively discriminate between the sphaleron and BH processes. Separation\namong BH scenarios with different minimal BH masses is also possible with a\nreasonable number of events, that can be collected in the LHC Run-2, -3 and the\nhigh-luminosity LHC (HL-LHC). We find, however, that a large number of events\nis needed to discriminate between BH hypotheses with the same minimal BH mass,\nbut different numbers of extra dimensions.",
            "author": [
                "Aurora Singstad Grefsrud",
                "Trygve Buanes",
                "Fotis Koutroulis",
                "Anna Lipniacka",
                "Rafa\u0142 Mase\u0142ek",
                "Andreas Papaefstathiou",
                "Kazuki Sakurai",
                "Therese B. Sjursen",
                "Igor Slazyk"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15227v1",
                "http://arxiv.org/pdf/2310.15227v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15171v1",
            "title": "RoboDepth: Robust Out-of-Distribution Depth Estimation under Corruptions",
            "updated": "2023-10-23T17:59:59Z",
            "published": "2023-10-23T17:59:59Z",
            "summary": "Depth estimation from monocular images is pivotal for real-world visual\nperception systems. While current learning-based depth estimation models train\nand test on meticulously curated data, they often overlook out-of-distribution\n(OoD) situations. Yet, in practical settings -- especially safety-critical ones\nlike autonomous driving -- common corruptions can arise. Addressing this\noversight, we introduce a comprehensive robustness test suite, RoboDepth,\nencompassing 18 corruptions spanning three categories: i) weather and lighting\nconditions; ii) sensor failures and movement; and iii) data processing\nanomalies. We subsequently benchmark 42 depth estimation models across indoor\nand outdoor scenes to assess their resilience to these corruptions. Our\nfindings underscore that, in the absence of a dedicated robustness evaluation\nframework, many leading depth estimation models may be susceptible to typical\ncorruptions. We delve into design considerations for crafting more robust depth\nestimation models, touching upon pre-training, augmentation, modality, model\ncapacity, and learning paradigms. We anticipate our benchmark will establish a\nfoundational platform for advancing robust OoD depth estimation.",
            "author": [
                "Lingdong Kong",
                "Shaoyuan Xie",
                "Hanjiang Hu",
                "Lai Xing Ng",
                "Benoit R. Cottereau",
                "Wei Tsang Ooi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15171v1",
                "http://arxiv.org/pdf/2310.15171v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15168v2",
            "title": "Ghost on the Shell: An Expressive Representation of General 3D Shapes",
            "updated": "2023-10-24T03:21:22Z",
            "published": "2023-10-23T17:59:52Z",
            "summary": "The creation of photorealistic virtual worlds requires the accurate modeling\nof 3D surface geometry for a wide range of objects. For this, meshes are\nappealing since they 1) enable fast physics-based rendering with realistic\nmaterial and lighting, 2) support physical simulation, and 3) are\nmemory-efficient for modern graphics pipelines. Recent work on reconstructing\nand statistically modeling 3D shape, however, has critiqued meshes as being\ntopologically inflexible. To capture a wide range of object shapes, any 3D\nrepresentation must be able to model solid, watertight, shapes as well as thin,\nopen, surfaces. Recent work has focused on the former, and methods for\nreconstructing open surfaces do not support fast reconstruction with material\nand lighting or unconditional generative modelling. Inspired by the observation\nthat open surfaces can be seen as islands floating on watertight surfaces, we\nparameterize open surfaces by defining a manifold signed distance field on\nwatertight templates. With this parameterization, we further develop a\ngrid-based and differentiable representation that parameterizes both watertight\nand non-watertight meshes of arbitrary topology. Our new representation, called\nGhost-on-the-Shell (G-Shell), enables two important applications:\ndifferentiable rasterization-based reconstruction from multiview images and\ngenerative modelling of non-watertight meshes. We empirically demonstrate that\nG-Shell achieves state-of-the-art performance on non-watertight mesh\nreconstruction and generation tasks, while also performing effectively for\nwatertight meshes.",
            "author": [
                "Zhen Liu",
                "Yao Feng",
                "Yuliang Xiu",
                "Weiyang Liu",
                "Liam Paull",
                "Michael J. Black",
                "Bernhard Sch\u00f6lkopf"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15168v2",
                "http://arxiv.org/pdf/2310.15168v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15166v1",
            "title": "Large Language Models are Visual Reasoning Coordinators",
            "updated": "2023-10-23T17:59:31Z",
            "published": "2023-10-23T17:59:31Z",
            "summary": "Visual reasoning requires multimodal perception and commonsense cognition of\nthe world. Recently, multiple vision-language models (VLMs) have been proposed\nwith excellent commonsense reasoning ability in various domains. However, how\nto harness the collective power of these complementary VLMs is rarely explored.\nExisting methods like ensemble still struggle to aggregate these models with\nthe desired higher-order communications. In this work, we propose Cola, a novel\nparadigm that coordinates multiple VLMs for visual reasoning. Our key insight\nis that a large language model (LLM) can efficiently coordinate multiple VLMs\nby facilitating natural language communication that leverages their distinct\nand complementary capabilities. Extensive experiments demonstrate that our\ninstruction tuning variant, Cola-FT, achieves state-of-the-art performance on\nvisual question answering (VQA), outside knowledge VQA, visual entailment, and\nvisual spatial reasoning tasks. Moreover, we show that our in-context learning\nvariant, Cola-Zero, exhibits competitive performance in zero and few-shot\nsettings, without finetuning. Through systematic ablation studies and\nvisualizations, we validate that a coordinator LLM indeed comprehends the\ninstruction prompts as well as the separate functionalities of VLMs; it then\ncoordinates them to enable impressive visual reasoning capabilities.",
            "author": [
                "Liangyu Chen",
                "Bo Li",
                "Sheng Shen",
                "Jingkang Yang",
                "Chunyuan Li",
                "Kurt Keutzer",
                "Trevor Darrell",
                "Ziwei Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15166v1",
                "http://arxiv.org/pdf/2310.15166v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15165v1",
            "title": "Handling Data Heterogeneity via Architectural Design for Federated\n  Visual Recognition",
            "updated": "2023-10-23T17:59:16Z",
            "published": "2023-10-23T17:59:16Z",
            "summary": "Federated Learning (FL) is a promising research paradigm that enables the\ncollaborative training of machine learning models among various parties without\nthe need for sensitive information exchange. Nonetheless, retaining data in\nindividual clients introduces fundamental challenges to achieving performance\non par with centrally trained models. Our study provides an extensive review of\nfederated learning applied to visual recognition. It underscores the critical\nrole of thoughtful architectural design choices in achieving optimal\nperformance, a factor often neglected in the FL literature. Many existing FL\nsolutions are tested on shallow or simple networks, which may not accurately\nreflect real-world applications. This practice restricts the transferability of\nresearch findings to large-scale visual recognition models. Through an in-depth\nanalysis of diverse cutting-edge architectures such as convolutional neural\nnetworks, transformers, and MLP-mixers, we experimentally demonstrate that\narchitectural choices can substantially enhance FL systems' performance,\nparticularly when handling heterogeneous data. We study 19 visual recognition\nmodels from five different architectural families on four challenging FL\ndatasets. We also re-investigate the inferior performance of convolution-based\narchitectures in the FL setting and analyze the influence of normalization\nlayers on the FL performance. Our findings emphasize the importance of\narchitectural design for computer vision tasks in practical scenarios,\neffectively narrowing the performance gap between federated and centralized\nlearning. Our source code is available at\nhttps://github.com/sarapieri/fed_het.git.",
            "author": [
                "Sara Pieri",
                "Jose Renato Restom",
                "Samuel Horvath",
                "Hisham Cholakkal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15165v1",
                "http://arxiv.org/pdf/2310.15165v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15163v2",
            "title": "Bitrate Ladder Prediction Methods for Adaptive Video Streaming: A Review\n  and Benchmark",
            "updated": "2023-10-30T19:11:04Z",
            "published": "2023-10-23T17:58:24Z",
            "summary": "HTTP adaptive streaming (HAS) has emerged as a widely adopted approach for\nover-the-top (OTT) video streaming services, due to its ability to deliver a\nseamless streaming experience. A key component of HAS is the bitrate ladder,\nwhich provides the encoding parameters (e.g., bitrate-resolution pairs) to\nencode the source video. The representations in the bitrate ladder allow the\nclient's player to dynamically adjust the quality of the video stream based on\nnetwork conditions by selecting the most appropriate representation from the\nbitrate ladder. The most straightforward and lowest complexity approach\ninvolves using a fixed bitrate ladder for all videos, consisting of\npre-determined bitrate-resolution pairs known as one-size-fits-all. Conversely,\nthe most reliable technique relies on intensively encoding all resolutions over\na wide range of bitrates to build the convex hull, thereby optimizing the\nbitrate ladder for each specific video. Several techniques have been proposed\nto predict content-based ladders without performing a costly exhaustive search\nencoding. This paper provides a comprehensive review of various methods,\nincluding both conventional and learning-based approaches. Furthermore, we\nconduct a benchmark study focusing exclusively on various learning-based\napproaches for predicting content-optimized bitrate ladders across multiple\ncodec settings. The considered methods are evaluated on our proposed\nlarge-scale dataset, which includes 300 UHD video shots encoded with software\nand hardware encoders using three state-of-the-art encoders, including\nAVC/H.264, HEVC/H.265, and VVC/H.266, at various bitrate points. Our analysis\nprovides baseline methods and insights, which will be valuable for future\nresearch in the field of bitrate ladder prediction. The source code of the\nproposed benchmark and the dataset will be made publicly available upon\nacceptance of the paper.",
            "author": [
                "Ahmed Telili",
                "Wassim Hamidouche",
                "Hadi Amirpour",
                "Sid Ahmed Fezza",
                "Luce Morin",
                "Christian Timmerer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15163v2",
                "http://arxiv.org/pdf/2310.15163v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15154v1",
            "title": "Linear Representations of Sentiment in Large Language Models",
            "updated": "2023-10-23T17:55:31Z",
            "published": "2023-10-23T17:55:31Z",
            "summary": "Sentiment is a pervasive feature in natural language text, yet it is an open\nquestion how sentiment is represented within Large Language Models (LLMs). In\nthis study, we reveal that across a range of models, sentiment is represented\nlinearly: a single direction in activation space mostly captures the feature\nacross a range of tasks with one extreme for positive and the other for\nnegative. Through causal interventions, we isolate this direction and show it\nis causally relevant in both toy tasks and real world datasets such as Stanford\nSentiment Treebank. Through this case study we model a thorough investigation\nof what a single direction means on a broad data distribution.\n  We further uncover the mechanisms that involve this direction, highlighting\nthe roles of a small subset of attention heads and neurons. Finally, we\ndiscover a phenomenon which we term the summarization motif: sentiment is not\nsolely represented on emotionally charged words, but is additionally summarized\nat intermediate positions without inherent sentiment, such as punctuation and\nnames. We show that in Stanford Sentiment Treebank zero-shot classification,\n76% of above-chance classification accuracy is lost when ablating the sentiment\ndirection, nearly half of which (36%) is due to ablating the summarized\nsentiment direction exclusively at comma positions.",
            "author": [
                "Curt Tigges",
                "Oskar John Hollinsworth",
                "Atticus Geiger",
                "Neel Nanda"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15154v1",
                "http://arxiv.org/pdf/2310.15154v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15153v1",
            "title": "Accelerate Microstructure Evolution Simulation Using Graph Neural\n  Networks with Adaptive Spatiotemporal Resolution",
            "updated": "2023-10-23T17:55:30Z",
            "published": "2023-10-23T17:55:30Z",
            "summary": "Surrogate models driven by sizeable datasets and scientific machine-learning\nmethods have emerged as an attractive microstructure simulation tool with the\npotential to deliver predictive microstructure evolution dynamics with huge\nsavings in computational costs. Taking 2D and 3D grain growth simulations as an\nexample, we present a completely overhauled computational framework based on\ngraph neural networks with not only excellent agreement to both the ground\ntruth phase-field methods and theoretical predictions, but enhanced accuracy\nand efficiency compared to previous works based on convolutional neural\nnetworks. These improvements can be attributed to the graph representation,\nboth improved predictive power and a more flexible data structure amenable to\nadaptive mesh refinement. As the simulated microstructures coarsen, our method\ncan adaptively adopt remeshed grids and larger timesteps to achieve further\nspeedup. The data-to-model pipeline with training procedures together with the\nsource codes are provided.",
            "author": [
                "Shaoxun Fan",
                "Andrew L. Hitt",
                "Ming Tang",
                "Babak Sadigh",
                "Fei Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15153v1",
                "http://arxiv.org/pdf/2310.15153v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15213v1",
            "title": "Function Vectors in Large Language Models",
            "updated": "2023-10-23T17:55:24Z",
            "published": "2023-10-23T17:55:24Z",
            "summary": "We report the presence of a simple neural mechanism that represents an\ninput-output function as a vector within autoregressive transformer language\nmodels (LMs). Using causal mediation analysis on a diverse range of\nin-context-learning (ICL) tasks, we find that a small number attention heads\ntransport a compact representation of the demonstrated task, which we call a\nfunction vector (FV). FVs are robust to changes in context, i.e., they trigger\nexecution of the task on inputs such as zero-shot and natural text settings\nthat do not resemble the ICL contexts from which they are collected. We test\nFVs across a range of tasks, models, and layers and find strong causal effects\nacross settings in middle layers. We investigate the internal structure of FVs\nand find while that they often contain information that encodes the output\nspace of the function, this information alone is not sufficient to reconstruct\nan FV. Finally, we test semantic vector composition in FVs, and find that to\nsome extent they can be summed to create vectors that trigger new complex\ntasks. Taken together, our findings suggest that LLMs contain internal\nabstractions of general-purpose functions that can be invoked in a variety of\ncontexts.",
            "author": [
                "Eric Todd",
                "Millicent L. Li",
                "Arnab Sen Sharma",
                "Aaron Mueller",
                "Byron C. Wallace",
                "David Bau"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15213v1",
                "http://arxiv.org/pdf/2310.15213v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15151v1",
            "title": "Verb Conjugation in Transformers Is Determined by Linear Encodings of\n  Subject Number",
            "updated": "2023-10-23T17:53:47Z",
            "published": "2023-10-23T17:53:47Z",
            "summary": "Deep architectures such as Transformers are sometimes criticized for having\nuninterpretable \"black-box\" representations. We use causal intervention\nanalysis to show that, in fact, some linguistic features are represented in a\nlinear, interpretable format. Specifically, we show that BERT's ability to\nconjugate verbs relies on a linear encoding of subject number that can be\nmanipulated with predictable effects on conjugation accuracy. This encoding is\nfound in the subject position at the first layer and the verb position at the\nlast layer, but distributed across positions at middle layers, particularly\nwhen there are multiple cues to subject number.",
            "author": [
                "Sophie Hao",
                "Tal Linzen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15151v1",
                "http://arxiv.org/pdf/2310.15151v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15150v1",
            "title": "Online Detection of AI-Generated Images",
            "updated": "2023-10-23T17:53:14Z",
            "published": "2023-10-23T17:53:14Z",
            "summary": "With advancements in AI-generated images coming on a continuous basis, it is\nincreasingly difficult to distinguish traditionally-sourced images (e.g.,\nphotos, artwork) from AI-generated ones. Previous detection methods study the\ngeneralization from a single generator to another in isolation. However, in\nreality, new generators are released on a streaming basis. We study\ngeneralization in this setting, training on N models and testing on the next\n(N+k), following the historical release dates of well-known generation methods.\nFurthermore, images increasingly consist of both real and generated components,\nfor example through image inpainting. Thus, we extend this approach to pixel\nprediction, demonstrating strong performance using automatically-generated\ninpainted data. In addition, for settings where commercial models are not\npublicly available for automatic data generation, we evaluate if pixel\ndetectors can be trained solely on whole synthetic images.",
            "author": [
                "David C. Epstein",
                "Ishan Jain",
                "Oliver Wang",
                "Richard Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15150v1",
                "http://arxiv.org/pdf/2310.15150v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15149v1",
            "title": "Unlocking the Transferability of Tokens in Deep Models for Tabular Data",
            "updated": "2023-10-23T17:53:09Z",
            "published": "2023-10-23T17:53:09Z",
            "summary": "Fine-tuning a pre-trained deep neural network has become a successful\nparadigm in various machine learning tasks. However, such a paradigm becomes\nparticularly challenging with tabular data when there are discrepancies between\nthe feature sets of pre-trained models and the target tasks. In this paper, we\npropose TabToken, a method aims at enhancing the quality of feature tokens\n(i.e., embeddings of tabular features). TabToken allows for the utilization of\npre-trained models when the upstream and downstream tasks share overlapping\nfeatures, facilitating model fine-tuning even with limited training examples.\nSpecifically, we introduce a contrastive objective that regularizes the tokens,\ncapturing the semantics within and across features. During the pre-training\nstage, the tokens are learned jointly with top-layer deep models such as\ntransformer. In the downstream task, tokens of the shared features are kept\nfixed while TabToken efficiently fine-tunes the remaining parts of the model.\nTabToken not only enables knowledge transfer from a pre-trained model to tasks\nwith heterogeneous features, but also enhances the discriminative ability of\ndeep tabular models in standard classification and regression tasks.",
            "author": [
                "Qi-Le Zhou",
                "Han-Jia Ye",
                "Le-Ye Wang",
                "De-Chuan Zhan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15149v1",
                "http://arxiv.org/pdf/2310.15149v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15148v1",
            "title": "Physics informed neural networks learning a two-qubit Hamiltonian",
            "updated": "2023-10-23T17:52:58Z",
            "published": "2023-10-23T17:52:58Z",
            "summary": "Machine learning techniques are employed to perform the full characterization\nof a quantum system. The particular artificial intelligence technique used to\nlearn the Hamiltonian is called physics informed neural network (PINN). The\nidea behind PINN is the universal approximation theorem, which claims that any\nfunction can be approximate by a neural network if it contains enough\ncomplexity. Consequently, a neural network can be a solution of a physical\nmodel. Moreover, by means of extra data provided by the user, intrinsic\nphysical parameters can be extracted from the approach called inverse-PINN.\nHere, we apply inverse-PINN with the goal of extracting all the physical\nparameters that constitutes a two qubit Hamiltonian. We find that this approach\nis very efficient. To probe the robustness of the inverse-PINN to learn the\nHamiltonian of a two-qubit system, we use the IBM quantum computers as\nexperimental platforms to obtain the data that is plugged in the PINN. We found\nthat our method is able to predict the two-qubit parameters with 5% of accuracy\non average.",
            "author": [
                "Leonardo K. Castelano",
                "Iann Cunha",
                "Fabricio S. Luiz",
                "Marcelo V. de Souza Prado",
                "Felipe F. Fanchini"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15148v1",
                "http://arxiv.org/pdf/2310.15148v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15145v1",
            "title": "Robot Fine-Tuning Made Easy: Pre-Training Rewards and Policies for\n  Autonomous Real-World Reinforcement Learning",
            "updated": "2023-10-23T17:50:08Z",
            "published": "2023-10-23T17:50:08Z",
            "summary": "The pre-train and fine-tune paradigm in machine learning has had dramatic\nsuccess in a wide range of domains because the use of existing data or\npre-trained models on the internet enables quick and easy learning of new\ntasks. We aim to enable this paradigm in robotic reinforcement learning,\nallowing a robot to learn a new task with little human effort by leveraging\ndata and models from the Internet. However, reinforcement learning often\nrequires significant human effort in the form of manual reward specification or\nenvironment resets, even if the policy is pre-trained. We introduce RoboFuME, a\nreset-free fine-tuning system that pre-trains a multi-task manipulation policy\nfrom diverse datasets of prior experiences and self-improves online to learn a\ntarget task with minimal human intervention. Our insights are to utilize\ncalibrated offline reinforcement learning techniques to ensure efficient online\nfine-tuning of a pre-trained policy in the presence of distribution shifts and\nleverage pre-trained vision language models (VLMs) to build a robust reward\nclassifier for autonomously providing reward signals during the online\nfine-tuning process. In a diverse set of five real robot manipulation tasks, we\nshow that our method can incorporate data from an existing robot dataset\ncollected at a different institution and improve on a target task within as\nlittle as 3 hours of autonomous real-world experience. We also demonstrate in\nsimulation experiments that our method outperforms prior works that use\ndifferent RL algorithms or different approaches for predicting rewards. Project\nwebsite: https://robofume.github.io",
            "author": [
                "Jingyun Yang",
                "Max Sobol Mark",
                "Brandon Vu",
                "Archit Sharma",
                "Jeannette Bohg",
                "Chelsea Finn"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15145v1",
                "http://arxiv.org/pdf/2310.15145v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15143v1",
            "title": "Hyperparameter optimization of hp-greedy reduced basis for gravitational\n  wave surrogates",
            "updated": "2023-10-23T17:48:11Z",
            "published": "2023-10-23T17:48:11Z",
            "summary": "In a previous work we introduced, in the context of gravitational wave\nscience, an initial study on an automated domain-decomposition approach for\nreduced basis through hp-greedy refinement. The approach constructs local\nreduced bases of lower dimensionality than global ones, with the same or higher\naccuracy. These ``light'' local bases should imply both faster evaluations when\npredicting new waveforms and faster data analysis, in particular faster\nstatistical inference (the forward and inverse problems, respectively). In this\napproach, however, we have previously found important dependence on several\nhyperparameters, which do not appear in global reduced basis. This naturally\nleads to the problem of hyperparameter optimization (HPO), which is the subject\nof this paper. We tackle the problem through a Bayesian optimization, and show\nits superiority when compared to grid or random searches. We find that for\ngravitational waves from the collision of two spinning but non-precessing black\nholes, for the same accuracy, local hp-greedy reduced bases with HPO have a\nlower dimensionality of up to $4 \\times$ for the cases here studied, depending\non the desired accuracy. This factor should directly translate in a parameter\nestimation speedup, for instance. Such acceleration might help in the near\nreal-time requirements for electromagnetic counterparts of gravitational waves\nfrom compact binary coalescences. In addition, we find that the Bayesian\napproach used in this paper for HPO is two orders of magnitude faster than, for\nexample, a grid search, with about a $100 \\times$ acceleration. The code\ndeveloped for this project is available as open source from public\nrepositories.",
            "author": [
                "Franco Cerino",
                "Andr\u00e9s Diaz-Pace",
                "Emmanuel Tassone",
                "Manuel Tiglio",
                "Atuel Villegas"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15143v1",
                "http://arxiv.org/pdf/2310.15143v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "astro-ph.IM",
                "cs.LG",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15141v1",
            "title": "SpecTr: Fast Speculative Decoding via Optimal Transport",
            "updated": "2023-10-23T17:47:34Z",
            "published": "2023-10-23T17:47:34Z",
            "summary": "Autoregressive sampling from large language models has led to\nstate-of-the-art results in several natural language tasks. However,\nautoregressive sampling generates tokens one at a time making it slow, and even\nprohibitive in certain tasks. One way to speed up sampling is\n$\\textit{speculative decoding}$: use a small model to sample a $\\textit{draft}$\n(block or sequence of tokens), and then score all tokens in the draft by the\nlarge language model in parallel. A subset of the tokens in the draft are\naccepted (and the rest rejected) based on a statistical method to guarantee\nthat the final output follows the distribution of the large model. In this\nwork, we provide a principled understanding of speculative decoding through the\nlens of optimal transport (OT) with $\\textit{membership cost}$. This framework\ncan be viewed as an extension of the well-known $\\textit{maximal-coupling}$\nproblem. This new formulation enables us to generalize the speculative decoding\nmethod to allow for a set of $k$ candidates at the token-level, which leads to\nan improved optimal membership cost. We show that the optimal draft selection\nalgorithm (transport plan) can be computed via linear programming, whose\nbest-known runtime is exponential in $k$. We then propose a valid draft\nselection algorithm whose acceptance probability is $(1-1/e)$-optimal\nmultiplicatively. Moreover, it can be computed in time almost linear with size\nof domain of a single token. Using this $new draft selection$ algorithm, we\ndevelop a new autoregressive sampling algorithm called $\\textit{SpecTr}$, which\nprovides speedup in decoding while ensuring that there is no quality\ndegradation in the decoded output. We experimentally demonstrate that for\nstate-of-the-art large language models, the proposed approach achieves a wall\nclock speedup of 2.13X, a further 1.37X speedup over speculative decoding on\nstandard benchmarks.",
            "author": [
                "Ziteng Sun",
                "Ananda Theertha Suresh",
                "Jae Hun Ro",
                "Ahmad Beirami",
                "Himanshu Jain",
                "Felix Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15141v1",
                "http://arxiv.org/pdf/2310.15141v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.DS",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15140v1",
            "title": "AutoDAN: Automatic and Interpretable Adversarial Attacks on Large\n  Language Models",
            "updated": "2023-10-23T17:46:07Z",
            "published": "2023-10-23T17:46:07Z",
            "summary": "Safety alignment of Large Language Models (LLMs) can be compromised with\nmanual jailbreak attacks and (automatic) adversarial attacks. Recent work\nsuggests that patching LLMs against these attacks is possible: manual jailbreak\nattacks are human-readable but often limited and public, making them easy to\nblock; adversarial attacks generate gibberish prompts that can be detected\nusing perplexity-based filters. In this paper, we show that these solutions may\nbe too optimistic. We propose an interpretable adversarial attack,\n\\texttt{AutoDAN}, that combines the strengths of both types of attacks. It\nautomatically generates attack prompts that bypass perplexity-based filters\nwhile maintaining a high attack success rate like manual jailbreak attacks.\nThese prompts are interpretable and diverse, exhibiting strategies commonly\nused in manual jailbreak attacks, and transfer better than their non-readable\ncounterparts when using limited training data or a single proxy model. We also\ncustomize \\texttt{AutoDAN}'s objective to leak system prompts, another\njailbreak application not addressed in the adversarial attack literature. Our\nwork provides a new way to red-team LLMs and to understand the mechanism of\njailbreak attacks.",
            "author": [
                "Sicheng Zhu",
                "Ruiyi Zhang",
                "Bang An",
                "Gang Wu",
                "Joe Barrow",
                "Zichao Wang",
                "Furong Huang",
                "Ani Nenkova",
                "Tong Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15140v1",
                "http://arxiv.org/pdf/2310.15140v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15135v1",
            "title": "Quantifying the Dialect Gap and its Correlates Across Languages",
            "updated": "2023-10-23T17:42:01Z",
            "published": "2023-10-23T17:42:01Z",
            "summary": "Historically, researchers and consumers have noticed a decrease in quality\nwhen applying NLP tools to minority variants of languages (i.e. Puerto Rican\nSpanish or Swiss German), but studies exploring this have been limited to a\nselect few languages. Additionally, past studies have mainly been conducted in\na monolingual context, so cross-linguistic trends have not been identified and\ntied to external factors. In this work, we conduct a comprehensive evaluation\nof the most influential, state-of-the-art large language models (LLMs) across\ntwo high-use applications, machine translation and automatic speech\nrecognition, to assess their functionality on the regional dialects of several\nhigh- and low-resource languages. Additionally, we analyze how the regional\ndialect gap is correlated with economic, social, and linguistic factors. The\nimpact of training data, including related factors like dataset size and its\nconstruction procedure, is shown to be significant but not consistent across\nmodels or languages, meaning a one-size-fits-all approach cannot be taken in\nsolving the dialect gap. This work will lay the foundation for furthering the\nfield of dialectal NLP by laying out evident disparities and identifying\npossible pathways for addressing them through mindful data collection.",
            "author": [
                "Anjali Kantharuban",
                "Ivan Vuli\u0107",
                "Anna Korhonen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15135v1",
                "http://arxiv.org/pdf/2310.15135v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15129v1",
            "title": "Location-Aware Visual Question Generation with Lightweight Models",
            "updated": "2023-10-23T17:33:31Z",
            "published": "2023-10-23T17:33:31Z",
            "summary": "This work introduces a novel task, location-aware visual question generation\n(LocaVQG), which aims to generate engaging questions from data relevant to a\nparticular geographical location. Specifically, we represent such\nlocation-aware information with surrounding images and a GPS coordinate. To\ntackle this task, we present a dataset generation pipeline that leverages GPT-4\nto produce diverse and sophisticated questions. Then, we aim to learn a\nlightweight model that can address the LocaVQG task and fit on an edge device,\nsuch as a mobile phone. To this end, we propose a method which can reliably\ngenerate engaging questions from location-aware information. Our proposed\nmethod outperforms baselines regarding human evaluation (e.g., engagement,\ngrounding, coherence) and automatic evaluation metrics (e.g., BERTScore,\nROUGE-2). Moreover, we conduct extensive ablation studies to justify our\nproposed techniques for both generating the dataset and solving the task.",
            "author": [
                "Nicholas Collin Suwono",
                "Justin Chih-Yao Chen",
                "Tun Min Hung",
                "Ting-Hao Kenneth Huang",
                "I-Bin Liao",
                "Yung-Hui Li",
                "Lun-Wei Ku",
                "Shao-Hua Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15129v1",
                "http://arxiv.org/pdf/2310.15129v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15128v1",
            "title": "Projected Stochastic Gradient Descent with Quantum Annealed Binary\n  Gradients",
            "updated": "2023-10-23T17:32:38Z",
            "published": "2023-10-23T17:32:38Z",
            "summary": "We present, QP-SBGD, a novel layer-wise stochastic optimiser tailored towards\ntraining neural networks with binary weights, known as binary neural networks\n(BNNs), on quantum hardware. BNNs reduce the computational requirements and\nenergy consumption of deep learning models with minimal loss in accuracy.\nHowever, training them in practice remains to be an open challenge. Most known\nBNN-optimisers either rely on projected updates or binarise weights\npost-training. Instead, QP-SBGD approximately maps the gradient onto binary\nvariables, by solving a quadratic constrained binary optimisation. Under\npractically reasonable assumptions, we show that this update rule converges\nwith a rate of $\\mathcal{O}(1 / \\sqrt{T})$. Moreover, we show how the\n$\\mathcal{NP}$-hard projection can be effectively executed on an adiabatic\nquantum annealer, harnessing recent advancements in quantum computation. We\nalso introduce a projected version of this update rule and prove that if a\nfixed point exists in the binary variable space, the modified updates will\nconverge to it. Last but not least, our algorithm is implemented layer-wise,\nmaking it suitable to train larger networks on resource-limited quantum\nhardware. Through extensive evaluations, we show that QP-SBGD outperforms or is\non par with competitive and well-established baselines such as BinaryConnect,\nsignSGD and ProxQuant when optimising the Rosenbrock function, training BNNs as\nwell as binary graph neural networks.",
            "author": [
                "Maximilian Krahn",
                "Michelle Sasdelli",
                "Fengyi Yang",
                "Vladislav Golyanik",
                "Juho Kannala",
                "Tat-Jun Chin",
                "Tolga Birdal"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15128v1",
                "http://arxiv.org/pdf/2310.15128v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15127v2",
            "title": "Open-Ended Instructable Embodied Agents with Memory-Augmented Large\n  Language Models",
            "updated": "2023-11-20T18:51:29Z",
            "published": "2023-10-23T17:31:55Z",
            "summary": "Pre-trained and frozen large language models (LLMs) can effectively map\nsimple scene rearrangement instructions to programs over a robot's visuomotor\nfunctions through appropriate few-shot example prompting. To parse open-domain\nnatural language and adapt to a user's idiosyncratic procedures, not known\nduring prompt engineering time, fixed prompts fall short. In this paper, we\nintroduce HELPER, an embodied agent equipped with an external memory of\nlanguage-program pairs that parses free-form human-robot dialogue into action\nprograms through retrieval-augmented LLM prompting: relevant memories are\nretrieved based on the current dialogue, instruction, correction, or VLM\ndescription, and used as in-context prompt examples for LLM querying. The\nmemory is expanded during deployment to include pairs of user's language and\naction plans, to assist future inferences and personalize them to the user's\nlanguage and routines. HELPER sets a new state-of-the-art in the TEACh\nbenchmark in both Execution from Dialog History (EDH) and Trajectory from\nDialogue (TfD), with a 1.7x improvement over the previous state-of-the-art for\nTfD. Our models, code, and video results can be found in our project's website:\nhttps://helper-agent-llm.github.io.",
            "author": [
                "Gabriel Sarch",
                "Yue Wu",
                "Michael J. Tarr",
                "Katerina Fragkiadaki"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15127v2",
                "http://arxiv.org/pdf/2310.15127v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15124v1",
            "title": "Mixed-Variable Global Sensitivity Analysis For Knowledge Discovery And\n  Efficient Combinatorial Materials Design",
            "updated": "2023-10-23T17:29:53Z",
            "published": "2023-10-23T17:29:53Z",
            "summary": "Global Sensitivity Analysis (GSA) is the study of the influence of any given\ninputs on the outputs of a model. In the context of engineering design, GSA has\nbeen widely used to understand both individual and collective contributions of\ndesign variables on the design objectives. So far, global sensitivity studies\nhave often been limited to design spaces with only quantitative (numerical)\ndesign variables. However, many engineering systems also contain, if not only,\nqualitative (categorical) design variables in addition to quantitative design\nvariables. In this paper, we integrate Latent Variable Gaussian Process (LVGP)\nwith Sobol' analysis to develop the first metamodel-based mixed-variable GSA\nmethod. Through numerical case studies, we validate and demonstrate the\neffectiveness of our proposed method for mixed-variable problems. Furthermore,\nwhile the proposed GSA method is general enough to benefit various engineering\ndesign applications, we integrate it with multi-objective Bayesian optimization\n(BO) to create a sensitivity-aware design framework in accelerating the Pareto\nfront design exploration for metal-organic framework (MOF) materials with\nmany-level combinatorial design spaces. Although MOFs are constructed only from\nqualitative variables that are notoriously difficult to design, our method can\nutilize sensitivity analysis to navigate the optimization in the many-level\nlarge combinatorial design space, greatly expediting the exploration of novel\nMOF candidates.",
            "author": [
                "Yigitcan Comlek",
                "Liwei Wang",
                "Wei Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15124v1",
                "http://arxiv.org/pdf/2310.15124v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cond-mat.mtrl-sci",
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15123v1",
            "title": "Branch-Solve-Merge Improves Large Language Model Evaluation and\n  Generation",
            "updated": "2023-10-23T17:29:48Z",
            "published": "2023-10-23T17:29:48Z",
            "summary": "Large Language Models (LLMs) are frequently used for multi-faceted language\ngeneration and evaluation tasks that involve satisfying intricate user\nconstraints or taking into account multiple aspects and criteria. However,\ntheir performance can fall short, due to the model's lack of coherence and\ninability to plan and decompose the problem. We propose Branch-Solve-Merge\n(BSM), a Large Language Model program (Schlag et al., 2023) for tackling such\nchallenging natural language tasks. It consists of branch, solve, and merge\nmodules that are parameterized with specific prompts to the base LLM. These\nthree modules plan a decomposition of the task into multiple parallel\nsub-tasks, independently solve them, and fuse the solutions to the sub-tasks.\nWe apply our method to the tasks of LLM response evaluation and constrained\ntext generation and evaluate its effectiveness with multiple LLMs, including\nVicuna, LLaMA-2-chat, and GPT-4. BSM improves the evaluation correctness and\nconsistency for each LLM by enhancing human-LLM agreement by up to 26%,\nreducing length and pairwise position biases by up to 50%, and allowing\nLLaMA-2-chat to match or outperform GPT-4 on most domains. On the constraint\nstory generation task, BSM improves the coherence of the stories while also\nimproving constraint satisfaction by 12%.",
            "author": [
                "Swarnadeep Saha",
                "Omer Levy",
                "Asli Celikyilmaz",
                "Mohit Bansal",
                "Jason Weston",
                "Xian Li"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15123v1",
                "http://arxiv.org/pdf/2310.15123v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15211v2",
            "title": "Modeling Path Importance for Effective Alzheimer's Disease Drug\n  Repurposing",
            "updated": "2023-10-27T16:29:44Z",
            "published": "2023-10-23T17:24:11Z",
            "summary": "Recently, drug repurposing has emerged as an effective and resource-efficient\nparadigm for AD drug discovery. Among various methods for drug repurposing,\nnetwork-based methods have shown promising results as they are capable of\nleveraging complex networks that integrate multiple interaction types, such as\nprotein-protein interactions, to more effectively identify candidate drugs.\nHowever, existing approaches typically assume paths of the same length in the\nnetwork have equal importance in identifying the therapeutic effect of drugs.\nOther domains have found that same length paths do not necessarily have the\nsame importance. Thus, relying on this assumption may be deleterious to drug\nrepurposing attempts. In this work, we propose MPI (Modeling Path Importance),\na novel network-based method for AD drug repurposing. MPI is unique in that it\nprioritizes important paths via learned node embeddings, which can effectively\ncapture a network's rich structural information. Thus, leveraging learned\nembeddings allows MPI to effectively differentiate the importance among paths.\nWe evaluate MPI against a commonly used baseline method that identifies anti-AD\ndrug candidates primarily based on the shortest paths between drugs and AD in\nthe network. We observe that among the top-50 ranked drugs, MPI prioritizes\n20.0% more drugs with anti-AD evidence compared to the baseline. Finally, Cox\nproportional-hazard models produced from insurance claims data aid us in\nidentifying the use of etodolac, nicotine, and BBB-crossing ACE-INHs as having\na reduced risk of AD, suggesting such drugs may be viable candidates for\nrepurposing and should be explored further in future studies.",
            "author": [
                "Shunian Xiang",
                "Patrick J. Lawrence",
                "Bo Peng",
                "ChienWei Chiang",
                "Dokyoon Kim",
                "Li Shen",
                "Xia Ning"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15211v2",
                "http://arxiv.org/pdf/2310.15211v2"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.AI",
                "cs.LG",
                "q-bio.MN"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15111v1",
            "title": "Matryoshka Diffusion Models",
            "updated": "2023-10-23T17:20:01Z",
            "published": "2023-10-23T17:20:01Z",
            "summary": "Diffusion models are the de facto approach for generating high-quality images\nand videos, but learning high-dimensional models remains a formidable task due\nto computational and optimization challenges. Existing methods often resort to\ntraining cascaded models in pixel space or using a downsampled latent space of\na separately trained auto-encoder. In this paper, we introduce Matryoshka\nDiffusion Models(MDM), an end-to-end framework for high-resolution image and\nvideo synthesis. We propose a diffusion process that denoises inputs at\nmultiple resolutions jointly and uses a NestedUNet architecture where features\nand parameters for small-scale inputs are nested within those of large scales.\nIn addition, MDM enables a progressive training schedule from lower to higher\nresolutions, which leads to significant improvements in optimization for\nhigh-resolution generation. We demonstrate the effectiveness of our approach on\nvarious benchmarks, including class-conditioned image generation,\nhigh-resolution text-to-image, and text-to-video applications. Remarkably, we\ncan train a single pixel-space model at resolutions of up to 1024x1024 pixels,\ndemonstrating strong zero-shot generalization using the CC12M dataset, which\ncontains only 12 million images.",
            "author": [
                "Jiatao Gu",
                "Shuangfei Zhai",
                "Yizhe Zhang",
                "Josh Susskind",
                "Navdeep Jaitly"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15111v1",
                "http://arxiv.org/pdf/2310.15111v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15109v1",
            "title": "GRENADE: Graph-Centric Language Model for Self-Supervised Representation\n  Learning on Text-Attributed Graphs",
            "updated": "2023-10-23T17:18:35Z",
            "published": "2023-10-23T17:18:35Z",
            "summary": "Self-supervised representation learning on text-attributed graphs, which aims\nto create expressive and generalizable representations for various downstream\ntasks, has received increasing research attention lately. However, existing\nmethods either struggle to capture the full extent of structural context\ninformation or rely on task-specific training labels, which largely hampers\ntheir effectiveness and generalizability in practice. To solve the problem of\nself-supervised representation learning on text-attributed graphs, we develop a\nnovel Graph-Centric Language model -- GRENADE. Specifically, GRENADE exploits\nthe synergistic effect of both pre-trained language model and graph neural\nnetwork by optimizing with two specialized self-supervised learning algorithms:\ngraph-centric contrastive learning and graph-centric knowledge alignment. The\nproposed graph-centric self-supervised learning algorithms effectively help\nGRENADE to capture informative textual semantics as well as structural context\ninformation on text-attributed graphs. Through extensive experiments, GRENADE\nshows its superiority over state-of-the-art methods. Implementation is\navailable at \\url{https://github.com/bigheiniu/GRENADE}.",
            "author": [
                "Yichuan Li",
                "Kaize Ding",
                "Kyumin Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15109v1",
                "http://arxiv.org/pdf/2310.15109v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15108v1",
            "title": "Evaluating machine learning models in non-standard settings: An overview\n  and new findings",
            "updated": "2023-10-23T17:15:11Z",
            "published": "2023-10-23T17:15:11Z",
            "summary": "Estimating the generalization error (GE) of machine learning models is\nfundamental, with resampling methods being the most common approach. However,\nin non-standard settings, particularly those where observations are not\nindependently and identically distributed, resampling using simple random data\ndivisions may lead to biased GE estimates. This paper strives to present\nwell-grounded guidelines for GE estimation in various such non-standard\nsettings: clustered data, spatial data, unequal sampling probabilities, concept\ndrift, and hierarchically structured outcomes. Our overview combines\nwell-established methodologies with other existing methods that, to our\nknowledge, have not been frequently considered in these particular settings. A\nunifying principle among these techniques is that the test data used in each\niteration of the resampling procedure should reflect the new observations to\nwhich the model will be applied, while the training data should be\nrepresentative of the entire data set used to obtain the final model. Beyond\nproviding an overview, we address literature gaps by conducting simulation\nstudies. These studies assess the necessity of using GE-estimation methods\ntailored to the respective setting. Our findings corroborate the concern that\nstandard resampling methods often yield biased GE estimates in non-standard\nsettings, underscoring the importance of tailored GE estimation.",
            "author": [
                "Roman Hornung",
                "Malte Nalenz",
                "Lennart Schneider",
                "Andreas Bender",
                "Ludwig Bothmann",
                "Bernd Bischl",
                "Thomas Augustin",
                "Anne-Laure Boulesteix"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15108v1",
                "http://arxiv.org/pdf/2310.15108v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.AP",
                "stat.CO",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15107v1",
            "title": "Assembling a high-precision abundance catalogue of solar twins in GALAH\n  for phylogenetic studies",
            "updated": "2023-10-23T17:14:43Z",
            "published": "2023-10-23T17:14:43Z",
            "summary": "Stellar chemical abundances have proved themselves a key source of\ninformation for understanding the evolution of the Milky Way, and the scale of\nmajor stellar surveys such as GALAH have massively increased the amount of\nchemical data available. However, progress is hampered by the level of\nprecision in chemical abundance data as well as the visualization methods for\ncomparing the multidimensional outputs of chemical evolution models to stellar\nabundance data. Machine learning methods have greatly improved the former;\nwhile the application of tree-building or phylogenetic methods borrowed from\nbiology are beginning to show promise with the latter. Here we analyse a sample\nof GALAH solar twins to address these issues. We apply The Cannon algorithm\n(Ness et al. (2015)) to generate a catalogue of about 40,000 solar twins with\n14 high precision abundances which we use to perform a phylogenetic analysis on\na selection of stars that have two different ranges of eccentricities. From our\nanalyses we are able to find a group with mostly stars on circular orbits and\nsome old stars with eccentric orbits whose age-[Y/Mg] relation agrees\nremarkably well with the chemical clocks published by previous high precision\nabundance studies. Our results show the power of combining survey data with\nmachine learning and phylogenetics to reconstruct the history of the Milky Way.",
            "author": [
                "Kurt Walsen",
                "Paula Jofr\u00e9",
                "Sven Buder",
                "Keaghan Yaxley",
                "Payel Das",
                "Robert Yates",
                "Xia Hua",
                "Theosamuele Signor",
                "Camilla Eldridge",
                "Alvaro Rojas-Arriagada",
                "Patricia Tissera",
                "Evelyn Johnston",
                "Claudia Aguilera-G\u00f3mez",
                "Manuela Zoccali",
                "Gerry Gilmore",
                "Robert Foley"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15107v1",
                "http://arxiv.org/pdf/2310.15107v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15105v4",
            "title": "FD-Align: Feature Discrimination Alignment for Fine-tuning Pre-Trained\n  Models in Few-Shot Learning",
            "updated": "2023-11-17T07:27:34Z",
            "published": "2023-10-23T17:12:01Z",
            "summary": "Due to the limited availability of data, existing few-shot learning methods\ntrained from scratch fail to achieve satisfactory performance. In contrast,\nlarge-scale pre-trained models such as CLIP demonstrate remarkable few-shot and\nzero-shot capabilities. To enhance the performance of pre-trained models for\ndownstream tasks, fine-tuning the model on downstream data is frequently\nnecessary. However, fine-tuning the pre-trained model leads to a decrease in\nits generalizability in the presence of distribution shift, while the limited\nnumber of samples in few-shot learning makes the model highly susceptible to\noverfitting. Consequently, existing methods for fine-tuning few-shot learning\nprimarily focus on fine-tuning the model's classification head or introducing\nadditional structure. In this paper, we introduce a fine-tuning approach termed\nFeature Discrimination Alignment (FD-Align). Our method aims to bolster the\nmodel's generalizability by preserving the consistency of spurious features\nacross the fine-tuning process. Extensive experimental results validate the\nefficacy of our approach for both ID and OOD tasks. Once fine-tuned, the model\ncan seamlessly integrate with existing methods, leading to performance\nimprovements. Our code can be found in https://github.com/skingorz/FD-Align.",
            "author": [
                "Kun Song",
                "Huimin Ma",
                "Bochao Zou",
                "Huishuai Zhang",
                "Weiran Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15105v4",
                "http://arxiv.org/pdf/2310.15105v4"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15100v1",
            "title": "LLM-in-the-loop: Leveraging Large Language Model for Thematic Analysis",
            "updated": "2023-10-23T17:05:59Z",
            "published": "2023-10-23T17:05:59Z",
            "summary": "Thematic analysis (TA) has been widely used for analyzing qualitative data in\nmany disciplines and fields. To ensure reliable analysis, the same piece of\ndata is typically assigned to at least two human coders. Moreover, to produce\nmeaningful and useful analysis, human coders develop and deepen their data\ninterpretation and coding over multiple iterations, making TA labor-intensive\nand time-consuming. Recently the emerging field of large language models (LLMs)\nresearch has shown that LLMs have the potential replicate human-like behavior\nin various tasks: in particular, LLMs outperform crowd workers on\ntext-annotation tasks, suggesting an opportunity to leverage LLMs on TA. We\npropose a human-LLM collaboration framework (i.e., LLM-in-the-loop) to conduct\nTA with in-context learning (ICL). This framework provides the prompt to frame\ndiscussions with a LLM (e.g., GPT-3.5) to generate the final codebook for TA.\nWe demonstrate the utility of this framework using survey datasets on the\naspects of the music listening experience and the usage of a password manager.\nResults of the two case studies show that the proposed framework yields similar\ncoding quality to that of human coders but reduces TA's labor and time demands.",
            "author": [
                "Shih-Chieh Dai",
                "Aiping Xiong",
                "Lun-Wei Ku"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15100v1",
                "http://arxiv.org/pdf/2310.15100v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15099v1",
            "title": "Dual-path convolutional neural network using micro-FTIR imaging to\n  predict breast cancer subtypes and biomarkers levels: estrogen receptor,\n  progesterone receptor, HER2 and Ki67",
            "updated": "2023-10-23T17:05:53Z",
            "published": "2023-10-23T17:05:53Z",
            "summary": "Breast cancer molecular subtypes classification plays an import role to sort\npatients with divergent prognosis. The biomarkers used are Estrogen Receptor\n(ER), Progesterone Receptor (PR), HER2, and Ki67. Based on these biomarkers\nexpression levels, subtypes are classified as Luminal A (LA), Luminal B (LB),\nHER2 subtype, and Triple-Negative Breast Cancer (TNBC). Immunohistochemistry is\nused to classify subtypes, although interlaboratory and interobserver\nvariations can affect its accuracy, besides being a time-consuming technique.\nThe Fourier transform infrared micro-spectroscopy may be coupled with deep\nlearning for cancer evaluation, where there is still a lack of studies for\nsubtypes and biomarker levels prediction. This study presents a novel 2D deep\nlearning approach to achieve these predictions. Sixty micro-FTIR images of\n320x320 pixels were collected from a human breast biopsies microarray. Data\nwere clustered by K-means, preprocessed and 32x32 patches were generated using\na fully automated approach. CaReNet-V2, a novel convolutional neural network,\nwas developed to classify breast cancer (CA) vs adjacent tissue (AT) and\nmolecular subtypes, and to predict biomarkers level. The clustering method\nenabled to remove non-tissue pixels. Test accuracies for CA vs AT and subtype\nwere above 0.84. The model enabled the prediction of ER, PR, and HER2 levels,\nwhere borderline values showed lower performance (minimum accuracy of 0.54).\nKi67 percentage regression demonstrated a mean error of 3.6%. Thus, CaReNet-V2\nis a potential technique for breast cancer biopsies evaluation, standing out as\na screening analysis technique and helping to prioritize patients.",
            "author": [
                "Matheus del-Valle",
                "Emerson Soares Bernardes",
                "Denise Maria Zezell"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15099v1",
                "http://arxiv.org/pdf/2310.15099v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "I.2; I.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15098v1",
            "title": "Acquiring Weak Annotations for Tumor Localization in Temporal and\n  Volumetric Data",
            "updated": "2023-10-23T17:03:02Z",
            "published": "2023-10-23T17:03:02Z",
            "summary": "Creating large-scale and well-annotated datasets to train AI algorithms is\ncrucial for automated tumor detection and localization. However, with limited\nresources, it is challenging to determine the best type of annotations when\nannotating massive amounts of unlabeled data. To address this issue, we focus\non polyps in colonoscopy videos and pancreatic tumors in abdominal CT scans;\nboth applications require significant effort and time for pixel-wise annotation\ndue to the high dimensional nature of the data, involving either temporary or\nspatial dimensions. In this paper, we develop a new annotation strategy, termed\nDrag&Drop, which simplifies the annotation process to drag and drop. This\nannotation strategy is more efficient, particularly for temporal and volumetric\nimaging, than other types of weak annotations, such as per-pixel, bounding\nboxes, scribbles, ellipses, and points. Furthermore, to exploit our Drag&Drop\nannotations, we develop a novel weakly supervised learning method based on the\nwatershed algorithm. Experimental results show that our method achieves better\ndetection and localization performance than alternative weak annotations and,\nmore importantly, achieves similar performance to that trained on detailed\nper-pixel annotations. Interestingly, we find that, with limited resources,\nallocating weak annotations from a diverse patient population can foster models\nmore robust to unseen images than allocating per-pixel annotations for a small\nset of images. In summary, this research proposes an efficient annotation\nstrategy for tumor detection and localization that is less accurate than\nper-pixel annotations but useful for creating large-scale datasets for\nscreening tumors in various medical modalities.",
            "author": [
                "Yu-Cheng Chou",
                "Bowen Li",
                "Deng-Ping Fan",
                "Alan Yuille",
                "Zongwei Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15098v1",
                "http://arxiv.org/pdf/2310.15098v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15097v1",
            "title": "A Canonical Data Transformation for Achieving Inter- and Within-group\n  Fairness",
            "updated": "2023-10-23T17:00:20Z",
            "published": "2023-10-23T17:00:20Z",
            "summary": "Increases in the deployment of machine learning algorithms for applications\nthat deal with sensitive data have brought attention to the issue of fairness\nin machine learning. Many works have been devoted to applications that require\ndifferent demographic groups to be treated fairly. However, algorithms that aim\nto satisfy inter-group fairness (also called group fairness) may inadvertently\ntreat individuals within the same demographic group unfairly. To address this\nissue, we introduce a formal definition of within-group fairness that maintains\nfairness among individuals from within the same group. We propose a\npre-processing framework to meet both inter- and within-group fairness criteria\nwith little compromise in accuracy. The framework maps the feature vectors of\nmembers from different groups to an inter-group-fair canonical domain before\nfeeding them into a scoring function. The mapping is constructed to preserve\nthe relative relationship between the scores obtained from the unprocessed\nfeature vectors of individuals from the same demographic group, guaranteeing\nwithin-group fairness. We apply this framework to the COMPAS risk assessment\nand Law School datasets and compare its performance in achieving inter-group\nand within-group fairness to two regularization-based methods.",
            "author": [
                "Zachary McBride Lazri",
                "Ivan Brugere",
                "Xin Tian",
                "Dana Dachman-Soled",
                "Antigoni Polychroniadou",
                "Danial Dervovic",
                "Min Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15097v1",
                "http://arxiv.org/pdf/2310.15097v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15094v1",
            "title": "One-dimensional convolutional neural network model for breast cancer\n  subtypes classification and biochemical content evaluation using micro-FTIR\n  hyperspectral images",
            "updated": "2023-10-23T16:58:34Z",
            "published": "2023-10-23T16:58:34Z",
            "summary": "Breast cancer treatment still remains a challenge, where molecular subtypes\nclassification plays a crucial role in selecting appropriate and specific\ntherapy. The four subtypes are Luminal A (LA), Luminal B (LB), HER2 subtype,\nand Triple-Negative Breast Cancer (TNBC). Immunohistochemistry is the\ngold-standard evaluation, although interobserver variations are reported and\nmolecular signatures identification is time-consuming. Fourier transform\ninfrared micro-spectroscopy with machine learning approaches have been used to\nevaluate cancer samples, presenting biochemical-related explainability.\nHowever, this explainability is harder when using deep learning. This study\ncreated a 1D deep learning tool for breast cancer subtype evaluation and\nbiochemical contribution. Sixty hyperspectral images were acquired from a human\nbreast cancer microarray. K-Means clustering was applied to select tissue and\nparaffin spectra. CaReNet-V1, a novel 1D convolutional neural network, was\ndeveloped to classify breast cancer (CA) and adjacent tissue (AT), and\nmolecular subtypes. A 1D adaptation of Grad-CAM was applied to assess the\nbiochemical impact to the classifications. CaReNet-V1 effectively classified CA\nand AT (test accuracy of 0.89), as well as HER2 and TNBC subtypes (0.83 and\n0.86), with greater difficulty for LA and LB (0.74 and 0.68). The model enabled\nthe evaluation of the most contributing wavenumbers to the predictions,\nproviding a direct relationship with the biochemical content. Therefore,\nCaReNet-V1 and hyperspectral images is a potential approach for breast cancer\nbiopsies assessment, providing additional information to the pathology report.\nBiochemical content impact feature may be used for other studies, such as\ntreatment efficacy evaluation and development new diagnostics and therapeutic\nmethods.",
            "author": [
                "Matheus del-Valle",
                "Emerson Soares Bernardes",
                "Denise Maria Zezell"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15094v1",
                "http://arxiv.org/pdf/2310.15094v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "I.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15085v1",
            "title": "On the Detection of Image-Scaling Attacks in Machine Learning",
            "updated": "2023-10-23T16:46:28Z",
            "published": "2023-10-23T16:46:28Z",
            "summary": "Image scaling is an integral part of machine learning and computer vision\nsystems. Unfortunately, this preprocessing step is vulnerable to so-called\nimage-scaling attacks where an attacker makes unnoticeable changes to an image\nso that it becomes a new image after scaling. This opens up new ways for\nattackers to control the prediction or to improve poisoning and backdoor\nattacks. While effective techniques exist to prevent scaling attacks, their\ndetection has not been rigorously studied yet. Consequently, it is currently\nnot possible to reliably spot these attacks in practice.\n  This paper presents the first in-depth systematization and analysis of\ndetection methods for image-scaling attacks. We identify two general detection\nparadigms and derive novel methods from them that are simple in design yet\nsignificantly outperform previous work. We demonstrate the efficacy of these\nmethods in a comprehensive evaluation with all major learning platforms and\nscaling algorithms. First, we show that image-scaling attacks modifying the\nentire scaled image can be reliably detected even under an adaptive adversary.\nSecond, we find that our methods provide strong detection performance even if\nonly minor parts of the image are manipulated. As a result, we can introduce a\nnovel protection layer against image-scaling attacks.",
            "author": [
                "Erwin Quiring",
                "Andreas M\u00fcller",
                "Konrad Rieck"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15085v1",
                "http://arxiv.org/pdf/2310.15085v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15084v1",
            "title": "Quantum Federated Learning With Quantum Networks",
            "updated": "2023-10-23T16:45:29Z",
            "published": "2023-10-23T16:45:29Z",
            "summary": "A major concern of deep learning models is the large amount of data that is\nrequired to build and train them, much of which is reliant on sensitive and\npersonally identifiable information that is vulnerable to access by third\nparties. Ideas of using the quantum internet to address this issue have been\npreviously proposed, which would enable fast and completely secure online\ncommunications. Previous work has yielded a hybrid quantum-classical transfer\nlearning scheme for classical data and communication with a hub-spoke topology.\nWhile quantum communication is secure from eavesdrop attacks and no\nmeasurements from quantum to classical translation, due to no cloning theorem,\nhub-spoke topology is not ideal for quantum communication without quantum\nmemory. Here we seek to improve this model by implementing a decentralized ring\ntopology for the federated learning scheme, where each client is given a\nportion of the entire dataset and only performs training on that set. We also\ndemonstrate the first successful use of quantum weights for quantum federated\nlearning, which allows us to perform our training entirely in quantum.",
            "author": [
                "Tyler Wang",
                "Huan-Hsin Tseng",
                "Shinjae Yoo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15084v1",
                "http://arxiv.org/pdf/2310.15084v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15083v1",
            "title": "Mass uptake during oxidation of metallic alloys: literature data\n  collection, analysis, and FAIR sharing",
            "updated": "2023-10-23T16:44:43Z",
            "published": "2023-10-23T16:44:43Z",
            "summary": "The area-normalized change of mass ($\\Delta$m/A) with time during the\noxidation of metallic alloys is commonly used to assess oxidation resistance.\nAnalyses of such data can also aid in evaluating underlying oxidation\nmechanisms. We performed an exhaustive literature search and digitized\nnormalized mass change vs. time data for 407 alloys. To maximize the impact of\nthese and future mass uptake data, we developed and published an open, online,\ncomputational workflow that fits the data to various models of oxidation\nkinetics, uses Bayesian statistics for model selection, and makes the raw data\nand model parameters available via a queryable database. The tool, Refractory\nOxidation Database (https://nanohub.org/tools/refoxdb/), uses nanoHUB's Sim2Ls\nto make the workflow and data (including metadata) findable, accessible,\ninteroperable, and reusable (FAIR). We find that the models selected by the\noriginal authors do not match the most likely one according to the Bayesian\ninformation criterion (BIC) in 71% of the cases. Further, in 56% of the cases,\nthe published model was not even in the top 3 models according to the BIC.\nThese numbers were obtained assuming an experimental noise of 2.5% of the mass\ngain range, a smaller noise leads to more discrepancies. The RefOxDB tool is\nopen access and researchers can add their own raw data (those to be included in\nfuture publications, as well as negative results) for analysis and to share\ntheir work with the community. Such consistent and systematic analysis of open,\ncommunity generated data can significantly accelerate the development of\nmachine-learning models for oxidation behavior and assist in the understanding\nand improvement of oxidation resistance.",
            "author": [
                "Saswat Mishra",
                "Sharmila Karumuri",
                "Vincent Mika",
                "Collin Scott",
                "Chadwick Choy",
                "Kenneth H. Sandhage",
                "Ilias Bilionis",
                "Michael S. Titus",
                "Alejandro Strachan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15083v1",
                "http://arxiv.org/pdf/2310.15083v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15080v2",
            "title": "Federated Learning of Large Language Models with Parameter-Efficient\n  Prompt Tuning and Adaptive Optimization",
            "updated": "2023-10-29T07:17:45Z",
            "published": "2023-10-23T16:37:59Z",
            "summary": "Federated learning (FL) is a promising paradigm to enable collaborative model\ntraining with decentralized data. However, the training process of Large\nLanguage Models (LLMs) generally incurs the update of significant parameters,\nwhich limits the applicability of FL techniques to tackle the LLMs in real\nscenarios. Prompt tuning can significantly reduce the number of parameters to\nupdate, but it either incurs performance degradation or low training\nefficiency. The straightforward utilization of prompt tuning in the FL often\nraises non-trivial communication costs and dramatically degrades performance.\nIn addition, the decentralized data is generally non-Independent and\nIdentically Distributed (non-IID), which brings client drift problems and thus\npoor performance. This paper proposes a Parameter-efficient prompt Tuning\napproach with Adaptive Optimization, i.e., FedPepTAO, to enable efficient and\neffective FL of LLMs. First, an efficient partial prompt tuning approach is\nproposed to improve performance and efficiency simultaneously. Second, a novel\nadaptive optimization method is developed to address the client drift problems\non both the device and server sides to enhance performance further. Extensive\nexperiments based on 10 datasets demonstrate the superb performance (up to\n60.8\\% in terms of accuracy) and efficiency (up to 97.59\\% in terms of training\ntime) of FedPepTAO compared with 9 baseline approaches. Our code is available\nat https://github.com/llm-eff/FedPepTAO.",
            "author": [
                "Tianshi Che",
                "Ji Liu",
                "Yang Zhou",
                "Jiaxiang Ren",
                "Jiwen Zhou",
                "Victor S. Sheng",
                "Huaiyu Dai",
                "Dejing Dou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15080v2",
                "http://arxiv.org/pdf/2310.15080v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15074v2",
            "title": "MGAS: Multi-Granularity Architecture Search for Effective and Efficient\n  Neural Networks",
            "updated": "2023-10-25T06:50:49Z",
            "published": "2023-10-23T16:32:18Z",
            "summary": "Differentiable architecture search (DAS) revolutionizes neural architecture\nsearch (NAS) with time-efficient automation, transitioning from discrete\ncandidate sampling and evaluation to differentiable super-net optimization and\ndiscretization. However, existing DAS methods either only conduct\ncoarse-grained operation-level search or manually define the remaining ratios\nfor fine-grained kernel-level and weight-level units, which fail to\nsimultaneously optimize model size and model performance. Furthermore, these\nmethods compromise search quality to reduce memory consumption. To tackle these\nissues, we introduce multi-granularity architecture search (MGAS), a unified\nframework which aims to comprehensively and memory-efficiently explore the\nmulti-granularity search space to discover both effective and efficient neural\nnetworks. Specifically, we learn discretization functions specific to each\ngranularity level to adaptively determine the remaining ratios according to the\nevolving architecture. This ensures an optimal balance among units of different\ngranularity levels for different target model sizes. Considering the memory\ndemands, we break down the super-net optimization and discretization into\nmultiple sub-net stages. Nevertheless, the greedy nature of this approach may\nintroduce bias in the early stages. To compensate for the bias, we propose\nprogressive re-evaluation to allow for re-pruning and regrowing of previous\nunits during subsequent stages. Extensive experiments on CIFAR-10, CIFAR-100\nand ImageNet demonstrate that MGAS outperforms other state-of-the-art methods\nin achieving a better trade-off between model performance and model size.",
            "author": [
                "Xiaoyun Liu",
                "Divya Saxena",
                "Jiannong Cao",
                "Yuqing Zhao",
                "Penghui Ruan"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15074v2",
                "http://arxiv.org/pdf/2310.15074v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15066v1",
            "title": "Localizing Active Objects from Egocentric Vision with Symbolic World\n  Knowledge",
            "updated": "2023-10-23T16:14:05Z",
            "published": "2023-10-23T16:14:05Z",
            "summary": "The ability to actively ground task instructions from an egocentric view is\ncrucial for AI agents to accomplish tasks or assist humans virtually. One\nimportant step towards this goal is to localize and track key active objects\nthat undergo major state change as a consequence of human actions/interactions\nto the environment without being told exactly what/where to ground (e.g.,\nlocalizing and tracking the `sponge` in video from the instruction \"Dip the\n`sponge` into the bucket.\"). While existing works approach this problem from a\npure vision perspective, we investigate to which extent the textual modality\n(i.e., task instructions) and their interaction with visual modality can be\nbeneficial. Specifically, we propose to improve phrase grounding models'\nability on localizing the active objects by: (1) learning the role of `objects\nundergoing change` and extracting them accurately from the instructions, (2)\nleveraging pre- and post-conditions of the objects during actions, and (3)\nrecognizing the objects more robustly with descriptional knowledge. We leverage\nlarge language models (LLMs) to extract the aforementioned action-object\nknowledge, and design a per-object aggregation masking technique to effectively\nperform joint inference on object phrases and symbolic knowledge. We evaluate\nour framework on Ego4D and Epic-Kitchens datasets. Extensive experiments\ndemonstrate the effectiveness of our proposed framework, which leads to>54%\nimprovements in all standard metrics on the TREK-150-OPE-Det localization +\ntracking task, >7% improvements in all standard metrics on the TREK-150-OPE\ntracking task, and >3% improvements in average precision (AP) on the Ego4D SCOD\ntask.",
            "author": [
                "Te-Lin Wu",
                "Yu Zhou",
                "Nanyun Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15066v1",
                "http://arxiv.org/pdf/2310.15066v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15065v2",
            "title": "Synergizing Human-AI Agency: A Guide of 23 Heuristics for Service\n  Co-Creation with LLM-Based Agents",
            "updated": "2023-11-29T22:37:21Z",
            "published": "2023-10-23T16:11:48Z",
            "summary": "This empirical study serves as a primer for interested service providers to\ndetermine if and how Large Language Models (LLMs) technology will be integrated\nfor their practitioners and the broader community. We investigate the mutual\nlearning journey of non-AI experts and AI through CoAGent, a service\nco-creation tool with LLM-based agents. Engaging in a three-stage participatory\ndesign processes, we work with with 23 domain experts from public libraries\nacross the U.S., uncovering their fundamental challenges of integrating AI into\nhuman workflows. Our findings provide 23 actionable \"heuristics for service\nco-creation with AI\", highlighting the nuanced shared responsibilities between\nhumans and AI. We further exemplar 9 foundational agency aspects for AI,\nemphasizing essentials like ownership, fair treatment, and freedom of\nexpression. Our innovative approach enriches the participatory design model by\nincorporating AI as crucial stakeholders and utilizing AI-AI interaction to\nidentify blind spots. Collectively, these insights pave the way for synergistic\nand ethical human-AI co-creation in service contexts, preparing for workforce\necosystems where AI coexists.",
            "author": [
                "Qingxiao Zheng",
                "Zhongwei Xu",
                "Abhinav Choudhry",
                "Yuting Chen",
                "Yongming Li",
                "Yun Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15065v2",
                "http://arxiv.org/pdf/2310.15065v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15061v1",
            "title": "The BLA Benchmark: Investigating Basic Language Abilities of Pre-Trained\n  Multimodal Models",
            "updated": "2023-10-23T16:05:13Z",
            "published": "2023-10-23T16:05:13Z",
            "summary": "Despite the impressive performance achieved by pre-trained\nlanguage-and-vision models in downstream tasks, it remains an open question\nwhether this reflects a proper understanding of image-text interaction. In this\nwork, we explore to what extent they handle basic linguistic constructions --\nactive-passive voice, coordination, and relative clauses -- that even preschool\nchildren can typically master. We present BLA, a novel, automatically\nconstructed benchmark to evaluate multimodal models on these Basic Language\nAbilities. We show that different types of Transformer-based systems, such as\nCLIP, ViLBERT, and BLIP2, generally struggle with BLA in a zero-shot setting,\nin line with previous findings. Our experiments, in particular, show that most\nof the tested models only marginally benefit when fine-tuned or prompted with\nconstruction-specific samples. Yet, the generative BLIP2 shows promising\ntrends, especially in an in-context learning setting. This opens the door to\nusing BLA not only as an evaluation benchmark but also to improve models' basic\nlanguage abilities.",
            "author": [
                "Xinyi Chen",
                "Raquel Fern\u00e1ndez",
                "Sandro Pezzelle"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15061v1",
                "http://arxiv.org/pdf/2310.15061v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15059v1",
            "title": "Robot Skill Generalization via Keypoint Integrated Soft Actor-Critic\n  Gaussian Mixture Models",
            "updated": "2023-10-23T16:03:23Z",
            "published": "2023-10-23T16:03:23Z",
            "summary": "A long-standing challenge for a robotic manipulation system operating in\nreal-world scenarios is adapting and generalizing its acquired motor skills to\nunseen environments. We tackle this challenge employing hybrid skill models\nthat integrate imitation and reinforcement paradigms, to explore how the\nlearning and adaptation of a skill, along with its core grounding in the scene\nthrough a learned keypoint, can facilitate such generalization. To that end, we\ndevelop Keypoint Integrated Soft Actor-Critic Gaussian Mixture Models (KIS-GMM)\napproach that learns to predict the reference of a dynamical system within the\nscene as a 3D keypoint, leveraging visual observations obtained by the robot's\nphysical interactions during skill learning. Through conducting comprehensive\nevaluations in both simulated and real-world environments, we show that our\nmethod enables a robot to gain a significant zero-shot generalization to novel\nenvironments and to refine skills in the target environments faster than\nlearning from scratch. Importantly, this is achieved without the need for new\nground truth data. Moreover, our method effectively copes with scene\ndisplacements.",
            "author": [
                "Iman Nematollahi",
                "Kirill Yankov",
                "Wolfram Burgard",
                "Tim Welschehold"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15059v1",
                "http://arxiv.org/pdf/2310.15059v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15057v2",
            "title": "Shareable Driving Style Learning and Analysis with a Hierarchical Latent\n  Model",
            "updated": "2023-10-24T06:46:13Z",
            "published": "2023-10-23T16:01:54Z",
            "summary": "Driving style is usually used to characterize driving behavior for a driver\nor a group of drivers. However, it remains unclear how one individual's driving\nstyle shares certain common grounds with other drivers. Our insight is that\ndriving behavior is a sequence of responses to the weighted mixture of latent\ndriving styles that are shareable within and between individuals. To this end,\nthis paper develops a hierarchical latent model to learn the relationship\nbetween driving behavior and driving styles. We first propose a fragment-based\napproach to represent complex sequential driving behavior, allowing for\nsufficiently representing driving behavior in a low-dimension feature space.\nThen, we provide an analytical formulation for the interaction of driving\nbehavior and shareable driving style with a hierarchical latent model by\nintroducing the mechanism of Dirichlet allocation. Our developed model is\nfinally validated and verified with 100 drivers in naturalistic driving\nsettings with urban and highways. Experimental results reveal that individuals\nshare driving styles within and between them. We also analyzed the influence of\npersonalities (e.g., age, gender, and driving experience) on driving styles and\nfound that a naturally aggressive driver would not always keep driving\naggressively (i.e., could behave calmly sometimes) but with a higher proportion\nof aggressiveness than other types of drivers.",
            "author": [
                "Chaopeng Zhang",
                "Wenshuo Wang",
                "Zhaokun Chen",
                "Jian Zhang",
                "Lijun Sun",
                "Junqiang Xi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15057v2",
                "http://arxiv.org/pdf/2310.15057v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15054v1",
            "title": "Coordinated Replay Sample Selection for Continual Federated Learning",
            "updated": "2023-10-23T15:56:39Z",
            "published": "2023-10-23T15:56:39Z",
            "summary": "Continual Federated Learning (CFL) combines Federated Learning (FL), the\ndecentralized learning of a central model on a number of client devices that\nmay not communicate their data, and Continual Learning (CL), the learning of a\nmodel from a continual stream of data without keeping the entire history. In\nCL, the main challenge is \\textit{forgetting} what was learned from past data.\nWhile replay-based algorithms that keep a small pool of past training data are\neffective to reduce forgetting, only simple replay sample selection strategies\nhave been applied to CFL in prior work, and no previous work has explored\ncoordination among clients for better sample selection. To bridge this gap, we\nadapt a replay sample selection objective based on loss gradient diversity to\nCFL and propose a new relaxation-based selection of samples to optimize the\nobjective. Next, we propose a practical algorithm to coordinate gradient-based\nreplay sample selection across clients without communicating private data. We\nbenchmark our coordinated and uncoordinated replay sample selection algorithms\nagainst random sampling-based baselines with language models trained on a large\nscale de-identified real-world text dataset. We show that gradient-based sample\nselection methods both boost performance and reduce forgetting compared to\nrandom sampling methods, with our coordination method showing gains early in\nthe low replay size regime (when the budget for storing past data is small).",
            "author": [
                "Jack Good",
                "Jimit Majmudar",
                "Christophe Dupuy",
                "Jixuan Wang",
                "Charith Peris",
                "Clement Chung",
                "Richard Zemel",
                "Rahul Gupta"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15054v1",
                "http://arxiv.org/pdf/2310.15054v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15051v1",
            "title": "TeleQnA: A Benchmark Dataset to Assess Large Language Models\n  Telecommunications Knowledge",
            "updated": "2023-10-23T15:55:15Z",
            "published": "2023-10-23T15:55:15Z",
            "summary": "We introduce TeleQnA, the first benchmark dataset designed to evaluate the\nknowledge of Large Language Models (LLMs) in telecommunications. Comprising\n10,000 questions and answers, this dataset draws from diverse sources,\nincluding standards and research articles. This paper outlines the automated\nquestion generation framework responsible for creating this dataset, along with\nhow human input was integrated at various stages to ensure the quality of the\nquestions. Afterwards, using the provided dataset, an evaluation is conducted\nto assess the capabilities of LLMs, including GPT-3.5 and GPT-4. The results\nhighlight that these models struggle with complex standards related questions\nbut exhibit proficiency in addressing general telecom-related inquiries.\nAdditionally, our results showcase how incorporating telecom knowledge context\nsignificantly enhances their performance, thus shedding light on the need for a\nspecialized telecom foundation model. Finally, the dataset is shared with\nactive telecom professionals, whose performance is subsequently benchmarked\nagainst that of the LLMs. The findings illustrate that LLMs can rival the\nperformance of active professionals in telecom knowledge, thanks to their\ncapacity to process vast amounts of information, underscoring the potential of\nLLMs within this domain. The dataset has been made publicly accessible on\nGitHub.",
            "author": [
                "Ali Maatouk",
                "Fadhel Ayed",
                "Nicola Piovesan",
                "Antonio De Domenico",
                "Merouane Debbah",
                "Zhi-Quan Luo"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15051v1",
                "http://arxiv.org/pdf/2310.15051v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.AI",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15047v2",
            "title": "Meta- (out-of-context) learning in neural networks",
            "updated": "2023-10-24T14:22:28Z",
            "published": "2023-10-23T15:50:08Z",
            "summary": "Brown et al. (2020) famously introduced the phenomenon of in-context learning\nin large language models (LLMs). We establish the existence of a phenomenon we\ncall meta-out-of-context learning (meta-OCL) via carefully designed synthetic\nexperiments with LLMs. Our results suggest that meta-OCL leads LLMs to more\nreadily \"internalize\" the semantic content of text that is, or appears to be,\nbroadly useful (such as true statements, or text from authoritative sources)\nand use it in appropriate circumstances. We further demonstrate meta-OCL in a\nsynthetic computer vision setting, and propose two hypotheses for the emergence\nof meta-OCL: one relying on the way models store knowledge in their parameters,\nand another suggesting that the implicit gradient alignment bias of\ngradient-descent-based optimizers may be responsible. Finally, we reflect on\nwhat our results might imply about capabilities of future AI systems, and\ndiscuss potential risks. Our code can be found at\nhttps://github.com/krasheninnikov/internalization.",
            "author": [
                "Dmitrii Krasheninnikov",
                "Egor Krasheninnikov",
                "Bruno Mlodozeniec",
                "David Krueger"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15047v2",
                "http://arxiv.org/pdf/2310.15047v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15043v1",
            "title": "CalibrationPhys: Self-supervised Video-based Heart and Respiratory Rate\n  Measurements by Calibrating Between Multiple Cameras",
            "updated": "2023-10-23T15:46:39Z",
            "published": "2023-10-23T15:46:39Z",
            "summary": "Video-based heart and respiratory rate measurements using facial videos are\nmore useful and user-friendly than traditional contact-based sensors. However,\nmost of the current deep learning approaches require ground-truth pulse and\nrespiratory waves for model training, which are expensive to collect. In this\npaper, we propose CalibrationPhys, a self-supervised video-based heart and\nrespiratory rate measurement method that calibrates between multiple cameras.\nCalibrationPhys trains deep learning models without supervised labels by using\nfacial videos captured simultaneously by multiple cameras. Contrastive learning\nis performed so that the pulse and respiratory waves predicted from the\nsynchronized videos using multiple cameras are positive and those from\ndifferent videos are negative. CalibrationPhys also improves the robustness of\nthe models by means of a data augmentation technique and successfully leverages\na pre-trained model for a particular camera. Experimental results utilizing two\ndatasets demonstrate that CalibrationPhys outperforms state-of-the-art heart\nand respiratory rate measurement methods. Since we optimize camera-specific\nmodels using only videos from multiple cameras, our approach makes it easy to\nuse arbitrary cameras for heart and respiratory rate measurements.",
            "author": [
                "Yusuke Akamatsu",
                "Terumi Umematsu",
                "Hitoshi Imaoka"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15043v1",
                "http://arxiv.org/pdf/2310.15043v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.19819v1",
            "title": "Machine Learning and Knowledge: Why Robustness Matters",
            "updated": "2023-10-23T15:45:27Z",
            "published": "2023-10-23T15:45:27Z",
            "summary": "Trusting machine learning algorithms requires having confidence in their\noutputs. Confidence is typically interpreted in terms of model reliability,\nwhere a model is reliable if it produces a high proportion of correct outputs.\nHowever, model reliability does not address concerns about the robustness of\nmachine learning models, such as models relying on the wrong features or\nvariations in performance based on context. I argue that the epistemic\ndimension of trust can instead be understood through the concept of knowledge,\nwhere the trustworthiness of an algorithm depends on whether its users are in\nthe position to know that its outputs are correct. Knowledge requires beliefs\nto be formed for the right reasons and to be robust to error, so machine\nlearning algorithms can only provide knowledge if they work well across\ncounterfactual scenarios and if they make decisions based on the right\nfeatures. This, I argue, can explain why we should care about model properties\nlike interpretability, causal shortcut independence, and distribution shift\nrobustness even if such properties are not required for model reliability.",
            "author": [
                "Jonathan Vandenburgh"
            ],
            "link": [
                "http://arxiv.org/abs/2310.19819v1",
                "http://arxiv.org/pdf/2310.19819v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15041v1",
            "title": "Manipulation Mask Generator: High-Quality Image Manipulation Mask\n  Generation Method Based on Modified Total Variation Noise Reduction",
            "updated": "2023-10-23T15:40:00Z",
            "published": "2023-10-23T15:40:00Z",
            "summary": "In artificial intelligence, any model that wants to achieve a good result is\ninseparable from a large number of high-quality data. It is especially true in\nthe field of tamper detection. This paper proposes a modified total variation\nnoise reduction method to acquire high-quality tampered images. We\nautomatically crawl original and tampered images from the Baidu PS Bar. Baidu\nPS Bar is a website where net friends post countless tampered images.\nSubtracting the original image with the tampered image can highlight the\ntampered area. However, there is also substantial noise on the final print, so\nthese images can't be directly used in the deep learning model. Our modified\ntotal variation noise reduction method is aimed at solving this problem.\nBecause a lot of text is slender, it is easy to lose text information after the\nopening and closing operation. We use MSER (Maximally Stable Extremal Regions)\nand NMS (Non-maximum Suppression) technology to extract text information. And\nthen use the modified total variation noise reduction technology to process the\nsubtracted image. Finally, we can obtain an image with little noise by adding\nthe image and text information. And the idea also largely retains the text\ninformation. Datasets generated in this way can be used in deep learning\nmodels, and they will help the model achieve better results.",
            "author": [
                "Xinyu Yang",
                "Jizhe Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15041v1",
                "http://arxiv.org/pdf/2310.15041v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15037v1",
            "title": "Engineered dissipation to mitigate barren plateaus",
            "updated": "2023-10-23T15:36:00Z",
            "published": "2023-10-23T15:36:00Z",
            "summary": "Variational quantum algorithms represent a powerful approach for solving\noptimization problems on noisy quantum computers, with a broad spectrum of\npotential applications ranging from chemistry to machine learning. However,\ntheir performances in practical implementations crucially depend on the\neffectiveness of quantum circuit training, which can be severely limited by\nphenomena such as barren plateaus. While, in general, dissipation is\ndetrimental for quantum algorithms, and noise itself can actually induce barren\nplateaus, here we describe how the inclusion of properly engineered Markovian\nlosses after each unitary quantum circuit layer can restore the trainability of\nquantum models. We identify the required form of the dissipation processes and\nestablish that their optimization is efficient. We benchmark our proposal in\nboth a synthetic and a practical quantum chemistry example, demonstrating its\neffectiveness and potential impact across different domains.",
            "author": [
                "Antonio Sannia",
                "Francesco Tacchino",
                "Ivano Tavernelli",
                "Gian Luca Giorgi",
                "Roberta Zambrini"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15037v1",
                "http://arxiv.org/pdf/2310.15037v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15027v1",
            "title": "Deep Autoencoder-based Z-Interference Channels with Perfect and\n  Imperfect CSI",
            "updated": "2023-10-23T15:23:42Z",
            "published": "2023-10-23T15:23:42Z",
            "summary": "A deep autoencoder (DAE)-based structure for endto-end communication over the\ntwo-user Z-interference channel (ZIC) with finite-alphabet inputs is designed\nin this paper. The proposed structure jointly optimizes the two encoder/decoder\npairs and generates interference-aware constellations that dynamically adapt\ntheir shape based on interference intensity to minimize the bit error rate\n(BER). An in-phase/quadrature-phase (I/Q) power allocation layer is introduced\nin the DAE to guarantee an average power constraint and enable the architecture\nto generate constellations with nonuniform shapes. This brings further gain\ncompared to standard uniform constellations such as quadrature amplitude\nmodulation. The proposed structure is then extended to work with imperfect\nchannel state information (CSI). The CSI imperfection due to both the\nestimation and quantization errors are examined. The performance of the DAEZIC\nis compared with two baseline methods, i.e., standard and rotated\nconstellations. The proposed structure significantly enhances the performance\nof the ZIC both for the perfect and imperfect CSI. Simulation results show that\nthe improvement is achieved in all interference regimes (weak, moderate, and\nstrong) and consistently increases with the signal-to-noise ratio (SNR). For\nexample, more than an order of magnitude BER reduction is obtained with respect\nto the most competitive conventional method at weak interference when SNR>15dB\nand two bits per symbol are transmitted. The improvements reach about two\norders of magnitude when quantization error exists, indicating that the DAE-ZIC\nis more robust to the interference compared to the conventional methods.",
            "author": [
                "Xinliang Zhang",
                "Mojtaba Vaezi"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15027v1",
                "http://arxiv.org/pdf/2310.15027v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.AI",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15026v1",
            "title": "Fast 2D Bicephalous Convolutional Autoencoder for Compressing 3D Time\n  Projection Chamber Data",
            "updated": "2023-10-23T15:23:32Z",
            "published": "2023-10-23T15:23:32Z",
            "summary": "High-energy large-scale particle colliders produce data at high speed in the\norder of 1 terabytes per second in nuclear physics and petabytes per second in\nhigh-energy physics. Developing real-time data compression algorithms to reduce\nsuch data at high throughput to fit permanent storage has drawn increasing\nattention. Specifically, at the newly constructed sPHENIX experiment at the\nRelativistic Heavy Ion Collider (RHIC), a time projection chamber is used as\nthe main tracking detector, which records particle trajectories in a volume of\na three-dimensional (3D) cylinder. The resulting data are usually very sparse\nwith occupancy around 10.8%. Such sparsity presents a challenge to conventional\nlearning-free lossy compression algorithms, such as SZ, ZFP, and MGARD. The 3D\nconvolutional neural network (CNN)-based approach, Bicephalous Convolutional\nAutoencoder (BCAE), outperforms traditional methods both in compression rate\nand reconstruction accuracy. BCAE can also utilize the computation power of\ngraphical processing units suitable for deployment in a modern heterogeneous\nhigh-performance computing environment. This work introduces two BCAE variants:\nBCAE++ and BCAE-2D. BCAE++ achieves a 15% better compression ratio and a 77%\nbetter reconstruction accuracy measured in mean absolute error compared with\nBCAE. BCAE-2D treats the radial direction as the channel dimension of an image,\nresulting in a 3x speedup in compression throughput. In addition, we\ndemonstrate an unbalanced autoencoder with a larger decoder can improve\nreconstruction accuracy without significantly sacrificing throughput. Lastly,\nwe observe both the BCAE++ and BCAE-2D can benefit more from using\nhalf-precision mode in throughput (76-79% increase) without loss in\nreconstruction accuracy. The source code and links to data and pretrained\nmodels can be found at https://github.com/BNL-DAQ-LDRD/NeuralCompression_v2.",
            "author": [
                "Yi Huang",
                "Yihui Ren",
                "Shinjae Yoo",
                "Jin Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15026v1",
                "http://arxiv.org/pdf/2310.15026v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "hep-ex",
                "nucl-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15024v1",
            "title": "From Proprietary to High-Level Trigger-Action Programming Rules: A\n  Natural Language Processing Approach",
            "updated": "2023-10-23T15:23:25Z",
            "published": "2023-10-23T15:23:25Z",
            "summary": "With the rise of popular task automation or IoT platforms such as 'If This\nThen That (IFTTT)', users can define rules to enable interactions between smart\ndevices in their environment and thereby improve their daily lives. However,\nthe rules authored via these platforms are usually tied to the platforms and\nsometimes even to the specific devices for which they have been defined.\nTherefore, when a user wishes to move to a different environment controlled by\na different platform and/or devices, they need to recreate their rules for the\nnew environment. The rise in the number of smart devices further adds to the\ncomplexity of rule authoring since users will have to navigate an ever-changing\nlandscape of IoT devices. In order to address this problem, we need\nhuman-computer interaction that works across the boundaries of specific IoT\nplatforms and devices. A step towards this human-computer interaction across\nplatforms and devices is the introduction of a high-level semantic model for\nend-user IoT development, enabling users to create rules at a higher level of\nabstraction. However, many users who already got used to the rule\nrepresentation in their favourite tool might be unwilling to learn and adapt to\na new representation. We present a method for translating proprietary rules to\na high-level semantic model by using natural language processing techniques.\nOur translation enables users to work with their familiar rule representation\nlanguage and tool, and at the same time apply their rules across different IoT\nplatforms and devices.",
            "author": [
                "Ekene Attoh",
                "Beat Signer"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15024v1",
                "http://arxiv.org/pdf/2310.15024v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "H.5.m"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15023v1",
            "title": "SONIC: Sonar Image Correspondence using Pose Supervised Learning for\n  Imaging Sonars",
            "updated": "2023-10-23T15:21:46Z",
            "published": "2023-10-23T15:21:46Z",
            "summary": "In this paper, we address the challenging problem of data association for\nunderwater SLAM through a novel method for sonar image correspondence using\nlearned features. We introduce SONIC (SONar Image Correspondence), a\npose-supervised network designed to yield robust feature correspondence capable\nof withstanding viewpoint variations. The inherent complexity of the underwater\nenvironment stems from the dynamic and frequently limited visibility\nconditions, restricting vision to a few meters of often featureless expanses.\nThis makes camera-based systems suboptimal in most open water application\nscenarios. Consequently, multibeam imaging sonars emerge as the preferred\nchoice for perception sensors. However, they too are not without their\nlimitations. While imaging sonars offer superior long-range visibility compared\nto cameras, their measurements can appear different from varying viewpoints.\nThis inherent variability presents formidable challenges in data association,\nparticularly for feature-based methods. Our method demonstrates significantly\nbetter performance in generating correspondences for sonar images which will\npave the way for more accurate loop closure constraints and sonar-based place\nrecognition. Code as well as simulated and real-world datasets will be made\npublic to facilitate further development in the field.",
            "author": [
                "Samiran Gode",
                "Akshay Hinduja",
                "Michael Kaess"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15023v1",
                "http://arxiv.org/pdf/2310.15023v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15021v1",
            "title": "Efficient Data Learning for Open Information Extraction with Pre-trained\n  Language Models",
            "updated": "2023-10-23T15:19:24Z",
            "published": "2023-10-23T15:19:24Z",
            "summary": "Open Information Extraction (OpenIE) is a fundamental yet challenging task in\nNatural Language Processing, which involves extracting all triples (subject,\npredicate, object) from a given sentence. While labeling-based methods have\ntheir merits, generation-based techniques offer unique advantages, such as the\nability to generate tokens not present in the original sentence. However, these\ngeneration-based methods often require a significant amount of training data to\nlearn the task form of OpenIE and substantial training time to overcome slow\nmodel convergence due to the order penalty. In this paper, we introduce a novel\nframework, OK-IE, that ingeniously transforms the task form of OpenIE into the\npre-training task form of the T5 model, thereby reducing the need for extensive\ntraining data. Furthermore, we introduce an innovative concept of Anchor to\ncontrol the sequence of model outputs, effectively eliminating the impact of\norder penalty on model convergence and significantly reducing training time.\nExperimental results indicate that, compared to previous SOTA methods, OK-IE\nrequires only 1/100 of the training data (900 instances) and 1/120 of the\ntraining time (3 minutes) to achieve comparable results.",
            "author": [
                "Zhiyuan Fan",
                "Shizhu He"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15021v1",
                "http://arxiv.org/pdf/2310.15021v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2310.15020v2",
            "title": "Invariance is Key to Generalization: Examining the Role of\n  Representation in Sim-to-Real Transfer for Visual Navigation",
            "updated": "2023-12-04T03:48:06Z",
            "published": "2023-10-23T15:15:19Z",
            "summary": "The data-driven approach to robot control has been gathering pace rapidly,\nyet generalization to unseen task domains remains a critical challenge. We\nargue that the key to generalization is representations that are (i) rich\nenough to capture all task-relevant information and (ii) invariant to\nsuperfluous variability between the training and the test domains. We\nexperimentally study such a representation -- containing both depth and\nsemantic information -- for visual navigation and show that it enables a\ncontrol policy trained entirely in simulated indoor scenes to generalize to\ndiverse real-world environments, both indoors and outdoors. Further, we show\nthat our representation reduces the A-distance between the training and test\ndomains, improving the generalization error bound as a result. Our proposed\napproach is scalable: the learned policy improves continuously, as the\nfoundation models that it exploits absorb more diverse data during\npre-training.",
            "author": [
                "Bo Ai",
                "Zhanxin Wu",
                "David Hsu"
            ],
            "link": [
                "http://arxiv.org/abs/2310.15020v2",
                "http://arxiv.org/pdf/2310.15020v2"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.CV",
                "cs.LG",
                "I.2.9; I.2.6; I.2.10"
            ]
        }
    }
]