[
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a5432190c514feb78873af1a696f965218a5445c",
            "@type": "ScholarlyArticle",
            "paperId": "a5432190c514feb78873af1a696f965218a5445c",
            "corpusId": 4161081,
            "url": "https://www.semanticscholar.org/paper/a5432190c514feb78873af1a696f965218a5445c",
            "title": "Bicycle-pedal model for the first step in the vision process",
            "venue": "Nature",
            "publicationVenue": {
                "id": "urn:research:6c24a0a0-b07d-4d7b-a19b-fd09a3ed453a",
                "name": "Nature",
                "alternate_names": null,
                "issn": "0028-0836",
                "url": "https://www.nature.com/"
            },
            "year": 1976,
            "externalIds": {
                "MAG": "2076961986",
                "DOI": "10.1038/260679A0",
                "CorpusId": 4161081,
                "PubMed": "1264239"
            },
            "abstract": null,
            "referenceCount": 24,
            "citationCount": 405,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Chemistry",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Chemistry",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Chemistry",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1976-04-22",
            "journal": {
                "name": "Nature",
                "volume": "260"
            },
            "citationStyles": {
                "bibtex": "@Article{Warshel1976BicyclepedalMF,\n author = {A. Warshel},\n booktitle = {Nature},\n journal = {Nature},\n pages = {679-683},\n title = {Bicycle-pedal model for the first step in the vision process},\n volume = {260},\n year = {1976}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4834ef7df6b94ad2d5ccf5c4714be1f98c54b69e",
            "@type": "ScholarlyArticle",
            "paperId": "4834ef7df6b94ad2d5ccf5c4714be1f98c54b69e",
            "corpusId": 15369615,
            "url": "https://www.semanticscholar.org/paper/4834ef7df6b94ad2d5ccf5c4714be1f98c54b69e",
            "title": "Gaussian-based edge-detection methods - a survey",
            "venue": "IEEE Trans. Syst. Man Cybern. Part C",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2002,
            "externalIds": {
                "MAG": "2116216752",
                "DBLP": "journals/tsmc/Basu02",
                "DOI": "10.1109/TSMCC.2002.804448",
                "CorpusId": 15369615
            },
            "abstract": "The Gaussian filter has been used extensively in image processing and computer vision for many years. We discuss the various features of this operator that make it the filter of choice in the area of edge detection. Despite these desirable features of the Gaussian filter, edge detection algorithms which use it suffer from many problems. We review several linear and nonlinear Gaussian-based edge detection methods.",
            "referenceCount": 44,
            "citationCount": 526,
            "influentialCitationCount": 29,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2002-08-01",
            "journal": {
                "name": "IEEE Trans. Syst. Man Cybern. Part C",
                "volume": "32"
            },
            "citationStyles": {
                "bibtex": "@Article{Basu2002GaussianbasedEM,\n author = {M. Basu},\n booktitle = {IEEE Trans. Syst. Man Cybern. Part C},\n journal = {IEEE Trans. Syst. Man Cybern. Part C},\n pages = {252-260},\n title = {Gaussian-based edge-detection methods - a survey},\n volume = {32},\n year = {2002}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6bae966a944a9938772d64b3082a5b199ce2ed10",
            "@type": "ScholarlyArticle",
            "paperId": "6bae966a944a9938772d64b3082a5b199ce2ed10",
            "corpusId": 7905699,
            "url": "https://www.semanticscholar.org/paper/6bae966a944a9938772d64b3082a5b199ce2ed10",
            "title": "Machine vision: automated visual inspection and robot vision",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1991,
            "externalIds": {
                "MAG": "1671651577",
                "CorpusId": 7905699
            },
            "abstract": "An introduction to computer vision illumination and fixturing sensors image acquisition and representation fundamentals of digital image processing image analysis the segmentation problem 2-D shape description and recognition 3-D object representations robot programming and robot vision bin picking trends and aspirations.",
            "referenceCount": 0,
            "citationCount": 258,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1991-08-01",
            "journal": {
                "name": "",
                "volume": "92"
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Vernon1991MachineVA,\n author = {D. Vernon},\n pages = {40499},\n title = {Machine vision: automated visual inspection and robot vision},\n volume = {92},\n year = {1991}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cc5d91b20c8769d1f040ff9a5166f76cc19d2d55",
            "@type": "ScholarlyArticle",
            "paperId": "cc5d91b20c8769d1f040ff9a5166f76cc19d2d55",
            "corpusId": 11863056,
            "url": "https://www.semanticscholar.org/paper/cc5d91b20c8769d1f040ff9a5166f76cc19d2d55",
            "title": "Self-Supervised Learning of Visual Features through Embedding Images into Text Topic Spaces",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/cvpr/Gomez-BigordaPR17",
                "ArXiv": "1705.08631",
                "MAG": "2619749592",
                "DOI": "10.1109/CVPR.2017.218",
                "CorpusId": 11863056
            },
            "abstract": "End-to-end training from scratch of current deep architectures for new computer vision problems would require Imagenet-scale datasets, and this is not always possible. In this paper we present a method that is able to take advantage of freely available multi-modal content to train computer vision algorithms without human supervision. We put forward the idea of performing self-supervised learning of visual features by mining a large scale corpus of multi-modal (text and image) documents. We show that discriminative visual features can be learnt efficiently by training a CNN to predict the semantic context in which a particular image is more probable to appear as an illustration. For this we leverage the hidden semantic structures discovered in the text corpus with a well-known topic modeling technique. Our experiments demonstrate state of the art performance in image classification, object detection, and multi-modal retrieval compared to recent self-supervised or natural-supervised approaches.",
            "referenceCount": 46,
            "citationCount": 104,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1705.08631",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-05-24",
            "journal": {
                "name": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bigorda2017SelfSupervisedLO,\n author = {L. G. I. Bigorda and Yash J. Patel and Mar\u00e7al Rusi\u00f1ol and Dimosthenis Karatzas and C. V. Jawahar},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {2017-2026},\n title = {Self-Supervised Learning of Visual Features through Embedding Images into Text Topic Spaces},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:844a1203c02b4083bcfa84db24815e62cd6fda51",
            "@type": "ScholarlyArticle",
            "paperId": "844a1203c02b4083bcfa84db24815e62cd6fda51",
            "corpusId": 143084110,
            "url": "https://www.semanticscholar.org/paper/844a1203c02b4083bcfa84db24815e62cd6fda51",
            "title": "Neural Networks and Natural Intelligence",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1988,
            "externalIds": {
                "MAG": "1943665722",
                "DOI": "10.7551/mitpress/4934.001.0001",
                "CorpusId": 143084110
            },
            "abstract": "From the Publisher: \nStephen Grossberg and his colleagues at Boston University's Center for Adaptive Systems are producing some of the most exciting research in the neural network approach to making computers \"think.\" Packed with real-time computer simulations and rigorous demonstrations of these phenomena, this book includes results on vision, speech, cognitive information processing; adaptive pattern recognition, adaptive robotics, conditioning and attention, cognitive-emotional interactions, and decision making under risk.",
            "referenceCount": 0,
            "citationCount": 680,
            "influentialCitationCount": 28,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1988-04-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Grossberg1988NeuralNA,\n author = {S. Grossberg},\n title = {Neural Networks and Natural Intelligence},\n year = {1988}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0753c5ea9e5c84d986946c67953bfea5a3ca1869",
            "@type": "ScholarlyArticle",
            "paperId": "0753c5ea9e5c84d986946c67953bfea5a3ca1869",
            "corpusId": 58153740,
            "url": "https://www.semanticscholar.org/paper/0753c5ea9e5c84d986946c67953bfea5a3ca1869",
            "title": "Kalman filter for vision tracking",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "MAG": "9513853",
                "DOI": "10.17169/REFUBIUM-22852",
                "CorpusId": 58153740
            },
            "abstract": "The Kalman filter has been used successfully in different prediction applications or state determination of a system. One important field in computer vision is the object tracking. Different movement conditions and occlusions can hinder the vision tracking of an object. In this report we present the use of the Kalman filter in the vision tracking. We consider the capacity of the Kalman filter to allow small occlusions and also the use of the extended Kalman filter (EKF) to model complex movements of objects.",
            "referenceCount": 5,
            "citationCount": 173,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Cuevas2005KalmanFF,\n author = {Erik Cuevas and D. Zald\u00edvar and R. Rojas},\n title = {Kalman filter for vision tracking},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cb329c8c1acc957655baf8daf5a3410ba7e33ba0",
            "@type": "ScholarlyArticle",
            "paperId": "cb329c8c1acc957655baf8daf5a3410ba7e33ba0",
            "corpusId": 2524500,
            "url": "https://www.semanticscholar.org/paper/cb329c8c1acc957655baf8daf5a3410ba7e33ba0",
            "title": "Face recognition",
            "venue": "Current Opinion in Neurobiology",
            "publicationVenue": {
                "id": "urn:research:d0db851a-b0a0-41e2-bef3-3861d0389a5b",
                "name": "Current Opinion in Neurobiology",
                "alternate_names": [
                    "Curr Opin Neurobiol"
                ],
                "issn": "0959-4388",
                "url": "http://www.current-opinion.com/journals/current-opinion-in-neurobiology/"
            },
            "year": 1992,
            "externalIds": {
                "MAG": "2955255970",
                "DBLP": "reference/mm/TsalakanidouMS06",
                "DOI": "10.1007/0-387-30038-4_75",
                "CorpusId": 2524500
            },
            "abstract": null,
            "referenceCount": 30,
            "citationCount": 589,
            "influentialCitationCount": 44,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1992-04-30",
            "journal": {
                "name": "Current Opinion in Neurobiology",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Tsalakanidou1992FaceR,\n author = {F. Tsalakanidou and S. Malassiotis and M. Strintzis},\n booktitle = {Current Opinion in Neurobiology},\n journal = {Current Opinion in Neurobiology},\n pages = {156-161},\n title = {Face recognition},\n volume = {2},\n year = {1992}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ea6d7923148a65372a539e686ec813d05233d5a8",
            "@type": "ScholarlyArticle",
            "paperId": "ea6d7923148a65372a539e686ec813d05233d5a8",
            "corpusId": 28403879,
            "url": "https://www.semanticscholar.org/paper/ea6d7923148a65372a539e686ec813d05233d5a8",
            "title": "Computer-aided mammographic screening for spiculated lesions.",
            "venue": "Radiology",
            "publicationVenue": {
                "id": "urn:research:357207a3-a4af-4091-822c-75ef52d02fb5",
                "name": "Radiology",
                "alternate_names": null,
                "issn": "0033-8419",
                "url": "http://radiology.rsna.org/"
            },
            "year": 1994,
            "externalIds": {
                "MAG": "2014408515",
                "DOI": "10.1148/RADIOLOGY.191.2.8153302",
                "CorpusId": 28403879,
                "PubMed": "8153302"
            },
            "abstract": "PURPOSE\nTo study the use of a computer vision method as a second reader for the detection of spiculated lesions on screening mammograms.\n\n\nMATERIALS AND METHODS\nAn algorithmic computer process for the detection of spiculated lesions on digitized screen-film mammograms was applied to 85 four-view clinical cases: 36 cases with cancer proved by means of biopsy and 49 cases with negative findings at examination and follow-up. The computer detections were printed as film with added outlines that indicated the suspected cancers. Four radiologists screened the 85 cases twice, once without and once with the computer reports as ancillary films.\n\n\nRESULTS\nThe algorithm alone achieved 100% sensitivity, with a specificity of 82%. The computer reports increased the average radiologist sensitivity by 9.7% (P = .005), moving from 80.6% to 90.3%, with no decrease in average specificity.\n\n\nCONCLUSION\nThe study demonstrated that computer analysis of mammograms can provide a substantial and statistically significant increase in radiologist screening efficacy.",
            "referenceCount": 0,
            "citationCount": 345,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1994-05-01",
            "journal": {
                "name": "Radiology",
                "volume": "191 2"
            },
            "citationStyles": {
                "bibtex": "@Article{Kegelmeyer1994ComputeraidedMS,\n author = {W. Kegelmeyer and J. M. Pruneda and P. Bourland and A. Hillis and M. Riggs and M. Nipper},\n booktitle = {Radiology},\n journal = {Radiology},\n pages = {\n          331-7\n        },\n title = {Computer-aided mammographic screening for spiculated lesions.},\n volume = {191 2},\n year = {1994}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b2544c93606e804c710e3f90f40407bd18b5f473",
            "@type": "ScholarlyArticle",
            "paperId": "b2544c93606e804c710e3f90f40407bd18b5f473",
            "corpusId": 9690772,
            "url": "https://www.semanticscholar.org/paper/b2544c93606e804c710e3f90f40407bd18b5f473",
            "title": "Vision by man and machine.",
            "venue": "Scientific American",
            "publicationVenue": {
                "id": "urn:research:fb27311b-7236-4828-ac26-ffbf0eec5dc8",
                "name": "Scientific American",
                "alternate_names": [
                    "Sci Am"
                ],
                "issn": "0036-8733",
                "url": "http://search.epnet.com/login.aspx?authtype=ip,uid&defaultdb=sfh&profile=sciamehost"
            },
            "year": 1984,
            "externalIds": {
                "MAG": "2018923125",
                "DOI": "10.1038/SCIENTIFICAMERICAN0484-106",
                "CorpusId": 9690772,
                "PubMed": "6729426"
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 266,
            "influentialCitationCount": 10,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Physics",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1984-03-01",
            "journal": {
                "name": "Scientific American",
                "volume": "250 4"
            },
            "citationStyles": {
                "bibtex": "@Article{Poggio1984VisionBM,\n author = {T. Poggio},\n booktitle = {Scientific American},\n journal = {Scientific American},\n pages = {\n          106-16\n        },\n title = {Vision by man and machine.},\n volume = {250 4},\n year = {1984}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0aaf0e3c5c70fc31bd6c3457b19c34e7db32f92d",
            "@type": "ScholarlyArticle",
            "paperId": "0aaf0e3c5c70fc31bd6c3457b19c34e7db32f92d",
            "corpusId": 1428329,
            "url": "https://www.semanticscholar.org/paper/0aaf0e3c5c70fc31bd6c3457b19c34e7db32f92d",
            "title": "Deformable Graph Matching",
            "venue": "2013 IEEE Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2013,
            "externalIds": {
                "MAG": "2094539604",
                "DBLP": "conf/cvpr/ZhouT13",
                "DOI": "10.1109/CVPR.2013.376",
                "CorpusId": 1428329
            },
            "abstract": "Graph matching (GM) is a fundamental problem in computer science, and it has been successfully applied to many problems in computer vision. Although widely used, existing GM algorithms cannot incorporate global consistence among nodes, which is a natural constraint in computer vision problems. This paper proposes deformable graph matching (DGM), an extension of GM for matching graphs subject to global rigid and non-rigid geometric constraints. The key idea of this work is a new factorization of the pair-wise affinity matrix. This factorization decouples the affinity matrix into the local structure of each graph and the pair-wise affinity edges. Besides the ability to incorporate global geometric transformations, this factorization offers three more benefits. First, there is no need to compute the costly (in space and time) pair-wise affinity matrix. Second, it provides a unified view of many GM methods and extends the standard iterative closest point algorithm. Third, it allows to use the path-following optimization algorithm that leads to improved optimization strategies and matching performance. Experimental results on synthetic and real databases illustrate how DGM outperforms state-of-the-art algorithms for GM. The code is available at http://humansensing.cs.cmu.edu/fgm.",
            "referenceCount": 28,
            "citationCount": 154,
            "influentialCitationCount": 15,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://figshare.com/articles/journal_contribution/Deformable_Graph_Matching/6552509/1/files/12033854.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2013-06-23",
            "journal": {
                "name": "2013 IEEE Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhou2013DeformableGM,\n author = {Feng Zhou and F. D. L. Torre},\n booktitle = {2013 IEEE Conference on Computer Vision and Pattern Recognition},\n journal = {2013 IEEE Conference on Computer Vision and Pattern Recognition},\n pages = {2922-2929},\n title = {Deformable Graph Matching},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cf4bd2795d132b2091efe37e0aed3f067a30c62b",
            "@type": "ScholarlyArticle",
            "paperId": "cf4bd2795d132b2091efe37e0aed3f067a30c62b",
            "corpusId": 12975479,
            "url": "https://www.semanticscholar.org/paper/cf4bd2795d132b2091efe37e0aed3f067a30c62b",
            "title": "A review of visual moving target tracking",
            "venue": "Multimedia tools and applications",
            "publicationVenue": {
                "id": "urn:research:477368e9-7a8e-475a-8c93-6d623797fd06",
                "name": "Multimedia tools and applications",
                "alternate_names": [
                    "Multimedia Tools and Applications",
                    "Multimedia Tool Appl",
                    "Multimedia tool appl"
                ],
                "issn": "1380-7501",
                "url": "https://www.springer.com/computer/information+systems+and+applications/journal/11042"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2434003202",
                "DBLP": "journals/mta/PanLF17",
                "DOI": "10.1007/s11042-016-3647-0",
                "CorpusId": 12975479
            },
            "abstract": null,
            "referenceCount": 108,
            "citationCount": 108,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-08-01",
            "journal": {
                "name": "Multimedia Tools and Applications",
                "volume": "76"
            },
            "citationStyles": {
                "bibtex": "@Article{Pan2017ARO,\n author = {Zheng Pan and Shuai Liu and Weina Fu},\n booktitle = {Multimedia tools and applications},\n journal = {Multimedia Tools and Applications},\n pages = {16989-17018},\n title = {A review of visual moving target tracking},\n volume = {76},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f0adc5155dc89d3f9ac567ade2da4dece9b78b59",
            "@type": "ScholarlyArticle",
            "paperId": "f0adc5155dc89d3f9ac567ade2da4dece9b78b59",
            "corpusId": 14329270,
            "url": "https://www.semanticscholar.org/paper/f0adc5155dc89d3f9ac567ade2da4dece9b78b59",
            "title": "An Evaluation of the Suitability of FPGAs for Embedded Vision Systems",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2005,
            "externalIds": {
                "MAG": "2118294079",
                "DBLP": "conf/cvpr/MacLean05",
                "DOI": "10.1109/CVPR.2005.408",
                "CorpusId": 14329270
            },
            "abstract": "Reconfigurable hardware, in the form of Field Programmable Gate Arrays (FPGAs), is becoming increasingly attractive for digital signal processing problems, including image processing and computer vision tasks. The ability to exploit the parallelism often found in these problems, as well as the ability to support different modes of operation on a single hardware substrate, gives these devices a particular advantage over fixed architecture devices such as serial CPUs and DSPs. Further, development times are substantially shorter than dedicated hardware in the form of Application Specific ICs (ASICs), and small changes to a design can be prototyped in a matter of hours. On the other hand, designing with FPGAs still requires expertise beyond that found in many vision labs today. This paper looks at the advantages and disadvantages of FPGA technology, its suitability for image processing and computer vision tasks, and attempts to suggest some directions for the future.",
            "referenceCount": 30,
            "citationCount": 133,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.wjamesmaclean.net//9501292851/cvpr05-ecv-MacLean-eval.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2005-06-20",
            "journal": {
                "name": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Workshops",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{MacLean2005AnEO,\n author = {W. J. MacLean},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Workshops},\n pages = {131-131},\n title = {An Evaluation of the Suitability of FPGAs for Embedded Vision Systems},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:dac200bc42d8c70e9f8a5137453d8a8b18435037",
            "@type": "ScholarlyArticle",
            "paperId": "dac200bc42d8c70e9f8a5137453d8a8b18435037",
            "corpusId": 9230437,
            "url": "https://www.semanticscholar.org/paper/dac200bc42d8c70e9f8a5137453d8a8b18435037",
            "title": "A Review on Vision-Based Full DOF Hand Motion Estimation",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2005,
            "externalIds": {
                "MAG": "2164807703",
                "DBLP": "conf/cvpr/ErolBNBT05",
                "DOI": "10.1109/CVPR.2005.395",
                "CorpusId": 9230437
            },
            "abstract": "Direct use of the hand as an input device is an attractive method for providing natural human-computer interaction (HCI). Currently, the only technology that satisfies the advanced requirements of hand-based input for HCI is glovebased sensing. This technology, however, has several drawbacks including that it hinders the ease and naturalness with which the user can interact with the computer controlled environment, and it requires long calibration and setup procedures. Computer vision has the potential to provide much more natural, non-contact solutions. As a result, there have been considerable research efforts to use the hand as an input device for HCI. A very challenging problem in this context, which is the focus of this review, is recovering the 3D pose of the hand and the fingers as glove-based devices do. This paper presents a brief literature review on full degreeof- freedom (DOF) hand motion estimation methods.",
            "referenceCount": 55,
            "citationCount": 113,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.cse.unr.edu/%7Emircea/Publications/mn_v4hci05.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": "2005-06-20",
            "journal": {
                "name": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Workshops",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Erol2005ARO,\n author = {A. Erol and G. Bebis and M. Nicolescu and Richard D. Boyle and Xander Twombly},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Workshops},\n pages = {75-75},\n title = {A Review on Vision-Based Full DOF Hand Motion Estimation},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4eed9d20232953a1265ef35edeeb4843a519b319",
            "@type": "ScholarlyArticle",
            "paperId": "4eed9d20232953a1265ef35edeeb4843a519b319",
            "corpusId": 13200879,
            "url": "https://www.semanticscholar.org/paper/4eed9d20232953a1265ef35edeeb4843a519b319",
            "title": "A vision system for observing and extracting facial action parameters",
            "venue": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1994,
            "externalIds": {
                "DBLP": "conf/cvpr/EssaP94",
                "MAG": "2170099627",
                "DOI": "10.1109/CVPR.1994.323813",
                "CorpusId": 13200879
            },
            "abstract": "We describe a computer vision system for observing the \"action units\" of a face using video sequences as input. The visual observation (sensing) is achieved by using an optimal estimation optical flow method coupled with a geometric and a physical (muscle) model describing the facial structure. This modeling results in a time-varying spatial patterning of facial shape and a parametric representation of the independent muscle action groups, responsible for the observed facial motions. These muscle action patterns may then be used for analysis, interpretation, and synthesis. Thus, by interpreting facial motions within a physics-based optimal estimation framework, a new control model of facial movement is developed. The newly extracted action units (which we name \"FACS+\") are both physics and geometry-based, and extend the well-known FACS parameters for facial expressions by adding temporal information and non-local spatial patterning of facial motion.<<ETX>>",
            "referenceCount": 19,
            "citationCount": 200,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1994-06-21",
            "journal": {
                "name": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Essa1994AVS,\n author = {Irfan Essa and A. Pentland},\n booktitle = {1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition},\n journal = {1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition},\n pages = {76-83},\n title = {A vision system for observing and extracting facial action parameters},\n year = {1994}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:558898a41f5205e5a7d0b093e9cea8e897c83d64",
            "@type": "ScholarlyArticle",
            "paperId": "558898a41f5205e5a7d0b093e9cea8e897c83d64",
            "corpusId": 121651020,
            "url": "https://www.semanticscholar.org/paper/558898a41f5205e5a7d0b093e9cea8e897c83d64",
            "title": "Stochastic geometry models in high-level vision",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1993,
            "externalIds": {
                "MAG": "2036591396",
                "DOI": "10.1080/02664769300000065",
                "CorpusId": 121651020
            },
            "abstract": "We survey the use of Markov models from stochastic geometry as priors in \u2018high-level\u2019 computer vision, in direct analogy with the use of discrete Markov random fields in \u2018low-level\u2019 vision. There are analogues of the Gibbs sampler, ICM and simulated annealing, and connections with existing methods in computer vision.",
            "referenceCount": 31,
            "citationCount": 203,
            "influentialCitationCount": 11,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ir.cwi.nl/pub/10408/10408D.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Journal of Applied Statistics",
                "volume": "20"
            },
            "citationStyles": {
                "bibtex": "@Article{Baddeley1993StochasticGM,\n author = {A. Baddeley and V. Lieshout},\n journal = {Journal of Applied Statistics},\n pages = {231-256},\n title = {Stochastic geometry models in high-level vision},\n volume = {20},\n year = {1993}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0bbee958655fbc9ffe0689909a3ed89d260ae55d",
            "@type": "ScholarlyArticle",
            "paperId": "0bbee958655fbc9ffe0689909a3ed89d260ae55d",
            "corpusId": 207166462,
            "url": "https://www.semanticscholar.org/paper/0bbee958655fbc9ffe0689909a3ed89d260ae55d",
            "title": "Merging virtual objects with the real world: seeing ultrasound imagery within the patient",
            "venue": "International Conference on Computer Graphics and Interactive Techniques",
            "publicationVenue": {
                "id": "urn:research:cf6b5e76-9274-46e6-a2dd-7c190ec2ec5f",
                "name": "International Conference on Computer Graphics and Interactive Techniques",
                "alternate_names": [
                    "Int Conf Comput Graph Interact Tech",
                    "SIGGRAPH"
                ],
                "issn": null,
                "url": "http://www.siggraph.org/"
            },
            "year": 1992,
            "externalIds": {
                "DBLP": "conf/siggraph/BajuraFO92",
                "MAG": "2141496966",
                "DOI": "10.1145/133994.134061",
                "CorpusId": 207166462
            },
            "abstract": "We describe initial results which show \u201clive\u201d ultrasound echography data visualized within a pregnant human subject. The visualization is achieved by using a small video camera mounted in front of a conventional head-mounted display worn by an observer. The camera\u2019s video images are composited with computer-generated ones that contain one or more 2D ultrasound images properly transformed to the observer\u2019s current viewing position. As the observer walks around the subject, the ultrasound images appear stationary in 3-space within the subject. This kind of enhancement of the observer\u2019s vision may have many other applications, e.g., image guided surgical procedures and on location 3D interactive architecture preview.",
            "referenceCount": 50,
            "citationCount": 687,
            "influentialCitationCount": 16,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/142920.134061",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book",
                "Conference",
                "Review"
            ],
            "publicationDate": "1992-07-01",
            "journal": {
                "name": "Proceedings of the 19th annual conference on Computer graphics and interactive techniques",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bajura1992MergingVO,\n author = {M. Bajura and H. Fuchs and Ryutarou Ohbuchi},\n booktitle = {International Conference on Computer Graphics and Interactive Techniques},\n journal = {Proceedings of the 19th annual conference on Computer graphics and interactive techniques},\n title = {Merging virtual objects with the real world: seeing ultrasound imagery within the patient},\n year = {1992}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c1d1bae79dbcd4f5fb45e37d58aedab9b337a13e",
            "@type": "ScholarlyArticle",
            "paperId": "c1d1bae79dbcd4f5fb45e37d58aedab9b337a13e",
            "corpusId": 61645069,
            "url": "https://www.semanticscholar.org/paper/c1d1bae79dbcd4f5fb45e37d58aedab9b337a13e",
            "title": "Improvements in real-time correlation-based stereo vision",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2001,
            "externalIds": {
                "MAG": "2126850011",
                "DOI": "10.1109/SMBV.2001.988772",
                "CorpusId": 61645069
            },
            "abstract": "A stereo vision system that is required to support high-level object based tasks in a tele-operated environment is described. Stereo vision is computationally expensive, due to having to find corresponding pixels. Correlation is a fast, standard way to solve the correspondence problem. This paper analyses the behaviour of correlation based stereo to find ways to improve its quality while maintaining its realtime suitability. Three methods are suggested. Two of them aim to improve the disparity image especially at depth discontinuities, while one targets the identification of possible errors in general. Results are given on real stereo images with ground truth. A comparison with five standard correlation methods shows that improvements of simple stereo correlation are possible in real-time on current computer hardware.",
            "referenceCount": 9,
            "citationCount": 181,
            "influentialCitationCount": 17,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2001-12-09",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Hirschm\u00fcller2001ImprovementsIR,\n author = {H. Hirschm\u00fcller},\n booktitle = {Computer Vision and Pattern Recognition},\n pages = {141-148},\n title = {Improvements in real-time correlation-based stereo vision},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3d24879f0593dd92c73856a8c60fe72e5a00b9e0",
            "@type": "ScholarlyArticle",
            "paperId": "3d24879f0593dd92c73856a8c60fe72e5a00b9e0",
            "corpusId": 263487718,
            "url": "https://www.semanticscholar.org/paper/3d24879f0593dd92c73856a8c60fe72e5a00b9e0",
            "title": "Light Fields and Computational Imaging",
            "venue": "Computer",
            "publicationVenue": {
                "id": "urn:research:f6572f66-2623-4a5e-b0d9-4a5028dea98f",
                "name": "Computer",
                "alternate_names": [
                    "IEEE Computer",
                    "IEEE Comput"
                ],
                "issn": "0018-9162",
                "url": "http://www.computer.org/computer"
            },
            "year": 2006,
            "externalIds": {
                "MAG": "2046321681",
                "DBLP": "journals/computer/Levoy06",
                "DOI": "10.1109/MC.2006.270",
                "CorpusId": 263487718
            },
            "abstract": "A survey of the theory and practice of light field imaging emphasizes the devices researchers in computer graphics and computer vision have built to capture light fields photographically and the techniques they have developed to compute novel images from them",
            "referenceCount": 23,
            "citationCount": 428,
            "influentialCitationCount": 17,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2006-08-01",
            "journal": {
                "name": "Computer",
                "volume": "39"
            },
            "citationStyles": {
                "bibtex": "@Article{Levoy2006LightFA,\n author = {M. Levoy},\n booktitle = {Computer},\n journal = {Computer},\n pages = {46-55},\n title = {Light Fields and Computational Imaging},\n volume = {39},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a313f0ca434a82da681b1aa1781ce8593874b768",
            "@type": "ScholarlyArticle",
            "paperId": "a313f0ca434a82da681b1aa1781ce8593874b768",
            "corpusId": 10121980,
            "url": "https://www.semanticscholar.org/paper/a313f0ca434a82da681b1aa1781ce8593874b768",
            "title": "Proactive computing",
            "venue": "Communications of the ACM",
            "publicationVenue": {
                "id": "urn:research:4d9ce1c4-dc84-46b9-903e-e3751c00c7dd",
                "name": "Communications of the ACM",
                "alternate_names": [
                    "Commun ACM",
                    "Communications of The ACM"
                ],
                "issn": "0001-0782",
                "url": "http://www.acm.org/pubs/cacm/"
            },
            "year": 2000,
            "externalIds": {
                "MAG": "2338251608",
                "DBLP": "journals/cacm/Tennenhouse00",
                "DOI": "10.1145/332833.332837",
                "CorpusId": 10121980
            },
            "abstract": "F or the past 40 years, most of the IT research community has focused on interactive computing, J.C.R. Licklider\u2019s powerful and human-centered vision of human-computer symbiosis [3]. In tandem with this research has come the creation of an IT industry that is hurtling toward the human/machine/network breakpoint\u2014the point at which the number of networked interactive computers will surpass the number of people on the planet. We still have a long way to go before Licklider\u2019s vision is attained\u2014and are many years from extending per-capita penetration to most parts of the world. However, \u201cmissing science\u201d may no longer be the factor limiting progress toward these long-cherished goals. It is reasonable, though perhaps heretical, to suggest that refinements of the existing science base will be sufficient to drive these efforts forward. It is time for a change. The computer science research community now enjoys a rare and exciting opportunity to redefine its agenda and establish the new goals that will propel society beyond interactive computing and the human/machine breakpoint. In lifting our sights toward a world in which networked computers outnumber human beings by a hundred or thousand to one, we should consider what these \u201cexcess\u201d computers will be doing and craft a research agenda that can lead to increased human productivity and quality of life.",
            "referenceCount": 11,
            "citationCount": 538,
            "influentialCitationCount": 21,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/332833.332837",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2000-05-01",
            "journal": {
                "name": "Communications of the ACM",
                "volume": "43"
            },
            "citationStyles": {
                "bibtex": "@Article{Tennenhouse2000ProactiveC,\n author = {D. Tennenhouse},\n booktitle = {Communications of the ACM},\n journal = {Communications of the ACM},\n pages = {43 - 50},\n title = {Proactive computing},\n volume = {43},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1c5c104b70f57986bb55f73614dde8f32ae3181c",
            "@type": "ScholarlyArticle",
            "paperId": "1c5c104b70f57986bb55f73614dde8f32ae3181c",
            "corpusId": 10070897,
            "url": "https://www.semanticscholar.org/paper/1c5c104b70f57986bb55f73614dde8f32ae3181c",
            "title": "Scattering",
            "venue": "SIGGRAPH ASIA Courses",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2008,
            "externalIds": {
                "DBLP": "conf/siggrapha/GutierrezNJJ08",
                "DOI": "10.1145/1508044.1508101",
                "CorpusId": 10070897
            },
            "abstract": "Computer graphics and computer vision techniques deal with acquiring, interpreting and presenting the rich visual world around us. These are exciting multi-disciplinary fields of research with a wide spectrum of applications that can impact our daily lives. However, most of the computer generated imagery today represents scenes with clear atmospheres, neglecting light scattering effects. Analogously, most computer vision systems have not enjoyed success when deployed in uncontrolled outdoor environments. Nevertheless, scattering is a fundamental aspect of light transport in a wide range of applications, whether simulating it or interpreting it, from medical imaging to driving simulators or underwater imagery.",
            "referenceCount": 0,
            "citationCount": 305,
            "influentialCitationCount": 28,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book"
            ],
            "publicationDate": "2008-12-10",
            "journal": {
                "name": "ACM SIGGRAPH ASIA 2008 courses",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gutierrez2008Scattering,\n author = {Diego Gutierrez and Srinivasa G. Narasimhan and H. Jensen and W. Jarosz},\n booktitle = {SIGGRAPH ASIA Courses},\n journal = {ACM SIGGRAPH ASIA 2008 courses},\n title = {Scattering},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d147dfa8f1417f3d7519929d9ae1051f91c98d0a",
            "@type": "ScholarlyArticle",
            "paperId": "d147dfa8f1417f3d7519929d9ae1051f91c98d0a",
            "corpusId": 2171476,
            "url": "https://www.semanticscholar.org/paper/d147dfa8f1417f3d7519929d9ae1051f91c98d0a",
            "title": "Animat vision: Active vision in artificial animals",
            "venue": "Proceedings of IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1995,
            "externalIds": {
                "MAG": "2169464814",
                "DBLP": "conf/iccv/TerzopoulosR95",
                "DOI": "10.1109/ICCV.1995.466856",
                "CorpusId": 2171476
            },
            "abstract": "We propose and demonstrate a new paradigm for active vision research that draws upon recent advances in the fields of artificial life and computer graphics. A software alternative to the prevailing hardware vision mindset, animat vision prescribes artificial animals, or animats, situated in physics-based virtual worlds as autonomous virtual robots possessing active perception systems. To be operative in its world, an animat must autonomously control its eyes and muscle-actuated body, applying computer vision algorithms to continuously analyze the retinal image streams acquired by its eyes in order to locomote purposefully through its world. We describe an initial animat vision implementation within lifelike artificial fishes inhabiting a physics-based, virtual marine world. Emulating the appearance, motion, and behavior of real fishes in their natural habitats, these animats are capable of spatially nonuniform retinal imaging, foveation, retinal image stabilization, color object recognition, and perceptually-guided navigation. These capabilities allow them to pursue moving targets such as fellow artificial fishes. Animat vision offers a fertile approach to the development, implementation, and evaluation of computational theories that profess sensorimotor competence for animal or robotic situated agents.<<ETX>>",
            "referenceCount": 37,
            "citationCount": 146,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.collectionscanada.ca/obj/s4/f2/dsk1/tape7/PQDD_0007/NQ41282.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1995-06-20",
            "journal": {
                "name": "Proceedings of IEEE International Conference on Computer Vision",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Terzopoulos1995AnimatVA,\n author = {Demetri Terzopoulos and T. Rabie},\n booktitle = {Proceedings of IEEE International Conference on Computer Vision},\n journal = {Proceedings of IEEE International Conference on Computer Vision},\n pages = {801-808},\n title = {Animat vision: Active vision in artificial animals},\n year = {1995}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5beb9c14476fd124e1ef8011a9845f8938096ec2",
            "@type": "ScholarlyArticle",
            "paperId": "5beb9c14476fd124e1ef8011a9845f8938096ec2",
            "corpusId": 5362853,
            "url": "https://www.semanticscholar.org/paper/5beb9c14476fd124e1ef8011a9845f8938096ec2",
            "title": "Structural Stereopsis for 3-D Vision",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 1988,
            "externalIds": {
                "MAG": "2148141929",
                "DBLP": "journals/pami/BoyerK88",
                "DOI": "10.1109/34.3880",
                "CorpusId": 5362853
            },
            "abstract": "A novel approach to solving the stereo correspondence problem in computer vision is described. Structural descriptions of two two-dimensional views of a scene are extracted by one of possibly several available low-level processes, and a new theory of inexact matching for such structures is derived. An entropy-based figure of merit for attribute selection and ordering is defined. Experimental results applying these techniques to real image pairs are presented. Some manipulation experiments are briefly presented. >",
            "referenceCount": 28,
            "citationCount": 187,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1988-03-01",
            "journal": {
                "name": "IEEE Trans. Pattern Anal. Mach. Intell.",
                "volume": "10"
            },
            "citationStyles": {
                "bibtex": "@Article{Boyer1988StructuralSF,\n author = {K. Boyer and A. Kak},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Trans. Pattern Anal. Mach. Intell.},\n pages = {144-166},\n title = {Structural Stereopsis for 3-D Vision},\n volume = {10},\n year = {1988}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4a1a91cdf12c63e66e79321120de2ff510355a21",
            "@type": "ScholarlyArticle",
            "paperId": "4a1a91cdf12c63e66e79321120de2ff510355a21",
            "corpusId": 10395533,
            "url": "https://www.semanticscholar.org/paper/4a1a91cdf12c63e66e79321120de2ff510355a21",
            "title": "Large-Scale Neuronal Theories of the Brain",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1994,
            "externalIds": {
                "MAG": "17920260",
                "DOI": "10.5860/choice.32-4182",
                "CorpusId": 10395533
            },
            "abstract": "Abstract : This book originated at a small and informal workshop held in December of 1992 in Idyllwild, a relatively secluded resort village situated amid forests in the San Jacinto Mountains above Palm Springs in Southern California. Eighteen colleagues from a broad range of disciplines, including biophysics, electrophysiology, neuroanatomy, psychophysics, clinical studies, mathematics and computer vision, discussed 'Large Scale Models of the Brain,' that is, theories and models that cover a broad range of phenomena, including early and late vision, various memory systems, selective attention, and the neuronal code underlying figure-ground segregation and awareness (for a brief summary of this meeting, see Stevens 1993). The bias in the selection of the speakers toward researchers in the area of visual perception reflects both the academic background of one of the organizers as well as the (relative) more mature status of vision compared with other modalities. This should not be surprising given the emphasis we humans place on'seeing' for orienting ourselves, as well as the intense scrutiny visual processes have received due to their obvious usefullness in military, industrial, and robotic applications. JMD",
            "referenceCount": 101,
            "citationCount": 676,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Koch1994LargeScaleNT,\n author = {C. Koch and Joel L. Davis},\n title = {Large-Scale Neuronal Theories of the Brain},\n year = {1994}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c8d45226a133ce224699a1dda45e97104594b506",
            "@type": "ScholarlyArticle",
            "paperId": "c8d45226a133ce224699a1dda45e97104594b506",
            "corpusId": 32425924,
            "url": "https://www.semanticscholar.org/paper/c8d45226a133ce224699a1dda45e97104594b506",
            "title": "Parallel integration of vision modules.",
            "venue": "Science",
            "publicationVenue": {
                "id": "urn:research:f59506a8-d8bb-4101-b3d4-c4ac3ed03dad",
                "name": "Science",
                "alternate_names": null,
                "issn": "0193-4511",
                "url": "https://www.jstor.org/journal/science"
            },
            "year": 1988,
            "externalIds": {
                "MAG": "2007579152",
                "DOI": "10.1126/SCIENCE.3175666",
                "CorpusId": 32425924,
                "PubMed": "3175666"
            },
            "abstract": "Computer algorithms have been developed for several early vision processes, such as edge detection, stereopsis, motion, texture, and color, that give separate cues to the distance from the viewer of three-dimensional surfaces, their shape, and their material properties. Not surprisingly, biological vision systems still greatly outperform computer vision programs. One of the keys to the reliability, flexibility, and robustness of biological vision systems is their ability to integrate several visual cues. A computational technique for integrating different visual cues has now been developed and implemented with encouraging results on a parallel supercomputer.",
            "referenceCount": 5,
            "citationCount": 167,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1988-10-21",
            "journal": {
                "name": "Science",
                "volume": "242 4877"
            },
            "citationStyles": {
                "bibtex": "@Article{Poggio1988ParallelIO,\n author = {T. Poggio and E. Gamble and J. Little},\n booktitle = {Science},\n journal = {Science},\n pages = {\n          436-40\n        },\n title = {Parallel integration of vision modules.},\n volume = {242 4877},\n year = {1988}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ea8e470fdb51ef485e995f55893262508326b964",
            "@type": "ScholarlyArticle",
            "paperId": "ea8e470fdb51ef485e995f55893262508326b964",
            "corpusId": 36530857,
            "url": "https://www.semanticscholar.org/paper/ea8e470fdb51ef485e995f55893262508326b964",
            "title": "The Convergence of Graphics and Vision",
            "venue": "Computer",
            "publicationVenue": {
                "id": "urn:research:f6572f66-2623-4a5e-b0d9-4a5028dea98f",
                "name": "Computer",
                "alternate_names": [
                    "IEEE Computer",
                    "IEEE Comput"
                ],
                "issn": "0018-9162",
                "url": "http://www.computer.org/computer"
            },
            "year": 1998,
            "externalIds": {
                "MAG": "2052936048",
                "DBLP": "journals/computer/Lengyel98",
                "DOI": "10.1109/2.689676",
                "CorpusId": 36530857
            },
            "abstract": "Computer graphics and computer vision are inverse problems. Traditional computer graphics starts with input geometric models and produces image sequences. Traditional computer vision starts with input image sequences and produces geometric models. Lately, there has been a meeting in the middle, and the center, the prize, is to create stunning images in real time. Vision researchers now work from images backward, just as far backward as necessary to create models that capture a scene without going to full geometric models. Graphics researchers now work with hybrid geometry and image models. Approaching similar problems from opposite directions, graphics and vision researchers are reaching a fertile middle ground. The goal is to find the best possible tools for the imagination. This overview describes cutting edge work, some of which will debut at Siggraph 98.",
            "referenceCount": 19,
            "citationCount": 97,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "1998-07-01",
            "journal": {
                "name": "Computer",
                "volume": "31"
            },
            "citationStyles": {
                "bibtex": "@Article{Lengyel1998TheCO,\n author = {Jed Lengyel},\n booktitle = {Computer},\n journal = {Computer},\n pages = {46-53},\n title = {The Convergence of Graphics and Vision},\n volume = {31},\n year = {1998}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a67e0c5b11caceafc0002b0aaff8d7db21eb3312",
            "@type": "ScholarlyArticle",
            "paperId": "a67e0c5b11caceafc0002b0aaff8d7db21eb3312",
            "corpusId": 14661676,
            "url": "https://www.semanticscholar.org/paper/a67e0c5b11caceafc0002b0aaff8d7db21eb3312",
            "title": "The variable bandwidth mean shift and data-driven scale selection",
            "venue": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2001,
            "externalIds": {
                "MAG": "2149107824",
                "DBLP": "conf/iccv/ComaniciuRM01",
                "DOI": "10.1109/ICCV.2001.937550",
                "CorpusId": 14661676
            },
            "abstract": "We present two solutions for the scale selection problem in computer vision. The first one is completely nonparametric and is based on the the adaptive estimation of the normalized density gradient. Employing the sample point estimator, we define the Variable Bandwidth Mean Shift, prove its convergence, and show its superiority over the fixed bandwidth procedure. The second technique has a semiparametric nature and imposes a local structure on the data to extract reliable scale information. The local scale of the underlying density is taken as the bandwidth which maximizes the magnitude of the normalized mean shift vector. Both estimators provide practical tools for autonomous image and quasi real-time video analysis and several examples are shown to illustrate their effectiveness.",
            "referenceCount": 23,
            "citationCount": 497,
            "influentialCitationCount": 32,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2001-07-07",
            "journal": {
                "name": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001",
                "volume": "1"
            },
            "citationStyles": {
                "bibtex": "@Article{Comaniciu2001TheVB,\n author = {D. Comaniciu and Visvanathan Ramesh and P. Meer},\n booktitle = {Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001},\n journal = {Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001},\n pages = {438-445 vol.1},\n title = {The variable bandwidth mean shift and data-driven scale selection},\n volume = {1},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:15fb19b3e28ad79d49cf989d1a742f1fd87d47af",
            "@type": "ScholarlyArticle",
            "paperId": "15fb19b3e28ad79d49cf989d1a742f1fd87d47af",
            "corpusId": 14320822,
            "url": "https://www.semanticscholar.org/paper/15fb19b3e28ad79d49cf989d1a742f1fd87d47af",
            "title": "Vision for a smart kiosk",
            "venue": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1997,
            "externalIds": {
                "DBLP": "conf/cvpr/RehgLW97",
                "MAG": "2112715536",
                "DOI": "10.1109/CVPR.1997.609401",
                "CorpusId": 14320822
            },
            "abstract": "We describe a novel computer vision application: vision-based human sensing for a Smart Kiosk interface. A Smart Kiosk is a free-standing information dispensing computer appliance capable of engaging in public interactions with multiple people. Vision sensing is a critical component of the kiosk interface, where it is used to determine the context for the interaction. We present a taxonomy of vision problems for a kiosk interface and describe a prototype kiosk which uses color stereo tracking and graphical output to interact with several users.",
            "referenceCount": 29,
            "citationCount": 106,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1997-06-17",
            "journal": {
                "name": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Rehg1997VisionFA,\n author = {James M. Rehg and M. Loughlin and K. Waters},\n booktitle = {Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition},\n journal = {Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition},\n pages = {690-696},\n title = {Vision for a smart kiosk},\n year = {1997}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:acda4460f0ad088023369c2e7e32f2512dcd75e7",
            "@type": "ScholarlyArticle",
            "paperId": "acda4460f0ad088023369c2e7e32f2512dcd75e7",
            "corpusId": 2260178,
            "url": "https://www.semanticscholar.org/paper/acda4460f0ad088023369c2e7e32f2512dcd75e7",
            "title": "Self-supervised Monocular Road Detection in Desert Terrain",
            "venue": "Robotics: Science and Systems",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2006,
            "externalIds": {
                "MAG": "97351935",
                "DBLP": "conf/rss/DahlkampKSTB06",
                "DOI": "10.15607/RSS.2006.II.005",
                "CorpusId": 2260178
            },
            "abstract": "We present a method for identifying drivable surfaces in difficult unpaved and offroad terrain conditions as encountered in the DARPA Grand Challenge robot race. Instead of relying on a static, pre-computed road appearance model, this method adjusts its model to changing environments. It achieves robustness by combining sensor information from a laser range finder, a pose estimation system and a color camera. Using the first two modalities, the system first identifies a nearby patch of drivable surface. Computer Vision then takes this patch and uses it to construct appearance models to find drivable surface outward into the far range. This information is put into a drivability map for the vehicle path planner. In addition to evaluating the method\u2019s performance using a scoring framework run on real-world data, the system was entered, and won, the 2005 DARPA Grand Challenge. Post-race log-file analysis proved that without the Computer Vision algorithm, the vehicle would not have driven fast enough to win.",
            "referenceCount": 16,
            "citationCount": 397,
            "influentialCitationCount": 33,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2006-08-16",
            "journal": {
                "name": "",
                "volume": "02"
            },
            "citationStyles": {
                "bibtex": "@Article{Dahlkamp2006SelfsupervisedMR,\n author = {Hendrik Dahlkamp and A. Kaehler and David Stavens and S. Thrun and G. Bradski},\n booktitle = {Robotics: Science and Systems},\n title = {Self-supervised Monocular Road Detection in Desert Terrain},\n volume = {02},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cb6a1213c115d3cd94ecf3aa057220a6cf2b9555",
            "@type": "ScholarlyArticle",
            "paperId": "cb6a1213c115d3cd94ecf3aa057220a6cf2b9555",
            "corpusId": 261594466,
            "url": "https://www.semanticscholar.org/paper/cb6a1213c115d3cd94ecf3aa057220a6cf2b9555",
            "title": "Computational vision",
            "venue": "Proceedings of the IEEE",
            "publicationVenue": {
                "id": "urn:research:6faaccca-1cc4-45a9-aeb6-96a4901d2606",
                "name": "Proceedings of the IEEE",
                "alternate_names": [
                    "Proc IEEE"
                ],
                "issn": "0018-9219",
                "url": "http://www.ieee.org/portal/pages/pubs/proceedings/"
            },
            "year": 1981,
            "externalIds": {
                "DOI": "10.1109/proc.1981.12026",
                "CorpusId": 261594466
            },
            "abstract": "Research is beginning to uncover fundamental computational principles underlying vision that apply equally to artificial and natural systems. These principles provide insights into the limitations of early machine vision systems and lay a foundation for building future systems capable of high performance in a broad range of visual domains. We present this emerging computational view of visual perception, discuss some early work in the field in its context, and put forward current thoughts on the overall organization and operation of a general-purpose computer vision system, synthesizing recent theoretical and experimental results.",
            "referenceCount": 0,
            "citationCount": 145,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "Proceedings of the IEEE",
                "volume": "69"
            },
            "citationStyles": {
                "bibtex": "@Article{Barrow1981ComputationalV,\n author = {H.G. Barrow and J.M. Tenenbaum},\n booktitle = {Proceedings of the IEEE},\n journal = {Proceedings of the IEEE},\n pages = {572-595},\n title = {Computational vision},\n volume = {69},\n year = {1981}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a6055f1b65f1153f1e37de2c1a4ad2a2ccdcaebf",
            "@type": "ScholarlyArticle",
            "paperId": "a6055f1b65f1153f1e37de2c1a4ad2a2ccdcaebf",
            "corpusId": 2793623,
            "url": "https://www.semanticscholar.org/paper/a6055f1b65f1153f1e37de2c1a4ad2a2ccdcaebf",
            "title": "The Proximity-Fixation-Disparity Curve and the Preferred Viewing Distance at a Visual Display as an Indicator of Near Vision Fatigue",
            "venue": "Optometry and Vision Science",
            "publicationVenue": {
                "id": "urn:research:0444c465-1041-40ca-963e-628694a9eccc",
                "name": "Optometry and Vision Science",
                "alternate_names": [
                    "Optom Vis Sci"
                ],
                "issn": "1040-5488",
                "url": "https://journals.lww.com/optvissci"
            },
            "year": 2002,
            "externalIds": {
                "MAG": "2136705239",
                "DOI": "10.1097/00006324-200203000-00010",
                "CorpusId": 2793623,
                "PubMed": "11913842"
            },
            "abstract": "Purpose. This laboratory study investigates the relation between measures of fixation disparity (FD) (and other optometric measures) and near vision fatigue at a computer workstation. Methods. Young adult subjects with normal binocular vision performed three blocks of a visual task of 30 min each. In Block A, the viewing distance was 100 cm, as a reference without near vision. In Block B, the viewing distance of 50 cm induced a defined near vision load. In Block C, subjects were free to choose a comfortable viewing distance. This preferred viewing distance was used as an indicator of near vision fatigue because subjects adopting longer viewing distances in Block C had more near vision fatigue at 50 cm in Block B. Results. Subjects with preferred viewing distances longer than average (63 cm) had steeper slopes of FD as a function of viewing distance (100\u201330 cm), as shown by discriminant analyses. Conclusions. Thus, this steep proximity-FD curve indicates a weak disparity vergence system that may cause near vision fatigue. This may explain why some young adults prefer longer viewing distances at the computer workstation.",
            "referenceCount": 61,
            "citationCount": 82,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2002-03-01",
            "journal": {
                "name": "Optometry and Vision Science",
                "volume": "79"
            },
            "citationStyles": {
                "bibtex": "@Article{Jaschinski2002ThePC,\n author = {W. Jaschinski},\n booktitle = {Optometry and Vision Science},\n journal = {Optometry and Vision Science},\n pages = {158-169},\n title = {The Proximity-Fixation-Disparity Curve and the Preferred Viewing Distance at a Visual Display as an Indicator of Near Vision Fatigue},\n volume = {79},\n year = {2002}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:70bf1f3727ee8a3d205861487b7762a3308e7793",
            "@type": "ScholarlyArticle",
            "paperId": "70bf1f3727ee8a3d205861487b7762a3308e7793",
            "corpusId": 6459836,
            "url": "https://www.semanticscholar.org/paper/70bf1f3727ee8a3d205861487b7762a3308e7793",
            "title": "Tone reproduction for realistic images",
            "venue": "IEEE Computer Graphics and Applications",
            "publicationVenue": {
                "id": "urn:research:0bf2c493-a93b-464a-b3d9-e18fbb4a7965",
                "name": "IEEE Computer Graphics and Applications",
                "alternate_names": [
                    "IEEE Comput Graph Appl"
                ],
                "issn": "0272-1716",
                "url": "http://www.computer.org/cga/"
            },
            "year": 1993,
            "externalIds": {
                "DBLP": "journals/cga/TumblinR93",
                "MAG": "2116057693",
                "DOI": "10.1109/38.252554",
                "CorpusId": 6459836
            },
            "abstract": "Radiosity and other global illumination methods for image synthesis calculate the real world radiance values of a scene instead of the display radiance values that will represent them. Though radiosity and ray tracing methods can compute extremely accurate and wide-ranging scene radiances, modern display devices emit light only in a tiny fixed range. The radiances must be converted, but ad-hoc conversions cause serious errors and give little assurance that the evoked visual sensations are truly equivalent. Sensation-preserving conversions for display, already known in photography, printing, and television as tone reproduction methods, are discussed. Computer graphics workers can apply the existing photographic methods, but may also extend them to include more complex and subtle effects of human vision using the published findings of vision researchers. Ways of constructing a sensation-preserving display converter, or tone reproduction operator, for monochrome images are demonstrated.<<ETX>>",
            "referenceCount": 10,
            "citationCount": 569,
            "influentialCitationCount": 32,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1993-11-01",
            "journal": {
                "name": "IEEE Computer Graphics and Applications",
                "volume": "13"
            },
            "citationStyles": {
                "bibtex": "@Article{Tumblin1993ToneRF,\n author = {J. Tumblin and H. Rushmeier},\n booktitle = {IEEE Computer Graphics and Applications},\n journal = {IEEE Computer Graphics and Applications},\n pages = {42-48},\n title = {Tone reproduction for realistic images},\n volume = {13},\n year = {1993}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7bc70f23189bf8a5a849ad81a6320948d425418f",
            "@type": "ScholarlyArticle",
            "paperId": "7bc70f23189bf8a5a849ad81a6320948d425418f",
            "corpusId": 2186746,
            "url": "https://www.semanticscholar.org/paper/7bc70f23189bf8a5a849ad81a6320948d425418f",
            "title": "3D distance fields: a survey of techniques and applications",
            "venue": "IEEE Transactions on Visualization and Computer Graphics",
            "publicationVenue": {
                "id": "urn:research:5e1f6444-5d03-48c7-b202-7f47d492aeae",
                "name": "IEEE Transactions on Visualization and Computer Graphics",
                "alternate_names": [
                    "IEEE Trans Vis Comput Graph"
                ],
                "issn": "1077-2626",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=2945"
            },
            "year": 2006,
            "externalIds": {
                "MAG": "2122851913",
                "DBLP": "journals/tvcg/JonesBS06",
                "DOI": "10.1109/TVCG.2006.56",
                "CorpusId": 2186746,
                "PubMed": "16805266"
            },
            "abstract": "A distance field is a representation where, at each point within the field, we know the distance from that point to the closest point on any object within the domain. In addition to distance, other properties may be derived from the distance field, such as the direction to the surface, and when the distance field is signed, we may also determine if the point is internal or external to objects within the domain. The distance field has been found to be a useful construction within the areas of computer vision, physics, and computer graphics. This paper serves as an exposition of methods for the production of distance fields, and a review of alternative representations and applications of distance fields. In the course of this paper, we present various methods from all three of the above areas, and we answer pertinent questions such as How accurate are these methods compared to each other? How simple are they to implement?, and What is the complexity and runtime of such methods?.",
            "referenceCount": 160,
            "citationCount": 406,
            "influentialCitationCount": 20,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www2.imm.dtu.dk/pubdb/edoc/imm4145.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle",
                "Study"
            ],
            "publicationDate": "2006-07-01",
            "journal": {
                "name": "IEEE Transactions on Visualization and Computer Graphics",
                "volume": "12"
            },
            "citationStyles": {
                "bibtex": "@Article{Jones20063DDF,\n author = {Mark W. Jones and J. A. B\u00e6rentzen and M. Sr\u00e1mek},\n booktitle = {IEEE Transactions on Visualization and Computer Graphics},\n journal = {IEEE Transactions on Visualization and Computer Graphics},\n pages = {581-599},\n title = {3D distance fields: a survey of techniques and applications},\n volume = {12},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1f87b2767b276fedf68db36616ba575deb02f571",
            "@type": "ScholarlyArticle",
            "paperId": "1f87b2767b276fedf68db36616ba575deb02f571",
            "corpusId": 6699480,
            "url": "https://www.semanticscholar.org/paper/1f87b2767b276fedf68db36616ba575deb02f571",
            "title": "Measuring Curved Surfaces for Robot Vision",
            "venue": "Computer",
            "publicationVenue": {
                "id": "urn:research:f6572f66-2623-4a5e-b0d9-4a5028dea98f",
                "name": "Computer",
                "alternate_names": [
                    "IEEE Computer",
                    "IEEE Comput"
                ],
                "issn": "0018-9162",
                "url": "http://www.computer.org/computer"
            },
            "year": 1982,
            "externalIds": {
                "DBLP": "journals/computer/HallTMS82",
                "MAG": "1901244654",
                "DOI": "10.1109/MC.1982.1653915",
                "CorpusId": 6699480
            },
            "abstract": "A new industrial revolution is in the making, produced by a marriage of two versatile technologies, the computer and the robot. This combination of control and manipulation produces a machine with enormous potential for performing useful tasks-yet such potential has not been fully realized. One way to improve the capabilities of current industrial robots is to add visual sensors. Robots that are deaf or dumb or that have no sense of force or touch perform only manually trainable tasks that can be dangerous in some working environments. Many applications call for an \"intelligent\" robot, a stand-alone machine-usually with its own visual, contact, or auditory sensory perception system-that can detect changes in its work environment and adapt to them. Such a detection process requires a large number of computations on the sensory data to distinguish features, recognize patterns, or compare input data with logical expectations. With the low cost of microprocessors and the increasing use of dedicated computers, intelligent systems for robots are becoming more and more sophisticated,\"2 and we have no shortage of potential applications: sensorybased robots can be used in space exploration, deep-sea mining, and industrial automation, for example.3'4 Computer vision, the collection of techniques, software, and hardware for measurements and inferences from images,3,6 appears to offer the richest source of sensory information for intelligent robotic manipulation in the greatest number of environments. A simple computer vision system usually consists of an image-processing unit interfaced with a minicomputer or mainframe,' but many kinds of systems are available, some for as little as $5000.8 However, most of these are low-level processing systems,9\"10 consisting of image acquisition, edge detection, feature extraction, template matching, and object recognition.* High-level processing is time consuming, since it requires a lot of computation. Nevertheless, image-processing algorithms can be implemented on minicomputers or mainframes.'3 In fact, imaging devices have been widely used in many automated visual inspection systems to perform pattern recognition and image processing for a specific task.'4\"l5 This article describes a technique that uses a recorded image of a projected pattern to measure 3-D surface points on simple, curved objects. The measured points are then fit to a quadric surface equation from which location, orientation, and surface recognition are extracted. For many man-made objects, this extracted information is sufficient to permit a robot hand to pick up the object, and results indicate that curved, featureless objects can be located.",
            "referenceCount": 44,
            "citationCount": 235,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1982-12-01",
            "journal": {
                "name": "Computer",
                "volume": "15"
            },
            "citationStyles": {
                "bibtex": "@Article{Hall1982MeasuringCS,\n author = {E. Hall and J. Tio and C. McPherson and F. Sadjadi},\n booktitle = {Computer},\n journal = {Computer},\n pages = {42-54},\n title = {Measuring Curved Surfaces for Robot Vision},\n volume = {15},\n year = {1982}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d0fabb120db2471edafcf4b3a63977e4be032b4f",
            "@type": "ScholarlyArticle",
            "paperId": "d0fabb120db2471edafcf4b3a63977e4be032b4f",
            "corpusId": 3138078,
            "url": "https://www.semanticscholar.org/paper/d0fabb120db2471edafcf4b3a63977e4be032b4f",
            "title": "Visual Persuasion: Inferring Communicative Intents of Images",
            "venue": "2014 IEEE Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "conf/cvpr/JooLSZ14",
                "MAG": "2073775149",
                "DOI": "10.1109/CVPR.2014.35",
                "CorpusId": 3138078
            },
            "abstract": "In this paper we introduce the novel problem of understanding visual persuasion. Modern mass media make extensive use of images to persuade people to make commercial and political decisions. These effects and techniques are widely studied in the social sciences, but behavioral studies do not scale to massive datasets. Computer vision has made great strides in building syntactical representations of images, such as detection and identification of objects. However, the pervasive use of images for communicative purposes has been largely ignored. We extend the significant advances in syntactic analysis in computer vision to the higher-level challenge of understanding the underlying communicative intent implied in images. We begin by identifying nine dimensions of persuasive intent latent in images of politicians, such as \"socially dominant, \" \"energetic, \" and \"trustworthy, \" and propose a hierarchical model that builds on the layer of syntactical attributes, such as \"smile\" and \"waving hand, \" to predict the intents presented in the images. To facilitate progress, we introduce a new dataset of 1, 124 images of politicians labeled with ground-truth intents in the form of rankings. This study demonstrates that a systematic focus on visual persuasion opens up the field of computer vision to a new class of investigations around mediated images, intersecting with media analysis, psychology, and political communication.",
            "referenceCount": 27,
            "citationCount": 107,
            "influentialCitationCount": 9,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.stat.ucla.edu/%7Esczhu/papers/Conf_2014/visual_persuasion_cvpr14.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2014-06-23",
            "journal": {
                "name": "2014 IEEE Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Joo2014VisualPI,\n author = {Jungseock Joo and Weixin Li and Francis F. Steen and Song-Chun Zhu},\n booktitle = {2014 IEEE Conference on Computer Vision and Pattern Recognition},\n journal = {2014 IEEE Conference on Computer Vision and Pattern Recognition},\n pages = {216-223},\n title = {Visual Persuasion: Inferring Communicative Intents of Images},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e8879195403e95fdc4b9dd0be80ccb9db4151200",
            "@type": "ScholarlyArticle",
            "paperId": "e8879195403e95fdc4b9dd0be80ccb9db4151200",
            "corpusId": 18684416,
            "url": "https://www.semanticscholar.org/paper/e8879195403e95fdc4b9dd0be80ccb9db4151200",
            "title": "A Probabilistic Approach to Robust Matrix Factorization",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2012,
            "externalIds": {
                "MAG": "199797433",
                "DBLP": "conf/eccv/WangYWY12",
                "DOI": "10.1007/978-3-642-33786-4_10",
                "CorpusId": 18684416
            },
            "abstract": null,
            "referenceCount": 17,
            "citationCount": 170,
            "influentialCitationCount": 30,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/978-3-642-33786-4_10.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2012-10-07",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2012APA,\n author = {Naiyan Wang and Tiansheng Yao and Jingdong Wang and D. Yeung},\n booktitle = {European Conference on Computer Vision},\n pages = {126-139},\n title = {A Probabilistic Approach to Robust Matrix Factorization},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b0ce65e04b1583f6e37536a828cf6799884ca43c",
            "@type": "ScholarlyArticle",
            "paperId": "b0ce65e04b1583f6e37536a828cf6799884ca43c",
            "corpusId": 3520757,
            "url": "https://www.semanticscholar.org/paper/b0ce65e04b1583f6e37536a828cf6799884ca43c",
            "title": "TUIO: A Protocol for Table-Top Tangible User Interfaces",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "MAG": "1481476279",
                "CorpusId": 3520757
            },
            "abstract": "In this article we present Tuio, a simple yet versatile protocol designed specifically to meet the requirements of table-top tangible user interfaces. Inspired by the idea of interconnecting various existing table interfaces such as the reacTable* , being developed in Barcelona and the tDesk from Bielefeld, this protocol defines common properties of controller objects on the table surface as well as of finger and hand gestures performed by the user. Currently this protocol has been implemented within a fiducial marker-based computer vision engine developed for the reacTable* project. This fast and robust computer vision engine is based on the original d-touch concept, which is also included as an alternative to the newer fiducial tracking engine. The computer vision framework has been implemented on various standard platforms and can be extended with additional sensor components. We are currently working on the tracking of finger-tips for gestural control within the table interface. The Tuio protocol has been implemented using OpenSound Control [4] and is therefore usable on any platform supporting this protocol. At the moment we have working implementations for Java, C++, PureData, Max/MSP, SuperCollider and Flash.",
            "referenceCount": 5,
            "citationCount": 353,
            "influentialCitationCount": 37,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2005-05-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Kaltenbrunner2005TUIOAP,\n author = {Martin Kaltenbrunner and Till Bovermann and Ross Bencina and Enrico Costanza},\n title = {TUIO: A Protocol for Table-Top Tangible User Interfaces},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bef862006a045d846d716346b0d27d3ca6cbf21b",
            "@type": "ScholarlyArticle",
            "paperId": "bef862006a045d846d716346b0d27d3ca6cbf21b",
            "corpusId": 13900471,
            "url": "https://www.semanticscholar.org/paper/bef862006a045d846d716346b0d27d3ca6cbf21b",
            "title": "Dynamic Eye Movement Datasets and Learnt Saliency Models for Visual Action Recognition",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2012,
            "externalIds": {
                "MAG": "33363299",
                "DBLP": "conf/eccv/MatheS12",
                "DOI": "10.1007/978-3-642-33709-3_60",
                "CorpusId": 13900471
            },
            "abstract": null,
            "referenceCount": 33,
            "citationCount": 164,
            "influentialCitationCount": 24,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2012-10-07",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Mathe2012DynamicEM,\n author = {Stefan Mathe and C. Sminchisescu},\n booktitle = {European Conference on Computer Vision},\n pages = {842-856},\n title = {Dynamic Eye Movement Datasets and Learnt Saliency Models for Visual Action Recognition},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9d896605fbf93315b68d4ee03be0770077f84e40",
            "@type": "ScholarlyArticle",
            "paperId": "9d896605fbf93315b68d4ee03be0770077f84e40",
            "corpusId": 18124397,
            "url": "https://www.semanticscholar.org/paper/9d896605fbf93315b68d4ee03be0770077f84e40",
            "title": "Baby Talk: Understanding and Generating Image Descriptions",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2011,
            "externalIds": {
                "CorpusId": 18124397
            },
            "abstract": "We posit that visually descriptive language offers computer vision researchers both information about the world, and information about how people describe the world. The potential bene\ufb01t from this source is made more signi\ufb01cant due to the enormous amount of language data easily available today. We present a system to automatically generate natural language descriptions from images that exploits both statistics gleaned from parsing large quantities of text data and recognition algorithms from computer vision. The system is very effective at producing relevant sentences for images. It also generates descriptions that are notably more true to the speci\ufb01c image content than previous work",
            "referenceCount": 26,
            "citationCount": 215,
            "influentialCitationCount": 15,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Kulkarni2011BabyTU,\n author = {Girish Kulkarni and Visruth Premraj and Sagnik Dhar and Siming Li and Yejin Choi and A. Berg and Tamara L. Berg},\n title = {Baby Talk: Understanding and Generating Image Descriptions},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b8bb7f5e411a15255f7fb13a851435346cc14e98",
            "@type": "ScholarlyArticle",
            "paperId": "b8bb7f5e411a15255f7fb13a851435346cc14e98",
            "corpusId": 8670199,
            "url": "https://www.semanticscholar.org/paper/b8bb7f5e411a15255f7fb13a851435346cc14e98",
            "title": "The computer image",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1998,
            "externalIds": {
                "DBLP": "books/daglib/0095341",
                "MAG": "1578374945",
                "CorpusId": 8670199
            },
            "abstract": "Computer images are everywhere, occupying a dominant part of the \n \ncomputer culture and now rivaling their analogue cousin the TV image \n \nin popularity, a process bound to increase with the advent of digital \n \nTV. This book is about the computer image, emphasizing the 'how', but \n \nalso addressing the 'whys' and 'wherefores' of this creation of the \n \n20th century. Where did it come from? Where is it going? What is its \n \nimportance? These questions cannot be answered without a knowledge of \n \nthe technology itself, its past and its evolutionary forces. \n \nThe three main fields of computer imagery - Computer graphics, image \n \nProcessing and Computer vision - are merging in many \n \napplications. Computer Vision techniques are used in computer graphics \n \nto collect and model complex scenes; computer graphics techniques are \n \nused to constrain the recognition of 3D objects by computers; image \n \nprocessing techniques are routinely used by graphic designers to \n \nmanipulate photographs. For the first time this textbook brings all \n \nthree areas together in a coherent overview. \n \nSpecial features \n \nUnique breadth of coverage of subjects that have previously only appeared in separate texts. \n \nNovel treatment of the moving image, Virtual reality, medical imaging and computer art. \n \nPackaged with the book is a CD-ROM that provides implementations of many of the techniques described in the book. \n \nThe CD-ROM contains scene files, animation demonstrations, a complete set of all the images used in the book and a suite of programs. \n \nThe software can be used for teaching, experimentation and the development of an application package. \n \nThe source code is written in C++. \n \nThe software includes a Z-buffer renderer, a distributed ray tracer, a radiosity renderer, an image processing module containing all the normal filtering facilities and transforms, morphing and warping software particle/elastic object simulation with collision detection, a progressive image compressor using wavelets (including a Java, ActiveX, OLE, 3DSMAX plugin), stereo and autostereogram generator, modeling software (including a Bezier modeller and a rnesh optimizer), computer vision software including depth from stereo, (low field estimation, object tracking and classification of satelliteimagery.",
            "referenceCount": 0,
            "citationCount": 130,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Watt1998TheCI,\n author = {A. Watt and F. Policarpo},\n pages = {I-XXXI, 1-751},\n title = {The computer image},\n year = {1998}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c416a885cc36515740ef8dfa9220366fa2a379f8",
            "@type": "ScholarlyArticle",
            "paperId": "c416a885cc36515740ef8dfa9220366fa2a379f8",
            "corpusId": 62198913,
            "url": "https://www.semanticscholar.org/paper/c416a885cc36515740ef8dfa9220366fa2a379f8",
            "title": "Measurement of Visual Motion",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1984,
            "externalIds": {
                "MAG": "2075611125",
                "DOI": "10.1007/978-3-642-68888-1_11",
                "CorpusId": 62198913
            },
            "abstract": null,
            "referenceCount": 56,
            "citationCount": 667,
            "influentialCitationCount": 23,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dspace.mit.edu/bitstream/1721.1/45554/1/AIM-699.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1984-04-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Hildreth1984MeasurementOV,\n author = {E. Hildreth},\n title = {Measurement of Visual Motion},\n year = {1984}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2bfeba9520e674cc31cc1748aad273ff5ce7f054",
            "@type": "ScholarlyArticle",
            "paperId": "2bfeba9520e674cc31cc1748aad273ff5ce7f054",
            "corpusId": 8249908,
            "url": "https://www.semanticscholar.org/paper/2bfeba9520e674cc31cc1748aad273ff5ce7f054",
            "title": "Simultaneous dimensionality reduction and human age estimation via kernel partial least squares regression",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2011,
            "externalIds": {
                "DBLP": "conf/cvpr/GuoM11",
                "MAG": "2146656095",
                "DOI": "10.1109/CVPR.2011.5995404",
                "CorpusId": 8249908
            },
            "abstract": "Human age estimation has recently become an active research topic in computer vision and pattern recognition, because of many potential applications in reality. In this paper we propose to use the kernel partial least squares (KPLS) regression for age estimation. The KPLS (or linear PLS) method has several advantages over previous approaches: (1) the KPLS can reduce feature dimensionality and learn the aging function simultaneously in a single learning framework, instead of performing each task separately using different techniques; (2) the KPLS can find a small number of latent variables, e.g., 20, to project thousands of features into a very low-dimensional subspace, which may have great impact on real-time applications; and (3) the KPLS regression has an output vector that can contain multiple labels, so that several related problems, e.g., age estimation, gender classification, and ethnicity estimation can be solved altogether. This is the first time that the kernel PLS method is introduced and applied to solve a regression problem in computer vision with high accuracy. Experimental results on a very large database show that the KPLS is significantly better than the popular SVM method, and outperform the state-of-the-art approaches in human age estimation.",
            "referenceCount": 36,
            "citationCount": 212,
            "influentialCitationCount": 22,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.cs.wisc.edu/%7Egdguo/myPapersOnWeb/CVPR11Guo.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2011-06-20",
            "journal": {
                "name": "CVPR 2011",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Guo2011SimultaneousDR,\n author = {G. Guo and Guowang Mu},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {CVPR 2011},\n pages = {657-664},\n title = {Simultaneous dimensionality reduction and human age estimation via kernel partial least squares regression},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:22894791cb1e139177cef3fbb1ebda417a4b549f",
            "@type": "ScholarlyArticle",
            "paperId": "22894791cb1e139177cef3fbb1ebda417a4b549f",
            "corpusId": 37185411,
            "url": "https://www.semanticscholar.org/paper/22894791cb1e139177cef3fbb1ebda417a4b549f",
            "title": "Attentive Systems: A Survey",
            "venue": "International Journal of Computer Vision",
            "publicationVenue": {
                "id": "urn:research:939ee07c-6009-43f8-b884-69238b40659e",
                "name": "International Journal of Computer Vision",
                "alternate_names": [
                    "Int J Comput Vis"
                ],
                "issn": "0920-5691",
                "url": "https://www.springer.com/computer/image+processing/journal/11263"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2756464018",
                "DBLP": "journals/ijcv/NguyenZY18",
                "DOI": "10.1007/s11263-017-1042-6",
                "CorpusId": 37185411
            },
            "abstract": null,
            "referenceCount": 215,
            "citationCount": 69,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "International Journal of Computer Vision",
                "volume": "126"
            },
            "citationStyles": {
                "bibtex": "@Article{Nguyen2017AttentiveSA,\n author = {Tam V. Nguyen and Qi Zhao and Shuicheng Yan},\n booktitle = {International Journal of Computer Vision},\n journal = {International Journal of Computer Vision},\n pages = {86-110},\n title = {Attentive Systems: A Survey},\n volume = {126},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5d7319332cd05ee3afadb872cb2ab153f9172679",
            "@type": "ScholarlyArticle",
            "paperId": "5d7319332cd05ee3afadb872cb2ab153f9172679",
            "corpusId": 1243044,
            "url": "https://www.semanticscholar.org/paper/5d7319332cd05ee3afadb872cb2ab153f9172679",
            "title": "A Streakline Representation of Flow in Crowded Scenes",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2010,
            "externalIds": {
                "DBLP": "conf/eccv/MehranMS10",
                "MAG": "1886885333",
                "DOI": "10.1007/978-3-642-15558-1_32",
                "CorpusId": 1243044
            },
            "abstract": null,
            "referenceCount": 25,
            "citationCount": 217,
            "influentialCitationCount": 32,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/978-3-642-15558-1_32.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2010-09-05",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Mehran2010ASR,\n author = {Ramin Mehran and Brian E. Moore and M. Shah},\n booktitle = {European Conference on Computer Vision},\n pages = {439-452},\n title = {A Streakline Representation of Flow in Crowded Scenes},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:33ca9c265a112f09544e4d368b83e53cea094260",
            "@type": "ScholarlyArticle",
            "paperId": "33ca9c265a112f09544e4d368b83e53cea094260",
            "corpusId": 5247846,
            "url": "https://www.semanticscholar.org/paper/33ca9c265a112f09544e4d368b83e53cea094260",
            "title": "A Closed-Form Solution to Non-Rigid Shape and Motion Recovery",
            "venue": "International Journal of Computer Vision",
            "publicationVenue": {
                "id": "urn:research:939ee07c-6009-43f8-b884-69238b40659e",
                "name": "International Journal of Computer Vision",
                "alternate_names": [
                    "Int J Comput Vis"
                ],
                "issn": "0920-5691",
                "url": "https://www.springer.com/computer/image+processing/journal/11263"
            },
            "year": 2004,
            "externalIds": {
                "MAG": "1965581703",
                "DBLP": "conf/eccv/XiaoCK04",
                "DOI": "10.1007/s11263-005-3962-9",
                "CorpusId": 5247846
            },
            "abstract": null,
            "referenceCount": 30,
            "citationCount": 364,
            "influentialCitationCount": 43,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://figshare.com/articles/journal_contribution/A_closed-form_solution_to_non-rigid_shape_and_motion_recovery/6549983/1/files/12028697.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2004-05-11",
            "journal": {
                "name": "International Journal of Computer Vision",
                "volume": "67"
            },
            "citationStyles": {
                "bibtex": "@Article{Xiao2004ACS,\n author = {Jing Xiao and Jinxiang Chai and T. Kanade},\n booktitle = {International Journal of Computer Vision},\n journal = {International Journal of Computer Vision},\n pages = {233-246},\n title = {A Closed-Form Solution to Non-Rigid Shape and Motion Recovery},\n volume = {67},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b3b5e58834eb0b1bca690d5cb02f53ed1e565581",
            "@type": "ScholarlyArticle",
            "paperId": "b3b5e58834eb0b1bca690d5cb02f53ed1e565581",
            "corpusId": 207319519,
            "url": "https://www.semanticscholar.org/paper/b3b5e58834eb0b1bca690d5cb02f53ed1e565581",
            "title": "The Maximum Consensus Problem: Recent Algorithmic Advances",
            "venue": "Synthesis Lectures on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:9724feeb-fb28-4443-898c-3c5964ded7ea",
                "name": "Synthesis Lectures on Computer Vision",
                "alternate_names": [
                    "Synth Lect Comput Vis"
                ],
                "issn": "2153-1064",
                "url": "https://www.morganclaypool.com/toc/cov/1/1"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "series/synthesis/2017Chin",
                "MAG": "2593721734",
                "DOI": "10.2200/S00757ED1V01Y201702COV011",
                "CorpusId": 207319519
            },
            "abstract": "Outlier-contaminated data is a fact of life in computer vision. For computer vision applications to perform reliably and accurately in practical settings, the processing of the input data must be conducted in a robust manner. In this context, the maximum consensus robust criterion plays a critical role by allowing the quantity of interest to be estimated from noisy and outlier-prone visual measurements. The maximum consensus problem refers to the problem of optimizing the quantity of interest according to the maximum consensus criterion. This book provides an overview of the algorithms for performing this optimization. The emphasis is on the basic operation or \"inner workings\" of the algorithms, and on their mathematical characteristics in terms of optimality and efficiency. The applicability of the techniques to common computer vision tasks is also highlighted. By collecting existing techniques in a single article, this book aims to trigger further developments in this theoretically interesting and practically important area.",
            "referenceCount": 101,
            "citationCount": 64,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/bfm:978-3-031-01818-3/1?pdf=chapter%20toc",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2017-02-27",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Chin2017TheMC,\n author = {Tat-Jun Chin and D. Suter},\n booktitle = {Synthesis Lectures on Computer Vision},\n title = {The Maximum Consensus Problem: Recent Algorithmic Advances},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f68227537e21ac8315a130bc022387ee6da931be",
            "@type": "ScholarlyArticle",
            "paperId": "f68227537e21ac8315a130bc022387ee6da931be",
            "corpusId": 5494636,
            "url": "https://www.semanticscholar.org/paper/f68227537e21ac8315a130bc022387ee6da931be",
            "title": "Time-of-Flight Cameras",
            "venue": "SpringerBriefs in Computer Science",
            "publicationVenue": {
                "id": "urn:research:f67df39a-b9ec-4fb6-aae0-b492b0bd6854",
                "name": "SpringerBriefs in Computer Science",
                "alternate_names": [
                    "Springerbriefs Comput Sci"
                ],
                "issn": "2191-5768",
                "url": "https://www.springer.com/series/10028"
            },
            "year": 2012,
            "externalIds": {
                "DBLP": "books/daglib/0030699",
                "MAG": "2944129199",
                "DOI": "10.1007/978-1-4471-4658-2",
                "CorpusId": 5494636
            },
            "abstract": null,
            "referenceCount": 73,
            "citationCount": 184,
            "influentialCitationCount": 1,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://hal.inria.fr/hal-00725654/file/TOF.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2012-11-07",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Hansard2012TimeofFlightC,\n author = {M. Hansard and Seungkyu Lee and O. Choi and R. Horaud},\n booktitle = {SpringerBriefs in Computer Science},\n pages = {I-X, 1-96},\n title = {Time-of-Flight Cameras},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:22ec32ab1494698e25aa895092203cb71864b742",
            "@type": "ScholarlyArticle",
            "paperId": "22ec32ab1494698e25aa895092203cb71864b742",
            "corpusId": 15541088,
            "url": "https://www.semanticscholar.org/paper/22ec32ab1494698e25aa895092203cb71864b742",
            "title": "LabelMe: Online Image Annotation and Applications",
            "venue": "Proceedings of the IEEE",
            "publicationVenue": {
                "id": "urn:research:6faaccca-1cc4-45a9-aeb6-96a4901d2606",
                "name": "Proceedings of the IEEE",
                "alternate_names": [
                    "Proc IEEE"
                ],
                "issn": "0018-9219",
                "url": "http://www.ieee.org/portal/pages/pubs/proceedings/"
            },
            "year": 2010,
            "externalIds": {
                "DBLP": "journals/pieee/TorralbaRY10",
                "MAG": "2064985253",
                "DOI": "10.1109/JPROC.2010.2050290",
                "CorpusId": 15541088
            },
            "abstract": "Central to the development of computer vision systems is the collection and use of annotated images spanning our visual world. Annotations may include information about the identity, spatial extent, and viewpoint of the objects present in a depicted scene. Such a database is useful for the training and evaluation of computer vision systems. Motivated by the availability of images on the Internet, we introduced a web-based annotation tool that allows online users to label objects and their spatial extent in images. To date, we have collected over 400 000 annotations that span a variety of different scene and object classes. In this paper, we show the contents of the database, its growth over time, and statistics of its usage. In addition, we explore and survey applications of the database in the areas of computer vision and computer graphics. Particularly, we show how to extract the real-world 3-D coordinates of images in a variety of scenes using only the user-provided object annotations. The output 3-D information is comparable to the quality produced by a laser range scanner. We also characterize the space of the images in the database by analyzing 1) statistics of the co-occurrence of large objects in the images and 2) the spatial layout of the labeled images.",
            "referenceCount": 100,
            "citationCount": 219,
            "influentialCitationCount": 14,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dspace.mit.edu/bitstream/1721.1/61984/1/Torralba_LabelMe%20online.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2010-06-10",
            "journal": {
                "name": "Proceedings of the IEEE",
                "volume": "98"
            },
            "citationStyles": {
                "bibtex": "@Article{Torralba2010LabelMeOI,\n author = {A. Torralba and Bryan C. Russell and Jenny Yuen},\n booktitle = {Proceedings of the IEEE},\n journal = {Proceedings of the IEEE},\n pages = {1467-1484},\n title = {LabelMe: Online Image Annotation and Applications},\n volume = {98},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ea7a97f58d5256060997a29d1c7f7c7a7a39c2e0",
            "@type": "ScholarlyArticle",
            "paperId": "ea7a97f58d5256060997a29d1c7f7c7a7a39c2e0",
            "corpusId": 40656135,
            "url": "https://www.semanticscholar.org/paper/ea7a97f58d5256060997a29d1c7f7c7a7a39c2e0",
            "title": "Image and Video-Based Artistic Stylisation",
            "venue": "Computational Imaging and Vision",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2012,
            "externalIds": {
                "MAG": "2288799730",
                "DBLP": "books/daglib/0031313",
                "DOI": "10.1007/978-1-4471-4519-6",
                "CorpusId": 40656135
            },
            "abstract": null,
            "referenceCount": 415,
            "citationCount": 137,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/bfm:978-1-4471-4519-6/1?pdf=chapter%20toc",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Art",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2012-10-30",
            "journal": {
                "name": "Computational Imaging and Vision",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Rosin2012ImageAV,\n author = {Paul L. Rosin and J. Collomosse},\n booktitle = {Computational Imaging and Vision},\n journal = {Computational Imaging and Vision},\n title = {Image and Video-Based Artistic Stylisation},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5dc6dd914273759c0da208260ffebe827df228ea",
            "@type": "ScholarlyArticle",
            "paperId": "5dc6dd914273759c0da208260ffebe827df228ea",
            "corpusId": 14443939,
            "url": "https://www.semanticscholar.org/paper/5dc6dd914273759c0da208260ffebe827df228ea",
            "title": "Symmetry Detection from RealWorld Images Competition 2013: Summary and Results",
            "venue": "2013 IEEE Conference on Computer Vision and Pattern Recognition Workshops",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2013,
            "externalIds": {
                "DBLP": "conf/cvpr/LiuSZWPLRL13",
                "MAG": "1981078224",
                "DOI": "10.1109/CVPRW.2013.155",
                "CorpusId": 14443939
            },
            "abstract": "Symmetry is a pervasive phenomenon presenting itself in all forms and scales in natural and manmade environments. Its detection plays an essential role at all levels of human as well as machine perception. The recent resurging interest in computational symmetry for computer vision and computer graphics applications has motivated us to conduct a US NSF funded symmetry detection algorithm competition as a workshop affiliated with the Computer Vision and Pattern Recognition (CVPR) Conference, 2013. This competition sets a more complete benchmark for computer vision symmetry detection algorithms. In this report we explain the evaluation metric and the automatic execution of the evaluation workflow. We also present and analyze the algorithms submitted, and show their results on three test sets of real world images depicting reflection, rotation and translation symmetries respectively. This competition establishes a performance baseline for future work on symmetry detection.",
            "referenceCount": 9,
            "citationCount": 79,
            "influentialCitationCount": 17,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2013-06-23",
            "journal": {
                "name": "2013 IEEE Conference on Computer Vision and Pattern Recognition Workshops",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Liu2013SymmetryDF,\n author = {Jingchen Liu and George M. Slota and Gang Zheng and Zhaohui Wu and Minwoo Park and Seungkyu Lee and Ingmar Rauschert and Yanxi Liu},\n booktitle = {2013 IEEE Conference on Computer Vision and Pattern Recognition Workshops},\n journal = {2013 IEEE Conference on Computer Vision and Pattern Recognition Workshops},\n pages = {200-205},\n title = {Symmetry Detection from RealWorld Images Competition 2013: Summary and Results},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:529c2c9c0d3aec9a2facd4df453bf72d4da623dc",
            "@type": "ScholarlyArticle",
            "paperId": "529c2c9c0d3aec9a2facd4df453bf72d4da623dc",
            "corpusId": 6284859,
            "url": "https://www.semanticscholar.org/paper/529c2c9c0d3aec9a2facd4df453bf72d4da623dc",
            "title": "Back to the Future: Learning Shape Models from 3D CAD Data",
            "venue": "British Machine Vision Conference",
            "publicationVenue": {
                "id": "urn:research:78a7fbcc-41c5-4258-b633-04b8637d4a9f",
                "name": "British Machine Vision Conference",
                "alternate_names": [
                    "Br Mach Vis Conf",
                    "BMVC"
                ],
                "issn": null,
                "url": "http://www.bmva.org/bmvc/"
            },
            "year": 2010,
            "externalIds": {
                "MAG": "2165741220",
                "DBLP": "conf/bmvc/StarkGS10",
                "DOI": "10.5244/C.24.106",
                "CorpusId": 6284859
            },
            "abstract": "Recognizing 3D objects from arbitrary view points is one of the most fundamental problems in computer vision. A major challenge lies in the transition between the 3D geometry of objects and 2D representations that can be robustly matched to natural images. Most approaches thus rely on 2D natural images either as the sole source of training data for building an implicit 3D representation, or by enriching 3D models with natural image features. In this paper, we go back to the ideas from the early days of computer vision, by using 3D object models as the only source of information for building a multi-view object class detector. In particular, we use these models for learning 2D shape that can be robustly matched to 2D natural images. Our experiments confirm the validity of our approach, which outperforms current state-of-the-art techniques on a multi-view detection data set.",
            "referenceCount": 31,
            "citationCount": 176,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.bmva.org/bmvc/2010/conference/paper106/paper106.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Stark2010BackTT,\n author = {Michael Stark and M. Goesele and B. Schiele},\n booktitle = {British Machine Vision Conference},\n pages = {1-11},\n title = {Back to the Future: Learning Shape Models from 3D CAD Data},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3928cddb421ab47e8f057d74662405beebf2623d",
            "@type": "ScholarlyArticle",
            "paperId": "3928cddb421ab47e8f057d74662405beebf2623d",
            "corpusId": 16036400,
            "url": "https://www.semanticscholar.org/paper/3928cddb421ab47e8f057d74662405beebf2623d",
            "title": "A mixed-state condensation tracker with automatic model-switching",
            "venue": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1998,
            "externalIds": {
                "DBLP": "conf/iccv/IsardB98",
                "MAG": "2120329636",
                "DOI": "10.1109/ICCV.1998.710707",
                "CorpusId": 16036400
            },
            "abstract": "There is considerable interest in the computer vision community in representing and modelling motion. Motion models are used as predictors to increase the robustness and accuracy of visual trackers, and as classifiers for gesture recognition. This paper presents a significant development of random sampling methods to allow automatic switching between multiple motion models as a natural extension of the tracking process. The Bayesian mixed-state framework is described in its generality, and the example of a bouncing ball is used to demonstrate that a mixed-state model can significantly improve tracking performance in heavy clutter. The relevance of the approach to the problem of gesture recognition is then investigated using a tracker which is able to follow the natural drawing action of a hand holding a pen, and switches state according to the hand's motion.",
            "referenceCount": 13,
            "citationCount": 399,
            "influentialCitationCount": 31,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1998-01-04",
            "journal": {
                "name": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Isard1998AMC,\n author = {M. Isard and A. Blake},\n booktitle = {Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)},\n journal = {Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)},\n pages = {107-112},\n title = {A mixed-state condensation tracker with automatic model-switching},\n year = {1998}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2fe5318c0a7f47e4a84c22608be17789293b784d",
            "@type": "ScholarlyArticle",
            "paperId": "2fe5318c0a7f47e4a84c22608be17789293b784d",
            "corpusId": 60608762,
            "url": "https://www.semanticscholar.org/paper/2fe5318c0a7f47e4a84c22608be17789293b784d",
            "title": "Handbook of Texture Analysis",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2008,
            "externalIds": {
                "MAG": "1553085054",
                "DOI": "10.1142/p547",
                "CorpusId": 60608762
            },
            "abstract": "Texture analysis is one of the fundamental aspects of human vision by which we discriminate between surfaces and objects. In a similar manner, computer vision can take advantage of the cues provided by surface texture to distinguish and recognize objects. In computer vision, texture analysis may be used alone or in combination with other sensed features (e.g. color, shape, or motion) to perform the task of recognition. Either way, it is a feature of paramount importance and boasts a tremendous body of work in terms of both research and applications.Currently, the main approaches to texture analysis must be sought out through a variety of research papers. This collection of chapters brings together in one handy volume the major topics of importance, and categorizes the various techniques into comprehensible concepts. The methods covered will not only be relevant to those working in computer vision, but will also be of benefit to the computer graphics, psychophysics, and pattern recognition communities, academic or industrial.",
            "referenceCount": 6,
            "citationCount": 252,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.gbv.de/dms/bowker/toc/9781848161153.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2008-08-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Mirmehdi2008HandbookOT,\n author = {M. Mirmehdi and Xianghua Xie and J. Suri},\n title = {Handbook of Texture Analysis},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a9b9866314054a7c8386bd44362e9034a0690007",
            "@type": "ScholarlyArticle",
            "paperId": "a9b9866314054a7c8386bd44362e9034a0690007",
            "corpusId": 15015096,
            "url": "https://www.semanticscholar.org/paper/a9b9866314054a7c8386bd44362e9034a0690007",
            "title": "ON IMAGE SEGMENTATION TECHNIQUES",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": null,
            "externalIds": {
                "CorpusId": 15015096
            },
            "abstract": "Digital image processing supports strong research program in areas of image enhancement and image based pattern recognition.Among the various image processing techniques image segmentation plays a vital role in step to analyze the given image. Image segmentation is the fundamental step to analyze images and extract data from them. This work deals on the basic principles on the methods used to segment an image. Segmentation has become a prominent objective in image analysis and computer vision. To segment the images, from segmentation techniques edge detection, thresholding, region growing and clustering are taken for this study. Segmentation algorithms are based on two properties similarity and discontinuity. This paper focuses on the various methods that are widely used to segment the image. I. INTRODUCTION Digital image processing is having many recent applications in the fields of remote sensing, medicine, photography, film and video production, security monitoring. New innovative technologies are emerging in the fields of image processing, especially in image segmentation domain.",
            "referenceCount": 13,
            "citationCount": 1965,
            "influentialCitationCount": 44,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Misc{None,\n author = {Kannan and G. Nalini},\n title = {ON IMAGE SEGMENTATION TECHNIQUES}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7edc86a04c69b43c05e8327db611d6ab0dd52c4d",
            "@type": "ScholarlyArticle",
            "paperId": "7edc86a04c69b43c05e8327db611d6ab0dd52c4d",
            "corpusId": 95006133,
            "url": "https://www.semanticscholar.org/paper/7edc86a04c69b43c05e8327db611d6ab0dd52c4d",
            "title": "Application of Image Analysis for Classification of Ripening Bananas",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2006,
            "externalIds": {
                "MAG": "2005013675",
                "DOI": "10.1111/J.1365-2621.2004.TB09932.X",
                "CorpusId": 95006133
            },
            "abstract": "ABSTRACT: A computer vision system was implemented to identify the ripening stages of bananas based on color, development of brown spots, and image texture information. Nine simple features of appearance (L*, a*, b* values; brown area percentage; number of brown spots per cm2; and homogeneity, contrast, correlation, and entropy of image texture) extracted from images of bananas were used for classification purposes. Results show that in spite of variations in data for color and appearance, a simple classification technique is as good to identify the ripening stages of bananas as professional visual perception. Using L*, a*, b* bands, brown area percentage, and contrast, it was possible to classify 49 banana samples in their 7 ripening stages with an accuracy of 98%. Computer vision shows promise for online prediction of ripening stages of bananas.",
            "referenceCount": 35,
            "citationCount": 273,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Agricultural and Food Sciences",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2006-05-31",
            "journal": {
                "name": "Journal of Food Science",
                "volume": "69"
            },
            "citationStyles": {
                "bibtex": "@Article{Mendoza2006ApplicationOI,\n author = {F. Mendoza and J. Aguilera},\n journal = {Journal of Food Science},\n pages = {28},\n title = {Application of Image Analysis for Classification of Ripening Bananas},\n volume = {69},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ea988103b8138ab6e36eca2cbde40bb9a5f54b69",
            "@type": "ScholarlyArticle",
            "paperId": "ea988103b8138ab6e36eca2cbde40bb9a5f54b69",
            "corpusId": 33989914,
            "url": "https://www.semanticscholar.org/paper/ea988103b8138ab6e36eca2cbde40bb9a5f54b69",
            "title": "A system for automated iris recognition",
            "venue": "Proceedings of 1994 IEEE Workshop on Applications of Computer Vision",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1994,
            "externalIds": {
                "DBLP": "conf/wacv/WildesAGHKMM94",
                "MAG": "2161872766",
                "DOI": "10.1109/ACV.1994.341298",
                "CorpusId": 33989914
            },
            "abstract": "This paper describes a prototype system for personnel verification based on automated iris recognition. The motivation for this endeavour stems from the observation that the human iris provides a particularly interesting structure on which to base a technology for noninvasive biometric measurement. In particular, it is known in the biomedical community that irises are as distinct as fingerprints or patterns of retinal blood vessels. Further, since the iris is an overt body its appearance is amenable to remote examination with the aid of a computer vision system. The body of this paper details the design and operation of such a system. Also presented are the results of an empirical study where the system exhibits flawless performance in the evaluation of 520 iris images.<<ETX>>",
            "referenceCount": 15,
            "citationCount": 421,
            "influentialCitationCount": 24,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1994-12-05",
            "journal": {
                "name": "Proceedings of 1994 IEEE Workshop on Applications of Computer Vision",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wildes1994ASF,\n author = {Richard P. Wildes and J. Asmuth and Gilbert L. Green and S. Hsu and R. Kolczynski and J. Matey and S. McBride},\n booktitle = {Proceedings of 1994 IEEE Workshop on Applications of Computer Vision},\n journal = {Proceedings of 1994 IEEE Workshop on Applications of Computer Vision},\n pages = {121-128},\n title = {A system for automated iris recognition},\n year = {1994}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5eeb3015008876cd2714f3301b8f7fe9bbc4b09d",
            "@type": "ScholarlyArticle",
            "paperId": "5eeb3015008876cd2714f3301b8f7fe9bbc4b09d",
            "corpusId": 4636468,
            "url": "https://www.semanticscholar.org/paper/5eeb3015008876cd2714f3301b8f7fe9bbc4b09d",
            "title": "Lie Bodies: A Manifold Representation of 3D Human Shape",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2012,
            "externalIds": {
                "MAG": "2109247271",
                "DBLP": "conf/eccv/FreifeldB12",
                "DOI": "10.1007/978-3-642-33718-5_1",
                "CorpusId": 4636468
            },
            "abstract": null,
            "referenceCount": 30,
            "citationCount": 102,
            "influentialCitationCount": 12,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007%2F978-3-642-33718-5_1.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2012-10-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Freifeld2012LieBA,\n author = {O. Freifeld and Michael J. Black},\n booktitle = {European Conference on Computer Vision},\n pages = {1-14},\n title = {Lie Bodies: A Manifold Representation of 3D Human Shape},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:32de7819a0f1701706f4199bea3b14d254c068a6",
            "@type": "ScholarlyArticle",
            "paperId": "32de7819a0f1701706f4199bea3b14d254c068a6",
            "corpusId": 16445051,
            "url": "https://www.semanticscholar.org/paper/32de7819a0f1701706f4199bea3b14d254c068a6",
            "title": "Hamilton-Jacobi Skeletons",
            "venue": "International Journal of Computer Vision",
            "publicationVenue": {
                "id": "urn:research:939ee07c-6009-43f8-b884-69238b40659e",
                "name": "International Journal of Computer Vision",
                "alternate_names": [
                    "Int J Comput Vis"
                ],
                "issn": "0920-5691",
                "url": "https://www.springer.com/computer/image+processing/journal/11263"
            },
            "year": 2002,
            "externalIds": {
                "DBLP": "journals/ijcv/SiddiqiBTZ02",
                "MAG": "1570514300",
                "DOI": "10.1023/A:1016376116653",
                "CorpusId": 16445051
            },
            "abstract": null,
            "referenceCount": 68,
            "citationCount": 306,
            "influentialCitationCount": 21,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2002-07-21",
            "journal": {
                "name": "International Journal of Computer Vision",
                "volume": "48"
            },
            "citationStyles": {
                "bibtex": "@Article{Siddiqi2002HamiltonJacobiS,\n author = {Kaleem Siddiqi and S. Bouix and A. Tannenbaum and S. Zucker},\n booktitle = {International Journal of Computer Vision},\n journal = {International Journal of Computer Vision},\n pages = {215-231},\n title = {Hamilton-Jacobi Skeletons},\n volume = {48},\n year = {2002}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5de9184007f305cb8fc6b8ebc95474a4cbc4cb94",
            "@type": "ScholarlyArticle",
            "paperId": "5de9184007f305cb8fc6b8ebc95474a4cbc4cb94",
            "corpusId": 328576,
            "url": "https://www.semanticscholar.org/paper/5de9184007f305cb8fc6b8ebc95474a4cbc4cb94",
            "title": "ASL recognition based on a coupling between HMMs and 3D motion analysis",
            "venue": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1998,
            "externalIds": {
                "DBLP": "conf/iccv/VoglerM98",
                "MAG": "2288738855",
                "DOI": "10.1109/ICCV.1998.710744",
                "CorpusId": 328576
            },
            "abstract": "We present a framework for recognizing isolated and continuous American Sign Language (ASL) sentences from three-dimensional data. The data are obtained by using physics-based three-dimensional tracking methods and then presented as input to Hidden Markov Models (HMMs) for recognition. To improve recognition performance, we model context-dependent HMMs and present a novel method of coupling three-dimensional computer vision methods and HMMs by temporally segmenting the data stream with vision methods. We then use the geometric properties of the segments to constrain the HMM framework for recognition. We show in experiments with a 53 sign vocabulary that three-dimensional features outperform two-dimensional features in recognition performance. Furthermore, we demonstrate that context-dependent modeling and the coupling of vision methods and HMMs improve the accuracy of continuous ASL recognition.",
            "referenceCount": 23,
            "citationCount": 348,
            "influentialCitationCount": 23,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://repository.upenn.edu/bitstreams/3dc669d3-7c72-40c1-9579-7f907fe0745f/download",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1998-01-04",
            "journal": {
                "name": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Vogler1998ASLRB,\n author = {Christian Vogler and Dimitris N. Metaxas},\n booktitle = {Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)},\n journal = {Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)},\n pages = {363-369},\n title = {ASL recognition based on a coupling between HMMs and 3D motion analysis},\n year = {1998}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:aba2b47172bc3573710717a7308ee8cd5f014945",
            "@type": "ScholarlyArticle",
            "paperId": "aba2b47172bc3573710717a7308ee8cd5f014945",
            "corpusId": 60186490,
            "url": "https://www.semanticscholar.org/paper/aba2b47172bc3573710717a7308ee8cd5f014945",
            "title": "The problem of perception",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1989,
            "externalIds": {
                "MAG": "333663304",
                "DOI": "10.1007/978-1-4684-6237-1_4",
                "CorpusId": 60186490
            },
            "abstract": null,
            "referenceCount": 1,
            "citationCount": 399,
            "influentialCitationCount": 52,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Lee1989ThePO,\n author = {Mark H. Lee},\n pages = {53-66},\n title = {The problem of perception},\n year = {1989}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:faef251d1ec6e1c121bab4210d1274ad6fb77b96",
            "@type": "ScholarlyArticle",
            "paperId": "faef251d1ec6e1c121bab4210d1274ad6fb77b96",
            "corpusId": 1224977,
            "url": "https://www.semanticscholar.org/paper/faef251d1ec6e1c121bab4210d1274ad6fb77b96",
            "title": "Correlated Label Propagation with Application to Multi-label Learning",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2006,
            "externalIds": {
                "DBLP": "conf/cvpr/KangJS06",
                "MAG": "2133510502",
                "DOI": "10.1109/CVPR.2006.90",
                "CorpusId": 1224977
            },
            "abstract": "Many computer vision applications, such as scene analysis and medical image interpretation, are ill-suited for traditional classification where each image can only be associated with a single class. This has stimulated recent work in multi-label learning where a given image can be tagged with multiple class labels. A serious problem with existing approaches is that they are unable to exploit correlations between class labels. This paper presents a novel framework for multi-label learning termed Correlated Label Propagation (CLP) that explicitly models interactions between labels in an efficient manner. As in standard label propagation, labels attached to training data points are propagated to test data points; however, unlike standard algorithms that treat each label independently, CLP simultaneously co-propagates multiple labels. Existing work eschews such an approach since naive algorithms for label co-propagation are intractable. We present an algorithm based on properties of submodular functions that efficiently finds an optimal solution. Our experiments demonstrate that CLP leads to significant gains in precision/recall against standard techniques on two real-world computer vision tasks involving several hundred labels.",
            "referenceCount": 29,
            "citationCount": 248,
            "influentialCitationCount": 23,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.cse.msu.edu/~rongjin/publications/cvpr2006_label_prop.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2006-06-17",
            "journal": {
                "name": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Kang2006CorrelatedLP,\n author = {Feng Kang and Rong Jin and R. Sukthankar},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)},\n pages = {1719-1726},\n title = {Correlated Label Propagation with Application to Multi-label Learning},\n volume = {2},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a1c45a16a17a94fbb1fb794f07237eabaddbe5e6",
            "@type": "ScholarlyArticle",
            "paperId": "a1c45a16a17a94fbb1fb794f07237eabaddbe5e6",
            "corpusId": 263493595,
            "url": "https://www.semanticscholar.org/paper/a1c45a16a17a94fbb1fb794f07237eabaddbe5e6",
            "title": "Shape from shading",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1989,
            "externalIds": {
                "MAG": "97083571",
                "CorpusId": 263493595
            },
            "abstract": "Understanding how the shape of a three dimensional object may be recovered from shading in a two-dimensional image of the object is one of the most important - and still unresolved - problems in machine vision. Although this important subfield is now in its second decade, this book is the first to provide a comprehensive review of shape from shading. It brings together all of the seminal papers on the subject, shows how recent work relates to more traditional approaches, and provides a comprehensive annotated bibliography.The book's 17 chapters cover: Surface Descriptions from Stereo and Shading. Shape and Source from Shading. The Eikonal Equation: some Results Applicable to Computer Vision. A Method for Enforcing Integrability in Shape from Shading Algorithms. Obtaining Shape from Shading Information. The Variational Approach to Shape from Shading. Calculating the Reflectance Map. Numerical Shape from Shading and Occluding Boundaries. Photometric Invariants Related to Solid Shape. Improved Methods of Estimating Shape from Shading Using the Light Source Coordinate System. A Provably Convergent Algorithm for Shape from Shading. Recovering Three Dimensional Shape from a Single Image of Curved Objects. Perception of Solid Shape from Shading. Local Shading Analysis Pentland. Radarclinometry for the Venus Radar Mapper. Photometric Method for Determining Surface Orientation from Multiple Images.Berthold K. P. Horn is Professor of Electrical Engineering and Computer Science at MIT. He has presided over the field of machine vision for more than a decade and is the author of \"Robot Vision. \"Michael Brooks is Reader in Computer Science at The Flinders University of South Australia. \"Shape from Shading\" is included in the Artificial Intelligence series, edited by Michael Brady, Daniel Bobrow, and Randall Davis.",
            "referenceCount": 0,
            "citationCount": 477,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Geography"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Geography",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "1989-08-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Horn1989ShapeFS,\n author = {Berthold K. P. Horn and Michael J. Brooks},\n title = {Shape from shading},\n year = {1989}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3a3457d49c92398df2dfe43a4a3bd4bbbabce425",
            "@type": "ScholarlyArticle",
            "paperId": "3a3457d49c92398df2dfe43a4a3bd4bbbabce425",
            "corpusId": 32357,
            "url": "https://www.semanticscholar.org/paper/3a3457d49c92398df2dfe43a4a3bd4bbbabce425",
            "title": "Comparing and evaluating interest points",
            "venue": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1998,
            "externalIds": {
                "MAG": "1773272891",
                "DBLP": "conf/iccv/SchmidMB98",
                "DOI": "10.1109/ICCV.1998.710723",
                "CorpusId": 32357
            },
            "abstract": "Many computer vision tasks rely on feature extraction. Interest points are such features. This paper shows that interest points are geometrically stable under different transformations and have high information content (distinctiveness). These two properties make interest points very successful in the contest of image matching. To measure these two properties quantitatively, we introduce two evaluation criteria: repeatability rate and information content. The quality of the interest points depends on the detector used. In this paper several detectors are compared according to the criteria specified above. We determine which detector gives the best results and show that it satisfies the criteria well.",
            "referenceCount": 11,
            "citationCount": 359,
            "influentialCitationCount": 15,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://hal.inria.fr/inria-00548328/file/schmid_iccv98.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1998-01-04",
            "journal": {
                "name": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Schmid1998ComparingAE,\n author = {C. Schmid and R. Mohr and C. Bauckhage},\n booktitle = {Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)},\n journal = {Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)},\n pages = {230-235},\n title = {Comparing and evaluating interest points},\n year = {1998}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:090d99b041023c1f4af445122906baa41e41372a",
            "@type": "ScholarlyArticle",
            "paperId": "090d99b041023c1f4af445122906baa41e41372a",
            "corpusId": 8268905,
            "url": "https://www.semanticscholar.org/paper/090d99b041023c1f4af445122906baa41e41372a",
            "title": "Searching the World's Herbaria: A System for Visual Identification of Plant Species",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2008,
            "externalIds": {
                "DBLP": "conf/eccv/BelhumeurCFJKLLRSWZ08",
                "MAG": "2126357415",
                "DOI": "10.1007/978-3-540-88693-8_9",
                "CorpusId": 8268905
            },
            "abstract": null,
            "referenceCount": 27,
            "citationCount": 213,
            "influentialCitationCount": 12,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/978-3-540-88693-8_9.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2008-10-12",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Belhumeur2008SearchingTW,\n author = {P. Belhumeur and Daozheng Chen and Steven K. Feiner and D. Jacobs and W. Kress and Haibin Ling and Ida C. Lopez and R. Ramamoorthi and Sameer Sheorey and Sean White and Ling Zhang},\n booktitle = {European Conference on Computer Vision},\n pages = {116-129},\n title = {Searching the World's Herbaria: A System for Visual Identification of Plant Species},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b4898a1c4930655665ac5b147b1df112dd2d94b1",
            "@type": "ScholarlyArticle",
            "paperId": "b4898a1c4930655665ac5b147b1df112dd2d94b1",
            "corpusId": 13937927,
            "url": "https://www.semanticscholar.org/paper/b4898a1c4930655665ac5b147b1df112dd2d94b1",
            "title": "Keyframe-based tracking for rotoscoping and animation",
            "venue": "ACM Transactions on Graphics",
            "publicationVenue": {
                "id": "urn:research:aab03e41-f80d-48b3-89bd-60eeeceafc7d",
                "name": "ACM Transactions on Graphics",
                "alternate_names": [
                    "ACM Trans Graph"
                ],
                "issn": "0730-0301",
                "url": "http://www.acm.org/tog/"
            },
            "year": 2004,
            "externalIds": {
                "MAG": "2017293771",
                "DBLP": "journals/tog/AgarwalaHSS04",
                "DOI": "10.1145/1186562.1015764",
                "CorpusId": 13937927
            },
            "abstract": "We describe a new approach to rotoscoping --- the process of tracking contours in a video sequence --- that combines computer vision with user interaction. In order to track contours in video, the user specifies curves in two or more frames; these curves are used as keyframes by a computer-vision-based tracking algorithm. The user may interactively refine the curves and then restart the tracking algorithm. Combining computer vision with user interaction allows our system to track any sequence with significantly less effort than interpolation-based systems --- and with better reliability than \"pure\" computer vision systems. Our tracking algorithm is cast as a spacetime optimization problem that solves for time-varying curve shapes based on an input video sequence and user-specified constraints. We demonstrate our system with several rotoscoped examples. Additionally, we show how these rotoscoped contours can be used to help create cartoon animation by attaching user-drawn strokes to the tracked contours.",
            "referenceCount": 36,
            "citationCount": 263,
            "influentialCitationCount": 19,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://grail.cs.washington.edu/projects/rotoscoping/roto.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle"
            ],
            "publicationDate": "2004-08-01",
            "journal": {
                "name": "ACM SIGGRAPH 2004 Papers",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Agarwala2004KeyframebasedTF,\n author = {A. Agarwala and Aaron Hertzmann and D. Salesin and S. Seitz},\n booktitle = {ACM Transactions on Graphics},\n journal = {ACM SIGGRAPH 2004 Papers},\n title = {Keyframe-based tracking for rotoscoping and animation},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1917f13246bcc7a2c396150f9de5e6ca5a74aff5",
            "@type": "ScholarlyArticle",
            "paperId": "1917f13246bcc7a2c396150f9de5e6ca5a74aff5",
            "corpusId": 8455164,
            "url": "https://www.semanticscholar.org/paper/1917f13246bcc7a2c396150f9de5e6ca5a74aff5",
            "title": "Is Machine Colour Constancy Good Enough?",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 1998,
            "externalIds": {
                "MAG": "1491192762",
                "DBLP": "conf/eccv/FuntBM98",
                "DOI": "10.1007/BFb0055683",
                "CorpusId": 8455164
            },
            "abstract": null,
            "referenceCount": 15,
            "citationCount": 318,
            "influentialCitationCount": 16,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/BFb0055683.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1998-06-02",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Funt1998IsMC,\n author = {B. Funt and Kobus Barnard and Lindsay Martin},\n booktitle = {European Conference on Computer Vision},\n pages = {445-459},\n title = {Is Machine Colour Constancy Good Enough?},\n year = {1998}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:620833ad7330b7285c1ea9005b838c731c9731c0",
            "@type": "ScholarlyArticle",
            "paperId": "620833ad7330b7285c1ea9005b838c731c9731c0",
            "corpusId": 22637359,
            "url": "https://www.semanticscholar.org/paper/620833ad7330b7285c1ea9005b838c731c9731c0",
            "title": "An Introduction to Distributed Smart Cameras",
            "venue": "Proceedings of the IEEE",
            "publicationVenue": {
                "id": "urn:research:6faaccca-1cc4-45a9-aeb6-96a4901d2606",
                "name": "Proceedings of the IEEE",
                "alternate_names": [
                    "Proc IEEE"
                ],
                "issn": "0018-9219",
                "url": "http://www.ieee.org/portal/pages/pubs/proceedings/"
            },
            "year": 2008,
            "externalIds": {
                "DBLP": "journals/pieee/RinnerW08",
                "MAG": "1970430984",
                "DOI": "10.1109/JPROC.2008.928742",
                "CorpusId": 22637359
            },
            "abstract": "Distributed smart cameras (DSCs) are real-time distributed embedded systems that perform computer vision using multiple cameras. This new approach has emerged thanks to a confluence of simultaneous advances in four key disciplines: computer vision, image sensors, embedded computing, and sensor networks. Processing images in a network of distributed smart cameras introduces several complications. However, we believe that the problems DSCs solve are much more important than the challenges of designing and building a distributed video system. We argue that distributed smart cameras represent key components for future embedded computer vision systems and that smart cameras will become an enabling technology for many new applications. We summarize smart camera technology and applications, discuss current trends, and identify important research challenges.",
            "referenceCount": 73,
            "citationCount": 215,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2008-10-17",
            "journal": {
                "name": "Proceedings of the IEEE",
                "volume": "96"
            },
            "citationStyles": {
                "bibtex": "@Article{Rinner2008AnIT,\n author = {B. Rinner and M. Wolf},\n booktitle = {Proceedings of the IEEE},\n journal = {Proceedings of the IEEE},\n pages = {1565-1575},\n title = {An Introduction to Distributed Smart Cameras},\n volume = {96},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3acebd8e2a1dcbc90a6a823c2729c88d37c21ec0",
            "@type": "ScholarlyArticle",
            "paperId": "3acebd8e2a1dcbc90a6a823c2729c88d37c21ec0",
            "corpusId": 23084687,
            "url": "https://www.semanticscholar.org/paper/3acebd8e2a1dcbc90a6a823c2729c88d37c21ec0",
            "title": "How close are we to solving the problem of automated visual surveillance?",
            "venue": "Machine Vision and Applications",
            "publicationVenue": {
                "id": "urn:research:400d5e36-be35-4097-898f-753f4493156e",
                "name": "Machine Vision and Applications",
                "alternate_names": [
                    "Journal of Machine Vision and Applications",
                    "Mach Vis Appl",
                    "J Mach Vis Appl"
                ],
                "issn": "0932-8092",
                "url": "https://www.springer.com/computer/image+processing/journal/138"
            },
            "year": 2008,
            "externalIds": {
                "MAG": "1987517671",
                "DBLP": "journals/mva/DeeV08",
                "DOI": "10.1007/s00138-007-0077-z",
                "CorpusId": 23084687
            },
            "abstract": null,
            "referenceCount": 93,
            "citationCount": 205,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2008-09-30",
            "journal": {
                "name": "Machine Vision and Applications",
                "volume": "19"
            },
            "citationStyles": {
                "bibtex": "@Article{Dee2008HowCA,\n author = {Hannah M. Dee and S. Velast\u00edn},\n booktitle = {Machine Vision and Applications},\n journal = {Machine Vision and Applications},\n pages = {329-343},\n title = {How close are we to solving the problem of automated visual surveillance?},\n volume = {19},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:778c17c29e46301449c14904c41738272859b31f",
            "@type": "ScholarlyArticle",
            "paperId": "778c17c29e46301449c14904c41738272859b31f",
            "corpusId": 117270151,
            "url": "https://www.semanticscholar.org/paper/778c17c29e46301449c14904c41738272859b31f",
            "title": "Theory of Reconstruction from Image Motion",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1992,
            "externalIds": {
                "MAG": "1548596190",
                "DOI": "10.1007/978-3-642-77557-4",
                "CorpusId": 117270151
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 357,
            "influentialCitationCount": 32,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/bfm:978-3-642-77557-4/1?pdf=chapter%20toc",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1992-12-11",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Maybank1992TheoryOR,\n author = {S. Maybank and Thomas S. Huang and T. Kohonen and M. Schroeder},\n title = {Theory of Reconstruction from Image Motion},\n year = {1992}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:303f8d99759e1f1fc922b0cffdd9fe3e75017b74",
            "@type": "ScholarlyArticle",
            "paperId": "303f8d99759e1f1fc922b0cffdd9fe3e75017b74",
            "corpusId": 16052318,
            "url": "https://www.semanticscholar.org/paper/303f8d99759e1f1fc922b0cffdd9fe3e75017b74",
            "title": "Algorithms for the satisfiability (SAT) problem: A survey",
            "venue": "Satisfiability Problem: Theory and Applications",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1996,
            "externalIds": {
                "DBLP": "conf/dimacs/GuPFW96",
                "MAG": "1627230931",
                "DOI": "10.1090/dimacs/035/02",
                "CorpusId": 16052318
            },
            "abstract": "Abstract : The satisfiability (SAT) problem is a core problem in mathematical logic and computing theory. In practice, SAT is fundamental in solving many problems in automated reasoning, computer aided design, computer aided manufacturing, machine vision, database, robotics, integrated circuit design, computer architecture design, and computer network design. Traditional methods treat SAT as a discrete, constrained decision problem. In recent years, many optimization methods, parallel algorithms, and practical techniques have been developed for solving SAT. In this survey, we present a general framework (an algorithm space) that integrates existing SAT algorithms into a unified perspective. We describe sequential and parallel SAT algorithms including variable splitting, resolution, local search, global optimization, mathematical programming, and practical SAT algorithms. We give performance evaluation of some existing SAT algorithms. Finally, we provide a set of practical applications of the satisfiability problems.",
            "referenceCount": 470,
            "citationCount": 366,
            "influentialCitationCount": 16,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gu1996AlgorithmsFT,\n author = {J. Gu and P. Purdom and J. Franco and B. Wah},\n booktitle = {Satisfiability Problem: Theory and Applications},\n pages = {19-151},\n title = {Algorithms for the satisfiability (SAT) problem: A survey},\n year = {1996}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5d63b2911d2447debb6dc8c220d267d4a2582cbe",
            "@type": "ScholarlyArticle",
            "paperId": "5d63b2911d2447debb6dc8c220d267d4a2582cbe",
            "corpusId": 3167340,
            "url": "https://www.semanticscholar.org/paper/5d63b2911d2447debb6dc8c220d267d4a2582cbe",
            "title": "Looking around the corner using transient imaging",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2009,
            "externalIds": {
                "MAG": "2538216436",
                "DBLP": "conf/iccv/KirmaniHDR09",
                "DOI": "10.1109/ICCV.2009.5459160",
                "CorpusId": 3167340
            },
            "abstract": "We show that multi-path analysis using images from a timeof-flight (ToF) camera provides a tantalizing opportunity to infer about 3D geometry of not only visible but hidden parts of a scene. We provide a novel framework for reconstructing scene geometry from a single viewpoint using a camera that captures a 3D time-image I(x, y, t) for each pixel. We propose a framework that uses the time-image and transient reasoning to expose scene properties that may be beyond the reach of traditional computer vision. We corroborate our theory with free space hardware experiments using a femtosecond laser and an ultrafast photo detector array. The ability to compute the geometry of hidden elements, unobservable by both the camera and illumination source, will create a range of new computer vision opportunities.",
            "referenceCount": 22,
            "citationCount": 169,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.mit.edu/%7Eakirmani/papers/Kirmani_ICCV_2009.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2009-09-01",
            "journal": {
                "name": "2009 IEEE 12th International Conference on Computer Vision",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Kirmani2009LookingAT,\n author = {Ahmed Kirmani and Tyler Hutchison and James Davis and R. Raskar},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2009 IEEE 12th International Conference on Computer Vision},\n pages = {159-166},\n title = {Looking around the corner using transient imaging},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:23d7057a863dd868f6be4a66fa13da62a5188097",
            "@type": "ScholarlyArticle",
            "paperId": "23d7057a863dd868f6be4a66fa13da62a5188097",
            "corpusId": 6550438,
            "url": "https://www.semanticscholar.org/paper/23d7057a863dd868f6be4a66fa13da62a5188097",
            "title": "IICBU 2008: a proposed benchmark suite for biological image analysis",
            "venue": "Medical and Biological Engineering and Computing",
            "publicationVenue": {
                "id": "urn:research:9742541e-b126-449a-bed9-7b0fcbf875ac",
                "name": "Medical and Biological Engineering and Computing",
                "alternate_names": [
                    "Med  Biological Eng  Comput",
                    "Med Biological Eng Comput",
                    "Medical & Biological Engineering & Computing"
                ],
                "issn": "0140-0118",
                "url": "https://www.springer.com/biomed/human+physiology/journal/11517"
            },
            "year": 2008,
            "externalIds": {
                "MAG": "2147377972",
                "DBLP": "journals/mbec/ShamirOEMG08",
                "DOI": "10.1007/s11517-008-0380-5",
                "CorpusId": 6550438,
                "PubMed": "18668273"
            },
            "abstract": null,
            "referenceCount": 8,
            "citationCount": 154,
            "influentialCitationCount": 15,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://europepmc.org/articles/pmc2562655?pdf=render",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2008-07-31",
            "journal": {
                "name": "Medical & Biological Engineering & Computing",
                "volume": "46"
            },
            "citationStyles": {
                "bibtex": "@Article{Shamir2008IICBU2A,\n author = {L. Shamir and Nikita Orlov and D. Eckley and T. Macura and I. Goldberg},\n booktitle = {Medical and Biological Engineering and Computing},\n journal = {Medical & Biological Engineering & Computing},\n pages = {943-947},\n title = {IICBU 2008: a proposed benchmark suite for biological image analysis},\n volume = {46},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3e0bdc00cdad744cf5d123f55cd200620487946e",
            "@type": "ScholarlyArticle",
            "paperId": "3e0bdc00cdad744cf5d123f55cd200620487946e",
            "corpusId": 15001430,
            "url": "https://www.semanticscholar.org/paper/3e0bdc00cdad744cf5d123f55cd200620487946e",
            "title": "Integration of depth modules: stereo and shading.",
            "venue": "Journal of the Optical Society of America. A, Optics and image science",
            "publicationVenue": {
                "id": "urn:research:b3482897-49da-4162-bfec-aec29f2fdef6",
                "name": "Journal of the Optical Society of America. A, Optics and image science",
                "alternate_names": [
                    "J Opt Soc Am Opt image sci"
                ],
                "issn": "0740-3232",
                "url": "http://www.opticsinfobase.org/josaa/"
            },
            "year": 1988,
            "externalIds": {
                "MAG": "2493655994",
                "DOI": "10.1364/JOSAA.5.001749",
                "CorpusId": 15001430,
                "PubMed": "3204438"
            },
            "abstract": "We studied the integration of image disparities, edge information, and shading in the three-dimensional perception of complex yet well-controlled images generated with a computer-graphics system. The images showed end-on views of flat- and smooth-shaded ellipsoids, i.e., images with and without intensity discontinuities (edges). A map of perceived depth was measured by adjusting a small stereo depth probe interactively to the perceived surface. Our data show that disparate shading (even in the absence of disparate edges) yields a vivid stereoscopic depth perception. The perceived depth is significantly reduced if the disparities are completely removed (shape-from-shading). If edge information is available, it overrides both shape-from-shading and disparate shading. Degradations of depth perception corresponded to a reduced depth rather than to an increased scatter in the depth measurement. The results are compared with computer-vision algorithms for both single cues and their integration for three-dimensional vision.",
            "referenceCount": 43,
            "citationCount": 365,
            "influentialCitationCount": 14,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine",
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Psychology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1988-10-01",
            "journal": {
                "name": "Journal of the Optical Society of America. A, Optics and image science",
                "volume": "5 10"
            },
            "citationStyles": {
                "bibtex": "@Article{B\u00fclthoff1988IntegrationOD,\n author = {H. B\u00fclthoff and H. Mallot},\n booktitle = {Journal of the Optical Society of America. A, Optics and image science},\n journal = {Journal of the Optical Society of America. A, Optics and image science},\n pages = {\n          1749-58\n        },\n title = {Integration of depth modules: stereo and shading.},\n volume = {5 10},\n year = {1988}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:594445440046a857004cf520156bfa6933a96899",
            "@type": "ScholarlyArticle",
            "paperId": "594445440046a857004cf520156bfa6933a96899",
            "corpusId": 1589694,
            "url": "https://www.semanticscholar.org/paper/594445440046a857004cf520156bfa6933a96899",
            "title": "A review of statistical data association techniques for motion correspondence",
            "venue": "International Journal of Computer Vision",
            "publicationVenue": {
                "id": "urn:research:939ee07c-6009-43f8-b884-69238b40659e",
                "name": "International Journal of Computer Vision",
                "alternate_names": [
                    "Int J Comput Vis"
                ],
                "issn": "0920-5691",
                "url": "https://www.springer.com/computer/image+processing/journal/11263"
            },
            "year": 1993,
            "externalIds": {
                "MAG": "2108874030",
                "DBLP": "journals/ijcv/Cox93",
                "DOI": "10.1007/BF01440847",
                "CorpusId": 1589694
            },
            "abstract": null,
            "referenceCount": 34,
            "citationCount": 316,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "1993-02-01",
            "journal": {
                "name": "International Journal of Computer Vision",
                "volume": "10"
            },
            "citationStyles": {
                "bibtex": "@Article{Cox1993ARO,\n author = {I. Cox},\n booktitle = {International Journal of Computer Vision},\n journal = {International Journal of Computer Vision},\n pages = {53-66},\n title = {A review of statistical data association techniques for motion correspondence},\n volume = {10},\n year = {1993}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f941caa13c57b2f63637baab8e78fc962da718e8",
            "@type": "ScholarlyArticle",
            "paperId": "f941caa13c57b2f63637baab8e78fc962da718e8",
            "corpusId": 17630074,
            "url": "https://www.semanticscholar.org/paper/f941caa13c57b2f63637baab8e78fc962da718e8",
            "title": "Papier-Mache: toolkit support for tangible input",
            "venue": "International Conference on Human Factors in Computing Systems",
            "publicationVenue": {
                "id": "urn:research:b55b50b1-aae7-47a7-b042-8aecc930073d",
                "name": "International Conference on Human Factors in Computing Systems",
                "alternate_names": [
                    "CHI",
                    "Int Conf Hum Factor Comput Syst",
                    "Human Factors in Computing Systems",
                    "Conference on Human Interface",
                    "Conf Hum Interface",
                    "Hum Factor Comput Syst"
                ],
                "issn": null,
                "url": "http://www.acm.org/sigchi/"
            },
            "year": 2004,
            "externalIds": {
                "MAG": "2160288944",
                "DBLP": "conf/chi/KlemmerLLL04",
                "DOI": "10.1145/985692.985743",
                "CorpusId": 17630074
            },
            "abstract": "Tangible user interfaces (TUIs) augment the physical world by integrating digital information with everyday physical objects. Currently, building these UIs requires \"getting down and dirty\" with input technologies such as computer vision. Consequently, only a small cadre of technology experts can currently build these UIs. Based on a literature review and structured interviews with nine TUI researchers, we created Papier-M\u00e2ch\u00e9, a toolkit for building tangible interfaces using computer vision, electronic tags, and barcodes. Papier-Mache introduces a high-level event model for working with these technologies that facilitates technology portability. For example, an application can be prototyped with computer vision and deployed with RFID. We present an evaluation of our toolkit with six class projects and a user study with seven programmers, finding the input abstractions, technology portability, and monitoring window to be highly effective.",
            "referenceCount": 35,
            "citationCount": 236,
            "influentialCitationCount": 8,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": "2004-04-25",
            "journal": {
                "name": "Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Klemmer2004PapierMacheTS,\n author = {Scott R. Klemmer and Jack Li and James Lin and J. Landay},\n booktitle = {International Conference on Human Factors in Computing Systems},\n journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},\n title = {Papier-Mache: toolkit support for tangible input},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:89121ed4d0d3db9bc192fd79f541fc299eba7d6b",
            "@type": "ScholarlyArticle",
            "paperId": "89121ed4d0d3db9bc192fd79f541fc299eba7d6b",
            "corpusId": 62531491,
            "url": "https://www.semanticscholar.org/paper/89121ed4d0d3db9bc192fd79f541fc299eba7d6b",
            "title": "Image Representations for Visual Learning",
            "venue": "Science",
            "publicationVenue": {
                "id": "urn:research:f59506a8-d8bb-4101-b3d4-c4ac3ed03dad",
                "name": "Science",
                "alternate_names": null,
                "issn": "0193-4511",
                "url": "https://www.jstor.org/journal/science"
            },
            "year": 1996,
            "externalIds": {
                "MAG": "2070320140",
                "DOI": "10.1126/science.272.5270.1905",
                "CorpusId": 62531491
            },
            "abstract": "Computer vision researchers are developing new approaches to object recognition and detection that are based almost directly on images and avoid the use of intermediate three-dimensional models. Many of these techniques depend on a representation of images that induces a linear vector space structure and in principle requires dense feature correspondence. This image representation allows the use of learning techniques for the analysis of images (for computer vision) as well as for the synthesis of images (for computer graphics).",
            "referenceCount": 34,
            "citationCount": 310,
            "influentialCitationCount": 8,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1996-06-28",
            "journal": {
                "name": "Science",
                "volume": "272"
            },
            "citationStyles": {
                "bibtex": "@Article{Beymer1996ImageRF,\n author = {D. Beymer and T. Poggio},\n booktitle = {Science},\n journal = {Science},\n pages = {1905 - 1909},\n title = {Image Representations for Visual Learning},\n volume = {272},\n year = {1996}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:23018619597a65af7151bb35e7c491ea39610948",
            "@type": "ScholarlyArticle",
            "paperId": "23018619597a65af7151bb35e7c491ea39610948",
            "corpusId": 11579898,
            "url": "https://www.semanticscholar.org/paper/23018619597a65af7151bb35e7c491ea39610948",
            "title": "Automated facial expression recognition based on FACS action units",
            "venue": "Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1998,
            "externalIds": {
                "DBLP": "conf/fgr/LienKCL98",
                "MAG": "2145012698",
                "DOI": "10.1109/AFGR.1998.670980",
                "CorpusId": 11579898
            },
            "abstract": "Automated recognition of facial expression is an important addition to computer vision research because of its relevance to the study of psychological phenomena and the development of human-computer interaction (HCI). We developed a computer vision system that automatically recognizes individual action units or action unit combinations in the upper face using hidden Markov models (HMMs). Our approach to facial expression recognition is based an the Facial Action Coding System (FACS), which separates expressions into upper and lower face action. We use three approaches to extract facial expression information: (1) facial feature point tracking; (2) dense flow tracking with principal component analysis (PCA); and (3) high gradient component detection (i.e. furrow detection). The recognition results of the upper face expressions using feature point tracking, dense flow tracking, and high gradient component detection are 85%, 93% and 85%, respectively.",
            "referenceCount": 20,
            "citationCount": 260,
            "influentialCitationCount": 14,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1998-04-14",
            "journal": {
                "name": "Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Lien1998AutomatedFE,\n author = {J. Lien and T. Kanade and J. Cohn and Ching-Chung Li},\n booktitle = {Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition},\n journal = {Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition},\n pages = {390-395},\n title = {Automated facial expression recognition based on FACS action units},\n year = {1998}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:13425bb41d326982ec6b3c6f3034aa978a1300ac",
            "@type": "ScholarlyArticle",
            "paperId": "13425bb41d326982ec6b3c6f3034aa978a1300ac",
            "corpusId": 14470115,
            "url": "https://www.semanticscholar.org/paper/13425bb41d326982ec6b3c6f3034aa978a1300ac",
            "title": "Face Recognition for Smart Environments",
            "venue": "Computer",
            "publicationVenue": {
                "id": "urn:research:f6572f66-2623-4a5e-b0d9-4a5028dea98f",
                "name": "Computer",
                "alternate_names": [
                    "IEEE Computer",
                    "IEEE Comput"
                ],
                "issn": "0018-9162",
                "url": "http://www.computer.org/computer"
            },
            "year": 2000,
            "externalIds": {
                "MAG": "2115943089",
                "DBLP": "journals/computer/PentlandC00",
                "DOI": "10.1109/2.820039",
                "CorpusId": 14470115
            },
            "abstract": "Smart environments, wearable computers, and ubiquitous computing in general are the coming \"fourth generation\" of computing and information technology. But that technology will be a stillbirth without new interfaces for interaction, minus a keyboard or mouse. To win wide consumer acceptance, these interactions must be friendly and personalized; the next generation interfaces must recognize people in their immediate environment and, at a minimum, know who they are. In this article, the authors discuss face recognition technology, how it works, problems to be overcome, current technologies, and future developments and possible applications. Twenty years ago, the problem of face recognition was considered among the most difficult in artificial intelligence and computer vision. Today, however, there are several companies that sell commercial face recognition software that is capable of high-accuracy recognition with databases of more than 1,000 people. The authors describe the face recognition technology used, explaining the algorithms for face recognition as well as novel applications, such as behavior monitoring that assesses emotions based on facial expressions.",
            "referenceCount": 13,
            "citationCount": 275,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://web.media.mit.edu/~tanzeem/computer2000_biometrics.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2000-02-01",
            "journal": {
                "name": "Computer",
                "volume": "33"
            },
            "citationStyles": {
                "bibtex": "@Article{Pentland2000FaceRF,\n author = {A. Pentland and Tanzeem Choudhury},\n booktitle = {Computer},\n journal = {Computer},\n pages = {50-55},\n title = {Face Recognition for Smart Environments},\n volume = {33},\n year = {2000}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:87f8c0e18d2c0d6f9b343268e8508df278b73cef",
            "@type": "ScholarlyArticle",
            "paperId": "87f8c0e18d2c0d6f9b343268e8508df278b73cef",
            "corpusId": 823798,
            "url": "https://www.semanticscholar.org/paper/87f8c0e18d2c0d6f9b343268e8508df278b73cef",
            "title": "Localization and Segmentation of A 2D High Capacity Color Barcode",
            "venue": "IEEE Workshop on Applications of Computer Vision",
            "publicationVenue": {
                "id": "urn:research:40a2efb3-38bd-4d3e-a84a-a1202ff48cc0",
                "name": "IEEE Workshop on Applications of Computer Vision",
                "alternate_names": [
                    "IEEE Workshop Appl Comput Vis"
                ],
                "issn": "1550-5790",
                "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000040"
            },
            "year": 2008,
            "externalIds": {
                "MAG": "2099066201",
                "DBLP": "conf/wacv/ParikhJ08",
                "DOI": "10.1109/WACV.2008.4544033",
                "CorpusId": 823798
            },
            "abstract": "A 2D color barcode can hold much more information than a binary barcode. Barcodes are often intended for consumer use where using a cellphone, a consumer can take an image of a barcode on a product, and retrieve relevant information about the product. The barcode must be read using computer vision techniques. While a color barcode can hold more information, it makes this vision task in consumer scenarios unusually challenging. We present our approach to the localization and segmentation of a 2D color barcode in such challenging scenarios, along with its evaluation on a diverse collection of images of Microsoft's recently launched high capacity color barcode (HCCB). We exploit the unique trait of barcode reading: the barcode decoder can give the vision algorithm feedback, and develop a progressive strategy to achieve both - high accuracy in diverse scenarios as well as computational efficiency.",
            "referenceCount": 7,
            "citationCount": 143,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2008-01-07",
            "journal": {
                "name": "2008 IEEE Workshop on Applications of Computer Vision",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Parikh2008LocalizationAS,\n author = {Devi Parikh and Gavin Jancke},\n booktitle = {IEEE Workshop on Applications of Computer Vision},\n journal = {2008 IEEE Workshop on Applications of Computer Vision},\n pages = {1-6},\n title = {Localization and Segmentation of A 2D High Capacity Color Barcode},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:89275f66c0a2397d1e0afe5b2615f3352d6799f2",
            "@type": "ScholarlyArticle",
            "paperId": "89275f66c0a2397d1e0afe5b2615f3352d6799f2",
            "corpusId": 195608239,
            "url": "https://www.semanticscholar.org/paper/89275f66c0a2397d1e0afe5b2615f3352d6799f2",
            "title": "Mathematical Morphology in Image Processing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1992,
            "externalIds": {
                "MAG": "1599786999",
                "DOI": "10.1201/9781482277234",
                "CorpusId": 195608239
            },
            "abstract": "Presents the statistical analysis of morphological filters and their automatic optical design, the development of morphological features for image signatures, and the design of efficient morphological algorithms. Extends the morphological paradigm to include other branches of science and mathematics.;This book is designed to be of interest to optical, electrical and electronics, and electro-optic engineers, including image processing, signal processing, machine vision, and computer vision engineers, applied mathematicians, image analysts and scientists and graduate-level students in image processing and mathematical morphology courses.",
            "referenceCount": 0,
            "citationCount": 368,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1992-09-25",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Dougherty1992MathematicalMI,\n author = {E. Dougherty},\n pages = {229},\n title = {Mathematical Morphology in Image Processing},\n year = {1992}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5f9ab31595003a235b9c433e0a82071fbeb03bed",
            "@type": "ScholarlyArticle",
            "paperId": "5f9ab31595003a235b9c433e0a82071fbeb03bed",
            "corpusId": 7823957,
            "url": "https://www.semanticscholar.org/paper/5f9ab31595003a235b9c433e0a82071fbeb03bed",
            "title": "Impairments of reaching movements in patients without proprioception. II. Effects of visual information on accuracy.",
            "venue": "Journal of Neurophysiology",
            "publicationVenue": {
                "id": "urn:research:d2b57141-ecff-4b3d-b490-7928e8aafc17",
                "name": "Journal of Neurophysiology",
                "alternate_names": [
                    "J Neurophysiol"
                ],
                "issn": "0022-3077",
                "url": "https://www.physiology.org/journal/jn"
            },
            "year": 1995,
            "externalIds": {
                "MAG": "284329785",
                "DOI": "10.1152/JN.1995.73.1.361",
                "CorpusId": 7823957,
                "PubMed": "7714578"
            },
            "abstract": "1. The aim of this study was to determine how vision of a cursor indicating hand position on a computer screen or vision of the limb itself improves the accuracy of reaching movements in patients deprived of limb proprioception due to large-fiber sensory neuropathy. In particular, we wished to ascertain the contribution of such information to improved planning rather than to feedback corrections. We analyzed spatial errors and hand trajectories of reaching movements made by subjects moving a hand-held cursor on a digitizing tablet while viewing targets displayed on a computer screen. The errors made when movements were performed without vision of their arm or of a screen cursor were compared with errors made when this information was available concurrently or prior to movement. 2. Both monitoring the screen cursor and seeing their limb in peripheral vision during movement improved the accuracy of the patients' movements. Improvements produced by seeing the cursor during movement are attributable simply to feedback corrections. However, because the target was not present in the actual workspace, improvements associated with vision of the limb must involve more complex corrective mechanisms. 3. Significant improvements in performance also occurred in trials without vision that were performed after viewing the limb at rest or during movements. In particular, prior vision of the limb in motion improved the ability of patients to vary the duration of movements in different directions so as to compensate for the inertial anisotropy of the limb. In addition, there were significant reductions in directional errors, path curvature, and late secondary movements. Comparable improvements in extent, direction, and curvature were produced when subjects could see the screen cursor during alternate movements to targets in different directions. 4. The effects of viewing the limb were transient and decayed during a period of minutes once vision of the limb was no longer available. 5. It is proposed that the improvements in performance produced after vision of the limb were mediated by the visual updating of internal models of the limb. Vision of the limb at rest may provide configuration information while vision of the limb in motion provides additional dynamic information. Vision of the cursor and the resulting ability to correct ongoing movements, however, is considered primarily to provide information about the dynamic properties of the limb and its response to neural commands.",
            "referenceCount": 32,
            "citationCount": 353,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Psychology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Journal of neurophysiology",
                "volume": "73 1"
            },
            "citationStyles": {
                "bibtex": "@Article{Ghez1995ImpairmentsOR,\n author = {C. Ghez and J. Gordon and Maria Felice Ghilardi},\n booktitle = {Journal of Neurophysiology},\n journal = {Journal of neurophysiology},\n pages = {\n          361-72\n        },\n title = {Impairments of reaching movements in patients without proprioception. II. Effects of visual information on accuracy.},\n volume = {73 1},\n year = {1995}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:85dd0898295a5c284f60a14d036b89f9e0b007f5",
            "@type": "ScholarlyArticle",
            "paperId": "85dd0898295a5c284f60a14d036b89f9e0b007f5",
            "corpusId": 1556660,
            "url": "https://www.semanticscholar.org/paper/85dd0898295a5c284f60a14d036b89f9e0b007f5",
            "title": "Computing Optical Flow via Variational Techniques",
            "venue": "SIAM Journal on Applied Mathematics",
            "publicationVenue": {
                "id": "urn:research:9b3052dd-9e29-41cb-927c-28df9e08a68b",
                "name": "SIAM Journal on Applied Mathematics",
                "alternate_names": [
                    "SIAM J Appl Math",
                    "Siam Journal on Applied Mathematics",
                    "Siam J Appl Math"
                ],
                "issn": "0036-1399",
                "url": "https://www.jstor.org/journal/siamjapplmath"
            },
            "year": 1999,
            "externalIds": {
                "MAG": "2054654931",
                "DBLP": "journals/siamam/AubertDK99",
                "DOI": "10.1137/S0036139998340170",
                "CorpusId": 1556660
            },
            "abstract": "Defined as the apparent motion in a sequence of images, the optical flow is very important in the computer vision community where its accurate estimation is necessary for many applications. It is o...",
            "referenceCount": 57,
            "citationCount": 251,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1999-11-01",
            "journal": {
                "name": "SIAM J. Appl. Math.",
                "volume": "60"
            },
            "citationStyles": {
                "bibtex": "@Article{Aubert1999ComputingOF,\n author = {G. Aubert and R. Deriche and Pierre Kornprobst},\n booktitle = {SIAM Journal on Applied Mathematics},\n journal = {SIAM J. Appl. Math.},\n pages = {156-182},\n title = {Computing Optical Flow via Variational Techniques},\n volume = {60},\n year = {1999}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6b1a05759f570f13ebdc5ea7f7a957e41f43203d",
            "@type": "ScholarlyArticle",
            "paperId": "6b1a05759f570f13ebdc5ea7f7a957e41f43203d",
            "corpusId": 341776,
            "url": "https://www.semanticscholar.org/paper/6b1a05759f570f13ebdc5ea7f7a957e41f43203d",
            "title": "Multiple Component Learning for Object Detection",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2008,
            "externalIds": {
                "MAG": "1573508639",
                "DBLP": "conf/eccv/DollarBBPT08",
                "DOI": "10.1007/978-3-540-88688-4_16",
                "CorpusId": 341776
            },
            "abstract": null,
            "referenceCount": 34,
            "citationCount": 151,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://authors.library.caltech.edu/47594/1/DollarEtAlECCV08mcl.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2008-10-12",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Doll\u00e1r2008MultipleCL,\n author = {Piotr Doll\u00e1r and Boris Babenko and Serge J. Belongie and P. Perona and Z. Tu},\n booktitle = {European Conference on Computer Vision},\n pages = {211-224},\n title = {Multiple Component Learning for Object Detection},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ac162e653183cf0c429a6cd63800aca59b4d226c",
            "@type": "ScholarlyArticle",
            "paperId": "ac162e653183cf0c429a6cd63800aca59b4d226c",
            "corpusId": 2050459,
            "url": "https://www.semanticscholar.org/paper/ac162e653183cf0c429a6cd63800aca59b4d226c",
            "title": "What Is a Good Nearest Neighbors Algorithm for Finding Similar Patches in Images?",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2008,
            "externalIds": {
                "DBLP": "conf/eccv/KumarZN08",
                "MAG": "2165428671",
                "DOI": "10.1007/978-3-540-88688-4_27",
                "CorpusId": 2050459
            },
            "abstract": null,
            "referenceCount": 26,
            "citationCount": 142,
            "influentialCitationCount": 5,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/978-3-540-88688-4_27.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2008-10-12",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Kumar2008WhatIA,\n author = {Neeraj Kumar and Li Zhang and S. Nayar},\n booktitle = {European Conference on Computer Vision},\n pages = {364-378},\n title = {What Is a Good Nearest Neighbors Algorithm for Finding Similar Patches in Images?},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:43230fe5e35b83b15f38b8935bfc1f1306932b00",
            "@type": "ScholarlyArticle",
            "paperId": "43230fe5e35b83b15f38b8935bfc1f1306932b00",
            "corpusId": 17507792,
            "url": "https://www.semanticscholar.org/paper/43230fe5e35b83b15f38b8935bfc1f1306932b00",
            "title": "Architecture and applications of the Connection Machine",
            "venue": "Computer",
            "publicationVenue": {
                "id": "urn:research:f6572f66-2623-4a5e-b0d9-4a5028dea98f",
                "name": "Computer",
                "alternate_names": [
                    "IEEE Computer",
                    "IEEE Comput"
                ],
                "issn": "0018-9162",
                "url": "http://www.computer.org/computer"
            },
            "year": 1988,
            "externalIds": {
                "DBLP": "journals/computer/TuckerR88",
                "MAG": "2009832491",
                "DOI": "10.1109/2.74",
                "CorpusId": 17507792
            },
            "abstract": "The concept of data-parallel computers is explained, and their architecture of the Connection Machine (CM), which implements this approach, is described. It provides 64 K physical processing elements, millions of virtual processing elements with its virtual processor mechanism, and general-purpose, reconfigurable communications networks. The evolution of the CM architecture is examined, and the software environment, engineering and physical characteristics, and performance of the current embodiment (the CM-2) are discussed. Applications of the CM to molecular dynamics, VLSI design and circuit simulation, and computer vision are described.<<ETX>>",
            "referenceCount": 13,
            "citationCount": 331,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1988-08-01",
            "journal": {
                "name": "Computer",
                "volume": "21"
            },
            "citationStyles": {
                "bibtex": "@Article{Tucker1988ArchitectureAA,\n author = {L. W. Tucker and G. Robertson},\n booktitle = {Computer},\n journal = {Computer},\n pages = {26-38},\n title = {Architecture and applications of the Connection Machine},\n volume = {21},\n year = {1988}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f73cf6769eb9c90c19a160cc67766511e6a07ac3",
            "@type": "ScholarlyArticle",
            "paperId": "f73cf6769eb9c90c19a160cc67766511e6a07ac3",
            "corpusId": 17791356,
            "url": "https://www.semanticscholar.org/paper/f73cf6769eb9c90c19a160cc67766511e6a07ac3",
            "title": "Model-based object recognition in dense-range images\u2014a review",
            "venue": "CSUR",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1993,
            "externalIds": {
                "DBLP": "journals/csur/ArmanA93",
                "MAG": "2075686162",
                "DOI": "10.1145/151254.151255",
                "CorpusId": 17791356
            },
            "abstract": "The goal in computer vision systems is to analyze data collected from the environment and derive an interpretation to complete a specified task. Vision system tasks may be divided into data acquisition, low-level processing, representation, model construction, and matching subtasks. This paper presents a comprehensive survey of model-based vision systems using dense-range images. A comprehensive survey of the recent publications in each subtask pertaining to dense-range image object recognition is presented.",
            "referenceCount": 150,
            "citationCount": 280,
            "influentialCitationCount": 8,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/151254.151255",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "1993-03-01",
            "journal": {
                "name": "ACM Comput. Surv.",
                "volume": "25"
            },
            "citationStyles": {
                "bibtex": "@Article{Arman1993ModelbasedOR,\n author = {F. Arman and J. Aggarwal},\n booktitle = {CSUR},\n journal = {ACM Comput. Surv.},\n pages = {5-43},\n title = {Model-based object recognition in dense-range images\u2014a review},\n volume = {25},\n year = {1993}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:256e0092ba62e4e56edfeed0ace89878c3eaaa53",
            "@type": "ScholarlyArticle",
            "paperId": "256e0092ba62e4e56edfeed0ace89878c3eaaa53",
            "corpusId": 62707015,
            "url": "https://www.semanticscholar.org/paper/256e0092ba62e4e56edfeed0ace89878c3eaaa53",
            "title": "Winged edge polyhedron representation.",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1972,
            "externalIds": {
                "MAG": "2108551799",
                "DOI": "10.21236/ad0755141",
                "CorpusId": 62707015
            },
            "abstract": "A winged edge polyhedron representation is stated and a set of primitives that preserve Euler''s F-E+V = 2 equation are explained. Present use of this representation in artificial intelligence for computer graphics and world modeling is illustrated and its intended future application to computer vision is described.",
            "referenceCount": 2,
            "citationCount": 378,
            "influentialCitationCount": 21,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1972-10-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Baumgart1972WingedEP,\n author = {Bruce G. Baumgart},\n title = {Winged edge polyhedron representation.},\n year = {1972}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cb1c84c69d4b8a7b633349800e8f5a93f3551452",
            "@type": "ScholarlyArticle",
            "paperId": "cb1c84c69d4b8a7b633349800e8f5a93f3551452",
            "corpusId": 14608692,
            "url": "https://www.semanticscholar.org/paper/cb1c84c69d4b8a7b633349800e8f5a93f3551452",
            "title": "The American Sign Language Lexicon Video Dataset",
            "venue": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition workshops",
            "publicationVenue": {
                "id": "urn:research:a38191e9-9b7f-4ca0-b7d4-fcf282b74ae1",
                "name": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition workshops",
                "alternate_names": [
                    "IEEE Comput Soc Conf Comput Vis Pattern Recognit work"
                ],
                "issn": "2160-7508",
                "url": "http://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1001809"
            },
            "year": 2008,
            "externalIds": {
                "DBLP": "conf/cvpr/AthitsosNSNSYT08",
                "MAG": "2161755782",
                "DOI": "10.1109/CVPRW.2008.4563181",
                "CorpusId": 14608692
            },
            "abstract": "The lack of a written representation for American sign language (ASL) makes it difficult to do something as commonplace as looking up an unknown word in a dictionary. The majority of printed dictionaries organize ASL signs (represented in drawings or pictures) based on their nearest English translation; so unless one already knows the meaning of a sign, dictionary look-up is not a simple proposition. In this paper we introduce the ASL lexicon video dataset, a large and expanding public dataset containing video sequences of thousands of distinct ASL signs, as well as annotations of those sequences, including start/end frames and class label of every sign. This dataset is being created as part of a project to develop a computer vision system that allows users to look up the meaning of an ASL sign. At the same time, the dataset can be useful for benchmarking a variety of computer vision and machine learning methods designed for learning and/or indexing a large number of visual classes, and especially approaches for analyzing gestures and human communication.",
            "referenceCount": 24,
            "citationCount": 123,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2008-06-23",
            "journal": {
                "name": "2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Athitsos2008TheAS,\n author = {V. Athitsos and C. Neidle and S. Sclaroff and Joan P. Nash and Alexandra Stefan and Quan Yuan and Ashwin Thangali},\n booktitle = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition workshops},\n journal = {2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},\n pages = {1-8},\n title = {The American Sign Language Lexicon Video Dataset},\n year = {2008}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1709faee1817122e13b2353b7b442b55c8031b0d",
            "@type": "ScholarlyArticle",
            "paperId": "1709faee1817122e13b2353b7b442b55c8031b0d",
            "corpusId": 2409240,
            "url": "https://www.semanticscholar.org/paper/1709faee1817122e13b2353b7b442b55c8031b0d",
            "title": "Occlusion Boundaries from Motion: Low-Level Detection and\u00a0Mid-Level Reasoning",
            "venue": "International Journal of Computer Vision",
            "publicationVenue": {
                "id": "urn:research:939ee07c-6009-43f8-b884-69238b40659e",
                "name": "International Journal of Computer Vision",
                "alternate_names": [
                    "Int J Comput Vis"
                ],
                "issn": "0920-5691",
                "url": "https://www.springer.com/computer/image+processing/journal/11263"
            },
            "year": 2009,
            "externalIds": {
                "MAG": "2036284314",
                "DBLP": "journals/ijcv/SteinH09",
                "DOI": "10.1007/s11263-008-0203-z",
                "CorpusId": 2409240
            },
            "abstract": null,
            "referenceCount": 99,
            "citationCount": 106,
            "influentialCitationCount": 14,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.ri.cmu.edu/pub_files/2009/4/fulltext.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2009-05-01",
            "journal": {
                "name": "International Journal of Computer Vision",
                "volume": "82"
            },
            "citationStyles": {
                "bibtex": "@Article{Stein2009OcclusionBF,\n author = {Andrew N. Stein and M. Hebert},\n booktitle = {International Journal of Computer Vision},\n journal = {International Journal of Computer Vision},\n pages = {325-357},\n title = {Occlusion Boundaries from Motion: Low-Level Detection and\u00a0Mid-Level Reasoning},\n volume = {82},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:815fb8d1fdf0311fdba0be56adbe3da6dda63be3",
            "@type": "ScholarlyArticle",
            "paperId": "815fb8d1fdf0311fdba0be56adbe3da6dda63be3",
            "corpusId": 6392469,
            "url": "https://www.semanticscholar.org/paper/815fb8d1fdf0311fdba0be56adbe3da6dda63be3",
            "title": "A common framework for curve evolution, segmentation and anisotropic diffusion",
            "venue": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1996,
            "externalIds": {
                "DBLP": "conf/cvpr/Shah96",
                "MAG": "2163111080",
                "DOI": "10.1109/CVPR.1996.517065",
                "CorpusId": 6392469
            },
            "abstract": "In recent years, curve evolution has developed into an important tool in Computer Vision and has been applied to a wide variety of problems such as smoothing of shapes, shape analysis and shape recovery. The underlying principle is the evolution of a simple closed curve whose points move in the direction of the normal with prescribed velocity. A fundamental limitation of the method as it stands is that it cannot deal with important image features such as triple points. The method also requires a choice of an \"edge-strength\" function, defined over the image domain. Indicating the likelihood of an object boundary being present at any point in the image domain. This implies a separate preprocessing step, in essence precomputing approximate boundaries in the presence of noise. One also has to choose the initial curve. It is shown here that the different versions of curve evolution used in Computer Vision together with the preprocessing step can be integrated in the form of a new segmentation functional which overcomes these limitations and extends curve evolution models. Moreover, the numerical solutions obtained retain sharp discontinuities or \"shocks\", thus providing sharp demarcation of object boundaries.",
            "referenceCount": 24,
            "citationCount": 238,
            "influentialCitationCount": 31,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1996-06-18",
            "journal": {
                "name": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Shah1996ACF,\n author = {J. Shah},\n booktitle = {Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition},\n journal = {Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition},\n pages = {136-142},\n title = {A common framework for curve evolution, segmentation and anisotropic diffusion},\n year = {1996}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:106fa0628a27470e6bc8d4242c9e5088493d38ac",
            "@type": "ScholarlyArticle",
            "paperId": "106fa0628a27470e6bc8d4242c9e5088493d38ac",
            "corpusId": 6136326,
            "url": "https://www.semanticscholar.org/paper/106fa0628a27470e6bc8d4242c9e5088493d38ac",
            "title": "Shedding light on the weather",
            "venue": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2003,
            "externalIds": {
                "MAG": "2129480988",
                "DBLP": "conf/cvpr/NarasimhanN03",
                "DOI": "10.1109/CVPR.2003.1211417",
                "CorpusId": 6136326
            },
            "abstract": "Virtually all methods in image processing and computer vision, for removing weather effects from images, assume single scattering of light by particles in the atmosphere. In reality, multiple scattering effects are significant. A common manifestation of multiple scattering is the appearance of glows around light sources in bad weather. Modeling multiple scattering is critical to understanding the complex effects of weather on images, and hence essential for improving the performance of outdoor vision systems. We develop a new physics-based model for the multiple scattering of light rays as they travel from a source to an observer. This model is valid for various weather conditions including fog, haze, mist and rain. Our model enables us to recover from a single image the shapes and depths of sources in the scene. In addition, the weather condition and the visibility of the atmosphere can be estimated. These quantities can, in turn, be used to remove the glows of sources to obtain a clear picture of the scene. Based on these results, we demonstrate that a camera observing a distant source can serve as a \"visual weather meter\". The model and techniques described in this paper can also be used to analyze scattering in other media, such as fluids and tissues. Therefore, in addition to vision in bad weather, our work has implications for medical and underwater imaging.",
            "referenceCount": 18,
            "citationCount": 216,
            "influentialCitationCount": 20,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2003-06-18",
            "journal": {
                "name": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings.",
                "volume": "1"
            },
            "citationStyles": {
                "bibtex": "@Article{Narasimhan2003SheddingLO,\n author = {S. Narasimhan and S. Nayar},\n booktitle = {2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings.},\n journal = {2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings.},\n pages = {I-I},\n title = {Shedding light on the weather},\n volume = {1},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:454443a6f19a67f2c2e0c0e3ccaabf35884b38ca",
            "@type": "ScholarlyArticle",
            "paperId": "454443a6f19a67f2c2e0c0e3ccaabf35884b38ca",
            "corpusId": 61357232,
            "url": "https://www.semanticscholar.org/paper/454443a6f19a67f2c2e0c0e3ccaabf35884b38ca",
            "title": "Handbook of pattern recognition and image processing",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1986,
            "externalIds": {
                "MAG": "2127201702",
                "CorpusId": 61357232
            },
            "abstract": "Principles of Computer Vision. Three-Dimensional Shape Representation. Three-Dimensional Shape Recovery from Line Drawings. Recovery of 3D Shape of Curved Objects. Surface Reflection Mechanism. Extracting Shape from Shading. Range Image Analysis. Stereo Vision. Machine Learning of Computer Vision Algorithms. Image Sequence Analysis for 3D Perception of Dynamic Scenes. Nonrigid Motion Analysis. Analysis and Synthesis of Human Movement. Relational Matching. Three-Dimensional Object Recognition. Fundamental Principles of Robot Vision. Chapter References.",
            "referenceCount": 0,
            "citationCount": 355,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Young1986HandbookOP,\n author = {T. Young and K. Fu},\n title = {Handbook of pattern recognition and image processing},\n year = {1986}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:236dd4aad44ed64e4fa13a2abd40840f086d23b7",
            "@type": "ScholarlyArticle",
            "paperId": "236dd4aad44ed64e4fa13a2abd40840f086d23b7",
            "corpusId": 27630300,
            "url": "https://www.semanticscholar.org/paper/236dd4aad44ed64e4fa13a2abd40840f086d23b7",
            "title": "Video Tracking: A Concise Survey",
            "venue": "IEEE Journal of Oceanic Engineering",
            "publicationVenue": {
                "id": "urn:research:ffdc730d-94d4-4af1-998c-03fb9dabc201",
                "name": "IEEE Journal of Oceanic Engineering",
                "alternate_names": [
                    "IEEE J Ocean Eng"
                ],
                "issn": "0364-9059",
                "url": "https://ieeexplore.ieee.org/servlet/opac?punumber=48"
            },
            "year": 2006,
            "externalIds": {
                "MAG": "2111804516",
                "DOI": "10.1109/JOE.2004.839933",
                "CorpusId": 27630300
            },
            "abstract": "This paper addresses video tracking, the problem of following moving targets automatically over a video sequence, and brings three main contributions. First, we give a concise introduction to video tracking in computer vision, including design requirements and a review of recent techniques, with some details of selected algorithms. Second, we give an overview of 28 recent papers on subsea video tracking and related motion analysis problems, arguably capturing the state-of-the-art of subsea video tracking. We summarize key features in a comparative, at-a-glance table, and discuss this work in comparison to the state-of-the-art in computer vision. Third, we identify well-proven computer vision techniques not yet embraced by the subsea research community, suggesting useful research directions for the subsea video processing community",
            "referenceCount": 112,
            "citationCount": 183,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2006-10-09",
            "journal": {
                "name": "IEEE Journal of Oceanic Engineering",
                "volume": "31"
            },
            "citationStyles": {
                "bibtex": "@Article{Trucco2006VideoTA,\n author = {Emanuele Trucco and Konstantinos Plakas},\n booktitle = {IEEE Journal of Oceanic Engineering},\n journal = {IEEE Journal of Oceanic Engineering},\n pages = {520-529},\n title = {Video Tracking: A Concise Survey},\n volume = {31},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:845357e48a16eb3bf5c6213162284944f4a30410",
            "@type": "ScholarlyArticle",
            "paperId": "845357e48a16eb3bf5c6213162284944f4a30410",
            "corpusId": 7452614,
            "url": "https://www.semanticscholar.org/paper/845357e48a16eb3bf5c6213162284944f4a30410",
            "title": "A System for Person-Independent Hand Posture Recognition against Complex Backgrounds",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2001,
            "externalIds": {
                "DBLP": "journals/pami/TrieschM01",
                "MAG": "2117683888",
                "DOI": "10.1109/34.977568",
                "CorpusId": 7452614
            },
            "abstract": "A computer vision system for person-independent recognition of hand postures against complex backgrounds is presented. The system is based on the elastic graph matching, which was extended to allow for combinations of different feature types at the graph nodes.",
            "referenceCount": 21,
            "citationCount": 219,
            "influentialCitationCount": 9,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://publikationen.ub.uni-frankfurt.de/files/3376/TriMal-PAMI2001.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2001-12-01",
            "journal": {
                "name": "IEEE Trans. Pattern Anal. Mach. Intell.",
                "volume": "23"
            },
            "citationStyles": {
                "bibtex": "@Article{Triesch2001ASF,\n author = {J. Triesch and C. Malsburg},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Trans. Pattern Anal. Mach. Intell.},\n pages = {1449-1453},\n title = {A System for Person-Independent Hand Posture Recognition against Complex Backgrounds},\n volume = {23},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:024b536094bf8c61c05e631eab3684d575676350",
            "@type": "ScholarlyArticle",
            "paperId": "024b536094bf8c61c05e631eab3684d575676350",
            "corpusId": 14575471,
            "url": "https://www.semanticscholar.org/paper/024b536094bf8c61c05e631eab3684d575676350",
            "title": "Randomized RANSAC with T(d, d) test",
            "venue": "British Machine Vision Conference",
            "publicationVenue": {
                "id": "urn:research:78a7fbcc-41c5-4258-b633-04b8637d4a9f",
                "name": "British Machine Vision Conference",
                "alternate_names": [
                    "Br Mach Vis Conf",
                    "BMVC"
                ],
                "issn": null,
                "url": "http://www.bmva.org/bmvc/"
            },
            "year": 2002,
            "externalIds": {
                "MAG": "2109069996",
                "DBLP": "conf/bmvc/MatasC02",
                "DOI": "10.5244/C.16.43",
                "CorpusId": 14575471
            },
            "abstract": "Many computer vision algorithms include a robust estimation step where model parameters are computed from a data set containing a significant proportion of outliers. The RANSAC algorithm is possibly the most widely used robust estimator in the field of computer vision. In the paper we show that under a broad range of conditions, RANSAC efficiency is significantly improved if its hypothesis evaluation step is randomized. A new randomized (hypothesis evaluation) version of the RANSAC algorithm, R-RANSAC, is introduced. Computational savings are achieved by typically evaluating only a fraction of data points for models contaminated with outliers. The idea is implemented in a two-step evaluation procedure. A mathematically tractable class of statistical preverification tests for test samples is introduced. For this class of preverification test we derive an approximate relation for the optimal setting of its single parameter. The proposed pre-test is evaluated on both synthetic data and real-world problems and a significant increase in speed is shown.",
            "referenceCount": 15,
            "citationCount": 191,
            "influentialCitationCount": 17,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://cmp.felk.cvut.cz/~matas/papers/chum-bmvc02.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Matas2002RandomizedRW,\n author = {Jiri Matas and Ond\u0159ej Chum},\n booktitle = {British Machine Vision Conference},\n pages = {1-10},\n title = {Randomized RANSAC with T(d, d) test},\n year = {2002}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7319a3a78763ed04bc8fe4b34a8248af52137e3c",
            "@type": "ScholarlyArticle",
            "paperId": "7319a3a78763ed04bc8fe4b34a8248af52137e3c",
            "corpusId": 322494,
            "url": "https://www.semanticscholar.org/paper/7319a3a78763ed04bc8fe4b34a8248af52137e3c",
            "title": "Perception-based 3D triangle mesh segmentation using fast marching watersheds",
            "venue": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2003,
            "externalIds": {
                "MAG": "2113169414",
                "DBLP": "conf/cvpr/PageKA03",
                "DOI": "10.1109/CVPR.2003.1211448",
                "CorpusId": 322494
            },
            "abstract": "In this paper, we describe an algorithm called fast marching watersheds that segments a triangle mesh into visual parts. This computer vision algorithm leverages a human vision theory known as the minima rule. Our implementation computes the principal curvatures and principal directions at each vertex of a mesh, and then our hill-climbing watershed algorithm identifies regions bounded by contours of negative curvature minima. These regions fit the definition of visual parts according to the minima rule. We present evaluation analysis and experimental results for the proposed algorithm.",
            "referenceCount": 19,
            "citationCount": 191,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://imaging.utk.edu/publications/papers/2003/page_cvpr03.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2003-06-18",
            "journal": {
                "name": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings.",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Page2003Perceptionbased3T,\n author = {D. Page and A. Koschan and M. Abidi},\n booktitle = {2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings.},\n journal = {2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings.},\n pages = {II-II},\n title = {Perception-based 3D triangle mesh segmentation using fast marching watersheds},\n volume = {2},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8ba4f440c775f2115ad58c0453cc3422e49bc117",
            "@type": "ScholarlyArticle",
            "paperId": "8ba4f440c775f2115ad58c0453cc3422e49bc117",
            "corpusId": 122436138,
            "url": "https://www.semanticscholar.org/paper/8ba4f440c775f2115ad58c0453cc3422e49bc117",
            "title": "Group-Theoretical Methods in Image Understanding",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1990,
            "externalIds": {
                "MAG": "1491306163",
                "DOI": "10.1007/978-3-642-61275-6",
                "CorpusId": 122436138
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 249,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1990-04-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Kanatani1990GroupTheoreticalMI,\n author = {K. Kanatani},\n title = {Group-Theoretical Methods in Image Understanding},\n year = {1990}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c4ee4f7a2342ae1adf7b5f2f48fe9251f8677dd5",
            "@type": "ScholarlyArticle",
            "paperId": "c4ee4f7a2342ae1adf7b5f2f48fe9251f8677dd5",
            "corpusId": 16009092,
            "url": "https://www.semanticscholar.org/paper/c4ee4f7a2342ae1adf7b5f2f48fe9251f8677dd5",
            "title": "Visualizing features and tracking their evolution",
            "venue": "Computer",
            "publicationVenue": {
                "id": "urn:research:f6572f66-2623-4a5e-b0d9-4a5028dea98f",
                "name": "Computer",
                "alternate_names": [
                    "IEEE Computer",
                    "IEEE Comput"
                ],
                "issn": "0018-9162",
                "url": "http://www.computer.org/computer"
            },
            "year": 1994,
            "externalIds": {
                "DBLP": "journals/computer/SamtaneySZC94",
                "MAG": "2103352588",
                "DOI": "10.1109/2.299407",
                "CorpusId": 16009092
            },
            "abstract": "We describe basic algorithms to extract coherent amorphous regions (features or objects) from 2 and 3D scalar and vector fields and then track them in a series of consecutive time steps. We use a combination of techniques from computer vision, image processing, computer graphics, and computational geometry and apply them to data sets from computational fluid dynamics. We demonstrate how these techniques can reduce visual clutter and provide the first step to quantifying observable phenomena. These results can be generalized to other disciplines with continuous time-dependent scalar (and vector) fields.<<ETX>>",
            "referenceCount": 15,
            "citationCount": 230,
            "influentialCitationCount": 14,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1994-07-01",
            "journal": {
                "name": "Computer",
                "volume": "27"
            },
            "citationStyles": {
                "bibtex": "@Article{Samtaney1994VisualizingFA,\n author = {R. Samtaney and D. Silver and N. Zabusky and Jim Cao},\n booktitle = {Computer},\n journal = {Computer},\n pages = {20-27},\n title = {Visualizing features and tracking their evolution},\n volume = {27},\n year = {1994}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:85bff6b31e61204e919fcd3253049bc4649fc384",
            "@type": "ScholarlyArticle",
            "paperId": "85bff6b31e61204e919fcd3253049bc4649fc384",
            "corpusId": 940389,
            "url": "https://www.semanticscholar.org/paper/85bff6b31e61204e919fcd3253049bc4649fc384",
            "title": "The Hamilton-Jacobi skeleton",
            "venue": "Proceedings of the Seventh IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1999,
            "externalIds": {
                "DBLP": "conf/iccv/SiddiqiBTZ99",
                "MAG": "2150179889",
                "DOI": "10.1109/ICCV.1999.790307",
                "CorpusId": 940389
            },
            "abstract": "The eikonal equation and variants of it are of significant interest for problems in computer vision and image processing. It is the basis for continuous versions of mathematical morphology, stereo, shape-from-shading and for recent dynamic theories of shape. Its numerical simulation can be delicate, owing to the formation of singularities in the evolving front, and is typically based or, level set methods. However there are more classical approaches rooted in Hamiltonian physics, which have received little consideration in computer vision. In this paper we first introduce a new algorithm for simulating the eikonal equation, which offers a number of computational and conceptual advantages over the earlier methods when it comes to shock tracking. Next, we introduce a very efficient algorithm for shock detection, where the key idea is to measure the net outward flux of a vector field per unit volume, and to detect locations where a conservation of energy principle is violated. We illustrate the approach with several numerical examples including skeletons of complex 2D and 3D shapes.",
            "referenceCount": 26,
            "citationCount": 187,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://smartech.gatech.edu/bitstream/1853/32154/1/1999_IEEE_ICCV_001.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1999-09-20",
            "journal": {
                "name": "Proceedings of the Seventh IEEE International Conference on Computer Vision",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Siddiqi1999TheHS,\n author = {Kaleem Siddiqi and S. Bouix and A. Tannenbaum and S. Zucker},\n booktitle = {Proceedings of the Seventh IEEE International Conference on Computer Vision},\n journal = {Proceedings of the Seventh IEEE International Conference on Computer Vision},\n pages = {828-834 vol.2},\n title = {The Hamilton-Jacobi skeleton},\n volume = {2},\n year = {1999}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b72a47b989807ef4376b0dd428f34e899190d91c",
            "@type": "ScholarlyArticle",
            "paperId": "b72a47b989807ef4376b0dd428f34e899190d91c",
            "corpusId": 7237532,
            "url": "https://www.semanticscholar.org/paper/b72a47b989807ef4376b0dd428f34e899190d91c",
            "title": "On-road vehicle detection using optical sensors: a review",
            "venue": "Proceedings. The 7th International IEEE Conference on Intelligent Transportation Systems (IEEE Cat. No.04TH8749)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2004,
            "externalIds": {
                "MAG": "2118152222",
                "DOI": "10.1109/ITSC.2004.1398966",
                "CorpusId": 7237532
            },
            "abstract": "As one of the most promising applications of computer vision, vision-based vehicle detection for driver assistance has received considerable attention over the last 15 years. There are at least three reasons for the blooming research in this field: first, the startling losses both in human lives and finance caused by vehicle accidents; second, the availability of feasible technologies accumulated within the last 30 years of computer vision research; and third, the exponential growth of processor speed has paved the way for running computation-intensive video-processing algorithms even on a low-end PC in realtime. This paper provides a critical survey of recent vision-based on-road vehicle detection systems appeared in the literature (i.e., the cameras are mounted on the vehicle rather than being static such as in traffic/driveway monitoring systems).",
            "referenceCount": 54,
            "citationCount": 179,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Conference",
                "Review"
            ],
            "publicationDate": "2004-10-03",
            "journal": {
                "name": "Proceedings. The 7th International IEEE Conference on Intelligent Transportation Systems (IEEE Cat. No.04TH8749)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Conference{Sun2004OnroadVD,\n author = {Zehang Sun and G. Bebis and Ronald Miller},\n booktitle = {Proceedings. The 7th International IEEE Conference on Intelligent Transportation Systems (IEEE Cat. No.04TH8749)},\n journal = {Proceedings. The 7th International IEEE Conference on Intelligent Transportation Systems (IEEE Cat. No.04TH8749)},\n pages = {585-590},\n title = {On-road vehicle detection using optical sensors: a review},\n year = {2004}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ffac24c220bdb3d1deedb78b18c68a932915e5f9",
            "@type": "ScholarlyArticle",
            "paperId": "ffac24c220bdb3d1deedb78b18c68a932915e5f9",
            "corpusId": 441561,
            "url": "https://www.semanticscholar.org/paper/ffac24c220bdb3d1deedb78b18c68a932915e5f9",
            "title": "Action Recognition Using a Bio-Inspired Feedforward Spiking Network",
            "venue": "International Journal of Computer Vision",
            "publicationVenue": {
                "id": "urn:research:939ee07c-6009-43f8-b884-69238b40659e",
                "name": "International Journal of Computer Vision",
                "alternate_names": [
                    "Int J Comput Vis"
                ],
                "issn": "0920-5691",
                "url": "https://www.springer.com/computer/image+processing/journal/11263"
            },
            "year": 2009,
            "externalIds": {
                "MAG": "1972053684",
                "DBLP": "journals/ijcv/EscobarMVK09",
                "DOI": "10.1007/s11263-008-0201-1",
                "CorpusId": 441561
            },
            "abstract": null,
            "referenceCount": 93,
            "citationCount": 87,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2009-05-01",
            "journal": {
                "name": "International Journal of Computer Vision",
                "volume": "82"
            },
            "citationStyles": {
                "bibtex": "@Article{Escobar2009ActionRU,\n author = {M. Escobar and G. Masson and T. Vi\u00e9ville and Pierre Kornprobst},\n booktitle = {International Journal of Computer Vision},\n journal = {International Journal of Computer Vision},\n pages = {284-301},\n title = {Action Recognition Using a Bio-Inspired Feedforward Spiking Network},\n volume = {82},\n year = {2009}\n}\n"
            }
        }
    }
]