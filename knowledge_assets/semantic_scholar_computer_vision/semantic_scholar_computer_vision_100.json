[
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:192235f5a9e4c9d6a28ec0d333e36f294b32f764",
            "@type": "ScholarlyArticle",
            "paperId": "192235f5a9e4c9d6a28ec0d333e36f294b32f764",
            "corpusId": 8589339,
            "url": "https://www.semanticscholar.org/paper/192235f5a9e4c9d6a28ec0d333e36f294b32f764",
            "title": "Reconfiguring the Imaging Pipeline for Computer Vision",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2954782598",
                "ArXiv": "1705.04352",
                "DBLP": "conf/iccv/BucklerJS17",
                "DOI": "10.1109/ICCV.2017.111",
                "CorpusId": 8589339
            },
            "abstract": "Advancements in deep learning have ignited an explosion of research on efficient hardware for embedded computer vision. Hardware vision acceleration, however, does not address the cost of capturing and processing the image data that feeds these algorithms. We examine the role of the image signal processing (ISP) pipeline in computer vision to identify opportunities to reduce computation and save energy. The key insight is that imaging pipelines should be be configurable: to switch between a traditional photography mode and a low-power vision mode that produces lower-quality image data suitable only for computer vision. We use eight computer vision algorithms and a reversible pipeline simulation tool to study the imaging system's impact on vision performance. For both CNN-based and classical vision algorithms, we observe that only two ISP stages, demosaicing and gamma compression, are critical for task performance. We propose a new image sensor design that can compensate for these stages. The sensor design features an adjustable resolution and tunable analog-to-digital converters (ADCs). Our proposed imaging system's vision mode disables the ISP entirely and configures the sensor to produce subsampled, lower-precision image data. This vision mode can save ~75% of the average energy of a baseline photography mode with only a small impact on vision task accuracy.",
            "referenceCount": 55,
            "citationCount": 88,
            "influentialCitationCount": 13,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1705.04352",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-05-11",
            "journal": {
                "name": "2017 IEEE International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Buckler2017ReconfiguringTI,\n author = {Mark Buckler and Suren Jayasuriya and Adrian Sampson},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2017 IEEE International Conference on Computer Vision (ICCV)},\n pages = {975-984},\n title = {Reconfiguring the Imaging Pipeline for Computer Vision},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:84e32cdb2a9e2fba5794f25fdd6f30cf33cdc2c2",
            "@type": "ScholarlyArticle",
            "paperId": "84e32cdb2a9e2fba5794f25fdd6f30cf33cdc2c2",
            "corpusId": 27400335,
            "url": "https://www.semanticscholar.org/paper/84e32cdb2a9e2fba5794f25fdd6f30cf33cdc2c2",
            "title": "Machine learning and computer vision approaches for phenotypic profiling",
            "venue": "Journal of Cell Biology",
            "publicationVenue": {
                "id": "urn:research:bf59074e-18fd-4f9a-a1b0-a9bafc16f518",
                "name": "Journal of Cell Biology",
                "alternate_names": [
                    "J Cell Biology"
                ],
                "issn": "0021-9525",
                "url": "http://www.pubmedcentral.nih.gov/tocrender.fcgi?action=archive&journal=482"
            },
            "year": 2017,
            "externalIds": {
                "PubMedCentral": "5223612",
                "MAG": "2560741024",
                "DOI": "10.1083/jcb.201610026",
                "CorpusId": 27400335,
                "PubMed": "27940887"
            },
            "abstract": "Grys et al. review computer vision and machine-learning methods that have been applied to phenotypic profiling of image-based data. Descriptions are provided for segmentation, feature extraction, selection, and dimensionality reduction, as well as clustering, outlier detection, and classification of data.",
            "referenceCount": 79,
            "citationCount": 128,
            "influentialCitationCount": 1,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://rupress.org/jcb/article-pdf/216/1/65/1374031/jcb_201610026.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Biology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2017-01-02",
            "journal": {
                "name": "The Journal of Cell Biology",
                "volume": "216"
            },
            "citationStyles": {
                "bibtex": "@Article{Grys2017MachineLA,\n author = {Ben T Grys and Dara S Lo and Nil Sahin and Oren Z. Kraus and Q. Morris and Charles Boone and B. Andrews},\n booktitle = {Journal of Cell Biology},\n journal = {The Journal of Cell Biology},\n pages = {65 - 71},\n title = {Machine learning and computer vision approaches for phenotypic profiling},\n volume = {216},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:979d536c45227aff97ef7e663cdcc1fd509410f2",
            "@type": "ScholarlyArticle",
            "paperId": "979d536c45227aff97ef7e663cdcc1fd509410f2",
            "corpusId": 242552013,
            "url": "https://www.semanticscholar.org/paper/979d536c45227aff97ef7e663cdcc1fd509410f2",
            "title": "Computer Vision",
            "venue": "Practical Machine Learning with Rust",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "DOI": "10.1007/978-1-4842-5121-8_6",
                "CorpusId": 242552013
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 1,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2019-12-11",
            "journal": {
                "name": "Practical Machine Learning with Rust",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bhattacharjee2019ComputerV,\n author = {J. Bhattacharjee},\n booktitle = {Practical Machine Learning with Rust},\n journal = {Practical Machine Learning with Rust},\n title = {Computer Vision},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:739ceacfafb1c4eaa17509351b647c773270b3ae",
            "@type": "ScholarlyArticle",
            "paperId": "739ceacfafb1c4eaa17509351b647c773270b3ae",
            "corpusId": 233024948,
            "url": "https://www.semanticscholar.org/paper/739ceacfafb1c4eaa17509351b647c773270b3ae",
            "title": "An Empirical Study of Training Self-Supervised Vision Transformers",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "journals/corr/abs-2104-02057",
                "ArXiv": "2104.02057",
                "MAG": "3145450063",
                "DOI": "10.1109/ICCV48922.2021.00950",
                "CorpusId": 233024948
            },
            "abstract": "This paper does not describe a novel method. Instead, it studies a straightforward, incremental, yet must-know baseline given the recent progress in computer vision: self-supervised learning for Vision Transformers (ViT). While the training recipes for standard convolutional networks have been highly mature and robust, the recipes for ViT are yet to be built, especially in the self-supervised scenarios where training becomes more challenging. In this work, we go back to basics and investigate the effects of several fundamental components for training self-supervised ViT. We observe that instability is a major issue that degrades accuracy, and it can be hidden by apparently good results. We reveal that these results are indeed partial failure, and they can be improved when training is made more stable. We benchmark ViT results in MoCo v3 and several other self-supervised frameworks, with ablations in various aspects. We discuss the currently positive evidence as well as challenges and open questions. We hope that this work will provide useful data points and experience for future research.",
            "referenceCount": 50,
            "citationCount": 1090,
            "influentialCitationCount": 170,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2104.02057",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2021-04-05",
            "journal": {
                "name": "2021 IEEE/CVF International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Chen2021AnES,\n author = {Xinlei Chen and Saining Xie and Kaiming He},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},\n pages = {9620-9629},\n title = {An Empirical Study of Training Self-Supervised Vision Transformers},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:363274316994e0b4d3377ebaa1ba942f61f510a3",
            "@type": "ScholarlyArticle",
            "paperId": "363274316994e0b4d3377ebaa1ba942f61f510a3",
            "corpusId": 206984585,
            "url": "https://www.semanticscholar.org/paper/363274316994e0b4d3377ebaa1ba942f61f510a3",
            "title": "Computer vision syndrome among computer office workers in a developing country: an evaluation of prevalence and risk factors",
            "venue": "BMC Research Notes",
            "publicationVenue": {
                "id": "urn:research:4edfcb61-9d1a-429f-a62d-5e205e249979",
                "name": "BMC Research Notes",
                "alternate_names": [
                    "BMC Res Note"
                ],
                "issn": "1756-0500",
                "url": "http://www.biomedcentral.com/bmcresnotes/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2299193384",
                "PubMedCentral": "4784392",
                "DOI": "10.1186/s13104-016-1962-1",
                "CorpusId": 206984585,
                "PubMed": "26956624"
            },
            "abstract": null,
            "referenceCount": 36,
            "citationCount": 233,
            "influentialCitationCount": 28,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://bmcresnotes.biomedcentral.com/track/pdf/10.1186/s13104-016-1962-1",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-03-09",
            "journal": {
                "name": "BMC Research Notes",
                "volume": "9"
            },
            "citationStyles": {
                "bibtex": "@Article{Ranasinghe2016ComputerVS,\n author = {P. Ranasinghe and W. Wathurapatha and Y. Perera and D. A. Lamabadusuriya and S. Kulatunga and N. Jayawardana and P. Katulanda},\n booktitle = {BMC Research Notes},\n journal = {BMC Research Notes},\n title = {Computer vision syndrome among computer office workers in a developing country: an evaluation of prevalence and risk factors},\n volume = {9},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7dc1519bdc2ecc11c7402842dbb792304c230735",
            "@type": "ScholarlyArticle",
            "paperId": "7dc1519bdc2ecc11c7402842dbb792304c230735",
            "corpusId": 4743901,
            "url": "https://www.semanticscholar.org/paper/7dc1519bdc2ecc11c7402842dbb792304c230735",
            "title": "Computer Vision for the Visually Impaired: the Sound of Vision System",
            "venue": "2017 IEEE International Conference on Computer Vision Workshops (ICCVW)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/iccvw/CaraimanMOBRBHM17",
                "MAG": "2770941075",
                "DOI": "10.1109/ICCVW.2017.175",
                "CorpusId": 4743901
            },
            "abstract": "This paper presents a computer vision based sensory substitution device for the visually impaired. Its main objective is to provide the users with a 3D representation of the environment around them, conveyed by means of the hearing and tactile senses. One of the biggest challenges for this system is to ensure pervasiveness, i.e., to be usable in any indoor or outdoor environments and in any illumination conditions. This work reveals both the hardware (3D acquisition system) and software (3D processing pipeline) used for developing this sensory substitution device and provides insight on its exploitation in various scenarios. Preliminary experiments with blind users revealed good usability results and provided valuable feedback for system improvement.",
            "referenceCount": 49,
            "citationCount": 70,
            "influentialCitationCount": 6,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-10-01",
            "journal": {
                "name": "2017 IEEE International Conference on Computer Vision Workshops (ICCVW)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Caraiman2017ComputerVF,\n author = {S. Caraiman and A. Morar and Mateusz Owczarek and A. Burlacu and D. Rzeszotarski and N. Botezatu and P. Herghelegiu and F. Moldoveanu and P. Strumi\u0142\u0142o and A. Moldoveanu},\n booktitle = {2017 IEEE International Conference on Computer Vision Workshops (ICCVW)},\n journal = {2017 IEEE International Conference on Computer Vision Workshops (ICCVW)},\n pages = {1480-1489},\n title = {Computer Vision for the Visually Impaired: the Sound of Vision System},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cc188b35108d089b31cc0cedcfed100e4e7ae8a1",
            "@type": "ScholarlyArticle",
            "paperId": "cc188b35108d089b31cc0cedcfed100e4e7ae8a1",
            "corpusId": 16387148,
            "url": "https://www.semanticscholar.org/paper/cc188b35108d089b31cc0cedcfed100e4e7ae8a1",
            "title": "Deep Learning Advances in Computer Vision with 3D Data",
            "venue": "ACM Computing Surveys",
            "publicationVenue": {
                "id": "urn:research:7b2adce0-d53f-49d6-8784-b0645604fe62",
                "name": "ACM Computing Surveys",
                "alternate_names": [
                    "ACM Comput Surv"
                ],
                "issn": "0360-0300",
                "url": "http://www.acm.org/pubs/surveys/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/csur/IoannidouCNK17",
                "MAG": "2604249033",
                "DOI": "10.1145/3042064",
                "CorpusId": 16387148
            },
            "abstract": "Deep learning has recently gained popularity achieving state-of-the-art performance in tasks involving text, sound, or image processing. Due to its outstanding performance, there have been efforts to apply it in more challenging scenarios, for example, 3D data processing. This article surveys methods applying deep learning on 3D data and provides a classification based on how they exploit them. From the results of the examined works, we conclude that systems employing 2D views of 3D data typically surpass voxel-based (3D) deep models, which however, can perform better with more layers and severe data augmentation. Therefore, larger-scale datasets and increased resolutions are required.",
            "referenceCount": 237,
            "citationCount": 246,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-04-06",
            "journal": {
                "name": "ACM Computing Surveys (CSUR)",
                "volume": "50"
            },
            "citationStyles": {
                "bibtex": "@Article{Ioannidou2017DeepLA,\n author = {Anastasia Ioannidou and E. Chatzilari and S. Nikolopoulos and I. Kompatsiaris},\n booktitle = {ACM Computing Surveys},\n journal = {ACM Computing Surveys (CSUR)},\n pages = {1 - 38},\n title = {Deep Learning Advances in Computer Vision with 3D Data},\n volume = {50},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fa1db5d590d383d721f1ccfd74c8202ee5452070",
            "@type": "ScholarlyArticle",
            "paperId": "fa1db5d590d383d721f1ccfd74c8202ee5452070",
            "corpusId": 54149442,
            "url": "https://www.semanticscholar.org/paper/fa1db5d590d383d721f1ccfd74c8202ee5452070",
            "title": "Explainable and Interpretable Models in Computer Vision and Machine Learning",
            "venue": "The Springer Series on Challenges in Machine Learning",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "ArXiv": "1709.05321",
                "MAG": "2901070617",
                "DOI": "10.1007/978-3-319-98131-4",
                "CorpusId": 54149442
            },
            "abstract": null,
            "referenceCount": 434,
            "citationCount": 81,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/bfm:978-3-319-98131-4/1?pdf=chapter%20toc",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2017-09-15",
            "journal": {
                "name": "The Springer Series on Challenges in Machine Learning",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Escalante2017ExplainableAI,\n author = {H. Escalante and Sergio Escalera and Isabelle M Guyon and Xavier Bar\u00f3 and Ya\u011fmur G\u00fc\u00e7l\u00fct\u00fcrk and Umut G\u00fc\u00e7l\u00fc and M. Gerven},\n booktitle = {The Springer Series on Challenges in Machine Learning},\n journal = {The Springer Series on Challenges in Machine Learning},\n title = {Explainable and Interpretable Models in Computer Vision and Machine Learning},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ce5e7ac609981a1e6da1031cde79c237acc985fe",
            "@type": "ScholarlyArticle",
            "paperId": "ce5e7ac609981a1e6da1031cde79c237acc985fe",
            "corpusId": 22833897,
            "url": "https://www.semanticscholar.org/paper/ce5e7ac609981a1e6da1031cde79c237acc985fe",
            "title": "Automatic Defect Recognition in X-Ray Testing Using Computer Vision",
            "venue": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
            "publicationVenue": {
                "id": "urn:research:acd15a6d-3248-41fb-8439-9a40aabe5608",
                "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                "alternate_names": [
                    "Workshop on Applications of Computer Vision",
                    "WACV",
                    "IEEE Work Conf Appl Comput Vis",
                    "Workshop Appl Comput Vis"
                ],
                "issn": null,
                "url": "http://www.wikicfp.com/cfp/program?id=2993"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2613000917",
                "DBLP": "conf/wacv/MeryA17",
                "DOI": "10.1109/WACV.2017.119",
                "CorpusId": 22833897
            },
            "abstract": "To ensure safety in the construction of important metallic components for roadworthiness, it is necessary to check every component thoroughly using non-destructive testing. In last decades, X-ray testing has been adopted as the principal non-destructive testing method to identify defects within a component which are undetectable to the naked eye. Nowadays, modern computer vision techniques, such as deep learning and sparse representations, are opening new avenues in automatic object recognition in optical images. These techniques have been broadly used in object and texture recognition by the computer vision community with promising results in optical images. However, a comprehensive evaluation in X-ray testing is required. In this paper, we release a new dataset containing around 47.500 cropped X-ray images of 32 32 pixels with defects and no-defects in automotive components. Using this dataset, we evaluate and compare 24 computer vision techniques including deep learning, sparse representations, local descriptors and texture features, among others. We show in our experiments that the best performance was achieved by a simple LBP descriptor with a SVM-linear classifier obtaining 97% precision and 94% recall. We believe that the methodology presented could be used in similar projects that have to deal with automated detection of defects.",
            "referenceCount": 43,
            "citationCount": 73,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Materials Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-03-24",
            "journal": {
                "name": "2017 IEEE Winter Conference on Applications of Computer Vision (WACV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Mery2017AutomaticDR,\n author = {D. Mery and C. Arteta},\n booktitle = {IEEE Workshop/Winter Conference on Applications of Computer Vision},\n journal = {2017 IEEE Winter Conference on Applications of Computer Vision (WACV)},\n pages = {1026-1035},\n title = {Automatic Defect Recognition in X-Ray Testing Using Computer Vision},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c55dfe48a3c49a6dc366d50a60521f73aa31151a",
            "@type": "ScholarlyArticle",
            "paperId": "c55dfe48a3c49a6dc366d50a60521f73aa31151a",
            "corpusId": 10336140,
            "url": "https://www.semanticscholar.org/paper/c55dfe48a3c49a6dc366d50a60521f73aa31151a",
            "title": "Scale-Space Theory in Computer Vision",
            "venue": "Lecture Notes in Computer Science",
            "publicationVenue": {
                "id": "urn:research:2f5d0e8a-faad-4f10-b323-2b2e3c439a78",
                "name": "Lecture Notes in Computer Science",
                "alternate_names": [
                    "LNCS",
                    "Transactions on Computational Systems Biology",
                    "Trans Comput Syst Biology",
                    "Lect Note Comput Sci"
                ],
                "issn": "0302-9743",
                "url": "http://www.springer.com/lncs"
            },
            "year": 1993,
            "externalIds": {
                "DBLP": "books/sp/Lindeberg94",
                "MAG": "2112328181",
                "DOI": "10.1007/3-540-63167-4",
                "CorpusId": 10336140
            },
            "abstract": null,
            "referenceCount": 7,
            "citationCount": 2677,
            "influentialCitationCount": 176,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/bfm:978-1-4757-6465-9/1?pdf=chapter%20toc",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1993-12-31",
            "journal": {
                "name": null,
                "volume": "1252"
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Lindeberg1993ScaleSpaceTI,\n author = {T. Lindeberg},\n booktitle = {Lecture Notes in Computer Science},\n title = {Scale-Space Theory in Computer Vision},\n volume = {1252},\n year = {1993}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:412b3ef02c85087e5f1721176114672c722b17a4",
            "@type": "ScholarlyArticle",
            "paperId": "412b3ef02c85087e5f1721176114672c722b17a4",
            "corpusId": 15929193,
            "url": "https://www.semanticscholar.org/paper/412b3ef02c85087e5f1721176114672c722b17a4",
            "title": "A Taxonomy of Deep Convolutional Neural Nets for Computer Vision",
            "venue": "Frontiers in Robotics and AI",
            "publicationVenue": {
                "id": "urn:research:2ee61499-676f-46c2-afde-d4c0cb4393e6",
                "name": "Frontiers in Robotics and AI",
                "alternate_names": [
                    "Front Robot AI"
                ],
                "issn": "2296-9144",
                "url": "https://www.frontiersin.org/journals/robotics-and-ai"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/SrinivasSMPKB16",
                "MAG": "3101287485",
                "ArXiv": "1601.06615",
                "DOI": "10.3389/frobt.2015.00036",
                "CorpusId": 15929193
            },
            "abstract": "Traditional architectures for solving computer vision problems and the degree of success they enjoyed have been heavily reliant on hand-crafted features. However, of late, deep learning techniques have offered a compelling alternative -- that of automatically learning problem-specific features. With this new paradigm, every problem in computer vision is now being re-examined from a deep learning perspective. Therefore, it has become important to understand what kind of deep networks are suitable for a given problem. Although general surveys of this fast-moving paradigm (i.e. deep-networks) exist, a survey specific to computer vision is missing. We specifically consider one form of deep networks widely used in computer vision - convolutional neural networks (CNNs). We start with \"AlexNet\" as our base CNN and then examine the broad variations proposed over time to suit different applications. We hope that our recipe-style survey will serve as a guide, particularly for novice practitioners intending to use deep-learning techniques for computer vision.",
            "referenceCount": 119,
            "citationCount": 199,
            "influentialCitationCount": 5,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.frontiersin.org/articles/10.3389/frobt.2015.00036/pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2016-01-11",
            "journal": {
                "name": "Frontiers Robotics AI",
                "volume": "2"
            },
            "citationStyles": {
                "bibtex": "@Article{Srinivas2016ATO,\n author = {Suraj Srinivas and Ravi Kiran Sarvadevabhatla and Konda Reddy Mopuri and N. Prabhu and S. Kruthiventi and R. Venkatesh Babu},\n booktitle = {Frontiers in Robotics and AI},\n journal = {Frontiers Robotics AI},\n pages = {36},\n title = {A Taxonomy of Deep Convolutional Neural Nets for Computer Vision},\n volume = {2},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:efa1647594b236361610a20d507127f0586a379b",
            "@type": "ScholarlyArticle",
            "paperId": "efa1647594b236361610a20d507127f0586a379b",
            "corpusId": 252199918,
            "url": "https://www.semanticscholar.org/paper/efa1647594b236361610a20d507127f0586a379b",
            "title": "Diffusion Models in Vision: A Survey",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2022,
            "externalIds": {
                "DBLP": "journals/corr/abs-2209-04747",
                "ArXiv": "2209.04747",
                "DOI": "10.1109/TPAMI.2023.3261988",
                "CorpusId": 252199918,
                "PubMed": "37030794"
            },
            "abstract": "Denoising diffusion models represent a recent emerging topic in computer vision, demonstrating remarkable results in the area of generative modeling. A diffusion model is a deep generative model that is based on two stages, a forward diffusion stage and a reverse diffusion stage. In the forward diffusion stage, the input data is gradually perturbed over several steps by adding Gaussian noise. In the reverse stage, a model is tasked at recovering the original input data by learning to gradually reverse the diffusion process, step by step. Diffusion models are widely appreciated for the quality and diversity of the generated samples, despite their known computational burdens, i.e., low speeds due to the high number of steps involved during sampling. In this survey, we provide a comprehensive review of articles on denoising diffusion models applied in vision, comprising both theoretical and practical contributions in the field. First, we identify and present three generic diffusion modeling frameworks, which are based on denoising diffusion probabilistic models, noise conditioned score networks, and stochastic differential equations. We further discuss the relations between diffusion models and other deep generative models, including variational auto-encoders, generative adversarial networks, energy-based models, autoregressive models and normalizing flows. Then, we introduce a multi-perspective categorization of diffusion models applied in computer vision. Finally, we illustrate the current limitations of diffusion models and envision some interesting directions for future research.",
            "referenceCount": 171,
            "citationCount": 255,
            "influentialCitationCount": 5,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2209.04747",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2022-09-10",
            "journal": {
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "volume": "45"
            },
            "citationStyles": {
                "bibtex": "@Article{Croitoru2022DiffusionMI,\n author = {Florinel-Alin Croitoru and Vlad Hondru and Radu Tudor Ionescu and M. Shah},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {10850-10869},\n title = {Diffusion Models in Vision: A Survey},\n volume = {45},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3e95b708f5f138252f84d8749a5b89cfb5c15dca",
            "@type": "ScholarlyArticle",
            "paperId": "3e95b708f5f138252f84d8749a5b89cfb5c15dca",
            "corpusId": 44969055,
            "url": "https://www.semanticscholar.org/paper/3e95b708f5f138252f84d8749a5b89cfb5c15dca",
            "title": "Introductory techniques for 3-D computer vision",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1998,
            "externalIds": {
                "DBLP": "books/daglib/0001350",
                "MAG": "1555614281",
                "CorpusId": 44969055
            },
            "abstract": "From the Publisher: \nFEATURES: \n \n \nProvides a guide to well-tested theory and algorithms including solutions of problems encountered in modern computer vision. \nContains many practical hints highlighted in the book. \nDevelops two parallel tracks in the presentation, showing how fundamental problems are solved using both intensity and range images, the most popular types of images used today. \nEach chapter contains notes on the literature, review questions, numerical exercises, and projects. \nProvides an Internet list for accessing links to test images, demos, archives and additional learning material.",
            "referenceCount": 0,
            "citationCount": 2185,
            "influentialCitationCount": 175,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Trucco1998IntroductoryTF,\n author = {E. Trucco and A. Verri},\n pages = {I-XVII, 1-341},\n title = {Introductory techniques for 3-D computer vision},\n year = {1998}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6aef8eeff5f532dcdad95043ba464720be664ab8",
            "@type": "ScholarlyArticle",
            "paperId": "6aef8eeff5f532dcdad95043ba464720be664ab8",
            "corpusId": 8003224,
            "url": "https://www.semanticscholar.org/paper/6aef8eeff5f532dcdad95043ba464720be664ab8",
            "title": "Computer vision for assistive technologies",
            "venue": "Computer Vision and Image Understanding",
            "publicationVenue": {
                "id": "urn:research:5fbb417b-d7a5-44e6-856d-993f0624ed9c",
                "name": "Computer Vision and Image Understanding",
                "alternate_names": [
                    "Comput Vis Image Underst"
                ],
                "issn": "1077-3142",
                "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/622809/description#description"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/cviu/LeoMTKF17",
                "MAG": "2513263058",
                "DOI": "10.1016/j.cviu.2016.09.001",
                "CorpusId": 8003224
            },
            "abstract": null,
            "referenceCount": 212,
            "citationCount": 170,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Comput. Vis. Image Underst.",
                "volume": "154"
            },
            "citationStyles": {
                "bibtex": "@Article{Leo2017ComputerVF,\n author = {Marco Leo and G. Medioni and M. Trivedi and T. Kanade and G. Farinella},\n booktitle = {Computer Vision and Image Understanding},\n journal = {Comput. Vis. Image Underst.},\n pages = {1-15},\n title = {Computer vision for assistive technologies},\n volume = {154},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b2fd519abc8d251b44e0d5c90c9a3f2e7a55e686",
            "@type": "ScholarlyArticle",
            "paperId": "b2fd519abc8d251b44e0d5c90c9a3f2e7a55e686",
            "corpusId": 36968004,
            "url": "https://www.semanticscholar.org/paper/b2fd519abc8d251b44e0d5c90c9a3f2e7a55e686",
            "title": "Computer vision for sports: Current applications and research topics",
            "venue": "Computer Vision and Image Understanding",
            "publicationVenue": {
                "id": "urn:research:5fbb417b-d7a5-44e6-856d-993f0624ed9c",
                "name": "Computer Vision and Image Understanding",
                "alternate_names": [
                    "Comput Vis Image Underst"
                ],
                "issn": "1077-3142",
                "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/622809/description#description"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/cviu/ThomasGMCH17",
                "MAG": "2609286783",
                "DOI": "10.1016/j.cviu.2017.04.011",
                "CorpusId": 36968004
            },
            "abstract": null,
            "referenceCount": 70,
            "citationCount": 153,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-06-01",
            "journal": {
                "name": "Comput. Vis. Image Underst.",
                "volume": "159"
            },
            "citationStyles": {
                "bibtex": "@Article{Thomas2017ComputerVF,\n author = {G. Thomas and Rikke Gade and T. Moeslund and Peter Carr and A. Hilton},\n booktitle = {Computer Vision and Image Understanding},\n journal = {Comput. Vis. Image Underst.},\n pages = {3-18},\n title = {Computer vision for sports: Current applications and research topics},\n volume = {159},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:debbe1c4f45854004868a163dbcaf318edaffe0e",
            "@type": "ScholarlyArticle",
            "paperId": "debbe1c4f45854004868a163dbcaf318edaffe0e",
            "corpusId": 9798435,
            "url": "https://www.semanticscholar.org/paper/debbe1c4f45854004868a163dbcaf318edaffe0e",
            "title": "UnrealCV: Connecting Computer Vision to Unreal Engine",
            "venue": "ECCV Workshops",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/corr/QiuY16",
                "MAG": "2517064749",
                "ArXiv": "1609.01326",
                "DOI": "10.1007/978-3-319-49409-8_75",
                "CorpusId": 9798435
            },
            "abstract": null,
            "referenceCount": 21,
            "citationCount": 237,
            "influentialCitationCount": 20,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1609.01326",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-09-05",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1609.01326"
            },
            "citationStyles": {
                "bibtex": "@Article{Qiu2016UnrealCVCC,\n author = {Weichao Qiu and A. Yuille},\n booktitle = {ECCV Workshops},\n journal = {ArXiv},\n title = {UnrealCV: Connecting Computer Vision to Unreal Engine},\n volume = {abs/1609.01326},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:eafb65051a1ea2b5cfdd47dfafb8c363d919a651",
            "@type": "ScholarlyArticle",
            "paperId": "eafb65051a1ea2b5cfdd47dfafb8c363d919a651",
            "corpusId": 17813841,
            "url": "https://www.semanticscholar.org/paper/eafb65051a1ea2b5cfdd47dfafb8c363d919a651",
            "title": "Computer Vision and Image Understanding",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "CorpusId": 17813841
            },
            "abstract": "Self-monitoring) project. The project aims to translate the semeiotic code of the human face into computational descriptors and measures, automatically extracted from videos, multispectral images, and 3D scans of the face. The multisensory platform, being developed as the result of that project, in the form of a smart mirror, looks for signs related to cardio-metabolic risks. The goal is to enable users to self-monitor their well-being status over time and improve their life-style via tailored user guidance. This paper is focused on the description of the part of that sys-tem, utilising computer vision and machine learning techniques to perform 3D morphological analysis of the face and recognition of psycho-somatic status both linked with cardio-metabolic risks. The paper describes the concepts, methods and the developed implementations as well as reports on the results obtained on both real and synthetic datasets.",
            "referenceCount": 67,
            "citationCount": 150,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Andreu2016ComputerVA,\n author = {Yasmina Andreu and F. Chiarugi and S. Colantonio and G. Giannakakis and D. Giorgi and P. Henr\u00edquez and E. Kazantzaki and D. Manousos and K. Marias and B. Matuszewski and M. A. Pascali and M. Pediaditis and Giovanni Raccichini and M. Tsiknakis},\n title = {Computer Vision and Image Understanding},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:64b9e48e71cd766b2503cc6079d52000a1133761",
            "@type": "ScholarlyArticle",
            "paperId": "64b9e48e71cd766b2503cc6079d52000a1133761",
            "corpusId": 8235184,
            "url": "https://www.semanticscholar.org/paper/64b9e48e71cd766b2503cc6079d52000a1133761",
            "title": "What is the Space of Attenuation Coefficients in Underwater Computer Vision?",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/cvpr/AkkaynakTSLTI17",
                "MAG": "2746518190",
                "DOI": "10.1109/CVPR.2017.68",
                "CorpusId": 8235184
            },
            "abstract": "Underwater image reconstruction methods require the knowledge of wideband attenuation coefficients per color channel. Current estimation methods for these coefficients require specialized hardware or multiple images, and none of them leverage the multitude of existing ocean optical measurements as priors. Here, we aim to constrain the set of physically-feasible wideband attenuation coefficients in the ocean by utilizing water attenuation measured worldwide by oceanographers. We calculate the space of valid wideband effective attenuation coefficients in the 3D RGB domain and find that a bound manifold in 3-space sufficiently represents the variation from the clearest to murkiest waters. We validate our model using in situ experiments in two different optical water bodies, the Red Sea and the Mediterranean. Moreover, we show that contradictory to the common image formation model, the coefficients depend on the imaging range and object reflectance, and quantify the errors resulting from ignoring these dependencies.",
            "referenceCount": 53,
            "citationCount": 104,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-07-01",
            "journal": {
                "name": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Akkaynak2017WhatIT,\n author = {D. Akkaynak and T. Treibitz and T. Shlesinger and Yossi Loya and R. Tamir and D. Iluz},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {568-577},\n title = {What is the Space of Attenuation Coefficients in Underwater Computer Vision?},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:84c95a8db377c25d4280f188e9477569ab57281b",
            "@type": "ScholarlyArticle",
            "paperId": "84c95a8db377c25d4280f188e9477569ab57281b",
            "corpusId": 51773513,
            "url": "https://www.semanticscholar.org/paper/84c95a8db377c25d4280f188e9477569ab57281b",
            "title": "Crowdsourcing in Computer Vision",
            "venue": "Foundations and Trends in Computer Graphics and Vision",
            "publicationVenue": {
                "id": "urn:research:a21f6aaa-21ef-418d-b2dd-e56ce6e16570",
                "name": "Foundations and Trends in Computer Graphics and Vision",
                "alternate_names": [
                    "Found Trends Comput Graph Vis"
                ],
                "issn": "1572-2740",
                "url": "https://www.nowpublishers.com/cgv"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/ftcgv/KovashkaRFG16",
                "MAG": "2554692997",
                "ArXiv": "1611.02145",
                "DOI": "10.1561/0600000073",
                "CorpusId": 51773513
            },
            "abstract": "Computer vision systems require large amounts of manually annotated data to properly learn challenging visual concepts. Crowdsourcing platforms offer an inexpensive method to capture human knowledge and understanding, for a vast number of visual perception tasks. Crowdsourcing in Computer Vision describes the types of annotations computer vision researchers have collected using crowdsourcing, and how they have ensured that this data is of high quality while annotation effort is minimized. It begins by discussing data collection on both classic vision tasks, such as object recognition, and recent vision tasks, such as visual story-telling. It then summarizes key design decisions for creating effective data collection interfaces and workflows, and presents strategies for intelligently selecting the most important data instances to annotate. It concludes with some thoughts on the future of crowdsourcing in computer vision. Crowdsourcing in Computer Vision provides an overview of how crowdsourcing has been used in computer vision, enabling a computer vision researcher who has previously not collected non-expert data to devise a data collection strategy. It will also be of help to researchers who focus broadly on crowdsourcing to examine how the latter has been applied in computer vision, and to improve the methods that can be employed to ensure the quality and expedience of data collection.",
            "referenceCount": 192,
            "citationCount": 122,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1611.02145",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2016-11-07",
            "journal": {
                "name": "Found. Trends Comput. Graph. Vis.",
                "volume": "10"
            },
            "citationStyles": {
                "bibtex": "@Article{Kovashka2016CrowdsourcingIC,\n author = {Adriana Kovashka and Olga Russakovsky and Li Fei-Fei and K. Grauman},\n booktitle = {Foundations and Trends in Computer Graphics and Vision},\n journal = {Found. Trends Comput. Graph. Vis.},\n pages = {177-243},\n title = {Crowdsourcing in Computer Vision},\n volume = {10},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:30f3c444500c414169cb33244226dd3f8913e4fe",
            "@type": "ScholarlyArticle",
            "paperId": "30f3c444500c414169cb33244226dd3f8913e4fe",
            "corpusId": 7611267,
            "url": "https://www.semanticscholar.org/paper/30f3c444500c414169cb33244226dd3f8913e4fe",
            "title": "Play and Learn: Using Video Games to Train Computer Vision Models",
            "venue": "British Machine Vision Conference",
            "publicationVenue": {
                "id": "urn:research:78a7fbcc-41c5-4258-b633-04b8637d4a9f",
                "name": "British Machine Vision Conference",
                "alternate_names": [
                    "Br Mach Vis Conf",
                    "BMVC"
                ],
                "issn": null,
                "url": "http://www.bmva.org/bmvc/"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2492904644",
                "DBLP": "conf/bmvc/ShafaeiLS16",
                "ArXiv": "1608.01745",
                "DOI": "10.5244/C.30.26",
                "CorpusId": 7611267
            },
            "abstract": "Video games are a compelling source of annotated data as they can readily provide fine-grained groundtruth for diverse tasks. However, it is not clear whether the synthetically generated data has enough resemblance to the real-world images to improve the performance of computer vision models in practice. We present experiments assessing the effectiveness on real-world data of systems trained on synthetic RGB images that are extracted from a video game. We collected over 60000 synthetic samples from a modern video game with similar conditions to the real-world CamVid and Cityscapes datasets. We provide several experiments to demonstrate that the synthetically generated RGB images can be used to improve the performance of deep neural networks on both image segmentation and depth estimation. These results show that a convolutional network trained on synthetic data achieves a similar test error to a network that is trained on real-world data for dense image classification. Furthermore, the synthetically generated RGB images can provide similar or better results compared to the real-world datasets if a simple domain adaptation technique is applied. Our results suggest that collaboration with game developers for an accessible interface to gather data is potentially a fruitful direction for future work in computer vision.",
            "referenceCount": 52,
            "citationCount": 101,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.bmva.org/bmvc/2016/papers/paper026/abstract026.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-08-01",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1608.01745"
            },
            "citationStyles": {
                "bibtex": "@Article{Shafaei2016PlayAL,\n author = {Alireza Shafaei and J. Little and Mark W. Schmidt},\n booktitle = {British Machine Vision Conference},\n journal = {ArXiv},\n title = {Play and Learn: Using Video Games to Train Computer Vision Models},\n volume = {abs/1608.01745},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:056cb544815a5875156008861e41b574b557b087",
            "@type": "ScholarlyArticle",
            "paperId": "056cb544815a5875156008861e41b574b557b087",
            "corpusId": 12733543,
            "url": "https://www.semanticscholar.org/paper/056cb544815a5875156008861e41b574b557b087",
            "title": "gvnn: Neural Network Library for Geometric Computer Vision",
            "venue": "ECCV Workshops",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1607.07405",
                "DBLP": "journals/corr/HandaBPSMD16",
                "MAG": "2951832501",
                "DOI": "10.1007/978-3-319-49409-8_9",
                "CorpusId": 12733543
            },
            "abstract": null,
            "referenceCount": 31,
            "citationCount": 96,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/978-3-319-49409-8_9.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-07-25",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Handa2016gvnnNN,\n author = {Ankur Handa and Michael Bl\u00f6sch and Viorica Patraucean and Simon Stent and J. McCormac and A. Davison},\n booktitle = {ECCV Workshops},\n pages = {67-82},\n title = {gvnn: Neural Network Library for Geometric Computer Vision},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fb662d021f05236c8ff2bea3be901cd25251487c",
            "@type": "ScholarlyArticle",
            "paperId": "fb662d021f05236c8ff2bea3be901cd25251487c",
            "corpusId": 38060995,
            "url": "https://www.semanticscholar.org/paper/fb662d021f05236c8ff2bea3be901cd25251487c",
            "title": "Computer Vision, Graphics, and Image Processing",
            "venue": "Lecture Notes in Computer Science",
            "publicationVenue": {
                "id": "urn:research:2f5d0e8a-faad-4f10-b323-2b2e3c439a78",
                "name": "Lecture Notes in Computer Science",
                "alternate_names": [
                    "LNCS",
                    "Transactions on Computational Systems Biology",
                    "Trans Comput Syst Biology",
                    "Lect Note Comput Sci"
                ],
                "issn": "0302-9743",
                "url": "http://www.springer.com/lncs"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/icvgip/2016w",
                "MAG": "2766798115",
                "DOI": "10.1007/978-3-319-68124-5",
                "CorpusId": 38060995
            },
            "abstract": null,
            "referenceCount": 33,
            "citationCount": 353,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": "10481"
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Mukherjee2016ComputerVG,\n author = {Snehasis Mukherjee and Suvadip Mukherjee and D. Mukherjee and J. Sivaswamy and Suyash P. Awate and S. Setlur and A. Namboodiri and S. Chaudhury},\n booktitle = {Lecture Notes in Computer Science},\n title = {Computer Vision, Graphics, and Image Processing},\n volume = {10481},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5befb1b0a993a018a55d6fd867af16882d1e9023",
            "@type": "ScholarlyArticle",
            "paperId": "5befb1b0a993a018a55d6fd867af16882d1e9023",
            "corpusId": 2868173,
            "url": "https://www.semanticscholar.org/paper/5befb1b0a993a018a55d6fd867af16882d1e9023",
            "title": "Atoms of recognition in human and computer vision",
            "venue": "Proceedings of the National Academy of Sciences of the United States of America",
            "publicationVenue": {
                "id": "urn:research:bb95bf2e-8383-4748-bf9d-d6906d091085",
                "name": "Proceedings of the National Academy of Sciences of the United States of America",
                "alternate_names": [
                    "PNAS",
                    "PNAS online",
                    "Proceedings of the National Academy of Sciences of the United States of America.",
                    "Proc National Acad Sci",
                    "Proceedings of the National Academy of Sciences",
                    "Proc National Acad Sci u s Am"
                ],
                "issn": "0027-8424",
                "url": "https://www.jstor.org/journal/procnatiacadscie"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2280426979",
                "DOI": "10.1073/pnas.1513198113",
                "CorpusId": 2868173,
                "PubMed": "26884200"
            },
            "abstract": "Significance Discovering the visual features and representations used by the brain to recognize objects is a central problem in the study of vision. Recent successes in computational models of visual recognition naturally raise the question: Do computer systems and the human brain use similar or different computations? We show by combining a novel method (minimal images) and simulations that the human recognition system uses features and learning processes, which are critical for recognition, but are not used by current models. The study uses a \u201cphase transition\u201d phenomenon in minimal images, in which minor changes to the image have a drastic effect on its recognition. The results show fundamental limitations of current approaches and suggest directions to produce more realistic and better-performing models. Discovering the visual features and representations used by the brain to recognize objects is a central problem in the study of vision. Recently, neural network models of visual object recognition, including biological and deep network models, have shown remarkable progress and have begun to rival human performance in some challenging tasks. These models are trained on image examples and learn to extract features and representations and to use them for categorization. It remains unclear, however, whether the representations and learning processes discovered by current models are similar to those used by the human visual system. Here we show, by introducing and using minimal recognizable images, that the human visual system uses features and processes that are not used by current models and that are critical for recognition. We found by psychophysical studies that at the level of minimal recognizable images a minute change in the image can have a drastic effect on recognition, thus identifying features that are critical for the task. Simulations then showed that current models cannot explain this sensitivity to precise feature configurations and, more generally, do not learn to recognize minimal images at a human level. The role of the features shown here is revealed uniquely at the minimal level, where the contribution of each feature is essential. A full understanding of the learning and use of such features will extend our understanding of visual recognition and its cortical mechanisms and will enhance the capacity of computational models to learn from visual experience and to deal with recognition and detailed image interpretation.",
            "referenceCount": 36,
            "citationCount": 150,
            "influentialCitationCount": 11,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.pnas.org/content/pnas/113/10/2744.full.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-02-16",
            "journal": {
                "name": "Proceedings of the National Academy of Sciences",
                "volume": "113"
            },
            "citationStyles": {
                "bibtex": "@Article{Ullman2016AtomsOR,\n author = {S. Ullman and Liav Assif and Ethan Fetaya and Daniel Harari},\n booktitle = {Proceedings of the National Academy of Sciences of the United States of America},\n journal = {Proceedings of the National Academy of Sciences},\n pages = {2744 - 2749},\n title = {Atoms of recognition in human and computer vision},\n volume = {113},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9dd158f601f7796074fa2bf55a0f393c7575a3df",
            "@type": "ScholarlyArticle",
            "paperId": "9dd158f601f7796074fa2bf55a0f393c7575a3df",
            "corpusId": 2171696,
            "url": "https://www.semanticscholar.org/paper/9dd158f601f7796074fa2bf55a0f393c7575a3df",
            "title": "A computer vision based vehicle detection and counting system",
            "venue": "International Conference on Knowledge and Smart Technology",
            "publicationVenue": {
                "id": "urn:research:db9c9754-4cc1-44db-a601-25d0e1d01879",
                "name": "International Conference on Knowledge and Smart Technology",
                "alternate_names": [
                    "KST",
                    "Int Conf Knowl Smart Technol"
                ],
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/kst/SeenouvongWNKO16",
                "MAG": "2303399114",
                "DOI": "10.1109/KST.2016.7440510",
                "CorpusId": 2171696
            },
            "abstract": "A vehicle detection and counting system plays an important role in an intelligent transportation system, especially for traffic management. This paper proposes a video-based method for vehicle detection and counting system based on computer vision technology. The proposed method uses background subtraction technique to find foreground objects in a video sequence. In order to detect moving vehicles more accurately, several computer vision techniques, including thresholding, hole filling and adaptive morphology operations, are then applied. Finally, vehicle counting is done by using a virtual detection zone. Experimental results show that the accuracy of the proposed vehicle counting system is around 96%.",
            "referenceCount": 7,
            "citationCount": 84,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-02-01",
            "journal": {
                "name": "2016 8th International Conference on Knowledge and Smart Technology (KST)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Seenouvong2016ACV,\n author = {Nilakorn Seenouvong and U. Watchareeruetai and C. Nuthong and K. Khongsomboon and N. Ohnishi},\n booktitle = {International Conference on Knowledge and Smart Technology},\n journal = {2016 8th International Conference on Knowledge and Smart Technology (KST)},\n pages = {224-227},\n title = {A computer vision based vehicle detection and counting system},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a9cebafd9c50632a8b5bb6c6a9b3333656cab6bc",
            "@type": "ScholarlyArticle",
            "paperId": "a9cebafd9c50632a8b5bb6c6a9b3333656cab6bc",
            "corpusId": 30019033,
            "url": "https://www.semanticscholar.org/paper/a9cebafd9c50632a8b5bb6c6a9b3333656cab6bc",
            "title": "Effect of contact lens use on Computer Vision Syndrome",
            "venue": "Ophthalmic & physiological optics",
            "publicationVenue": {
                "id": "urn:research:b188600c-27d3-4a50-b40f-445216b9dddc",
                "name": "Ophthalmic & physiological optics",
                "alternate_names": [
                    "Ophthalmic and Physiological Optics",
                    "Ophthalmic  physiol opt",
                    "Ophthalmic Physiol Opt"
                ],
                "issn": "0275-5408",
                "url": "https://onlinelibrary.wiley.com/journal/14751313"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2224403273",
                "DOI": "10.1111/opo.12275",
                "CorpusId": 30019033,
                "PubMed": "26743161"
            },
            "abstract": "To analyse the relationship between Computer Vision Syndrome (CVS) in computer workers and contact lens use, according to lens materials.",
            "referenceCount": 48,
            "citationCount": 72,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Study",
                "JournalArticle"
            ],
            "publicationDate": "2016-03-01",
            "journal": {
                "name": "Ophthalmic and Physiological Optics",
                "volume": "36"
            },
            "citationStyles": {
                "bibtex": "@Article{Tauste2016EffectOC,\n author = {Ana Tauste and E. Ronda and Mar\u00eda-Jos\u00e9 Molina and M. Segu\u00ed},\n booktitle = {Ophthalmic & physiological optics},\n journal = {Ophthalmic and Physiological Optics},\n pages = {112 - 119},\n title = {Effect of contact lens use on Computer Vision Syndrome},\n volume = {36},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3c1370477a40e4ae76e83d2c899103cb8338df0e",
            "@type": "ScholarlyArticle",
            "paperId": "3c1370477a40e4ae76e83d2c899103cb8338df0e",
            "corpusId": 62991054,
            "url": "https://www.semanticscholar.org/paper/3c1370477a40e4ae76e83d2c899103cb8338df0e",
            "title": "Handbook Of Computer Vision And Applications",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2529921745",
                "CorpusId": 62991054
            },
            "abstract": "Thank you for downloading handbook of computer vision and applications. Maybe you have knowledge that, people have look numerous times for their chosen readings like this handbook of computer vision and applications, but end up in harmful downloads. Rather than enjoying a good book with a cup of tea in the afternoon, instead they cope with some harmful virus inside their computer. handbook of computer vision and applications is available in our book collection an online access to it is set as public so you can get it instantly. Our book servers hosts in multiple locations, allowing you to get the most less latency time to download any of our books like this one. Kindly say, the handbook of computer vision and applications is universally compatible with any devices to read.",
            "referenceCount": 0,
            "citationCount": 74,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Hirsch2016HandbookOC,\n author = {Leon Hirsch},\n title = {Handbook Of Computer Vision And Applications},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:061d5e96f1f6d91fe22eec1cde328201149a912d",
            "@type": "ScholarlyArticle",
            "paperId": "061d5e96f1f6d91fe22eec1cde328201149a912d",
            "corpusId": 41423627,
            "url": "https://www.semanticscholar.org/paper/061d5e96f1f6d91fe22eec1cde328201149a912d",
            "title": "Computer Vision \u2013 ECCV 2016",
            "venue": "Lecture Notes in Computer Science",
            "publicationVenue": {
                "id": "urn:research:2f5d0e8a-faad-4f10-b323-2b2e3c439a78",
                "name": "Lecture Notes in Computer Science",
                "alternate_names": [
                    "LNCS",
                    "Transactions on Computational Systems Biology",
                    "Trans Comput Syst Biology",
                    "Lect Note Comput Sci"
                ],
                "issn": "0302-9743",
                "url": "http://www.springer.com/lncs"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/eccv/2016-1",
                "MAG": "2520200494",
                "DOI": "10.1007/978-3-319-46448-0",
                "CorpusId": 41423627
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 77,
            "influentialCitationCount": 0,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": "9905"
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Leibe2016ComputerV,\n author = {B. Leibe and Jiri Matas and N. Sebe and M. Welling},\n booktitle = {Lecture Notes in Computer Science},\n title = {Computer Vision \u2013 ECCV 2016},\n volume = {9905},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:692a1360eb870155c7da2d01bfcf6f15dae3df35",
            "@type": "ScholarlyArticle",
            "paperId": "692a1360eb870155c7da2d01bfcf6f15dae3df35",
            "corpusId": 63625734,
            "url": "https://www.semanticscholar.org/paper/692a1360eb870155c7da2d01bfcf6f15dae3df35",
            "title": "Decision Forests For Computer Vision And Medical Image Analysis",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2507831994",
                "CorpusId": 63625734
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 138,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Eberhart2016DecisionFF,\n author = {M. Eberhart},\n title = {Decision Forests For Computer Vision And Medical Image Analysis},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:eb1178a81239c0d17a09cdcdbf9a6fd16f645ed8",
            "@type": "ScholarlyArticle",
            "paperId": "eb1178a81239c0d17a09cdcdbf9a6fd16f645ed8",
            "corpusId": 5916572,
            "url": "https://www.semanticscholar.org/paper/eb1178a81239c0d17a09cdcdbf9a6fd16f645ed8",
            "title": "Photogrammetric Computer Vision - Statistics, Geometry, Orientation and Reconstruction",
            "venue": "Geometry and Computing",
            "publicationVenue": {
                "id": "urn:research:96127b8e-75fe-46d4-97a4-1a69e57c796c",
                "name": "Geometry and Computing",
                "alternate_names": [
                    "Geom Comput"
                ],
                "issn": "1866-6795",
                "url": "https://www.springer.com/series/7580"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "series/gac/ForstnerW16",
                "MAG": "2528398598",
                "DOI": "10.1007/978-3-319-11550-4",
                "CorpusId": 5916572
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 141,
            "influentialCitationCount": 13,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2016-10-12",
            "journal": {
                "name": null,
                "volume": "11"
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{F\u00f6rstner2016PhotogrammetricCV,\n author = {W. F\u00f6rstner and B. Wrobel},\n booktitle = {Geometry and Computing},\n pages = {1-816},\n title = {Photogrammetric Computer Vision - Statistics, Geometry, Orientation and Reconstruction},\n volume = {11},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:67040b931c1a384426c44ae73f9553e97f08cf6a",
            "@type": "ScholarlyArticle",
            "paperId": "67040b931c1a384426c44ae73f9553e97f08cf6a",
            "corpusId": 235652212,
            "url": "https://www.semanticscholar.org/paper/67040b931c1a384426c44ae73f9553e97f08cf6a",
            "title": "PVT v2: Improved baselines with Pyramid Vision Transformer",
            "venue": "Computational Visual Media",
            "publicationVenue": {
                "id": "urn:research:d2dfc02a-9028-4345-b6cf-556b76ac435b",
                "name": "Computational Visual Media",
                "alternate_names": [
                    "Comput Vis Media"
                ],
                "issn": "2096-0433",
                "url": "http://www.springer.com/41095"
            },
            "year": 2021,
            "externalIds": {
                "ArXiv": "2106.13797",
                "DBLP": "journals/cvm/WangXLFSLLLS22",
                "DOI": "10.1007/s41095-022-0274-8",
                "CorpusId": 235652212
            },
            "abstract": null,
            "referenceCount": 41,
            "citationCount": 656,
            "influentialCitationCount": 131,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/s41095-022-0274-8.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-06-25",
            "journal": {
                "name": "Computational Visual Media",
                "volume": "8"
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2021PVTVI,\n author = {Wenhai Wang and Enze Xie and Xiang Li and Deng-Ping Fan and Kaitao Song and Ding Liang and Tong Lu and P. Luo and Ling Shao},\n booktitle = {Computational Visual Media},\n journal = {Computational Visual Media},\n pages = {415 - 424},\n title = {PVT v2: Improved baselines with Pyramid Vision Transformer},\n volume = {8},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a9eaaecf23f3a4b7822e4bcca924e02cd5b4dc4e",
            "@type": "ScholarlyArticle",
            "paperId": "a9eaaecf23f3a4b7822e4bcca924e02cd5b4dc4e",
            "corpusId": 61087042,
            "url": "https://www.semanticscholar.org/paper/a9eaaecf23f3a4b7822e4bcca924e02cd5b4dc4e",
            "title": "Computer and Robot Vision",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1991,
            "externalIds": {
                "MAG": "1564419782",
                "CorpusId": 61087042
            },
            "abstract": "From the Publisher: \nThis two-volume set is an authoritative, comprehensive, modern work on computer vision that covers all of the different areas of vision with a balanced and unified approach. The discussion in \"Volume I\" focuses on image in, and image out or feature set out. \"Volume II\" covers the higher level techniques of illumination, perspective projection, analytical photogrammetry, motion, image matching, consistent labeling, model matching, and knowledge-based vision systems.",
            "referenceCount": 0,
            "citationCount": 3272,
            "influentialCitationCount": 87,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1991-09-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Haralock1991ComputerAR,\n author = {Robert M. Haralock and L. Shapiro},\n title = {Computer and Robot Vision},\n year = {1991}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:eb5aadc3dd9e3048571586dcf8b05dc2722b3bcf",
            "@type": "ScholarlyArticle",
            "paperId": "eb5aadc3dd9e3048571586dcf8b05dc2722b3bcf",
            "corpusId": 30733145,
            "url": "https://www.semanticscholar.org/paper/eb5aadc3dd9e3048571586dcf8b05dc2722b3bcf",
            "title": "Advances in Computer Vision and Pattern Recognition",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "CorpusId": 30733145
            },
            "abstract": "In this chapter, we present Bayesian models for diffeomorphic shape variability in populations of images. The first model is a probabilistic formulation of the image atlas construction problem, which seeks to compute an atlas image most representative of a set of input images. The second model adds diffeomorphic modes of shape variation, or principal geodesics. Both of these models represent shape variability as random variables on the manifold of diffeomorphic transformations. We define a Gaussian prior distribution for diffeomorphic transformations using the inner product in the tangent space to the diffeomorphism group. We develop a Monte Carlo Expectation Maximization (MCEM) algorithm for the Bayesian inference, due to the lack of closed-form solutions, where the expectation step is approximated via Hamiltonian Monte Carlo (HMC) sampling of diffeomorphisms. The resulting inference produces estimates of the image atlas, principal geodesic modes of variation, and model parameters. We show that the advantage of the Bayesian formulation is that it provides a principled way to estimate both the regularization parameter of the diffeomorphic transformations and the intrinsic dimensionality of the input data.",
            "referenceCount": 291,
            "citationCount": 186,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Bowyer2016AdvancesIC,\n author = {K. Bowyer and Sameer Singh and M. Burge},\n title = {Advances in Computer Vision and Pattern Recognition},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1b9ba6c71113dc2e67f719fe1db5246a59db6eda",
            "@type": "ScholarlyArticle",
            "paperId": "1b9ba6c71113dc2e67f719fe1db5246a59db6eda",
            "corpusId": 10461252,
            "url": "https://www.semanticscholar.org/paper/1b9ba6c71113dc2e67f719fe1db5246a59db6eda",
            "title": "Efficient Intersection of Three Quadrics and Applications in Computer Vision",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/cvpr/KukelovaHF16",
                "MAG": "2463978669",
                "DOI": "10.1109/CVPR.2016.199",
                "CorpusId": 10461252
            },
            "abstract": "In this paper, we present a new algorithm for finding all intersections of three quadrics. The proposed method is algebraic in nature and it is considerably more efficient than the Gro\u0308bner basis and resultant-based solutions previously used in computer vision applications. We identify several computer vision problems that are formulated and solved as systems of three quadratic equations and for which our algorithm readily delivers considerably faster results. Also, we propose new formulations of three important vision problems: absolute camera pose with unknown focal length, generalized pose-and-scale, and hand-eye calibration with known translation. These new formulations allow our algorithm to significantly outperform the state-of-the-art in speed.",
            "referenceCount": 40,
            "citationCount": 45,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-06-27",
            "journal": {
                "name": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Kukelova2016EfficientIO,\n author = {Z. Kukelova and Jan Heller and A. Fitzgibbon},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {1799-1808},\n title = {Efficient Intersection of Three Quadrics and Applications in Computer Vision},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2d63ec5af60b4895e2710428ec0950f503d73a82",
            "@type": "ScholarlyArticle",
            "paperId": "2d63ec5af60b4895e2710428ec0950f503d73a82",
            "corpusId": 3870255,
            "url": "https://www.semanticscholar.org/paper/2d63ec5af60b4895e2710428ec0950f503d73a82",
            "title": "Computer vision-based method for concrete crack detection",
            "venue": "International Conference on Control, Automation, Robotics and Vision",
            "publicationVenue": {
                "id": "urn:research:413493e7-4bb6-4c68-a57a-e21b1b3ca448",
                "name": "International Conference on Control, Automation, Robotics and Vision",
                "alternate_names": [
                    "Int Conf Control Autom Robot Vis",
                    "ICARCV"
                ],
                "issn": null,
                "url": "https://www.ieee-ras.org/conferences-workshops/technically-co-sponsored/icarcv"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/icarcv/DinhHL16",
                "MAG": "2516939133",
                "DOI": "10.1109/ICARCV.2016.7838682",
                "CorpusId": 3870255
            },
            "abstract": "This paper presents a computer vision-based method to automatically detect concrete cracks. We focus on images containing the concrete: background and crack, where the background is the major mode of the gray-scale histogram. Therefore, we address the detection problem of potential concrete cracks by dealing with histogram thresholding to extract regions of interests from the background. We first employ line emphasis and moving average filters to remove noise from concrete surface images obtained from an inspection robot. The developed algorithm is then applied for automatic detection of significant peaks from the gray-scale histogram of the smoothed image. The biggest peak and its corresponding valley(s) are consequently identified to calculate the threshold value for image binarization. The effectiveness of our proposed method was successfully evaluated on various test images, where cracks could be identified without the requirement of some heuristic reasoning.",
            "referenceCount": 16,
            "citationCount": 56,
            "influentialCitationCount": 0,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://opus.lib.uts.edu.au/bitstream/10453/89624/6/Computer%2bvision-based%2bmethod%2bfor%2bconcrete%2bcrack%2bdetection.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Materials Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2016-11-01",
            "journal": {
                "name": "2016 14th International Conference on Control, Automation, Robotics and Vision (ICARCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Dinh2016ComputerVM,\n author = {Tran Hiep Dinh and Q. Ha and Hung M. La},\n booktitle = {International Conference on Control, Automation, Robotics and Vision},\n journal = {2016 14th International Conference on Control, Automation, Robotics and Vision (ICARCV)},\n pages = {1-6},\n title = {Computer vision-based method for concrete crack detection},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:050da5d159fb0dd96143948e1cffeb3dec814673",
            "@type": "ScholarlyArticle",
            "paperId": "050da5d159fb0dd96143948e1cffeb3dec814673",
            "corpusId": 8687210,
            "url": "https://www.semanticscholar.org/paper/050da5d159fb0dd96143948e1cffeb3dec814673",
            "title": "Visual Turing test for computer vision systems",
            "venue": "Proceedings of the National Academy of Sciences of the United States of America",
            "publicationVenue": {
                "id": "urn:research:bb95bf2e-8383-4748-bf9d-d6906d091085",
                "name": "Proceedings of the National Academy of Sciences of the United States of America",
                "alternate_names": [
                    "PNAS",
                    "PNAS online",
                    "Proceedings of the National Academy of Sciences of the United States of America.",
                    "Proc National Acad Sci",
                    "Proceedings of the National Academy of Sciences",
                    "Proc National Acad Sci u s Am"
                ],
                "issn": "0027-8424",
                "url": "https://www.jstor.org/journal/procnatiacadscie"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "journals/pnas/GemanGHY15",
                "MAG": "1983927101",
                "DOI": "10.1073/pnas.1422953112",
                "CorpusId": 8687210,
                "PubMed": "25755262"
            },
            "abstract": "Significance In computer vision, as in other fields of artificial intelligence, the methods of evaluation largely define the scientific effort. Most current evaluations measure detection accuracy, emphasizing the classification of regions according to objects from a predefined library. But detection is not the same as understanding. We present here a different evaluation system, in which a query engine prepares a written test (\u201cvisual Turing test\u201d) that uses binary questions to probe a system\u2019s ability to identify attributes and relationships in addition to recognizing objects. Today, computer vision systems are tested by their accuracy in detecting and localizing instances of objects. As an alternative, and motivated by the ability of humans to provide far richer descriptions and even tell a story about an image, we construct a \u201cvisual Turing test\u201d: an operator-assisted device that produces a stochastic sequence of binary questions from a given test image. The query engine proposes a question; the operator either provides the correct answer or rejects the question as ambiguous; the engine proposes the next question (\u201cjust-in-time truthing\u201d). The test is then administered to the computer-vision system, one question at a time. After the system\u2019s answer is recorded, the system is provided the correct answer and the next question. Parsing is trivial and deterministic; the system being tested requires no natural language processing. The query engine employs statistical constraints, learned from a training set, to produce questions with essentially unpredictable answers\u2014the answer to a question, given the history of questions and their correct answers, is nearly equally likely to be positive or negative. In this sense, the test is only about vision. The system is designed to produce streams of questions that follow natural story lines, from the instantiation of a unique object, through an exploration of its properties, and on to its relationships with other uniquely instantiated objects.",
            "referenceCount": 29,
            "citationCount": 272,
            "influentialCitationCount": 16,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.pnas.org/content/pnas/112/12/3618.full.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-03-09",
            "journal": {
                "name": "Proceedings of the National Academy of Sciences",
                "volume": "112"
            },
            "citationStyles": {
                "bibtex": "@Article{Geman2015VisualTT,\n author = {D. Geman and S. Geman and Neil Hallonquist and L. Younes},\n booktitle = {Proceedings of the National Academy of Sciences of the United States of America},\n journal = {Proceedings of the National Academy of Sciences},\n pages = {3618 - 3623},\n title = {Visual Turing test for computer vision systems},\n volume = {112},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2a805d0e1b067444a554c5169d189fa1f649f411",
            "@type": "ScholarlyArticle",
            "paperId": "2a805d0e1b067444a554c5169d189fa1f649f411",
            "corpusId": 235367962,
            "url": "https://www.semanticscholar.org/paper/2a805d0e1b067444a554c5169d189fa1f649f411",
            "title": "Scaling Vision Transformers",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2021,
            "externalIds": {
                "ArXiv": "2106.04560",
                "DBLP": "journals/corr/abs-2106-04560",
                "DOI": "10.1109/CVPR52688.2022.01179",
                "CorpusId": 235367962
            },
            "abstract": "Attention-based neural networks such as the Vision Transformer (ViT) have recently attained state-of-the-art results on many computer vision benchmarks. Scale is a primary ingredient in attaining excellent results, therefore, understanding a model's scaling properties is a key to designing future generations effectively. While the laws for scaling Transformer language models have been studied, it is unknown how Vision Transformers scale. To address this, we scale ViT models and data, both up and down, and characterize the relationships between error rate, data, and compute. Along the way, we refine the architecture and training of ViT, reducing memory consumption and increasing accuracy of the resulting models. As a result, we successfully train a ViT model with two billion parameters, which attains a new state-of-the-art on ImageNet of 90.45% top-1 accuracy. The model also performs well for few-shot transfer, for example, reaching 84.86% top-1 accuracy on ImageNet with only 10 examples per class.",
            "referenceCount": 52,
            "citationCount": 633,
            "influentialCitationCount": 63,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2106.04560",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2021-06-08",
            "journal": {
                "name": "2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhai2021ScalingVT,\n author = {Xiaohua Zhai and Alexander Kolesnikov and N. Houlsby and Lucas Beyer},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {1204-1213},\n title = {Scaling Vision Transformers},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4e18b48f0e745a7df7c7ffb7a4df96ee07408d97",
            "@type": "ScholarlyArticle",
            "paperId": "4e18b48f0e745a7df7c7ffb7a4df96ee07408d97",
            "corpusId": 12624638,
            "url": "https://www.semanticscholar.org/paper/4e18b48f0e745a7df7c7ffb7a4df96ee07408d97",
            "title": "Computer Vision \u2013 ECCV 2016",
            "venue": "Lecture Notes in Computer Science",
            "publicationVenue": {
                "id": "urn:research:2f5d0e8a-faad-4f10-b323-2b2e3c439a78",
                "name": "Lecture Notes in Computer Science",
                "alternate_names": [
                    "LNCS",
                    "Transactions on Computational Systems Biology",
                    "Trans Comput Syst Biology",
                    "Lect Note Comput Sci"
                ],
                "issn": "0302-9743",
                "url": "http://www.springer.com/lncs"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "conf/eccv/2016-6",
                "DOI": "10.1007/978-3-319-46466-4",
                "CorpusId": 12624638
            },
            "abstract": null,
            "referenceCount": 102,
            "citationCount": 98,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/bfm:978-3-319-46466-4/1?pdf=chapter%20toc",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": "9910"
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Leibe2016ComputerV,\n author = {B. Leibe and Jiri Matas and N. Sebe and M. Welling and G. Goos and J. Hartmanis and J. Leeuwen},\n booktitle = {Lecture Notes in Computer Science},\n title = {Computer Vision \u2013 ECCV 2016},\n volume = {9910},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4d2b5e619ed1c02440ada05cf499b4caa6af63cf",
            "@type": "ScholarlyArticle",
            "paperId": "4d2b5e619ed1c02440ada05cf499b4caa6af63cf",
            "corpusId": 1887911,
            "url": "https://www.semanticscholar.org/paper/4d2b5e619ed1c02440ada05cf499b4caa6af63cf",
            "title": "On Iteratively Reweighted Algorithms for Nonsmooth Nonconvex Optimization in Computer Vision",
            "venue": "SIAM Journal of Imaging Sciences",
            "publicationVenue": {
                "id": "urn:research:7de25fc2-ec8b-4d6c-b578-bbe232d8c8f6",
                "name": "SIAM Journal of Imaging Sciences",
                "alternate_names": [
                    "Siam Journal on Imaging Sciences",
                    "Siam J Imaging Sci",
                    "SIAM J Imaging Sci"
                ],
                "issn": "1936-4954",
                "url": "http://ejournals.ebsco.com/direct.asp?JournalID=714884"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2804930575",
                "DBLP": "journals/siamis/OchsDBP15",
                "DOI": "10.1137/140971518",
                "CorpusId": 1887911
            },
            "abstract": "Natural image statistics indicate that we should use nonconvex norms for most regularization tasks in image processing and computer vision. Still, they are rarely used in practice due to the challenge of optimization. Recently, iteratively reweighed $\\ell_1$ minimization (IRL1) has been proposed as a way to tackle a class of nonconvex functions by solving a sequence of convex $\\ell_2$-$\\ell_1$ problems. We extend the problem class to the sum of a convex function and a (nonconvex) nondecreasing function applied to another convex function. The proposed algorithm sequentially optimizes suitably constructed convex majorizers. Convergence to a critical point is proved when the Kurdyka--\u0141ojasiewicz property and additional mild restrictions hold for the objective function. The efficiency and practical importance of the algorithm are demonstrated in computer vision tasks such as image denoising and optical flow. Most applications seek smooth results with sharp discontinuities. These are achieved by combining nonc...",
            "referenceCount": 92,
            "citationCount": 201,
            "influentialCitationCount": 20,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-02-03",
            "journal": {
                "name": "SIAM J. Imaging Sci.",
                "volume": "8"
            },
            "citationStyles": {
                "bibtex": "@Article{Ochs2015OnIR,\n author = {Peter Ochs and A. Dosovitskiy and T. Brox and T. Pock},\n booktitle = {SIAM Journal of Imaging Sciences},\n journal = {SIAM J. Imaging Sci.},\n pages = {331-372},\n title = {On Iteratively Reweighted Algorithms for Nonsmooth Nonconvex Optimization in Computer Vision},\n volume = {8},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ab28171a7f6e7d6ee8f1f6b0583ffdc8dca2d0a9",
            "@type": "ScholarlyArticle",
            "paperId": "ab28171a7f6e7d6ee8f1f6b0583ffdc8dca2d0a9",
            "corpusId": 5511005,
            "url": "https://www.semanticscholar.org/paper/ab28171a7f6e7d6ee8f1f6b0583ffdc8dca2d0a9",
            "title": "Computer vision syndrome",
            "venue": "Glavvra\u010d (Chief Medical Officer)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2221060573",
                "DOI": "10.1201/9781420032055-4",
                "CorpusId": 5511005
            },
            "abstract": "Technological advances in computing and Internet access enable workers to process more information and be more productive. It also means that workers are spending more time on electronic devices with visual displays such as computers, laptops, smartphones, tablets, e-readers, and even watches that contribute to eye strain. The same applies to children, as they spend many hours each day using electronic devices with digital displays to complete school assignments, play video games, and communicate in the Internet [4]. With the increasing use of these electronic devices, computer vision syndrome is becoming a major public health problem.",
            "referenceCount": 38,
            "citationCount": 204,
            "influentialCitationCount": 10,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2015-12-29",
            "journal": {
                "name": "Glavvra\u010d (Chief Medical Officer)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Lawrence2015ComputerVS,\n author = {Lynn E. Lawrence},\n booktitle = {Glavvra\u010d (Chief Medical Officer)},\n journal = {Glavvra\u010d (Chief Medical Officer)},\n title = {Computer vision syndrome},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:57150ca7d793d6f784cf82da1c349edf7beb6bc2",
            "@type": "ScholarlyArticle",
            "paperId": "57150ca7d793d6f784cf82da1c349edf7beb6bc2",
            "corpusId": 244478080,
            "url": "https://www.semanticscholar.org/paper/57150ca7d793d6f784cf82da1c349edf7beb6bc2",
            "title": "MetaFormer is Actually What You Need for Vision",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "conf/cvpr/YuLZSZWFY22",
                "ArXiv": "2111.11418",
                "DOI": "10.1109/CVPR52688.2022.01055",
                "CorpusId": 244478080
            },
            "abstract": "Transformers have shown great potential in computer vision tasks. A common belief is their attention-based token mixer module contributes most to their competence. However, recent works show the attention-based module in transformers can be replaced by spatial MLPs and the resulted models still perform quite well. Based on this observation, we hypothesize that the general architecture of the transformers, instead of the specific token mixer module, is more essential to the model's performance. To verify this, we deliberately replace the attention module in transformers with an embarrassingly simple spatial pooling operator to conduct only basic token mixing. Surprisingly, we observe that the derived model, termed as PoolFormer, achieves competitive performance on multiple computer vision tasks. For example, on ImageNet-1K, PoolFormer achieves 82.1 % top-1 accuracy, surpassing well-tuned vision transformer/MLP-like baselines DeiT-B/ResMLP-B24 by 0.3%/1.1% accuracy with 35%/52% fewer parameters and 49%/61% fewer MACs. The effectiveness of Pool-Former verifies our hypothesis and urges us to initiate the concept of \u201cMetaFormer\u201d, a general architecture abstracted from transformers without specifying the token mixer. Based on the extensive experiments, we argue that MetaFormer is the key player in achieving superior results for recent transformer and MLP-like models on vision tasks. This work calls for more future research dedicated to improving MetaFormer instead of focusing on the token mixer modules. Additionally, our proposed PoolFormer could serve as a starting baseline for future MetaFormer architecture design.",
            "referenceCount": 69,
            "citationCount": 372,
            "influentialCitationCount": 68,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2111.11418",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2021-11-22",
            "journal": {
                "name": "2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yu2021MetaFormerIA,\n author = {Weihao Yu and Mi Luo and Pan Zhou and Chenyang Si and Yichen Zhou and Xinchao Wang and Jiashi Feng and Shuicheng Yan},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {10809-10819},\n title = {MetaFormer is Actually What You Need for Vision},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f95420f26dc2f920014527fe8eb15e7b74fe3b68",
            "@type": "ScholarlyArticle",
            "paperId": "f95420f26dc2f920014527fe8eb15e7b74fe3b68",
            "corpusId": 12538673,
            "url": "https://www.semanticscholar.org/paper/f95420f26dc2f920014527fe8eb15e7b74fe3b68",
            "title": "Bio-inspired computer vision: Towards a synergistic approach of artificial and biological vision",
            "venue": "Computer Vision and Image Understanding",
            "publicationVenue": {
                "id": "urn:research:5fbb417b-d7a5-44e6-856d-993f0624ed9c",
                "name": "Computer Vision and Image Understanding",
                "alternate_names": [
                    "Comput Vis Image Underst"
                ],
                "issn": "1077-3142",
                "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/622809/description#description"
            },
            "year": 2016,
            "externalIds": {
                "DBLP": "journals/cviu/MedathatiNMK16",
                "MAG": "2345032733",
                "DOI": "10.1016/j.cviu.2016.04.009",
                "CorpusId": 12538673
            },
            "abstract": null,
            "referenceCount": 405,
            "citationCount": 76,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2016-09-01",
            "journal": {
                "name": "Comput. Vis. Image Underst.",
                "volume": "150"
            },
            "citationStyles": {
                "bibtex": "@Article{Medathati2016BioinspiredCV,\n author = {N. V. K. Medathati and H. Neumann and G. Masson and Pierre Kornprobst},\n booktitle = {Computer Vision and Image Understanding},\n journal = {Comput. Vis. Image Underst.},\n pages = {1-30},\n title = {Bio-inspired computer vision: Towards a synergistic approach of artificial and biological vision},\n volume = {150},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:74227090d23c958f601ad05369fad587e3b546f1",
            "@type": "ScholarlyArticle",
            "paperId": "74227090d23c958f601ad05369fad587e3b546f1",
            "corpusId": 207020771,
            "url": "https://www.semanticscholar.org/paper/74227090d23c958f601ad05369fad587e3b546f1",
            "title": "Sparse Representation for Computer Vision and Pattern Recognition",
            "venue": "Proceedings of the IEEE",
            "publicationVenue": {
                "id": "urn:research:6faaccca-1cc4-45a9-aeb6-96a4901d2606",
                "name": "Proceedings of the IEEE",
                "alternate_names": [
                    "Proc IEEE"
                ],
                "issn": "0018-9219",
                "url": "http://www.ieee.org/portal/pages/pubs/proceedings/"
            },
            "year": 2010,
            "externalIds": {
                "DBLP": "journals/pieee/WrightMMSHY10",
                "MAG": "2069959554",
                "DOI": "10.1109/JPROC.2010.2044470",
                "CorpusId": 207020771
            },
            "abstract": "Techniques from sparse signal representation are beginning to see significant impact in computer vision, often on nontraditional applications where the goal is not just to obtain a compact high-fidelity representation of the observed signal, but also to extract semantic information. The choice of dictionary plays a key role in bridging this gap: unconventional dictionaries consisting of, or learned from, the training samples themselves provide the key to obtaining state-of-the-art results and to attaching semantic meaning to sparse signal representations. Understanding the good performance of such unconventional dictionaries in turn demands new algorithmic and analytical techniques. This review paper highlights a few representative examples of how the interaction between sparse signal representation and computer vision can enrich both fields, and raises a number of open questions for further study.",
            "referenceCount": 105,
            "citationCount": 1853,
            "influentialCitationCount": 72,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://conservancy.umn.edu/bitstream/11299/180123/1/2252.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2010-04-29",
            "journal": {
                "name": "Proceedings of the IEEE",
                "volume": "98"
            },
            "citationStyles": {
                "bibtex": "@Article{Wright2010SparseRF,\n author = {John Wright and Yi Ma and J. Mairal and G. Sapiro and Thomas S. Huang and Shuicheng Yan},\n booktitle = {Proceedings of the IEEE},\n journal = {Proceedings of the IEEE},\n pages = {1031-1044},\n title = {Sparse Representation for Computer Vision and Pattern Recognition},\n volume = {98},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8fc928bb430d3f72ac876ca156042ad1860acacd",
            "@type": "ScholarlyArticle",
            "paperId": "8fc928bb430d3f72ac876ca156042ad1860acacd",
            "corpusId": 204980757,
            "url": "https://www.semanticscholar.org/paper/8fc928bb430d3f72ac876ca156042ad1860acacd",
            "title": "Article in Press Future Generation Computer Systems ( ) \u2013 Future Generation Computer Systems Cloud Computing and Emerging It Platforms: Vision, Hype, and Reality for Delivering Computing as the 5th Utility",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": null,
            "externalIds": {
                "CorpusId": 204980757
            },
            "abstract": "With the significant advances in Information and Communications Technology (ICT) over the last half century, there is an increasingly perceived vision that computing will one day be the 5th utility (after water, electricity, gas, and telephony). This computing utility, like all other four existing utilities, will provide the basic level of computing service that is considered essential to meet the everyday needs of the general community. To deliver this vision, a number of computing paradigms have been proposed, of which the latest one is known as Cloud computing. Hence, in this paper, we define Cloud computing and provide the architecture for creating Clouds with market-oriented resource allocation by leveraging technologies such as Virtual Machines (VMs). We also provide insights on market-based resource management strategies that encompass both customer-driven service management and computational risk management to sustain Service Level Agreement (SLA)-oriented resource allocation. In addition, we reveal our early thoughts on interconnecting Clouds for dynamically creating global Cloud exchanges and markets. Then, we present some representative Cloud platforms, especially those developed in industries, along with our current work towards realizing market-oriented resource allocation of Clouds as realized in Aneka enterprise Cloud technology. Furthermore, we highlight the difference between High Performance Computing (HPC) workload and Internet-based services workload. We also describe a meta-negotiation infrastructure to establish global Cloud exchanges and markets, and illustrate a case study of harnessing 'Storage Clouds' for high performance content delivery. Finally, we conclude with the need for convergence of competing IT paradigms to deliver our 21st century vision. Computing is being transformed to a model consisting of services that are commoditized and delivered in a manner similar to traditional utilities such as water, electricity, gas, and telephony. In such a model, users access services based on their requirements without regard to where the services are hosted or how they are delivered. Several computing paradigms have promised to deliver this utility computing vision and these include cluster computing, Grid computing, and more recently Cloud computing. businesses and users are able to access applications from anywhere in the world on demand. Thus, the computing world is rapidly transforming towards developing software for millions to consume as a service, rather than to run on their individual computers. At present, it is common to access content across the Internet independently without reference to the underlying hosting infrastructure. This infrastructure consists of data centers that are monitored and maintained around the clock \u2026",
            "referenceCount": 68,
            "citationCount": 5434,
            "influentialCitationCount": 241,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Misc{None,\n author = {R. Buyya and Chee Shin Yeo and S. Venugopal and J. Broberg and I. Brandi\u0107},\n title = {Article in Press Future Generation Computer Systems ( ) \u2013 Future Generation Computer Systems Cloud Computing and Emerging It Platforms: Vision, Hype, and Reality for Delivering Computing as the 5th Utility}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:40f4d7fe800810288a80f84cdb357a8f4c28e880",
            "@type": "ScholarlyArticle",
            "paperId": "40f4d7fe800810288a80f84cdb357a8f4c28e880",
            "corpusId": 232417451,
            "url": "https://www.semanticscholar.org/paper/40f4d7fe800810288a80f84cdb357a8f4c28e880",
            "title": "Rethinking Spatial Dimensions of Vision Transformers",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "conf/iccv/HeoYHCCO21",
                "ArXiv": "2103.16302",
                "DOI": "10.1109/ICCV48922.2021.01172",
                "CorpusId": 232417451
            },
            "abstract": "Vision Transformer (ViT) extends the application range of transformers from language processing to computer vision tasks as being an alternative architecture against the existing convolutional neural networks (CNN). Since the transformer-based architecture has been innovative for computer vision modeling, the design convention towards an effective architecture has been less studied yet. From the successful design principles of CNN, we investigate the role of spatial dimension conversion and its effectiveness on transformer-based architecture. We particularly attend to the dimension reduction principle of CNNs; as the depth increases, a conventional CNN increases channel dimension and decreases spatial dimensions. We empirically show that such a spatial dimension reduction is beneficial to a transformer architecture as well, and propose a novel Pooling-based Vision Transformer (PiT) upon the original ViT model. We show that PiT achieves the improved model capability and generalization performance against ViT. Throughout the extensive experiments, we further show PiT outperforms the baseline on several tasks such as image classification, object detection, and robustness evaluation. Source codes and ImageNet models are available at https://github.com/naver-ai/pit.",
            "referenceCount": 46,
            "citationCount": 369,
            "influentialCitationCount": 44,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2103.16302",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2021-03-30",
            "journal": {
                "name": "2021 IEEE/CVF International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Heo2021RethinkingSD,\n author = {Byeongho Heo and Sangdoo Yun and Dongyoon Han and Sanghyuk Chun and Junsuk Choe and Seong Joon Oh},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},\n pages = {11916-11925},\n title = {Rethinking Spatial Dimensions of Vision Transformers},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:56fab8e3b9d3a806ebeea41a7d01f8e3eeadc3a2",
            "@type": "ScholarlyArticle",
            "paperId": "56fab8e3b9d3a806ebeea41a7d01f8e3eeadc3a2",
            "corpusId": 35633101,
            "url": "https://www.semanticscholar.org/paper/56fab8e3b9d3a806ebeea41a7d01f8e3eeadc3a2",
            "title": "Computer Vision \u2013 ECCV 2016",
            "venue": "Lecture Notes in Computer Science",
            "publicationVenue": {
                "id": "urn:research:2f5d0e8a-faad-4f10-b323-2b2e3c439a78",
                "name": "Lecture Notes in Computer Science",
                "alternate_names": [
                    "LNCS",
                    "Transactions on Computational Systems Biology",
                    "Trans Comput Syst Biology",
                    "Lect Note Comput Sci"
                ],
                "issn": "0302-9743",
                "url": "http://www.springer.com/lncs"
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2564755587",
                "DBLP": "conf/eccv/2016-7",
                "DOI": "10.1007/978-3-319-46478-7",
                "CorpusId": 35633101
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 61,
            "influentialCitationCount": 0,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": "9911"
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Leibe2016ComputerV,\n author = {B. Leibe and Jiri Matas and N. Sebe and M. Welling and G. Goos and J. Hartmanis and J. Leeuwen},\n booktitle = {Lecture Notes in Computer Science},\n title = {Computer Vision \u2013 ECCV 2016},\n volume = {9911},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:19d7335379d363b612c31900da8cec885d821853",
            "@type": "ScholarlyArticle",
            "paperId": "19d7335379d363b612c31900da8cec885d821853",
            "corpusId": 33716877,
            "url": "https://www.semanticscholar.org/paper/19d7335379d363b612c31900da8cec885d821853",
            "title": "Computer vision techniques for construction safety and health monitoring",
            "venue": "Advanced Engineering Informatics",
            "publicationVenue": {
                "id": "urn:research:ec497fa8-833a-4d68-873a-539c20989c22",
                "name": "Advanced Engineering Informatics",
                "alternate_names": [
                    "Adv Eng Informatics"
                ],
                "issn": "1474-0346",
                "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/622240/description#description"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "journals/aei/SeoHLK15",
                "MAG": "1966941463",
                "DOI": "10.1016/j.aei.2015.02.001",
                "CorpusId": 33716877
            },
            "abstract": null,
            "referenceCount": 90,
            "citationCount": 346,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2015-04-01",
            "journal": {
                "name": "Adv. Eng. Informatics",
                "volume": "29"
            },
            "citationStyles": {
                "bibtex": "@Article{Seo2015ComputerVT,\n author = {Joonoh Seo and SangUk Han and SangHyun Lee and Hyoungkwan Kim},\n booktitle = {Advanced Engineering Informatics},\n journal = {Adv. Eng. Informatics},\n pages = {239-251},\n title = {Computer vision techniques for construction safety and health monitoring},\n volume = {29},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:abb4f2161a09cd532a34ee052f1bb6a1304eb821",
            "@type": "ScholarlyArticle",
            "paperId": "abb4f2161a09cd532a34ee052f1bb6a1304eb821",
            "corpusId": 3604961,
            "url": "https://www.semanticscholar.org/paper/abb4f2161a09cd532a34ee052f1bb6a1304eb821",
            "title": "Computer Vision Syndrome and Associated Factors Among Medical and Engineering Students in Chennai",
            "venue": "Annals of Medical and Health Sciences Research",
            "publicationVenue": {
                "id": "urn:research:52f48784-c779-4b36-b360-b5f0b4ad632c",
                "name": "Annals of Medical and Health Sciences Research",
                "alternate_names": [
                    "Ann Med Health Sci Res"
                ],
                "issn": "2141-9248",
                "url": "https://www.ajol.info/index.php/amhsr"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2157289162",
                "PubMedCentral": "3991936",
                "DOI": "10.4103/2141-9248.129028",
                "CorpusId": 3604961,
                "PubMed": "24761234"
            },
            "abstract": "Background: Almost all institutions, colleges, universities and homes today were using computer regularly. Very little research has been carried out on Indian users especially among college students the effects of computer use on the eye and vision related problems. Aim: The aim of this study was to assess the prevalence of computer vision syndrome (CVS) among medical and engineering students and the factors associated with the same. Subjects and Methods: A cross-sectional study was conducted among medical and engineering college students of a University situated in the suburban area of Chennai. Students who used computer in the month preceding the date of study were included in the study. The participants were surveyed using pre-tested structured questionnaire. Results: Among engineering students, the prevalence of CVS was found to be 81.9% (176/215) while among medical students; it was found to be 78.6% (158/201). A significantly higher proportion of engineering students 40.9% (88/215) used computers for 4-6 h/day as compared to medical students 10% (20/201) (P < 0.001). The reported symptoms of CVS were higher among engineering students compared with medical students. Students who used computer for 4-6 h were at significantly higher risk of developing redness (OR = 1.2, 95% CI = 1.0-3.1,P = 0.04), burning sensation (OR = 2.1,95% CI = 1.3-3.1, P < 0.01 ) and dry eyes (OR = 1.8, 95% CI = 1.1-2.9, P = 0.02) compared to those who used computer for less than 4 h. Significant correlation was found between increased hours of computer use and the symptoms redness, burning sensation, blurred vision and dry eyes. Conclusion: The present study revealed that more than three-fourth of the students complained of any one of the symptoms of CVS while working on the computer.",
            "referenceCount": 41,
            "citationCount": 197,
            "influentialCitationCount": 25,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2014-03-01",
            "journal": {
                "name": "Annals of Medical and Health Sciences Research",
                "volume": "4"
            },
            "citationStyles": {
                "bibtex": "@Article{Logaraj2014ComputerVS,\n author = {M. Logaraj and V. Madhupriya and S. Hegde},\n booktitle = {Annals of Medical and Health Sciences Research},\n journal = {Annals of Medical and Health Sciences Research},\n pages = {179 - 185},\n title = {Computer Vision Syndrome and Associated Factors Among Medical and Engineering Students in Chennai},\n volume = {4},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f518b7cf40203f6d514be42ad4ce0f9caf98efeb",
            "@type": "ScholarlyArticle",
            "paperId": "f518b7cf40203f6d514be42ad4ce0f9caf98efeb",
            "corpusId": 61016466,
            "url": "https://www.semanticscholar.org/paper/f518b7cf40203f6d514be42ad4ce0f9caf98efeb",
            "title": "Deep Convolution Neural Networks in Computer Vision: a Review",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2015,
            "externalIds": {
                "MAG": "1563697767",
                "DOI": "10.5573/IEIESPC.2015.4.1.035",
                "CorpusId": 61016466
            },
            "abstract": "Over the past couple of years, tremendous progress has been made in applying deep learning (DL) techniques to computer vision. Especially, deep convolutional neural networks (DCNNs) have achieved state-of-the-art performance on standard recognition datasets and tasks such as ImageNet Large-Scale Visual Recognition Challenge (ILSVRC). Among them, GoogLeNet network which is a radically redesigned DCNN based on the Hebbian principle and scale invariance set the new state of the art for classification and detection in the ILSVRC 2014. Since there exist various deep learning techniques, this review paper is focusing on techniques directly related to DCNNs, especially those needed to understand the architecture and techniques employed in GoogLeNet network.",
            "referenceCount": 37,
            "citationCount": 100,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2015-02-28",
            "journal": {
                "name": "IEIE Transactions on Smart Processing and Computing",
                "volume": "4"
            },
            "citationStyles": {
                "bibtex": "@Article{Yoo2015DeepCN,\n author = {H. Yoo},\n journal = {IEIE Transactions on Smart Processing and Computing},\n pages = {35-43},\n title = {Deep Convolution Neural Networks in Computer Vision: a Review},\n volume = {4},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:34a9b63e14adaae3eee4810ca0e2911cd3f76599",
            "@type": "ScholarlyArticle",
            "paperId": "34a9b63e14adaae3eee4810ca0e2911cd3f76599",
            "corpusId": 12719177,
            "url": "https://www.semanticscholar.org/paper/34a9b63e14adaae3eee4810ca0e2911cd3f76599",
            "title": "Computer Vision for X-Ray Testing",
            "venue": "Cambridge International Law Journal",
            "publicationVenue": {
                "id": "urn:research:43d8ff46-e680-4c40-84dc-a8f86d3f559b",
                "name": "Cambridge International Law Journal",
                "alternate_names": [
                    "Springer International Publishing",
                    "Springer Int Publ",
                    "Camb Int Law J"
                ],
                "issn": "2398-9173",
                "url": "https://www.elgaronline.com/view/journals/cilj/cilj-overview.xml"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2499915346",
                "DBLP": "books/sp/Mery15",
                "DOI": "10.1007/978-3-319-20747-6",
                "CorpusId": 12719177
            },
            "abstract": null,
            "referenceCount": 98,
            "citationCount": 72,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Mery2015ComputerVF,\n author = {D. Mery},\n booktitle = {Cambridge International Law Journal},\n pages = {1-347},\n title = {Computer Vision for X-Ray Testing},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:27fc2c0e3e34c46071dd4f57663d86c779db02ee",
            "@type": "ScholarlyArticle",
            "paperId": "27fc2c0e3e34c46071dd4f57663d86c779db02ee",
            "corpusId": 25158004,
            "url": "https://www.semanticscholar.org/paper/27fc2c0e3e34c46071dd4f57663d86c779db02ee",
            "title": "Computer vision syndrome: A review.",
            "venue": "Work",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2172478310",
                "DOI": "10.3233/WOR-152162",
                "CorpusId": 25158004,
                "PubMed": "26519133"
            },
            "abstract": "BACKGROUND\nComputer vision syndrome (CVS) is a collection of symptoms related to prolonged work at a computer display.\n\n\nOBJECTIVE\nThis article reviews the current knowledge about the symptoms, related factors and treatment modalities for CVS.\n\n\nMETHODS\nRelevant literature on CVS published during the past 65 years was analyzed.\n\n\nRESULTS\nSymptoms reported by computer users are classified into internal ocular symptoms (strain and ache), external ocular symptoms (dryness, irritation, burning), visual symptoms (blur, double vision) and musculoskeletal symptoms (neck and shoulder pain). The major factors associated with CVS are either environmental (improper lighting, display position and viewing distance) and/or dependent on the user's visual abilities (uncorrected refractive error, oculomotor disorders and tear film abnormalities).\n\n\nCONCLUSION\nAlthough the factors associated with CVS have been identified the physiological mechanisms that underlie CVS are not completely understood. Additionally, advances in technology have led to the increased use of hand-held devices, which might impose somewhat different visual challenges compared to desktop displays. Further research is required to better understand the physiological mechanisms underlying CVS and symptoms associated with the use of hand-held and stereoscopic displays.",
            "referenceCount": 102,
            "citationCount": 78,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Work",
                "volume": "52 2"
            },
            "citationStyles": {
                "bibtex": "@Article{Gowrisankaran2015ComputerVS,\n author = {Sowjanya Gowrisankaran and J. Sheedy},\n booktitle = {Work},\n journal = {Work},\n pages = {\n          303-14\n        },\n title = {Computer vision syndrome: A review.},\n volume = {52 2},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8edefb42a012cf1b3ca82e869ad56690d4f798f3",
            "@type": "ScholarlyArticle",
            "paperId": "8edefb42a012cf1b3ca82e869ad56690d4f798f3",
            "corpusId": 62425750,
            "url": "https://www.semanticscholar.org/paper/8edefb42a012cf1b3ca82e869ad56690d4f798f3",
            "title": "Concise Computer Vision: An Introduction into Theory and Algorithms",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2235377633",
                "CorpusId": 62425750
            },
            "abstract": "This textbook provides an accessible general introduction to the essential topics in computer vision. Classroom-tested programming exercises and review questions are also supplied at the end of each chapter. Features: provides an introduction to the basic notation and mathematical concepts for describing an image and the key concepts for mapping an image into an image; explains the topologic and geometric basics for analysing image regions and distributions of image values and discusses identifying patterns in an image; introduces optic flow for representing dense motion and various topics in sparse motion analysis; describes special approaches for image binarization and segmentation of still images or video frames; examines the basic components of a computer vision system; reviews different techniques for vision-based 3D shape reconstruction; includes a discussion of stereo matchers and the phase-congruency model for image features; presents an introduction into classification and learning.",
            "referenceCount": 3,
            "citationCount": 117,
            "influentialCitationCount": 7,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2014-01-04",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Klette2014ConciseCV,\n author = {R. Klette},\n title = {Concise Computer Vision: An Introduction into Theory and Algorithms},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2ab061744bff08d56f82a0939b66fa6785b21f03",
            "@type": "ScholarlyArticle",
            "paperId": "2ab061744bff08d56f82a0939b66fa6785b21f03",
            "corpusId": 63759198,
            "url": "https://www.semanticscholar.org/paper/2ab061744bff08d56f82a0939b66fa6785b21f03",
            "title": "Computer Vision Metrics: Survey, Taxonomy, and Analysis",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2472556136",
                "CorpusId": 63759198
            },
            "abstract": "Computer Vision Metrics: Survey, Taxonomy, and Analysis provides a technical tourthrough computer vision, with a survey of nearly 100 types of local, regional, andglobal feature descriptors, blending history of the field with state-of-the-art analysisof contemporary methods, rather than just another how-to book with source codeshortcuts and performance analysis. Observations are provided to develop intuitionbehind the methods and mathematics, interesting questions are raised for futureresearch rather than providing all the answers, and a Vision Taxonomy is suggested todraw a conceptual map of the field. Extensive illustrations are included, with over 540references to the literature in the comprehensive bibliography to dig deeper. Computer Vision Metrics explores the key questions behind the design and mathematicsof computer vision metrics and feature descriptors, providing a comprehensive surveyand taxonomy of what methods are used, with analysis and observations about why themethods work. Several 3D depth sensing methods are surveyed including MVS, stereo, andstructured light. This work focuses on a slice through the field from the view of feature descriptionmetrics, or how to describe, compute, and design the macro-features and micro-featuresthat make up larger objects in images. The focus is on the pixel-side of the vision pipeline,with a light introduction to the back-end training, classification, machine learning, andmatching stages. Computer Vision Metrics is written for engineers, scientists, and academicresearchers in areas including video analytics, scene understanding, machine vision,face recognition, gesture recognition, pattern recognition, general object analysis, mediaprocessing, and computational photography. What youll learn Current status, brief history, and future directions for computer vision metrics Taxonomy of local binary, gradient & other spectra, shape features,and basis spaces Overview of 2D image sensing, 3D depth sensing, and image preprocessing Vision pipeline optimization methods for computer vision applications Characterization of ten Open CV detectors using synthetic feature alphabets Who this book is for Engineers, scientists, and academic researchers in areas including media processing, computational photography, video analytics, scene understanding, machine vision, face recognition, gesture recognition, pattern recognition and general object analysis.",
            "referenceCount": 0,
            "citationCount": 103,
            "influentialCitationCount": 8,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2014-05-30",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Krig2014ComputerVM,\n author = {Scott Krig},\n title = {Computer Vision Metrics: Survey, Taxonomy, and Analysis},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5dbf3aa6d9c644168e97ad57612653757373756d",
            "@type": "ScholarlyArticle",
            "paperId": "5dbf3aa6d9c644168e97ad57612653757373756d",
            "corpusId": 32086840,
            "url": "https://www.semanticscholar.org/paper/5dbf3aa6d9c644168e97ad57612653757373756d",
            "title": "Scale Space and Variational Methods in Computer Vision",
            "venue": "Lecture Notes in Computer Science",
            "publicationVenue": {
                "id": "urn:research:2f5d0e8a-faad-4f10-b323-2b2e3c439a78",
                "name": "Lecture Notes in Computer Science",
                "alternate_names": [
                    "LNCS",
                    "Transactions on Computational Systems Biology",
                    "Trans Comput Syst Biology",
                    "Lect Note Comput Sci"
                ],
                "issn": "0302-9743",
                "url": "http://www.springer.com/lncs"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2481387966",
                "DBLP": "conf/scalespace/2015",
                "DOI": "10.1007/978-3-319-18461-6",
                "CorpusId": 32086840
            },
            "abstract": null,
            "referenceCount": 31,
            "citationCount": 152,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": "9087"
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Aujol2015ScaleSA,\n author = {Jean-Fran\u00e7ois Aujol and M. Nikolova and N. Papadakis},\n booktitle = {Lecture Notes in Computer Science},\n title = {Scale Space and Variational Methods in Computer Vision},\n volume = {9087},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:64701615e21225864634633a78a4f7b3e20735a0",
            "@type": "ScholarlyArticle",
            "paperId": "64701615e21225864634633a78a4f7b3e20735a0",
            "corpusId": 9972779,
            "url": "https://www.semanticscholar.org/paper/64701615e21225864634633a78a4f7b3e20735a0",
            "title": "Impact of computer technology on health: Computer Vision Syndrome (CVS)",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2185327680",
                "DOI": "10.5897/MPR.2014.0121",
                "CorpusId": 9972779
            },
            "abstract": "In today\u2019s society, the use of computer as a tool at workplaces, academic institutions, recreation facilities and homes has become very common. It is estimated that globally, about 45 to 70 million people spend hours staring into a video display terminal, popularly known as computer screen. Several studies, mainly in developed countries, have shown an association between computer use and visual health related symptoms (Computer Vision Syndrome, CVS) in both children and adults. In this report, a review of literature on CVS was undertaken to determine the prevalence of CVS and compare the prevalence between studies. The risk factors associated with the syndrome range from individual visual problems and poor ergonomics. The most common symptoms include headache, eye strain, double vision, dry eyes, eye fatigue and other symptoms of eye strain. The prevalence of the symptoms varied between studies. It is concluded that, as computer users are increasing rapidly, they are at risk of CVS. A better understanding of the pathophysiology underlying CVS is necessary to empower practitioners to accurately diagnose and treat patients with CVS; necessary precautions and care should be exercised to prevent serious impact of CVS on productivity and sustainable economic development of countries in Africa. In addition, special attention should be given to the young population including children and students in schools, colleges and universities. \n \n \u00a0 \n \n Key words: Computer vision syndrome (CVS), computer users, health impact.",
            "referenceCount": 81,
            "citationCount": 80,
            "influentialCitationCount": 8,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2014-11-30",
            "journal": {
                "name": "",
                "volume": "5"
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{AkinbinuT.2014ImpactOC,\n author = {R. AkinbinuT. and J. MashallaY.},\n pages = {20-30},\n title = {Impact of computer technology on health: Computer Vision Syndrome (CVS)},\n volume = {5},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c78f0dafb2f832f7423d40276d9990293fc6e59a",
            "@type": "ScholarlyArticle",
            "paperId": "c78f0dafb2f832f7423d40276d9990293fc6e59a",
            "corpusId": 118691723,
            "url": "https://www.semanticscholar.org/paper/c78f0dafb2f832f7423d40276d9990293fc6e59a",
            "title": "Jet-images: computer vision inspired techniques for jet tagging",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2047792789",
                "ArXiv": "1407.5675",
                "DOI": "10.1007/JHEP02(2015)118",
                "CorpusId": 118691723
            },
            "abstract": null,
            "referenceCount": 66,
            "citationCount": 192,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/JHEP02(2015)118.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Physics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Physics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2014-07-21",
            "journal": {
                "name": "Journal of High Energy Physics",
                "volume": "2015"
            },
            "citationStyles": {
                "bibtex": "@Article{Cogan2014JetimagesCV,\n author = {J. Cogan and M. Kagan and E. Strauss and Ariel Schwarztman},\n journal = {Journal of High Energy Physics},\n pages = {1-16},\n title = {Jet-images: computer vision inspired techniques for jet tagging},\n volume = {2015},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1c88720c3314d6f7a61a1c2f197740b70300605f",
            "@type": "ScholarlyArticle",
            "paperId": "1c88720c3314d6f7a61a1c2f197740b70300605f",
            "corpusId": 63592990,
            "url": "https://www.semanticscholar.org/paper/1c88720c3314d6f7a61a1c2f197740b70300605f",
            "title": "A Practical Introduction to Computer Vision with Opencv",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2341356235",
                "CorpusId": 63592990
            },
            "abstract": "Explains the theory behind basic computer vision and provides a bridge from the theory to practical implementation using the industry standard OpenCV librariesComputer Vision is a rapidly expanding area and it is becoming progressively easier for developers to make use of this field due to the ready availability of high quality libraries (such as OpenCV 2). This text is intended to facilitate the practical use of computer vision with the goal being to bridge the gap between the theory and the practical implementation of computer vision. The book will explain how to use the relevant OpenCV library routines and will be accompanied by a full working program including the code snippets from the text. This textbook is a heavily illustrated, practical introduction to an exciting field, the applications of which are becoming almost ubiquitous. We are now surrounded by cameras, for example cameras on computers & tablets/ cameras built into our mobile phones/ cameras in games consoles; cameras imaging difficult modalities (such as ultrasound, X-ray, MRI) in hospitals, and surveillance cameras. This book is concerned with helping the next generation of computer developers to make use of all these images in order to develop systems which are more intuitive and interact with us in more intelligent ways.Explains the theory behind basic computer vision and provides a bridge from the theory to practical implementation using the industry standard OpenCV librariesOffers an introduction to computer vision, with enough theory to make clear how the various algorithms work but with an emphasis on practical programming issuesProvides enough material for a one semester course in computer vision at senior undergraduate and Masters levelsIncludes the basics of cameras and images and image processing to remove noise, before moving on to topics such as image histogramming; binary imaging; video processing to detect and model moving objects; geometric operations & camera models; edge detection; features detection; recognition in imagesContains a large number of vision application problems to provide students with the opportunity to solve real problems. Images or videos for these problems are provided in the resources associated with this book which include an enhanced eBook",
            "referenceCount": 20,
            "citationCount": 71,
            "influentialCitationCount": 10,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2014-05-12",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Dawson-Howe2014API,\n author = {K. Dawson-Howe},\n title = {A Practical Introduction to Computer Vision with Opencv},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7432dc8b9940ca89380704141e28e5839ec7d8e0",
            "@type": "ScholarlyArticle",
            "paperId": "7432dc8b9940ca89380704141e28e5839ec7d8e0",
            "corpusId": 60007916,
            "url": "https://www.semanticscholar.org/paper/7432dc8b9940ca89380704141e28e5839ec7d8e0",
            "title": "Computer Vision: A Reference Guide",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "MAG": "401671674",
                "DOI": "10.1007/978-3-030-63416-2",
                "CorpusId": 60007916
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 131,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/bfm:978-3-030-63416-2/1?pdf=chapter%20toc",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Computer Vision",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{\u514b\u53f22014ComputerVA,\n author = {\u6c60\u5185 \u514b\u53f2},\n journal = {Computer Vision},\n title = {Computer Vision: A Reference Guide},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:11c162a45c87c6e36674f01982d4086e880b4229",
            "@type": "ScholarlyArticle",
            "paperId": "11c162a45c87c6e36674f01982d4086e880b4229",
            "corpusId": 5560079,
            "url": "https://www.semanticscholar.org/paper/11c162a45c87c6e36674f01982d4086e880b4229",
            "title": "Computer vision-based object recognition for the visually impaired in an indoors environment: a survey",
            "venue": "The Visual Computer",
            "publicationVenue": {
                "id": "urn:research:9a037417-d032-481a-bb54-de987ec2138b",
                "name": "The Visual Computer",
                "alternate_names": [
                    "Vis Comput"
                ],
                "issn": "0178-2789",
                "url": "https://link.springer.com/journal/371"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "1969113967",
                "DBLP": "journals/vc/JafriAAF14",
                "DOI": "10.1007/s00371-013-0886-1",
                "CorpusId": 5560079
            },
            "abstract": null,
            "referenceCount": 134,
            "citationCount": 113,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2014-11-01",
            "journal": {
                "name": "The Visual Computer",
                "volume": "30"
            },
            "citationStyles": {
                "bibtex": "@Article{Jafri2014ComputerVO,\n author = {Rabia Jafri and Syed Abid Ali and H. Arabnia and Shameem Fatima},\n booktitle = {The Visual Computer},\n journal = {The Visual Computer},\n pages = {1197-1222},\n title = {Computer vision-based object recognition for the visually impaired in an indoors environment: a survey},\n volume = {30},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5ee709de9c13034bcae1fff96b5abb7312bd097e",
            "@type": "ScholarlyArticle",
            "paperId": "5ee709de9c13034bcae1fff96b5abb7312bd097e",
            "corpusId": 14970359,
            "url": "https://www.semanticscholar.org/paper/5ee709de9c13034bcae1fff96b5abb7312bd097e",
            "title": "A Survey of Computer Vision-Based Human Motion Capture",
            "venue": "Computer Vision and Image Understanding",
            "publicationVenue": {
                "id": "urn:research:5fbb417b-d7a5-44e6-856d-993f0624ed9c",
                "name": "Computer Vision and Image Understanding",
                "alternate_names": [
                    "Comput Vis Image Underst"
                ],
                "issn": "1077-3142",
                "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/622809/description#description"
            },
            "year": 2001,
            "externalIds": {
                "MAG": "2090110089",
                "DBLP": "journals/cviu/MoeslundG01",
                "DOI": "10.1006/cviu.2000.0897",
                "CorpusId": 14970359
            },
            "abstract": "A comprehensive survey of computer vision-based human motion capture literature from the past two decades is presented. The focus is on a general overview based on a taxonomy of system functionalities, broken down into four processes: initialization, tracking, pose estimation, and recognition. Each process is discussed and divided into subprocesses and/or categories of methods to provide a reference to describe and compare the more than 130 publications covered by the survey. References are included throughout the paper to exemplify important issues and their relations to the various methods. A number of general assumptions used in this research field are identified and the character of these assumptions indicates that the research field is still in an early stage of development. To evaluate the state of the art, the major application areas are identified and performances are analyzed in light of the methods presented in the survey. Finally, suggestions for future research directions are offered.",
            "referenceCount": 161,
            "citationCount": 2022,
            "influentialCitationCount": 57,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://graphics.im.ntu.edu.tw/~kyatapi/papers/A Survey of Computer Vision-Based Human Motion Capture.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2001-03-01",
            "journal": {
                "name": "Comput. Vis. Image Underst.",
                "volume": "81"
            },
            "citationStyles": {
                "bibtex": "@Article{Moeslund2001ASO,\n author = {T. Moeslund and E. Granum},\n booktitle = {Computer Vision and Image Understanding},\n journal = {Comput. Vis. Image Underst.},\n pages = {231-268},\n title = {A Survey of Computer Vision-Based Human Motion Capture},\n volume = {81},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0864bc25d306e37fe69e4a29b8d8a85cebe8b812",
            "@type": "ScholarlyArticle",
            "paperId": "0864bc25d306e37fe69e4a29b8d8a85cebe8b812",
            "corpusId": 6798655,
            "url": "https://www.semanticscholar.org/paper/0864bc25d306e37fe69e4a29b8d8a85cebe8b812",
            "title": "Computer Vision \u2013 ECCV 2014",
            "venue": "Lecture Notes in Computer Science",
            "publicationVenue": {
                "id": "urn:research:2f5d0e8a-faad-4f10-b323-2b2e3c439a78",
                "name": "Lecture Notes in Computer Science",
                "alternate_names": [
                    "LNCS",
                    "Transactions on Computational Systems Biology",
                    "Trans Comput Syst Biology",
                    "Lect Note Comput Sci"
                ],
                "issn": "0302-9743",
                "url": "http://www.springer.com/lncs"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "conf/eccv/2014-6",
                "DOI": "10.1007/978-3-319-10599-4",
                "CorpusId": 6798655
            },
            "abstract": null,
            "referenceCount": 107,
            "citationCount": 93,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": "8694"
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Kanade2014ComputerV,\n author = {T. Kanade and J. Kittler and J. Kleinberg and A. Kobsa and John C. Mitchell and M. Naor},\n booktitle = {Lecture Notes in Computer Science},\n title = {Computer Vision \u2013 ECCV 2014},\n volume = {8694},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:bd19ceb323e749c8d4fe310061578035f774a8cf",
            "@type": "ScholarlyArticle",
            "paperId": "bd19ceb323e749c8d4fe310061578035f774a8cf",
            "corpusId": 119850124,
            "url": "https://www.semanticscholar.org/paper/bd19ceb323e749c8d4fe310061578035f774a8cf",
            "title": "Fruit classification using computer vision and feedforward neural network",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "MAG": "1963939054",
                "DOI": "10.1016/J.JFOODENG.2014.07.001",
                "CorpusId": 119850124
            },
            "abstract": null,
            "referenceCount": 50,
            "citationCount": 275,
            "influentialCitationCount": 13,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2014-12-01",
            "journal": {
                "name": "Journal of Food Engineering",
                "volume": "143"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhang2014FruitCU,\n author = {Yudong Zhang and Shuihua Wang and G. Ji and Preetha Phillips},\n journal = {Journal of Food Engineering},\n pages = {167-177},\n title = {Fruit classification using computer vision and feedforward neural network},\n volume = {143},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:48418b285a92376a38daafa664a2dd07d42e3fe3",
            "@type": "ScholarlyArticle",
            "paperId": "48418b285a92376a38daafa664a2dd07d42e3fe3",
            "corpusId": 235694438,
            "url": "https://www.semanticscholar.org/paper/48418b285a92376a38daafa664a2dd07d42e3fe3",
            "title": "Focal Self-attention for Local-Global Interactions in Vision Transformers",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2021,
            "externalIds": {
                "ArXiv": "2107.00641",
                "DBLP": "journals/corr/abs-2107-00641",
                "CorpusId": 235694438
            },
            "abstract": "Recently, Vision Transformer and its variants have shown great promise on various computer vision tasks. The ability of capturing short- and long-range visual dependencies through self-attention is arguably the main source for the success. But it also brings challenges due to quadratic computational overhead, especially for the high-resolution vision tasks (e.g., object detection). In this paper, we present focal self-attention, a new mechanism that incorporates both fine-grained local and coarse-grained global interactions. Using this new mechanism, each token attends the closest surrounding tokens at fine granularity but the tokens far away at coarse granularity, and thus can capture both short- and long-range visual dependencies efficiently and effectively. With focal self-attention, we propose a new variant of Vision Transformer models, called Focal Transformer, which achieves superior performance over the state-of-the-art vision Transformers on a range of public image classification and object detection benchmarks. In particular, our Focal Transformer models with a moderate size of 51.1M and a larger size of 89.8M achieve 83.5 and 83.8 Top-1 accuracy, respectively, on ImageNet classification at 224x224 resolution. Using Focal Transformers as the backbones, we obtain consistent and substantial improvements over the current state-of-the-art Swin Transformers for 6 different object detection methods trained with standard 1x and 3x schedules. Our largest Focal Transformer yields 58.7/58.9 box mAPs and 50.9/51.3 mask mAPs on COCO mini-val/test-dev, and 55.4 mIoU on ADE20K for semantic segmentation, creating new SoTA on three of the most challenging computer vision tasks.",
            "referenceCount": 94,
            "citationCount": 286,
            "influentialCitationCount": 29,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-07-01",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2107.00641"
            },
            "citationStyles": {
                "bibtex": "@Article{Yang2021FocalSF,\n author = {Jianwei Yang and Chunyuan Li and Pengchuan Zhang and Xiyang Dai and Bin Xiao and Lu Yuan and Jianfeng Gao},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Focal Self-attention for Local-Global Interactions in Vision Transformers},\n volume = {abs/2107.00641},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8690d62d4bbbd0b1ed5e1f25320d10853bfbeb01",
            "@type": "ScholarlyArticle",
            "paperId": "8690d62d4bbbd0b1ed5e1f25320d10853bfbeb01",
            "corpusId": 235417196,
            "url": "https://www.semanticscholar.org/paper/8690d62d4bbbd0b1ed5e1f25320d10853bfbeb01",
            "title": "Scaling Vision with Sparse Mixture of Experts",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2021,
            "externalIds": {
                "ArXiv": "2106.05974",
                "DBLP": "conf/nips/RiquelmePMNJPKH21",
                "CorpusId": 235417196
            },
            "abstract": "Sparsely-gated Mixture of Experts networks (MoEs) have demonstrated excellent scalability in Natural Language Processing. In Computer Vision, however, almost all performant networks are\"dense\", that is, every input is processed by every parameter. We present a Vision MoE (V-MoE), a sparse version of the Vision Transformer, that is scalable and competitive with the largest dense networks. When applied to image recognition, V-MoE matches the performance of state-of-the-art networks, while requiring as little as half of the compute at inference time. Further, we propose an extension to the routing algorithm that can prioritize subsets of each input across the entire batch, leading to adaptive per-image compute. This allows V-MoE to trade-off performance and compute smoothly at test-time. Finally, we demonstrate the potential of V-MoE to scale vision models, and train a 15B parameter model that attains 90.35% on ImageNet.",
            "referenceCount": 73,
            "citationCount": 252,
            "influentialCitationCount": 33,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-06-10",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Riquelme2021ScalingVW,\n author = {C. Riquelme and J. Puigcerver and Basil Mustafa and Maxim Neumann and Rodolphe Jenatton and Andr\u00e9 Susano Pinto and Daniel Keysers and N. Houlsby},\n booktitle = {Neural Information Processing Systems},\n pages = {8583-8595},\n title = {Scaling Vision with Sparse Mixture of Experts},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:de5b0fd02ea4f4d67fe3ae0d74603b9822df4e42",
            "@type": "ScholarlyArticle",
            "paperId": "de5b0fd02ea4f4d67fe3ae0d74603b9822df4e42",
            "corpusId": 6724907,
            "url": "https://www.semanticscholar.org/paper/de5b0fd02ea4f4d67fe3ae0d74603b9822df4e42",
            "title": "Are we ready for autonomous driving? The KITTI vision benchmark suite",
            "venue": "2012 IEEE Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2012,
            "externalIds": {
                "DBLP": "conf/cvpr/GeigerLU12",
                "MAG": "2150066425",
                "DOI": "10.1109/CVPR.2012.6248074",
                "CorpusId": 6724907
            },
            "abstract": "Today, visual recognition systems are still rarely employed in robotics applications. Perhaps one of the main reasons for this is the lack of demanding benchmarks that mimic such scenarios. In this paper, we take advantage of our autonomous driving platform to develop novel challenging benchmarks for the tasks of stereo, optical flow, visual odometry/SLAM and 3D object detection. Our recording platform is equipped with four high resolution video cameras, a Velodyne laser scanner and a state-of-the-art localization system. Our benchmarks comprise 389 stereo and optical flow image pairs, stereo visual odometry sequences of 39.2 km length, and more than 200k 3D object annotations captured in cluttered scenarios (up to 15 cars and 30 pedestrians are visible per image). Results from state-of-the-art algorithms reveal that methods ranking high on established datasets such as Middlebury perform below average when being moved outside the laboratory to the real world. Our goal is to reduce this bias by providing challenging benchmarks with novel difficulties to the computer vision community. Our benchmarks are available online at: www.cvlibs.net/datasets/kitti.",
            "referenceCount": 50,
            "citationCount": 10253,
            "influentialCitationCount": 2368,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2012-06-16",
            "journal": {
                "name": "2012 IEEE Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Geiger2012AreWR,\n author = {Andreas Geiger and Philip Lenz and R. Urtasun},\n booktitle = {2012 IEEE Conference on Computer Vision and Pattern Recognition},\n journal = {2012 IEEE Conference on Computer Vision and Pattern Recognition},\n pages = {3354-3361},\n title = {Are we ready for autonomous driving? The KITTI vision benchmark suite},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9b03a8361ee931ba0d6fee3b627e9b10b7c696a7",
            "@type": "ScholarlyArticle",
            "paperId": "9b03a8361ee931ba0d6fee3b627e9b10b7c696a7",
            "corpusId": 10877217,
            "url": "https://www.semanticscholar.org/paper/9b03a8361ee931ba0d6fee3b627e9b10b7c696a7",
            "title": "Concise Computer Vision",
            "venue": "Undergraduate Topics in Computer Science",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2498148408",
                "DBLP": "series/utcs/Klette14",
                "DOI": "10.1007/978-1-4471-6320-6",
                "CorpusId": 10877217
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 219,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/bfm:978-1-4471-6320-6/1?pdf=chapter%20toc",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Klette2014ConciseCV,\n author = {R. Klette},\n booktitle = {Undergraduate Topics in Computer Science},\n pages = {1-413},\n title = {Concise Computer Vision},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b5e2a80bb245b037c6ab6f1c69470d2d80d78c6e",
            "@type": "ScholarlyArticle",
            "paperId": "b5e2a80bb245b037c6ab6f1c69470d2d80d78c6e",
            "corpusId": 45199630,
            "url": "https://www.semanticscholar.org/paper/b5e2a80bb245b037c6ab6f1c69470d2d80d78c6e",
            "title": "Computer Vision and Machine Learning with RGB-D Sensors",
            "venue": "Advances in Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:e97fa60a-354c-45ea-abf9-f3949365196c",
                "name": "Advances in Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "Adv Comput Vis Pattern Recognit"
                ],
                "issn": "2191-6586",
                "url": "https://www.springer.com/series/4205"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "1491538016",
                "DOI": "10.1007/978-3-319-08651-4",
                "CorpusId": 45199630
            },
            "abstract": null,
            "referenceCount": 58,
            "citationCount": 49,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2014-07-15",
            "journal": {
                "name": "Advances in Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Shao2014ComputerVA,\n author = {Ling Shao and J. Han and Pushmeet Kohli and Zhengyou Zhang},\n booktitle = {Advances in Computer Vision and Pattern Recognition},\n journal = {Advances in Computer Vision and Pattern Recognition},\n title = {Computer Vision and Machine Learning with RGB-D Sensors},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fd924c39b1f44890af033db445e4a72291bdbf0b",
            "@type": "ScholarlyArticle",
            "paperId": "fd924c39b1f44890af033db445e4a72291bdbf0b",
            "corpusId": 46817381,
            "url": "https://www.semanticscholar.org/paper/fd924c39b1f44890af033db445e4a72291bdbf0b",
            "title": "Review of constraints on vision-based gesture recognition for human-computer interaction",
            "venue": "IET Computer Vision",
            "publicationVenue": {
                "id": "urn:research:d8f7a93a-ec60-4a71-a085-6891d8652e03",
                "name": "IET Computer Vision",
                "alternate_names": [
                    "Iet Computer Vision",
                    "Iet Comput Vis",
                    "IET Comput Vis"
                ],
                "issn": "1751-9632",
                "url": "http://www.iee.org/Publish/Journals/Profjourn/Proc/vis/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2769575562",
                "DBLP": "journals/iet-cvi/ChakrabortySBM18",
                "DOI": "10.1049/iet-cvi.2017.0052",
                "CorpusId": 46817381
            },
            "abstract": "The ability of computers to recognise hand gestures visually is essential for progress in human-computer interaction. Gesture recognition has applications ranging from sign language to medical assistance to virtual reality. However, gesture recognition is extremely challenging not only because of its diverse contexts, multiple interpretations, and spatio-temporal variations but also because of the complex non-rigid properties of the hand. This study surveys major constraints on vision-based gesture recognition occurring in detection and pre-processing, representation and feature extraction, and recognition. Current challenges are explored in detail.",
            "referenceCount": 156,
            "citationCount": 162,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://scholarworks.iupui.edu/bitstream/1805/17801/1/Chakraborty-2017-Review.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-02-01",
            "journal": {
                "name": "IET Comput. Vis.",
                "volume": "12"
            },
            "citationStyles": {
                "bibtex": "@Article{Chakraborty2018ReviewOC,\n author = {B. Chakraborty and Debajit Sarma and M. Bhuyan and K. Macdorman},\n booktitle = {IET Computer Vision},\n journal = {IET Comput. Vis.},\n pages = {3-15},\n title = {Review of constraints on vision-based gesture recognition for human-computer interaction},\n volume = {12},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b56f1ea5df4a7933fbca6f6f409d1f8135181cd6",
            "@type": "ScholarlyArticle",
            "paperId": "b56f1ea5df4a7933fbca6f6f409d1f8135181cd6",
            "corpusId": 13377671,
            "url": "https://www.semanticscholar.org/paper/b56f1ea5df4a7933fbca6f6f409d1f8135181cd6",
            "title": "Neural Networks and Neuroscience-Inspired Computer Vision",
            "venue": "Current Biology",
            "publicationVenue": {
                "id": "urn:research:9469269e-53d7-4955-b1a5-17a75bee7634",
                "name": "Current Biology",
                "alternate_names": [
                    "Curr Biology"
                ],
                "issn": "0960-9822",
                "url": "http://www.current-biology.com/"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "2153158097",
                "DOI": "10.1016/j.cub.2014.08.026",
                "CorpusId": 13377671,
                "PubMed": "25247371"
            },
            "abstract": null,
            "referenceCount": 109,
            "citationCount": 168,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.cell.com/article/S0960982214010392/pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Biology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2014-09-22",
            "journal": {
                "name": "Current Biology",
                "volume": "24"
            },
            "citationStyles": {
                "bibtex": "@Article{Cox2014NeuralNA,\n author = {David D. Cox and Thomas L. Dean},\n booktitle = {Current Biology},\n journal = {Current Biology},\n pages = {R921-R929},\n title = {Neural Networks and Neuroscience-Inspired Computer Vision},\n volume = {24},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:47d021995963981376448e1ca329e7ea2c125833",
            "@type": "ScholarlyArticle",
            "paperId": "47d021995963981376448e1ca329e7ea2c125833",
            "corpusId": 34748840,
            "url": "https://www.semanticscholar.org/paper/47d021995963981376448e1ca329e7ea2c125833",
            "title": "Computer Vision and Graphics",
            "venue": "Lecture Notes in Computer Science",
            "publicationVenue": {
                "id": "urn:research:2f5d0e8a-faad-4f10-b323-2b2e3c439a78",
                "name": "Lecture Notes in Computer Science",
                "alternate_names": [
                    "LNCS",
                    "Transactions on Computational Systems Biology",
                    "Trans Comput Syst Biology",
                    "Lect Note Comput Sci"
                ],
                "issn": "0302-9743",
                "url": "http://www.springer.com/lncs"
            },
            "year": 2014,
            "externalIds": {
                "MAG": "1650607383",
                "DBLP": "conf/iccvg/2014",
                "DOI": "10.1007/978-3-319-11331-9",
                "CorpusId": 34748840
            },
            "abstract": null,
            "referenceCount": 35,
            "citationCount": 137,
            "influentialCitationCount": 0,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://diposit.ub.edu/dspace/bitstream/2445/69667/1/643897.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": "8671"
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Bolc2014ComputerVA,\n author = {L. Bolc and R. Tadeusiewicz and L. Chmielewski and K. Wojciechowski},\n booktitle = {Lecture Notes in Computer Science},\n title = {Computer Vision and Graphics},\n volume = {8671},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:50832083df91f83333364544b24f8af4798eca32",
            "@type": "ScholarlyArticle",
            "paperId": "50832083df91f83333364544b24f8af4798eca32",
            "corpusId": 6575064,
            "url": "https://www.semanticscholar.org/paper/50832083df91f83333364544b24f8af4798eca32",
            "title": "Head Pose Estimation in Computer Vision: A Survey",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2009,
            "externalIds": {
                "MAG": "2149382413",
                "DBLP": "journals/pami/Murphy-ChutorianT09",
                "DOI": "10.1109/TPAMI.2008.106",
                "CorpusId": 6575064,
                "PubMed": "19229078"
            },
            "abstract": "The capacity to estimate the head pose of another person is a common human ability that presents a unique challenge for computer vision systems. Compared to face detection and recognition, which have been the primary foci of face-related vision research, identity-invariant head pose estimation has fewer rigorously evaluated systems or generic solutions. In this paper, we discuss the inherent difficulties in head pose estimation and present an organized survey describing the evolution of the field. Our discussion focuses on the advantages and disadvantages of each approach and spans 90 of the most innovative and characteristic papers that have been published on this topic. We compare these systems by focusing on their ability to estimate coarse and fine head pose, highlighting approaches that are well suited for unconstrained environments.",
            "referenceCount": 152,
            "citationCount": 1378,
            "influentialCitationCount": 83,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2009-04-01",
            "journal": {
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "volume": "31"
            },
            "citationStyles": {
                "bibtex": "@Article{Murphy-Chutorian2009HeadPE,\n author = {Erik Murphy-Chutorian and M. Trivedi},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {607-626},\n title = {Head Pose Estimation in Computer Vision: A Survey},\n volume = {31},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:099bdecfb6876524a240c6378d1ddc3b3c36e4da",
            "@type": "ScholarlyArticle",
            "paperId": "099bdecfb6876524a240c6378d1ddc3b3c36e4da",
            "corpusId": 1865334,
            "url": "https://www.semanticscholar.org/paper/099bdecfb6876524a240c6378d1ddc3b3c36e4da",
            "title": "Computer Vision in Sports",
            "venue": "Computer Vision and Image Understanding",
            "publicationVenue": {
                "id": "urn:research:5fbb417b-d7a5-44e6-856d-993f0624ed9c",
                "name": "Computer Vision and Image Understanding",
                "alternate_names": [
                    "Comput Vis Image Underst"
                ],
                "issn": "1077-3142",
                "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/622809/description#description"
            },
            "year": 2015,
            "externalIds": {
                "DBLP": "journals/cviu/MoeslundTHCE17",
                "MAG": "2621638931",
                "DOI": "10.1016/j.cviu.2017.05.006",
                "CorpusId": 1865334
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 49,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2015-01-20",
            "journal": {
                "name": "Comput. Vis. Image Underst.",
                "volume": "159"
            },
            "citationStyles": {
                "bibtex": "@Article{Singh2015ComputerVI,\n author = {Sameer Singh and T. Moeslund and G. Thomas and A. Hilton},\n booktitle = {Computer Vision and Image Understanding},\n journal = {Comput. Vis. Image Underst.},\n pages = {1-2},\n title = {Computer Vision in Sports},\n volume = {159},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0f421ce620850f346a346fcb78dc2d3843fb554f",
            "@type": "ScholarlyArticle",
            "paperId": "0f421ce620850f346a346fcb78dc2d3843fb554f",
            "corpusId": 820948,
            "url": "https://www.semanticscholar.org/paper/0f421ce620850f346a346fcb78dc2d3843fb554f",
            "title": "Deep Hierarchies in the Primate Visual Cortex: What Can We Learn for Computer Vision?",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2013,
            "externalIds": {
                "DBLP": "journals/pami/KrugerJKLLPRW13",
                "MAG": "2019377328",
                "DOI": "10.1109/TPAMI.2012.272",
                "CorpusId": 820948,
                "PubMed": "23787340"
            },
            "abstract": "Computational modeling of the primate visual system yields insights of potential relevance to some of the challenges that computer vision is facing, such as object recognition and categorization, motion detection and activity recognition, or vision-based navigation and manipulation. This paper reviews some functional principles and structures that are generally thought to underlie the primate visual cortex, and attempts to extract biological principles that could further advance computer vision research. Organized for a computer vision audience, we present functional principles of the processing hierarchies present in the primate visual system considering recent discoveries in neurophysiology. The hierarchical processing in the primate visual system is characterized by a sequence of different levels of processing (on the order of 10) that constitute a deep hierarchy in contrast to the flat vision architectures predominantly used in today's mainstream computer vision. We hope that the functional description of the deep hierarchies realized in the primate visual system provides valuable insights for the design of computer vision algorithms, fostering increasingly productive interaction between biological and computer vision research.",
            "referenceCount": 221,
            "citationCount": 348,
            "influentialCitationCount": 22,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://lirias.kuleuven.be/bitstream/123456789/372382/3/kruger_janssen%20PAMI%202013.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2013-08-01",
            "journal": {
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "volume": "35"
            },
            "citationStyles": {
                "bibtex": "@Article{Kr\u00fcger2013DeepHI,\n author = {N. Kr\u00fcger and P. Janssen and Sinan Kalkan and M. Lappe and A. Leonardis and J. Piater and A. Rodr\u00edguez-S\u00e1nchez and Laurenz Wiskott},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {1847-1871},\n title = {Deep Hierarchies in the Primate Visual Cortex: What Can We Learn for Computer Vision?},\n volume = {35},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e018fa4a1c893f964f76cee8ff735573974f87cc",
            "@type": "ScholarlyArticle",
            "paperId": "e018fa4a1c893f964f76cee8ff735573974f87cc",
            "corpusId": 2333743,
            "url": "https://www.semanticscholar.org/paper/e018fa4a1c893f964f76cee8ff735573974f87cc",
            "title": "Combining embedded accelerometers with computer vision for recognizing food preparation activities",
            "venue": "Ubiquitous Computing",
            "publicationVenue": {
                "id": "urn:research:2b672dfa-333b-4231-b056-bb6ec13c2173",
                "name": "Ubiquitous Computing",
                "alternate_names": [
                    "Ubiquitous Comput",
                    "UbiComp"
                ],
                "issn": null,
                "url": "http://www.ubicomp.org/"
            },
            "year": 2013,
            "externalIds": {
                "DBLP": "conf/huc/SteinM13",
                "MAG": "2109698606",
                "DOI": "10.1145/2493432.2493482",
                "CorpusId": 2333743
            },
            "abstract": "This paper introduces a publicly available dataset of complex activities that involve manipulative gestures. The dataset captures people preparing mixed salads and contains more than 4.5 hours of accelerometer and RGB-D video data, detailed annotations, and an evaluation protocol for comparison of activity recognition algorithms. Providing baseline results for one possible activity recognition task, this paper further investigates modality fusion methods at different stages of the recognition pipeline: (i) prior to feature extraction through accelerometer localization, (ii) at feature level via feature concatenation, and (iii) at classification level by combining classifier outputs. Empirical evaluation shows that fusing information captured by these sensor types can considerably improve recognition performance.",
            "referenceCount": 33,
            "citationCount": 367,
            "influentialCitationCount": 65,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://cvip.computing.dundee.ac.uk/papers/Stein2013UbiComp.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book",
                "Conference"
            ],
            "publicationDate": "2013-09-08",
            "journal": {
                "name": "Proceedings of the 2013 ACM international joint conference on Pervasive and ubiquitous computing",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Stein2013CombiningEA,\n author = {Sebastian Stein and S. McKenna},\n booktitle = {Ubiquitous Computing},\n journal = {Proceedings of the 2013 ACM international joint conference on Pervasive and ubiquitous computing},\n title = {Combining embedded accelerometers with computer vision for recognizing food preparation activities},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2f01d2a293984d35b041d109609960b54c7379e3",
            "@type": "ScholarlyArticle",
            "paperId": "2f01d2a293984d35b041d109609960b54c7379e3",
            "corpusId": 2017032,
            "url": "https://www.semanticscholar.org/paper/2f01d2a293984d35b041d109609960b54c7379e3",
            "title": "Leafsnap: A Computer Vision System for Automatic Plant Species Identification",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2012,
            "externalIds": {
                "DBLP": "conf/eccv/KumarBBJKLS12",
                "MAG": "2213241010",
                "DOI": "10.1007/978-3-642-33709-3_36",
                "CorpusId": 2017032
            },
            "abstract": null,
            "referenceCount": 17,
            "citationCount": 756,
            "influentialCitationCount": 79,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/978-3-642-33709-3_36.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2012-10-07",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Kumar2012LeafsnapAC,\n author = {Neeraj Kumar and P. Belhumeur and Arijit Biswas and David W. Jacobs and W. Kress and Ida C. Lopez and Jo\u00e3o V. B. Soares},\n booktitle = {European Conference on Computer Vision},\n pages = {502-516},\n title = {Leafsnap: A Computer Vision System for Automatic Plant Species Identification},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a9c214e846188adb645021cd7b1964b8ea1fef6f",
            "@type": "ScholarlyArticle",
            "paperId": "a9c214e846188adb645021cd7b1964b8ea1fef6f",
            "corpusId": 236493453,
            "url": "https://www.semanticscholar.org/paper/a9c214e846188adb645021cd7b1964b8ea1fef6f",
            "title": "Rethinking and Improving Relative Position Encoding for Vision Transformer",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "conf/iccv/WuPCFC21",
                "ArXiv": "2107.14222",
                "DOI": "10.1109/iccv48922.2021.00988",
                "CorpusId": 236493453
            },
            "abstract": "Relative position encoding (RPE) is important for transformer to capture sequence ordering of input tokens. General efficacy has been proven in natural language processing. However, in computer vision, its efficacy is not well studied and even remains controversial, e.g., whether relative position encoding can work equally well as absolute position? In order to clarify this, we first review existing relative position encoding methods and analyze their pros and cons when applied in vision transformers. We then propose new relative position encoding methods dedicated to 2D images, called image RPE (iRPE). Our methods consider directional relative distance modeling as well as the interactions between queries and relative position embeddings in self-attention mechanism. The proposed iRPE methods are simple and lightweight. They can be easily plugged into transformer blocks. Experiments demonstrate that solely due to the proposed encoding methods, DeiT [21] and DETR [1] obtain up to 1.5% (top-1 Acc) and 1.3% (mAP) stable improvements over their original versions on ImageNet and COCO respectively, without tuning any extra hyperparameters such as learning rate and weight decay. Our ablation and analysis also yield interesting findings, some of which run counter to previous understanding. Code and models are open-sourced at https://github.com/microsoft/Cream/tree/main/iRPE.",
            "referenceCount": 32,
            "citationCount": 184,
            "influentialCitationCount": 14,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2107.14222",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": "2021-07-29",
            "journal": {
                "name": "2021 IEEE/CVF International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wu2021RethinkingAI,\n author = {Kan Wu and Houwen Peng and Minghao Chen and Jianlong Fu and Hongyang Chao},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},\n pages = {10013-10021},\n title = {Rethinking and Improving Relative Position Encoding for Vision Transformer},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:50997081b89dcee1c304a16f714385142d512fa5",
            "@type": "ScholarlyArticle",
            "paperId": "50997081b89dcee1c304a16f714385142d512fa5",
            "corpusId": 19397286,
            "url": "https://www.semanticscholar.org/paper/50997081b89dcee1c304a16f714385142d512fa5",
            "title": "Computer Vision \u2013 ECCV 2014",
            "venue": "Lecture Notes in Computer Science",
            "publicationVenue": {
                "id": "urn:research:2f5d0e8a-faad-4f10-b323-2b2e3c439a78",
                "name": "Lecture Notes in Computer Science",
                "alternate_names": [
                    "LNCS",
                    "Transactions on Computational Systems Biology",
                    "Trans Comput Syst Biology",
                    "Lect Note Comput Sci"
                ],
                "issn": "0302-9743",
                "url": "http://www.springer.com/lncs"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "conf/eccv/2014-3",
                "MAG": "832971097",
                "DOI": "10.1007/978-3-319-10578-9",
                "CorpusId": 19397286
            },
            "abstract": null,
            "referenceCount": 69,
            "citationCount": 58,
            "influentialCitationCount": 0,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": "8691"
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Fleet2014ComputerV,\n author = {David J. Fleet and T. Pajdla and B. Schiele and T. Tuytelaars},\n booktitle = {Lecture Notes in Computer Science},\n title = {Computer Vision \u2013 ECCV 2014},\n volume = {8691},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:18101bfc08381ddea8fd944a3300dc8cffe34e63",
            "@type": "ScholarlyArticle",
            "paperId": "18101bfc08381ddea8fd944a3300dc8cffe34e63",
            "corpusId": 28404718,
            "url": "https://www.semanticscholar.org/paper/18101bfc08381ddea8fd944a3300dc8cffe34e63",
            "title": "Computer Vision \u2013 ECCV 2014",
            "venue": "Lecture Notes in Computer Science",
            "publicationVenue": {
                "id": "urn:research:2f5d0e8a-faad-4f10-b323-2b2e3c439a78",
                "name": "Lecture Notes in Computer Science",
                "alternate_names": [
                    "LNCS",
                    "Transactions on Computational Systems Biology",
                    "Trans Comput Syst Biology",
                    "Lect Note Comput Sci"
                ],
                "issn": "0302-9743",
                "url": "http://www.springer.com/lncs"
            },
            "year": 2014,
            "externalIds": {
                "DBLP": "conf/eccv/2014-5",
                "DOI": "10.1007/978-3-319-10602-1",
                "CorpusId": 28404718
            },
            "abstract": null,
            "referenceCount": 51,
            "citationCount": 48,
            "influentialCitationCount": 0,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/bfm%3A978-3-319-10602-1%2F1.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": "8693"
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Fleet2014ComputerV,\n author = {David J. Fleet and T. Pajdla and B. Schiele and T. Tuytelaars},\n booktitle = {Lecture Notes in Computer Science},\n title = {Computer Vision \u2013 ECCV 2014},\n volume = {8693},\n year = {2014}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:570502599a26bab7281ce7cbc07eb36bf7b12a51",
            "@type": "ScholarlyArticle",
            "paperId": "570502599a26bab7281ce7cbc07eb36bf7b12a51",
            "corpusId": 2928235,
            "url": "https://www.semanticscholar.org/paper/570502599a26bab7281ce7cbc07eb36bf7b12a51",
            "title": "Computer Vision Face Tracking For Use in a Perceptual User Interface",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1998,
            "externalIds": {
                "MAG": "1502024436",
                "CorpusId": 2928235
            },
            "abstract": "As a first step towards a perceptual user interface, a computer vision color tracking algorithm is developed and applied towards tracking human faces. Computer vision algorithms that are intended to form part of a perceptual user interface must be fast and efficient. They must be able to track in real time yet not absorb a major share of computational resources: other tasks must be able to run while the visual interface is being used. The new algorithm developed here is based on a robust non-parametric technique for climbing density gradients to find the mode (peak) of probability distributions called the mean shift algorithm. In our case, we want to find the mode of a color distribution within a video scene. Therefore, the mean shift algorithm is modified to deal with dynamically changing color probability distributions derived from video frame sequences. The modified algorithm is called the Continuously Adaptive Mean Shift (CAMSHIFT) algorithm. CAMSHIFT\u2019s tracking accuracy is compared against a Polhemus tracker. Tolerance to noise, distractors and performance is studied. CAMSHIFT is then used as a computer interface for controlling commercial computer games and for exploring immersive 3D graphic worlds. 3D structure 3D graphics; pattern recognition; perception and self-organization.",
            "referenceCount": 18,
            "citationCount": 1793,
            "influentialCitationCount": 146,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Bradski1998ComputerVF,\n author = {G. Bradski},\n title = {Computer Vision Face Tracking For Use in a Perceptual User Interface},\n year = {1998}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:eca5b9447cae81ec01582b5834a19308d7b99def",
            "@type": "ScholarlyArticle",
            "paperId": "eca5b9447cae81ec01582b5834a19308d7b99def",
            "corpusId": 88484291,
            "url": "https://www.semanticscholar.org/paper/eca5b9447cae81ec01582b5834a19308d7b99def",
            "title": "Three-dimensional computer vision: a geometric viewpoint",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1993,
            "externalIds": {
                "MAG": "2028310195",
                "DOI": "10.5860/choice.32-0357",
                "CorpusId": 88484291
            },
            "abstract": "Projective geometry modelling and calibrating cameras edge detection representing geometric primitives and their uncertainty stereo vision determining discrete motion from points and lines tracking tokens over time motion fields of curves interpolating and approximating three-dimensional data recognizing and locating objects and places answers to problems. Appendices: constrained optimization some results from algebraic geometry differential geometry.",
            "referenceCount": 0,
            "citationCount": 1982,
            "influentialCitationCount": 89,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1993-12-31",
            "journal": {
                "name": "",
                "volume": "29"
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Faugeras1993ThreedimensionalCV,\n author = {O. Faugeras},\n title = {Three-dimensional computer vision: a geometric viewpoint},\n volume = {29},\n year = {1993}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7b3b180fa12a2dcee8ff28bd88ba6c299405cd9c",
            "@type": "ScholarlyArticle",
            "paperId": "7b3b180fa12a2dcee8ff28bd88ba6c299405cd9c",
            "corpusId": 108456052,
            "url": "https://www.semanticscholar.org/paper/7b3b180fa12a2dcee8ff28bd88ba6c299405cd9c",
            "title": "Colour measurements by computer vision for food quality control \u2013 A review",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2013,
            "externalIds": {
                "MAG": "2007020941",
                "DOI": "10.1016/J.TIFS.2012.08.004",
                "CorpusId": 108456052
            },
            "abstract": null,
            "referenceCount": 94,
            "citationCount": 480,
            "influentialCitationCount": 17,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Agricultural and Food Sciences",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Trends in Food Science and Technology",
                "volume": "29"
            },
            "citationStyles": {
                "bibtex": "@Article{Wu2013ColourMB,\n author = {Di Wu and Da\u2010Wen Sun},\n journal = {Trends in Food Science and Technology},\n pages = {5-20},\n title = {Colour measurements by computer vision for food quality control \u2013 A review},\n volume = {29},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a067a682ecbb0d533d7fa7f84b4a322ab3714882",
            "@type": "ScholarlyArticle",
            "paperId": "a067a682ecbb0d533d7fa7f84b4a322ab3714882",
            "corpusId": 9356866,
            "url": "https://www.semanticscholar.org/paper/a067a682ecbb0d533d7fa7f84b4a322ab3714882",
            "title": "Computer vision syndrome: a study of knowledge and practices in university students.",
            "venue": "Nepalese Journal of Ophthalmology",
            "publicationVenue": {
                "id": "urn:research:52df9a54-6cc3-4685-9826-f6ba927def1a",
                "name": "Nepalese Journal of Ophthalmology",
                "alternate_names": [
                    "Nepal J Ophthalmol"
                ],
                "issn": "2072-6805",
                "url": "https://www.nepjol.info/index.php/NEPJOPH"
            },
            "year": 2013,
            "externalIds": {
                "MAG": "2082387856",
                "DOI": "10.3126/nepjoph.v5i2.8707",
                "CorpusId": 9356866,
                "PubMed": "24172549"
            },
            "abstract": "INTRODUCTION\nComputer vision syndrome (CVS) is a condition in which a person experiences one or more of eye symptoms as a result of prolonged working on a computer.\n\n\nOBJECTIVES\nTo determine the prevalence of CVS symptoms, knowledge and practices of computer use in students studying in different universities in Malaysia, and to evaluate the association of various factors in computer use with the occurrence of symptoms.\n\n\nMATERIAL AND METHODS\nIn a cross sectional, questionnaire survey study, data was collected in college students regarding the demography, use of spectacles, duration of daily continuous use of computer, symptoms of CVS, preventive measures taken to reduce the symptoms, use of radiation filter on the computer screen, and lighting in the room.\n\n\nRESULTS\nA total of 795 students, aged between 18 and 25 years, from five universities in Malaysia were surveyed. The prevalence of symptoms of CVS (one or more) was found to be 89.9%; the most disturbing symptom was headache (19.7%) followed by eye strain (16.4%). Students who used computer for more than 2 hours per day experienced significantly more symptoms of CVS (p=0.0001). Looking at far objects in-between the work was significantly (p=0.0008) associated with less frequency of CVS symptoms. The use of radiation filter on the screen (p=0.6777) did not help in reducing the CVS symptoms.\n\n\nCONCLUSION\nNinety percent of university students in Malaysia experienced symptoms related to CVS, which was seen more often in those who used computer for more than 2 hours continuously per day.",
            "referenceCount": 34,
            "citationCount": 195,
            "influentialCitationCount": 23,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nepjol.info/index.php/NEPJOPH/article/view/8707/7099",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Education",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2013-09-23",
            "journal": {
                "name": "Nepalese journal of ophthalmology : a biannual peer-reviewed academic journal of the Nepal Ophthalmic Society : NEPJOPH",
                "volume": "5 2"
            },
            "citationStyles": {
                "bibtex": "@Article{Sc2013ComputerVS,\n author = {Reddy Sc and Low Ck and Lim Yp and Low Ll and M. F and Nursaleha Mp},\n booktitle = {Nepalese Journal of Ophthalmology},\n journal = {Nepalese journal of ophthalmology : a biannual peer-reviewed academic journal of the Nepal Ophthalmic Society : NEPJOPH},\n pages = {\n          161-8\n        },\n title = {Computer vision syndrome: a study of knowledge and practices in university students.},\n volume = {5 2},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:786bf78d2e67e9c839fcdc5a955b5daa6a3f523f",
            "@type": "ScholarlyArticle",
            "paperId": "786bf78d2e67e9c839fcdc5a955b5daa6a3f523f",
            "corpusId": 207252215,
            "url": "https://www.semanticscholar.org/paper/786bf78d2e67e9c839fcdc5a955b5daa6a3f523f",
            "title": "International Journal of Computer Vision manuscript No. (will be inserted by the editor) Image Classification with the Fisher Vector: Theory and Practice",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": null,
            "externalIds": {
                "CorpusId": 207252215
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 1415,
            "influentialCitationCount": 176,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Misc{None,\n title = {International Journal of Computer Vision manuscript No. (will be inserted by the editor) Image Classification with the Fisher Vector: Theory and Practice}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4fc2074e7f057ae255a6a79efecdf5df3d121895",
            "@type": "ScholarlyArticle",
            "paperId": "4fc2074e7f057ae255a6a79efecdf5df3d121895",
            "corpusId": 261497448,
            "url": "https://www.semanticscholar.org/paper/4fc2074e7f057ae255a6a79efecdf5df3d121895",
            "title": "Multiple View Geometry in Computer Vision (2nd ed)",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2003,
            "externalIds": {
                "MAG": "2209124607",
                "CorpusId": 261497448
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 1438,
            "influentialCitationCount": 231,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Hartley2003MultipleVG,\n author = {Richard Hartley and Andrew Zisserman},\n title = {Multiple View Geometry in Computer Vision (2nd ed)},\n year = {2003}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:18b02beb27288f6bd9d4376ca41e70655a698084",
            "@type": "ScholarlyArticle",
            "paperId": "18b02beb27288f6bd9d4376ca41e70655a698084",
            "corpusId": 1545504,
            "url": "https://www.semanticscholar.org/paper/18b02beb27288f6bd9d4376ca41e70655a698084",
            "title": "A Bayesian Computer Vision System for Modeling Human Interactions",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 1999,
            "externalIds": {
                "MAG": "2102188949",
                "DBLP": "journals/pami/OliverRP00",
                "DOI": "10.1109/34.868684",
                "CorpusId": 1545504
            },
            "abstract": "We describe a real-time computer vision and machine learning system for modeling and recognizing human behaviors in a visual surveillance task. The system is particularly concerned with detecting when interactions between people occur, and classifying the type of interaction. Examples of interesting interaction behaviors include following another person, altering one's path to meet another, and so forth. Our system combines top-down with bottom-up information in a closed feedback loop, with both components employing a statistical Bayesian approach. We propose and compare two different state-based learning architectures, namely HMMs and CHMMs, for modeling behaviors and interactions. The CHMM model is shown to work much more efficiently and accurately. \n \nFinally, to deal with the problem of limited training data, a synthetic 'Alife-style' training system is used to develop flexible prior models for recognizing human interactions. We demonstrate the ability to use these a priori models to accurately classify real human behaviors and interactions with no additional tuning or training.",
            "referenceCount": 40,
            "citationCount": 1903,
            "influentialCitationCount": 111,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "1999-01-13",
            "journal": {
                "name": "IEEE Trans. Pattern Anal. Mach. Intell.",
                "volume": "22"
            },
            "citationStyles": {
                "bibtex": "@Article{Oliver1999ABC,\n author = {N. Oliver and Barbara Rosario and A. Pentland},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Trans. Pattern Anal. Mach. Intell.},\n pages = {831-843},\n title = {A Bayesian Computer Vision System for Modeling Human Interactions},\n volume = {22},\n year = {1999}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ad2c0ae801c9e8adece483e74725e12a8544d440",
            "@type": "ScholarlyArticle",
            "paperId": "ad2c0ae801c9e8adece483e74725e12a8544d440",
            "corpusId": 66425,
            "url": "https://www.semanticscholar.org/paper/ad2c0ae801c9e8adece483e74725e12a8544d440",
            "title": "Studying Relationships between Human Gaze, Description, and Computer Vision",
            "venue": "2013 IEEE Conference on Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2013,
            "externalIds": {
                "DBLP": "conf/cvpr/YunPSZB13",
                "MAG": "2100379672",
                "DOI": "10.1109/CVPR.2013.101",
                "CorpusId": 66425
            },
            "abstract": "We posit that user behavior during natural viewing of images contains an abundance of information about the content of images as well as information related to user intent and user defined content importance. In this paper, we conduct experiments to better understand the relationship between images, the eye movements people make while viewing images, and how people construct natural language to describe images. We explore these relationships in the context of two commonly used computer vision datasets. We then further relate human cues with outputs of current visual recognition systems and demonstrate prototype applications for gaze-enabled detection and annotation.",
            "referenceCount": 35,
            "citationCount": 88,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.cs.stonybrook.edu/~kyun/papers/kiwon_cvpr13_gaze.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2013-06-23",
            "journal": {
                "name": "2013 IEEE Conference on Computer Vision and Pattern Recognition",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yun2013StudyingRB,\n author = {Kiwon Yun and Yifan Peng and D. Samaras and G. Zelinsky and Tamara L. Berg},\n booktitle = {2013 IEEE Conference on Computer Vision and Pattern Recognition},\n journal = {2013 IEEE Conference on Computer Vision and Pattern Recognition},\n pages = {739-746},\n title = {Studying Relationships between Human Gaze, Description, and Computer Vision},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7564224d2a2e5ab702932baadf7d8da7730c43d6",
            "@type": "ScholarlyArticle",
            "paperId": "7564224d2a2e5ab702932baadf7d8da7730c43d6",
            "corpusId": 12980892,
            "url": "https://www.semanticscholar.org/paper/7564224d2a2e5ab702932baadf7d8da7730c43d6",
            "title": "Blink Rate, Incomplete Blinks and Computer Vision Syndrome",
            "venue": "Optometry and Vision Science",
            "publicationVenue": {
                "id": "urn:research:0444c465-1041-40ca-963e-628694a9eccc",
                "name": "Optometry and Vision Science",
                "alternate_names": [
                    "Optom Vis Sci"
                ],
                "issn": "1040-5488",
                "url": "https://journals.lww.com/optvissci"
            },
            "year": 2013,
            "externalIds": {
                "MAG": "2318888246",
                "DOI": "10.1097/OPX.0b013e31828f09a7",
                "CorpusId": 12980892,
                "PubMed": "23538437"
            },
            "abstract": "Purpose Computer vision syndrome (CVS), a highly prevalent condition, is frequently associated with dry eye disorders. Furthermore, a reduced blink rate has been observed during computer use. The present study examined whether post task ocular and visual symptoms are associated with either a decreased blink rate or a higher prevalence of incomplete blinks. An additional trial tested whether increasing the blink rate would reduce CVS symptoms. Methods Subjects (N = 21) were required to perform a continuous 15-minute reading task on a desktop computer at a viewing distance of 50 cm. Subjects were videotaped during the task to determine their blink rate and amplitude. Immediately after the task, subjects completed a questionnaire regarding ocular symptoms experienced during the trial. In a second session, the blink rate was increased by means of an audible tone that sounded every 4 seconds, with subjects being instructed to blink on hearing the tone. Results The mean blink rate during the task without the audible tone was 11.6 blinks per minute (SD, 7.84). The percentage of blinks deemed incomplete for each subject ranged from 0.9 to 56.5%, with a mean of 16.1% (SD, 15.7). A significant positive correlation was observed between the total symptom score and the percentage of incomplete blinks during the task (p = 0.002). Furthermore, a significant negative correlation was noted between the blink score and symptoms (p = 0.035). Increasing the mean blink rate to 23.5 blinks per minute by means of the audible tone did not produce a significant change in the symptom score. Conclusions Whereas CVS symptoms are associated with a reduced blink rate, the completeness of the blink may be equally significant. Because instructing a patient to increase his or her blink rate may be ineffective or impractical, actions to achieve complete corneal coverage during blinking may be more helpful in alleviating symptoms during computer operation.",
            "referenceCount": 35,
            "citationCount": 163,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Study"
            ],
            "publicationDate": "2013-05-01",
            "journal": {
                "name": "Optometry and Vision Science",
                "volume": "90"
            },
            "citationStyles": {
                "bibtex": "@Article{Portello2013BlinkRI,\n author = {J. Portello and M. Rosenfield and Christina A. Chu},\n booktitle = {Optometry and Vision Science},\n journal = {Optometry and Vision Science},\n pages = {482\u2013487},\n title = {Blink Rate, Incomplete Blinks and Computer Vision Syndrome},\n volume = {90},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9b5cfa32dc382c468fd7410a28783b4b85712844",
            "@type": "ScholarlyArticle",
            "paperId": "9b5cfa32dc382c468fd7410a28783b4b85712844",
            "corpusId": 61523068,
            "url": "https://www.semanticscholar.org/paper/9b5cfa32dc382c468fd7410a28783b4b85712844",
            "title": "Three-Dimensional Computer Vision: A Geometric Viewpoint",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1995,
            "externalIds": {
                "MAG": "2332833001",
                "DOI": "10.1093/COMJNL/38.1.85",
                "CorpusId": 61523068
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 1864,
            "influentialCitationCount": 127,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "The Computer Journal",
                "volume": "38"
            },
            "citationStyles": {
                "bibtex": "@Article{Ghosh1995ThreeDimensionalCV,\n author = {P. K. Ghosh and S. Mudur},\n journal = {The Computer Journal},\n pages = {85-86},\n title = {Three-Dimensional Computer Vision: A Geometric Viewpoint},\n volume = {38},\n year = {1995}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:088aee19d75ecd83530f0f653eed35a9d322be8f",
            "@type": "ScholarlyArticle",
            "paperId": "088aee19d75ecd83530f0f653eed35a9d322be8f",
            "corpusId": 27075543,
            "url": "https://www.semanticscholar.org/paper/088aee19d75ecd83530f0f653eed35a9d322be8f",
            "title": "Scale Space and Variational Methods in Computer Vision",
            "venue": "Lecture Notes in Computer Science",
            "publicationVenue": {
                "id": "urn:research:2f5d0e8a-faad-4f10-b323-2b2e3c439a78",
                "name": "Lecture Notes in Computer Science",
                "alternate_names": [
                    "LNCS",
                    "Transactions on Computational Systems Biology",
                    "Trans Comput Syst Biology",
                    "Lect Note Comput Sci"
                ],
                "issn": "0302-9743",
                "url": "http://www.springer.com/lncs"
            },
            "year": 2013,
            "externalIds": {
                "DBLP": "conf/scalespace/2013",
                "MAG": "2502328895",
                "DOI": "10.1007/978-3-642-38267-3",
                "CorpusId": 27075543
            },
            "abstract": null,
            "referenceCount": 25,
            "citationCount": 68,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/bfm:978-3-642-38267-3/1?pdf=chapter%20toc",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": "7893"
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Kuijper2013ScaleSA,\n author = {Arjan Kuijper and K. Bredies and T. Pock and H. Bischof},\n booktitle = {Lecture Notes in Computer Science},\n title = {Scale Space and Variational Methods in Computer Vision},\n volume = {7893},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0196776b7d5f512914687d793f0e7d9ab96f5854",
            "@type": "ScholarlyArticle",
            "paperId": "0196776b7d5f512914687d793f0e7d9ab96f5854",
            "corpusId": 34636639,
            "url": "https://www.semanticscholar.org/paper/0196776b7d5f512914687d793f0e7d9ab96f5854",
            "title": "Measurement of meat color using a computer vision system.",
            "venue": "Meat Science",
            "publicationVenue": {
                "id": "urn:research:8c61a40f-d013-4cce-a8c5-8c75c21e9faa",
                "name": "Meat Science",
                "alternate_names": [
                    "Meat Sci"
                ],
                "issn": "0309-1740",
                "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/405866/description#description"
            },
            "year": 2013,
            "externalIds": {
                "MAG": "1966170232",
                "DOI": "10.1016/j.meatsci.2012.08.010",
                "CorpusId": 34636639,
                "PubMed": "22981646"
            },
            "abstract": null,
            "referenceCount": 40,
            "citationCount": 163,
            "influentialCitationCount": 10,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Mathematics",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Agricultural and Food Sciences",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Study",
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "Meat science",
                "volume": "93 1"
            },
            "citationStyles": {
                "bibtex": "@Article{Girolami2013MeasurementOM,\n author = {A. Girolami and F. Napolitano and D. Faraone and A. Braghieri},\n booktitle = {Meat Science},\n journal = {Meat science},\n pages = {\n          111-8\n        },\n title = {Measurement of meat color using a computer vision system.},\n volume = {93 1},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:34e93b172dca389b7daa2d0770a205723a4a1593",
            "@type": "ScholarlyArticle",
            "paperId": "34e93b172dca389b7daa2d0770a205723a4a1593",
            "corpusId": 195932460,
            "url": "https://www.semanticscholar.org/paper/34e93b172dca389b7daa2d0770a205723a4a1593",
            "title": "Computer Vision",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2001,
            "externalIds": {
                "MAG": "2611684114",
                "DOI": "10.1201/9780203494455.sec4",
                "CorpusId": 195932460
            },
            "abstract": "From the Publisher: \nComputer Vision presents the necessary theory and techniques for students and practitioners who will work in fields where significant information must be extracted automatically from images. It will be a useful resource automatically from images. It will be a useful resource book for professionals and a core text for both undergraduate and beginning graduate computer vision and imaging courses. \n \nFeatures \n \n \nTopics include image databases an virtual and augmented reality in addition to classical topics. \nOffers a complete view of two real-world systems that use computer vision. \nContains applications from industry, medicine, land use, multimedia, and computer graphics. \nIncludes over 250 exercises and programming projects, 48 separately defined algorithms, and 360 figures. \nThe companion website features include image archive, sample",
            "referenceCount": 1,
            "citationCount": 1679,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2001-02-02",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Stockman2001ComputerV,\n author = {G. Stockman and L. Shapiro},\n title = {Computer Vision},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5c683de8cf1d702354de1c5c0abb603c2f138479",
            "@type": "ScholarlyArticle",
            "paperId": "5c683de8cf1d702354de1c5c0abb603c2f138479",
            "corpusId": 264810629,
            "url": "https://www.semanticscholar.org/paper/5c683de8cf1d702354de1c5c0abb603c2f138479",
            "title": "Decision Forests for Computer Vision and Medical Image Analysis",
            "venue": "Advances in Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:e97fa60a-354c-45ea-abf9-f3949365196c",
                "name": "Advances in Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "Adv Comput Vis Pattern Recognit"
                ],
                "issn": "2191-6586",
                "url": "https://www.springer.com/series/4205"
            },
            "year": 2013,
            "externalIds": {
                "MAG": "137456267",
                "DOI": "10.1007/978-1-4471-4929-3",
                "CorpusId": 264810629
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 214,
            "influentialCitationCount": 5,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2013-01-31",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Criminisi2013DecisionFF,\n author = {A. Criminisi and J. Shotton},\n booktitle = {Advances in Computer Vision and Pattern Recognition},\n title = {Decision Forests for Computer Vision and Medical Image Analysis},\n year = {2013}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6e33fca1addd62cc278023cabac60141c4af60ec",
            "@type": "ScholarlyArticle",
            "paperId": "6e33fca1addd62cc278023cabac60141c4af60ec",
            "corpusId": 207079297,
            "url": "https://www.semanticscholar.org/paper/6e33fca1addd62cc278023cabac60141c4af60ec",
            "title": "Vision based hand gesture recognition for human computer interaction: a survey",
            "venue": "Artificial Intelligence Review",
            "publicationVenue": {
                "id": "urn:research:ea8553fe-2467-4367-afee-c4deb3754820",
                "name": "Artificial Intelligence Review",
                "alternate_names": [
                    "Artif Intell Rev"
                ],
                "issn": "0269-2821",
                "url": "https://link.springer.com/journal/10462"
            },
            "year": 2012,
            "externalIds": {
                "DBLP": "journals/air/RautarayA15",
                "MAG": "1977995219",
                "DOI": "10.1007/s10462-012-9356-9",
                "CorpusId": 207079297
            },
            "abstract": null,
            "referenceCount": 263,
            "citationCount": 1333,
            "influentialCitationCount": 54,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2012-11-06",
            "journal": {
                "name": "Artificial Intelligence Review",
                "volume": "43"
            },
            "citationStyles": {
                "bibtex": "@Article{Rautaray2012VisionBH,\n author = {S. Rautaray and A. Agrawal},\n booktitle = {Artificial Intelligence Review},\n journal = {Artificial Intelligence Review},\n pages = {1 - 54},\n title = {Vision based hand gesture recognition for human computer interaction: a survey},\n volume = {43},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:dd971c07879e1ce12b06991319528c06280eeb9b",
            "@type": "ScholarlyArticle",
            "paperId": "dd971c07879e1ce12b06991319528c06280eeb9b",
            "corpusId": 118684904,
            "url": "https://www.semanticscholar.org/paper/dd971c07879e1ce12b06991319528c06280eeb9b",
            "title": "Event-Based Vision: A Survey",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2939877207",
                "ArXiv": "1904.08405",
                "DBLP": "journals/pami/GallegoDOBTCLDC22",
                "DOI": "10.5167/UZH-185139",
                "CorpusId": 118684904,
                "PubMed": "32750812"
            },
            "abstract": "Event cameras are bio-inspired sensors that differ from conventional frame cameras: Instead of capturing images at a fixed rate, they asynchronously measure per-pixel brightness changes, and output a stream of events that encode the time, location and sign of the brightness changes. Event cameras offer attractive properties compared to traditional cameras: high temporal resolution (in the order of $\\mu$\u03bcs), very high dynamic range (140 dB versus 60 dB), low power consumption, and high pixel bandwidth (on the order of kHz) resulting in reduced motion blur. Hence, event cameras have a large potential for robotics and computer vision in challenging scenarios for traditional cameras, such as low-latency, high speed, and high dynamic range. However, novel methods are required to process the unconventional output of these sensors in order to unlock their potential. This paper provides a comprehensive overview of the emerging field of event-based vision, with a focus on the applications and the algorithms developed to unlock the outstanding properties of event cameras. We present event cameras from their working principle, the actual sensors that are available and the tasks that they have been used for, from low-level vision (feature detection and tracking, optic flow, etc.) to high-level vision (reconstruction, segmentation, recognition). We also discuss the techniques developed to process events, including learning-based techniques, as well as specialized processors for these novel sensors, such as spiking neural networks. Additionally, we highlight the challenges that remain to be tackled and the opportunities that lie ahead in the search for a more efficient, bio-inspired way for machines to perceive and interact with the world.",
            "referenceCount": 296,
            "citationCount": 976,
            "influentialCitationCount": 93,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ieeexplore.ieee.org/ielx7/34/9639876/09138762.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-04-17",
            "journal": {
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "volume": "44"
            },
            "citationStyles": {
                "bibtex": "@Article{Gallego2019EventBasedVA,\n author = {Guillermo Gallego and T. Delbr\u00fcck and G. Orchard and C. Bartolozzi and B. Taba and A. Censi and Stefan Leutenegger and A. Davison and J. Conradt and Kostas Daniilidis and D. Scaramuzza},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {154-180},\n title = {Event-Based Vision: A Survey},\n volume = {44},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d6dccb5d71fbb6f5765f89633ba3a8e6809a720d",
            "@type": "ScholarlyArticle",
            "paperId": "d6dccb5d71fbb6f5765f89633ba3a8e6809a720d",
            "corpusId": 189897750,
            "url": "https://www.semanticscholar.org/paper/d6dccb5d71fbb6f5765f89633ba3a8e6809a720d",
            "title": "Stand-Alone Self-Attention in Vision Models",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2970389371",
                "DBLP": "conf/nips/ParmarRVBLS19",
                "ArXiv": "1906.05909",
                "CorpusId": 189897750
            },
            "abstract": "Convolutions are a fundamental building block of modern computer vision systems. Recent approaches have argued for going beyond convolutions in order to capture long-range dependencies. These efforts focus on augmenting convolutional models with content-based interactions, such as self-attention and non-local means, to achieve gains on a number of vision tasks. The natural question that arises is whether attention can be a stand-alone primitive for vision models instead of serving as just an augmentation on top of convolutions. In developing and testing a pure self-attention vision model, we verify that self-attention can indeed be an effective stand-alone layer. A simple procedure of replacing all instances of spatial convolutions with a form of self-attention applied to ResNet model produces a fully self-attentional model that outperforms the baseline on ImageNet classification with 12% fewer FLOPS and 29% fewer parameters. On COCO object detection, a pure self-attention model matches the mAP of a baseline RetinaNet while having 39% fewer FLOPS and 34% fewer parameters. Detailed ablation studies demonstrate that self-attention is especially impactful when used in later layers. These results establish that stand-alone self-attention is an important addition to the vision practitioner's toolbox.",
            "referenceCount": 70,
            "citationCount": 919,
            "influentialCitationCount": 58,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-06-13",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1906.05909"
            },
            "citationStyles": {
                "bibtex": "@Article{Ramachandran2019StandAloneSI,\n author = {Prajit Ramachandran and Niki Parmar and Ashish Vaswani and Irwan Bello and Anselm Levskaya and Jonathon Shlens},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {Stand-Alone Self-Attention in Vision Models},\n volume = {abs/1906.05909},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:98811e9bb24657e1fac4512be39ea9acd4c85230",
            "@type": "ScholarlyArticle",
            "paperId": "98811e9bb24657e1fac4512be39ea9acd4c85230",
            "corpusId": 5991042,
            "url": "https://www.semanticscholar.org/paper/98811e9bb24657e1fac4512be39ea9acd4c85230",
            "title": "Algorithms for image processing and computer vision",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1996,
            "externalIds": {
                "DBLP": "books/daglib/0000417",
                "MAG": "1575739010",
                "CorpusId": 5991042
            },
            "abstract": "A cookbook of algorithms for common image processing applicationsThanks to advances in computer hardware and software, algorithms have been developed that support sophisticated image processing without requiring an extensive background in mathematics. This bestselling book has been fully updated with the newest of these, including 2D vision methods in content-based searches and the use of graphics cards as image processing computational aids. Its an ideal reference for software engineers and developers, advanced programmers, graphics programmers, scientists, and other specialists who require highly specialized image processing.Algorithms now exist for a wide variety of sophisticated image processing applications required by software engineers and developers, advanced programmers, graphics programmers, scientists, and related specialistsThis bestselling book has been completely updated to include the latest algorithms, including 2D vision methods in content-based searches, details on modern classifier methods, and graphics cards used as image processing computational aidsSaves hours of mathematical calculating by using distributed processing and GPU programming, and gives non-mathematicians the shortcuts needed to program relatively sophisticated applications.Algorithms for Image Processing and Computer Vision, 2nd Edition provides the tools to speed development of image processing applications.",
            "referenceCount": 188,
            "citationCount": 1630,
            "influentialCitationCount": 74,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "1996-11-25",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Parker1996AlgorithmsFI,\n author = {J. Parker},\n pages = {I-XIII, 1-417},\n title = {Algorithms for image processing and computer vision},\n year = {1996}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4844150f7aefd3c449c3bd81e94581ff0061037e",
            "@type": "ScholarlyArticle",
            "paperId": "4844150f7aefd3c449c3bd81e94581ff0061037e",
            "corpusId": 59644500,
            "url": "https://www.semanticscholar.org/paper/4844150f7aefd3c449c3bd81e94581ff0061037e",
            "title": "Computer Vision: Models, Learning, and Inference",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2012,
            "externalIds": {
                "MAG": "35490052",
                "CorpusId": 59644500
            },
            "abstract": "This modern treatment of computer vision focuses on learning and inference in probabilistic models as a unifying theme. It shows how to use training data to learn the relationships between the observed image data and the aspects of the world that we wish to estimate, such as the 3D structure or the object class, and how to exploit these relationships to make new inferences about the world from new image data. With minimal prerequisites, the book starts from the basics of probability and model fitting and works up to real examples that the reader can implement and modify to build useful vision systems. Primarily meant for advanced undergraduate and graduate students, the detailed methodological presentation will also be useful for practitioners of computer vision. - Covers cutting-edge techniques, including graph cuts, machine learning, and multiple view geometry. - A unified approach shows the common basis for solutions of important computer vision problems, such as camera calibration, face recognition, and object tracking. - More than 70 algorithms are described in sufficient detail to implement. - More than 350 full-color illustrations amplify the text. - The treatment is self-contained, including all of the background mathematics. - Additional resources at www.computervisionmodels.com.",
            "referenceCount": 2,
            "citationCount": 485,
            "influentialCitationCount": 34,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2012-06-18",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Prince2012ComputerVM,\n author = {S. Prince},\n title = {Computer Vision: Models, Learning, and Inference},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:355de7460120ddc1150d9ce3756f9848983f7ff4",
            "@type": "ScholarlyArticle",
            "paperId": "355de7460120ddc1150d9ce3756f9848983f7ff4",
            "corpusId": 2972357,
            "url": "https://www.semanticscholar.org/paper/355de7460120ddc1150d9ce3756f9848983f7ff4",
            "title": "Midge: Generating Image Descriptions From Computer Vision Detections",
            "venue": "Conference of the European Chapter of the Association for Computational Linguistics",
            "publicationVenue": {
                "id": "urn:research:8de18c35-6785-4e54-99f2-21ee961302c6",
                "name": "Conference of the European Chapter of the Association for Computational Linguistics",
                "alternate_names": [
                    "Conf Eur Chapter Assoc Comput Linguistics",
                    "EACL"
                ],
                "issn": null,
                "url": "https://www.aclweb.org/anthology/venues/eacl/"
            },
            "year": 2012,
            "externalIds": {
                "MAG": "8316075",
                "ACL": "E12-1076",
                "DBLP": "conf/eacl/MitchellDGYSHMBBD12",
                "CorpusId": 2972357
            },
            "abstract": "This paper introduces a novel generation system that composes humanlike descriptions of images from computer vision detections. By leveraging syntactically informed word co-occurrence statistics, the generator filters and constrains the noisy detections output from a vision system to generate syntactic trees that detail what the computer vision system sees. Results show that the generation system outperforms state-of-the-art systems, automatically generating some of the most natural image descriptions to date.",
            "referenceCount": 32,
            "citationCount": 454,
            "influentialCitationCount": 18,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2012-04-23",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Mitchell2012MidgeGI,\n author = {Margaret Mitchell and Jesse Dodge and Amit Goyal and Kota Yamaguchi and K. Stratos and Xufeng Han and Alyssa C. Mensch and A. Berg and Tamara L. Berg and Hal Daum\u00e9},\n booktitle = {Conference of the European Chapter of the Association for Computational Linguistics},\n pages = {747-756},\n title = {Midge: Generating Image Descriptions From Computer Vision Detections},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:23b560227c1e8f37348f24ff34e42113cbb11719",
            "@type": "ScholarlyArticle",
            "paperId": "23b560227c1e8f37348f24ff34e42113cbb11719",
            "corpusId": 18919438,
            "url": "https://www.semanticscholar.org/paper/23b560227c1e8f37348f24ff34e42113cbb11719",
            "title": "PIXHAWK: A micro aerial vehicle design for autonomous flight using onboard computer vision",
            "venue": "Auton. Robots",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2012,
            "externalIds": {
                "DBLP": "journals/arobots/MeierTHLFP12",
                "MAG": "1966301784",
                "DOI": "10.1007/s10514-012-9281-4",
                "CorpusId": 18919438
            },
            "abstract": null,
            "referenceCount": 41,
            "citationCount": 391,
            "influentialCitationCount": 29,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.research-collection.ethz.ch/bitstream/20.500.11850/62550/2/10514_2012_Article_9281.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2012-02-23",
            "journal": {
                "name": "Autonomous Robots",
                "volume": "33"
            },
            "citationStyles": {
                "bibtex": "@Article{Meier2012PIXHAWKAM,\n author = {Lorenz Meier and Petri Tanskanen and Lionel Heng and Gim Hee Lee and F. Fraundorfer and M. Pollefeys},\n booktitle = {Auton. Robots},\n journal = {Autonomous Robots},\n pages = {21-39},\n title = {PIXHAWK: A micro aerial vehicle design for autonomous flight using onboard computer vision},\n volume = {33},\n year = {2012}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a06547951c97b2a32f23a6c2b5f79c8c75c9b9bd",
            "@type": "ScholarlyArticle",
            "paperId": "a06547951c97b2a32f23a6c2b5f79c8c75c9b9bd",
            "corpusId": 2121536,
            "url": "https://www.semanticscholar.org/paper/a06547951c97b2a32f23a6c2b5f79c8c75c9b9bd",
            "title": "An Iterative Image Registration Technique with an Application to Stereo Vision",
            "venue": "International Joint Conference on Artificial Intelligence",
            "publicationVenue": {
                "id": "urn:research:67f7f831-711a-43c8-8785-1e09005359b5",
                "name": "International Joint Conference on Artificial Intelligence",
                "alternate_names": [
                    "Int Jt Conf Artif Intell",
                    "IJCAI"
                ],
                "issn": null,
                "url": "http://www.ijcai.org/"
            },
            "year": 1981,
            "externalIds": {
                "MAG": "2118877769",
                "DBLP": "conf/ijcai/LucasK81",
                "CorpusId": 2121536
            },
            "abstract": "Image registration finds a variety of applications in computer vision. Unfortunately, traditional image registration techniques tend to be costly. We present a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of Newton-Raphson iteration. Our technique is taster because it examines far fewer potential matches between the images than existing techniques Furthermore, this registration technique can be generalized to handle rotation, scaling and shearing. We show how our technique can be adapted tor use in a stereo vision system.",
            "referenceCount": 10,
            "citationCount": 14199,
            "influentialCitationCount": 1033,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "1981-08-24",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Lucas1981AnII,\n author = {B. D. Lucas and T. Kanade},\n booktitle = {International Joint Conference on Artificial Intelligence},\n pages = {674-679},\n title = {An Iterative Image Registration Technique with an Application to Stereo Vision},\n year = {1981}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d40c77c010c8dbef6142903a02f2a73a85012d5d",
            "@type": "ScholarlyArticle",
            "paperId": "d40c77c010c8dbef6142903a02f2a73a85012d5d",
            "corpusId": 236986986,
            "url": "https://www.semanticscholar.org/paper/d40c77c010c8dbef6142903a02f2a73a85012d5d",
            "title": "A Survey on Vision Transformer",
            "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
            "publicationVenue": {
                "id": "urn:research:25248f80-fe99-48e5-9b8e-9baef3b8e23b",
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "alternate_names": [
                    "IEEE Trans Pattern Anal Mach Intell"
                ],
                "issn": "0162-8828",
                "url": "http://www.computer.org/tpami/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/pami/00020C0GLTXXXYZ23",
                "ArXiv": "2012.12556",
                "DOI": "10.1109/TPAMI.2022.3152247",
                "CorpusId": 236986986,
                "PubMed": "35180075"
            },
            "abstract": "Transformer, first applied to the field of natural language processing, is a type of deep neural network mainly based on the self-attention mechanism. Thanks to its strong representation capabilities, researchers are looking at ways to apply transformer to computer vision tasks. In a variety of visual benchmarks, transformer-based models perform similar to or better than other types of networks such as convolutional and recurrent neural networks. Given its high performance and less need for vision-specific inductive bias, transformer is receiving more and more attention from the computer vision community. In this paper, we review these vision transformer models by categorizing them in different tasks and analyzing their advantages and disadvantages. The main categories we explore include the backbone network, high/mid-level vision, low-level vision, and video processing. We also include efficient transformer methods for pushing transformer into real device-based applications. Furthermore, we also take a brief look at the self-attention mechanism in computer vision, as it is the base component in transformer. Toward the end of this paper, we discuss the challenges and provide several further research directions for vision transformers.",
            "referenceCount": 327,
            "citationCount": 703,
            "influentialCitationCount": 18,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2012.12556",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-12-23",
            "journal": {
                "name": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
                "volume": "PP"
            },
            "citationStyles": {
                "bibtex": "@Article{Han2020ASO,\n author = {Kai Han and Yunhe Wang and Hanting Chen and Xinghao Chen and Jianyuan Guo and Zhenhua Liu and Yehui Tang and An Xiao and Chunjing Xu and Yixing Xu and Zhaohui Yang and Yiman Zhang and D. Tao},\n booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n pages = {1-1},\n title = {A Survey on Vision Transformer},\n volume = {PP},\n year = {2020}\n}\n"
            }
        }
    }
]