[
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:290f40b6e5ad78a7f5c2cb226e48f98132843d9f",
            "@type": "ScholarlyArticle",
            "paperId": "290f40b6e5ad78a7f5c2cb226e48f98132843d9f",
            "corpusId": 218760367,
            "url": "https://www.semanticscholar.org/paper/290f40b6e5ad78a7f5c2cb226e48f98132843d9f",
            "title": "Design and Development of Cost-Effective Child Surveillance System using Computer Vision Technology",
            "venue": "2022 International Conference on Recent Trends in Microelectronics, Automation, Computing and Communications Systems (ICMACC)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2022,
            "externalIds": {
                "DOI": "10.1109/ICMACC54824.2022.10093561",
                "CorpusId": 218760367
            },
            "abstract": "The project's primary goal is to ensure child surveillance, continuous monitor and alert system for safety. Pre-defined navigation is one of the primary challenges in the robotic industry. Many technologies have been developed to overcome these problems. The project utilizes a high-quality night vision camera that is installed on a navigation robot that moves in the pre-defined path. The night vision camera captures the image and video of child activity, and transmits the data to the main system. The navigation robot is also equipped with the passive infrared (PIR) sensor to monitor any unauthorized human face intervention for child abuduction, and sound sensor for cry detection. The sound sensor detects the crying of the child and gives alert to the parent for immediate assistance.re will be developed using Python in the Google Colab.",
            "referenceCount": 16,
            "citationCount": 3804,
            "influentialCitationCount": 258,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Conference"
            ],
            "publicationDate": "2022-12-28",
            "journal": {
                "name": "2022 International Conference on Recent Trends in Microelectronics, Automation, Computing and Communications Systems (ICMACC)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Conference{Peddiraju2022DesignAD,\n author = {Vedavyas Peddiraju and Ramchandar Rao Pamulaparthi and Chakaradhar Adupa and Laxman Raju Thoutam},\n booktitle = {2022 International Conference on Recent Trends in Microelectronics, Automation, Computing and Communications Systems (ICMACC)},\n journal = {2022 International Conference on Recent Trends in Microelectronics, Automation, Computing and Communications Systems (ICMACC)},\n pages = {119-124},\n title = {Design and Development of Cost-Effective Child Surveillance System using Computer Vision Technology},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:23ffaa0fe06eae05817f527a47ac3291077f9e58",
            "@type": "ScholarlyArticle",
            "paperId": "23ffaa0fe06eae05817f527a47ac3291077f9e58",
            "corpusId": 206593880,
            "url": "https://www.semanticscholar.org/paper/23ffaa0fe06eae05817f527a47ac3291077f9e58",
            "title": "Rethinking the Inception Architecture for Computer Vision",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2015,
            "externalIds": {
                "MAG": "2183341477",
                "DBLP": "conf/cvpr/SzegedyVISW16",
                "ArXiv": "1512.00567",
                "DOI": "10.1109/CVPR.2016.308",
                "CorpusId": 206593880
            },
            "abstract": "Convolutional networks are at the core of most state of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21:2% top-1 and 5:6% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3:5% top-5 error and 17:3% top-1 error on the validation set and 3:6% top-5 error on the official test set.",
            "referenceCount": 24,
            "citationCount": 22448,
            "influentialCitationCount": 3101,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1512.00567",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2015-12-02",
            "journal": {
                "name": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Szegedy2015RethinkingTI,\n author = {Christian Szegedy and Vincent Vanhoucke and Sergey Ioffe and Jonathon Shlens and Z. Wojna},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {2818-2826},\n title = {Rethinking the Inception Architecture for Computer Vision},\n year = {2015}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ff7bcaa4556cb13fc7bf03e477172493546172cd",
            "@type": "ScholarlyArticle",
            "paperId": "ff7bcaa4556cb13fc7bf03e477172493546172cd",
            "corpusId": 71134,
            "url": "https://www.semanticscholar.org/paper/ff7bcaa4556cb13fc7bf03e477172493546172cd",
            "title": "What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/KendallG17",
                "MAG": "2600383743",
                "ArXiv": "1703.04977",
                "CorpusId": 71134
            },
            "abstract": "There are two major types of uncertainty one can model. Aleatoric uncertainty captures noise inherent in the observations. On the other hand, epistemic uncertainty accounts for uncertainty in the model - uncertainty which can be explained away given enough data. Traditionally it has been difficult to model epistemic uncertainty in computer vision, but with new Bayesian deep learning tools this is now possible. We study the benefits of modeling epistemic vs. aleatoric uncertainty in Bayesian deep learning models for vision tasks. For this we present a Bayesian deep learning framework combining input-dependent aleatoric uncertainty together with epistemic uncertainty. We study models under the framework with per-pixel semantic segmentation and depth regression tasks. Further, our explicit uncertainty formulation leads to new loss functions for these tasks, which can be interpreted as learned attenuation. This makes the loss more robust to noisy data, also giving new state-of-the-art results on segmentation and depth regression benchmarks.",
            "referenceCount": 41,
            "citationCount": 3601,
            "influentialCitationCount": 479,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2017-03-15",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1703.04977"
            },
            "citationStyles": {
                "bibtex": "@Article{Kendall2017WhatUD,\n author = {Alex Kendall and Y. Gal},\n booktitle = {Neural Information Processing Systems},\n journal = {ArXiv},\n title = {What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?},\n volume = {abs/1703.04977},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d274dfd00aaac4c4f50030c489c31ea1b6169376",
            "@type": "ScholarlyArticle",
            "paperId": "d274dfd00aaac4c4f50030c489c31ea1b6169376",
            "corpusId": 261497446,
            "url": "https://www.semanticscholar.org/paper/d274dfd00aaac4c4f50030c489c31ea1b6169376",
            "title": "Multiple View Geometry in Computer Vision",
            "venue": "K\u00fcnstliche Intell.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2001,
            "externalIds": {
                "DBLP": "journals/ki/Wrobel01",
                "MAG": "1517129425",
                "CorpusId": 261497446
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 17587,
            "influentialCitationCount": 1988,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": null,
            "journal": {
                "name": "K\u00fcnstliche Intell.",
                "volume": "15"
            },
            "citationStyles": {
                "bibtex": "@Article{Wrobel2001MultipleVG,\n author = {Bernhard P. Wrobel},\n booktitle = {K\u00fcnstliche Intell.},\n journal = {K\u00fcnstliche Intell.},\n pages = {41},\n title = {Multiple View Geometry in Computer Vision},\n volume = {15},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:21ec90872abd986c12afe39bebe807732ffa70c9",
            "@type": "ScholarlyArticle",
            "paperId": "21ec90872abd986c12afe39bebe807732ffa70c9",
            "corpusId": 244477674,
            "url": "https://www.semanticscholar.org/paper/21ec90872abd986c12afe39bebe807732ffa70c9",
            "title": "Florence: A New Foundation Model for Computer Vision",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2021,
            "externalIds": {
                "ArXiv": "2111.11432",
                "DBLP": "journals/corr/abs-2111-11432",
                "CorpusId": 244477674
            },
            "abstract": "Automated visual understanding of our diverse and open world demands computer vision models to generalize well with minimal customization for specific tasks, similar to human vision. Computer vision foundation models, which are trained on diverse, large-scale dataset and can be adapted to a wide range of downstream tasks, are critical for this mission to solve real-world computer vision applications. While existing vision foundation models such as CLIP, ALIGN, and Wu Dao 2.0 focus mainly on mapping images and textual representations to a cross-modal shared representation, we introduce a new computer vision foundation model, Florence, to expand the representations from coarse (scene) to fine (object), from static (images) to dynamic (videos), and from RGB to multiple modalities (caption, depth). By incorporating universal visual-language representations from Web-scale image-text data, our Florence model can be easily adapted for various computer vision tasks, such as classification, retrieval, object detection, VQA, image caption, video retrieval and action recognition. Moreover, Florence demonstrates outstanding performance in many types of transfer learning: fully sampled fine-tuning, linear probing, few-shot transfer and zero-shot transfer for novel images and objects. All of these properties are critical for our vision foundation model to serve general purpose vision tasks. Florence achieves new state-of-the-art results in majority of 44 representative benchmarks, e.g., ImageNet-1K zero-shot classification with top-1 accuracy of 83.74 and the top-5 accuracy of 97.18, 62.4 mAP on COCO fine tuning, 80.36 on VQA, and 87.8 on Kinetics-600.",
            "referenceCount": 87,
            "citationCount": 511,
            "influentialCitationCount": 42,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-11-22",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2111.11432"
            },
            "citationStyles": {
                "bibtex": "@Article{Yuan2021FlorenceAN,\n author = {Lu Yuan and Dongdong Chen and Yi-Ling Chen and N. Codella and Xiyang Dai and Jianfeng Gao and Houdong Hu and Xuedong Huang and Boxin Li and Chunyuan Li and Ce Liu and Mengchen Liu and Zicheng Liu and Yumao Lu and Yu Shi and Lijuan Wang and Jianfeng Wang and Bin Xiao and Zhen Xiao and Jianwei Yang and Michael Zeng and Luowei Zhou and Pengchuan Zhang},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Florence: A New Foundation Model for Computer Vision},\n volume = {abs/2111.11432},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ca011427853d34ce4ec9ccafde8a70c9eacc3e21",
            "@type": "ScholarlyArticle",
            "paperId": "ca011427853d34ce4ec9ccafde8a70c9eacc3e21",
            "corpusId": 3557281,
            "url": "https://www.semanticscholar.org/paper/ca011427853d34ce4ec9ccafde8a70c9eacc3e21",
            "title": "Deep Learning for Computer Vision: A Brief Review",
            "venue": "Computational Intelligence and Neuroscience",
            "publicationVenue": {
                "id": "urn:research:f32b7322-b69c-4e63-801d-8f50784ef778",
                "name": "Computational Intelligence and Neuroscience",
                "alternate_names": [
                    "Comput Intell Neurosci"
                ],
                "issn": "1687-5265",
                "url": "https://www.hindawi.com/journals/cin/"
            },
            "year": 2018,
            "externalIds": {
                "PubMedCentral": "5816885",
                "DBLP": "journals/cin/VoulodimosDDP18",
                "MAG": "2794284562",
                "DOI": "10.1155/2018/7068349",
                "CorpusId": 3557281,
                "PubMed": "29487619"
            },
            "abstract": "Over the last years deep learning methods have been shown to outperform previous state-of-the-art machine learning techniques in several fields, with computer vision being one of the most prominent cases. This review paper provides a brief overview of some of the most significant deep learning schemes used in computer vision problems, that is, Convolutional Neural Networks, Deep Boltzmann Machines and Deep Belief Networks, and Stacked Denoising Autoencoders. A brief account of their history, structure, advantages, and limitations is given, followed by a description of their applications in various computer vision tasks, such as object detection, face recognition, action and activity recognition, and human pose estimation. Finally, a brief overview is given of future directions in designing deep learning schemes for computer vision problems and the challenges involved therein.",
            "referenceCount": 115,
            "citationCount": 2020,
            "influentialCitationCount": 29,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://downloads.hindawi.com/journals/cin/2018/7068349.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2018-02-01",
            "journal": {
                "name": "Computational Intelligence and Neuroscience",
                "volume": "2018"
            },
            "citationStyles": {
                "bibtex": "@Article{Voulodimos2018DeepLF,\n author = {A. Voulodimos and N. Doulamis and A. Doulamis and Eftychios E. Protopapadakis},\n booktitle = {Computational Intelligence and Neuroscience},\n journal = {Computational Intelligence and Neuroscience},\n title = {Deep Learning for Computer Vision: A Brief Review},\n volume = {2018},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c8b25fab5608c3e033d34b4483ec47e68ba109b7",
            "@type": "ScholarlyArticle",
            "paperId": "c8b25fab5608c3e033d34b4483ec47e68ba109b7",
            "corpusId": 232352874,
            "url": "https://www.semanticscholar.org/paper/c8b25fab5608c3e033d34b4483ec47e68ba109b7",
            "title": "Swin Transformer: Hierarchical Vision Transformer using Shifted Windows",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2021,
            "externalIds": {
                "ArXiv": "2103.14030",
                "DBLP": "conf/iccv/LiuL00W0LG21",
                "DOI": "10.1109/ICCV48922.2021.00986",
                "CorpusId": 232352874
            },
            "abstract": "This paper presents a new vision Transformer, called Swin Transformer, that capably serves as a general-purpose backbone for computer vision. Challenges in adapting Transformer from language to vision arise from differences between the two domains, such as large variations in the scale of visual entities and the high resolution of pixels in images compared to words in text. To address these differences, we propose a hierarchical Transformer whose representation is computed with Shifted windows. The shifted windowing scheme brings greater efficiency by limiting self-attention computation to non-overlapping local windows while also allowing for cross-window connection. This hierarchical architecture has the flexibility to model at various scales and has linear computational complexity with respect to image size. These qualities of Swin Transformer make it compatible with a broad range of vision tasks, including image classification (87.3 top-1 accuracy on ImageNet-1K) and dense prediction tasks such as object detection (58.7 box AP and 51.1 mask AP on COCO test-dev) and semantic segmentation (53.5 mIoU on ADE20K val). Its performance surpasses the previous state-of-the-art by a large margin of +2.7 box AP and +2.6 mask AP on COCO, and +3.2 mIoU on ADE20K, demonstrating the potential of Transformer-based models as vision backbones. The hierarchical design and the shifted window approach also prove beneficial for all-MLP architectures. The code and models are publicly available at https://github.com/microsoft/Swin-Transformer.",
            "referenceCount": 85,
            "citationCount": 9661,
            "influentialCitationCount": 2076,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2103.14030",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": null,
            "journal": {
                "name": "2021 IEEE/CVF International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Liu2021SwinTH,\n author = {Ze Liu and Yutong Lin and Yue Cao and Han Hu and Yixuan Wei and Zheng Zhang and Stephen Lin and B. Guo},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},\n pages = {9992-10002},\n title = {Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:45f686be3b96302ede327645227134e1c304dbab",
            "@type": "ScholarlyArticle",
            "paperId": "45f686be3b96302ede327645227134e1c304dbab",
            "corpusId": 244117862,
            "url": "https://www.semanticscholar.org/paper/45f686be3b96302ede327645227134e1c304dbab",
            "title": "Attention mechanisms in computer vision: A survey",
            "venue": "Computational Visual Media",
            "publicationVenue": {
                "id": "urn:research:d2dfc02a-9028-4345-b6cf-556b76ac435b",
                "name": "Computational Visual Media",
                "alternate_names": [
                    "Comput Vis Media"
                ],
                "issn": "2096-0433",
                "url": "http://www.springer.com/41095"
            },
            "year": 2021,
            "externalIds": {
                "ArXiv": "2111.07624",
                "DBLP": "journals/cvm/GuoXLLJMZMCH22",
                "DOI": "10.1007/s41095-022-0271-y",
                "CorpusId": 244117862
            },
            "abstract": null,
            "referenceCount": 198,
            "citationCount": 644,
            "influentialCitationCount": 13,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/s41095-022-0271-y.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2021-11-15",
            "journal": {
                "name": "Computational Visual Media",
                "volume": "8"
            },
            "citationStyles": {
                "bibtex": "@Article{Guo2021AttentionMI,\n author = {Meng-Hao Guo and Tianhan Xu and Jiangjiang Liu and Zheng-Ning Liu and Peng-Tao Jiang and Tai-Jiang Mu and Song-Hai Zhang and Ralph Robert Martin and Ming-Ming Cheng and Shimin Hu},\n booktitle = {Computational Visual Media},\n journal = {Computational Visual Media},\n pages = {331 - 368},\n title = {Attention mechanisms in computer vision: A survey},\n volume = {8},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c3df199cbca74763c4ae9889409bbd4aa29b6255",
            "@type": "ScholarlyArticle",
            "paperId": "c3df199cbca74763c4ae9889409bbd4aa29b6255",
            "corpusId": 231202901,
            "url": "https://www.semanticscholar.org/paper/c3df199cbca74763c4ae9889409bbd4aa29b6255",
            "title": "Deep learning-enabled medical computer vision",
            "venue": "npj Digital Medicine",
            "publicationVenue": {
                "id": "urn:research:ef485645-f75f-4344-8b9d-3c260e69503b",
                "name": "npj Digital Medicine",
                "alternate_names": [
                    "npj Digit Med"
                ],
                "issn": "2398-6352",
                "url": "http://www.nature.com/npjdigitalmed/"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "journals/npjdm/EstevaCYNMM0TDS21",
                "PubMedCentral": "7794558",
                "DOI": "10.1038/s41746-020-00376-2",
                "CorpusId": 231202901,
                "PubMed": "33420381"
            },
            "abstract": null,
            "referenceCount": 170,
            "citationCount": 416,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s41746-020-00376-2.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2021-01-08",
            "journal": {
                "name": "NPJ Digital Medicine",
                "volume": "4"
            },
            "citationStyles": {
                "bibtex": "@Article{Esteva2021DeepLM,\n author = {A. Esteva and Katherine Chou and Serena Yeung and N. Naik and Ali Madani and A. Mottaghi and Yun Liu and E. Topol and J. Dean and R. Socher},\n booktitle = {npj Digital Medicine},\n journal = {NPJ Digital Medicine},\n title = {Deep learning-enabled medical computer vision},\n volume = {4},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:327109fdbc6291c231dc4a7c3c2515e77202f894",
            "@type": "ScholarlyArticle",
            "paperId": "327109fdbc6291c231dc4a7c3c2515e77202f894",
            "corpusId": 242826183,
            "url": "https://www.semanticscholar.org/paper/327109fdbc6291c231dc4a7c3c2515e77202f894",
            "title": "CNN Variants for Computer Vision: History, Architecture, Application, Challenges and Future Scope",
            "venue": "Electronics",
            "publicationVenue": {
                "id": "urn:research:ccd8e532-73c6-414f-bc91-271bbb2933e2",
                "name": "Electronics",
                "alternate_names": null,
                "issn": "1450-5843",
                "url": "http://www.electronics.etfbl.net/"
            },
            "year": 2021,
            "externalIds": {
                "DOI": "10.3390/electronics10202470",
                "CorpusId": 242826183
            },
            "abstract": "Computer vision is becoming an increasingly trendy word in the area of image processing. With the emergence of computer vision applications, there is a significant demand to recognize objects automatically. Deep CNN (convolution neural network) has benefited the computer vision community by producing excellent results in video processing, object recognition, picture classification and segmentation, natural language processing, speech recognition, and many other fields. Furthermore, the introduction of large amounts of data and readily available hardware has opened new avenues for CNN study. Several inspirational concepts for the progress of CNN have been investigated, including alternative activation functions, regularization, parameter optimization, and architectural advances. Furthermore, achieving innovations in architecture results in a tremendous enhancement in the capacity of the deep CNN. Significant emphasis has been given to leveraging channel and spatial information, with a depth of architecture and information processing via multi-path. This survey paper focuses mainly on the primary taxonomy and newly released deep CNN architectures, and it divides numerous recent developments in CNN architectures into eight groups. Spatial exploitation, multi-path, depth, breadth, dimension, channel boosting, feature-map exploitation, and attention-based CNN are the eight categories. The main contribution of this manuscript is in comparing various architectural evolutions in CNN by its architectural change, strengths, and weaknesses. Besides, it also includes an explanation of the CNN\u2019s components, the strengths and weaknesses of various CNN variants, research gap or open challenges, CNN applications, and the future research direction.",
            "referenceCount": 70,
            "citationCount": 186,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.mdpi.com/2079-9292/10/20/2470/pdf?version=1633955851",
                "status": "GOLD"
            },
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2021-10-11",
            "journal": {
                "name": "Electronics",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bhatt2021CNNVF,\n author = {Dulari Bhatt and C. Patel and Hardik N. Talsania and Jigar A. Patel and Rasmika Vaghela and Sharnil Pandya and Kirit J. Modi and H. Ghayvat},\n booktitle = {Electronics},\n journal = {Electronics},\n title = {CNN Variants for Computer Vision: History, Architecture, Application, Challenges and Future Scope},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4282a344671189e17c9c9e00e329fe2d0fa71769",
            "@type": "ScholarlyArticle",
            "paperId": "4282a344671189e17c9c9e00e329fe2d0fa71769",
            "corpusId": 27350524,
            "url": "https://www.semanticscholar.org/paper/4282a344671189e17c9c9e00e329fe2d0fa71769",
            "title": "Computer Vision - Algorithms and Applications",
            "venue": "Texts in Computer Science",
            "publicationVenue": {
                "id": "urn:research:1dce04f1-655b-4db9-a1ae-f9595ff4d6dc",
                "name": "Texts in Computer Science",
                "alternate_names": [
                    "Text Comput Sci"
                ],
                "issn": "1868-0941",
                "url": null
            },
            "year": 2011,
            "externalIds": {
                "DBLP": "series/txcs/Szeliski11",
                "CorpusId": 27350524
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 4410,
            "influentialCitationCount": 291,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Szeliski2011ComputerV,\n author = {R. Szeliski},\n booktitle = {Texts in Computer Science},\n pages = {i-xx, 1-812},\n title = {Computer Vision - Algorithms and Applications},\n year = {2011}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c44e8d07cf606bfcef2576e6dc2b1e05b0e63408",
            "@type": "ScholarlyArticle",
            "paperId": "c44e8d07cf606bfcef2576e6dc2b1e05b0e63408",
            "corpusId": 64682463,
            "url": "https://www.semanticscholar.org/paper/c44e8d07cf606bfcef2576e6dc2b1e05b0e63408",
            "title": "Fruits and vegetables quality evaluation using computer vision: A review",
            "venue": "Journal of King Saud University: Computer and Information Sciences",
            "publicationVenue": {
                "id": "urn:research:5d2ac1a1-1fcd-4505-8b9d-5484ad5ffa66",
                "name": "Journal of King Saud University: Computer and Information Sciences",
                "alternate_names": [
                    "Journal of King Saud University - Computer and Information Sciences",
                    "J King Saud Univ Comput Inf Sci",
                    "J King Saud Univ  Comput Inf Sci"
                ],
                "issn": "1319-1578",
                "url": "https://www.journals.elsevier.com/journal-of-king-saud-university-computer-and-information-sciences/"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "journals/jksucis/BhargavaB21",
                "MAG": "2807383083",
                "DOI": "10.1016/J.JKSUCI.2018.06.002",
                "CorpusId": 64682463
            },
            "abstract": null,
            "referenceCount": 168,
            "citationCount": 287,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Agricultural and Food Sciences",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2021-03-01",
            "journal": {
                "name": "J. King Saud Univ. Comput. Inf. Sci.",
                "volume": "33"
            },
            "citationStyles": {
                "bibtex": "@Article{Bhargava2021FruitsAV,\n author = {Anuja Bhargava and A. Bansal},\n booktitle = {Journal of King Saud University: Computer and Information Sciences},\n journal = {J. King Saud Univ. Comput. Inf. Sci.},\n pages = {243-257},\n title = {Fruits and vegetables quality evaluation using computer vision: A review},\n volume = {33},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b514949ad8344071c0f342f182390d2d88bcc26d",
            "@type": "ScholarlyArticle",
            "paperId": "b514949ad8344071c0f342f182390d2d88bcc26d",
            "corpusId": 3536399,
            "url": "https://www.semanticscholar.org/paper/b514949ad8344071c0f342f182390d2d88bcc26d",
            "title": "Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey",
            "venue": "IEEE Access",
            "publicationVenue": {
                "id": "urn:research:2633f5b2-c15c-49fe-80f5-07523e770c26",
                "name": "IEEE Access",
                "alternate_names": null,
                "issn": "2169-3536",
                "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2951179338",
                "DBLP": "journals/corr/abs-1801-00553",
                "ArXiv": "1801.00553",
                "DOI": "10.1109/ACCESS.2018.2807385",
                "CorpusId": 3536399
            },
            "abstract": "Deep learning is at the heart of the current rise of artificial intelligence. In the field of computer vision, it has become the workhorse for applications ranging from self-driving cars to surveillance and security. Whereas, deep neural networks have demonstrated phenomenal success (often beyond human capabilities) in solving complex problems, recent studies show that they are vulnerable to adversarial attacks in the form of subtle perturbations to inputs that lead a model to predict incorrect outputs. For images, such perturbations are often too small to be perceptible, yet they completely fool the deep learning models. Adversarial attacks pose a serious threat to the success of deep learning in practice. This fact has recently led to a large influx of contributions in this direction. This paper presents the first comprehensive survey on adversarial attacks on deep learning in computer vision. We review the works that design adversarial attacks, analyze the existence of such attacks and propose defenses against them. To emphasize that adversarial attacks are possible in practical conditions, we separately review the contributions that evaluate adversarial attacks in the real-world scenarios. Finally, drawing on the reviewed literature, we provide a broader outlook of this research direction.",
            "referenceCount": 205,
            "citationCount": 1572,
            "influentialCitationCount": 63,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-01-02",
            "journal": {
                "name": "IEEE Access",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Akhtar2018ThreatOA,\n author = {Naveed Akhtar and A. Mian},\n booktitle = {IEEE Access},\n journal = {IEEE Access},\n pages = {14410-14430},\n title = {Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey},\n volume = {6},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7cc3414b8c0791f1d5e8f82ee65cb99a7a876774",
            "@type": "ScholarlyArticle",
            "paperId": "7cc3414b8c0791f1d5e8f82ee65cb99a7a876774",
            "corpusId": 236965639,
            "url": "https://www.semanticscholar.org/paper/7cc3414b8c0791f1d5e8f82ee65cb99a7a876774",
            "title": "Do Datasets Have Politics? Disciplinary Values in Computer Vision Dataset Development",
            "venue": "Proc. ACM Hum. Comput. Interact.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "journals/pacmhci/ScheuermanHD21",
                "ArXiv": "2108.04308",
                "DOI": "10.1145/3476058",
                "CorpusId": 236965639
            },
            "abstract": "Data is a crucial component of machine learning. The field is reliant on data to train, validate, and test models. With increased technical capabilities, machine learning research has boomed in both academic and industry settings, and one major focus has been on computer vision. Computer vision is a popular domain of machine learning increasingly pertinent to real-world applications, from facial recognition in policing to object detection for autonomous vehicles. Given computer vision's propensity to shape machine learning research and impact human life, we seek to understand disciplinary practices around dataset documentation - how data is collected, curated, annotated, and packaged into datasets for computer vision researchers and practitioners to use for model tuning and development. Specifically, we examine what dataset documentation communicates about the underlying values of vision data and the larger practices and goals of computer vision as a field. To conduct this study, we collected a corpus of about 500 computer vision datasets, from which we sampled 114 dataset publications across different vision tasks. Through both a structured and thematic content analysis, we document a number of values around accepted data practices, what makes desirable data, and the treatment of humans in the dataset construction process. We discuss how computer vision datasets authors value efficiency at the expense of care; universality at the expense of contextuality; impartiality at the expense of positionality; and model work at the expense of data work. Many of the silenced values we identify sit in opposition with social computing practices. We conclude with suggestions on how to better incorporate silenced values into the dataset creation and curation process.",
            "referenceCount": 134,
            "citationCount": 123,
            "influentialCitationCount": 8,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/3476058",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Sociology",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Political Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-08-09",
            "journal": {
                "name": "Proceedings of the ACM on Human-Computer Interaction",
                "volume": "5"
            },
            "citationStyles": {
                "bibtex": "@Article{Scheuerman2021DoDH,\n author = {M. Scheuerman and Emily L. Denton and A. Hanna},\n booktitle = {Proc. ACM Hum. Comput. Interact.},\n journal = {Proceedings of the ACM on Human-Computer Interaction},\n pages = {1 - 37},\n title = {Do Datasets Have Politics? Disciplinary Values in Computer Vision Dataset Development},\n volume = {5},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1a0829a7bef8ea3ecb33b55871b4498dd328ff68",
            "@type": "ScholarlyArticle",
            "paperId": "1a0829a7bef8ea3ecb33b55871b4498dd328ff68",
            "corpusId": 237396325,
            "url": "https://www.semanticscholar.org/paper/1a0829a7bef8ea3ecb33b55871b4498dd328ff68",
            "title": "Advances in adversarial attacks and defenses in computer vision: A survey",
            "venue": "IEEE Access",
            "publicationVenue": {
                "id": "urn:research:2633f5b2-c15c-49fe-80f5-07523e770c26",
                "name": "IEEE Access",
                "alternate_names": null,
                "issn": "2169-3536",
                "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "journals/access/AkhtarMKS21",
                "ArXiv": "2108.00401",
                "DOI": "10.1109/ACCESS.2021.3127960",
                "CorpusId": 237396325
            },
            "abstract": "Deep Learning is the most widely used tool in the contemporary field of computer vision. Its ability to accurately solve complex problems is employed in vision research to learn deep neural models for a variety of tasks, including security critical applications. However, it is now known that deep learning is vulnerable to adversarial attacks that can manipulate its predictions by introducing visually imperceptible perturbations in images and videos. Since the discovery of this phenomenon in 2013, it has attracted significant attention of researchers from multiple sub-fields of machine intelligence. In 2018, we published the first-ever review of the contributions made by the computer vision community in adversarial attacks on deep learning (and their defenses). Many of those contributions have inspired new directions in this area, which has matured significantly since witnessing the first generation methods. Hence, as a legacy sequel of our first literature survey, this review article focuses on the advances in this area since 2018. We thoroughly discuss the first generation attacks and comprehensively cover the modern attacks and their defenses appearing in the prestigious sources of computer vision and machine learning research. Besides offering the most comprehensive literature review of adversarial attacks and defenses to date, the article also provides concise definitions of technical terminologies for the non-experts. Finally, it discusses challenges and future outlook of this direction based on the literature since the advent of this research direction.",
            "referenceCount": 461,
            "citationCount": 123,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2021-08-01",
            "journal": {
                "name": "IEEE Access",
                "volume": "PP"
            },
            "citationStyles": {
                "bibtex": "@Article{Akhtar2021AdvancesIA,\n author = {Naveed Akhtar and A. Mian and Navid Kardan and M. Shah},\n booktitle = {IEEE Access},\n journal = {IEEE Access},\n pages = {1-1},\n title = {Advances in adversarial attacks and defenses in computer vision: A survey},\n volume = {PP},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4ec9edd7b2e3eb9b93ed131e1753bd403e2354f8",
            "@type": "ScholarlyArticle",
            "paperId": "4ec9edd7b2e3eb9b93ed131e1753bd403e2354f8",
            "corpusId": 233465455,
            "url": "https://www.semanticscholar.org/paper/4ec9edd7b2e3eb9b93ed131e1753bd403e2354f8",
            "title": "Tensor Methods in Computer Vision and Deep Learning",
            "venue": "Proceedings of the IEEE",
            "publicationVenue": {
                "id": "urn:research:6faaccca-1cc4-45a9-aeb6-96a4901d2606",
                "name": "Proceedings of the IEEE",
                "alternate_names": [
                    "Proc IEEE"
                ],
                "issn": "0018-9219",
                "url": "http://www.ieee.org/portal/pages/pubs/proceedings/"
            },
            "year": 2021,
            "externalIds": {
                "ArXiv": "2107.03436",
                "MAG": "3182136581",
                "DBLP": "journals/corr/abs-2107-03436",
                "DOI": "10.1109/JPROC.2021.3074329",
                "CorpusId": 233465455
            },
            "abstract": "Tensors, or multidimensional arrays, are data structures that can naturally represent visual data of multiple dimensions. Inherently able to efficiently capture structured, latent semantic spaces and high-order interactions, tensors have a long history of applications in a wide span of computer vision problems. With the advent of the deep learning paradigm shift in computer vision, tensors have become even more fundamental. Indeed, essential ingredients in modern deep learning architectures, such as convolutions and attention mechanisms, can readily be considered as tensor mappings. In effect, tensor methods are increasingly finding significant applications in deep learning, including the design of memory and compute efficient network architectures, improving robustness to random noise and adversarial attacks, and aiding the theoretical understanding of deep networks. This article provides an in-depth and practical review of tensors and tensor methods in the context of representation learning and deep learning, with a particular focus on visual data analysis and computer vision applications. Concretely, besides fundamental work in tensor-based visual data analysis methods, we focus on recent developments that have brought on a gradual increase in tensor methods, especially in deep learning architectures and their implications in computer vision applications. To further enable the newcomer to grasp such concepts quickly, we provide companion Python notebooks, covering key aspects of this article and implementing them, step-by-step with TensorLy.",
            "referenceCount": 235,
            "citationCount": 70,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://arxiv.org/pdf/2107.03436",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2021-05-01",
            "journal": {
                "name": "Proceedings of the IEEE",
                "volume": "109"
            },
            "citationStyles": {
                "bibtex": "@Article{Panagakis2021TensorMI,\n author = {Yannis Panagakis and Jean Kossaifi and Grigorios G. Chrysos and James Oldfield and M. Nicolaou and Anima Anandkumar and S. Zafeiriou},\n booktitle = {Proceedings of the IEEE},\n journal = {Proceedings of the IEEE},\n pages = {863-890},\n title = {Tensor Methods in Computer Vision and Deep Learning},\n volume = {109},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2a9b33f66ccc3806af58bdab2319559f4f9d2c5e",
            "@type": "ScholarlyArticle",
            "paperId": "2a9b33f66ccc3806af58bdab2319559f4f9d2c5e",
            "corpusId": 235410640,
            "url": "https://www.semanticscholar.org/paper/2a9b33f66ccc3806af58bdab2319559f4f9d2c5e",
            "title": "A survey on deep multimodal learning for computer vision: advances, trends, applications, and datasets",
            "venue": "The Visual Computer",
            "publicationVenue": {
                "id": "urn:research:9a037417-d032-481a-bb54-de987ec2138b",
                "name": "The Visual Computer",
                "alternate_names": [
                    "Vis Comput"
                ],
                "issn": "0178-2789",
                "url": "https://link.springer.com/journal/371"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "journals/vc/BayoudhKHM22",
                "PubMedCentral": "8192112",
                "DOI": "10.1007/s00371-021-02166-7",
                "CorpusId": 235410640,
                "PubMed": "34131356"
            },
            "abstract": null,
            "referenceCount": 245,
            "citationCount": 118,
            "influentialCitationCount": 1,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/s00371-021-02166-7.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2021-06-10",
            "journal": {
                "name": "The Visual Computer",
                "volume": "38"
            },
            "citationStyles": {
                "bibtex": "@Article{Bayoudh2021ASO,\n author = {Khaled Bayoudh and Raja Knani and F. Hamdaoui and A. Mtibaa},\n booktitle = {The Visual Computer},\n journal = {The Visual Computer},\n pages = {2939 - 2970},\n title = {A survey on deep multimodal learning for computer vision: advances, trends, applications, and datasets},\n volume = {38},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:89e5e7665e3b8bf9bf675400fa31d23300d62ea5",
            "@type": "ScholarlyArticle",
            "paperId": "89e5e7665e3b8bf9bf675400fa31d23300d62ea5",
            "corpusId": 232269674,
            "url": "https://www.semanticscholar.org/paper/89e5e7665e3b8bf9bf675400fa31d23300d62ea5",
            "title": "Learning to Resize Images for Computer Vision Tasks",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2021,
            "externalIds": {
                "ArXiv": "2103.09950",
                "DBLP": "conf/iccv/TalebiM21",
                "DOI": "10.1109/ICCV48922.2021.00055",
                "CorpusId": 232269674
            },
            "abstract": "For all the ways convolutional neural nets have revolutionized computer vision in recent years, one important aspect has received surprisingly little attention: the effect of image size on the accuracy of tasks being trained for. Typically, to be efficient, the input images are resized to a relatively small spatial resolution (e.g. 224 \u00d7 224), and both training and inference are carried out at this resolution. The actual mechanism for this re-scaling has been an afterthought: Namely, off-the-shelf image re sizers such as bilinear and bicubic are commonly used in most machine learning software frameworks. But do these re sizers limit the on-task performance of the trained networks? The answer is yes. Indeed, we show that the typical linear re sizer can be replaced with learned resizers that can substantially improve performance. Importantly, while the classical re-sizers typically result in better perceptual quality of the downscaled images, our proposed learned resizers do not necessarily give better visual quality, but instead improve task performance.Our learned image resizer is jointly trained with a base-line vision model. This learned CNN-based resizer creates machine friendly visual manipulations that lead to a consistent improvement of the end task metric over the baseline model. Specifically, here we focus on the classification task with the ImageNet dataset [26], and experiment with four different models to learn resizers adapted to each model. Moreover, we show that the proposed resizer can also be useful for fine-tuning the classification baselines for other vision tasks. To this end, we experiment with three different baselines to develop image quality assessment (IQA) models on the AVA dataset [24].",
            "referenceCount": 46,
            "citationCount": 63,
            "influentialCitationCount": 5,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2103.09950",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2021-03-17",
            "journal": {
                "name": "2021 IEEE/CVF International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Talebi2021LearningTR,\n author = {Hossein Talebi and P. Milanfar},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},\n pages = {487-496},\n title = {Learning to Resize Images for Computer Vision Tasks},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8fe44af15f0e31c090c0dde4b606e91360a6fb74",
            "@type": "ScholarlyArticle",
            "paperId": "8fe44af15f0e31c090c0dde4b606e91360a6fb74",
            "corpusId": 237303796,
            "url": "https://www.semanticscholar.org/paper/8fe44af15f0e31c090c0dde4b606e91360a6fb74",
            "title": "Deep reinforcement learning in computer vision: a comprehensive survey",
            "venue": "Artificial Intelligence Review",
            "publicationVenue": {
                "id": "urn:research:ea8553fe-2467-4367-afee-c4deb3754820",
                "name": "Artificial Intelligence Review",
                "alternate_names": [
                    "Artif Intell Rev"
                ],
                "issn": "0269-2821",
                "url": "https://link.springer.com/journal/10462"
            },
            "year": 2021,
            "externalIds": {
                "ArXiv": "2108.11510",
                "DBLP": "journals/corr/abs-2108-11510",
                "DOI": "10.1007/s10462-021-10061-9",
                "CorpusId": 237303796
            },
            "abstract": null,
            "referenceCount": 140,
            "citationCount": 77,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2108.11510",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2021-08-25",
            "journal": {
                "name": "Artificial Intelligence Review",
                "volume": "55"
            },
            "citationStyles": {
                "bibtex": "@Article{Le2021DeepRL,\n author = {Ngan T. H. Le and V. Rathour and Kashu Yamazaki and Khoa Luu and M. Savvides},\n booktitle = {Artificial Intelligence Review},\n journal = {Artificial Intelligence Review},\n pages = {2733 - 2819},\n title = {Deep reinforcement learning in computer vision: a comprehensive survey},\n volume = {55},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:934d7bffdba0b560a80a518b99a791a16b3e198c",
            "@type": "ScholarlyArticle",
            "paperId": "934d7bffdba0b560a80a518b99a791a16b3e198c",
            "corpusId": 195317007,
            "url": "https://www.semanticscholar.org/paper/934d7bffdba0b560a80a518b99a791a16b3e198c",
            "title": "A Fourier Perspective on Model Robustness in Computer Vision",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2971028215",
                "DBLP": "conf/nips/YinLSCG19",
                "ArXiv": "1906.08988",
                "CorpusId": 195317007
            },
            "abstract": "Achieving robustness to distributional shift is a longstanding and challenging goal of computer vision. Data augmentation is a commonly used approach for improving robustness, however robustness gains are typically not uniform across corruption types. Indeed increasing performance in the presence of random noise is often met with reduced performance on other corruptions such as contrast change. Understanding when and why these sorts of trade-offs occur is a crucial step towards mitigating them. Towards this end, we investigate recently observed trade-offs caused by Gaussian data augmentation and adversarial training. We find that both methods improve robustness to corruptions that are concentrated in the high frequency domain while reducing robustness to corruptions that are concentrated in the low frequency domain. This suggests that one way to mitigate these trade-offs via data augmentation is to use a more diverse set of augmentations. Towards this end we observe that AutoAugment, a recently proposed data augmentation policy optimized for clean accuracy, achieves state-of-the-art robustness on the CIFAR-10-C benchmark.",
            "referenceCount": 27,
            "citationCount": 351,
            "influentialCitationCount": 42,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-06-21",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Yin2019AFP,\n author = {Dong Yin and Raphael Gontijo Lopes and Jonathon Shlens and E. D. Cubuk and J. Gilmer},\n booktitle = {Neural Information Processing Systems},\n pages = {13255-13265},\n title = {A Fourier Perspective on Model Robustness in Computer Vision},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:787827850b614135f6b432603afc90b58a8cc665",
            "@type": "ScholarlyArticle",
            "paperId": "787827850b614135f6b432603afc90b58a8cc665",
            "corpusId": 53924538,
            "url": "https://www.semanticscholar.org/paper/787827850b614135f6b432603afc90b58a8cc665",
            "title": "Computer Vision: A Modern Approach",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2002,
            "externalIds": {
                "MAG": "2594702178",
                "CorpusId": 53924538
            },
            "abstract": "From the Publisher: \nThe accessible presentation of this book gives both a general view of the entire computer vision enterprise and also offers sufficient detail to be able to build useful applications. Users learn techniques that have proven to be useful by first-hand experience and a wide range of mathematical methods. A CD-ROM with every copy of the text contains source code for programming practice, color images, and illustrative movies. Comprehensive and up-to-date, this book includes essential topics that either reflect practical significance or are of theoretical importance. Topics are discussed in substantial and increasing depth. Application surveys describe numerous important application areas such as image based rendering and digital libraries. Many important algorithms broken down and illustrated in pseudo code. Appropriate for use by engineers as a comprehensive reference to the computer vision enterprise.",
            "referenceCount": 0,
            "citationCount": 4337,
            "influentialCitationCount": 243,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2002-08-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Forsyth2002ComputerVA,\n author = {D. Forsyth and J. Ponce},\n title = {Computer Vision: A Modern Approach},\n year = {2002}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b8cb9c0b02da96a9908665ae67692a6da4dd25a4",
            "@type": "ScholarlyArticle",
            "paperId": "b8cb9c0b02da96a9908665ae67692a6da4dd25a4",
            "corpusId": 239616056,
            "url": "https://www.semanticscholar.org/paper/b8cb9c0b02da96a9908665ae67692a6da4dd25a4",
            "title": "SCENIC: A JAX Library for Computer Vision Research and Beyond",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "journals/corr/abs-2110-11403",
                "ArXiv": "2110.11403",
                "DOI": "10.1109/CVPR52688.2022.02070",
                "CorpusId": 239616056
            },
            "abstract": "Scenic is an open-source11https://github.com/google-research/scenic JAX library with a focus on transformer-based models for computer vision research and beyond. The goal of this toolkit is to facilitate rapid experimentation, prototyping, and research of new architectures and models. Scenic supports a diverse range of tasks (e.g., classification, segmentation, detection) and facilitates working on multi-modal problems, along with GPU/TPU support for large-scale, multi-host and multi-device training. Scenic also offers optimized implementations of state-of-the-art research models spanning a wide range of modalities. Scenic has been successfully used for numerous projects and published papers and continues serving as the library of choice for rapid prototyping and publication of new research ideas.",
            "referenceCount": 30,
            "citationCount": 49,
            "influentialCitationCount": 0,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2110.11403",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2021-10-18",
            "journal": {
                "name": "2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Dehghani2021SCENICAJ,\n author = {Mostafa Dehghani and A. Gritsenko and Anurag Arnab and Matthias Minderer and Yi Tay},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {21361-21366},\n title = {SCENIC: A JAX Library for Computer Vision Research and Beyond},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c920b70c96cee7f96957679190453c6758bed0e4",
            "@type": "ScholarlyArticle",
            "paperId": "c920b70c96cee7f96957679190453c6758bed0e4",
            "corpusId": 9201140,
            "url": "https://www.semanticscholar.org/paper/c920b70c96cee7f96957679190453c6758bed0e4",
            "title": "Introduction to computer vision",
            "venue": "Optics and Artificial Vision",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2021,
            "externalIds": {
                "MAG": "3203892326",
                "DOI": "10.1088/978-0-7503-3707-6ch2",
                "CorpusId": 9201140
            },
            "abstract": "NOTE: THIS IS A DRAFT DOCUMENT",
            "referenceCount": 24,
            "citationCount": 83,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Physics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2021-09-01",
            "journal": {
                "name": "Optics and Artificial Vision",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gonz\u00e1lez-Acu\u00f1a2021IntroductionTC,\n author = {Rafael G. Gonz\u00e1lez-Acu\u00f1a and H\u00e9ctor A. Chaparro-Romo and I. Melendez-Montoya},\n booktitle = {Optics and Artificial Vision},\n journal = {Optics and Artificial Vision},\n title = {Introduction to computer vision},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:d720a95e1501922ea17ee31f299f43b2db5e15ef",
            "@type": "ScholarlyArticle",
            "paperId": "d720a95e1501922ea17ee31f299f43b2db5e15ef",
            "corpusId": 1458265,
            "url": "https://www.semanticscholar.org/paper/d720a95e1501922ea17ee31f299f43b2db5e15ef",
            "title": "Vlfeat: an open and portable library of computer vision algorithms",
            "venue": "ACM Multimedia",
            "publicationVenue": {
                "id": "urn:research:f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                "name": "ACM Multimedia",
                "alternate_names": [
                    "MM"
                ],
                "issn": null,
                "url": null
            },
            "year": 2010,
            "externalIds": {
                "DBLP": "conf/mm/VedaldiF10",
                "MAG": "2066941820",
                "DOI": "10.1145/1873951.1874249",
                "CorpusId": 1458265
            },
            "abstract": "VLFeat is an open and portable library of computer vision algorithms. It aims at facilitating fast prototyping and reproducible research for computer vision scientists and students. It includes rigorous implementations of common building blocks such as feature detectors, feature extractors, (hierarchical) k-means clustering, randomized kd-tree matching, and super-pixelization. The source code and interfaces are fully documented. The library integrates directly with MATLAB, a popular language for computer vision research.",
            "referenceCount": 16,
            "citationCount": 3491,
            "influentialCitationCount": 211,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle"
            ],
            "publicationDate": "2010-10-25",
            "journal": {
                "name": "Proceedings of the 18th ACM international conference on Multimedia",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Vedaldi2010VlfeatAO,\n author = {A. Vedaldi and B. Fulkerson},\n booktitle = {ACM Multimedia},\n journal = {Proceedings of the 18th ACM international conference on Multimedia},\n title = {Vlfeat: an open and portable library of computer vision algorithms},\n year = {2010}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a23fbf6e7c224e696662b948163cb27e52188356",
            "@type": "ScholarlyArticle",
            "paperId": "a23fbf6e7c224e696662b948163cb27e52188356",
            "corpusId": 115151433,
            "url": "https://www.semanticscholar.org/paper/a23fbf6e7c224e696662b948163cb27e52188356",
            "title": "Events-To-Video: Bringing Modern Computer Vision to Event Cameras",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2938463073",
                "ArXiv": "1904.08298",
                "DBLP": "conf/cvpr/RebecqRKS19",
                "DOI": "10.1109/CVPR.2019.00398",
                "CorpusId": 115151433
            },
            "abstract": "Event cameras are novel sensors that report brightness changes in the form of asynchronous \"events\" instead of intensity frames. They have significant advantages over conventional cameras: high temporal resolution, high dynamic range, and no motion blur. Since the output of event cameras is fundamentally different from conventional cameras, it is commonly accepted that they require the development of specialized algorithms to accommodate the particular nature of events. In this work, we take a different view and propose to apply existing, mature computer vision techniques to videos reconstructed from event data. We propose a novel, recurrent neural network to reconstruct videos from a stream of events and train it on a large amount of simulated event data. Our experiments show that our approach surpasses state-of-the-art reconstruction methods by a large margin (> 20%) in terms of image quality. We further apply off-the-shelf computer vision algorithms to videos reconstructed from event data on tasks such as object classification and visual-inertial odometry, and show that this strategy consistently outperforms algorithms that were specifically designed for event data. We believe that our approach opens the door to bringing the outstanding properties of event cameras to an entirely new range of tasks.",
            "referenceCount": 60,
            "citationCount": 254,
            "influentialCitationCount": 50,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.zora.uzh.ch/id/eprint/197731/1/CVPR19_Rebecq.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-04-17",
            "journal": {
                "name": "2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Rebecq2019EventsToVideoBM,\n author = {Henri Rebecq and Ren\u00e9 Ranftl and V. Koltun and D. Scaramuzza},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {3852-3861},\n title = {Events-To-Video: Bringing Modern Computer Vision to Event Cameras},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:03ea251b802fd46fe45483d40f01238a4ac9f4f7",
            "@type": "ScholarlyArticle",
            "paperId": "03ea251b802fd46fe45483d40f01238a4ac9f4f7",
            "corpusId": 219531480,
            "url": "https://www.semanticscholar.org/paper/03ea251b802fd46fe45483d40f01238a4ac9f4f7",
            "title": "Visual Transformers: Token-based Image Representation and Processing for Computer Vision",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3033210410",
                "ArXiv": "2006.03677",
                "DBLP": "journals/corr/abs-2006-03677",
                "CorpusId": 219531480
            },
            "abstract": "Computer vision has achieved great success using standardized image representations -- pixel arrays, and the corresponding deep learning operators -- convolutions. In this work, we challenge this paradigm: we instead (a) represent images as a set of visual tokens and (b) apply visual transformers to find relationships between visual semantic concepts. Given an input image, we dynamically extract a set of visual tokens from the image to obtain a compact representation for high-level semantics. We then use visual transformers to operate over the visual tokens to densely model relationships between them. We find that this paradigm of token-based image representation and processing drastically outperforms its convolutional counterparts on image classification and semantic segmentation. To demonstrate the power of this approach on ImageNet classification, we use ResNet as a convenient baseline and use visual transformers to replace the last stage of convolutions. This reduces the stage's MACs by up to 6.9x, while attaining up to 4.53 points higher top-1 accuracy. For semantic segmentation, we use a visual-transformer-based FPN (VT-FPN) module to replace a convolution-based FPN, saving 6.5x fewer MACs while achieving up to 0.35 points higher mIoU on LIP and COCO-stuff.",
            "referenceCount": 49,
            "citationCount": 331,
            "influentialCitationCount": 17,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-06-05",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2006.03677"
            },
            "citationStyles": {
                "bibtex": "@Article{Wu2020VisualTT,\n author = {Bichen Wu and Chenfeng Xu and Xiaoliang Dai and Alvin Wan and Peizhao Zhang and M. Tomizuka and K. Keutzer and P\u00e9ter Vajda},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Visual Transformers: Token-based Image Representation and Processing for Computer Vision},\n volume = {abs/2006.03677},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:08cc923c0386cdc92630bcc3cb00a337a0d91212",
            "@type": "ScholarlyArticle",
            "paperId": "08cc923c0386cdc92630bcc3cb00a337a0d91212",
            "corpusId": 225627479,
            "url": "https://www.semanticscholar.org/paper/08cc923c0386cdc92630bcc3cb00a337a0d91212",
            "title": "A review of computer vision\u2013based structural health monitoring at local and global levels",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3044248863",
                "DOI": "10.1177/1475921720935585",
                "CorpusId": 225627479
            },
            "abstract": "Structural health monitoring at local and global levels using computer vision technologies has gained much attention in the structural health monitoring community in research and practice. Due to the computer vision technology application advantages such as non-contact, long distance, rapid, low cost and labor, and low interference to the daily operation of structures, it is promising to consider computer vision\u2013structural health monitoring as a complement to the conventional structural health monitoring. This article presents a general overview of the concepts, approaches, and real-life practice of computer vision\u2013structural health monitoring along with some relevant literature that is rapidly accumulating. The computer vision\u2013structural health monitoring covered in this article at local level includes applications such as crack, spalling, delamination, rust, and loose bolt detection. At the global level, applications include displacement measurement, structural behavior analysis, vibration serviceability, modal identification, model updating, damage detection, cable force monitoring, load factor estimation, and structural identification using input\u2013output information. The current research studies and applications of computer vision\u2013structural health monitoring mainly focus on the implementation and integration of two-dimensional computer vision techniques to solve structural health monitoring problems and the projective geometry methods implemented are utilized to convert the three-dimensional problems into two-dimensional problems. This review mainly puts emphasis on two-dimensional computer vision\u2013structural health monitoring applications. Subsequently, a brief review of representative developments of three-dimensional computer vision in the area of civil engineering is presented along with the challenges and opportunities of two-dimensional and three-dimensional computer vision\u2013structural health monitoring. Finally, the article presents a forward look to the future of computer vision\u2013structural health monitoring.",
            "referenceCount": 236,
            "citationCount": 269,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2020-07-20",
            "journal": {
                "name": "Structural Health Monitoring",
                "volume": "20"
            },
            "citationStyles": {
                "bibtex": "@Article{Dong2020ARO,\n author = {C. Dong and N. Catbas},\n journal = {Structural Health Monitoring},\n pages = {692 - 743},\n title = {A review of computer vision\u2013based structural health monitoring at local and global levels},\n volume = {20},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b4efbd4e0885d8a2e98acb5a23acbc134e08e8d1",
            "@type": "ScholarlyArticle",
            "paperId": "b4efbd4e0885d8a2e98acb5a23acbc134e08e8d1",
            "corpusId": 221356266,
            "url": "https://www.semanticscholar.org/paper/b4efbd4e0885d8a2e98acb5a23acbc134e08e8d1",
            "title": "Hand Gesture Recognition Based on Computer Vision: A Review of Techniques",
            "venue": "Journal of Imaging",
            "publicationVenue": {
                "id": "urn:research:c0fc53c7-b0ed-487d-9191-1262c8322621",
                "name": "Journal of Imaging",
                "alternate_names": [
                    "J Imaging"
                ],
                "issn": "2313-433X",
                "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-556372"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/jimaging/OudahAC20",
                "MAG": "3044285175",
                "PubMedCentral": "8321080",
                "DOI": "10.3390/jimaging6080073",
                "CorpusId": 221356266,
                "PubMed": "34460688"
            },
            "abstract": "Hand gestures are a form of nonverbal communication that can be used in several fields such as communication between deaf-mute people, robot control, human\u2013computer interaction (HCI), home automation and medical applications. Research papers based on hand gestures have adopted many different techniques, including those based on instrumented sensor technology and computer vision. In other words, the hand sign can be classified under many headings, such as posture and gesture, as well as dynamic and static, or a hybrid of the two. This paper focuses on a review of the literature on hand gesture techniques and introduces their merits and limitations under different circumstances. In addition, it tabulates the performance of these methods, focusing on computer vision techniques that deal with the similarity and difference points, technique of hand segmentation used, classification algorithms and drawbacks, number and types of gestures, dataset used, detection range (distance) and type of camera used. This paper is a thorough general overview of hand gesture methods with a brief discussion of some possible applications.",
            "referenceCount": 106,
            "citationCount": 219,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.mdpi.com/2313-433X/6/8/73/pdf?version=1595503383",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2020-07-23",
            "journal": {
                "name": "Journal of Imaging",
                "volume": "6"
            },
            "citationStyles": {
                "bibtex": "@Article{Oudah2020HandGR,\n author = {M. Oudah and A. Al-Naji and J. Chahl},\n booktitle = {Journal of Imaging},\n journal = {Journal of Imaging},\n title = {Hand Gesture Recognition Based on Computer Vision: A Review of Techniques},\n volume = {6},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6351ebb4a3287f5f3e1273464b3b91e5df5a16d7",
            "@type": "ScholarlyArticle",
            "paperId": "6351ebb4a3287f5f3e1273464b3b91e5df5a16d7",
            "corpusId": 243985980,
            "url": "https://www.semanticscholar.org/paper/6351ebb4a3287f5f3e1273464b3b91e5df5a16d7",
            "title": "Masked Autoencoders Are Scalable Vision Learners",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "journals/corr/abs-2111-06377",
                "ArXiv": "2111.06377",
                "DOI": "10.1109/CVPR52688.2022.01553",
                "CorpusId": 243985980
            },
            "abstract": "This paper shows that masked autoencoders (MAE) are scalable self-supervised learners for computer vision. Our MAE approach is simple: we mask random patches of the input image and reconstruct the missing pixels. It is based on two core designs. First, we develop an asymmetric encoder-decoder architecture, with an encoder that operates only on the visible subset of patches (without mask tokens), along with a lightweight decoder that reconstructs the original image from the latent representation and mask tokens. Second, we find that masking a high proportion of the input image, e.g., 75%, yields a nontrivial and meaningful self-supervisory task. Coupling these two designs enables us to train large models efficiently and effectively: we accelerate training (by 3\u00d7 or more) and improve accuracy. Our scalable approach allows for learning high-capacity models that generalize well: e.g., a vanilla ViT-Huge model achieves the best accuracy (87.8%) among methods that use only ImageNet-1K data. Transfer performance in downstream tasks outperforms supervised pretraining and shows promising scaling behavior.",
            "referenceCount": 71,
            "citationCount": 3293,
            "influentialCitationCount": 862,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2111.06377",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2021-11-11",
            "journal": {
                "name": "2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{He2021MaskedAA,\n author = {Kaiming He and Xinlei Chen and Saining Xie and Yanghao Li and Piotr Doll'ar and Ross B. Girshick},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {15979-15988},\n title = {Masked Autoencoders Are Scalable Vision Learners},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:f2d32b9a81b78dbbccfa1616c019bbc32b2a8efb",
            "@type": "ScholarlyArticle",
            "paperId": "f2d32b9a81b78dbbccfa1616c019bbc32b2a8efb",
            "corpusId": 220265500,
            "url": "https://www.semanticscholar.org/paper/f2d32b9a81b78dbbccfa1616c019bbc32b2a8efb",
            "title": "Large image datasets: A pyrrhic win for computer vision?",
            "venue": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
            "publicationVenue": {
                "id": "urn:research:acd15a6d-3248-41fb-8439-9a40aabe5608",
                "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                "alternate_names": [
                    "Workshop on Applications of Computer Vision",
                    "WACV",
                    "IEEE Work Conf Appl Comput Vis",
                    "Workshop Appl Comput Vis"
                ],
                "issn": null,
                "url": "http://www.wikicfp.com/cfp/program?id=2993"
            },
            "year": 2020,
            "externalIds": {
                "ArXiv": "2006.16923",
                "DBLP": "journals/corr/abs-2006-16923",
                "MAG": "3040589425",
                "DOI": "10.1109/WACV48630.2021.00158",
                "CorpusId": 220265500
            },
            "abstract": "In this paper we investigate problematic practices and consequences of large scale vision datasets (LSVDs). We examine broad issues such as the question of consent and justice as well as specific concerns such as the inclusion of verifiably pornographic images in datasets. Taking the ImageNet-ILSVRC-2012 dataset as an example, we perform a cross-sectional model-based quantitative census covering factors such as age, gender, NSFW content scoring, class- wise accuracy, human-cardinality-analysis, and the semanticity of the image class information in order to statistically investigate the extent and subtleties of ethical transgressions. We then use the census to help hand-curate a look-up-table of images in the ImageNet-ILSVRC-2012 dataset that fall into the categories of verifiably pornographic: shot in a non-consensual setting (up-skirt), beach voyeuristic, and exposed private parts. We survey the landscape of harm and threats both the society at large and individuals face due to uncritical and ill-considered dataset curation practices. We then propose possible courses of correction and critique their pros and cons. We have duly open-sourced all of the code and the census meta-datasets generated in this endeavor for the computer vision community to build on. By unveiling the severity of the threats, our hope is to motivate the constitution of mandatory Institutional Review Boards (IRB) for large scale dataset curation.",
            "referenceCount": 116,
            "citationCount": 250,
            "influentialCitationCount": 17,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2006.16923",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Sociology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference",
                "Review"
            ],
            "publicationDate": "2020-06-24",
            "journal": {
                "name": "2021 IEEE Winter Conference on Applications of Computer Vision (WACV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Prabhu2020LargeID,\n author = {Vinay Uday Prabhu and A. Birhane},\n booktitle = {IEEE Workshop/Winter Conference on Applications of Computer Vision},\n journal = {2021 IEEE Winter Conference on Applications of Computer Vision (WACV)},\n pages = {1536-1546},\n title = {Large image datasets: A pyrrhic win for computer vision?},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8ea2ee7127fd03229a3e42a4092438d812f109b5",
            "@type": "ScholarlyArticle",
            "paperId": "8ea2ee7127fd03229a3e42a4092438d812f109b5",
            "corpusId": 204167355,
            "url": "https://www.semanticscholar.org/paper/8ea2ee7127fd03229a3e42a4092438d812f109b5",
            "title": "Computer vision technology in agricultural automation \u2014A review",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2020,
            "externalIds": {
                "MAG": "2976292222",
                "DOI": "10.1016/j.inpa.2019.09.006",
                "CorpusId": 204167355
            },
            "abstract": null,
            "referenceCount": 110,
            "citationCount": 272,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Agricultural and Food Sciences",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2020-03-01",
            "journal": {
                "name": "Information Processing in Agriculture",
                "volume": "7"
            },
            "citationStyles": {
                "bibtex": "@Article{Tian2020ComputerVT,\n author = {Hongkun Tian and Tianhai Wang and Yadong Liu and Xi Qiao and Yanzhou Li},\n journal = {Information Processing in Agriculture},\n pages = {1-19},\n title = {Computer vision technology in agricultural automation \u2014A review},\n volume = {7},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a88ef706316946d6862adcd15254bfe6537b149c",
            "@type": "ScholarlyArticle",
            "paperId": "a88ef706316946d6862adcd15254bfe6537b149c",
            "corpusId": 246788511,
            "url": "https://www.semanticscholar.org/paper/a88ef706316946d6862adcd15254bfe6537b149c",
            "title": "Computer Vision",
            "venue": "Advanced Sensing in Image Processing and IoT",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2022,
            "externalIds": {
                "DOI": "10.1201/9781003221333-2",
                "CorpusId": 246788511
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 0,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2022-02-11",
            "journal": {
                "name": "Advanced Sensing in Image Processing and IoT",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gupta2022ComputerV,\n author = {Shalini Gupta},\n booktitle = {Advanced Sensing in Image Processing and IoT},\n journal = {Advanced Sensing in Image Processing and IoT},\n title = {Computer Vision},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:71d0204f78bc86f4bf4dbefd21731f022ad9e66d",
            "@type": "ScholarlyArticle",
            "paperId": "71d0204f78bc86f4bf4dbefd21731f022ad9e66d",
            "corpusId": 226352879,
            "url": "https://www.semanticscholar.org/paper/71d0204f78bc86f4bf4dbefd21731f022ad9e66d",
            "title": "Computer Vision Techniques in Construction: A Critical Review",
            "venue": "Archives of Computational Methods in Engineering",
            "publicationVenue": {
                "id": "urn:research:f9c1272f-e8c2-4e8c-bdae-fc9c2bb2cb85",
                "name": "Archives of Computational Methods in Engineering",
                "alternate_names": [
                    "Arch Comput Method Eng"
                ],
                "issn": "1134-3060",
                "url": "http://www.cimne.com/arcme/"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3094418071",
                "DOI": "10.1007/s11831-020-09504-3",
                "CorpusId": 226352879
            },
            "abstract": null,
            "referenceCount": 130,
            "citationCount": 167,
            "influentialCitationCount": 3,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2020-10-19",
            "journal": {
                "name": "Archives of Computational Methods in Engineering",
                "volume": "28"
            },
            "citationStyles": {
                "bibtex": "@Article{Xu2020ComputerVT,\n author = {Shuyuan Xu and Jun Wang and W. Shou and T. Ngo and Abdul-Manan Sadick and Xiangyu Wang},\n booktitle = {Archives of Computational Methods in Engineering},\n journal = {Archives of Computational Methods in Engineering},\n pages = {3383 - 3397},\n title = {Computer Vision Techniques in Construction: A Critical Review},\n volume = {28},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4fd9bc4c8622ffdb8ee44444173472561bd660df",
            "@type": "ScholarlyArticle",
            "paperId": "4fd9bc4c8622ffdb8ee44444173472561bd660df",
            "corpusId": 220367009,
            "url": "https://www.semanticscholar.org/paper/4fd9bc4c8622ffdb8ee44444173472561bd660df",
            "title": "Deep learning and computer vision will transform entomology",
            "venue": "Proceedings of the National Academy of Sciences of the United States of America",
            "publicationVenue": {
                "id": "urn:research:bb95bf2e-8383-4748-bf9d-d6906d091085",
                "name": "Proceedings of the National Academy of Sciences of the United States of America",
                "alternate_names": [
                    "PNAS",
                    "PNAS online",
                    "Proceedings of the National Academy of Sciences of the United States of America.",
                    "Proc National Acad Sci",
                    "Proceedings of the National Academy of Sciences",
                    "Proc National Acad Sci u s Am"
                ],
                "issn": "0027-8424",
                "url": "https://www.jstor.org/journal/procnatiacadscie"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3039538651",
                "DOI": "10.1101/2020.07.03.187252",
                "CorpusId": 220367009,
                "PubMed": "33431561"
            },
            "abstract": "Most animal species on Earth are insects, and recent reports suggest that their abundance is in drastic decline. Although these reports come from a wide range of insect taxa and regions, the evidence to assess the extent of the phenomenon is sparse. Insect populations are challenging to study, and most monitoring methods are labor intensive and inefficient. Advances in computer vision and deep learning provide potential new solutions to this global challenge. Cameras and other sensors can effectively, continuously, and noninvasively perform entomological observations throughout diurnal and seasonal cycles. The physical appearance of specimens can also be captured by automated imaging in the laboratory. When trained on these data, deep learning models can provide estimates of insect abundance, biomass, and diversity. Further, deep learning models can quantify variation in phenotypic traits, behavior, and interactions. Here, we connect recent developments in deep learning and computer vision to the urgent demand for more cost-efficient monitoring of insects and other invertebrates. We present examples of sensor-based monitoring of insects. We show how deep learning tools can be applied to exceptionally large datasets to derive ecological information and discuss the challenges that lie ahead for the implementation of such solutions in entomology. We identify four focal areas, which will facilitate this transformation: 1) validation of image-based taxonomic identification; 2) generation of sufficient training data; 3) development of public, curated reference databases; and 4) solutions to integrate deep learning and molecular tools.",
            "referenceCount": 144,
            "citationCount": 173,
            "influentialCitationCount": 4,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-07-04",
            "journal": {
                "name": "Proceedings of the National Academy of Sciences",
                "volume": "118"
            },
            "citationStyles": {
                "bibtex": "@Article{H\u00f8ye2020DeepLA,\n author = {T. H\u00f8ye and J. \u00c4rje and Kim Bjerge and O. L. P. Hansen and Alexandros Iosifidis and F. Leese and Hjalte M. R. Mann and Kristian Meissner and C. Melvad and Jenni Raitoharju},\n booktitle = {Proceedings of the National Academy of Sciences of the United States of America},\n journal = {Proceedings of the National Academy of Sciences},\n title = {Deep learning and computer vision will transform entomology},\n volume = {118},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0dce2bd4c7641f3df5846842ae45e10787d2272a",
            "@type": "ScholarlyArticle",
            "paperId": "0dce2bd4c7641f3df5846842ae45e10787d2272a",
            "corpusId": 243421597,
            "url": "https://www.semanticscholar.org/paper/0dce2bd4c7641f3df5846842ae45e10787d2272a",
            "title": "Feature Extraction and Image Processing for Computer Vision",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2020,
            "externalIds": {
                "DOI": "10.1016/c2017-0-02153-5",
                "CorpusId": 243421597
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 185,
            "influentialCitationCount": 12,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{None,\n title = {Feature Extraction and Image Processing for Computer Vision},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:92e4ef5575f3f22f3f22526cd1fdfd2d0397d094",
            "@type": "ScholarlyArticle",
            "paperId": "92e4ef5575f3f22f3f22526cd1fdfd2d0397d094",
            "corpusId": 150135520,
            "url": "https://www.semanticscholar.org/paper/92e4ef5575f3f22f3f22526cd1fdfd2d0397d094",
            "title": "Deep Learning vs. Traditional Computer Vision",
            "venue": "Computer Vision Conference",
            "publicationVenue": {
                "id": "urn:research:06c2d80a-20e3-4f49-b53f-456ddc67db0b",
                "name": "Computer Vision Conference",
                "alternate_names": [
                    "CVC",
                    "Comput Vis Conf"
                ],
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "conf/cvc/MahonyCCHVKRW19",
                "MAG": "2982580633",
                "ArXiv": "1910.13796",
                "DOI": "10.1007/978-3-030-17795-9",
                "CorpusId": 150135520
            },
            "abstract": null,
            "referenceCount": 67,
            "citationCount": 636,
            "influentialCitationCount": 14,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/bfm:978-3-030-17795-9/1?pdf=chapter%20toc",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-04-24",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1910.13796"
            },
            "citationStyles": {
                "bibtex": "@Article{Mahony2019DeepLV,\n author = {Niall O' Mahony and S. Campbell and A. Carvalho and Suman Harapanahalli and G. Velasco-Hern\u00e1ndez and L. Krpalkova and D. Riordan and Joseph Walsh},\n booktitle = {Computer Vision Conference},\n journal = {ArXiv},\n title = {Deep Learning vs. Traditional Computer Vision},\n volume = {abs/1910.13796},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:45db7f95f7eb60f480b659b6203f992235f0397f",
            "@type": "ScholarlyArticle",
            "paperId": "45db7f95f7eb60f480b659b6203f992235f0397f",
            "corpusId": 214728128,
            "url": "https://www.semanticscholar.org/paper/45db7f95f7eb60f480b659b6203f992235f0397f",
            "title": "Fashion Meets Computer Vision",
            "venue": "ACM Computing Surveys",
            "publicationVenue": {
                "id": "urn:research:7b2adce0-d53f-49d6-8784-b0645604fe62",
                "name": "ACM Computing Surveys",
                "alternate_names": [
                    "ACM Comput Surv"
                ],
                "issn": "0360-0300",
                "url": "http://www.acm.org/pubs/surveys/"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/corr/abs-2003-13988",
                "MAG": "3015093447",
                "ArXiv": "2003.13988",
                "DOI": "10.1145/3447239",
                "CorpusId": 214728128
            },
            "abstract": "Fashion is the way we present ourselves to the world and has become one of the world\u2019s largest industries. Fashion, mainly conveyed by vision, has thus attracted much attention from computer vision researchers in recent years. Given the rapid development, this article provides a comprehensive survey of more than 200 major fashion-related works covering four main aspects for enabling intelligent fashion: (1) Fashion detection includes landmark detection, fashion parsing, and item retrieval; (2) Fashion analysis contains attribute recognition, style learning, and popularity prediction; (3) Fashion synthesis involves style transfer, pose transformation, and physical simulation; and (4) Fashion recommendation comprises fashion compatibility, outfit matching, and hairstyle suggestion. For each task, the benchmark datasets and the evaluation protocols are summarized. Furthermore, we highlight promising directions for future research.",
            "referenceCount": 235,
            "citationCount": 94,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/3447239",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Art",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-03-31",
            "journal": {
                "name": "ACM Computing Surveys (CSUR)",
                "volume": "54"
            },
            "citationStyles": {
                "bibtex": "@Article{Cheng2020FashionMC,\n author = {Wen-Huang Cheng and Sijie Song and Chieh-Yun Chen and S. Hidayati and Jiaying Liu},\n booktitle = {ACM Computing Surveys},\n journal = {ACM Computing Surveys (CSUR)},\n pages = {1 - 41},\n title = {Fashion Meets Computer Vision},\n volume = {54},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7cdbc51293f7d7ed78ec84a1cfbf84b1bad5a852",
            "@type": "ScholarlyArticle",
            "paperId": "7cdbc51293f7d7ed78ec84a1cfbf84b1bad5a852",
            "corpusId": 215827741,
            "url": "https://www.semanticscholar.org/paper/7cdbc51293f7d7ed78ec84a1cfbf84b1bad5a852",
            "title": "Computer Vision for COVID-19 Control: A Survey",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2020,
            "externalIds": {
                "ArXiv": "2004.09420",
                "MAG": "3017364285",
                "DBLP": "journals/corr/abs-2004-09420",
                "DOI": "10.31224/osf.io/yt9sx",
                "CorpusId": 215827741
            },
            "abstract": "The COVID-19 pandemic has triggered an urgent need to contribute to the fight against an immense threat to the human population. Computer Vision, as a subfield of Artificial Intelligence, has enjoyed recent success in solvingvarious complex problems in health care and has the potential to contribute to the fight of controlling COVID-19. In response to this call, computer vision researchers are putting their knowledge base at work to devise effective ways to counter COVID-19 challenge and serve the global community. New contributions are being shared with everypassing day. It motivated us to review the recent work, collect information about available research resources and an indication of future research directions. We want to make it available to computer vision researchers to save precious time. This survey paper is intended to provide a preliminary review of the available literature on the computer vision efforts against COVID-19 pandemic.",
            "referenceCount": 96,
            "citationCount": 84,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://engrxiv.org/preprint/download/931/2026",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-04-15",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/2004.09420"
            },
            "citationStyles": {
                "bibtex": "@Article{Ulhaq2020ComputerVF,\n author = {A. Ulhaq and Asim Khan and D. Gomes and M. Paul},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Computer Vision for COVID-19 Control: A Survey},\n volume = {abs/2004.09420},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6e4e75c88a0801c87f47a171aa69a9914f9129bf",
            "@type": "ScholarlyArticle",
            "paperId": "6e4e75c88a0801c87f47a171aa69a9914f9129bf",
            "corpusId": 174802368,
            "url": "https://www.semanticscholar.org/paper/6e4e75c88a0801c87f47a171aa69a9914f9129bf",
            "title": "MNIST-C: A Robustness Benchmark for Computer Vision",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1906.02337",
                "DBLP": "journals/corr/abs-1906-02337",
                "MAG": "2948140748",
                "CorpusId": 174802368
            },
            "abstract": "We introduce the MNIST-C dataset, a comprehensive suite of 15 corruptions applied to the MNIST test set, for benchmarking out-of-distribution robustness in computer vision. Through several experiments and visualizations we demonstrate that our corruptions significantly degrade performance of state-of-the-art computer vision models while preserving the semantic content of the test images. In contrast to the popular notion of adversarial robustness, our model-agnostic corruptions do not seek worst-case performance but are instead designed to be broad and diverse, capturing multiple failure modes of modern models. In fact, we find that several previously published adversarial defenses significantly degrade robustness as measured by MNIST-C. We hope that our benchmark serves as a useful tool for future work in designing systems that are able to learn robust feature representations that capture the underlying semantics of the input.",
            "referenceCount": 21,
            "citationCount": 157,
            "influentialCitationCount": 35,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2019-06-05",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1906.02337"
            },
            "citationStyles": {
                "bibtex": "@Article{Mu2019MNISTCAR,\n author = {Norman Mu and J. Gilmer},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {MNIST-C: A Robustness Benchmark for Computer Vision},\n volume = {abs/1906.02337},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2673354bc246e65962a6dca32d5f41cc8f11a249",
            "@type": "ScholarlyArticle",
            "paperId": "2673354bc246e65962a6dca32d5f41cc8f11a249",
            "corpusId": 213072261,
            "url": "https://www.semanticscholar.org/paper/2673354bc246e65962a6dca32d5f41cc8f11a249",
            "title": "Generative Adversarial Networks in Computer Vision",
            "venue": "ACM Computing Surveys",
            "publicationVenue": {
                "id": "urn:research:7b2adce0-d53f-49d6-8784-b0645604fe62",
                "name": "ACM Computing Surveys",
                "alternate_names": [
                    "ACM Comput Surv"
                ],
                "issn": "0360-0300",
                "url": "http://www.acm.org/pubs/surveys/"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/csur/WangSW21",
                "MAG": "3004056434",
                "DOI": "10.1145/3439723",
                "CorpusId": 213072261
            },
            "abstract": "Generative adversarial networks (GANs) have been extensively studied in the past few years. Arguably their most significant impact has been in the area of computer vision where great advances have been made in challenges such as plausible image generation, image-to-image translation, facial attribute manipulation, and similar domains. Despite the significant successes achieved to date, applying GANs to real-world problems still poses significant challenges, three of which we focus on here. These are as follows: (1) the generation of high quality images, (2) diversity of image generation, and (3) stabilizing training. Focusing on the degree to which popular GAN technologies have made progress against these challenges, we provide a detailed review of the state-of-the-art in GAN-related research in the published scientific literature. We further structure this review through a convenient taxonomy we have adopted based on variations in GAN architectures and loss functions. While several reviews for GANs have been presented to date, none have considered the status of this field based on their progress toward addressing practical challenges relevant to computer vision. Accordingly, we review and critically discuss the most popular architecture-variant, and loss-variant GANs, for tackling these challenges. Our objective is to provide an overview as well as a critical analysis of the status of GAN research in terms of relevant progress toward critical computer vision application requirements. As we do this we also discuss the most compelling applications in computer vision in which GANs have demonstrated considerable success along with some suggestions for future research directions. Codes related to the GAN-variants studied in this work is summarized on https://github.com/sheqi/GAN_Review.",
            "referenceCount": 167,
            "citationCount": 264,
            "influentialCitationCount": 11,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://dl.acm.org/doi/pdf/10.1145/3439723",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-06-04",
            "journal": {
                "name": "ACM Computing Surveys (CSUR)",
                "volume": "54"
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2019GenerativeAN,\n author = {Zhengwei Wang and Qi She and T. Ward},\n booktitle = {ACM Computing Surveys},\n journal = {ACM Computing Surveys (CSUR)},\n pages = {1 - 38},\n title = {Generative Adversarial Networks in Computer Vision},\n volume = {54},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c7d6f073d89f31e6584450713013c1fd85138090",
            "@type": "ScholarlyArticle",
            "paperId": "c7d6f073d89f31e6584450713013c1fd85138090",
            "corpusId": 52095792,
            "url": "https://www.semanticscholar.org/paper/c7d6f073d89f31e6584450713013c1fd85138090",
            "title": "A Guide to Convolutional Neural Networks for Computer Vision",
            "venue": "A Guide to Convolutional Neural Networks for Computer Vision",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "series/synthesis/2018Khan",
                "MAG": "2795061970",
                "DOI": "10.2200/S00822ED1V01Y201712COV015",
                "CorpusId": 52095792
            },
            "abstract": "Computer vision has become increasingly important and effective in recent years due to its wide-ranging applications in areas as diverse as smart surveillance and monitoring, health and medicine, sports and recreation, robotics, drones, and self-driving cars. Visual recognition tasks, such as image classification, localization, and detection, are the core building blocks of many of these applications, and recent developments in Convolutional Neural Networks (CNNs) have led to outstanding performance in these state-of-the-art visual recognition tasks and systems. As a result, CNNs now form the crux of deep learning algorithms in computer vision. This self-contained guide will benefit those who seek to both understand the theory behind CNNs and to gain hands-on experience on the application of CNNs in computer vision. It provides a comprehensive introduction to CNNs starting with the essential concepts behind neural networks: training, regularization, and optimization of CNNs. The book also discusses a wide range of loss functions, network layers, and popular CNN architectures, reviews the different techniques for the evaluation of CNNs, and presents some popular CNN tools and libraries that are commonly used in computer vision. Further, this text describes and discusses case studies that are related to the application of CNN in computer vision, including image classification, object detection, semantic segmentation, scene understanding, and image generation. This book is ideal for undergraduate and graduate students, as no prior background knowledge in the field is required to follow the material, as well as new researchers, developers, engineers, and practitioners who are interested in gaining a quick understanding of CNN models.",
            "referenceCount": 85,
            "citationCount": 445,
            "influentialCitationCount": 30,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/bfm:978-3-031-01821-3/1?pdf=chapter%20toc",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2018-02-13",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Khan2018AGT,\n author = {Salman Hameed Khan and H. Rahmani and S. A. A. Shah and Bennamoun},\n booktitle = {A Guide to Convolutional Neural Networks for Computer Vision},\n title = {A Guide to Convolutional Neural Networks for Computer Vision},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:efd41c0bef1f1f5f25acd0f7b7caf73df1960d20",
            "@type": "ScholarlyArticle",
            "paperId": "efd41c0bef1f1f5f25acd0f7b7caf73df1960d20",
            "corpusId": 235224957,
            "url": "https://www.semanticscholar.org/paper/efd41c0bef1f1f5f25acd0f7b7caf73df1960d20",
            "title": "Application of Deep Convolutional Neural Network in Computer Vision",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2020,
            "externalIds": {
                "CorpusId": 235224957
            },
            "abstract": "With the rapid development of computer technology, computer vision brings a lot of convenience to people\u2019s lives, study and work. Because computer vision is a newly developed field, there are still many problems in computer vision research. For example, it is not perfect for image segmentation, target detection, and image classification. This paper addresses computer vision, mainly to improve image segmentation and target detection in computer vision. In this paper, deep convolutional neural networks are used, which must first be constructed. Then, both the loss function of the network and the gradient magnitude are calculated. Finally, the sharing mode of the network and the target detection based on the bidirectional feature pyramid, are examined. The results show that the image segmentation and target detection using the deep convolutional neural network can make the gradient amplitude of the filler sub-branches in the basic network significantly larger than the gradient amplitude of the instance segmentation network. The sharing mode can bring about a 70% improvement in performance. Furthermore, the target detection method based on the bidirectional feature pyramid extracts more information.",
            "referenceCount": 10,
            "citationCount": 70,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Chen2020ApplicationOD,\n author = {Lepeng Chen and Chengjiang Wang},\n title = {Application of Deep Convolutional Neural Network in Computer Vision},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cf1f166d3fe7a40117764c0c415055cf518e08e1",
            "@type": "ScholarlyArticle",
            "paperId": "cf1f166d3fe7a40117764c0c415055cf518e08e1",
            "corpusId": 222071022,
            "url": "https://www.semanticscholar.org/paper/cf1f166d3fe7a40117764c0c415055cf518e08e1",
            "title": "Computer vision in autism spectrum disorder research: a systematic review of published studies from 2009 to 2019",
            "venue": "Translational Psychiatry",
            "publicationVenue": {
                "id": "urn:research:18232e92-ef10-46fd-ad77-bb418dcd525d",
                "name": "Translational Psychiatry",
                "alternate_names": [
                    "Transl Psychiatry"
                ],
                "issn": "2158-3188",
                "url": "https://www.nature.com/tp/"
            },
            "year": 2020,
            "externalIds": {
                "PubMedCentral": "7528087",
                "MAG": "3091624500",
                "DOI": "10.1038/s41398-020-01015-w",
                "CorpusId": 222071022,
                "PubMed": "32999273"
            },
            "abstract": null,
            "referenceCount": 150,
            "citationCount": 71,
            "influentialCitationCount": 0,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.nature.com/articles/s41398-020-01015-w.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Psychology",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Psychology",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2020-09-30",
            "journal": {
                "name": "Translational Psychiatry",
                "volume": "10"
            },
            "citationStyles": {
                "bibtex": "@Article{Belen2020ComputerVI,\n author = {Ryan Anthony J. de Belen and T. Bednarz and A. Sowmya and Dennis Del Favero},\n booktitle = {Translational Psychiatry},\n journal = {Translational Psychiatry},\n title = {Computer vision in autism spectrum disorder research: a systematic review of published studies from 2009 to 2019},\n volume = {10},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2e0798922142020b2f3e0ad14bb570555babcc57",
            "@type": "ScholarlyArticle",
            "paperId": "2e0798922142020b2f3e0ad14bb570555babcc57",
            "corpusId": 242167001,
            "url": "https://www.semanticscholar.org/paper/2e0798922142020b2f3e0ad14bb570555babcc57",
            "title": "Computer Vision",
            "venue": "Vision",
            "publicationVenue": {
                "id": "urn:research:4144b5fb-0a80-4663-8ebf-80ca0c47231a",
                "name": "Vision",
                "alternate_names": [
                    "International Conference on Computer Vision",
                    "Int Conf Comput Vis",
                    "VISION"
                ],
                "issn": "0917-1142",
                "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-1000285"
            },
            "year": 2021,
            "externalIds": {
                "DOI": "10.1017/9781108946339.008",
                "CorpusId": 242167001
            },
            "abstract": null,
            "referenceCount": 110,
            "citationCount": 0,
            "influentialCitationCount": 0,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2021-08-26",
            "journal": {
                "name": "Vision",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Blake2021ComputerV,\n author = {Andrew Blake},\n booktitle = {Vision},\n journal = {Vision},\n title = {Computer Vision},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5bacdc39a2702e31739f65df40030215975cd597",
            "@type": "ScholarlyArticle",
            "paperId": "5bacdc39a2702e31739f65df40030215975cd597",
            "corpusId": 221714987,
            "url": "https://www.semanticscholar.org/paper/5bacdc39a2702e31739f65df40030215975cd597",
            "title": "A review of computer vision technologies for plant phenotyping",
            "venue": "Computers and Electronics in Agriculture",
            "publicationVenue": {
                "id": "urn:research:80fdf70e-8520-4bb7-b387-3abebc9970b7",
                "name": "Computers and Electronics in Agriculture",
                "alternate_names": [
                    "Comput Electron Agric"
                ],
                "issn": "0168-1699",
                "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/503304/description#description"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "journals/cea/LiGLCL20",
                "MAG": "3047532279",
                "DOI": "10.1016/j.compag.2020.105672",
                "CorpusId": 221714987
            },
            "abstract": null,
            "referenceCount": 187,
            "citationCount": 137,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Agricultural and Food Sciences",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2020-09-01",
            "journal": {
                "name": "Comput. Electron. Agric.",
                "volume": "176"
            },
            "citationStyles": {
                "bibtex": "@Article{Li2020ARO,\n author = {Zhenbo Li and Ruohao Guo and Meng Li and Yaru Chen and Guangyao Li},\n booktitle = {Computers and Electronics in Agriculture},\n journal = {Comput. Electron. Agric.},\n pages = {105672},\n title = {A review of computer vision technologies for plant phenotyping},\n volume = {176},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4d3b047f645c68fd7f4bacf189964d4b5356f691",
            "@type": "ScholarlyArticle",
            "paperId": "4d3b047f645c68fd7f4bacf189964d4b5356f691",
            "corpusId": 115528380,
            "url": "https://www.semanticscholar.org/paper/4d3b047f645c68fd7f4bacf189964d4b5356f691",
            "title": "Advances in Computer Vision-Based Civil Infrastructure Inspection and Monitoring",
            "venue": "Engineering",
            "publicationVenue": {
                "id": "urn:research:349a6ffc-3527-4d3d-aef4-8372fbc1a084",
                "name": "Engineering",
                "alternate_names": null,
                "issn": "1947-394X",
                "url": "https://www.scirp.org/journal/eng/"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2922073063",
                "DOI": "10.1016/J.ENG.2018.11.030",
                "CorpusId": 115528380
            },
            "abstract": null,
            "referenceCount": 238,
            "citationCount": 534,
            "influentialCitationCount": 11,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2019-05-08",
            "journal": {
                "name": "Engineering",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Spencer2019AdvancesIC,\n author = {B. Spencer and Vedhus Hoskere and Y. Narazaki},\n booktitle = {Engineering},\n journal = {Engineering},\n title = {Advances in Computer Vision-Based Civil Infrastructure Inspection and Monitoring},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:efe5beb88412a4dae12f04121e775695bd4f510e",
            "@type": "ScholarlyArticle",
            "paperId": "efe5beb88412a4dae12f04121e775695bd4f510e",
            "corpusId": 219161846,
            "url": "https://www.semanticscholar.org/paper/efe5beb88412a4dae12f04121e775695bd4f510e",
            "title": "Private-kNN: Practical Differential Privacy for Computer Vision",
            "venue": "Computer Vision and Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:768b87bb-8a18-4d9c-a161-4d483c776bcf",
                "name": "Computer Vision and Pattern Recognition",
                "alternate_names": [
                    "CVPR",
                    "Comput Vis Pattern Recognit"
                ],
                "issn": "1063-6919",
                "url": "https://ieeexplore.ieee.org/xpl/conhome.jsp?punumber=1000147"
            },
            "year": 2020,
            "externalIds": {
                "DBLP": "conf/cvpr/00050CW20",
                "MAG": "3035174002",
                "DOI": "10.1109/CVPR42600.2020.01187",
                "CorpusId": 219161846
            },
            "abstract": "With increasing ethical and legal concerns on privacy for deep models in visual recognition, differential privacy has emerged as a mechanism to disguise membership of sensitive data in training datasets. Recent methods like Private Aggregation of Teacher Ensembles (PATE) leverage a large ensemble of teacher models trained on disjoint subsets of private data, to transfer knowledge to a student model with privacy guarantees. However, labeled vision data is often expensive and datasets, when split into many disjoint training sets, lead to signi\u00ef\u00ac\u0081cantly sub-optimal accuracy and thus hardly sustain good privacy bounds. We propose a practically data-ef\u00ef\u00ac\u0081cient scheme based on private release of k-nearest neighbor (kNN) queries, which altogether avoids splitting the training dataset. Our approach allows the use of privacy-ampli\u00ef\u00ac\u0081cation by subsampling and iterative re\u00ef\u00ac\u0081nement of the kNN feature embedding. We rigorously analyze the theoretical properties of our method and demonstrate strong experimental performance on practical computer vision datasets for face attribute recognition and person reidenti\u00ef\u00ac\u0081cation. In particular, we achieve comparable or better accuracy than PATE while reducing more than 90% of the privacy loss, thereby providing the \u201cmost practical method to-date\u201d for private deep learning in computer vision.",
            "referenceCount": 33,
            "citationCount": 55,
            "influentialCitationCount": 4,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2020-06-01",
            "journal": {
                "name": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Zhu2020PrivatekNNPD,\n author = {Yuqing Zhu and Xiang Yu and Manmohan Chandraker and Yu-Xiang Wang},\n booktitle = {Computer Vision and Pattern Recognition},\n journal = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n pages = {11851-11859},\n title = {Private-kNN: Practical Differential Privacy for Computer Vision},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:520b28e4a03123b6081ff3b1d137c2b395842ac0",
            "@type": "ScholarlyArticle",
            "paperId": "520b28e4a03123b6081ff3b1d137c2b395842ac0",
            "corpusId": 227283686,
            "url": "https://www.semanticscholar.org/paper/520b28e4a03123b6081ff3b1d137c2b395842ac0",
            "title": "Computer vision in surgery.",
            "venue": "Surgery",
            "publicationVenue": {
                "id": "urn:research:25140240-c27e-483b-92d6-12f261d5a28d",
                "name": "Surgery",
                "alternate_names": null,
                "issn": "0039-6060",
                "url": "https://www.journals.elsevier.com/surgery/"
            },
            "year": 2020,
            "externalIds": {
                "MAG": "3110385255",
                "DOI": "10.1016/j.surg.2020.10.039",
                "CorpusId": 227283686,
                "PubMed": "33272610"
            },
            "abstract": null,
            "referenceCount": 35,
            "citationCount": 63,
            "influentialCitationCount": 1,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2020-11-30",
            "journal": {
                "name": "Surgery",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Ward2020ComputerVI,\n author = {Thomas M. Ward and P. Mascagni and Yutong Ban and G. Rosman and N. Padoy and O. Meireles and D. Hashimoto},\n booktitle = {Surgery},\n journal = {Surgery},\n title = {Computer vision in surgery.},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a0e2a71d42df8578cab7dc7e13a5c3068546a962",
            "@type": "ScholarlyArticle",
            "paperId": "a0e2a71d42df8578cab7dc7e13a5c3068546a962",
            "corpusId": 242648890,
            "url": "https://www.semanticscholar.org/paper/a0e2a71d42df8578cab7dc7e13a5c3068546a962",
            "title": "Computer Vision",
            "venue": "The Use of Applied Technology in Team Sport",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2021,
            "externalIds": {
                "DOI": "10.4324/9781003157007-21",
                "CorpusId": 242648890
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 0,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2021-07-16",
            "journal": {
                "name": "The Use of Applied Technology in Team Sport",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Baca2021ComputerV,\n author = {A. Baca},\n booktitle = {The Use of Applied Technology in Team Sport},\n journal = {The Use of Applied Technology in Team Sport},\n title = {Computer Vision},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:056eaaeec68420286a80c3f593b7711d5cc17ef6",
            "@type": "ScholarlyArticle",
            "paperId": "056eaaeec68420286a80c3f593b7711d5cc17ef6",
            "corpusId": 203836247,
            "url": "https://www.semanticscholar.org/paper/056eaaeec68420286a80c3f593b7711d5cc17ef6",
            "title": "Kornia: an Open Source Differentiable Computer Vision Library for PyTorch",
            "venue": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
            "publicationVenue": {
                "id": "urn:research:acd15a6d-3248-41fb-8439-9a40aabe5608",
                "name": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
                "alternate_names": [
                    "Workshop on Applications of Computer Vision",
                    "WACV",
                    "IEEE Work Conf Appl Comput Vis",
                    "Workshop Appl Comput Vis"
                ],
                "issn": null,
                "url": "http://www.wikicfp.com/cfp/program?id=2993"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "conf/wacv/RibaMPRB20",
                "ArXiv": "1910.02190",
                "MAG": "2978730776",
                "DOI": "10.1109/WACV45572.2020.9093363",
                "CorpusId": 203836247
            },
            "abstract": "This work presents Kornia \u2013 an open source computer vision library which consists of a set of differentiable routines and modules to solve generic computer vision problems. The package uses PyTorch as its main backend both for efficiency and to take advantage of the reverse-mode auto-differentiation to define and compute the gradient of complex functions. Inspired by OpenCV, Kornia is composed of a set of modules containing operators that can be inserted inside neural networks to train models to perform image transformations, camera calibration, epipolar geometry, and low level image processing techniques, such as filtering and edge detection that operate directly on high dimensional tensor representations. Examples of classical vision problems implemented using our framework are provided including a benchmark comparing to existing vision libraries.",
            "referenceCount": 60,
            "citationCount": 237,
            "influentialCitationCount": 10,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1910.02190",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-10-05",
            "journal": {
                "name": "2020 IEEE Winter Conference on Applications of Computer Vision (WACV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Riba2019KorniaAO,\n author = {Edgar Riba and Dmytro Mishkin and D. Ponsa and Ethan Rublee and G. Bradski},\n booktitle = {IEEE Workshop/Winter Conference on Applications of Computer Vision},\n journal = {2020 IEEE Winter Conference on Applications of Computer Vision (WACV)},\n pages = {3663-3672},\n title = {Kornia: an Open Source Differentiable Computer Vision Library for PyTorch},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:c6e4516912e31ceca7151781b71e13e41dc50b84",
            "@type": "ScholarlyArticle",
            "paperId": "c6e4516912e31ceca7151781b71e13e41dc50b84",
            "corpusId": 174798361,
            "url": "https://www.semanticscholar.org/paper/c6e4516912e31ceca7151781b71e13e41dc50b84",
            "title": "Evaluating Scalable Bayesian Deep Learning Methods for Robust Computer Vision",
            "venue": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "ArXiv": "1906.01620",
                "DBLP": "journals/corr/abs-1906-01620",
                "MAG": "2948210138",
                "DOI": "10.1109/CVPRW50498.2020.00167",
                "CorpusId": 174798361
            },
            "abstract": "While deep neural networks have become the go-to approach in computer vision, the vast majority of these models fail to properly capture the uncertainty inherent in their predictions. Estimating this predictive uncertainty can be crucial, for example in automotive applications. In Bayesian deep learning, predictive uncertainty is commonly decomposed into the distinct types of aleatoric and epistemic uncertainty. The former can be estimated by letting a neural network output the parameters of a certain probability distribution. Epistemic uncertainty estimation is a more challenging problem, and while different scalable methods recently have emerged, no extensive comparison has been performed in a real-world setting. We therefore accept this task and propose a comprehensive evaluation framework for scalable epistemic uncertainty estimation methods in deep learning. Our proposed framework is specifically designed to test the robustness required in real-world computer vision applications. We also apply this framework to provide the first properly extensive and conclusive comparison of the two current state-of-the- art scalable methods: ensembling and MC-dropout. Our comparison demonstrates that ensembling consistently provides more reliable and practically useful uncertainty estimates. Code is available at https://github.com/fregu856/evaluating_bdl.",
            "referenceCount": 64,
            "citationCount": 212,
            "influentialCitationCount": 19,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1906.01620",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2019-06-04",
            "journal": {
                "name": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gustafsson2019EvaluatingSB,\n author = {F. Gustafsson and Martin Danelljan and Thomas Bo Sch\u00f6n},\n booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},\n journal = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},\n pages = {1289-1298},\n title = {Evaluating Scalable Bayesian Deep Learning Methods for Robust Computer Vision},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9a4382bc7aad5b0f33360e7b119929b95eb04f00",
            "@type": "ScholarlyArticle",
            "paperId": "9a4382bc7aad5b0f33360e7b119929b95eb04f00",
            "corpusId": 208309956,
            "url": "https://www.semanticscholar.org/paper/9a4382bc7aad5b0f33360e7b119929b95eb04f00",
            "title": "Analysis of Explainers of Black Box Deep Neural Networks for Computer Vision: A Survey",
            "venue": "Machine Learning and Knowledge Extraction",
            "publicationVenue": {
                "id": "urn:research:472fe64a-ea91-4506-8d2d-4c9a9374e1ea",
                "name": "Machine Learning and Knowledge Extraction",
                "alternate_names": [
                    "Mach Learn Knowl Extr"
                ],
                "issn": "2504-4990",
                "url": "http://www.e-helvetica.nb.admin.ch/directAccess?callnumber=bel-1327032"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2990283237",
                "DBLP": "journals/corr/abs-1911-12116",
                "ArXiv": "1911.12116",
                "DOI": "10.3390/make3040048",
                "CorpusId": 208309956
            },
            "abstract": "Deep Learning is a state-of-the-art technique to make inference on extensive or complex data. As a black box model due to their multilayer nonlinear structure, Deep Neural Networks are often criticized as being non-transparent and their predictions not traceable by humans. Furthermore, the models learn from artificially generated datasets, which often do not reflect reality. By basing decision-making algorithms on Deep Neural Networks, prejudice and unfairness may be promoted unknowingly due to a lack of transparency. Hence, several so-called explanators, or explainers, have been developed. Explainers try to give insight into the inner structure of machine learning black boxes by analyzing the connection between the input and output. In this survey, we present the mechanisms and properties of explaining systems for Deep Neural Networks for Computer Vision tasks. We give a comprehensive overview about the taxonomy of related studies and compare several survey papers that deal with explainability in general. We work out the drawbacks and gaps and summarize further research ideas.",
            "referenceCount": 124,
            "citationCount": 205,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.mdpi.com/2504-4990/3/4/48/pdf?version=1640275931",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-11-27",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1911.12116"
            },
            "citationStyles": {
                "bibtex": "@Article{Buhrmester2019AnalysisOE,\n author = {Vanessa Buhrmester and David M\u00fcnch and Michael Arens},\n booktitle = {Machine Learning and Knowledge Extraction},\n journal = {ArXiv},\n title = {Analysis of Explainers of Black Box Deep Neural Networks for Computer Vision: A Survey},\n volume = {abs/1911.12116},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4f140022ae2a37b8186b34e690012a58fee0c820",
            "@type": "ScholarlyArticle",
            "paperId": "4f140022ae2a37b8186b34e690012a58fee0c820",
            "corpusId": 844981,
            "url": "https://www.semanticscholar.org/paper/4f140022ae2a37b8186b34e690012a58fee0c820",
            "title": "Conference on Computer Vision and Pattern Recognition 2005 . Overview of the Face Recognition Grand Challenge \u2217",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2005,
            "externalIds": {
                "CorpusId": 844981
            },
            "abstract": "Over the last couple of years, face recognition researchers have been developing new techniques. These developments are being fueled by advances in computer vision techniques, computer design, sensor design, and interest in fielding face recognition systems. Such advances hold the promise of reducing the error rate in face recognition systems by an order of magnitude over Face Recognition Vendor Test (FRVT) 2002 results. The Face Recognition Grand Challenge (FRGC) is designed to achieve this performance goal by presenting to researchers a six-experiment challenge problem along with data corpus of 50,000 images. The data consists of 3D scans and high resolution still imagery taken under controlled and uncontrolled conditions. This paper describes the challenge problem, data corpus, and presents baseline performance and preliminary results on natural statistics of facial imagery.",
            "referenceCount": 7,
            "citationCount": 2650,
            "influentialCitationCount": 350,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Phillips2005ConferenceOC,\n author = {P. Phillips and P. Flynn and W. T. Scruggs and K. Bowyer and Jin Chang and Kevin Hoffman and Joe Marques and Jaesik Min and W. Worek},\n title = {Conference on Computer Vision and Pattern Recognition 2005 . Overview of the Face Recognition Grand Challenge \u2217},\n year = {2005}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a4af1d879281da729a824d5825a507ac9ec54b50",
            "@type": "ScholarlyArticle",
            "paperId": "a4af1d879281da729a824d5825a507ac9ec54b50",
            "corpusId": 61806147,
            "url": "https://www.semanticscholar.org/paper/a4af1d879281da729a824d5825a507ac9ec54b50",
            "title": "Recent Advances of Generative Adversarial Networks in Computer Vision",
            "venue": "IEEE Access",
            "publicationVenue": {
                "id": "urn:research:2633f5b2-c15c-49fe-80f5-07523e770c26",
                "name": "IEEE Access",
                "alternate_names": null,
                "issn": "2169-3536",
                "url": "http://www.ieee.org/publications_standards/publications/ieee_access.html"
            },
            "year": 2019,
            "externalIds": {
                "DBLP": "journals/access/CaoJCLYZLLD19",
                "MAG": "2904843110",
                "DOI": "10.1109/ACCESS.2018.2886814",
                "CorpusId": 61806147
            },
            "abstract": "The appearance of generative adversarial networks (GAN) provides a new approach and framework for computer vision. Compared with traditional machine learning algorithms, GAN works via adversarial training concept and is more powerful in both feature learning and representation. GAN also exhibits some problems, such as non-convergence, model collapse, and uncontrollability due to high degree of freedom. How to improve the theory of GAN and apply it to computer-vision-related tasks have now attracted much research efforts. In this paper, recently proposed GAN models and their applications in computer vision are systematically reviewed. In particular, we firstly survey the history and development of generative algorithms, the mechanism of GAN, its fundamental network structures, and theoretical analysis of the original GAN. Classical GAN algorithms are then compared comprehensively in terms of the mechanism, visual results of generated samples, and Frechet Inception Distance. These networks are further evaluated from network construction, performance, and applicability aspects by extensive experiments conducted over public datasets. After that, several typical applications of GAN in computer vision, including high-quality samples generation, style transfer, and image translation, are examined. Finally, some existing problems of GAN are summarized and discussed and potential future research topics are forecasted.",
            "referenceCount": 93,
            "citationCount": 117,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ieeexplore.ieee.org/ielx7/6287639/8600701/08576508.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": "IEEE Access",
                "volume": "7"
            },
            "citationStyles": {
                "bibtex": "@Article{Cao2019RecentAO,\n author = {Yangjie Cao and Li-Li Jia and Yongxia Chen and Nan Lin and Cong Yang and Bo Zhang and Zhi Liu and Xuexiang Li and Honghua Dai},\n booktitle = {IEEE Access},\n journal = {IEEE Access},\n pages = {14985-15006},\n title = {Recent Advances of Generative Adversarial Networks in Computer Vision},\n volume = {7},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2243f46e171cf184412b4b93325dc96e445252ca",
            "@type": "ScholarlyArticle",
            "paperId": "2243f46e171cf184412b4b93325dc96e445252ca",
            "corpusId": 52814451,
            "url": "https://www.semanticscholar.org/paper/2243f46e171cf184412b4b93325dc96e445252ca",
            "title": "Computer vision and artificial intelligence in precision agriculture for grain crops: A systematic review",
            "venue": "Computers and Electronics in Agriculture",
            "publicationVenue": {
                "id": "urn:research:80fdf70e-8520-4bb7-b387-3abebc9970b7",
                "name": "Computers and Electronics in Agriculture",
                "alternate_names": [
                    "Comput Electron Agric"
                ],
                "issn": "0168-1699",
                "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/503304/description#description"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/cea/PatricioR18",
                "MAG": "2887311010",
                "DOI": "10.1016/j.compag.2018.08.001",
                "CorpusId": 52814451
            },
            "abstract": null,
            "referenceCount": 70,
            "citationCount": 501,
            "influentialCitationCount": 13,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://www.alice.cnptia.embrapa.br/bitstream/doc/1099103/1/ID444052008CompElectroAgricv153p69.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Agricultural and Food Sciences",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-10-01",
            "journal": {
                "name": "Comput. Electron. Agric.",
                "volume": "153"
            },
            "citationStyles": {
                "bibtex": "@Article{Patr\u00edcio2018ComputerVA,\n author = {D. I. Patr\u00edcio and Rafael Rieder},\n booktitle = {Computers and Electronics in Agriculture},\n journal = {Comput. Electron. Agric.},\n pages = {69-81},\n title = {Computer vision and artificial intelligence in precision agriculture for grain crops: A systematic review},\n volume = {153},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b441dd8fb25eddbaf92bc9938afda69627a281ab",
            "@type": "ScholarlyArticle",
            "paperId": "b441dd8fb25eddbaf92bc9938afda69627a281ab",
            "corpusId": 441278,
            "url": "https://www.semanticscholar.org/paper/b441dd8fb25eddbaf92bc9938afda69627a281ab",
            "title": "Computer Vision",
            "venue": "Advances in Computing",
            "publicationVenue": {
                "id": "urn:research:9d626429-1a76-48d5-8929-53e1ed7f83de",
                "name": "Advances in Computing",
                "alternate_names": [
                    "Advances in Computers",
                    "Adv Comput"
                ],
                "issn": "2163-2944",
                "url": "http://www.sapub.org/journal/issuelist.aspx?journalid=1007"
            },
            "year": 1988,
            "externalIds": {
                "MAG": "2913758415",
                "DBLP": "journals/ac/Rosenfeld88",
                "DOI": "10.1016/S0065-2458(08)60261-2",
                "CorpusId": 441278,
                "PubMed": "1891713"
            },
            "abstract": null,
            "referenceCount": 7,
            "citationCount": 4583,
            "influentialCitationCount": 137,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "1988-08-01",
            "journal": {
                "name": "Science",
                "volume": "253 5025"
            },
            "citationStyles": {
                "bibtex": "@Article{Rosenfeld1988ComputerV,\n author = {A. Rosenfeld},\n booktitle = {Advances in Computing},\n journal = {Science},\n pages = {\n          1249-54\n        },\n title = {Computer Vision},\n volume = {253 5025},\n year = {1988}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3fa7c465dd4deb44147f2896a5bc24b3a4ead697",
            "@type": "ScholarlyArticle",
            "paperId": "3fa7c465dd4deb44147f2896a5bc24b3a4ead697",
            "corpusId": 64609780,
            "url": "https://www.semanticscholar.org/paper/3fa7c465dd4deb44147f2896a5bc24b3a4ead697",
            "title": "Deep Learning for Computer Vision",
            "venue": "Learn Computer Vision Using OpenCV",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2941687618",
                "DOI": "10.1007/978-1-4842-4261-2_3",
                "CorpusId": 64609780
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 103,
            "influentialCitationCount": 8,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "Learn Computer Vision Using OpenCV",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Gollapudi2019DeepLF,\n author = {Sunila Gollapudi},\n booktitle = {Learn Computer Vision Using OpenCV},\n journal = {Learn Computer Vision Using OpenCV},\n title = {Deep Learning for Computer Vision},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:8b6bd623a19a0f2219fa637cafd7658c8797ffe6",
            "@type": "ScholarlyArticle",
            "paperId": "8b6bd623a19a0f2219fa637cafd7658c8797ffe6",
            "corpusId": 261618265,
            "url": "https://www.semanticscholar.org/paper/8b6bd623a19a0f2219fa637cafd7658c8797ffe6",
            "title": "International Journal of Computer Vision",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "CorpusId": 261618265
            },
            "abstract": "\u25b6 Details the science and engineering of the rapidly growing field of computer vision \u25b6 Presents major technical advances of broad general interest \u25b6 Provides a fast publication path for novel research results \u25b6 Offers critical reviews of the state of the art and/or tutorial presentations of pertinent topics \u25b6 92% of authors who answered a survey reported that they would definitely publish or probably publish in the journal again",
            "referenceCount": 0,
            "citationCount": 142,
            "influentialCitationCount": 16,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{None,\n title = {International Journal of Computer Vision},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:aa1679e90d060ada522c91d3171f73f5037a5337",
            "@type": "ScholarlyArticle",
            "paperId": "aa1679e90d060ada522c91d3171f73f5037a5337",
            "corpusId": 21707426,
            "url": "https://www.semanticscholar.org/paper/aa1679e90d060ada522c91d3171f73f5037a5337",
            "title": "Computer vision and deep learning techniques for pedestrian detection and tracking: A survey",
            "venue": "Neurocomputing",
            "publicationVenue": {
                "id": "urn:research:df12d289-f447-47d3-8846-75e39de3ab57",
                "name": "Neurocomputing",
                "alternate_names": null,
                "issn": "0925-2312",
                "url": "http://www.elsevier.com/locate/neucom"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/ijon/BrunettiBTB18",
                "MAG": "2791697444",
                "DOI": "10.1016/j.neucom.2018.01.092",
                "CorpusId": 21707426
            },
            "abstract": null,
            "referenceCount": 203,
            "citationCount": 360,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-07-01",
            "journal": {
                "name": "Neurocomputing",
                "volume": "300"
            },
            "citationStyles": {
                "bibtex": "@Article{Brunetti2018ComputerVA,\n author = {Antonio Brunetti and D. Buongiorno and Gianpaolo Francesco Trotta and Vitoantonio Bevilacqua},\n booktitle = {Neurocomputing},\n journal = {Neurocomputing},\n pages = {17-33},\n title = {Computer vision and deep learning techniques for pedestrian detection and tracking: A survey},\n volume = {300},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:25b9b9df391fc73f05db813d54e535aa9f8a4d10",
            "@type": "ScholarlyArticle",
            "paperId": "25b9b9df391fc73f05db813d54e535aa9f8a4d10",
            "corpusId": 206885860,
            "url": "https://www.semanticscholar.org/paper/25b9b9df391fc73f05db813d54e535aa9f8a4d10",
            "title": "A computer vision for animal ecology.",
            "venue": "Journal of Animal Ecology",
            "publicationVenue": {
                "id": "urn:research:c677b276-bd96-4f64-acb0-961e5a19c318",
                "name": "Journal of Animal Ecology",
                "alternate_names": [
                    "J Anim Ecol"
                ],
                "issn": "0021-8790",
                "url": "http://www3.interscience.wiley.com/journal/117960113/home"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2767556927",
                "DOI": "10.1111/1365-2656.12780",
                "CorpusId": 206885860,
                "PubMed": "29111567"
            },
            "abstract": "A central goal of animal ecology is to observe species in the natural world. The cost and challenge of data collection often limit the breadth and scope of ecological study. Ecologists often use image capture to bolster data collection in time and space. However, the ability to process these images remains a bottleneck. Computer vision can greatly increase the efficiency, repeatability and accuracy of image review. Computer vision uses image features, such as colour, shape and texture to infer image content. I provide a brief primer on ecological computer vision to outline its goals, tools and applications to animal ecology. I reviewed 187 existing applications of computer vision and divided articles into ecological description, counting and identity tasks. I discuss recommendations for enhancing the collaboration between ecologists and computer scientists and highlight areas for future growth of automated image analysis.",
            "referenceCount": 105,
            "citationCount": 257,
            "influentialCitationCount": 8,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://besjournals.onlinelibrary.wiley.com/doi/pdfdirect/10.1111/1365-2656.12780",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Medicine",
                "Biology"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2018-05-01",
            "journal": {
                "name": "The Journal of animal ecology",
                "volume": "87 3"
            },
            "citationStyles": {
                "bibtex": "@Article{Weinstein2018ACV,\n author = {Ben. G. Weinstein},\n booktitle = {Journal of Animal Ecology},\n journal = {The Journal of animal ecology},\n pages = {\n          533-545\n        },\n title = {A computer vision for animal ecology.},\n volume = {87 3},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5888d7dad8a2f825be1f573a5a90ef058cf946de",
            "@type": "ScholarlyArticle",
            "paperId": "5888d7dad8a2f825be1f573a5a90ef058cf946de",
            "corpusId": 8641226,
            "url": "https://www.semanticscholar.org/paper/5888d7dad8a2f825be1f573a5a90ef058cf946de",
            "title": "Multiple view geometry in computer vision (2. ed.)",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2006,
            "externalIds": {
                "DBLP": "books/daglib/0015576",
                "MAG": "2066933313",
                "CorpusId": 8641226
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 2800,
            "influentialCitationCount": 304,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Harltey2006MultipleVG,\n author = {Andrew Harltey and Andrew Zisserman},\n pages = {I-XVI, 1-655},\n title = {Multiple view geometry in computer vision (2. ed.)},\n year = {2006}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:be4a4f7f65d397a4e07dc83b95da6b414e0634e2",
            "@type": "ScholarlyArticle",
            "paperId": "be4a4f7f65d397a4e07dc83b95da6b414e0634e2",
            "corpusId": 44220250,
            "url": "https://www.semanticscholar.org/paper/be4a4f7f65d397a4e07dc83b95da6b414e0634e2",
            "title": "Adversarial Examples that Fool both Computer Vision and Time-Limited Humans",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2804342109",
                "DBLP": "conf/nips/ElsayedSCPKGS18",
                "ArXiv": "1802.08195",
                "CorpusId": 44220250
            },
            "abstract": "Machine learning models are vulnerable to adversarial examples: small changes to images can cause computer vision models to make mistakes such as identifying a school bus as an ostrich. However, it is still an open question whether humans are prone to similar mistakes. Here, we address this question by leveraging recent techniques that transfer adversarial examples from computer vision models with known parameters and architecture to other models with unknown parameters and architecture, and by matching the initial processing of the human visual system. We find that adversarial examples that strongly transfer across computer vision models influence the classifications made by time-limited human observers.",
            "referenceCount": 48,
            "citationCount": 225,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology",
                "Mathematics"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Biology",
                    "source": "external"
                },
                {
                    "category": "Mathematics",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-01",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Elsayed2018AdversarialET,\n author = {Gamaleldin F. Elsayed and Shreya Shankar and Brian Cheung and Nicolas Papernot and Alexey Kurakin and I. Goodfellow and Jascha Narain Sohl-Dickstein},\n booktitle = {Neural Information Processing Systems},\n pages = {3914-3924},\n title = {Adversarial Examples that Fool both Computer Vision and Time-Limited Humans},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e03aade1d4856e2fe9d2963ceb7de7bc4f3e13fd",
            "@type": "ScholarlyArticle",
            "paperId": "e03aade1d4856e2fe9d2963ceb7de7bc4f3e13fd",
            "corpusId": 201140977,
            "url": "https://www.semanticscholar.org/paper/e03aade1d4856e2fe9d2963ceb7de7bc4f3e13fd",
            "title": "Computer vision algorithms and hardware implementations: A survey",
            "venue": "Integr.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2019,
            "externalIds": {
                "MAG": "2972373811",
                "DBLP": "journals/integration/FengJYDL19",
                "DOI": "10.1016/j.vlsi.2019.07.005",
                "CorpusId": 201140977
            },
            "abstract": null,
            "referenceCount": 124,
            "citationCount": 198,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2019-11-01",
            "journal": {
                "name": "Integr.",
                "volume": "69"
            },
            "citationStyles": {
                "bibtex": "@Article{Feng2019ComputerVA,\n author = {Xin Feng and Youni Jiang and Xuejiao Yang and Ming Du and Xin Li},\n booktitle = {Integr.},\n journal = {Integr.},\n pages = {309-320},\n title = {Computer vision algorithms and hardware implementations: A survey},\n volume = {69},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:72c600b4f1e49eee8ebf1aa84ccb5f4b95387285",
            "@type": "ScholarlyArticle",
            "paperId": "72c600b4f1e49eee8ebf1aa84ccb5f4b95387285",
            "corpusId": 27388863,
            "url": "https://www.semanticscholar.org/paper/72c600b4f1e49eee8ebf1aa84ccb5f4b95387285",
            "title": "Learning OpenCV---Computer Vision with the OpenCV Library (Bradski, G.R. et al.; 2008)[On the Shelf]",
            "venue": "IEEE robotics & automation magazine",
            "publicationVenue": {
                "id": "urn:research:bb803f8e-3f8e-4fd1-8192-391b7d4de1f1",
                "name": "IEEE robotics & automation magazine",
                "alternate_names": [
                    "IEEE robot  autom mag",
                    "IEEE Robotics & Automation Magazine",
                    "IEEE Robot  Autom Mag"
                ],
                "issn": "1070-9932",
                "url": "http://ieeexplore.ieee.org/servlet/opac?punumber=100"
            },
            "year": 2009,
            "externalIds": {
                "MAG": "2077606434",
                "DOI": "10.1109/MRA.2009.933612",
                "CorpusId": 27388863
            },
            "abstract": "This is an introductory textbook for teachers, students, professionals, and hobbyists who want to learn the basics of computer vision. The book is completely based around the OpenCV library, an open source project that started in 1999 by the computer-vision community. The authors of the text are among the principal contributors to this real-time library that has developed in C/C++ to run Linux, Windows, and Mac OS X. Although it is unashamedly a promotion for the open-source library, it is still a worthy educational text.",
            "referenceCount": 0,
            "citationCount": 2354,
            "influentialCitationCount": 217,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2009-09-09",
            "journal": {
                "name": "IEEE Robotics & Automation Magazine",
                "volume": "16"
            },
            "citationStyles": {
                "bibtex": "@Article{Zelinsky2009LearningOV,\n author = {A. Zelinsky},\n booktitle = {IEEE robotics & automation magazine},\n journal = {IEEE Robotics & Automation Magazine},\n pages = {100-100},\n title = {Learning OpenCV---Computer Vision with the OpenCV Library (Bradski, G.R. et al.; 2008)[On the Shelf]},\n volume = {16},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3e398bad2d8636491a1034cc938a5e024c7aa881",
            "@type": "ScholarlyArticle",
            "paperId": "3e398bad2d8636491a1034cc938a5e024c7aa881",
            "corpusId": 232035922,
            "url": "https://www.semanticscholar.org/paper/3e398bad2d8636491a1034cc938a5e024c7aa881",
            "title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions",
            "venue": "IEEE International Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:7654260e-79f9-45c5-9663-d72027cf88f3",
                "name": "IEEE International Conference on Computer Vision",
                "alternate_names": [
                    "ICCV",
                    "IEEE Int Conf Comput Vis",
                    "ICCV Workshops",
                    "ICCV Work"
                ],
                "issn": null,
                "url": "https://ieeexplore.ieee.org/xpl/conhome/1000149/all-proceedings"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "conf/iccv/WangX0FSLL0021",
                "ArXiv": "2102.12122",
                "DOI": "10.1109/ICCV48922.2021.00061",
                "CorpusId": 232035922
            },
            "abstract": "Although convolutional neural networks (CNNs) have achieved great success in computer vision, this work investigates a simpler, convolution-free backbone network use-fid for many dense prediction tasks. Unlike the recently-proposed Vision Transformer (ViT) that was designed for image classification specifically, we introduce the Pyramid Vision Transformer (PVT), which overcomes the difficulties of porting Transformer to various dense prediction tasks. PVT has several merits compared to current state of the arts. (1) Different from ViT that typically yields low-resolution outputs and incurs high computational and memory costs, PVT not only can be trained on dense partitions of an image to achieve high output resolution, which is important for dense prediction, but also uses a progressive shrinking pyramid to reduce the computations of large feature maps. (2) PVT inherits the advantages of both CNN and Transformer, making it a unified backbone for various vision tasks without convolutions, where it can be used as a direct replacement for CNN backbones. (3) We validate PVT through extensive experiments, showing that it boosts the performance of many downstream tasks, including object detection, instance and semantic segmentation. For example, with a comparable number of parameters, PVT+RetinaNet achieves 40.4 AP on the COCO dataset, surpassing ResNet50+RetinNet (36.3 AP) by 4.1 absolute AP (see Figure 2). We hope that PVT could, serre as an alternative and useful backbone for pixel-level predictions and facilitate future research.",
            "referenceCount": 87,
            "citationCount": 2049,
            "influentialCitationCount": 386,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2102.12122",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2021-02-24",
            "journal": {
                "name": "2021 IEEE/CVF International Conference on Computer Vision (ICCV)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wang2021PyramidVT,\n author = {Wenhai Wang and Enze Xie and Xiang Li and Deng-Ping Fan and Kaitao Song and Ding Liang and Tong Lu and P. Luo and Ling Shao},\n booktitle = {IEEE International Conference on Computer Vision},\n journal = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},\n pages = {548-558},\n title = {Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:e66511e5ba523c914dbd265f8ce38028d534f497",
            "@type": "ScholarlyArticle",
            "paperId": "e66511e5ba523c914dbd265f8ce38028d534f497",
            "corpusId": 213295090,
            "url": "https://www.semanticscholar.org/paper/e66511e5ba523c914dbd265f8ce38028d534f497",
            "title": "COMPUTER VISION FOR HUMAN-MACHINE INTERACTION-REVIEW",
            "venue": "Journal of Trends in Computer Science and Smart Technology",
            "publicationVenue": {
                "id": "urn:research:86fe65f8-9db0-4e39-a4bf-d09388d43078",
                "name": "Journal of Trends in Computer Science and Smart Technology",
                "alternate_names": [
                    "J Trends Comput Sci Smart Technol"
                ],
                "issn": "2582-4104",
                "url": "https://www.irojournals.com/tcsst/index.html"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "3002574225",
                "DOI": "10.36548/jtcsst.2019.2.006",
                "CorpusId": 213295090
            },
            "abstract": "The paper is a review on the computer vision that is helpful in the interaction between the human and the machines. The computer vision that is termed as the subfield of the artificial intelligence and the machine learning is capable of training the computer to visualize, interpret and respond back to the visual world in a similar way as the human vision does. Nowadays the computer vision has found its application in broader areas such as the heath care, safety security, surveillance etc. due to the progress, developments and latest innovations in the artificial intelligence, deep learning and neural networks. The paper presents the enhanced capabilities of the computer vision experienced in various applications related to the interactions between the human and machines involving the artificial intelligence, deep learning and the neural networks.",
            "referenceCount": 30,
            "citationCount": 38,
            "influentialCitationCount": 1,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2019-12-29",
            "journal": {
                "name": "Journal of Trends in Computer Science and Smart Technology",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{V.2019COMPUTERVF,\n author = {Dr. Suma V.},\n booktitle = {Journal of Trends in Computer Science and Smart Technology},\n journal = {Journal of Trends in Computer Science and Smart Technology},\n title = {COMPUTER VISION FOR HUMAN-MACHINE INTERACTION-REVIEW},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:9a674d82cd4f47477e3f1aa7b89a3d9f6e3894b8",
            "@type": "ScholarlyArticle",
            "paperId": "9a674d82cd4f47477e3f1aa7b89a3d9f6e3894b8",
            "corpusId": 61875646,
            "url": "https://www.semanticscholar.org/paper/9a674d82cd4f47477e3f1aa7b89a3d9f6e3894b8",
            "title": "Learning OpenCV 3: Computer Vision in C++ with the OpenCV Library",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2246690291",
                "CorpusId": 61875646
            },
            "abstract": "Learning OpenCV puts you in the middle of the rapidly expanding field of computer vision. Written by the creators of the free open source OpenCV library, this book introduces you to computer vision and demonstrates how you can quickly build applications that enable computers to \"see\" and make decisions based on that data.The second edition is updated to cover new features and changes in OpenCV 2.0, especially the C++ interface.Computer vision is everywherein security systems, manufacturing inspection systems, medical image analysis, Unmanned Aerial Vehicles, and more. OpenCV provides an easy-to-use computer vision framework and a comprehensive library with more than 500 functions that can run vision code in real time. Whether you want to build simple or sophisticated vision applications, Learning OpenCV is the book any developer or hobbyist needs to get started, with the help of hands-on exercises in each chapter.This book includes:A thorough introduction to OpenCV Getting input from cameras Transforming images Segmenting images and shape matching Pattern recognition, including face detection Tracking and motion in 2 and 3 dimensions 3D reconstruction from stereo vision Machine learning algorithms",
            "referenceCount": 194,
            "citationCount": 1003,
            "influentialCitationCount": 45,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2016-12-14",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Kaehler2016LearningO3,\n author = {A. Kaehler and G. Bradski},\n title = {Learning OpenCV 3: Computer Vision in C++ with the OpenCV Library},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:572785b5d6f6fa4b174d79725f82c056b0fb4565",
            "@type": "ScholarlyArticle",
            "paperId": "572785b5d6f6fa4b174d79725f82c056b0fb4565",
            "corpusId": 23267374,
            "url": "https://www.semanticscholar.org/paper/572785b5d6f6fa4b174d79725f82c056b0fb4565",
            "title": "Computer Vision for Autonomous Vehicles: Problems, Datasets and State-of-the-Art",
            "venue": "Foundations and Trends in Computer Graphics and Vision",
            "publicationVenue": {
                "id": "urn:research:a21f6aaa-21ef-418d-b2dd-e56ce6e16570",
                "name": "Foundations and Trends in Computer Graphics and Vision",
                "alternate_names": [
                    "Found Trends Comput Graph Vis"
                ],
                "issn": "1572-2740",
                "url": "https://www.nowpublishers.com/cgv"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2609532991",
                "ArXiv": "1704.05519",
                "DBLP": "journals/corr/JanaiGBG17",
                "DOI": "10.1561/0600000079",
                "CorpusId": 23267374
            },
            "abstract": "Recent years have witnessed enormous progress in AI-related fields such as computer vision, machine learning, and autonomous vehicles. As with any rapidly growing field, it becomes increasingly difficult to stay up-to-date or enter the field as a beginner. While several survey papers on particular sub-problems have appeared, no comprehensive survey on problems, datasets, and methods in computer vision for autonomous vehicles has been published. This book attempts to narrow this gap by providing a survey on the state-of-the-art datasets and techniques. Our survey includes both the historically most relevant literature as well as the current state of the art on several specific topics, including recognition, reconstruction, motion estimation, tracking, scene understanding, and end-to-end learning for autonomous driving. Towards this goal, we analyze the performance of the state of the art on several challenging benchmarking datasets, including KITTI, MOT, and Cityscapes. Besides, we discuss open problems and current research challenges. To ease accessibility and accommodate missing references, we also provide a website that allows navigating topics as well as methods and provides additional information.",
            "referenceCount": 471,
            "citationCount": 586,
            "influentialCitationCount": 14,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-04-18",
            "journal": {
                "name": "Found. Trends Comput. Graph. Vis.",
                "volume": "12"
            },
            "citationStyles": {
                "bibtex": "@Article{Janai2017ComputerVF,\n author = {J. Janai and F. G\u00fcney and Aseem Behl and Andreas Geiger},\n booktitle = {Foundations and Trends in Computer Graphics and Vision},\n journal = {Found. Trends Comput. Graph. Vis.},\n pages = {1-308},\n title = {Computer Vision for Autonomous Vehicles: Problems, Datasets and State-of-the-Art},\n volume = {12},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0d9ebe5c24b592970759e11dd24de2b919d19f2c",
            "@type": "ScholarlyArticle",
            "paperId": "0d9ebe5c24b592970759e11dd24de2b919d19f2c",
            "corpusId": 163164816,
            "url": "https://www.semanticscholar.org/paper/0d9ebe5c24b592970759e11dd24de2b919d19f2c",
            "title": "Does computer vision matter for action?",
            "venue": "Science Robotics",
            "publicationVenue": {
                "id": "urn:research:e09464be-9afe-4f80-961f-1f692839a54a",
                "name": "Science Robotics",
                "alternate_names": [
                    "Sci Robot"
                ],
                "issn": "2470-9476",
                "url": "http://www.sciencemag.org/journals/robotics"
            },
            "year": 2019,
            "externalIds": {
                "MAG": "3102597561",
                "DBLP": "journals/corr/abs-1905-12887",
                "ArXiv": "1905.12887",
                "DOI": "10.1126/scirobotics.aaw6661",
                "CorpusId": 163164816,
                "PubMed": "33137779"
            },
            "abstract": "Controlled experiments indicate that explicit intermediate representations help action. Controlled experiments indicate that explicit intermediate representations help action.",
            "referenceCount": 18,
            "citationCount": 86,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1905.12887",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2019-05-22",
            "journal": {
                "name": "Science Robotics",
                "volume": "4"
            },
            "citationStyles": {
                "bibtex": "@Article{Zhou2019DoesCV,\n author = {Brady Zhou and Philipp Kr\u00e4henb\u00fchl and V. Koltun},\n booktitle = {Science Robotics},\n journal = {Science Robotics},\n title = {Does computer vision matter for action?},\n volume = {4},\n year = {2019}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6299479a83c37ea1c9d253dd1100da7aeef78677",
            "@type": "ScholarlyArticle",
            "paperId": "6299479a83c37ea1c9d253dd1100da7aeef78677",
            "corpusId": 53740923,
            "url": "https://www.semanticscholar.org/paper/6299479a83c37ea1c9d253dd1100da7aeef78677",
            "title": "Prevalence of self-reported computer vision syndrome symptoms and its associated factors among university students",
            "venue": "European Journal of Ophthalmology",
            "publicationVenue": {
                "id": "urn:research:1c43f64e-a318-4124-b165-ceb894d2614b",
                "name": "European Journal of Ophthalmology",
                "alternate_names": [
                    "Eur J Ophthalmol"
                ],
                "issn": "1120-6721",
                "url": "https://journals.sagepub.com/loi/ejoa"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2903138221",
                "DOI": "10.1177/1120672118815110",
                "CorpusId": 53740923,
                "PubMed": "30474390"
            },
            "abstract": "Purpose: To determine the prevalence of symptoms of computer vision syndrome and to identify its associated factors. The secondary objective was to assess knowledge and practices related to preventing computer vision syndrome symptoms. Methods: The data for this cross-sectional study were collected through a self-administered questionnaire distributed to 713 female undergraduates studying business and medicine in Saudi Arabia. The questionnaire included computer vision syndrome validated symptoms and factors associated with computer vision syndrome development. Results: The most common symptom due to prolonged computer use was neck or shoulder pain, reported by 82.2% of the subjects. Overall, 66.5% of the subjects suffered from headache and 51.5% from dry eyes, in mild, moderate, or severe form. Business students were 1.6 times as likely as medical students to suffer from computer vision syndrome (odds ratio\u2009=\u20091.65; 95% confidence interval: 1.22, 2.24). The use of electronic devices for more than 5\u2009h (odds ratio\u2009=\u20091.52; 95% confidence interval: 1.07, 2.16) was also associated with experiencing computer vision syndrome symptoms. Regarding computer vision syndrome prevention, factors such as hours of use, screen distance, screen brightness, and room illumination showed statistically significant difference between the two groups (p\u2009<\u20090.0001). Conclusion: The prevalence of computer vision syndrome symptoms was significantly higher among business students, who reported lower awareness and poor practice measures of computer use recommendations. Relevant awareness campaigns focusing on the appropriate use of computers are highly recommended.",
            "referenceCount": 31,
            "citationCount": 85,
            "influentialCitationCount": 7,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-11-26",
            "journal": {
                "name": "European Journal of Ophthalmology",
                "volume": "30"
            },
            "citationStyles": {
                "bibtex": "@Article{Tawil2018PrevalenceOS,\n author = {Layan Al Tawil and Sara Aldokhayel and Leena Zeitouni and Tala Qadoumi and Siham Hussein and S. Ahamed},\n booktitle = {European Journal of Ophthalmology},\n journal = {European Journal of Ophthalmology},\n pages = {189 - 195},\n title = {Prevalence of self-reported computer vision syndrome symptoms and its associated factors among university students},\n volume = {30},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2def61f556f9a5576ace08911496b7c7e4f970a4",
            "@type": "ScholarlyArticle",
            "paperId": "2def61f556f9a5576ace08911496b7c7e4f970a4",
            "corpusId": 233714958,
            "url": "https://www.semanticscholar.org/paper/2def61f556f9a5576ace08911496b7c7e4f970a4",
            "title": "MLP-Mixer: An all-MLP Architecture for Vision",
            "venue": "Neural Information Processing Systems",
            "publicationVenue": {
                "id": "urn:research:d9720b90-d60b-48bc-9df8-87a30b9a60dd",
                "name": "Neural Information Processing Systems",
                "alternate_names": [
                    "Neural Inf Process Syst",
                    "NeurIPS",
                    "NIPS"
                ],
                "issn": null,
                "url": "http://neurips.cc/"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "conf/nips/TolstikhinHKBZU21",
                "ArXiv": "2105.01601",
                "CorpusId": 233714958
            },
            "abstract": "Convolutional Neural Networks (CNNs) are the go-to model for computer vision. Recently, attention-based networks, such as the Vision Transformer, have also become popular. In this paper we show that while convolutions and attention are both sufficient for good performance, neither of them are necessary. We present MLP-Mixer, an architecture based exclusively on multi-layer perceptrons (MLPs). MLP-Mixer contains two types of layers: one with MLPs applied independently to image patches (i.e.\"mixing\"the per-location features), and one with MLPs applied across patches (i.e.\"mixing\"spatial information). When trained on large datasets, or with modern regularization schemes, MLP-Mixer attains competitive scores on image classification benchmarks, with pre-training and inference cost comparable to state-of-the-art models. We hope that these results spark further research beyond the realms of well established CNNs and Transformers.",
            "referenceCount": 63,
            "citationCount": 1413,
            "influentialCitationCount": 308,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2021-05-04",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Tolstikhin2021MLPMixerAA,\n author = {I. Tolstikhin and N. Houlsby and Alexander Kolesnikov and Lucas Beyer and Xiaohua Zhai and Thomas Unterthiner and Jessica Yung and Daniel Keysers and Jakob Uszkoreit and Mario Lucic and A. Dosovitskiy},\n booktitle = {Neural Information Processing Systems},\n pages = {24261-24272},\n title = {MLP-Mixer: An all-MLP Architecture for Vision},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4f8b3a4ca73f29b6b6dd5643a6da09c885d7f108",
            "@type": "ScholarlyArticle",
            "paperId": "4f8b3a4ca73f29b6b6dd5643a6da09c885d7f108",
            "corpusId": 46932576,
            "url": "https://www.semanticscholar.org/paper/4f8b3a4ca73f29b6b6dd5643a6da09c885d7f108",
            "title": "A Review of the Evolution of Vision-Based Motion Analysis and the Integration of Advanced Computer Vision Methods Towards Developing a Markerless System",
            "venue": "Sports Medicine - Open",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "PubMedCentral": "5986692",
                "MAG": "2805442627",
                "DOI": "10.1186/s40798-018-0139-y",
                "CorpusId": 46932576,
                "PubMed": "29869300"
            },
            "abstract": null,
            "referenceCount": 120,
            "citationCount": 263,
            "influentialCitationCount": 13,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://sportsmedicine-open.springeropen.com/track/pdf/10.1186/s40798-018-0139-y.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review",
                "JournalArticle"
            ],
            "publicationDate": "2018-06-05",
            "journal": {
                "name": "Sports Medicine - Open",
                "volume": "4"
            },
            "citationStyles": {
                "bibtex": "@Article{Colyer2018ARO,\n author = {Steffi L. Colyer and M. Evans and D. Cosker and A. Salo},\n booktitle = {Sports Medicine - Open},\n journal = {Sports Medicine - Open},\n title = {A Review of the Evolution of Vision-Based Motion Analysis and the Integration of Advanced Computer Vision Methods Towards Developing a Markerless System},\n volume = {4},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:0fc813854ddab0f0f6face1e137d0f0f19c7d1b0",
            "@type": "ScholarlyArticle",
            "paperId": "0fc813854ddab0f0f6face1e137d0f0f19c7d1b0",
            "corpusId": 117697362,
            "url": "https://www.semanticscholar.org/paper/0fc813854ddab0f0f6face1e137d0f0f19c7d1b0",
            "title": "Falls from heights: A computer vision-based approach for safety harness detection",
            "venue": "Automation in Construction",
            "publicationVenue": {
                "id": "urn:research:cbe2e2e0-f4d3-4923-8b48-a02259e5f89c",
                "name": "Automation in Construction",
                "alternate_names": [
                    "Autom Constr"
                ],
                "issn": "0926-5805",
                "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/523112/description#description"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2790722345",
                "DOI": "10.1016/J.AUTCON.2018.02.018",
                "CorpusId": 117697362
            },
            "abstract": null,
            "referenceCount": 67,
            "citationCount": 259,
            "influentialCitationCount": 11,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2018-07-01",
            "journal": {
                "name": "Automation in Construction",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Fang2018FallsFH,\n author = {Weili Fang and L. Ding and Hanbin Luo and P. Love},\n booktitle = {Automation in Construction},\n journal = {Automation in Construction},\n title = {Falls from heights: A computer vision-based approach for safety harness detection},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:dc27ef97f0252b37641358ed67f50e857b6602b6",
            "@type": "ScholarlyArticle",
            "paperId": "dc27ef97f0252b37641358ed67f50e857b6602b6",
            "corpusId": 52946054,
            "url": "https://www.semanticscholar.org/paper/dc27ef97f0252b37641358ed67f50e857b6602b6",
            "title": "Computer Vision Syndrome and Associated Factors among Computer Users in Debre Tabor Town, Northwest Ethiopia",
            "venue": "Journal of Environmental and Public Health",
            "publicationVenue": {
                "id": "urn:research:472adb76-f5bd-4ad0-a989-08c3a9ccf86e",
                "name": "Journal of Environmental and Public Health",
                "alternate_names": [
                    "J Environ Public Health"
                ],
                "issn": "1687-9805",
                "url": "https://www.hindawi.com/journals/jeph/"
            },
            "year": 2018,
            "externalIds": {
                "PubMedCentral": "6165611",
                "MAG": "2891619202",
                "DOI": "10.1155/2018/4107590",
                "CorpusId": 52946054,
                "PubMed": "30305823"
            },
            "abstract": "Background Globally, computer is one of the common office tools used in various institutions. Using computer for prolonged time led to the users at greater health risk of computer vision syndrome (CVS). Computer vision syndrome is the leading occupational health problem of the twenty-first century. About 70 percent of computer users are suffered from CVS. Besides the health problems, CVS causes inefficiency at workplace and deteriorate quality of work. The problem of CVS and its risk factors are not well known in Ethiopia. Method A cross-sectional study was conducted to assess the prevalence of CVS and associated factors among computer user government employees in Debre Tabor town from February to March, 2016. Multistage random sampling method was applied to select 607 study participants, and the data were collected by using a structured questionnaire. Computer vision syndrome was measured by self-reported method. Bivariate and multivariable binary logistic regression analyses were performed using SPSS version 20. Significance level was obtained at 95% CI and p value\u2009<\u20090.05. Results The prevalence of CVS was 422 (69.5%) with 95% CI of 65.60, 73.0%. Blurred vision, eyestrain, and eye irritation were the commonest reported symptoms of CVS with proportion of 62.60%, 47.63%, and 47.40%, respectively. Occupation: officer (adjusted odds ratio (AOR)\u2009=\u20094.74) and secretary (AOR\u2009=\u20099.17), daily computer usage (AOR: 2.29), and preexisting eye disease (AOR\u2009=\u20093.19) were risk factors for CVS. However, computer users with high payment, who took regular health break, and with good knowledge on computer safety measures were less impacted by CVS. Conclusion The prevalence of computer vision syndrome was found to be higher in Debre Tabor town. Monthly income, occupation, daily computer usage, regular health break, knowledge, and preexisting eye disease were predictor variables for CVS. Optimizing exposure time, improving awareness on safety measures, and management support are important to tackle CVS.",
            "referenceCount": 31,
            "citationCount": 80,
            "influentialCitationCount": 6,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://downloads.hindawi.com/journals/jeph/2018/4107590.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-09-16",
            "journal": {
                "name": "Journal of Environmental and Public Health",
                "volume": "2018"
            },
            "citationStyles": {
                "bibtex": "@Article{Dessie2018ComputerVS,\n author = {Awrajaw Dessie and Fentahun Adane and Ansha Nega and S. Wami and D. H. Chercos},\n booktitle = {Journal of Environmental and Public Health},\n journal = {Journal of Environmental and Public Health},\n title = {Computer Vision Syndrome and Associated Factors among Computer Users in Debre Tabor Town, Northwest Ethiopia},\n volume = {2018},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:de38eed87dec5b3c5ede4461196015cdcb193dd2",
            "@type": "ScholarlyArticle",
            "paperId": "de38eed87dec5b3c5ede4461196015cdcb193dd2",
            "corpusId": 3960664,
            "url": "https://www.semanticscholar.org/paper/de38eed87dec5b3c5ede4461196015cdcb193dd2",
            "title": "EVA\u00b2: Exploiting Temporal Redundancy in Live Computer Vision",
            "venue": "International Symposium on Computer Architecture",
            "publicationVenue": {
                "id": "urn:research:deedf64a-dd5c-4b33-b345-ff83bfb93d71",
                "name": "International Symposium on Computer Architecture",
                "alternate_names": [
                    "Int Symp Comput Archit",
                    "ISCA"
                ],
                "issn": null,
                "url": "http://www.cs.wisc.edu/~arch/www/"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "conf/isca/BucklerBJS18",
                "MAG": "2950023582",
                "ArXiv": "1803.06312",
                "DOI": "10.1109/ISCA.2018.00051",
                "CorpusId": 3960664
            },
            "abstract": "Hardware support for deep convolutional neural networks (CNNs) is critical to advanced computer vision in mobile and embedded devices. Current designs, however, accelerate generic CNNs; they do not exploit the unique characteristics of real-time vision. We propose to use the temporal redundancy in natural video to avoid unnecessary computation on most frames. A new algorithm, activation motion compensation, detects changes in the visual input and incrementally updates a previously-computed activation. The technique takes inspiration from video compression and applies well-known motion estimation techniques to adapt to visual changes. We use an adaptive key frame rate to control the trade-off between efficiency and vision quality as the input changes. We implement the technique in hardware as an extension to state-of-the-art CNN accelerator designs. The new unit reduces the average energy per frame by 54%, 62%, and 87% for three CNNs with less than 1% loss in vision accuracy.",
            "referenceCount": 64,
            "citationCount": 64,
            "influentialCitationCount": 13,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1803.06312",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Book",
                "JournalArticle"
            ],
            "publicationDate": "2018-03-16",
            "journal": {
                "name": "2018 ACM/IEEE 45th Annual International Symposium on Computer Architecture (ISCA)",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Book{Buckler2018EVA\u00b2ET,\n author = {Mark Buckler and Philip Bedoukian and Suren Jayasuriya and Adrian Sampson},\n booktitle = {International Symposium on Computer Architecture},\n journal = {2018 ACM/IEEE 45th Annual International Symposium on Computer Architecture (ISCA)},\n pages = {533-546},\n title = {EVA\u00b2: Exploiting Temporal Redundancy in Live Computer Vision},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:7b074827587903f05a4a1fcdbe189b39c6661862",
            "@type": "ScholarlyArticle",
            "paperId": "7b074827587903f05a4a1fcdbe189b39c6661862",
            "corpusId": 57808356,
            "url": "https://www.semanticscholar.org/paper/7b074827587903f05a4a1fcdbe189b39c6661862",
            "title": "Computer Vision and Image Processing: A Paper Review",
            "venue": "International Journal of Artificial Intelligence Research",
            "publicationVenue": {
                "id": "urn:research:24916b9d-d404-4fd1-abdf-111d61f57dc4",
                "name": "International Journal of Artificial Intelligence Research",
                "alternate_names": [
                    "Int J Artif Intell Res"
                ],
                "issn": "2579-7298",
                "url": "http://ijair.id/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2793959159",
                "DOI": "10.29099/IJAIR.V2I1.42",
                "CorpusId": 57808356
            },
            "abstract": "Computer vision has been studied from many persective. It expands from raw data recording into techniques and ideas combining digital image processing, pattern recognition, machine learning and computer graphics. The wide usage has attracted many scholars to integrate with many disciplines and fields. This paper provide a survey of the recent technologies and theoretical concept explaining the development of computer vision especially related to image processing using different areas of their field application. Computer vision helps scholars to analyze images and video to obtain necessary information,\u00a0\u00a0\u00a0 understand information on events or descriptions, and scenic pattern. It used method of multi-range application domain with massive data analysis. This paper provides contribution of recent development on reviews related to computer vision, image processing, and their related studies. We categorized the computer vision mainstream into four group e.g., image processing, object recognition, and machine learning. We also provide brief explanation on the up-to-date information about the techniques and their performance.",
            "referenceCount": 52,
            "citationCount": 110,
            "influentialCitationCount": 1,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://ijair.id/index.php/ijair/article/download/42/pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Review"
            ],
            "publicationDate": "2018-06-01",
            "journal": {
                "name": "International Journal of Artificial Intelligence Research",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Wiley2018ComputerVA,\n author = {Victor Wiley and Thomas Lucas},\n booktitle = {International Journal of Artificial Intelligence Research},\n journal = {International Journal of Artificial Intelligence Research},\n title = {Computer Vision and Image Processing: A Paper Review},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6255099ba4c815655f0fad8175d5254199867ade",
            "@type": "ScholarlyArticle",
            "paperId": "6255099ba4c815655f0fad8175d5254199867ade",
            "corpusId": 23279769,
            "url": "https://www.semanticscholar.org/paper/6255099ba4c815655f0fad8175d5254199867ade",
            "title": "A Survey on Computer Vision for Assistive Medical Diagnosis From Faces",
            "venue": "IEEE journal of biomedical and health informatics",
            "publicationVenue": {
                "id": "urn:research:eac74c9c-a5c0-417d-8088-8164a6a8bfb3",
                "name": "IEEE journal of biomedical and health informatics",
                "alternate_names": [
                    "IEEE Journal of Biomedical and Health Informatics",
                    "IEEE j biomed health informatics",
                    "IEEE J Biomed Health Informatics"
                ],
                "issn": "2168-2194",
                "url": "https://ieeexplore.ieee.org/xpl/aboutJournal.jsp?punumber=6221020"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "journals/titb/ThevenotLH18",
                "MAG": "2761974878",
                "DOI": "10.1109/JBHI.2017.2754861",
                "CorpusId": 23279769,
                "PubMed": "28991753"
            },
            "abstract": "Automatic medical diagnosis is an emerging center of interest in computer vision as it provides unobtrusive objective information on a patient's condition. The face, as a mirror of health status, can reveal symptomatic indications of specific diseases. Thus, the detection of facial abnormalities or atypical features is at upmost importance when it comes to medical diagnostics. This survey aims to give an overview of the recent developments in medical diagnostics from facial images based on computer vision methods. Various approaches have been considered to assess facial symptoms and to eventually provide further help to the practitioners. However, the developed tools are still seldom used in clinical practice, since their reliability is still a concern due to the lack of clinical validation of the methodologies and their inadequate applicability. Nonetheless, efforts are being made to provide robust solutions suitable for healthcare environments, by dealing with practical issues such as real-time assessment or patients positioning. This survey provides an updated collection of the most relevant and innovative solutions in facial images analysis. The findings show that with the help of computer vision methods, over 30 medical conditions can be preliminarily diagnosed from the automatic detection of some of their symptoms. Furthermore, future perspectives, such as the need for interdisciplinary collaboration and collecting publicly available databases, are highlighted.",
            "referenceCount": 202,
            "citationCount": 108,
            "influentialCitationCount": 2,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://ieeexplore.ieee.org/ielx7/6221020/8432070/08059954.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2018-09-01",
            "journal": {
                "name": "IEEE Journal of Biomedical and Health Informatics",
                "volume": "22"
            },
            "citationStyles": {
                "bibtex": "@Article{Thevenot2018ASO,\n author = {J. Thevenot and Miguel Bordallo L\u00f3pez and A. Hadid},\n booktitle = {IEEE journal of biomedical and health informatics},\n journal = {IEEE Journal of Biomedical and Health Informatics},\n pages = {1497-1511},\n title = {A Survey on Computer Vision for Assistive Medical Diagnosis From Faces},\n volume = {22},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5e5442991e11a434b3be891ca3efd9f6034ab24b",
            "@type": "ScholarlyArticle",
            "paperId": "5e5442991e11a434b3be891ca3efd9f6034ab24b",
            "corpusId": 239930849,
            "url": "https://www.semanticscholar.org/paper/5e5442991e11a434b3be891ca3efd9f6034ab24b",
            "title": "Computer vision",
            "venue": "Radiopaedia.org",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2020,
            "externalIds": {
                "DOI": "10.53347/rid-74840",
                "CorpusId": 239930849
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 0,
            "influentialCitationCount": 0,
            "isOpenAccess": true,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2020-03-06",
            "journal": {
                "name": "Radiopaedia.org",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Bell2020ComputerV,\n author = {D. Bell and Candace Moore},\n booktitle = {Radiopaedia.org},\n journal = {Radiopaedia.org},\n title = {Computer vision},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ca4a270a7ec0a156a115cda1fd0c8f2ac01b69c3",
            "@type": "ScholarlyArticle",
            "paperId": "ca4a270a7ec0a156a115cda1fd0c8f2ac01b69c3",
            "corpusId": 242110568,
            "url": "https://www.semanticscholar.org/paper/ca4a270a7ec0a156a115cda1fd0c8f2ac01b69c3",
            "title": "Computer vision",
            "venue": "An Introduction to Artificial Intelligence",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2020,
            "externalIds": {
                "DOI": "10.1201/9781003072485-8",
                "CorpusId": 242110568
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 0,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": null,
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Art",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2020-10-28",
            "journal": {
                "name": "An Introduction to Artificial Intelligence",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Finlay2020ComputerV,\n author = {J. Finlay and A. Dix},\n booktitle = {An Introduction to Artificial Intelligence},\n journal = {An Introduction to Artificial Intelligence},\n title = {Computer vision},\n year = {2020}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1e26162d70f04da2091d1aa011f6999b76cbddff",
            "@type": "ScholarlyArticle",
            "paperId": "1e26162d70f04da2091d1aa011f6999b76cbddff",
            "corpusId": 195995446,
            "url": "https://www.semanticscholar.org/paper/1e26162d70f04da2091d1aa011f6999b76cbddff",
            "title": "Computer Vision",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 1982,
            "externalIds": {
                "MAG": "2740373864",
                "DOI": "10.1109/hsi.2017.8005033",
                "CorpusId": 195995446
            },
            "abstract": null,
            "referenceCount": 0,
            "citationCount": 4492,
            "influentialCitationCount": 35,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Ballard1982ComputerV,\n author = {D. Ballard and C. Brown},\n title = {Computer Vision},\n year = {1982}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:4bc22398a204662aa53fd61ded4500c75e0edc30",
            "@type": "ScholarlyArticle",
            "paperId": "4bc22398a204662aa53fd61ded4500c75e0edc30",
            "corpusId": 4775806,
            "url": "https://www.semanticscholar.org/paper/4bc22398a204662aa53fd61ded4500c75e0edc30",
            "title": "Bedside Computer Vision - Moving Artificial Intelligence from Driver Assistance to Patient Safety.",
            "venue": "New England Journal of Medicine",
            "publicationVenue": {
                "id": "urn:research:dc31f077-7737-4e33-baa3-bceeff44ec27",
                "name": "New England Journal of Medicine",
                "alternate_names": [
                    "n engl J Med",
                    "The New England Journal of Medicine",
                    "N Engl J Med"
                ],
                "issn": "0028-4793",
                "url": "https://www.nejm.org/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2796101516",
                "DOI": "10.1056/NEJMp1716891",
                "CorpusId": 4775806,
                "PubMed": "29617592"
            },
            "abstract": "Bedside Computer Vision Computer vision, a rapidly progressing domain of artificial intelligence, may ultimately permit further improvement in patient safety. Researchers have been testing an AI-ba...",
            "referenceCount": 5,
            "citationCount": 80,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-04-04",
            "journal": {
                "name": "The New England journal of medicine",
                "volume": "378 14"
            },
            "citationStyles": {
                "bibtex": "@Article{Yeung2018BedsideCV,\n author = {Serena Yeung and N. L. Downing and Li Fei-Fei and A. Milstein},\n booktitle = {New England Journal of Medicine},\n journal = {The New England journal of medicine},\n pages = {\n          1271-1273\n        },\n title = {Bedside Computer Vision - Moving Artificial Intelligence from Driver Assistance to Patient Safety.},\n volume = {378 14},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ce1ff1a833f38e411c0ecdbf84426cfea8842646",
            "@type": "ScholarlyArticle",
            "paperId": "ce1ff1a833f38e411c0ecdbf84426cfea8842646",
            "corpusId": 195346561,
            "url": "https://www.semanticscholar.org/paper/ce1ff1a833f38e411c0ecdbf84426cfea8842646",
            "title": "Adversarial Examples that Fool both Human and Computer Vision",
            "venue": "arXiv.org",
            "publicationVenue": {
                "id": "urn:research:1901e811-ee72-4b20-8f7e-de08cd395a10",
                "name": "arXiv.org",
                "alternate_names": [
                    "ArXiv"
                ],
                "issn": "2331-8422",
                "url": "https://arxiv.org"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2788590143",
                "DBLP": "journals/corr/abs-1802-08195",
                "CorpusId": 195346561
            },
            "abstract": "Machine learning models are vulnerable to adversarial examples: small changes to images can cause computer vision models to make mistakes such as identifying a school bus as an ostrich. However, it is still an open question whether humans are prone to similar mistakes. Here, we create the first adversarial examples designed to fool humans, by leveraging recent techniques that transfer adversarial examples from computer vision models with known parameters and architecture to other models with unknown parameters and architecture, and by modifying models to more closely match the initial processing of the human visual system. We find that adversarial examples that strongly transfer across computer vision models influence the classifications made by time-limited human observers.",
            "referenceCount": 46,
            "citationCount": 77,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-22",
            "journal": {
                "name": "ArXiv",
                "volume": "abs/1802.08195"
            },
            "citationStyles": {
                "bibtex": "@Article{Elsayed2018AdversarialET,\n author = {Gamaleldin F. Elsayed and Shreya Shankar and Brian Cheung and Nicolas Papernot and Alexey Kurakin and I. Goodfellow and Jascha Narain Sohl-Dickstein},\n booktitle = {arXiv.org},\n journal = {ArXiv},\n title = {Adversarial Examples that Fool both Human and Computer Vision},\n volume = {abs/1802.08195},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:ac2bcf21e382346f1f555c9757db55dea62d7af7",
            "@type": "ScholarlyArticle",
            "paperId": "ac2bcf21e382346f1f555c9757db55dea62d7af7",
            "corpusId": 3603983,
            "url": "https://www.semanticscholar.org/paper/ac2bcf21e382346f1f555c9757db55dea62d7af7",
            "title": "Robust Fitting in Computer Vision: Easy or Hard?",
            "venue": "International Journal of Computer Vision",
            "publicationVenue": {
                "id": "urn:research:939ee07c-6009-43f8-b884-69238b40659e",
                "name": "International Journal of Computer Vision",
                "alternate_names": [
                    "Int J Comput Vis"
                ],
                "issn": "0920-5691",
                "url": "https://www.springer.com/computer/image+processing/journal/11263"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2788127582",
                "ArXiv": "1802.06464",
                "DBLP": "conf/eccv/ChinCN18",
                "DOI": "10.1007/s11263-019-01207-y",
                "CorpusId": 3603983
            },
            "abstract": null,
            "referenceCount": 43,
            "citationCount": 64,
            "influentialCitationCount": 3,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1802.06464",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2018-02-18",
            "journal": {
                "name": "International Journal of Computer Vision",
                "volume": "128"
            },
            "citationStyles": {
                "bibtex": "@Article{Chin2018RobustFI,\n author = {Tat-Jun Chin and Zhipeng Cai and F. Neumann},\n booktitle = {International Journal of Computer Vision},\n journal = {International Journal of Computer Vision},\n pages = {575 - 587},\n title = {Robust Fitting in Computer Vision: Easy or Hard?},\n volume = {128},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:326fdd827e8026ea313c769452912eebf56eff5d",
            "@type": "ScholarlyArticle",
            "paperId": "326fdd827e8026ea313c769452912eebf56eff5d",
            "corpusId": 52923234,
            "url": "https://www.semanticscholar.org/paper/326fdd827e8026ea313c769452912eebf56eff5d",
            "title": "Computer Vision \u2013 ECCV 2018",
            "venue": "Lecture Notes in Computer Science",
            "publicationVenue": {
                "id": "urn:research:2f5d0e8a-faad-4f10-b323-2b2e3c439a78",
                "name": "Lecture Notes in Computer Science",
                "alternate_names": [
                    "LNCS",
                    "Transactions on Computational Systems Biology",
                    "Trans Comput Syst Biology",
                    "Lect Note Comput Sci"
                ],
                "issn": "0302-9743",
                "url": "http://www.springer.com/lncs"
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "conf/eccv/2018-6",
                "DOI": "10.1007/978-3-030-01231-1",
                "CorpusId": 52923234
            },
            "abstract": null,
            "referenceCount": 72,
            "citationCount": 53,
            "influentialCitationCount": 2,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": null,
                "volume": "11210"
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Ferrari2018ComputerV,\n author = {V. Ferrari and M. Hebert and C. Sminchisescu and Y. Weiss},\n booktitle = {Lecture Notes in Computer Science},\n title = {Computer Vision \u2013 ECCV 2018},\n volume = {11210},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:dd116435b6f93e803e8db708ad4d0bce71499982",
            "@type": "ScholarlyArticle",
            "paperId": "dd116435b6f93e803e8db708ad4d0bce71499982",
            "corpusId": 64711781,
            "url": "https://www.semanticscholar.org/paper/dd116435b6f93e803e8db708ad4d0bce71499982",
            "title": "Computer Vision and Pattern Recognition (CVPR)",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2009,
            "externalIds": {
                "MAG": "2768066693",
                "DOI": "10.1109/CVPR.2009.5206636",
                "CorpusId": 64711781
            },
            "abstract": null,
            "referenceCount": 4,
            "citationCount": 2138,
            "influentialCitationCount": 271,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://eprints.whiterose.ac.uk/75464/14/hoggdc13.pdf",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Damen2009ComputerVA,\n author = {D. Damen and David C. Hogg},\n title = {Computer Vision and Pattern Recognition (CVPR)},\n year = {2009}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:282578039c767f3d393529565cae6be56fda6242",
            "@type": "ScholarlyArticle",
            "paperId": "282578039c767f3d393529565cae6be56fda6242",
            "corpusId": 3731652,
            "url": "https://www.semanticscholar.org/paper/282578039c767f3d393529565cae6be56fda6242",
            "title": "Augmented Reality Meets Computer Vision: Efficient Data Generation for Urban Driving Scenes",
            "venue": "International Journal of Computer Vision",
            "publicationVenue": {
                "id": "urn:research:939ee07c-6009-43f8-b884-69238b40659e",
                "name": "International Journal of Computer Vision",
                "alternate_names": [
                    "Int J Comput Vis"
                ],
                "issn": "0920-5691",
                "url": "https://www.springer.com/computer/image+processing/journal/11263"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/corr/abs-1708-01566",
                "ArXiv": "1708.01566",
                "MAG": "2951286740",
                "DOI": "10.1007/s11263-018-1070-x",
                "CorpusId": 3731652
            },
            "abstract": null,
            "referenceCount": 36,
            "citationCount": 339,
            "influentialCitationCount": 23,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1708.01566",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-08-04",
            "journal": {
                "name": "International Journal of Computer Vision",
                "volume": "126"
            },
            "citationStyles": {
                "bibtex": "@Article{Alhaija2017AugmentedRM,\n author = {Hassan Abu Alhaija and Siva Karthik Mustikovela and L. Mescheder and Andreas Geiger and C. Rother},\n booktitle = {International Journal of Computer Vision},\n journal = {International Journal of Computer Vision},\n pages = {961 - 972},\n title = {Augmented Reality Meets Computer Vision: Efficient Data Generation for Urban Driving Scenes},\n volume = {126},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:a6cfe548f34a5af4f5441ddade464a4c31af838a",
            "@type": "ScholarlyArticle",
            "paperId": "a6cfe548f34a5af4f5441ddade464a4c31af838a",
            "corpusId": 41041337,
            "url": "https://www.semanticscholar.org/paper/a6cfe548f34a5af4f5441ddade464a4c31af838a",
            "title": "Handcrafted vs. non-handcrafted features for computer vision classification",
            "venue": "Pattern Recognition",
            "publicationVenue": {
                "id": "urn:research:266f640f-003e-453b-ab76-57e4053252f8",
                "name": "Pattern Recognition",
                "alternate_names": [
                    "Pattern Recognit"
                ],
                "issn": "0031-3203",
                "url": "http://www.elsevier.com/wps/find/journaldescription.cws_home/328/description#description"
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "journals/pr/NanniGB17",
                "MAG": "2621367454",
                "DOI": "10.1016/j.patcog.2017.05.025",
                "CorpusId": 41041337
            },
            "abstract": null,
            "referenceCount": 78,
            "citationCount": 378,
            "influentialCitationCount": 10,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-11-01",
            "journal": {
                "name": "Pattern Recognit.",
                "volume": "71"
            },
            "citationStyles": {
                "bibtex": "@Article{Nanni2017HandcraftedVN,\n author = {L. Nanni and S. Ghidoni and S. Brahnam},\n booktitle = {Pattern Recognition},\n journal = {Pattern Recognit.},\n pages = {158-172},\n title = {Handcrafted vs. non-handcrafted features for computer vision classification},\n volume = {71},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:b323aa63247c6a1f3076bee55e49188a09d6c6ab",
            "@type": "ScholarlyArticle",
            "paperId": "b323aa63247c6a1f3076bee55e49188a09d6c6ab",
            "corpusId": 49539405,
            "url": "https://www.semanticscholar.org/paper/b323aa63247c6a1f3076bee55e49188a09d6c6ab",
            "title": "Plant Species Identification Using Computer Vision Techniques: A Systematic Literature Review",
            "venue": "Archives of Computational Methods in Engineering",
            "publicationVenue": {
                "id": "urn:research:f9c1272f-e8c2-4e8c-bdae-fc9c2bb2cb85",
                "name": "Archives of Computational Methods in Engineering",
                "alternate_names": [
                    "Arch Comput Method Eng"
                ],
                "issn": "1134-3060",
                "url": "http://www.cimne.com/arcme/"
            },
            "year": 2017,
            "externalIds": {
                "PubMedCentral": "6003396",
                "MAG": "2568155635",
                "DOI": "10.1007/s11831-016-9206-z",
                "CorpusId": 49539405,
                "PubMed": "29962832"
            },
            "abstract": null,
            "referenceCount": 172,
            "citationCount": 298,
            "influentialCitationCount": 12,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007/s11831-016-9206-z.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Environmental Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Biology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-01-07",
            "journal": {
                "name": "Archives of Computational Methods in Engineering",
                "volume": "25"
            },
            "citationStyles": {
                "bibtex": "@Article{W\u00e4ldchen2017PlantSI,\n author = {Jana W\u00e4ldchen and Patrick M\u00e4der},\n booktitle = {Archives of Computational Methods in Engineering},\n journal = {Archives of Computational Methods in Engineering},\n pages = {507 - 543},\n title = {Plant Species Identification Using Computer Vision Techniques: A Systematic Literature Review},\n volume = {25},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:339093c7ed71919ce59a7e78979a77abd25bad0c",
            "@type": "ScholarlyArticle",
            "paperId": "339093c7ed71919ce59a7e78979a77abd25bad0c",
            "corpusId": 264850475,
            "url": "https://www.semanticscholar.org/paper/339093c7ed71919ce59a7e78979a77abd25bad0c",
            "title": "Multiple View Geometry in Computer Vision",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2001,
            "externalIds": {
                "DBLP": "books/cu/HZ2004",
                "MAG": "2033819227",
                "CorpusId": 264850475
            },
            "abstract": "From the Publisher: \nA basic problem in computer vision is to understand the structure of a real world scene given several images of it. Recent major developments in the theory and practice of scene reconstruction are described in detail in a unified framework. The book covers the geometric principles and how to represent objects algebraically so they can be computed and applied. The authors provide comprehensive background material and explain how to apply the methods and implement the algorithms directly.",
            "referenceCount": 208,
            "citationCount": 2859,
            "influentialCitationCount": 140,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Mathematics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2001-04-01",
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Hartley2001MultipleVG,\n author = {Richard Hartley and Andrew Zisserman},\n title = {Multiple View Geometry in Computer Vision},\n year = {2001}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5152277235d03179a277bc26ef573d8744d6de5b",
            "@type": "ScholarlyArticle",
            "paperId": "5152277235d03179a277bc26ef573d8744d6de5b",
            "corpusId": 64685463,
            "url": "https://www.semanticscholar.org/paper/5152277235d03179a277bc26ef573d8744d6de5b",
            "title": "Reinforcement learning in computer vision",
            "venue": "International Conference on Machine Vision",
            "publicationVenue": {
                "id": "urn:research:c4e26c05-cc78-4a34-9cc8-567aa54a8877",
                "name": "International Conference on Machine Vision",
                "alternate_names": [
                    "Int Conf Mach Vis",
                    "ICMV"
                ],
                "issn": null,
                "url": null
            },
            "year": 2018,
            "externalIds": {
                "DBLP": "conf/icmv/BernsteinB17",
                "MAG": "2800934671",
                "DOI": "10.1117/12.2309945",
                "CorpusId": 64685463
            },
            "abstract": "Nowadays, machine learning has become one of the basic technologies used in solving various computer vision tasks such as feature detection, image segmentation, object recognition and tracking. In many applications, various complex systems such as robots are equipped with visual sensors from which they learn state of surrounding environment by solving corresponding computer vision tasks. Solutions of these tasks are used for making decisions about possible future actions. It is not surprising that when solving computer vision tasks we should take into account special aspects of their subsequent application in model-based predictive control. Reinforcement learning is one of modern machine learning technologies in which learning is carried out through interaction with the environment. In recent years, Reinforcement learning has been used both for solving such applied tasks as processing and analysis of visual information, and for solving specific computer vision problems such as filtering, extracting image features, localizing objects in scenes, and many others. The paper describes shortly the Reinforcement learning technology and its use for solving computer vision problems.",
            "referenceCount": 58,
            "citationCount": 28,
            "influentialCitationCount": 0,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2018-04-13",
            "journal": {
                "name": null,
                "volume": "10696"
            },
            "citationStyles": {
                "bibtex": "@Article{Bernstein2018ReinforcementLI,\n author = {A. Bernstein and Evgeny Burnaev},\n booktitle = {International Conference on Machine Vision},\n title = {Reinforcement learning in computer vision},\n volume = {10696},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:3a906b77fa218adc171fecb28bb81c24c14dcc7b",
            "@type": "ScholarlyArticle",
            "paperId": "3a906b77fa218adc171fecb28bb81c24c14dcc7b",
            "corpusId": 230435805,
            "url": "https://www.semanticscholar.org/paper/3a906b77fa218adc171fecb28bb81c24c14dcc7b",
            "title": "Transformers in Vision: A Survey",
            "venue": "ACM Computing Surveys",
            "publicationVenue": {
                "id": "urn:research:7b2adce0-d53f-49d6-8784-b0645604fe62",
                "name": "ACM Computing Surveys",
                "alternate_names": [
                    "ACM Comput Surv"
                ],
                "issn": "0360-0300",
                "url": "http://www.acm.org/pubs/surveys/"
            },
            "year": 2021,
            "externalIds": {
                "DBLP": "journals/csur/KhanNHZKS22",
                "ArXiv": "2101.01169",
                "DOI": "10.1145/3505244",
                "CorpusId": 230435805
            },
            "abstract": "Astounding results from Transformer models on natural language tasks have intrigued the vision community to study their application to computer vision problems. Among their salient benefits, Transformers enable modeling long dependencies between input sequence elements and support parallel processing of sequence as compared to recurrent networks, e.g., Long short-term memory. Different from convolutional networks, Transformers require minimal inductive biases for their design and are naturally suited as set-functions. Furthermore, the straightforward design of Transformers allows processing multiple modalities (e.g., images, videos, text, and speech) using similar processing blocks and demonstrates excellent scalability to very large capacity networks and huge datasets. These strengths have led to exciting progress on a number of vision tasks using Transformer networks. This survey aims to provide a comprehensive overview of the Transformer models in the computer vision discipline. We start with an introduction to fundamental concepts behind the success of Transformers, i.e., self-attention, large-scale pre-training, and bidirectional feature encoding. We then cover extensive applications of transformers in vision including popular recognition tasks (e.g., image classification, object detection, action recognition, and segmentation), generative modeling, multi-modal tasks (e.g., visual-question answering, visual reasoning, and visual grounding), video processing (e.g., activity recognition, video forecasting), low-level vision (e.g., image super-resolution, image enhancement, and colorization), and three-dimensional analysis (e.g., point cloud classification and segmentation). We compare the respective advantages and limitations of popular techniques both in terms of architectural design and their experimental value. Finally, we provide an analysis on open research directions and possible future works. We hope this effort will ignite further interest in the community to solve current challenges toward the application of transformer models in computer vision.",
            "referenceCount": 285,
            "citationCount": 1204,
            "influentialCitationCount": 40,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/2101.01169",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2021-01-04",
            "journal": {
                "name": "ACM Computing Surveys (CSUR)",
                "volume": "54"
            },
            "citationStyles": {
                "bibtex": "@Article{Khan2021TransformersIV,\n author = {Salman Hameed Khan and Muzammal Naseer and Munawar Hayat and Syed Waqas Zamir and F. Khan and M. Shah},\n booktitle = {ACM Computing Surveys},\n journal = {ACM Computing Surveys (CSUR)},\n pages = {1 - 41},\n title = {Transformers in Vision: A Survey},\n volume = {54},\n year = {2021}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:1f31e16c7dc55bd4eb96ae5978ce82db697617f7",
            "@type": "ScholarlyArticle",
            "paperId": "1f31e16c7dc55bd4eb96ae5978ce82db697617f7",
            "corpusId": 5035081,
            "url": "https://www.semanticscholar.org/paper/1f31e16c7dc55bd4eb96ae5978ce82db697617f7",
            "title": "Computer Vision in Healthcare Applications",
            "venue": "Journal of Healthcare Engineering",
            "publicationVenue": {
                "id": "urn:research:946e893f-4e7f-47c5-8544-15aa5a2cc679",
                "name": "Journal of Healthcare Engineering",
                "alternate_names": [
                    "J Healthc Eng"
                ],
                "issn": "2040-2295",
                "url": "https://www.hindawi.com/journals/jhe/"
            },
            "year": 2018,
            "externalIds": {
                "MAG": "2792633707",
                "PubMedCentral": "5857319",
                "DOI": "10.1155/2018/5157020",
                "CorpusId": 5035081,
                "PubMed": "29686826"
            },
            "abstract": "College of Biomedical Engineering, South-Central University for Nationalities, Wuhan 430074, China Key Laboratory of Cognitive Science, State Ethnic Affairs Commission, Wuhan 430074, China Hubei Key Laboratory of Medical Information Analysis and Tumor Diagnosis & Treatment, Wuhan 430074, China School of Information Technology, Jiangxi University of Finance and Economics, Nanchang 330032, China IT Convergence Research Center, Chonbuk National University, Jeonju, Jeonbuk 54896, Republic of Korea",
            "referenceCount": 0,
            "citationCount": 57,
            "influentialCitationCount": 0,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://downloads.hindawi.com/journals/jhe/2018/5157020.pdf",
                "status": "GOLD"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Medicine"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "Editorial"
            ],
            "publicationDate": "2018-03-04",
            "journal": {
                "name": "Journal of Healthcare Engineering",
                "volume": "2018"
            },
            "citationStyles": {
                "bibtex": "@Article{Gao2018ComputerVI,\n author = {Junfeng Gao and Yong Yang and P. Lin and D. Park},\n booktitle = {Journal of Healthcare Engineering},\n journal = {Journal of Healthcare Engineering},\n title = {Computer Vision in Healthcare Applications},\n volume = {2018},\n year = {2018}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:cae56bb2657943bb07823fdf076625643e75095a",
            "@type": "ScholarlyArticle",
            "paperId": "cae56bb2657943bb07823fdf076625643e75095a",
            "corpusId": 8528041,
            "url": "https://www.semanticscholar.org/paper/cae56bb2657943bb07823fdf076625643e75095a",
            "title": "UnrealCV: Virtual Worlds for Computer Vision",
            "venue": "ACM Multimedia",
            "publicationVenue": {
                "id": "urn:research:f2c85de5-7cfa-4b92-8714-a0fbdcf0274e",
                "name": "ACM Multimedia",
                "alternate_names": [
                    "MM"
                ],
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "DBLP": "conf/mm/QiuZZQXKW17",
                "MAG": "2767011576",
                "DOI": "10.1145/3123266.3129396",
                "CorpusId": 8528041
            },
            "abstract": "UnrealCV is a project to help computer vision researchers build virtual worlds using Unreal Engine 4 (UE4). It extends UE4 with a plugin by providing (1) A set of UnrealCV commands to interact with the virtual world. (2) Communication between UE4 and an external program, such as Caffe. UnrealCV can be used in two ways. The first one is using a compiled game binary with UnrealCV embedded. This is as simple as running a game, no knowledge of Unreal Engine is required. The second is installing UnrealCV plugin to Unreal Engine 4 (UE4) and use the editor of UE4 to build a new virtual world. UnrealCV is an open-source software under the MIT license. Since the initial release in September 2016, it has gathered an active community of users, including students and researchers.",
            "referenceCount": 11,
            "citationCount": 164,
            "influentialCitationCount": 9,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Book"
            ],
            "publicationDate": "2017-10-19",
            "journal": {
                "name": "Proceedings of the 25th ACM international conference on Multimedia",
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Qiu2017UnrealCVVW,\n author = {Weichao Qiu and Fangwei Zhong and Yi Zhang and Siyuan Qiao and Zihao Xiao and Tae Soo Kim and Yizhou Wang},\n booktitle = {ACM Multimedia},\n journal = {Proceedings of the 25th ACM international conference on Multimedia},\n title = {UnrealCV: Virtual Worlds for Computer Vision},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:6488738d41906b5a44027f55fb766bbb6637da7d",
            "@type": "ScholarlyArticle",
            "paperId": "6488738d41906b5a44027f55fb766bbb6637da7d",
            "corpusId": 6875964,
            "url": "https://www.semanticscholar.org/paper/6488738d41906b5a44027f55fb766bbb6637da7d",
            "title": "Computer vision uncovers predictors of physical urban change",
            "venue": "Proceedings of the National Academy of Sciences of the United States of America",
            "publicationVenue": {
                "id": "urn:research:bb95bf2e-8383-4748-bf9d-d6906d091085",
                "name": "Proceedings of the National Academy of Sciences of the United States of America",
                "alternate_names": [
                    "PNAS",
                    "PNAS online",
                    "Proceedings of the National Academy of Sciences of the United States of America.",
                    "Proc National Acad Sci",
                    "Proceedings of the National Academy of Sciences",
                    "Proc National Acad Sci u s Am"
                ],
                "issn": "0027-8424",
                "url": "https://www.jstor.org/journal/procnatiacadscie"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2732873697",
                "DBLP": "journals/pnas/NaikKRGH17",
                "DOI": "10.1073/pnas.1619003114",
                "CorpusId": 6875964,
                "PubMed": "28684401"
            },
            "abstract": "Significance We develop a computer vision method to measure changes in the physical appearances of neighborhoods from street-level imagery. We correlate the measured changes with neighborhood characteristics to determine which characteristics predict neighborhood improvement. We find that both education and population density predict improvements in neighborhood infrastructure, in support of theories of human capital agglomeration. Neighborhoods with better initial appearances experience more substantial upgrading, as predicted by the tipping theory of urban change. Finally, we observe more improvement in neighborhoods closer to both city centers and other physically attractive neighborhoods, in agreement with the invasion theory of urban sociology. Our results show how computer vision techniques, in combination with traditional methods, can be used to explore the dynamics of urban change. Which neighborhoods experience physical improvements? In this paper, we introduce a computer vision method to measure changes in the physical appearances of neighborhoods from time-series street-level imagery. We connect changes in the physical appearance of five US cities with economic and demographic data and find three factors that predict neighborhood improvement. First, neighborhoods that are densely populated by college-educated adults are more likely to experience physical improvements\u2014an observation that is compatible with the economic literature linking human capital and local success. Second, neighborhoods with better initial appearances experience, on average, larger positive improvements\u2014an observation that is consistent with \u201ctipping\u201d theories of urban change. Third, neighborhood improvement correlates positively with physical proximity to the central business district and to other physically attractive neighborhoods\u2014an observation that is consistent with the \u201cinvasion\u201d theories of urban sociology. Together, our results provide support for three classical theories of urban change and illustrate the value of using computer vision methods and street-level imagery to understand the physical dynamics of cities.",
            "referenceCount": 37,
            "citationCount": 196,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://www.pnas.org/content/pnas/114/29/7571.full.pdf",
                "status": "BRONZE"
            },
            "fieldsOfStudy": [
                "Geography",
                "Medicine",
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Geography",
                    "source": "external"
                },
                {
                    "category": "Medicine",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Geography",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Sociology",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-07-06",
            "journal": {
                "name": "Proceedings of the National Academy of Sciences",
                "volume": "114"
            },
            "citationStyles": {
                "bibtex": "@Article{Naik2017ComputerVU,\n author = {Nikhil Naik and S. Kominers and R. Raskar and E. Glaeser and C\u00e9sar A. Hidalgo},\n booktitle = {Proceedings of the National Academy of Sciences of the United States of America},\n journal = {Proceedings of the National Academy of Sciences},\n pages = {7571 - 7576},\n title = {Computer vision uncovers predictors of physical urban change},\n volume = {114},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2ad12a7be5eaf339a98c4defd8669e11fe726acc",
            "@type": "ScholarlyArticle",
            "paperId": "2ad12a7be5eaf339a98c4defd8669e11fe726acc",
            "corpusId": 247939839,
            "url": "https://www.semanticscholar.org/paper/2ad12a7be5eaf339a98c4defd8669e11fe726acc",
            "title": "MaxViT: Multi-Axis Vision Transformer",
            "venue": "European Conference on Computer Vision",
            "publicationVenue": {
                "id": "urn:research:167fa0ca-e88a-4ef7-a16f-bc66c457c806",
                "name": "European Conference on Computer Vision",
                "alternate_names": [
                    "ECCV",
                    "Eur Conf Comput Vis"
                ],
                "issn": null,
                "url": "https://link.springer.com/conference/eccv"
            },
            "year": 2022,
            "externalIds": {
                "ArXiv": "2204.01697",
                "DBLP": "journals/corr/abs-2204-01697",
                "DOI": "10.48550/arXiv.2204.01697",
                "CorpusId": 247939839
            },
            "abstract": "Transformers have recently gained significant attention in the computer vision community. However, the lack of scalability of self-attention mechanisms with respect to image size has limited their wide adoption in state-of-the-art vision backbones. In this paper we introduce an efficient and scalable attention model we call multi-axis attention, which consists of two aspects: blocked local and dilated global attention. These design choices allow global-local spatial interactions on arbitrary input resolutions with only linear complexity. We also present a new architectural element by effectively blending our proposed attention model with convolutions, and accordingly propose a simple hierarchical vision backbone, dubbed MaxViT, by simply repeating the basic building block over multiple stages. Notably, MaxViT is able to ''see'' globally throughout the entire network, even in earlier, high-resolution stages. We demonstrate the effectiveness of our model on a broad spectrum of vision tasks. On image classification, MaxViT achieves state-of-the-art performance under various settings: without extra data, MaxViT attains 86.5% ImageNet-1K top-1 accuracy; with ImageNet-21K pre-training, our model achieves 88.7% top-1 accuracy. For downstream tasks, MaxViT as a backbone delivers favorable performance on object detection as well as visual aesthetic assessment. We also show that our proposed model expresses strong generative modeling capability on ImageNet, demonstrating the superior potential of MaxViT blocks as a universal vision module. The source code and trained models will be available at https://github.com/google-research/maxvit.",
            "referenceCount": 111,
            "citationCount": 222,
            "influentialCitationCount": 29,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "http://arxiv.org/pdf/2204.01697",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Conference"
            ],
            "publicationDate": "2022-04-04",
            "journal": {
                "name": null,
                "volume": null
            },
            "citationStyles": {
                "bibtex": "@Article{Tu2022MaxViTMV,\n author = {Zhengzhong Tu and Hossein Talebi and Han Zhang and Feng Yang and P. Milanfar and A. Bovik and Yinxiao Li},\n booktitle = {European Conference on Computer Vision},\n pages = {459-479},\n title = {MaxViT: Multi-Axis Vision Transformer},\n year = {2022}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d",
            "@type": "ScholarlyArticle",
            "paperId": "afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d",
            "corpusId": 4492210,
            "url": "https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d",
            "title": "Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations",
            "venue": "International Journal of Computer Vision",
            "publicationVenue": {
                "id": "urn:research:939ee07c-6009-43f8-b884-69238b40659e",
                "name": "International Journal of Computer Vision",
                "alternate_names": [
                    "Int J Comput Vis"
                ],
                "issn": "0920-5691",
                "url": "https://www.springer.com/computer/image+processing/journal/11263"
            },
            "year": 2016,
            "externalIds": {
                "ArXiv": "1602.07332",
                "DBLP": "journals/corr/KrishnaZGJHKCKL16",
                "MAG": "2277195237",
                "DOI": "10.1007/s11263-016-0981-7",
                "CorpusId": 4492210
            },
            "abstract": null,
            "referenceCount": 130,
            "citationCount": 4274,
            "influentialCitationCount": 664,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007%2Fs11263-016-0981-7.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Linguistics",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2016-02-23",
            "journal": {
                "name": "International Journal of Computer Vision",
                "volume": "123"
            },
            "citationStyles": {
                "bibtex": "@Article{Krishna2016VisualGC,\n author = {Ranjay Krishna and Yuke Zhu and O. Groth and Justin Johnson and K. Hata and Joshua Kravitz and Stephanie Chen and Yannis Kalantidis and Li-Jia Li and David A. Shamma and Michael S. Bernstein and Li Fei-Fei},\n booktitle = {International Journal of Computer Vision},\n journal = {International Journal of Computer Vision},\n pages = {32 - 73},\n title = {Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations},\n volume = {123},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:59262161731caab503b016493b7549ef6a9f3a09",
            "@type": "ScholarlyArticle",
            "paperId": "59262161731caab503b016493b7549ef6a9f3a09",
            "corpusId": 63115125,
            "url": "https://www.semanticscholar.org/paper/59262161731caab503b016493b7549ef6a9f3a09",
            "title": "Decision Forests For Computer Vision And Medical Image Analysis",
            "venue": "",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2016,
            "externalIds": {
                "MAG": "2508186887",
                "CorpusId": 63115125
            },
            "abstract": "Thank you very much for downloading decision forests for computer vision and medical image analysis. As you may know, people have search hundreds times for their favorite readings like this decision forests for computer vision and medical image analysis, but end up in harmful downloads. Rather than enjoying a good book with a cup of tea in the afternoon, instead they cope with some malicious bugs inside their computer.",
            "referenceCount": 0,
            "citationCount": 359,
            "influentialCitationCount": 27,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Medicine",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": null,
            "journal": {
                "name": "",
                "volume": ""
            },
            "citationStyles": {
                "bibtex": "@Inproceedings{Fruehauf2016DecisionFF,\n author = {S. Fruehauf},\n title = {Decision Forests For Computer Vision And Medical Image Analysis},\n year = {2016}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:fb39b1a73b37170d22d2588fd5af460c17156ce2",
            "@type": "ScholarlyArticle",
            "paperId": "fb39b1a73b37170d22d2588fd5af460c17156ce2",
            "corpusId": 40293387,
            "url": "https://www.semanticscholar.org/paper/fb39b1a73b37170d22d2588fd5af460c17156ce2",
            "title": "Survey on Computer Vision for UAVs: Current Developments and Trends",
            "venue": "J. Intell. Robotic Syst.",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2582222835",
                "DBLP": "journals/jirs/KanellakisN17",
                "DOI": "10.1007/s10846-017-0483-z",
                "CorpusId": 40293387
            },
            "abstract": null,
            "referenceCount": 149,
            "citationCount": 258,
            "influentialCitationCount": 11,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://link.springer.com/content/pdf/10.1007%2Fs10846-017-0483-z.pdf",
                "status": "HYBRID"
            },
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle",
                "Review"
            ],
            "publicationDate": "2017-07-01",
            "journal": {
                "name": "Journal of Intelligent & Robotic Systems",
                "volume": "87"
            },
            "citationStyles": {
                "bibtex": "@Article{Kanellakis2017SurveyOC,\n author = {C. Kanellakis and G. Nikolakopoulos},\n booktitle = {J. Intell. Robotic Syst.},\n journal = {Journal of Intelligent & Robotic Systems},\n pages = {141-168},\n title = {Survey on Computer Vision for UAVs: Current Developments and Trends},\n volume = {87},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:2d5a838da3cb3f60487fa7ce918960f0dc16c8c1",
            "@type": "ScholarlyArticle",
            "paperId": "2d5a838da3cb3f60487fa7ce918960f0dc16c8c1",
            "corpusId": 4304219,
            "url": "https://www.semanticscholar.org/paper/2d5a838da3cb3f60487fa7ce918960f0dc16c8c1",
            "title": "Sim4CV: A Photo-Realistic Simulator for Computer Vision Applications",
            "venue": "International Journal of Computer Vision",
            "publicationVenue": {
                "id": "urn:research:939ee07c-6009-43f8-b884-69238b40659e",
                "name": "International Journal of Computer Vision",
                "alternate_names": [
                    "Int J Comput Vis"
                ],
                "issn": "0920-5691",
                "url": "https://www.springer.com/computer/image+processing/journal/11263"
            },
            "year": 2017,
            "externalIds": {
                "MAG": "3098009429",
                "ArXiv": "1708.05869",
                "DBLP": "journals/corr/abs-1708-05869",
                "DOI": "10.1007/s11263-018-1073-7",
                "CorpusId": 4304219
            },
            "abstract": null,
            "referenceCount": 66,
            "citationCount": 147,
            "influentialCitationCount": 7,
            "isOpenAccess": true,
            "openAccessPdf": {
                "url": "https://arxiv.org/pdf/1708.05869",
                "status": "GREEN"
            },
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Computer Science",
                    "source": "external"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": [
                "JournalArticle"
            ],
            "publicationDate": "2017-08-19",
            "journal": {
                "name": "International Journal of Computer Vision",
                "volume": "126"
            },
            "citationStyles": {
                "bibtex": "@Article{M\u00fcller2017Sim4CVAP,\n author = {Matthias M\u00fcller and Vincent Casser and Jean Lahoud and Neil G. Smith and Bernard Ghanem},\n booktitle = {International Journal of Computer Vision},\n journal = {International Journal of Computer Vision},\n pages = {902 - 919},\n title = {Sim4CV: A Photo-Realistic Simulator for Computer Vision Applications},\n volume = {126},\n year = {2017}\n}\n"
            }
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@id": "urn:research:5b7582a523c17dda6dfb54b7cfd06be755296e75",
            "@type": "ScholarlyArticle",
            "paperId": "5b7582a523c17dda6dfb54b7cfd06be755296e75",
            "corpusId": 111935702,
            "url": "https://www.semanticscholar.org/paper/5b7582a523c17dda6dfb54b7cfd06be755296e75",
            "title": "Computer vision-based displacement and vibration monitoring without using physical target on structures",
            "venue": "Bridge Design, Assessment and Monitoring",
            "publicationVenue": {
                "id": null,
                "name": null,
                "alternate_names": null,
                "issn": null,
                "url": null
            },
            "year": 2017,
            "externalIds": {
                "MAG": "2338966209",
                "DOI": "10.1080/15732479.2016.1164729",
                "CorpusId": 111935702
            },
            "abstract": "Abstract Although vision-based methods for displacement and vibration monitoring have been used in civil engineering for more than a decade, most of these techniques require physical targets attached to the structures. This requirement makes computer vision-based monitoring for real-life structures cumbersome due to need to access certain critical locations. In this study, a non-target computer vision-based method for displacement and vibration measurement is proposed by exploring a new type of virtual markers instead of physical targets. The key points of measurement positions obtained using a robust computer vision technique named scale-invariant feature transform show a potential ability to take the place of classical targets. To calculate the converting ratio between pixel-based displacement and engineering unit (millimetre), a practical camera calibration method is developed to convert pixel-based displacements to engineering unit since a calibration standard (a target) is not available. Methods and approaches to handle challenges such as low contrast, changing illumination and outliers in matching key points are also presented. The proposed method is verified and demonstrated on the UCF four-span bridge model and on a real-life structure, with excellent results for both static and dynamic behaviour of the two structures. Finally, the method requires a simple, less complicated and more cost-effective hardware compared to conventional displacement and vibration monitoring measuring technologies.",
            "referenceCount": 25,
            "citationCount": 122,
            "influentialCitationCount": 7,
            "isOpenAccess": false,
            "openAccessPdf": null,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "s2FieldsOfStudy": [
                {
                    "category": "Engineering",
                    "source": "external"
                },
                {
                    "category": "Engineering",
                    "source": "s2-fos-model"
                },
                {
                    "category": "Computer Science",
                    "source": "s2-fos-model"
                }
            ],
            "publicationTypes": null,
            "publicationDate": "2017-04-03",
            "journal": {
                "name": "Structure and Infrastructure Engineering",
                "volume": "13"
            },
            "citationStyles": {
                "bibtex": "@Article{Khuc2017ComputerVD,\n author = {Tung Khuc and F. Catbas},\n booktitle = {Bridge Design, Assessment and Monitoring},\n journal = {Structure and Infrastructure Engineering},\n pages = {505 - 516},\n title = {Computer vision-based displacement and vibration monitoring without using physical target on structures},\n volume = {13},\n year = {2017}\n}\n"
            }
        }
    }
]