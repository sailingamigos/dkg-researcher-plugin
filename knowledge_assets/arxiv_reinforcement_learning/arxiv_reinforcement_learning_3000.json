[
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12017v1",
            "title": "Public-key pseudoentanglement and the hardness of learning ground state\n  entanglement structure",
            "updated": "2023-11-20T18:54:48Z",
            "published": "2023-11-20T18:54:48Z",
            "summary": "Given a local Hamiltonian, how difficult is it to determine the entanglement\nstructure of its ground state? We show that this problem is computationally\nintractable even if one is only trying to decide if the ground state is\nvolume-law vs near area-law entangled. We prove this by constructing strong\nforms of pseudoentanglement in a public-key setting, where the circuits used to\nprepare the states are public knowledge. In particular, we construct two\nfamilies of quantum circuits which produce volume-law vs near area-law\nentangled states, but nonetheless the classical descriptions of the circuits\nare indistinguishable under the Learning with Errors (LWE) assumption.\nIndistinguishability of the circuits then allows us to translate our\nconstruction to Hamiltonians. Our work opens new directions in Hamiltonian\ncomplexity, for example whether it is difficult to learn certain phases of\nmatter.",
            "author": [
                "Adam Bouland",
                "Bill Fefferman",
                "Soumik Ghosh",
                "Tony Metger",
                "Umesh Vazirani",
                "Chenyi Zhang",
                "Zixin Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12017v1",
                "http://arxiv.org/pdf/2311.12017v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CC",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12090v1",
            "title": "FrePolad: Frequency-Rectified Point Latent Diffusion for Point Cloud\n  Generation",
            "updated": "2023-11-20T18:43:31Z",
            "published": "2023-11-20T18:43:31Z",
            "summary": "We propose FrePolad: frequency-rectified point latent diffusion, a point\ncloud generation pipeline integrating a variational autoencoder (VAE) with a\ndenoising diffusion probabilistic model (DDPM) for the latent distribution.\nFrePolad simultaneously achieves high quality, diversity, and flexibility in\npoint cloud cardinality for generation tasks while maintaining high\ncomputational efficiency. The improvement in generation quality and diversity\nis achieved through (1) a novel frequency rectification module via spherical\nharmonics designed to retain high-frequency content while learning the point\ncloud distribution; and (2) a latent DDPM to learn the regularized yet complex\nlatent distribution. In addition, FrePolad supports variable point cloud\ncardinality by formulating the sampling of points as conditional distributions\nover a latent shape distribution. Finally, the low-dimensional latent space\nencoded by the VAE contributes to FrePolad's fast and scalable sampling. Our\nquantitative and qualitative results demonstrate the state-of-the-art\nperformance of FrePolad in terms of quality, diversity, and computational\nefficiency.",
            "author": [
                "Chenliang Zhou",
                "Fangcheng Zhong",
                "Param Hanji",
                "Zhilin Guo",
                "Kyle Fogarty",
                "Alejandro Sztrajman",
                "Hongyun Gao",
                "Cengiz Oztireli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12090v1",
                "http://arxiv.org/pdf/2311.12090v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12880v1",
            "title": "Weak-Form Latent Space Dynamics Identification",
            "updated": "2023-11-20T18:42:14Z",
            "published": "2023-11-20T18:42:14Z",
            "summary": "Recent work in data-driven modeling has demonstrated that a weak formulation\nof model equations enhances the noise robustness of a wide range of\ncomputational methods. In this paper, we demonstrate the power of the weak form\nto enhance the LaSDI (Latent Space Dynamics Identification) algorithm, a\nrecently developed data-driven reduced order modeling technique.\n  We introduce a weak form-based version WLaSDI (Weak-form Latent Space\nDynamics Identification). WLaSDI first compresses data, then projects onto the\ntest functions and learns the local latent space models. Notably, WLaSDI\ndemonstrates significantly enhanced robustness to noise. With WLaSDI, the local\nlatent space is obtained using weak-form equation learning techniques. Compared\nto the standard sparse identification of nonlinear dynamics (SINDy) used in\nLaSDI, the variance reduction of the weak form guarantees a robust and precise\nlatent space recovery, hence allowing for a fast, robust, and accurate\nsimulation. We demonstrate the efficacy of WLaSDI vs. LaSDI on several common\nbenchmark examples including viscid and inviscid Burgers', radial advection,\nand heat conduction. For instance, in the case of 1D inviscid Burgers'\nsimulations with the addition of up to 100% Gaussian white noise, the relative\nerror remains consistently below 6% for WLaSDI, while it can exceed 10,000% for\nLaSDI. Similarly, for radial advection simulations, the relative errors stay\nbelow 15% for WLaSDI, in stark contrast to the potential errors of up to\n10,000% with LaSDI. Moreover, speedups of several orders of magnitude can be\nobtained with WLaSDI. For example applying WLaSDI to 1D Burgers' yields a 140X\nspeedup compared to the corresponding full order model.\n  Python code to reproduce the results in this work is available at\n(https://github.com/MathBioCU/PyWSINDy_ODE) and\n(https://github.com/MathBioCU/PyWLaSDI).",
            "author": [
                "April Tran",
                "Xiaolong He",
                "Daniel A. Messenger",
                "Youngsoo Choi",
                "David M. Bortz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12880v1",
                "http://arxiv.org/pdf/2311.12880v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.CE",
                "cs.LG",
                "cs.NA",
                "cs.SY",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12004v1",
            "title": "Risk-averse Batch Active Inverse Reward Design",
            "updated": "2023-11-20T18:36:10Z",
            "published": "2023-11-20T18:36:10Z",
            "summary": "Designing a perfect reward function that depicts all the aspects of the\nintended behavior is almost impossible, especially generalizing it outside of\nthe training environments. Active Inverse Reward Design (AIRD) proposed the use\nof a series of queries, comparing possible reward functions in a single\ntraining environment. This allows the human to give information to the agent\nabout suboptimal behaviors, in order to compute a probability distribution over\nthe intended reward function. However, it ignores the possibility of unknown\nfeatures appearing in real-world environments, and the safety measures needed\nuntil the agent completely learns the reward function. I improved this method\nand created Risk-averse Batch Active Inverse Reward Design (RBAIRD), which\nconstructs batches, sets of environments the agent encounters when being used\nin the real world, processes them sequentially, and, for a predetermined number\nof iterations, asks queries that the human needs to answer for each environment\nof the batch. After this process is completed in one batch, the probabilities\nhave been improved and are transferred to the next batch. This makes it capable\nof adapting to real-world scenarios and learning how to treat unknown features\nit encounters for the first time. I also integrated a risk-averse planner,\nsimilar to that of Inverse Reward Design (IRD), which samples a set of reward\nfunctions from the probability distribution and computes a trajectory that\ntakes the most certain rewards possible. This ensures safety while the agent is\nstill learning the reward function, and enables the use of this approach in\nsituations where cautiousness is vital. RBAIRD outperformed the previous\napproaches in terms of efficiency, accuracy, and action certainty, demonstrated\nquick adaptability to new, unknown features, and can be more widely used for\nthe alignment of crucial, powerful AI models.",
            "author": [
                "Panagiotis Liampas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12004v1",
                "http://arxiv.org/pdf/2311.12004v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11995v3",
            "title": "BrainWash: A Poisoning Attack to Forget in Continual Learning",
            "updated": "2023-11-24T02:51:30Z",
            "published": "2023-11-20T18:26:01Z",
            "summary": "Continual learning has gained substantial attention within the deep learning\ncommunity, offering promising solutions to the challenging problem of\nsequential learning. Yet, a largely unexplored facet of this paradigm is its\nsusceptibility to adversarial attacks, especially with the aim of inducing\nforgetting. In this paper, we introduce \"BrainWash,\" a novel data poisoning\nmethod tailored to impose forgetting on a continual learner. By adding the\nBrainWash noise to a variety of baselines, we demonstrate how a trained\ncontinual learner can be induced to forget its previously learned tasks\ncatastrophically, even when using these continual learning baselines. An\nimportant feature of our approach is that the attacker requires no access to\nprevious tasks' data and is armed merely with the model's current parameters\nand the data belonging to the most recent task. Our extensive experiments\nhighlight the efficacy of BrainWash, showcasing degradation in performance\nacross various regularization-based continual learning methods.",
            "author": [
                "Ali Abbasi",
                "Parsa Nooralinejad",
                "Hamed Pirsiavash",
                "Soheil Kolouri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11995v3",
                "http://arxiv.org/pdf/2311.11995v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11992v1",
            "title": "Exploring Lip Segmentation Techniques in Computer Vision: A Comparative\n  Analysis",
            "updated": "2023-11-20T18:23:41Z",
            "published": "2023-11-20T18:23:41Z",
            "summary": "Lip segmentation is crucial in computer vision, especially for lip reading.\nDespite extensive face segmentation research, lip segmentation has received\nlimited attention. The aim of this study is to compare state-of-the-art lip\nsegmentation models using a standardized setting and a publicly available\ndataset. Five techniques, namely EHANet, Mask2Former, BiSeNet V2, PIDNet, and\nSTDC1, are qualitatively selected based on their reported performance,\ninference time, code availability, recency, and popularity. The CelebAMask-HQ\ndataset, comprising manually annotated face images, is used to fairly assess\nthe lip segmentation performance of the selected models. Inference experiments\nare conducted on a Raspberry Pi4 to emulate limited computational resources.\nThe results show that Mask2Former and EHANet have the best performances in\nterms of mIoU score. BiSeNet V2 demonstrate competitive performance, while\nPIDNet excels in recall but has lower precision. Most models present inference\ntime ranging from 1000 to around 3000 milliseconds on a Raspberry Pi4, with\nPIDNet having the lowest mean inference time. This study provides a\ncomprehensive evaluation of lip segmentation models, highlighting their\nperformance and inference times. The findings contribute to the development of\nlightweight techniques and establish benchmarks for future advances in lip\nsegmentation, especially in IoT and edge computing scenarios.",
            "author": [
                "Pietro B. S. Masur",
                "Francisco Braulio Oliveira",
                "Lucas Moreira Medino",
                "Emanuel Huber",
                "Milene Haraguchi Padilha",
                "Cassio de Alcantara",
                "Renata Sellaro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11992v1",
                "http://arxiv.org/pdf/2311.11992v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11990v1",
            "title": "Machine-Learned Atomic Cluster Expansion Potentials for Fast and\n  Quantum-Accurate Thermal Simulations of Wurtzite AlN",
            "updated": "2023-11-20T18:21:53Z",
            "published": "2023-11-20T18:21:53Z",
            "summary": "Using the atomic cluster expansion (ACE) framework, we develop a machine\nlearning interatomic potential for fast and accurately modelling the phonon\ntransport properties of wurtzite aluminum nitride. The predictive power of the\nACE potential against density functional theory (DFT) is demonstrated across a\nbroad range of properties of w-AlN, including ground-state lattice parameters,\nspecific heat capacity, coefficients of thermal expansion, bulk modulus, and\nharmonic phonon dispersions. Validation of lattice thermal conductivity is\nfurther carried out by comparing the ACE-predicted values to the DFT\ncalculations and experiments, exhibiting the overall capability of our ACE\npotential in sufficiently describing anharmonic phonon interactions. As a\npractical application, we perform a lattice dynamics analysis using the\npotential to unravel the effects of biaxial strains on thermal conductivity and\nphonon properties of w-AlN, which is identified as a significant tuning factor\nfor near-junction thermal design of w-AlN-based electronics.",
            "author": [
                "Guang Yang",
                "Yuan-Bin Liu",
                "Lei Yang",
                "Bing-Yang Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11990v1",
                "http://arxiv.org/pdf/2311.11990v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.LG",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11981v1",
            "title": "H-COAL: Human Correction of AI-Generated Labels for Biomedical Named\n  Entity Recognition",
            "updated": "2023-11-20T18:16:27Z",
            "published": "2023-11-20T18:16:27Z",
            "summary": "With the rapid advancement of machine learning models for NLP tasks,\ncollecting high-fidelity labels from AI models is a realistic possibility.\nFirms now make AI available to customers via predictions as a service (PaaS).\nThis includes PaaS products for healthcare. It is unclear whether these labels\ncan be used for training a local model without expensive annotation checking by\nin-house experts. In this work, we propose a new framework for Human Correction\nof AI-Generated Labels (H-COAL). By ranking AI-generated outputs, one can\nselectively correct labels and approach gold standard performance (100% human\nlabeling) with significantly less human effort. We show that correcting 5% of\nlabels can close the AI-human performance gap by up to 64% relative\nimprovement, and correcting 20% of labels can close the performance gap by up\nto 86% relative improvement.",
            "author": [
                "Xiaojing Duan",
                "John P. Lalor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11981v1",
                "http://arxiv.org/pdf/2311.11981v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11980v1",
            "title": "Leveraging Previous Facial Action Units Knowledge for Emotion\n  Recognition on Faces",
            "updated": "2023-11-20T18:14:53Z",
            "published": "2023-11-20T18:14:53Z",
            "summary": "People naturally understand emotions, thus permitting a machine to do the\nsame could open new paths for human-computer interaction. Facial expressions\ncan be very useful for emotion recognition techniques, as these are the biggest\ntransmitters of non-verbal cues capable of being correlated with emotions.\nSeveral techniques are based on Convolutional Neural Networks (CNNs) to extract\ninformation in a machine learning process. However, simple CNNs are not always\nsufficient to locate points of interest on the face that can be correlated with\nemotions. In this work, we intend to expand the capacity of emotion recognition\ntechniques by proposing the usage of Facial Action Units (AUs) recognition\ntechniques to recognize emotions. This recognition will be based on the Facial\nAction Coding System (FACS) and computed by a machine learning system. In\nparticular, our method expands over EmotiRAM, an approach for multi-cue emotion\nrecognition, in which we improve over their facial encoding module.",
            "author": [
                "Pietro B. S. Masur",
                "Willams Costa",
                "Lucas S. Figueredo",
                "Veronica Teichrieb"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11980v1",
                "http://arxiv.org/pdf/2311.11980v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12879v1",
            "title": "MiniAnDE: a reduced AnDE ensemble to deal with microarray data",
            "updated": "2023-11-20T18:12:55Z",
            "published": "2023-11-20T18:12:55Z",
            "summary": "This article focuses on the supervised classification of datasets with a\nlarge number of variables and a small number of instances. This is the case,\nfor example, for microarray data sets commonly used in bioinformatics. Complex\nclassifiers that require estimating statistics over many variables are not\nsuitable for this type of data. Probabilistic classifiers with low-order\nprobability tables, e.g. NB and AODE, are good alternatives for dealing with\nthis type of data. AODE usually improves NB in accuracy, but suffers from high\nspatial complexity since $k$ models, each with $n+1$ variables, are included in\nthe AODE ensemble. In this paper, we propose MiniAnDE, an algorithm that\nincludes only a small number of heterogeneous base classifiers in the ensemble,\ni.e., each model only includes a different subset of the $k$ predictive\nvariables. Experimental evaluation shows that using MiniAnDE classifiers on\nmicroarray data is feasible and outperforms NB and other ensembles such as\nbagging and random forest.",
            "author": [
                "Pablo Torrijos",
                "Jos\u00e9 A. G\u00e1mez",
                "Jos\u00e9 M. Puerta"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-34204-2_12",
                "http://arxiv.org/abs/2311.12879v1",
                "http://arxiv.org/pdf/2311.12879v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11979v1",
            "title": "On the Potential and Limitations of Few-Shot In-Context Learning to\n  Generate Metamorphic Specifications for Tax Preparation Software",
            "updated": "2023-11-20T18:12:28Z",
            "published": "2023-11-20T18:12:28Z",
            "summary": "Due to the ever-increasing complexity of income tax laws in the United\nStates, the number of US taxpayers filing their taxes using tax preparation\nsoftware (henceforth, tax software) continues to increase. According to the\nU.S. Internal Revenue Service (IRS), in FY22, nearly 50% of taxpayers filed\ntheir individual income taxes using tax software. Given the legal consequences\nof incorrectly filing taxes for the taxpayer, ensuring the correctness of tax\nsoftware is of paramount importance. Metamorphic testing has emerged as a\nleading solution to test and debug legal-critical tax software due to the\nabsence of correctness requirements and trustworthy datasets. The key idea\nbehind metamorphic testing is to express the properties of a system in terms of\nthe relationship between one input and its slightly metamorphosed twinned\ninput. Extracting metamorphic properties from IRS tax publications is a tedious\nand time-consuming process. As a response, this paper formulates the task of\ngenerating metamorphic specifications as a translation task between properties\nextracted from tax documents - expressed in natural language - to a contrastive\nfirst-order logic form. We perform a systematic analysis on the potential and\nlimitations of in-context learning with Large Language Models(LLMs) for this\ntask, and outline a research agenda towards automating the generation of\nmetamorphic specifications for tax preparation software.",
            "author": [
                "Dananjay Srinivas",
                "Rohan Das",
                "Saeid Tizpaz-Niari",
                "Ashutosh Trivedi",
                "Maria Leonor Pacheco"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11979v1",
                "http://arxiv.org/pdf/2311.11979v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14729v1",
            "title": "App for Resume-Based Job Matching with Speech Interviews and Grammar\n  Analysis: A Review",
            "updated": "2023-11-20T18:03:08Z",
            "published": "2023-11-20T18:03:08Z",
            "summary": "Through the advancement in natural language processing (NLP), specifically in\nspeech recognition, fully automated complex systems functioning on voice input\nhave started proliferating in areas such as home automation. These systems have\nbeen termed Automatic Speech Recognition Systems (ASR). In this review paper,\nwe explore the feasibility of an end-to-end system providing speech and text\nbased natural language processing for job interview preparation as well as\nrecommendation of relevant job postings. We also explore existing\nrecommender-based systems and note their limitations. This literature review\nwould help us identify the approaches and limitations of the various similar\nuse-cases of NLP technology for our upcoming project.",
            "author": [
                "Tanmay Kulkarni",
                "Yuvraj Pardeshi",
                "Yash Shah",
                "Vaishnvi Sakat",
                "Sapana Bhirud"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14729v1",
                "http://arxiv.org/pdf/2311.14729v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR",
                "cs.LG",
                "I.7.0; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11974v1",
            "title": "Evaluating Supervision Levels Trade-Offs for Infrared-Based People\n  Counting",
            "updated": "2023-11-20T18:02:20Z",
            "published": "2023-11-20T18:02:20Z",
            "summary": "Object detection models are commonly used for people counting (and\nlocalization) in many applications but require a dataset with costly bounding\nbox annotations for training. Given the importance of privacy in people\ncounting, these models rely more and more on infrared images, making the task\neven harder. In this paper, we explore how weaker levels of supervision can\naffect the performance of deep person counting architectures for image\nclassification and point-level localization. Our experiments indicate that\ncounting people using a CNN Image-Level model achieves competitive results with\nYOLO detectors and point-level models, yet provides a higher frame rate and a\nsimilar amount of model parameters.",
            "author": [
                "David Latortue",
                "Moetez Kdayem",
                "Fidel A Guerrero Pe\u00f1a",
                "Eric Granger",
                "Marco Pedersoli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11974v1",
                "http://arxiv.org/pdf/2311.11974v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11973v1",
            "title": "Adaptive Training Distributions with Scalable Online Bilevel\n  Optimization",
            "updated": "2023-11-20T18:01:29Z",
            "published": "2023-11-20T18:01:29Z",
            "summary": "Large neural networks pretrained on web-scale corpora are central to modern\nmachine learning. In this paradigm, the distribution of the large,\nheterogeneous pretraining data rarely matches that of the application domain.\nThis work considers modifying the pretraining distribution in the case where\none has a small sample of data reflecting the targeted test conditions. We\npropose an algorithm motivated by a recent formulation of this setting as an\nonline, bilevel optimization problem. With scalability in mind, our algorithm\nprioritizes computing gradients at training points which are likely to most\nimprove the loss on the targeted distribution. Empirically, we show that in\nsome cases this approach is beneficial over existing strategies from the domain\nadaptation literature but may not succeed in other cases. We propose a simple\ntest to evaluate when our approach can be expected to work well and point\ntowards further research to address current limitations.",
            "author": [
                "David Grangier",
                "Pierre Ablin",
                "Awni Hannun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11973v1",
                "http://arxiv.org/pdf/2311.11973v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12878v2",
            "title": "Adaptive Bayesian Learning with Action and State-Dependent Signal\n  Variance",
            "updated": "2023-11-28T18:29:09Z",
            "published": "2023-11-20T17:59:30Z",
            "summary": "This manuscript presents an advanced framework for Bayesian learning by\nincorporating action and state-dependent signal variances into decision-making\nmodels. This framework is pivotal in understanding complex data-feedback loops\nand decision-making processes in various economic systems. Through a series of\nexamples, we demonstrate the versatility of this approach in different\ncontexts, ranging from simple Bayesian updating in stable environments to\ncomplex models involving social learning and state-dependent uncertainties. The\npaper uniquely contributes to the understanding of the nuanced interplay\nbetween data, actions, outcomes, and the inherent uncertainty in economic\nmodels.",
            "author": [
                "Kaiwen Hou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12878v2",
                "http://arxiv.org/pdf/2311.12878v2"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG",
                "econ.EM",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11965v1",
            "title": "Provably Efficient CVaR RL in Low-rank MDPs",
            "updated": "2023-11-20T17:44:40Z",
            "published": "2023-11-20T17:44:40Z",
            "summary": "We study risk-sensitive Reinforcement Learning (RL), where we aim to maximize\nthe Conditional Value at Risk (CVaR) with a fixed risk tolerance $\\tau$. Prior\ntheoretical work studying risk-sensitive RL focuses on the tabular Markov\nDecision Processes (MDPs) setting. To extend CVaR RL to settings where state\nspace is large, function approximation must be deployed. We study CVaR RL in\nlow-rank MDPs with nonlinear function approximation. Low-rank MDPs assume the\nunderlying transition kernel admits a low-rank decomposition, but unlike prior\nlinear models, low-rank MDPs do not assume the feature or state-action\nrepresentation is known. We propose a novel Upper Confidence Bound (UCB)\nbonus-driven algorithm to carefully balance the interplay between exploration,\nexploitation, and representation learning in CVaR RL. We prove that our\nalgorithm achieves a sample complexity of $\\tilde{O}\\left(\\frac{H^7 A^2\nd^4}{\\tau^2 \\epsilon^2}\\right)$ to yield an $\\epsilon$-optimal CVaR, where $H$\nis the length of each episode, $A$ is the capacity of action space, and $d$ is\nthe dimension of representations. Computational-wise, we design a novel\ndiscretized Least-Squares Value Iteration (LSVI) algorithm for the CVaR\nobjective as the planning oracle and show that we can find the near-optimal\npolicy in a polynomial running time with a Maximum Likelihood Estimation\noracle. To our knowledge, this is the first provably efficient CVaR RL\nalgorithm in low-rank MDPs.",
            "author": [
                "Yulai Zhao",
                "Wenhao Zhan",
                "Xiaoyan Hu",
                "Ho-fung Leung",
                "Farzan Farnia",
                "Wen Sun",
                "Jason D. Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11965v1",
                "http://arxiv.org/pdf/2311.11965v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11963v1",
            "title": "What Can AutoML Do For Continual Learning?",
            "updated": "2023-11-20T17:43:09Z",
            "published": "2023-11-20T17:43:09Z",
            "summary": "This position paper outlines the potential of AutoML for incremental\n(continual) learning to encourage more research in this direction. Incremental\nlearning involves incorporating new data from a stream of tasks and\ndistributions to learn enhanced deep representations and adapt better to new\ntasks. However, a significant limitation of incremental learners is that most\ncurrent techniques freeze the backbone architecture, hyperparameters, and the\norder & structure of the learning tasks throughout the learning and adaptation\nprocess. We strongly believe that AutoML offers promising solutions to address\nthese limitations, enabling incremental learning to adapt to more diverse\nreal-world tasks. Therefore, instead of directly proposing a new method, this\npaper takes a step back by posing the question: \"What can AutoML do for\nincremental learning?\" We outline three key areas of research that can\ncontribute to making incremental learners more dynamic, highlighting concrete\nopportunities to apply AutoML methods in novel ways as well as entirely new\nchallenges for AutoML research.",
            "author": [
                "Mert Kilickaya",
                "Joaquin Vanschoren"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11963v1",
                "http://arxiv.org/pdf/2311.11963v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11961v1",
            "title": "NNG-Mix: Improving Semi-supervised Anomaly Detection with Pseudo-anomaly\n  Generation",
            "updated": "2023-11-20T17:38:35Z",
            "published": "2023-11-20T17:38:35Z",
            "summary": "Anomaly detection (AD) is essential in identifying rare and often critical\nevents in complex systems, finding applications in fields such as network\nintrusion detection, financial fraud detection, and fault detection in\ninfrastructure and industrial systems. While AD is typically treated as an\nunsupervised learning task due to the high cost of label annotation, it is more\npractical to assume access to a small set of labeled anomaly samples from\ndomain experts, as is the case for semi-supervised anomaly detection.\nSemi-supervised and supervised approaches can leverage such labeled data,\nresulting in improved performance. In this paper, rather than proposing a new\nsemi-supervised or supervised approach for AD, we introduce a novel algorithm\nfor generating additional pseudo-anomalies on the basis of the limited labeled\nanomalies and a large volume of unlabeled data. This serves as an augmentation\nto facilitate the detection of new anomalies. Our proposed algorithm, named\nNearest Neighbor Gaussian Mixup (NNG-Mix), efficiently integrates information\nfrom both labeled and unlabeled data to generate pseudo-anomalies. We compare\nthe performance of this novel algorithm with commonly applied augmentation\ntechniques, such as Mixup and Cutout. We evaluate NNG-Mix by training various\nexisting semi-supervised and supervised anomaly detection algorithms on the\noriginal training data along with the generated pseudo-anomalies. Through\nextensive experiments on 57 benchmark datasets in ADBench, reflecting different\ndata types, we demonstrate that NNG-Mix outperforms other data augmentation\nmethods. It yields significant performance improvements compared to the\nbaselines trained exclusively on the original training data. Notably, NNG-Mix\nyields up to 16.4%, 8.8%, and 8.0% improvements on Classical, CV, and NLP\ndatasets in ADBench. Our source code will be available at\nhttps://github.com/donghao51/NNG-Mix.",
            "author": [
                "Hao Dong",
                "Ga\u00ebtan Frusque",
                "Yue Zhao",
                "Eleni Chatzi",
                "Olga Fink"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11961v1",
                "http://arxiv.org/pdf/2311.11961v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11959v1",
            "title": "Correlated Attention in Transformers for Multivariate Time Series",
            "updated": "2023-11-20T17:35:44Z",
            "published": "2023-11-20T17:35:44Z",
            "summary": "Multivariate time series (MTS) analysis prevails in real-world applications\nsuch as finance, climate science and healthcare. The various self-attention\nmechanisms, the backbone of the state-of-the-art Transformer-based models,\nefficiently discover the temporal dependencies, yet cannot well capture the\nintricate cross-correlation between different features of MTS data, which\ninherently stems from complex dynamical systems in practice. To this end, we\npropose a novel correlated attention mechanism, which not only efficiently\ncaptures feature-wise dependencies, but can also be seamlessly integrated\nwithin the encoder blocks of existing well-known Transformers to gain\nefficiency improvement. In particular, correlated attention operates across\nfeature channels to compute cross-covariance matrices between queries and keys\nwith different lag values, and selectively aggregate representations at the\nsub-series level. This architecture facilitates automated discovery and\nrepresentation learning of not only instantaneous but also lagged\ncross-correlations, while inherently capturing time series auto-correlation.\nWhen combined with prevalent Transformer baselines, correlated attention\nmechanism constitutes a better alternative for encoder-only architectures,\nwhich are suitable for a wide range of tasks including imputation, anomaly\ndetection and classification. Extensive experiments on the aforementioned tasks\nconsistently underscore the advantages of correlated attention mechanism in\nenhancing base Transformer models, and demonstrate our state-of-the-art results\nin imputation, anomaly detection and classification.",
            "author": [
                "Quang Minh Nguyen",
                "Lam M. Nguyen",
                "Subhro Das"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11959v1",
                "http://arxiv.org/pdf/2311.11959v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11944v1",
            "title": "FinanceBench: A New Benchmark for Financial Question Answering",
            "updated": "2023-11-20T17:28:02Z",
            "published": "2023-11-20T17:28:02Z",
            "summary": "FinanceBench is a first-of-its-kind test suite for evaluating the performance\nof LLMs on open book financial question answering (QA). It comprises 10,231\nquestions about publicly traded companies, with corresponding answers and\nevidence strings. The questions in FinanceBench are ecologically valid and\ncover a diverse set of scenarios. They are intended to be clear-cut and\nstraightforward to answer to serve as a minimum performance standard. We test\n16 state of the art model configurations (including GPT-4-Turbo, Llama2 and\nClaude2, with vector stores and long context prompts) on a sample of 150 cases\nfrom FinanceBench, and manually review their answers (n=2,400). The cases are\navailable open-source. We show that existing LLMs have clear limitations for\nfinancial QA. Notably, GPT-4-Turbo used with a retrieval system incorrectly\nanswered or refused to answer 81% of questions. While augmentation techniques\nsuch as using longer context window to feed in relevant evidence improve\nperformance, they are unrealistic for enterprise settings due to increased\nlatency and cannot support larger financial documents. We find that all models\nexamined exhibit weaknesses, such as hallucinations, that limit their\nsuitability for use by enterprises.",
            "author": [
                "Pranab Islam",
                "Anand Kannappan",
                "Douwe Kiela",
                "Rebecca Qian",
                "Nino Scherrer",
                "Bertie Vidgen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11944v1",
                "http://arxiv.org/pdf/2311.11944v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CE",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11940v1",
            "title": "Characterisation of high velocity stars in the S-PLUS internal fourth\n  data release",
            "updated": "2023-11-20T17:22:35Z",
            "published": "2023-11-20T17:22:35Z",
            "summary": "In general, the atypical high velocity of some stars in the Galaxy can only\nbe explained by invoking acceleration mechanisms related to extreme\nastrophysical events in the Milky Way. Using astrometric data from Gaia and the\nphotometric information in 12 filters of the S-PLUS, we performed a kinematic,\ndynamical, and chemical analysis of 64 stars with galactocentric velocities\nhigher than 400 $\\mathrm{km\\,s}^{-1}$. All the stars are gravitationally bound\nto the Galaxy and exhibit halo kinematics. Some of the stars could be remnants\nof structures such as the Sequoia and the Gaia-Sausage/Enceladus. Supported by\norbital and chemical analysis, we identified Gaia DR3 5401875170994688896 as a\nstar likely to be originated at the centre of the Galaxy. Application of a\nmachine learning technique to the S-PLUS photometric data allows us to obtain\nvery good estimates of magnesium abundances for this sample of high velocity\nstars.",
            "author": [
                "F. Quispe-Huaynasi",
                "F. Roig",
                "V. M. Placco",
                "L. Beraldo e Silva",
                "S. Daflon",
                "C. B. Pereira",
                "A. Kanaan",
                "C. Mendes de Oliveira",
                "T. Ribeiro",
                "W. Schoenell"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11940v1",
                "http://arxiv.org/pdf/2311.11940v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11934v1",
            "title": "Estimation of entropy-regularized optimal transport maps between\n  non-compactly supported measures",
            "updated": "2023-11-20T17:18:21Z",
            "published": "2023-11-20T17:18:21Z",
            "summary": "This paper addresses the problem of estimating entropy-regularized optimal\ntransport (EOT) maps with squared-Euclidean cost between source and target\nmeasures that are subGaussian. In the case that the target measure is compactly\nsupported or strongly log-concave, we show that for a recently proposed\nin-sample estimator, the expected squared $L^2$-error decays at least as fast\nas $O(n^{-1/3})$ where $n$ is the sample size. For the general subGaussian case\nwe show that the expected $L^1$-error decays at least as fast as $O(n^{-1/6})$,\nand in both cases we have polynomial dependence on the regularization\nparameter. While these results are suboptimal compared to known results in the\ncase of compactness of both the source and target measures (squared $L^2$-error\nconverging at a rate $O(n^{-1})$) and for when the source is subGaussian while\nthe target is compactly supported (squared $L^2$-error converging at a rate\n$O(n^{-1/2})$), their importance lie in eliminating the compact support\nrequirements. The proof technique makes use of a bias-variance decomposition\nwhere the variance is controlled using standard concentration of measure\nresults and the bias is handled by T1-transport inequalities along with sample\ncomplexity results in estimation of EOT cost under subGaussian assumptions. Our\nexperimental results point to a looseness in controlling the variance terms and\nwe conclude by posing several open problems.",
            "author": [
                "Matthew Werenski",
                "James M. Murphy",
                "Shuchin Aeron"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11934v1",
                "http://arxiv.org/pdf/2311.11934v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.IT",
                "cs.LG",
                "math.IT",
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11932v1",
            "title": "Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review\n  from the Perspectives of Key Features of Data Analysis and AI Assurance",
            "updated": "2023-11-20T17:17:29Z",
            "published": "2023-11-20T17:17:29Z",
            "summary": "Background and objectives: By extracting this information, Machine or Deep\nLearning (ML/DL)-based autonomous data analysis tools can assist clinicians and\ncancer researchers in discovering patterns and relationships from complex data\nsets. Many DL-based analyses on ovarian cancer (OC) data have recently been\npublished. These analyses are highly diverse in various aspects of cancer\n(e.g., subdomain(s) and cancer type they address) and data analysis features.\nHowever, a comprehensive understanding of these analyses in terms of these\nfeatures and AI assurance (AIA) is currently lacking. This systematic review\naims to fill this gap by examining the existing literature and identifying\nimportant aspects of OC data analysis using DL, explicitly focusing on the key\nfeatures and AI assurance perspectives. Methods: The PRISMA framework was used\nto conduct comprehensive searches in three journal databases. Only studies\npublished between 2015 and 2023 in peer-reviewed journals were included in the\nanalysis. Results: In the review, a total of 96 DL-driven analyses were\nexamined. The findings reveal several important insights regarding DL-driven\novarian cancer data analysis: - Most studies 71% (68 out of 96) focused on\ndetection and diagnosis, while no study addressed the prediction and prevention\nof OC. - The analyses were predominantly based on samples from a non-diverse\npopulation (75% (72/96 studies)), limited to a geographic location or country.\n- Only a small proportion of studies (only 33% (32/96)) performed integrated\nanalyses, most of which used homogeneous data (clinical or omics). - Notably, a\nmere 8.3% (8/96) of the studies validated their models using external and\ndiverse data sets, highlighting the need for enhanced model validation, and -\nThe inclusion of AIA in cancer data analysis is in a very early stage; only\n2.1% (2/96) explicitly addressed AIA through explainability.",
            "author": [
                "Muta Tah Hira",
                "Mohammad A. Razzaque",
                "Mosharraf Sarker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11932v1",
                "http://arxiv.org/pdf/2311.11932v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11919v1",
            "title": "An Image is Worth Multiple Words: Multi-attribute Inversion for\n  Constrained Text-to-Image Synthesis",
            "updated": "2023-11-20T16:54:07Z",
            "published": "2023-11-20T16:54:07Z",
            "summary": "We consider the problem of constraining diffusion model outputs with a\nuser-supplied reference image. Our key objective is to extract multiple\nattributes (e.g., color, object, layout, style) from this single reference\nimage, and then generate new samples with them. One line of existing work\nproposes to invert the reference images into a single textual conditioning\nvector, enabling generation of new samples with this learned token. These\nmethods, however, do not learn multiple tokens that are necessary to condition\nmodel outputs on the multiple attributes noted above. Another line of\ntechniques expand the inversion space to learn multiple embeddings but they do\nthis only along the layer dimension (e.g., one per layer of the DDPM model) or\nthe timestep dimension (one for a set of timesteps in the denoising process),\nleading to suboptimal attribute disentanglement. To address the aforementioned\ngaps, the first contribution of this paper is an extensive analysis to\ndetermine which attributes are captured in which dimension of the denoising\nprocess. As noted above, we consider both the time-step dimension (in reverse\ndenoising) as well as the DDPM model layer dimension. We observe that often a\nsubset of these attributes are captured in the same set of model layers and/or\nacross same denoising timesteps. For instance, color and style are captured\nacross same U-Net layers, whereas layout and color are captured across same\ntimestep stages. Consequently, an inversion process that is designed only for\nthe time-step dimension or the layer dimension is insufficient to disentangle\nall attributes. This leads to our second contribution where we design a new\nmulti-attribute inversion algorithm, MATTE, with associated\ndisentanglement-enhancing regularization losses, that operates across both\ndimensions and explicitly leads to four disentangled tokens (color, style,\nlayout, and object).",
            "author": [
                "Aishwarya Agarwal",
                "Srikrishna Karanam",
                "Tripti Shukla",
                "Balaji Vasan Srinivasan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11919v1",
                "http://arxiv.org/pdf/2311.11919v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00034v1",
            "title": "Enhancing IoT Security via Automatic Network Traffic Analysis: The\n  Transition from Machine Learning to Deep Learning",
            "updated": "2023-11-20T16:48:50Z",
            "published": "2023-11-20T16:48:50Z",
            "summary": "This work provides a comparative analysis illustrating how Deep Learning (DL)\nsurpasses Machine Learning (ML) in addressing tasks within Internet of Things\n(IoT), such as attack classification and device-type identification. Our\napproach involves training and evaluating a DL model using a range of diverse\nIoT-related datasets, allowing us to gain valuable insights into how adaptable\nand practical these models can be when confronted with various IoT\nconfigurations. We initially convert the unstructured network traffic data from\nIoT networks, stored in PCAP files, into images by processing the packet data.\nThis conversion process adapts the data to meet the criteria of DL\nclassification methods. The experiments showcase the ability of DL to surpass\nthe constraints tied to manually engineered features, achieving superior\nresults in attack detection and maintaining comparable outcomes in device-type\nidentification. Additionally, a notable feature extraction time difference\nbecomes evident in the experiments: traditional methods require around 29\nmilliseconds per data packet, while DL accomplishes the same task in just 2.9\nmilliseconds. The significant time gap, DL's superior performance, and the\nrecognized limitations of manually engineered features, presents a compelling\ncall to action within the IoT community. This encourages us to shift from\nexploring new IoT features for each dataset to addressing the challenges of\nintegrating DL into IoT, making it a more efficient solution for real-world IoT\nscenarios.",
            "author": [
                "Mounia Hamidouche",
                "Eugeny Popko",
                "Bassem Ouni"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00034v1",
                "http://arxiv.org/pdf/2312.00034v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11913v2",
            "title": "Deep Calibration of Market Simulations using Neural Density Estimators\n  and Embedding Networks",
            "updated": "2023-11-27T17:17:39Z",
            "published": "2023-11-20T16:44:18Z",
            "summary": "The ability to construct a realistic simulator of financial exchanges,\nincluding reproducing the dynamics of the limit order book, can give insight\ninto many counterfactual scenarios, such as a flash crash, a margin call, or\nchanges in macroeconomic outlook. In recent years, agent-based models have been\ndeveloped that reproduce many features of an exchange, as summarised by a set\nof stylised facts and statistics. However, the ability to calibrate simulators\nto a specific period of trading remains an open challenge. In this work, we\ndevelop a novel approach to the calibration of market simulators by leveraging\nrecent advances in deep learning, specifically using neural density estimators\nand embedding networks. We demonstrate that our approach is able to correctly\nidentify high probability parameter sets, both when applied to synthetic and\nhistorical data, and without reliance on manually selected or weighted\nensembles of stylised facts.",
            "author": [
                "Namid R. Stillman",
                "Rory Baggott",
                "Justin Lyon",
                "Jianfei Zhang",
                "Dingqiu Zhu",
                "Tao Chen",
                "Perukrishnen Vytelingum"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11913v2",
                "http://arxiv.org/pdf/2311.11913v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-fin.CP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11911v1",
            "title": "Certification of Distributional Individual Fairness",
            "updated": "2023-11-20T16:41:54Z",
            "published": "2023-11-20T16:41:54Z",
            "summary": "Providing formal guarantees of algorithmic fairness is of paramount\nimportance to socially responsible deployment of machine learning algorithms.\nIn this work, we study formal guarantees, i.e., certificates, for individual\nfairness (IF) of neural networks. We start by introducing a novel convex\napproximation of IF constraints that exponentially decreases the computational\ncost of providing formal guarantees of local individual fairness. We highlight\nthat prior methods are constrained by their focus on global IF certification\nand can therefore only scale to models with a few dozen hidden neurons, thus\nlimiting their practical impact. We propose to certify distributional\nindividual fairness which ensures that for a given empirical distribution and\nall distributions within a $\\gamma$-Wasserstein ball, the neural network has\nguaranteed individually fair predictions. Leveraging developments in\nquasi-convex optimization, we provide novel and efficient certified bounds on\ndistributional individual fairness and show that our method allows us to\ncertify and regularize neural networks that are several orders of magnitude\nlarger than those considered by prior works. Moreover, we study real-world\ndistribution shifts and find our bounds to be a scalable, practical, and sound\nsource of IF guarantees.",
            "author": [
                "Matthew Wicker",
                "Vihari Piratia",
                "Adrian Weller"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11911v1",
                "http://arxiv.org/pdf/2311.11911v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11910v1",
            "title": "Generalization of Fitness Exercise Recognition from Doppler Measurements\n  by Domain-adaption and Few-Shot Learning",
            "updated": "2023-11-20T16:40:48Z",
            "published": "2023-11-20T16:40:48Z",
            "summary": "In previous works, a mobile application was developed using an unmodified\ncommercial off-the-shelf smartphone to recognize whole-body exercises. The\nworking principle was based on the ultrasound Doppler sensing with the device\nbuilt-in hardware. Applying such a lab-environment trained model on realistic\napplication variations causes a significant drop in performance, and thus\ndecimate its applicability. The reason of the reduced performance can be\nmanifold. It could be induced by the user, environment, and device variations\nin realistic scenarios. Such scenarios are often more complex and diverse,\nwhich can be challenging to anticipate in the initial training data. To study\nand overcome this issue, this paper presents a database with controlled and\nuncontrolled subsets of fitness exercises. We propose two concepts to utilize\nsmall adaption data to successfully improve model generalization in an\nuncontrolled environment, increasing the recognition accuracy by two to six\nfolds compared to the baseline for different users.",
            "author": [
                "Biying Fu",
                "Naser Damer",
                "Florian Kirchbuchner",
                "Arjan Kuijper"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11910v1",
                "http://arxiv.org/pdf/2311.11910v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11908v2",
            "title": "Continual Learning: Applications and the Road Forward",
            "updated": "2023-11-21T15:17:00Z",
            "published": "2023-11-20T16:40:29Z",
            "summary": "Continual learning is a sub-field of machine learning, which aims to allow\nmachine learning models to continuously learn on new data, by accumulating\nknowledge without forgetting what was learned in the past. In this work, we\ntake a step back, and ask: \"Why should one care about continual learning in the\nfirst place?\". We set the stage by surveying recent continual learning papers\npublished at three major machine learning conferences, and show that\nmemory-constrained settings dominate the field. Then, we discuss five open\nproblems in machine learning, and even though they seem unrelated to continual\nlearning at first sight, we show that continual learning will inevitably be\npart of their solution. These problems are model-editing, personalization,\non-device learning, faster (re-)training and reinforcement learning. Finally,\nby comparing the desiderata from these unsolved problems and the current\nassumptions in continual learning, we highlight and discuss four future\ndirections for continual learning research. We hope that this work offers an\ninteresting perspective on the future of continual learning, while displaying\nits potential value and the paths we have to pursue in order to make it\nsuccessful. This work is the result of the many discussions the authors had at\nthe Dagstuhl seminar on Deep Continual Learning, in March 2023.",
            "author": [
                "Eli Verwimp",
                "Rahaf Aljundi",
                "Shai Ben-David",
                "Matthias Bethge",
                "Andrea Cossu",
                "Alexander Gepperth",
                "Tyler L. Hayes",
                "Eyke H\u00fcllermeier",
                "Christopher Kanan",
                "Dhireesha Kudithipudi",
                "Christoph H. Lampert",
                "Martin Mundt",
                "Razvan Pascanu",
                "Adrian Popescu",
                "Andreas S. Tolias",
                "Joost van de Weijer",
                "Bing Liu",
                "Vincenzo Lomonaco",
                "Tinne Tuytelaars",
                "Gido M. van de Ven"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11908v2",
                "http://arxiv.org/pdf/2311.11908v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11905v2",
            "title": "Real-Time Surface-to-Air Missile Engagement Zone Prediction Using\n  Simulation and Machine Learning",
            "updated": "2023-12-05T01:50:27Z",
            "published": "2023-11-20T16:38:45Z",
            "summary": "Surface-to-Air Missiles (SAMs) are crucial in modern air defense systems. A\ncritical aspect of their effectiveness is the Engagement Zone (EZ), the spatial\nregion within which a SAM can effectively engage and neutralize a target.\nNotably, the EZ is intrinsically related to the missile's maximum range; it\ndefines the furthest distance at which a missile can intercept a target. The\naccurate computation of this EZ is essential but challenging due to the dynamic\nand complex factors involved, which often lead to high computational costs and\nextended processing times when using conventional simulation methods. In light\nof these challenges, our study investigates the potential of machine learning\ntechniques, proposing an approach that integrates machine learning with a\ncustom-designed simulation tool to train supervised algorithms. We leverage a\ncomprehensive dataset of pre-computed SAM EZ simulations, enabling our model to\naccurately predict the SAM EZ for new input parameters. It accelerates SAM EZ\nsimulations, enhances air defense strategic planning, and provides real-time\ninsights, improving SAM system performance. The study also includes a\ncomparative analysis of machine learning algorithms, illuminating their\ncapabilities and performance metrics and suggesting areas for future research,\nhighlighting the transformative potential of machine learning in SAM EZ\nsimulations.",
            "author": [
                "Joao P. A. Dantas",
                "Diego Geraldo",
                "Felipe L. L. Medeiros",
                "Marcos R. O. A. Maximo",
                "Takashi Yoneyama"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11905v2",
                "http://arxiv.org/pdf/2311.11905v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11904v1",
            "title": "LLMs as Visual Explainers: Advancing Image Classification with Evolving\n  Visual Descriptions",
            "updated": "2023-11-20T16:37:45Z",
            "published": "2023-11-20T16:37:45Z",
            "summary": "Vision-language models (VLMs) offer a promising paradigm for image\nclassification by comparing the similarity between images and class embeddings.\nA critical challenge lies in crafting precise textual representations for class\nnames. While previous studies have leveraged recent advancements in large\nlanguage models (LLMs) to enhance these descriptors, their outputs often suffer\nfrom ambiguity and inaccuracy. We identify two primary causes: 1) The prevalent\nreliance on textual interactions with LLMs, leading to a mismatch between the\ngenerated text and the visual content in VLMs' latent space - a phenomenon we\nterm the \"explain without seeing\" dilemma. 2) The oversight of the inter-class\nrelationships, resulting in descriptors that fail to differentiate similar\nclasses effectively. To address these issues, we propose a novel image\nclassification framework combining VLMs with LLMs, named Iterative Optimization\nwith Visual Feedback. In particular, our method develops an LLM-based agent,\nemploying an evolutionary optimization strategy to refine class descriptors.\nCrucially, we incorporate visual feedback from VLM classification metrics,\nthereby guiding the optimization process with concrete visual data. Our method\nleads to improving accuracy on a wide range of image classification benchmarks,\nwith 3.47\\% average gains over state-of-the-art methods. We also highlight the\nresulting descriptions serve as explainable and robust features that can\nconsistently improve the performance across various backbone models.",
            "author": [
                "Songhao Han",
                "Le Zhuo",
                "Yue Liao",
                "Si Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11904v1",
                "http://arxiv.org/pdf/2311.11904v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11900v1",
            "title": "Measuring and Mitigating Biases in Motor Insurance Pricing",
            "updated": "2023-11-20T16:34:48Z",
            "published": "2023-11-20T16:34:48Z",
            "summary": "The non-life insurance sector operates within a highly competitive and\ntightly regulated framework, confronting a pivotal juncture in the formulation\nof pricing strategies. Insurers are compelled to harness a range of statistical\nmethodologies and available data to construct optimal pricing structures that\nalign with the overarching corporate strategy while accommodating the dynamics\nof market competition. Given the fundamental societal role played by insurance,\npremium rates are subject to rigorous scrutiny by regulatory authorities. These\nrates must conform to principles of transparency, explainability, and ethical\nconsiderations. Consequently, the act of pricing transcends mere statistical\ncalculations and carries the weight of strategic and societal factors. These\nmultifaceted concerns may drive insurers to establish equitable premiums,\ntaking into account various variables. For instance, regulations mandate the\nprovision of equitable premiums, considering factors such as policyholder\ngender or mutualist group dynamics in accordance with respective corporate\nstrategies. Age-based premium fairness is also mandated. In certain insurance\ndomains, variables such as the presence of serious illnesses or disabilities\nare emerging as new dimensions for evaluating fairness. Regardless of the\nmotivating factor prompting an insurer to adopt fairer pricing strategies for a\nspecific variable, the insurer must possess the capability to define, measure,\nand ultimately mitigate any ethical biases inherent in its pricing practices\nwhile upholding standards of consistency and performance. This study seeks to\nprovide a comprehensive set of tools for these endeavors and assess their\neffectiveness through practical application in the context of automobile\ninsurance.",
            "author": [
                "Mulah Moriah",
                "Franck Vermet",
                "Arthur Charpentier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11900v1",
                "http://arxiv.org/pdf/2311.11900v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11892v1",
            "title": "Multimodal Characterization of Emotion within Multimedia Space",
            "updated": "2023-11-20T16:25:23Z",
            "published": "2023-11-20T16:25:23Z",
            "summary": "Technological advancement and its omnipresent connection have pushed humans\npast the boundaries and limitations of a computer screen, physical state, or\ngeographical location. It has provided a depth of avenues that facilitate\nhuman-computer interaction that was once inconceivable such as audio and body\nlanguage detection. Given the complex modularities of emotions, it becomes\nvital to study human-computer interaction, as it is the commencement of a\nthorough understanding of the emotional state of users and, in the context of\nsocial networks, the producers of multimodal information. This study first\nacknowledges the accuracy of classification found within multimodal emotion\ndetection systems compared to unimodal solutions. Second, it explores the\ncharacterization of multimedia content produced based on their emotions and the\ncoherence of emotion in different modalities by utilizing deep learning models\nto classify emotion across different modalities.",
            "author": [
                "Dayo Samuel Banjo",
                "Connice Trimmingham",
                "Niloofar Yousefi",
                "Nitin Agarwal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11892v1",
                "http://arxiv.org/pdf/2311.11892v1"
            ],
            "primary_category": "cs.MM",
            "category": [
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11891v1",
            "title": "AMES: A Differentiable Embedding Space Selection Framework for Latent\n  Graph Inference",
            "updated": "2023-11-20T16:24:23Z",
            "published": "2023-11-20T16:24:23Z",
            "summary": "In real-world scenarios, although data entities may possess inherent\nrelationships, the specific graph illustrating their connections might not be\ndirectly accessible. Latent graph inference addresses this issue by enabling\nGraph Neural Networks (GNNs) to operate on point cloud data, dynamically\nlearning the necessary graph structure. These graphs are often derived from a\nlatent embedding space, which can be modeled using Euclidean, hyperbolic,\nspherical, or product spaces. However, currently, there is no principled\ndifferentiable method for determining the optimal embedding space. In this\nwork, we introduce the Attentional Multi-Embedding Selection (AMES) framework,\na differentiable method for selecting the best embedding space for latent graph\ninference through backpropagation, considering a downstream task. Our framework\nconsistently achieves comparable or superior results compared to previous\nmethods for latent graph inference across five benchmark datasets. Importantly,\nour approach eliminates the need for conducting multiple experiments to\nidentify the optimal embedding space. Furthermore, we explore interpretability\ntechniques that track the gradient contributions of different latent graphs,\nshedding light on how our attention-based, fully differentiable approach learns\nto choose the appropriate latent space. In line with previous works, our\nexperiments emphasize the advantages of hyperbolic spaces in enhancing\nperformance. More importantly, our interpretability framework provides a\ngeneral approach for quantitatively comparing embedding spaces across different\ntasks based on their contributions, a dimension that has been overlooked in\nprevious literature on latent graph inference.",
            "author": [
                "Yuan Lu",
                "Haitz S\u00e1ez de Oc\u00e1riz Borde",
                "Pietro Li\u00f2"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11891v1",
                "http://arxiv.org/pdf/2311.11891v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11890v1",
            "title": "A Modular Approach to Unclonable Cryptography",
            "updated": "2023-11-20T16:22:52Z",
            "published": "2023-11-20T16:22:52Z",
            "summary": "We explore a new pathway to designing unclonable cryptographic primitives. We\npropose a new notion called unclonable puncturable obfuscation (UPO) and study\nits implications for unclonable cryptography. Using UPO, we present modular\n(and arguably, simple) constructions of many primitives in unclonable\ncryptography, including public-key quantum money, quantum copy-protection for\nmany classes of functionalities, unclonable encryption, and single-decryption\nencryption. Notably, we obtain the following new results assuming the existence\nof UPO: We show that any cryptographic functionality can be copy-protected as\nlong as this functionality satisfies a notion of security, which we term as\npuncturable security. Prior feasibility results focused on copy-protecting\nspecific cryptographic functionalities. We show that copy-protection exists for\nany class of evasive functions as long as the associated distribution satisfies\na preimage-sampleability condition. Prior works demonstrated copy-protection\nfor point functions, which follows as a special case of our result. We show\nthat unclonable encryption exists in the plain model. Prior works demonstrated\nfeasibility results in the quantum random oracle model. We put forward a\ncandidate construction of UPO and prove two notions of security, each based on\nthe existence of (post-quantum) sub-exponentially secure indistinguishability\nobfuscation and one-way functions, the quantum hardness of learning with\nerrors, and a new conjecture called simultaneous inner product conjecture.",
            "author": [
                "Prabhanjan Ananth",
                "Amit Behera"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11890v1",
                "http://arxiv.org/pdf/2311.11890v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11883v1",
            "title": "Efficient Neural Networks for Tiny Machine Learning: A Comprehensive\n  Review",
            "updated": "2023-11-20T16:20:13Z",
            "published": "2023-11-20T16:20:13Z",
            "summary": "The field of Tiny Machine Learning (TinyML) has gained significant attention\ndue to its potential to enable intelligent applications on resource-constrained\ndevices. This review provides an in-depth analysis of the advancements in\nefficient neural networks and the deployment of deep learning models on\nultra-low power microcontrollers (MCUs) for TinyML applications. It begins by\nintroducing neural networks and discussing their architectures and resource\nrequirements. It then explores MEMS-based applications on ultra-low power MCUs,\nhighlighting their potential for enabling TinyML on resource-constrained\ndevices. The core of the review centres on efficient neural networks for\nTinyML. It covers techniques such as model compression, quantization, and\nlow-rank factorization, which optimize neural network architectures for minimal\nresource utilization on MCUs. The paper then delves into the deployment of deep\nlearning models on ultra-low power MCUs, addressing challenges such as limited\ncomputational capabilities and memory resources. Techniques like model pruning,\nhardware acceleration, and algorithm-architecture co-design are discussed as\nstrategies to enable efficient deployment. Lastly, the review provides an\noverview of current limitations in the field, including the trade-off between\nmodel complexity and resource constraints. Overall, this review paper presents\na comprehensive analysis of efficient neural networks and deployment strategies\nfor TinyML on ultra-low-power MCUs. It identifies future research directions\nfor unlocking the full potential of TinyML applications on resource-constrained\ndevices.",
            "author": [
                "Minh Tri L\u00ea",
                "Pierre Wolinski",
                "Julyan Arbel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11883v1",
                "http://arxiv.org/pdf/2311.11883v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11882v1",
            "title": "Multi-Task Faces (MTF) Data Set: A Legally and Ethically Compliant\n  Collection of Face Images for Various Classification Tasks",
            "updated": "2023-11-20T16:19:46Z",
            "published": "2023-11-20T16:19:46Z",
            "summary": "Human facial data hold tremendous potential to address a variety of\nclassification problems, including face recognition, age estimation, gender\nidentification, emotion analysis, and race classification. However, recent\nprivacy regulations, such as the EU General Data Protection Regulation and\nothers, have restricted the ways in which human images may be collected and\nused for research. As a result, several previously published data sets\ncontaining human faces have been removed from the internet due to inadequate\ndata collection methods that failed to meet privacy regulations. Data sets\nconsisting of synthetic data have been proposed as an alternative, but they\nfall short of accurately representing the real data distribution. On the other\nhand, most available data sets are labeled for just a single task, which limits\ntheir applicability. To address these issues, we present the Multi-Task Faces\n(MTF) image data set, a meticulously curated collection of face images designed\nfor various classification tasks, including face recognition, as well as race,\ngender, and age classification. The MTF data set has been ethically gathered by\nleveraging publicly available images of celebrities and strictly adhering to\ncopyright regulations. In this paper, we present this data set and provide\ndetailed descriptions of the followed data collection and processing\nprocedures. Furthermore, we evaluate the performance of five deep learning (DL)\nmodels on the MTF data set across the aforementioned classification tasks.\nAdditionally, we compare the performance of DL models over the processed MTF\ndata and over raw data crawled from the internet. The reported results\nconstitute a baseline for further research employing these data. The MTF data\nset can be accessed through the following link (please cite the present paper\nif you use the data set): https://github.com/RamiHaf/MTF_data_set",
            "author": [
                "Rami Haffar",
                "David S\u00e1nchez",
                "Josep Domingo-Ferrer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11882v1",
                "http://arxiv.org/pdf/2311.11882v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11876v2",
            "title": "Forward Gradients for Data-Driven CFD Wall Modeling",
            "updated": "2023-11-28T18:36:13Z",
            "published": "2023-11-20T16:12:34Z",
            "summary": "Computational Fluid Dynamics (CFD) is used in the design and optimization of\ngas turbines and many other industrial/ scientific applications. However, the\npractical use is often limited by the high computational cost, and the accurate\nresolution of near-wall flow is a significant contributor to this cost. Machine\nlearning (ML) and other data-driven methods can complement existing wall\nmodels. Nevertheless, training these models is bottlenecked by the large\ncomputational effort and memory footprint demanded by back-propagation. Recent\nwork has presented alternatives for computing gradients of neural networks\nwhere a separate forward and backward sweep is not needed and storage of\nintermediate results between sweeps is not required because an unbiased\nestimator for the gradient is computed in a single forward sweep. In this\npaper, we discuss the application of this approach for training a subgrid wall\nmodel that could potentially be used as a surrogate in wall-bounded flow CFD\nsimulations to reduce the computational overhead while preserving predictive\naccuracy.",
            "author": [
                "Jan H\u00fcckelheim",
                "Tadbhagya Kumar",
                "Krishnan Raghavan",
                "Pinaki Pal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11876v2",
                "http://arxiv.org/pdf/2311.11876v2"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12089v2",
            "title": "Explaining Deep Learning Models for Age-related Gait Classification\n  based on time series acceleration",
            "updated": "2023-11-28T14:15:33Z",
            "published": "2023-11-20T16:09:06Z",
            "summary": "Gait analysis holds significant importance in monitoring daily health,\nparticularly among older adults. Advancements in sensor technology enable the\ncapture of movement in real-life environments and generate big data. Machine\nlearning, notably deep learning (DL), shows promise to use these big data in\ngait analysis. However, the inherent black-box nature of these models poses\nchallenges for their clinical application. This study aims to enhance\ntransparency in DL-based gait classification for aged-related gait patterns\nusing Explainable Artificial Intelligence, such as SHAP.\n  A total of 244 subjects, comprising 129 adults and 115 older adults (age>65),\nwere included. They performed a 3-minute walking task while accelerometers were\naffixed to the lumbar segment L3. DL models, convolutional neural network (CNN)\nand gated recurrent unit (GRU), were trained using 1-stride and 8-stride\naccelerations, respectively, to classify adult and older adult groups. SHAP was\nemployed to explain the models' predictions.\n  CNN achieved a satisfactory performance with an accuracy of 81.4% and an AUC\nof 0.89, and GRU demonstrated promising results with an accuracy of 84.5% and\nan AUC of 0.94. SHAP analysis revealed that both CNN and GRU assigned higher\nSHAP values to the data from vertical and walking directions, particularly\nemphasizing data around heel contact, spanning from the terminal swing to\nloading response phases. Furthermore, SHAP values indicated that GRU did not\ntreat every stride equally.\n  CNN accurately distinguished between adults and older adults based on the\ncharacteristics of a single stride's data. GRU achieved accurate classification\nby considering the relationships and subtle differences between strides. In\nboth models, data around heel contact emerged as most critical, suggesting\ndifferences in acceleration and deceleration patterns during walking between\ndifferent age groups.",
            "author": [
                "Xiaoping Zheng",
                "Bert Otten",
                "Michiel F Reneman",
                "Claudine JC Lamoth"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12089v2",
                "http://arxiv.org/pdf/2311.12089v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11871v1",
            "title": "Training robust and generalizable quantum models",
            "updated": "2023-11-20T16:06:35Z",
            "published": "2023-11-20T16:06:35Z",
            "summary": "Adversarial robustness and generalization are both crucial properties of\nreliable machine learning models. In this paper, we study these properties in\nthe context of quantum machine learning based on Lipschitz bounds. We derive\ntailored, parameter-dependent Lipschitz bounds for quantum models with\ntrainable encoding, showing that the norm of the data encoding has a crucial\nimpact on the robustness against perturbations in the input data. Further, we\nderive a bound on the generalization error which explicitly depends on the\nparameters of the data encoding. Our theoretical findings give rise to a\npractical strategy for training robust and generalizable quantum models by\nregularizing the Lipschitz bound in the cost. Further, we show that, for fixed\nand non-trainable encodings as frequently employed in quantum machine learning,\nthe Lipschitz bound cannot be influenced by tuning the parameters. Thus,\ntrainable encodings are crucial for systematically adapting robustness and\ngeneralization during training. With numerical results, we demonstrate that,\nindeed, Lipschitz bound regularization leads to substantially more robust and\ngeneralizable quantum models.",
            "author": [
                "Julian Berberich",
                "Daniel Fink",
                "Daniel Pranji\u0107",
                "Christian Tutschku",
                "Christian Holm"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11871v1",
                "http://arxiv.org/pdf/2311.11871v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11862v1",
            "title": "Establishing Central Sensitization Inventory Cut-off Values in patients\n  with Chronic Low Back Pain by Unsupervised Machine Learning",
            "updated": "2023-11-20T15:57:49Z",
            "published": "2023-11-20T15:57:49Z",
            "summary": "Human Assumed Central Sensitization is involved in the development and\nmaintenance of chronic low back pain (CLBP). The Central Sensitization\nInventory (CSI) was developed to evaluate the presence of HACS, with a cut-off\nvalue of 40/100 based on patients with chronic pain. However, various factors\nincluding pain conditions (e.g., CLBP), and gender may influence this cut-off\nvalue. For chronic pain condition such as CLBP, unsupervised clustering\napproaches can take these factors into consideration and automatically learn\nthe HACS-related patterns. Therefore, this study aimed to determine the cut-off\nvalues for a Dutch-speaking population with CLBP, considering the total group\nand stratified by gender based on unsupervised machine learning. In this study,\nquestionnaire data covering pain, physical, and psychological aspects were\ncollected from patients with CLBP and aged-matched pain-free adults (referred\nto as healthy controls, HC). Four clustering approaches were applied to\nidentify HACS-related clusters based on the questionnaire data and gender. The\nclustering performance was assessed using internal and external indicators.\nSubsequently, receiver operating characteristic analysis was conducted on the\nbest clustering results to determine the optimal cut-off values. The study\nincluded 151 subjects, consisting of 63 HCs and 88 patients with CLBP.\nHierarchical clustering yielded the best results, identifying three clusters:\nhealthy group, CLBP with low HACS level, and CLBP with high HACS level groups.\nBased on the low HACS levels group (including HC and CLBP with low HACS level)\nand high HACS level group, the cut-off value for the overall groups were 35, 34\nfor females, and 35 for. The findings suggest that the optimal cut-off values\nfor CLBP is 35. The gender-related cut-off values should be interpreted with\ncaution due to the unbalanced gender distribution in the sample.",
            "author": [
                "Xiaoping Zheng",
                "Claudine JC Lamoth",
                "Hans Timmerman",
                "Ebert Otten",
                "Michiel F Reneman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11862v1",
                "http://arxiv.org/pdf/2311.11862v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11861v1",
            "title": "Generating Valid and Natural Adversarial Examples with Large Language\n  Models",
            "updated": "2023-11-20T15:57:04Z",
            "published": "2023-11-20T15:57:04Z",
            "summary": "Deep learning-based natural language processing (NLP) models, particularly\npre-trained language models (PLMs), have been revealed to be vulnerable to\nadversarial attacks. However, the adversarial examples generated by many\nmainstream word-level adversarial attack models are neither valid nor natural,\nleading to the loss of semantic maintenance, grammaticality, and human\nimperceptibility. Based on the exceptional capacity of language understanding\nand generation of large language models (LLMs), we propose LLM-Attack, which\naims at generating both valid and natural adversarial examples with LLMs. The\nmethod consists of two stages: word importance ranking (which searches for the\nmost vulnerable words) and word synonym replacement (which substitutes them\nwith their synonyms obtained from LLMs). Experimental results on the Movie\nReview (MR), IMDB, and Yelp Review Polarity datasets against the baseline\nadversarial attack models illustrate the effectiveness of LLM-Attack, and it\noutperforms the baselines in human and GPT-4 evaluation by a significant\nmargin. The model can generate adversarial examples that are typically valid\nand natural, with the preservation of semantic meaning, grammaticality, and\nhuman imperceptibility.",
            "author": [
                "Zimu Wang",
                "Wei Wang",
                "Qi Chen",
                "Qiufeng Wang",
                "Anh Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11861v1",
                "http://arxiv.org/pdf/2311.11861v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11847v1",
            "title": "Deep learning complete intersection Calabi-Yau manifolds",
            "updated": "2023-11-20T15:37:39Z",
            "published": "2023-11-20T15:37:39Z",
            "summary": "We review advancements in deep learning techniques for complete intersection\nCalabi-Yau (CICY) 3- and 4-folds, with the aim of understanding better how to\nhandle algebraic topological data with machine learning. We first discuss\nmethodological aspects and data analysis, before describing neural networks\narchitectures. Then, we describe the state-of-the art accuracy in predicting\nHodge numbers. We include new results on extrapolating predictions from low to\nhigh Hodge numbers, and conversely.",
            "author": [
                "Harold Erbin",
                "Riccardo Finotello"
            ],
            "link": [
                "http://dx.doi.org/10.1142/9781800613706_0005",
                "http://arxiv.org/abs/2311.11847v1",
                "http://arxiv.org/pdf/2311.11847v1"
            ],
            "primary_category": "hep-th",
            "category": [
                "hep-th",
                "cs.LG",
                "math.AG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11846v1",
            "title": "Deepparse : An Extendable, and Fine-Tunable State-Of-The-Art Library for\n  Parsing Multinational Street Addresses",
            "updated": "2023-11-20T15:37:33Z",
            "published": "2023-11-20T15:37:33Z",
            "summary": "Segmenting an address into meaningful components, also known as address\nparsing, is an essential step in many applications from record linkage to\ngeocoding and package delivery. Consequently, a lot of work has been dedicated\nto develop accurate address parsing techniques, with machine learning and\nneural network methods leading the state-of-the-art scoreboard. However, most\nof the work on address parsing has been confined to academic endeavours with\nlittle availability of free and easy-to-use open-source solutions.\n  This paper presents Deepparse, a Python open-source, extendable, fine-tunable\naddress parsing solution under LGPL-3.0 licence to parse multinational\naddresses using state-of-the-art deep learning algorithms and evaluated on over\n60 countries. It can parse addresses written in any language and use any\naddress standard. The pre-trained model achieves average $99~\\%$ parsing\naccuracies on the countries used for training with no pre-processing nor\npost-processing needed. Moreover, the library supports fine-tuning with new\ndata to generate a custom address parser.",
            "author": [
                "David Beauchemin",
                "Marouane Yassine"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11846v1",
                "http://arxiv.org/pdf/2311.11846v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00799v1",
            "title": "hvEEGNet: exploiting hierarchical VAEs on EEG data for neuroscience\n  applications",
            "updated": "2023-11-20T15:36:31Z",
            "published": "2023-11-20T15:36:31Z",
            "summary": "With the recent success of artificial intelligence in neuroscience, a number\nof deep learning (DL) models were proposed for classification, anomaly\ndetection, and pattern recognition tasks in electroencephalography (EEG). EEG\nis a multi-channel time-series that provides information about the individual\nbrain activity for diagnostics, neuro-rehabilitation, and other applications\n(including emotions recognition). Two main issues challenge the existing\nDL-based modeling methods for EEG: the high variability between subjects and\nthe low signal-to-noise ratio making it difficult to ensure a good quality in\nthe EEG data. In this paper, we propose two variational autoencoder models,\nnamely vEEGNet-ver3 and hvEEGNet, to target the problem of high-fidelity EEG\nreconstruction. We properly designed their architectures using the blocks of\nthe well-known EEGNet as the encoder, and proposed a loss function based on\ndynamic time warping. We tested the models on the public Dataset 2a - BCI\nCompetition IV, where EEG was collected from 9 subjects and 22 channels.\nhvEEGNet was found to reconstruct the EEG data with very high-fidelity,\noutperforming most previous solutions (including our vEEGNet-ver3 ).\nFurthermore, this was consistent across all subjects. Interestingly, hvEEGNet\nmade it possible to discover that this popular dataset includes a number of\ncorrupted EEG recordings that might have influenced previous literature\nresults. We also investigated the training behaviour of our models and related\nit with the quality and the size of the input EEG dataset, aiming at opening a\nnew research debate on this relationship. In the future, hvEEGNet could be used\nas anomaly (e.g., artefact) detector in large EEG datasets to support the\ndomain experts, but also the latent representations it provides could be used\nin other classification problems and EEG data generation.",
            "author": [
                "Giulia Cisotto",
                "Alberto Zancanaro",
                "Italo F. Zoppis",
                "Sara L. Manzoni"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00799v1",
                "http://arxiv.org/pdf/2312.00799v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11842v1",
            "title": "Spontaneous supercrystal formation during a strain-engineered\n  metal-insulator transition",
            "updated": "2023-11-20T15:30:14Z",
            "published": "2023-11-20T15:30:14Z",
            "summary": "Mott metal-insulator transitions possess electronic, magnetic, and structural\ndegrees of freedom promising next generation energy-efficient electronics. We\nreport a previously unknown, hierarchically ordered state during a Mott\ntransition and demonstrate correlated switching of functional electronic\nproperties. We elucidate in-situ formation of an intrinsic supercrystal in a\nCa2RuO4 thin film. Machine learning-assisted X-ray nanodiffraction together\nwith electron microscopy reveal multi-scale periodic domain formation at and\nbelow the film transition temperature (TFilm ~ 200-250 K) and a separate\nanisotropic spatial structure at and above TFilm. Local resistivity\nmeasurements imply an intrinsic coupling of the supercrystal orientation to the\nmaterial's anisotropic conductivity. Our findings add an additional degree of\ncomplexity to the physical understanding of Mott transitions, opening\nopportunities for designing materials with tunable electronic properties.",
            "author": [
                "O. Yu. Gorobtsov",
                "L. Miao",
                "Z. Shao",
                "Y. Tan",
                "N. I. Schnitzer",
                "B. H. Goodge",
                "J. Ruf",
                "D. Weinstock",
                "M. Cherukara",
                "M. V. Holt",
                "H. Nair",
                "L. -Q. Chen",
                "L. F. Kourkoutis",
                "D. G. Schlom",
                "K. M. Shen",
                "A. Singer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11842v1",
                "http://arxiv.org/pdf/2311.11842v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11841v1",
            "title": "High Probability Guarantees for Random Reshuffling",
            "updated": "2023-11-20T15:17:20Z",
            "published": "2023-11-20T15:17:20Z",
            "summary": "We consider the stochastic gradient method with random reshuffling\n($\\mathsf{RR}$) for tackling smooth nonconvex optimization problems.\n$\\mathsf{RR}$ finds broad applications in practice, notably in training neural\nnetworks. In this work, we first investigate the concentration property of\n$\\mathsf{RR}$'s sampling procedure and establish a new high probability sample\ncomplexity guarantee for driving the gradient (without expectation) below\n$\\varepsilon$, which effectively characterizes the efficiency of a single\n$\\mathsf{RR}$ execution. Our derived complexity matches the best existing\nin-expectation one up to a logarithmic term while imposing no additional\nassumptions nor changing $\\mathsf{RR}$'s updating rule. Furthermore, by\nleveraging our derived high probability descent property and bound on the\nstochastic error, we propose a simple and computable stopping criterion for\n$\\mathsf{RR}$ (denoted as $\\mathsf{RR}$-$\\mathsf{sc}$). This criterion is\nguaranteed to be triggered after a finite number of iterations, and then\n$\\mathsf{RR}$-$\\mathsf{sc}$ returns an iterate with its gradient below\n$\\varepsilon$ with high probability. Moreover, building on the proposed\nstopping criterion, we design a perturbed random reshuffling method\n($\\mathsf{p}$-$\\mathsf{RR}$) that involves an additional randomized\nperturbation procedure near stationary points. We derive that\n$\\mathsf{p}$-$\\mathsf{RR}$ provably escapes strict saddle points and\nefficiently returns a second-order stationary point with high probability,\nwithout making any sub-Gaussian tail-type assumptions on the stochastic\ngradient errors. Finally, we conduct numerical experiments on neural network\ntraining to support our theoretical findings.",
            "author": [
                "Hengxu Yu",
                "Xiao Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11841v1",
                "http://arxiv.org/pdf/2311.11841v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "90C30, 90C06, 90C26, 90C15"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11837v1",
            "title": "Kandinsky Conformal Prediction: Efficient Calibration of Image\n  Segmentation Algorithms",
            "updated": "2023-11-20T15:11:31Z",
            "published": "2023-11-20T15:11:31Z",
            "summary": "Image segmentation algorithms can be understood as a collection of pixel\nclassifiers, for which the outcomes of nearby pixels are correlated. Classifier\nmodels can be calibrated using Inductive Conformal Prediction, but this\nrequires holding back a sufficiently large calibration dataset for computing\nthe distribution of non-conformity scores of the model's predictions. If one\nonly requires only marginal calibration on the image level, this calibration\nset consists of all individual pixels in the images available for calibration.\nHowever, if the goal is to attain proper calibration for each individual pixel\nclassifier, the calibration set consists of individual images. In a scenario\nwhere data are scarce (such as the medical domain), it may not always be\npossible to set aside sufficiently many images for this pixel-level\ncalibration. The method we propose, dubbed ``Kandinsky calibration'', makes use\nof the spatial structure present in the distribution of natural images to\nsimultaneously calibrate the classifiers of ``similar'' pixels. This can be\nseen as an intermediate approach between marginal (imagewise) and conditional\n(pixelwise) calibration, where non-conformity scores are aggregated over\nsimilar image regions, thereby making more efficient use of the images\navailable for calibration. We run experiments on segmentation algorithms\ntrained and calibrated on subsets of the public MS-COCO and Medical Decathlon\ndatasets, demonstrating that Kandinsky calibration method can significantly\nimprove the coverage. When compared to both pixelwise and imagewise calibration\non little data, the Kandinsky method achieves much lower coverage errors,\nindicating the data efficiency of the Kandinsky calibration.",
            "author": [
                "Joren Brunekreef",
                "Eric Marcus",
                "Ray Sheombarsing",
                "Jan-Jakob Sonke",
                "Jonas Teuwen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11837v1",
                "http://arxiv.org/pdf/2311.11837v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11829v1",
            "title": "System 2 Attention (is something you might need too)",
            "updated": "2023-11-20T15:04:50Z",
            "published": "2023-11-20T15:04:50Z",
            "summary": "Soft attention in Transformer-based Large Language Models (LLMs) is\nsusceptible to incorporating irrelevant information from the context into its\nlatent representations, which adversely affects next token generations. To help\nrectify these issues, we introduce System 2 Attention (S2A), which leverages\nthe ability of LLMs to reason in natural language and follow instructions in\norder to decide what to attend to. S2A regenerates the input context to only\ninclude the relevant portions, before attending to the regenerated context to\nelicit the final response. In experiments, S2A outperforms standard\nattention-based LLMs on three tasks containing opinion or irrelevant\ninformation, QA, math word problems and longform generation, where S2A\nincreases factuality and objectivity, and decreases sycophancy.",
            "author": [
                "Jason Weston",
                "Sainbayar Sukhbaatar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11829v1",
                "http://arxiv.org/pdf/2311.11829v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11827v1",
            "title": "Few-shot Multispectral Segmentation with Representations Generated by\n  Reinforcement Learning",
            "updated": "2023-11-20T15:04:16Z",
            "published": "2023-11-20T15:04:16Z",
            "summary": "The task of multispectral image segmentation (segmentation of images with\nnumerous channels/bands, each capturing a specific range of wavelengths of\nelectromagnetic radiation) has been previously explored in contexts with large\namounts of labeled data. However, these models tend not to generalize well to\ndatasets of smaller size. In this paper, we propose a novel approach for\nimproving few-shot segmentation performance on multispectral images using\nreinforcement learning to generate representations. These representations are\ngenerated in the form of mathematical expressions between channels and are\ntailored to the specific class being segmented. Our methodology involves\ntraining an agent to identify the most informative expressions, updating the\ndataset using these expressions, and then using the updated dataset to perform\nsegmentation. Due to the limited length of the expressions, the model receives\nuseful representations without any added risk of overfitting. We evaluate the\neffectiveness of our approach on several multispectral datasets and demonstrate\nits effectiveness in boosting the performance of segmentation algorithms.",
            "author": [
                "Dilith Jayakody",
                "Thanuja Ambegoda"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11827v1",
                "http://arxiv.org/pdf/2311.11827v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11824v2",
            "title": "Neural Graph Collaborative Filtering Using Variational Inference",
            "updated": "2023-12-02T18:43:13Z",
            "published": "2023-11-20T15:01:33Z",
            "summary": "The customization of recommended content to users holds significant\nimportance in enhancing user experiences across a wide spectrum of applications\nsuch as e-commerce, music, and shopping. Graph-based methods have achieved\nconsiderable performance by capturing user-item interactions. However, these\nmethods tend to utilize randomly constructed embeddings in the dataset used for\ntraining the recommender, which lacks any user preferences. Here, we propose\nthe concept of variational embeddings as a means of pre-training the\nrecommender system to improve the feature propagation through the layers of\ngraph convolutional networks (GCNs). The graph variational embedding\ncollaborative filtering (GVECF) is introduced as a novel framework to\nincorporate representations learned through a variational graph auto-encoder\nwhich are embedded into a GCN-based collaborative filtering. This approach\neffectively transforms latent high-order user-item interactions into more\ntrainable vectors, ultimately resulting in better performance in terms of\nrecall and normalized discounted cumulative gain(NDCG) metrics. The experiments\nconducted on benchmark datasets demonstrate that our proposed method achieves\nup to 13.78% improvement in the recall over the test data.",
            "author": [
                "Narges Sadat Fazeli Dehkordi",
                "Hadi Zare",
                "Parham Moradi",
                "Mahdi Jalili"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11824v2",
                "http://arxiv.org/pdf/2311.11824v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11822v1",
            "title": "Zero redundancy distributed learning with differential privacy",
            "updated": "2023-11-20T14:58:56Z",
            "published": "2023-11-20T14:58:56Z",
            "summary": "Deep learning using large models have achieved great success in a wide range\nof domains. However, training these models on billions of parameters is very\nchallenging in terms of the training speed, memory cost, and communication\nefficiency, especially under the privacy-preserving regime with differential\nprivacy (DP). On the one hand, DP optimization has comparable efficiency to the\nstandard non-private optimization on a single GPU, but on multiple GPUs,\nexisting DP distributed learning (such as pipeline parallel) has suffered from\nsignificantly worse efficiency. On the other hand, the Zero Redundancy\nOptimizer (ZeRO) is a state-of-the-art solution to the standard distributed\nlearning, exhibiting excellent training efficiency on large models, but to work\ncompatibly with DP is technically complicated. In this work, we develop a new\nsystematic solution, DP-ZeRO, (I) to scale up the trainable DP model size, e.g.\nto GPT-100B, (II) to obtain the same computation and communication efficiency\nas the standard ZeRO, and (III) to enable mixed-precision DP training. Our\nDP-ZeRO, like the standard ZeRO, has the potential to train models with\narbitrary size and is evaluated on the world's largest DP models in terms of\nthe number of trainable parameters.",
            "author": [
                "Zhiqi Bu",
                "Justin Chiu",
                "Ruixuan Liu",
                "Sheng Zha",
                "George Karypis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11822v1",
                "http://arxiv.org/pdf/2311.11822v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CC",
                "cs.CR",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11821v1",
            "title": "Cross-View Graph Consistency Learning for Invariant Graph\n  Representations",
            "updated": "2023-11-20T14:58:47Z",
            "published": "2023-11-20T14:58:47Z",
            "summary": "Graph representation learning is fundamental for analyzing graph-structured\ndata. Exploring invariant graph representations remains a challenge for most\nexisting graph representation learning methods. In this paper, we propose a\ncross-view graph consistency learning (CGCL) method that learns invariant graph\nrepresentations for link prediction. First, two complementary augmented views\nare derived from an incomplete graph structure through a bidirectional graph\nstructure augmentation scheme. This augmentation scheme mitigates the potential\ninformation loss that is commonly associated with various data augmentation\ntechniques involving raw graph data, such as edge perturbation, node removal,\nand attribute masking. Second, we propose a CGCL model that can learn invariant\ngraph representations. A cross-view training scheme is proposed to train the\nproposed CGCL model. This scheme attempts to maximize the consistency\ninformation between one augmented view and the graph structure reconstructed\nfrom the other augmented view. Furthermore, we offer a comprehensive\ntheoretical CGCL analysis. This paper empirically and experimentally\ndemonstrates the effectiveness of the proposed CGCL method, achieving\ncompetitive results on graph datasets in comparisons with several\nstate-of-the-art algorithms.",
            "author": [
                "Jie Chen",
                "Zhiming Li",
                "Hua Mao",
                "Wai Lok Woo",
                "Xi Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11821v1",
                "http://arxiv.org/pdf/2311.11821v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11819v2",
            "title": "Generalized super-resolution 4D Flow MRI $\\unicode{x2013}$ using\n  ensemble learning to extend across the cardiovascular system",
            "updated": "2023-11-21T20:45:51Z",
            "published": "2023-11-20T14:55:40Z",
            "summary": "4D Flow Magnetic Resonance Imaging (4D Flow MRI) is a non-invasive\nmeasurement technique capable of quantifying blood flow across the\ncardiovascular system. While practical use is limited by spatial resolution and\nimage noise, incorporation of trained super-resolution (SR) networks has\npotential to enhance image quality post-scan. However, these efforts have\npredominantly been restricted to narrowly defined cardiovascular domains, with\nlimited exploration of how SR performance extends across the cardiovascular\nsystem; a task aggravated by contrasting hemodynamic conditions apparent across\nthe cardiovasculature. The aim of our study was to explore the generalizability\nof SR 4D Flow MRI using a combination of heterogeneous training sets and\ndedicated ensemble learning. With synthetic training data generated across\nthree disparate domains (cardiac, aortic, cerebrovascular), varying\nconvolutional base and ensemble learners were evaluated as a function of domain\nand architecture, quantifying performance on both in-silico and acquired\nin-vivo data from the same three domains. Results show that both bagging and\nstacking ensembling enhance SR performance across domains, accurately\npredicting high-resolution velocities from low-resolution input data in-silico.\nLikewise, optimized networks successfully recover native resolution velocities\nfrom downsampled in-vivo data, as well as show qualitative potential in\ngenerating denoised SR-images from clinical level input data. In conclusion,\nour work presents a viable approach for generalized SR 4D Flow MRI, with\nensemble learning extending utility across various clinical areas of interest.",
            "author": [
                "Leon Ericsson",
                "Adam Hjalmarsson",
                "Muhammad Usman Akbar",
                "Edward Ferdian",
                "Mia Bonini",
                "Brandon Hardy",
                "Jonas Schollenberger",
                "Maria Aristova",
                "Patrick Winter",
                "Nicholas Burris",
                "Alexander Fyrdahl",
                "Andreas Sigfridsson",
                "Susanne Schnell",
                "C. Alberto Figueroa",
                "David Nordsletten",
                "Alistair A. Young",
                "David Marlevi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11819v2",
                "http://arxiv.org/pdf/2311.11819v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.CV",
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11815v1",
            "title": "CrackCLF: Automatic Pavement Crack Detection based on Closed-Loop\n  Feedback",
            "updated": "2023-11-20T14:52:48Z",
            "published": "2023-11-20T14:52:48Z",
            "summary": "Automatic pavement crack detection is an important task to ensure the\nfunctional performances of pavements during their service life. Inspired by\ndeep learning (DL), the encoder-decoder framework is a powerful tool for crack\ndetection. However, these models are usually open-loop (OL) systems that tend\nto treat thin cracks as the background. Meanwhile, these models can not\nautomatically correct errors in the prediction, nor can it adapt to the changes\nof the environment to automatically extract and detect thin cracks. To tackle\nthis problem, we embed closed-loop feedback (CLF) into the neural network so\nthat the model could learn to correct errors on its own, based on generative\nadversarial networks (GAN). The resulting model is called CrackCLF and includes\nthe front and back ends, i.e. segmentation and adversarial network. The front\nend with U-shape framework is employed to generate crack maps, and the back end\nwith a multi-scale loss function is used to correct higher-order\ninconsistencies between labels and crack maps (generated by the front end) to\naddress open-loop system issues. Empirical results show that the proposed\nCrackCLF outperforms others methods on three public datasets. Moreover, the\nproposed CLF can be defined as a plug and play module, which can be embedded\ninto different neural network models to improve their performances.",
            "author": [
                "Chong Li",
                "Zhun Fan",
                "Ying Chen",
                "Huibiao Lin",
                "Laura Moretti",
                "Giuseppe Loprencipe",
                "Weihua Sheng",
                "Kelvin C. P. Wang"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TITS.2023.3332995",
                "http://arxiv.org/abs/2311.11815v1",
                "http://arxiv.org/pdf/2311.11815v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11810v3",
            "title": "DocPedia: Unleashing the Power of Large Multimodal Model in the\n  Frequency Domain for Versatile Document Understanding",
            "updated": "2023-11-30T08:27:38Z",
            "published": "2023-11-20T14:42:25Z",
            "summary": "This work presents DocPedia, a novel large multimodal model (LMM) for\nversatile OCR-free document understanding, capable of parsing images up to\n2,560$\\times$2,560 resolution. Unlike existing work either struggle with\nhigh-resolution documents or give up the large language model thus vision or\nlanguage ability constrained, our DocPedia directly processes visual input in\nthe frequency domain rather than the pixel space. The unique characteristic\nenables DocPedia to capture a greater amount of visual and textual information\nusing a limited number of visual tokens. To consistently enhance both\nperception and comprehension abilities of our model, we develop a dual-stage\ntraining strategy and enrich instructions/annotations of all training tasks\ncovering multiple document types. Extensive quantitative and qualitative\nexperiments conducted on various publicly available benchmarks confirm the\nmutual benefits of jointly learning perception and comprehension tasks. The\nresults provide further evidence of the effectiveness and superior performance\nof our DocPedia over other methods.",
            "author": [
                "Hao Feng",
                "Qi Liu",
                "Hao Liu",
                "Wengang Zhou",
                "Houqiang Li",
                "Can Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11810v3",
                "http://arxiv.org/pdf/2311.11810v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11809v1",
            "title": "LogLead -- Fast and Integrated Log Loader, Enhancer, and Anomaly\n  Detector",
            "updated": "2023-11-20T14:42:13Z",
            "published": "2023-11-20T14:42:13Z",
            "summary": "This paper introduces LogLead, a tool designed for efficient log analysis.\nLogLead combines three essential steps in log processing: loading, enhancing,\nand anomaly detection. The tool leverages Polars, a high-speed DataFrame\nlibrary. We currently have 7 Loaders out of which 4 is for public data sets\n(HDFS, Hadoop, BGL, and Thunderbird). We have multiple enhancers with three\nparsers (Drain, Spell, LenMa), Bert embedding creation and other log\nrepresentation techniques like bag-of-words. LogLead integrates to 5 supervised\nand 4 unsupervised machine learning algorithms for anomaly detection from\nSKLearn. By integrating diverse datasets, log representation methods and\nanomaly detectors, LogLead facilitates comprehensive benchmarking in log\nanalysis research. We demonstrate that log loading from raw file to dataframe\nis over 10x faster with LogLead is compared to past solutions. We demonstrate\nroughly 2x improvement in Drain parsing speed by off-loading log message\nnormalization to LogLead. We demonstrate a brief benchmarking on HDFS\nsuggesting that log representations beyond bag-of-words provide limited\nbenefits. Screencast demonstrating the tool: https://youtu.be/8stdbtTfJVo",
            "author": [
                "Mika M\u00e4ntyl\u00e4",
                "Yuqing Wang",
                "Jesse Nyyss\u00f6l\u00e4"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11809v1",
                "http://arxiv.org/pdf/2311.11809v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11798v1",
            "title": "Operator Learning for Continuous Spatial-Temporal Model with A Hybrid\n  Optimization Scheme",
            "updated": "2023-11-20T14:31:18Z",
            "published": "2023-11-20T14:31:18Z",
            "summary": "Partial differential equations are often used in the spatial-temporal\nmodeling of complex dynamical systems in many engineering applications. In this\nwork, we build on the recent progress of operator learning and present a\ndata-driven modeling framework that is continuous in both space and time. A key\nfeature of the proposed model is the resolution-invariance with respect to both\nspatial and temporal discretizations. To improve the long-term performance of\nthe calibrated model, we further propose a hybrid optimization scheme that\nleverages both gradient-based and derivative-free optimization methods and\nefficiently trains on both short-term time series and long-term statistics. We\ninvestigate the performance of the spatial-temporal continuous learning\nframework with three numerical examples, including the viscous Burgers'\nequation, the Navier-Stokes equations, and the Kuramoto-Sivashinsky equation.\nThe results confirm the resolution-invariance of the proposed modeling\nframework and also demonstrate stable long-term simulations with only\nshort-term time series data. In addition, we show that the proposed model can\nbetter predict long-term statistics via the hybrid optimization scheme with a\ncombined use of short-term and long-term data.",
            "author": [
                "Chuanqi Chen",
                "Jin-Long Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11798v1",
                "http://arxiv.org/pdf/2311.11798v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11796v1",
            "title": "Beyond Boundaries: A Comprehensive Survey of Transferable Attacks on AI\n  Systems",
            "updated": "2023-11-20T14:29:45Z",
            "published": "2023-11-20T14:29:45Z",
            "summary": "Artificial Intelligence (AI) systems such as autonomous vehicles, facial\nrecognition, and speech recognition systems are increasingly integrated into\nour daily lives. However, despite their utility, these AI systems are\nvulnerable to a wide range of attacks such as adversarial, backdoor, data\npoisoning, membership inference, model inversion, and model stealing attacks.\nIn particular, numerous attacks are designed to target a particular model or\nsystem, yet their effects can spread to additional targets, referred to as\ntransferable attacks. Although considerable efforts have been directed toward\ndeveloping transferable attacks, a holistic understanding of the advancements\nin transferable attacks remains elusive. In this paper, we comprehensively\nexplore learning-based attacks from the perspective of transferability,\nparticularly within the context of cyber-physical security. We delve into\ndifferent domains -- the image, text, graph, audio, and video domains -- to\nhighlight the ubiquitous and pervasive nature of transferable attacks. This\npaper categorizes and reviews the architecture of existing attacks from various\nviewpoints: data, process, model, and system. We further examine the\nimplications of transferable attacks in practical scenarios such as autonomous\ndriving, speech recognition, and large language models (LLMs). Additionally, we\noutline the potential research directions to encourage efforts in exploring the\nlandscape of transferable attacks. This survey offers a holistic understanding\nof the prevailing transferable attacks and their impacts across different\ndomains.",
            "author": [
                "Guangjing Wang",
                "Ce Zhou",
                "Yuanda Wang",
                "Bocheng Chen",
                "Hanqing Guo",
                "Qiben Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11796v1",
                "http://arxiv.org/pdf/2311.11796v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11789v1",
            "title": "Approximate Linear Programming and Decentralized Policy Improvement in\n  Cooperative Multi-agent Markov Decision Processes",
            "updated": "2023-11-20T14:14:13Z",
            "published": "2023-11-20T14:14:13Z",
            "summary": "In this work, we consider a `cooperative' multi-agent Markov decision process\n(MDP) involving m greater than 1 agents, where all agents are aware of the\nsystem model. At each decision epoch, all the m agents cooperatively select\nactions in order to maximize a common long-term objective. Since the number of\nactions grows exponentially in the number of agents, policy improvement is\ncomputationally expensive. Recent works have proposed using decentralized\npolicy improvement in which each agent assumes that the decisions of the other\nagents are fixed and it improves its decisions unilaterally. Yet, in these\nworks, exact values are computed. In our work, for cooperative multi-agent\nfinite and infinite horizon discounted MDPs, we propose suitable approximate\npolicy iteration algorithms, wherein we use approximate linear programming to\ncompute the approximate value function and use decentralized policy\nimprovement. Thus our algorithms can handle both large number of states as well\nas multiple agents. We provide theoretical guarantees for our algorithms and\nalso demonstrate the performance of our algorithms on some numerical examples.",
            "author": [
                "Lakshmi Mandal",
                "Chandrashekar Lakshminarayanan",
                "Shalabh Bhatnagar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11789v1",
                "http://arxiv.org/pdf/2311.11789v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.MA",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11782v1",
            "title": "Robust Tumor Segmentation with Hyperspectral Imaging and Graph Neural\n  Networks",
            "updated": "2023-11-20T14:07:38Z",
            "published": "2023-11-20T14:07:38Z",
            "summary": "Segmenting the boundary between tumor and healthy tissue during surgical\ncancer resection poses a significant challenge. In recent years, Hyperspectral\nImaging (HSI) combined with Machine Learning (ML) has emerged as a promising\nsolution. However, due to the extensive information contained within the\nspectral domain, most ML approaches primarily classify individual HSI\n(super-)pixels, or tiles, without taking into account their spatial context. In\nthis paper, we propose an improved methodology that leverages the spatial\ncontext of tiles for more robust and smoother segmentation. To address the\nirregular shapes of tiles, we utilize Graph Neural Networks (GNNs) to propagate\ncontext information across neighboring regions. The features for each tile\nwithin the graph are extracted using a Convolutional Neural Network (CNN),\nwhich is trained simultaneously with the subsequent GNN. Moreover, we\nincorporate local image quality metrics into the loss function to enhance the\ntraining procedure's robustness against low-quality regions in the training\nimages. We demonstrate the superiority of our proposed method using a clinical\nex vivo dataset consisting of 51 HSI images from 30 patients. Despite the\nlimited dataset, the GNN-based model significantly outperforms context-agnostic\napproaches, accurately distinguishing between healthy and tumor tissues, even\nin images from previously unseen patients. Furthermore, we show that our\ncarefully designed loss function, accounting for local image quality, results\nin additional improvements. Our findings demonstrate that context-aware GNN\nalgorithms can robustly find tumor demarcations on HSI images, ultimately\ncontributing to better surgery success and patient outcome.",
            "author": [
                "Mayar Lotfy",
                "Anna Alperovich",
                "Tommaso Giannantonio",
                "Bjorn Barz",
                "Xiaohan Zhang",
                "Felix Holm",
                "Nassir Navab",
                "Felix Boehm",
                "Carolin Schwamborn",
                "Thomas K. Hoffmann",
                "Patrick J. Schuler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11782v1",
                "http://arxiv.org/pdf/2311.11782v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11778v1",
            "title": "Preliminary Report: On Information Hiding in Multi-Hop Radio Networks",
            "updated": "2023-11-20T14:03:37Z",
            "published": "2023-11-20T14:03:37Z",
            "summary": "In this paper, we consider the problem of an adversary aiming to learn\ninformation about the network topology or the executed algorithm from some\nsignals obtained during the algorithm's execution. The problem is defined in a\nvery general form. However, it is mainly motivated by multi-hop ad hoc radio\nnetworks. In contrast to previous work concentrated on single-hop radio\nnetworks, this model is critically more complex due to the number of possible\nsettings that need to be taken into account when considering different\ncombinations of topologies and communication models. Moreover, the definition\nof the adversary is also ambiguous, and the adequate approach needs to depend\non the adversary's aims and capabilities. This preliminary report presents a\ngeneral theoretical background and some basic algorithms. We also propose some\ngeneral taxonomy as a framework for future research.",
            "author": [
                "Marek Klonowski",
                "Mateusz Marciniak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11778v1",
                "http://arxiv.org/pdf/2311.11778v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11777v1",
            "title": "Multimodal deep learning for mapping forest dominant height by fusing\n  GEDI with earth observation data",
            "updated": "2023-11-20T14:02:50Z",
            "published": "2023-11-20T14:02:50Z",
            "summary": "The integration of multisource remote sensing data and deep learning models\noffers new possibilities for accurately mapping high spatial resolution forest\nheight. We found that GEDI relative heights (RH) metrics exhibited strong\ncorrelation with the mean of the top 10 highest trees (dominant height)\nmeasured in situ at the corresponding footprint locations. Consequently, we\nproposed a novel deep learning framework termed the multi-modal attention\nremote sensing network (MARSNet) to estimate forest dominant height by\nextrapolating dominant height derived from GEDI, using Setinel-1 data, ALOS-2\nPALSAR-2 data, Sentinel-2 optical data and ancillary data. MARSNet comprises\nseparate encoders for each remote sensing data modality to extract multi-scale\nfeatures, and a shared decoder to fuse the features and estimate height. Using\nindividual encoders for each remote sensing imagery avoids interference across\nmodalities and extracts distinct representations. To focus on the efficacious\ninformation from each dataset, we reduced the prevalent spatial and band\nredundancies in each remote sensing data by incorporating the extended spatial\nand band reconstruction convolution modules in the encoders. MARSNet achieved\ncommendable performance in estimating dominant height, with an R2 of 0.62 and\nRMSE of 2.82 m, outperforming the widely used random forest approach which\nattained an R2 of 0.55 and RMSE of 3.05 m. Finally, we applied the trained\nMARSNet model to generate wall-to-wall maps at 10 m resolution for Jilin,\nChina. Through independent validation using field measurements, MARSNet\ndemonstrated an R2 of 0.58 and RMSE of 3.76 m, compared to 0.41 and 4.37 m for\nthe random forest baseline. Our research demonstrates the effectiveness of a\nmultimodal deep learning approach fusing GEDI with SAR and passive optical\nimagery for enhancing the accuracy of high resolution dominant height\nestimation.",
            "author": [
                "Man Chen",
                "Wenquan Dong",
                "Hao Yu",
                "Iain Woodhouse",
                "Casey M. Ryan",
                "Haoyu Liu",
                "Selena Georgiou",
                "Edward T. A. Mitchard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11777v1",
                "http://arxiv.org/pdf/2311.11777v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11775v1",
            "title": "Intelligent methods for business rule processing: State-of-the-art",
            "updated": "2023-11-20T14:02:10Z",
            "published": "2023-11-20T14:02:10Z",
            "summary": "In this article, we provide an overview of the latest intelligent techniques\nused for processing business rules. We have conducted a comprehensive survey of\nthe relevant literature on robot process automation, with a specific focus on\nmachine learning and other intelligent approaches. Additionally, we have\nexamined the top vendors in the market and their leading solutions to tackle\nthis issue.",
            "author": [
                "Cristiano Andr\u00e9 da Costa",
                "U\u00e9lison Jean Lopes dos Santos",
                "Eduardo Souza dos Reis",
                "Rodolfo Stoffel Antunes",
                "Henrique Chaves Pacheco",
                "Thayn\u00e3 da Silva Fran\u00e7a",
                "Rodrigo da Rosa Righi",
                "Jorge Luis Vict\u00f3ria Barbosa",
                "Franklin Jebadoss",
                "Jorge Montalvao",
                "Rogerio Kunkel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11775v1",
                "http://arxiv.org/pdf/2311.11775v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11772v3",
            "title": "A Good Feature Extractor Is All You Need for Weakly Supervised Learning\n  in Histopathology",
            "updated": "2023-11-29T00:06:13Z",
            "published": "2023-11-20T13:58:26Z",
            "summary": "Deep learning is revolutionising pathology, offering novel opportunities in\ndisease prognosis and personalised treatment. Historically, stain normalisation\nhas been a crucial preprocessing step in computational pathology pipelines, and\npersists into the deep learning era. Yet, with the emergence of feature\nextractors trained using self-supervised learning (SSL) on diverse pathology\ndatasets, we call this practice into question. In an empirical evaluation of\npublicly available feature extractors, we find that omitting stain\nnormalisation and image augmentations does not compromise downstream\nperformance, while incurring substantial savings in memory and compute.\nFurther, we show that the top-performing feature extractors are remarkably\nrobust to variations in stain and augmentations like rotation in their latent\nspace. Contrary to previous patch-level benchmarking studies, our approach\nemphasises clinical relevance by focusing on slide-level prediction tasks in a\nweakly supervised setting with external validation cohorts. This work\nrepresents the most comprehensive robustness evaluation of public pathology SSL\nfeature extractors to date, involving more than 6,000 training runs across nine\ntasks, five datasets, three downstream architectures, and various preprocessing\nsetups. Our findings stand to streamline digital pathology workflows by\nminimising preprocessing needs and informing the selection of feature\nextractors.",
            "author": [
                "Georg W\u00f6lflein",
                "Dyke Ferber",
                "Asier Rabasco Meneghetti",
                "Omar S. M. El Nahhas",
                "Daniel Truhn",
                "Zunamys I. Carrero",
                "David J. Harrison",
                "Ognjen Arandjelovi\u0107",
                "Jakob N. Kather"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11772v3",
                "http://arxiv.org/pdf/2311.11772v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12086v1",
            "title": "Masked Autoencoders Are Robust Neural Architecture Search Learners",
            "updated": "2023-11-20T13:45:21Z",
            "published": "2023-11-20T13:45:21Z",
            "summary": "Neural Architecture Search (NAS) currently relies heavily on labeled data,\nwhich is both expensive and time-consuming to acquire. In this paper, we\npropose a novel NAS framework based on Masked Autoencoders (MAE) that\neliminates the need for labeled data during the search process. By replacing\nthe supervised learning objective with an image reconstruction task, our\napproach enables the robust discovery of network architectures without\ncompromising performance and generalization ability. Additionally, we address\nthe problem of performance collapse encountered in the widely-used\nDifferentiable Architecture Search (DARTS) method in the unsupervised paradigm\nby introducing a multi-scale decoder. Through extensive experiments conducted\non various search spaces and datasets, we demonstrate the effectiveness and\nrobustness of the proposed method, providing empirical evidence of its\nsuperiority over baseline approaches.",
            "author": [
                "Yiming Hu",
                "Xiangxiang Chu",
                "Bo Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12086v1",
                "http://arxiv.org/pdf/2311.12086v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11762v2",
            "title": "MUVO: A Multimodal Generative World Model for Autonomous Driving with\n  Geometric Representations",
            "updated": "2023-11-23T17:26:53Z",
            "published": "2023-11-20T13:40:40Z",
            "summary": "Learning unsupervised world models for autonomous driving has the potential\nto improve the reasoning capabilities of today's systems dramatically. However,\nmost work neglects the physical attributes of the world and focuses on sensor\ndata alone. We propose MUVO, a MUltimodal World Model with Geometric VOxel\nRepresentations to address this challenge. We utilize raw camera and lidar data\nto learn a sensor-agnostic geometric representation of the world, which can\ndirectly be used by downstream tasks, such as planning. We demonstrate\nmultimodal future predictions and show that our geometric representation\nimproves the prediction quality of both camera images and lidar point clouds.",
            "author": [
                "Daniel Bogdoll",
                "Yitian Yang",
                "J. Marius Z\u00f6llner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11762v2",
                "http://arxiv.org/pdf/2311.11762v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11759v1",
            "title": "Unveiling the Unseen Potential of Graph Learning through MLPs: Effective\n  Graph Learners Using Propagation-Embracing MLPs",
            "updated": "2023-11-20T13:39:19Z",
            "published": "2023-11-20T13:39:19Z",
            "summary": "Recent studies attempted to utilize multilayer perceptrons (MLPs) to solve\nsemi-supervised node classification on graphs, by training a student MLP by\nknowledge distillation (KD) from a teacher graph neural network (GNN). While\nprevious studies have focused mostly on training the student MLP by matching\nthe output probability distributions between the teacher and student models\nduring KD, it has not been systematically studied how to inject the structural\ninformation in an explicit and interpretable manner. Inspired by GNNs that\nseparate feature transformation $T$ and propagation $\\Pi$, we re-frame the KD\nprocess as enabling the student MLP to explicitly learn both $T$ and $\\Pi$.\nAlthough this can be achieved by applying the inverse propagation $\\Pi^{-1}$\nbefore distillation from the teacher GNN, it still comes with a high\ncomputational cost from large matrix multiplications during training. To solve\nthis problem, we propose Propagate & Distill (P&D), which propagates the output\nof the teacher GNN before KD and can be interpreted as an approximate process\nof the inverse propagation $\\Pi^{-1}$. Through comprehensive evaluations using\nreal-world benchmark datasets, we demonstrate the effectiveness of P&D by\nshowing further performance boost of the student MLP.",
            "author": [
                "Yong-Min Shin",
                "Won-Yong Shin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11759v1",
                "http://arxiv.org/pdf/2311.11759v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.IT",
                "cs.NE",
                "cs.SI",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11756v1",
            "title": "LSTM-CNN: An efficient diagnostic network for Parkinson's disease\n  utilizing dynamic handwriting analysis",
            "updated": "2023-11-20T13:34:08Z",
            "published": "2023-11-20T13:34:08Z",
            "summary": "Background and objectives: Dynamic handwriting analysis, due to its\nnon-invasive and readily accessible nature, has recently emerged as a vital\nadjunctive method for the early diagnosis of Parkinson's disease. In this\nstudy, we design a compact and efficient network architecture to analyse the\ndistinctive handwriting patterns of patients' dynamic handwriting signals,\nthereby providing an objective identification for the Parkinson's disease\ndiagnosis.\n  Methods: The proposed network is based on a hybrid deep learning approach\nthat fully leverages the advantages of both long short-term memory (LSTM) and\nconvolutional neural networks (CNNs). Specifically, the LSTM block is adopted\nto extract the time-varying features, while the CNN-based block is implemented\nusing one-dimensional convolution for low computational cost. Moreover, the\nhybrid model architecture is continuously refined under ablation studies for\nsuperior performance. Finally, we evaluate the proposed method with its\ngeneralization under a five-fold cross-validation, which validates its\nefficiency and robustness.\n  Results: The proposed network demonstrates its versatility by achieving\nimpressive classification accuracies on both our new DraWritePD dataset\n($96.2\\%$) and the well-established PaHaW dataset ($90.7\\%$). Moreover, the\nnetwork architecture also stands out for its excellent lightweight design,\noccupying a mere $0.084$M of parameters, with a total of only $0.59$M\nfloating-point operations. It also exhibits near real-time CPU inference\nperformance, with inference times ranging from $0.106$ to $0.220$s.\n  Conclusions: We present a series of experiments with extensive analysis,\nwhich systematically demonstrate the effectiveness and efficiency of the\nproposed hybrid neural network in extracting distinctive handwriting patterns\nfor precise diagnosis of Parkinson's disease.",
            "author": [
                "Xuechao Wang",
                "Junqing Huang",
                "Sven Nomm",
                "Marianna Chatzakou",
                "Kadri Medijainen",
                "Aaro Toomela",
                "Michael Ruzhansky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11756v1",
                "http://arxiv.org/pdf/2311.11756v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11753v1",
            "title": "AdvGen: Physical Adversarial Attack on Face Presentation Attack\n  Detection Systems",
            "updated": "2023-11-20T13:28:42Z",
            "published": "2023-11-20T13:28:42Z",
            "summary": "Evaluating the risk level of adversarial images is essential for safely\ndeploying face authentication models in the real world. Popular approaches for\nphysical-world attacks, such as print or replay attacks, suffer from some\nlimitations, like including physical and geometrical artifacts. Recently,\nadversarial attacks have gained attraction, which try to digitally deceive the\nlearning strategy of a recognition system using slight modifications to the\ncaptured image. While most previous research assumes that the adversarial image\ncould be digitally fed into the authentication systems, this is not always the\ncase for systems deployed in the real world. This paper demonstrates the\nvulnerability of face authentication systems to adversarial images in physical\nworld scenarios. We propose AdvGen, an automated Generative Adversarial\nNetwork, to simulate print and replay attacks and generate adversarial images\nthat can fool state-of-the-art PADs in a physical domain attack setting. Using\nthis attack strategy, the attack success rate goes up to 82.01%. We test AdvGen\nextensively on four datasets and ten state-of-the-art PADs. We also demonstrate\nthe effectiveness of our attack by conducting experiments in a realistic,\nphysical environment.",
            "author": [
                "Sai Amrit Patnaik",
                "Shivali Chansoriya",
                "Anil K. Jain",
                "Anoop M. Namboodiri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11753v1",
                "http://arxiv.org/pdf/2311.11753v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11751v1",
            "title": "Quantum approximated cloning-assisted density matrix exponentiation",
            "updated": "2023-11-20T13:27:00Z",
            "published": "2023-11-20T13:27:00Z",
            "summary": "Classical information loading is an essential task for many processing\nquantum algorithms, constituting a cornerstone in the field of quantum machine\nlearning. In particular, the embedding techniques based on Hamiltonian\nsimulation techniques enable the loading of matrices into quantum computers. A\nrepresentative example of these methods is the Lloyd-Mohseni-Rebentrost\nprotocol, which efficiently implements matrix exponentiation when multiple\ncopies of a quantum state are available. However, this is a quite ideal set up,\nand in a realistic scenario, the copies are limited and the non-cloning theorem\nprevents from producing more exact copies in order to increase the accuracy of\nthe protocol. Here, we propose a method to circumvent this limitation by\nintroducing imperfect quantum copies that significantly enhance the performance\nof previous proposals.",
            "author": [
                "Pablo Rodriguez-Grasa",
                "Ruben Ibarrondo",
                "Javier Gonzalez-Conde",
                "Yue Ban",
                "Patrick Rebentrost",
                "Mikel Sanz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11751v1",
                "http://arxiv.org/pdf/2311.11751v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16172v1",
            "title": "Evolutionary Machine Learning and Games",
            "updated": "2023-11-20T13:21:39Z",
            "published": "2023-11-20T13:21:39Z",
            "summary": "Evolutionary machine learning (EML) has been applied to games in multiple\nways, and for multiple different purposes. Importantly, AI research in games is\nnot only about playing games; it is also about generating game content,\nmodeling players, and many other applications. Many of these applications pose\ninteresting problems for EML. We will structure this chapter on EML for games\nbased on whether evolution is used to augment machine learning (ML) or ML is\nused to augment evolution. For completeness, we also briefly discuss the usage\nof ML and evolution separately in games.",
            "author": [
                "Julian Togelius",
                "Ahmed Khalifa",
                "Sam Earle",
                "Michael Cerny Green",
                "Lisa Soros"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16172v1",
                "http://arxiv.org/pdf/2311.16172v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11749v1",
            "title": "Revealing behavioral impact on mobility prediction networks through\n  causal interventions",
            "updated": "2023-11-20T13:21:10Z",
            "published": "2023-11-20T13:21:10Z",
            "summary": "Deep neural networks are increasingly utilized in mobility prediction tasks,\nyet their intricate internal workings pose challenges for interpretability,\nespecially in comprehending how various aspects of mobility behavior affect\npredictions. In this study, we introduce a causal intervention framework to\nassess the impact of mobility-related factors on neural networks designed for\nnext location prediction -- a task focusing on predicting the immediate next\nlocation of an individual. To achieve this, we employ individual mobility\nmodels to generate synthetic location visit sequences and control behavior\ndynamics by intervening in their data generation process. We evaluate the\ninterventional location sequences using mobility metrics and input them into\nwell-trained networks to analyze performance variations. The results\ndemonstrate the effectiveness in producing location sequences with distinct\nmobility behaviors, thus facilitating the simulation of diverse spatial and\ntemporal changes. These changes result in performance fluctuations in next\nlocation prediction networks, revealing impacts of critical mobility behavior\nfactors, including sequential patterns in location transitions, proclivity for\nexploring new locations, and preferences in location choices at population and\nindividual levels. The gained insights hold significant value for the\nreal-world application of mobility prediction networks, and the framework is\nexpected to promote the use of causal inference for enhancing the\ninterpretability and robustness of neural networks in mobility applications.",
            "author": [
                "Ye Hong",
                "Yanan Xin",
                "Simon Dirmeier",
                "Fernando Perez-Cruz",
                "Martin Raubal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11749v1",
                "http://arxiv.org/pdf/2311.11749v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11745v1",
            "title": "Encoding Speaker-Specific Latent Speech Feature for Speech Synthesis",
            "updated": "2023-11-20T13:13:24Z",
            "published": "2023-11-20T13:13:24Z",
            "summary": "In this work, we propose a novel method for modeling numerous speakers, which\nenables expressing the overall characteristics of speakers in detail like a\ntrained multi-speaker model without additional training on the target speaker's\ndataset. Although various works with similar purposes have been actively\nstudied, their performance has not yet reached that of trained multi-speaker\nmodels due to their fundamental limitations. To overcome previous limitations,\nwe propose effective methods for feature learning and representing target\nspeakers' speech characteristics by discretizing the features and conditioning\nthem to a speech synthesis model. Our method obtained a significantly higher\nsimilarity mean opinion score (SMOS) in subjective similarity evaluation than\nseen speakers of a best-performing multi-speaker model, even with unseen\nspeakers. The proposed method also outperforms a zero-shot method by\nsignificant margins. Furthermore, our method shows remarkable performance in\ngenerating new artificial speakers. In addition, we demonstrate that the\nencoded latent features are sufficiently informative to reconstruct an original\nspeaker's speech completely. It implies that our method can be used as a\ngeneral methodology to encode and reconstruct speakers' characteristics in\nvarious tasks.",
            "author": [
                "Jungil Kong",
                "Junmo Lee",
                "Jeongmin Kim",
                "Beomjeong Kim",
                "Jihoon Park",
                "Dohee Kong",
                "Changheon Lee",
                "Sangjin Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11745v1",
                "http://arxiv.org/pdf/2311.11745v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14727v1",
            "title": "Optimal Strategies to Perform Multilingual Analysis of Social Content\n  for a Novel Dataset in the Tourism Domain",
            "updated": "2023-11-20T13:08:21Z",
            "published": "2023-11-20T13:08:21Z",
            "summary": "The rising influence of social media platforms in various domains, including\ntourism, has highlighted the growing need for efficient and automated natural\nlanguage processing (NLP) approaches to take advantage of this valuable\nresource. However, the transformation of multilingual, unstructured, and\ninformal texts into structured knowledge often poses significant challenges.\n  In this work, we evaluate and compare few-shot, pattern-exploiting and\nfine-tuning machine learning techniques on large multilingual language models\n(LLMs) to establish the best strategy to address the lack of annotated data for\n3 common NLP tasks in the tourism domain: (1) Sentiment Analysis, (2) Named\nEntity Recognition, and (3) Fine-grained Thematic Concept Extraction (linked to\na semantic resource). Furthermore, we aim to ascertain the quantity of\nannotated examples required to achieve good performance in those 3 tasks,\naddressing a common challenge encountered by NLP researchers in the\nconstruction of domain-specific datasets.\n  Extensive experimentation on a newly collected and annotated multilingual\n(French, English, and Spanish) dataset composed of tourism-related tweets shows\nthat current few-shot learning techniques allow us to obtain competitive\nresults for all three tasks with very little annotation data: 5 tweets per\nlabel (15 in total) for Sentiment Analysis, 10% of the tweets for location\ndetection (around 160) and 13% (200 approx.) of the tweets annotated with\nthematic concepts, a highly fine-grained sequence labeling task based on an\ninventory of 315 classes.\n  This comparative analysis, grounded in a novel dataset, paves the way for\napplying NLP to new domain-specific applications, reducing the need for manual\nannotations and circumventing the complexities of rule-based, ad hoc solutions.",
            "author": [
                "Maxime Masson",
                "Rodrigo Agerri",
                "Christian Sallaberry",
                "Marie-Noelle Bessagnet",
                "Annig Le Parc Lacayrelle",
                "Philippe Roose"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14727v1",
                "http://arxiv.org/pdf/2311.14727v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11741v1",
            "title": "Machine learning of (1+1)-dimensional directed percolation based on raw\n  and shuffled configurations",
            "updated": "2023-11-20T13:04:47Z",
            "published": "2023-11-20T13:04:47Z",
            "summary": "Machine learning (ML) can process large sets of data generated from complex\nsystems, which is ideal for classification tasks as often appeared in critical\nphenomena. Meanwhile ML techniques have been found effective in detecting\ncritical points, or in a broader sense phase separation, and extracting\ncritical exponents. But there are still many unsolved issues with the ML, one\nof which is the meaning of hidden variables of unsupervised learning. Some say\nthat the hidden variables and the principal component may contain basic\ninformation regarding the order parameter of the system of interest, which\nsounds plausible but lacks evidence. This study aims at searching for evidence\nsupporting the conjecture that the autoencoder's (AE) single latent variable\nand PCA's first principal component can only serve as signals related to\nparticle density, which happens to be the order parameter of the\nnon-equilibrium DP model. Indeed, in some phase transition (PT) models the\norder parameter is the particle density, whereas in some PT models it is not.\nHaving conducted a certain degree of random shuffling on the DP configurations,\nwhich are then fed to the neural networks as input, we find that AE's single\nlatent variable and PCA's first principal component can indeed represent\nparticle density. It is found that shuffling does affect the size of maximum\ncluster in the system, which suggests that the second principal component of\nthe PCA is related to the maximal cluster. This has been supported by changes\nin the correlation length of the transition system with variations in the\nshuffle ratio.",
            "author": [
                "Shen Jianmin",
                "Wang Shanshan",
                "Li Wei",
                "Xu Dian",
                "Yang Yuxiang",
                "Wang Yanyang",
                "Gao Feng",
                "Zhu Yueying",
                "Tuo Kui"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11741v1",
                "http://arxiv.org/pdf/2311.11741v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "cond-mat.dis-nn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11723v1",
            "title": "Leveraging Uncertainty Estimates To Improve Classifier Performance",
            "updated": "2023-11-20T12:40:25Z",
            "published": "2023-11-20T12:40:25Z",
            "summary": "Binary classification involves predicting the label of an instance based on\nwhether the model score for the positive class exceeds a threshold chosen based\non the application requirements (e.g., maximizing recall for a precision\nbound). However, model scores are often not aligned with the true positivity\nrate. This is especially true when the training involves a differential\nsampling across classes or there is distributional drift between train and test\nsettings. In this paper, we provide theoretical analysis and empirical evidence\nof the dependence of model score estimation bias on both uncertainty and score\nitself. Further, we formulate the decision boundary selection in terms of both\nmodel score and uncertainty, prove that it is NP-hard, and present algorithms\nbased on dynamic programming and isotonic regression. Evaluation of the\nproposed algorithms on three real-world datasets yield 25%-40% gain in recall\nat high precision bounds over the traditional approach of using model score\nalone, highlighting the benefits of leveraging uncertainty.",
            "author": [
                "Gundeep Arora",
                "Srujana Merugu",
                "Anoop Saladi",
                "Rajeev Rastogi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11723v1",
                "http://arxiv.org/pdf/2311.11723v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11717v1",
            "title": "Can we infer the presence of Differential Privacy in Deep Learning\n  models' weights? Towards more secure Deep Learning",
            "updated": "2023-11-20T12:35:11Z",
            "published": "2023-11-20T12:35:11Z",
            "summary": "Differential Privacy (DP) is a key property to protect data and models from\nintegrity attacks. In the Deep Learning (DL) field, it is commonly implemented\nthrough the Differentially Private Stochastic Gradient Descent (DP-SGD).\nHowever, when a model is shared or released, there is no way to check whether\nit is differentially private, that is, it required to trust the model provider.\nThis situation poses a problem when data privacy is mandatory, specially with\ncurrent data regulations, as the presence of DP can not be certificated\nconsistently by any third party. Thus, we face the challenge of determining\nwhether a DL model has been trained with DP, according to the title question:\nCan we infer the presence of Differential Privacy in Deep Learning models'\nweights? Since the DP-SGD significantly changes the training process of a DL\nmodel, we hypothesize that DP leaves an imprint in the weights of a DL model,\nwhich can be used to predict whether a model has been trained with DP\nregardless of its architecture and the training dataset. In this paper, we\npropose to employ the imprint in model weights of using DP to infer the\npresence of DP training in a DL model. To substantiate our hypothesis, we\ndeveloped an experimental methodology based on two datasets of weights of DL\nmodels, each with models with and without DP training and a meta-classifier to\ninfer whether DP was used in the training process of a DL model, by accessing\nits weights. We accomplish both, the removal of the requirement of a trusted\nmodel provider and a strong foundation for this interesting line of research.\nThus, our contribution is an additional layer of security on top of the strict\nprivate requirements of DP training in DL models, towards to DL models.",
            "author": [
                "Jim\u00e9nez-L\u00f3pez",
                "Daniel",
                "Rodr\u00edguez-Barroso",
                "Nuria",
                "Luz\u00f3n",
                "M. Victoria",
                "Herrera",
                "Francisco"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11717v1",
                "http://arxiv.org/pdf/2311.11717v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11714v1",
            "title": "On the Importance of Large Objects in CNN Based Object Detection\n  Algorithms",
            "updated": "2023-11-20T12:32:32Z",
            "published": "2023-11-20T12:32:32Z",
            "summary": "Object detection models, a prominent class of machine learning algorithms,\naim to identify and precisely locate objects in images or videos. However, this\ntask might yield uneven performances sometimes caused by the objects sizes and\nthe quality of the images and labels used for training. In this paper, we\nhighlight the importance of large objects in learning features that are\ncritical for all sizes. Given these findings, we propose to introduce a\nweighting term into the training loss. This term is a function of the object\narea size. We show that giving more weight to large objects leads to improved\ndetection scores across all object sizes and so an overall improvement in\nObject Detectors performances (+2 p.p. of mAP on small objects, +2 p.p. on\nmedium and +4 p.p. on large on COCO val 2017 with InternImage-T). Additional\nexperiments and ablation studies with different models and on a different\ndataset further confirm the robustness of our findings.",
            "author": [
                "Ahmed Ben Saad",
                "Gabriele Facciolo",
                "Axel Davy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11714v1",
                "http://arxiv.org/pdf/2311.11714v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14744v1",
            "title": "Coarse-Grained Configurational Polymer Fingerprints for Property\n  Prediction using Machine Learning",
            "updated": "2023-11-20T12:17:25Z",
            "published": "2023-11-20T12:17:25Z",
            "summary": "In this work, we present a method to generate a configurational level\nfingerprint for polymers using the Bead-Spring-Model. Unlike some of the\nprevious fingerprinting approaches that employ monomer-level information where\natomistic descriptors are computed using quantum chemistry calculations, this\napproach incorporates configurational information from a coarse-grained model\nof a long polymer chain. The proposed approach may be advantageous for the\nstudy of behavior resulting from large molecular weights. To create this\nfingerprint, we make use of two kinds of descriptors. First, we calculate\ncertain geometric descriptors like Re2, Rg2 etc. and label them as Calculated\nDescriptors. Second, we generate a set of data-driven descriptors using an\nunsupervised autoencoder model and call them Learnt Descriptors. Using a\ncombination of both of them, we are able to learn mappings from the structure\nto various properties of the polymer chain by training ML models. We test our\nfingerprint to predict the probability of occurrence of a configuration at\nequilibrium, which is approximated by a simple linear relationship between the\ninstantaneous internal energy and equilibrium average internal energy.",
            "author": [
                "Ishan Kumar",
                "Prateek K Jha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14744v1",
                "http://arxiv.org/pdf/2311.14744v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11696v1",
            "title": "Sparse Low-rank Adaptation of Pre-trained Language Models",
            "updated": "2023-11-20T11:56:25Z",
            "published": "2023-11-20T11:56:25Z",
            "summary": "Fine-tuning pre-trained large language models in a parameter-efficient manner\nis widely studied for its effectiveness and efficiency. The popular method of\nlow-rank adaptation (LoRA) offers a notable approach, hypothesizing that the\nadaptation process is intrinsically low-dimensional. Although LoRA has\ndemonstrated commendable performance, it is implemented with a fixed and\nunalterable intrinsic rank that might not always be the ideal choice.\nRecognizing the need for more flexible adaptation, we extend the methodology of\nLoRA to an innovative approach we call sparse low-rank adaptation (SoRA) that\nenables dynamic adjustments to the intrinsic rank during the adaptation\nprocess. We achieve this through the incorporation of a gate unit optimized\nwith proximal gradient method in the training stage, controlling the\ncardinality of rank under the sparsity of the gate. In the subsequent inference\nstage, we eliminate the parameter blocks corresponding to the zeroed-out ranks,\nto reduce each SoRA module back to a concise yet rank-optimal LoRA. Our\napproach strengthens the representation power of LoRA by initializing it with a\nhigher rank, while efficiently taming a temporarily increased number of\nparameters via updating in a sparse way. We further introduce a sparsifying\nscheduler for SoRA, aiming to examine the impact of the number of non-zero\nparameters on the model's memorization and generalization. Our experimental\nresults demonstrate that SoRA can outperform other baselines even with 70%\nretained parameters and 70% training time.",
            "author": [
                "Ning Ding",
                "Xingtai Lv",
                "Qiaosen Wang",
                "Yulin Chen",
                "Bowen Zhou",
                "Zhiyuan Liu",
                "Maosong Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11696v1",
                "http://arxiv.org/pdf/2311.11696v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11694v1",
            "title": "Unveiling the Power of Self-Attention for Shipping Cost Prediction: The\n  Rate Card Transformer",
            "updated": "2023-11-20T11:48:50Z",
            "published": "2023-11-20T11:48:50Z",
            "summary": "Amazon ships billions of packages to its customers annually within the United\nStates. Shipping cost of these packages are used on the day of shipping (day 0)\nto estimate profitability of sales. Downstream systems utilize these days 0\nprofitability estimates to make financial decisions, such as pricing strategies\nand delisting loss-making products. However, obtaining accurate shipping cost\nestimates on day 0 is complex for reasons like delay in carrier invoicing or\nfixed cost components getting recorded at monthly cadence. Inaccurate shipping\ncost estimates can lead to bad decision, such as pricing items too low or high,\nor promoting the wrong product to the customers. Current solutions for\nestimating shipping costs on day 0 rely on tree-based models that require\nextensive manual engineering efforts. In this study, we propose a novel\narchitecture called the Rate Card Transformer (RCT) that uses self-attention to\nencode all package shipping information such as package attributes, carrier\ninformation and route plan. Unlike other transformer-based tabular models, RCT\nhas the ability to encode a variable list of one-to-many relations of a\nshipment, allowing it to capture more information about a shipment. For\nexample, RCT can encode properties of all products in a package. Our results\ndemonstrate that cost predictions made by the RCT have 28.82% less error\ncompared to tree-based GBDT model. Moreover, the RCT outperforms the\nstate-of-the-art transformer-based tabular model, FTTransformer, by 6.08%. We\nalso illustrate that the RCT learns a generalized manifold of the rate card\nthat can improve the performance of tree-based models.",
            "author": [
                "P Aditya Sreekar",
                "Sahil Verma",
                "Varun Madhavan",
                "Abhishek Persad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11694v1",
                "http://arxiv.org/pdf/2311.11694v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11691v1",
            "title": "Towards Robust Text Retrieval with Progressive Learning",
            "updated": "2023-11-20T11:44:01Z",
            "published": "2023-11-20T11:44:01Z",
            "summary": "Retrieval augmentation has become an effective solution to empower large\nlanguage models (LLMs) with external and verified knowledge sources from the\ndatabase, which overcomes the limitations and hallucinations of LLMs in\nhandling up-to-date and domain-specific information. However, existing\nembedding models for text retrieval usually have three non-negligible\nlimitations. First, the number and diversity of samples in a batch are too\nrestricted to supervise the modeling of textual nuances at scale. Second, the\nhigh proportional noise are detrimental to the semantic correctness and\nconsistency of embeddings. Third, the equal treatment to easy and difficult\nsamples would cause sub-optimum convergence of embeddings with poorer\ngeneralization. In this paper, we propose the PEG, a progressively learned\nembeddings for robust text retrieval. Specifically, we increase the training\nin-batch negative samples to 80,000, and for each query, we extracted five hard\nnegatives. Concurrently, we incorporated a progressive learning mechanism,\nenabling the model to dynamically modulate its attention to the samples\nthroughout the entire training process. Additionally, PEG is trained on more\nthan 100 million data, encompassing a wide range of domains (e.g., finance,\nmedicine, and tourism) and covering various tasks (e.g., question-answering,\nmachine reading comprehension, and similarity matching). Extensive experiments\nconducted on C-MTEB and DuReader demonstrate that PEG surpasses\nstate-of-the-art embeddings in retrieving true positives, highlighting its\nsignificant potential for applications in LLMs. Our model is publicly available\nat https://huggingface.co/TownsWu/PEG.",
            "author": [
                "Tong Wu",
                "Yulei Qin",
                "Enwei Zhang",
                "Zihan Xu",
                "Yuting Gao",
                "Ke Li",
                "Xing Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11691v1",
                "http://arxiv.org/pdf/2311.11691v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11690v1",
            "title": "Refactoring Programs Using Large Language Models with Few-Shot Examples",
            "updated": "2023-11-20T11:43:45Z",
            "published": "2023-11-20T11:43:45Z",
            "summary": "A less complex and more straightforward program is a crucial factor that\nenhances its maintainability and makes writing secure and bug-free programs\neasier. However, due to its heavy workload and the risks of breaking the\nworking programs, programmers are reluctant to do code refactoring, and thus,\nit also causes the loss of potential learning experiences. To mitigate this, we\ndemonstrate the application of using a large language model (LLM), GPT-3.5, to\nsuggest less complex versions of the user-written Python program, aiming to\nencourage users to learn how to write better programs. We propose a method to\nleverage the prompting with few-shot examples of the LLM by selecting the\nbest-suited code refactoring examples for each target programming problem based\non the prior evaluation of prompting with the one-shot example. The\nquantitative evaluation shows that 95.68% of programs can be refactored by\ngenerating 10 candidates each, resulting in a 17.35% reduction in the average\ncyclomatic complexity and a 25.84% decrease in the average number of lines\nafter filtering only generated programs that are semantically correct.\nFurthermore, the qualitative evaluation shows outstanding capability in code\nformatting, while unnecessary behaviors such as deleting or translating\ncomments are also observed.",
            "author": [
                "Atsushi Shirafuji",
                "Yusuke Oda",
                "Jun Suzuki",
                "Makoto Morishita",
                "Yutaka Watanobe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11690v1",
                "http://arxiv.org/pdf/2311.11690v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL",
                "cs.AI",
                "cs.CL",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11689v1",
            "title": "Causal Structure Learning Supervised by Large Language Model",
            "updated": "2023-11-20T11:43:20Z",
            "published": "2023-11-20T11:43:20Z",
            "summary": "Causal discovery from observational data is pivotal for deciphering complex\nrelationships. Causal Structure Learning (CSL), which focuses on deriving\ncausal Directed Acyclic Graphs (DAGs) from data, faces challenges due to vast\nDAG spaces and data sparsity. The integration of Large Language Models (LLMs),\nrecognized for their causal reasoning capabilities, offers a promising\ndirection to enhance CSL by infusing it with knowledge-based causal inferences.\nHowever, existing approaches utilizing LLMs for CSL have encountered issues,\nincluding unreliable constraints from imperfect LLM inferences and the\ncomputational intensity of full pairwise variable analyses. In response, we\nintroduce the Iterative LLM Supervised CSL (ILS-CSL) framework. ILS-CSL\ninnovatively integrates LLM-based causal inference with CSL in an iterative\nprocess, refining the causal DAG using feedback from LLMs. This method not only\nutilizes LLM resources more efficiently but also generates more robust and\nhigh-quality structural constraints compared to previous methodologies. Our\ncomprehensive evaluation across eight real-world datasets demonstrates\nILS-CSL's superior performance, setting a new standard in CSL efficacy and\nshowcasing its potential to significantly advance the field of causal\ndiscovery. The codes are available at\n\\url{https://github.com/tyMadara/ILS-CSL}.",
            "author": [
                "Taiyu Ban",
                "Lyuzhou Chen",
                "Derui Lyu",
                "Xiangyu Wang",
                "Huanhuan Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11689v1",
                "http://arxiv.org/pdf/2311.11689v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11686v1",
            "title": "Segment Together: A Versatile Paradigm for Semi-Supervised Medical Image\n  Segmentation",
            "updated": "2023-11-20T11:35:52Z",
            "published": "2023-11-20T11:35:52Z",
            "summary": "Annotation scarcity has become a major obstacle for training powerful\ndeep-learning models for medical image segmentation, restricting their\ndeployment in clinical scenarios. To address it, semi-supervised learning by\nexploiting abundant unlabeled data is highly desirable to boost the model\ntraining. However, most existing works still focus on limited medical tasks and\nunderestimate the potential of learning across diverse tasks and multiple\ndatasets. Therefore, in this paper, we introduce a \\textbf{Ver}satile\n\\textbf{Semi}-supervised framework (VerSemi) to point out a new perspective\nthat integrates various tasks into a unified model with a broad label space, to\nexploit more unlabeled data for semi-supervised medical image segmentation.\nSpecifically, we introduce a dynamic task-prompted design to segment various\ntargets from different datasets. Next, this unified model is used to identify\nthe foreground regions from all labeled data, to capture cross-dataset\nsemantics. Particularly, we create a synthetic task with a cutmix strategy to\naugment foreground targets within the expanded label space. To effectively\nutilize unlabeled data, we introduce a consistency constraint. This involves\naligning aggregated predictions from various tasks with those from the\nsynthetic task, further guiding the model in accurately segmenting foreground\nregions during training. We evaluated our VerSemi model on four public\nbenchmarking datasets. Extensive experiments demonstrated that VerSemi can\nconsistently outperform the second-best method by a large margin (e.g., an\naverage 2.69\\% Dice gain on four datasets), setting new SOTA performance for\nsemi-supervised medical image segmentation. The code will be released.",
            "author": [
                "Qingjie Zeng",
                "Yutong Xie",
                "Zilin Lu",
                "Mengkang Lu",
                "Yicheng Wu",
                "Yong Xia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11686v1",
                "http://arxiv.org/pdf/2311.11686v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11676v1",
            "title": "Extracting neutron skin from elastic proton-nucleus scattering with deep\n  neural network",
            "updated": "2023-11-20T11:21:27Z",
            "published": "2023-11-20T11:21:27Z",
            "summary": "Based on the relativistic impulse approximation of proton-nucleus elastic\nscattering theory, the nucleon density distribution and neutron skin thickness\nof $^{48}$Ca are estimated via the deep learning method. The\nneural-network-generated densities are mainly compressed to be lower inside the\nnucleus compared with the results from the relativistic PC-PK1 density\nfunctional, resulting in a significant improvement on the large-angle\nscattering observables, both for the differential cross section and analyzing\npower. The neutron skin thickness of $^{48}$Ca is captured to be 0.211(11) fm.\nThe relatively thicker neutron skin is deemed reasonable from the perspective\nof density functional analysis.",
            "author": [
                "G. H. Yang",
                "Y. Kuang",
                "Z. X. Yang",
                "Z. P. Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11676v1",
                "http://arxiv.org/pdf/2311.11676v1"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12084v1",
            "title": "ODDR: Outlier Detection & Dimension Reduction Based Defense Against\n  Adversarial Patches",
            "updated": "2023-11-20T11:08:06Z",
            "published": "2023-11-20T11:08:06Z",
            "summary": "Adversarial attacks are a major deterrent towards the reliable use of machine\nlearning models. A powerful type of adversarial attacks is the patch-based\nattack, wherein the adversarial perturbations modify localized patches or\nspecific areas within the images to deceive the trained machine learning model.\nIn this paper, we introduce Outlier Detection and Dimension Reduction (ODDR), a\nholistic defense mechanism designed to effectively mitigate patch-based\nadversarial attacks. In our approach, we posit that input features\ncorresponding to adversarial patches, whether naturalistic or otherwise,\ndeviate from the inherent distribution of the remaining image sample and can be\nidentified as outliers or anomalies. ODDR employs a three-stage pipeline:\nFragmentation, Segregation, and Neutralization, providing a model-agnostic\nsolution applicable to both image classification and object detection tasks.\nThe Fragmentation stage parses the samples into chunks for the subsequent\nSegregation process. Here, outlier detection techniques identify and segregate\nthe anomalous features associated with adversarial perturbations. The\nNeutralization stage utilizes dimension reduction methods on the outliers to\nmitigate the impact of adversarial perturbations without sacrificing pertinent\ninformation necessary for the machine learning task. Extensive testing on\nbenchmark datasets and state-of-the-art adversarial patches demonstrates the\neffectiveness of ODDR. Results indicate robust accuracies matching and lying\nwithin a small range of clean accuracies (1%-3% for classification and 3%-5%\nfor object detection), with only a marginal compromise of 1%-2% in performance\non clean samples, thereby significantly outperforming other defenses.",
            "author": [
                "Nandish Chattopadhyay",
                "Amira Guesmi",
                "Muhammad Abdullah Hanif",
                "Bassem Ouni",
                "Muhammad Shafique"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12084v1",
                "http://arxiv.org/pdf/2311.12084v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11668v1",
            "title": "AIaaS for ORAN-based 6G Networks: Multi-time scale slice resource\n  management with DRL",
            "updated": "2023-11-20T11:07:33Z",
            "published": "2023-11-20T11:07:33Z",
            "summary": "This paper addresses how to handle slice resources for 6G networks at\ndifferent time scales in an architecture based on an open radio access network\n(ORAN). The proposed solution includes artificial intelligence (AI) at the edge\nof the network and applies two control-level loops to obtain optimal\nperformance compared to other techniques. The ORAN facilitates programmable\nnetwork architectures to support such multi-time scale management using AI\napproaches. The proposed algorithms analyze the maximum utilization of\nresources from slice performance to take decisions at the inter-slice level.\nInter-slice intelligent agents work at a non-real-time level to reconfigure\nresources within various slices. Further than meeting the slice requirements,\nthe intra-slice objective must also include the minimization of maximum\nresource utilization. This enables smart utilization of the resources within\neach slice without affecting slice performance. Here, each xApp that is an\nintra-slice agent aims at meeting the optimal QoS of the users, but at the same\ntime, some inter-slice objectives should be included to coordinate intra- and\ninter-slice agents. This is done without penalizing the main intra-slice\nobjective. All intelligent agents use deep reinforcement learning (DRL)\nalgorithms to meet their objectives. We have presented results for enhanced\nmobile broadband (eMBB), ultra-reliable low latency (URLLC), and massive\nmachine type communication (mMTC) slice categories.",
            "author": [
                "Suvidha Mhatre",
                "Ferran Adelantado",
                "Kostas Ramantas",
                "Christos Verikoukis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11668v1",
                "http://arxiv.org/pdf/2311.11668v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11666v1",
            "title": "OmniSeg3D: Omniversal 3D Segmentation via Hierarchical Contrastive\n  Learning",
            "updated": "2023-11-20T11:04:59Z",
            "published": "2023-11-20T11:04:59Z",
            "summary": "Towards holistic understanding of 3D scenes, a general 3D segmentation method\nis needed that can segment diverse objects without restrictions on object\nquantity or categories, while also reflecting the inherent hierarchical\nstructure. To achieve this, we propose OmniSeg3D, an omniversal segmentation\nmethod aims for segmenting anything in 3D all at once. The key insight is to\nlift multi-view inconsistent 2D segmentations into a consistent 3D feature\nfield through a hierarchical contrastive learning framework, which is\naccomplished by two steps. Firstly, we design a novel hierarchical\nrepresentation based on category-agnostic 2D segmentations to model the\nmulti-level relationship among pixels. Secondly, image features rendered from\nthe 3D feature field are clustered at different levels, which can be further\ndrawn closer or pushed apart according to the hierarchical relationship between\ndifferent levels. In tackling the challenges posed by inconsistent 2D\nsegmentations, this framework yields a global consistent 3D feature field,\nwhich further enables hierarchical segmentation, multi-object selection, and\nglobal discretization. Extensive experiments demonstrate the effectiveness of\nour method on high-quality 3D segmentation and accurate hierarchical structure\nunderstanding. A graphical user interface further facilitates flexible\ninteraction for omniversal 3D segmentation.",
            "author": [
                "Haiyang Ying",
                "Yixuan Yin",
                "Jinzhi Zhang",
                "Fan Wang",
                "Tao Yu",
                "Ruqi Huang",
                "Lu Fang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11666v1",
                "http://arxiv.org/pdf/2311.11666v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11665v1",
            "title": "Enhancing crystal structure prediction by leveraging computational and\n  experimental data: a combination of deep learning and optimization algorithms",
            "updated": "2023-11-20T11:01:21Z",
            "published": "2023-11-20T11:01:21Z",
            "summary": "The determination of material crystal structures has long been a central\nfocus in disciplines such as physics, chemistry, and materials science. In this\nstudy, we introduce an efficient crystal structure prediction method that\ncombines physics-inspired heuristics with advanced deep learning models,\nutilizing extensive quantum mechanics material databases and experimental data.\nBy incorporating both enthalpy of formation and synthesizability, our approach\nenables more accurate predictions of crystal structures that exhibit structural\nstability and are more likely to be successfully synthesized in experiments. In\nparallel, we integrate intelligent optimization algorithms to enhance the\nmodel's efficiency in searching for potential structures within the vast\nchemical space. This comprehensive approach, which merges advanced deep\nlearning models with optimization algorithms while considering factors such as\nthermodynamic stability and synthesizability, holds significant promise for\nsubstantially improving the predictive performance of crystal structures.",
            "author": [
                "Chenglong Qin",
                "Jinde Liu",
                "Yushu Yu",
                "Zihan Xu",
                "Jiguang Du",
                "Shiyin Ma",
                "Gang Jiang",
                "Liang Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11665v1",
                "http://arxiv.org/pdf/2311.11665v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12083v1",
            "title": "PanBench: Towards High-Resolution and High-Performance Pansharpening",
            "updated": "2023-11-20T10:57:23Z",
            "published": "2023-11-20T10:57:23Z",
            "summary": "Pansharpening, a pivotal task in remote sensing, involves integrating\nlow-resolution multispectral images with high-resolution panchromatic images to\nsynthesize an image that is both high-resolution and retains multispectral\ninformation. These pansharpened images enhance precision in land cover\nclassification, change detection, and environmental monitoring within remote\nsensing data analysis. While deep learning techniques have shown significant\nsuccess in pansharpening, existing methods often face limitations in their\nevaluation, focusing on restricted satellite data sources, single scene types,\nand low-resolution images. This paper addresses this gap by introducing\nPanBench, a high-resolution multi-scene dataset containing all mainstream\nsatellites and comprising 5,898 pairs of samples. Each pair includes a\nfour-channel (RGB + near-infrared) multispectral image of 256x256 pixels and a\nmono-channel panchromatic image of 1,024x1,024 pixels. To achieve high-fidelity\nsynthesis, we propose a Cascaded Multiscale Fusion Network (CMFNet) for\nPansharpening. Extensive experiments validate the effectiveness of CMFNet. We\nhave released the dataset, source code, and pre-trained models in the\nsupplementary, fostering further research in remote sensing.",
            "author": [
                "Shiying Wang",
                "Xuechao Zou",
                "Kai Li",
                "Junliang Xing",
                "Pin Tao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12083v1",
                "http://arxiv.org/pdf/2311.12083v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11659v1",
            "title": "MGCT: Mutual-Guided Cross-Modality Transformer for Survival Outcome\n  Prediction using Integrative Histopathology-Genomic Features",
            "updated": "2023-11-20T10:49:32Z",
            "published": "2023-11-20T10:49:32Z",
            "summary": "The rapidly emerging field of deep learning-based computational pathology has\nshown promising results in utilizing whole slide images (WSIs) to objectively\nprognosticate cancer patients. However, most prognostic methods are currently\nlimited to either histopathology or genomics alone, which inevitably reduces\ntheir potential to accurately predict patient prognosis. Whereas integrating\nWSIs and genomic features presents three main challenges: (1) the enormous\nheterogeneity of gigapixel WSIs which can reach sizes as large as\n150,000x150,000 pixels; (2) the absence of a spatially corresponding\nrelationship between histopathology images and genomic molecular data; and (3)\nthe existing early, late, and intermediate multimodal feature fusion strategies\nstruggle to capture the explicit interactions between WSIs and genomics. To\nameliorate these issues, we propose the Mutual-Guided Cross-Modality\nTransformer (MGCT), a weakly-supervised, attention-based multimodal learning\nframework that can combine histology features and genomic features to model the\ngenotype-phenotype interactions within the tumor microenvironment. To validate\nthe effectiveness of MGCT, we conduct experiments using nearly 3,600 gigapixel\nWSIs across five different cancer types sourced from The Cancer Genome Atlas\n(TCGA). Extensive experimental results consistently emphasize that MGCT\noutperforms the state-of-the-art (SOTA) methods.",
            "author": [
                "Mingxin Liu",
                "Yunzan Liu",
                "Hui Cui",
                "Chunquan Li",
                "Jiquan Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11659v1",
                "http://arxiv.org/pdf/2311.11659v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12082v1",
            "title": "Tiny-VBF: Resource-Efficient Vision Transformer based Lightweight\n  Beamformer for Ultrasound Single-Angle Plane Wave Imaging",
            "updated": "2023-11-20T10:47:52Z",
            "published": "2023-11-20T10:47:52Z",
            "summary": "Accelerating compute intensive non-real-time beam-forming algorithms in\nultrasound imaging using deep learning architectures has been gaining momentum\nin the recent past. Nonetheless, the complexity of the state-of-the-art deep\nlearning techniques poses challenges for deployment on resource-constrained\nedge devices. In this work, we propose a novel vision transformer based tiny\nbeamformer (Tiny-VBF), which works on the raw radio-frequency channel data\nacquired through single-angle plane wave insonification. The output of our\nTiny-VBF provides fast envelope detection requiring very low frame rate, i.e.\n0.34 GOPs/Frame for a frame size of 368 x 128 in comparison to the\nstate-of-the-art deep learning models. It also exhibited an 8% increase in\ncontrast and gains of 5% and 33% in axial and lateral resolution respectively\nwhen compared to Tiny-CNN on in-vitro dataset. Additionally, our model showed a\n4.2% increase in contrast and gains of 4% and 20% in axial and lateral\nresolution respectively when compared against conventional Delay-and-Sum (DAS)\nbeamformer. We further propose an accelerator architecture and implement our\nTiny-VBF model on a Zynq UltraScale+ MPSoC ZCU104 FPGA using a hybrid\nquantization scheme with 50% less resource consumption compared to the\nfloating-point implementation, while preserving the image quality.",
            "author": [
                "Abdul Rahoof",
                "Vivek Chaturvedi",
                "Mahesh Raveendranatha Panicker",
                "Muhammad Shafique"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12082v1",
                "http://arxiv.org/pdf/2311.12082v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11656v1",
            "title": "Double-Condensing Attention Condenser: Leveraging Attention in Deep\n  Learning to Detect Skin Cancer from Skin Lesion Images",
            "updated": "2023-11-20T10:45:39Z",
            "published": "2023-11-20T10:45:39Z",
            "summary": "Skin cancer is the most common type of cancer in the United States and is\nestimated to affect one in five Americans. Recent advances have demonstrated\nstrong performance on skin cancer detection, as exemplified by state of the art\nperformance in the SIIM-ISIC Melanoma Classification Challenge; however these\nsolutions leverage ensembles of complex deep neural architectures requiring\nimmense storage and compute costs, and therefore may not be tractable. A recent\nmovement for TinyML applications is integrating Double-Condensing Attention\nCondensers (DC-AC) into a self-attention neural network backbone architecture\nto allow for faster and more efficient computation. This paper explores\nleveraging an efficient self-attention structure to detect skin cancer in skin\nlesion images and introduces a deep neural network design with DC-AC customized\nfor skin cancer detection from skin lesion images. The final model is publicly\navailable as a part of a global open-source initiative dedicated to\naccelerating advancement in machine learning to aid clinicians in the fight\nagainst cancer.",
            "author": [
                "Chi-en Amy Tai",
                "Elizabeth Janes",
                "Chris Czarnecki",
                "Alexander Wong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11656v1",
                "http://arxiv.org/pdf/2311.11656v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16171v1",
            "title": "Multi-Agent Learning of Efficient Fulfilment and Routing Strategies in\n  E-Commerce",
            "updated": "2023-11-20T10:32:28Z",
            "published": "2023-11-20T10:32:28Z",
            "summary": "This paper presents an integrated algorithmic framework for minimising\nproduct delivery costs in e-commerce (known as the cost-to-serve or C2S). One\nof the major challenges in e-commerce is the large volume of spatio-temporally\ndiverse orders from multiple customers, each of which has to be fulfilled from\none of several warehouses using a fleet of vehicles. This results in two levels\nof decision-making: (i) selection of a fulfillment node for each order\n(including the option of deferral to a future time), and then (ii) routing of\nvehicles (each of which can carry multiple orders originating from the same\nwarehouse). We propose an approach that combines graph neural networks and\nreinforcement learning to train the node selection and vehicle routing agents.\nWe include real-world constraints such as warehouse inventory capacity, vehicle\ncharacteristics such as travel times, service times, carrying capacity, and\ncustomer constraints including time windows for delivery. The complexity of\nthis problem arises from the fact that outcomes (rewards) are driven both by\nthe fulfillment node mapping as well as the routing algorithms, and are\nspatio-temporally distributed. Our experiments show that this algorithmic\npipeline outperforms pure heuristic policies.",
            "author": [
                "Omkar Shelke",
                "Pranavi Pathakota",
                "Anandsingh Chauhan",
                "Harshad Khadilkar",
                "Hardik Meisheri",
                "Balaraman Ravindran"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16171v1",
                "http://arxiv.org/pdf/2311.16171v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11647v1",
            "title": "Cancer-Net PCa-Data: An Open-Source Benchmark Dataset for Prostate\n  Cancer Clinical Decision Support using Synthetic Correlated Diffusion Imaging\n  Data",
            "updated": "2023-11-20T10:28:52Z",
            "published": "2023-11-20T10:28:52Z",
            "summary": "The recent introduction of synthetic correlated diffusion (CDI$^s$) imaging\nhas demonstrated significant potential in the realm of clinical decision\nsupport for prostate cancer (PCa). CDI$^s$ is a new form of magnetic resonance\nimaging (MRI) designed to characterize tissue characteristics through the joint\ncorrelation of diffusion signal attenuation across different Brownian motion\nsensitivities. Despite the performance improvement, the CDI$^s$ data for PCa\nhas not been previously made publicly available. In our commitment to advance\nresearch efforts for PCa, we introduce Cancer-Net PCa-Data, an open-source\nbenchmark dataset of volumetric CDI$^s$ imaging data of PCa patients.\nCancer-Net PCa-Data consists of CDI$^s$ volumetric images from a patient cohort\nof 200 patient cases, along with full annotations (gland masks, tumor masks,\nand PCa diagnosis for each tumor). We also analyze the demographic and label\nregion diversity of Cancer-Net PCa-Data for potential biases. Cancer-Net\nPCa-Data is the first-ever public dataset of CDI$^s$ imaging data for PCa, and\nis a part of the global open-source initiative dedicated to advancement in\nmachine learning and imaging research to aid clinicians in the global fight\nagainst cancer.",
            "author": [
                "Hayden Gunraj",
                "Chi-en Amy Tai",
                "Alexander Wong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11647v1",
                "http://arxiv.org/pdf/2311.11647v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12081v1",
            "title": "Leveraging healthy population variability in deep learning unsupervised\n  anomaly detection in brain FDG PET",
            "updated": "2023-11-20T10:28:10Z",
            "published": "2023-11-20T10:28:10Z",
            "summary": "Unsupervised anomaly detection is a popular approach for the analysis of\nneuroimaging data as it allows to identify a wide variety of anomalies from\nunlabelled data. It relies on building a subject-specific model of healthy\nappearance to which a subject's image can be compared to detect anomalies. In\nthe literature, it is common for anomaly detection to rely on analysing the\nresidual image between the subject's image and its pseudo-healthy\nreconstruction. This approach however has limitations partly due to the\npseudo-healthy reconstructions being imperfect and to the lack of natural\nthresholding mechanism. Our proposed method, inspired by Z-scores, leverages\nthe healthy population variability to overcome these limitations. Our\nexperiments conducted on FDG PET scans from the ADNI database demonstrate the\neffectiveness of our approach in accurately identifying Alzheimer's disease\nrelated anomalies.",
            "author": [
                "Ma\u00eblys Solal",
                "Ravi Hassanaly",
                "Ninon Burgos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12081v1",
                "http://arxiv.org/pdf/2311.12081v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.LG",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11646v1",
            "title": "CastDet: Toward Open Vocabulary Aerial Object Detection with\n  CLIP-Activated Student-Teacher Learning",
            "updated": "2023-11-20T10:26:04Z",
            "published": "2023-11-20T10:26:04Z",
            "summary": "Object detection in aerial images is a pivotal task for various earth\nobservation applications, whereas current algorithms learn to detect only a\npre-defined set of object categories demanding sufficient bounding-box\nannotated training samples and fail to detect novel object categories. In this\npaper, we consider open-vocabulary object detection (OVD) in aerial images that\nenables the characterization of new objects beyond training categories on the\nearth surface without annotating training images for these new categories. The\nperformance of OVD depends on the quality of class-agnostic region proposals\nand pseudo-labels that can generalize well to novel object categories. To\nsimultaneously generate high-quality proposals and pseudo-labels, we propose\nCastDet, a CLIP-activated student-teacher open-vocabulary object Detection\nframework. Our end-to-end framework within the student-teacher mechanism\nemploys the CLIP model as an extra omniscient teacher of rich knowledge into\nthe student-teacher self-learning process. By doing so, our approach boosts\nnovel object proposals and classification. Furthermore, we design a dynamic\nlabel queue technique to maintain high-quality pseudo labels during batch\ntraining and mitigate label imbalance. We conduct extensive experiments on\nmultiple existing aerial object detection datasets, which are set up for the\nOVD task. Experimental results demonstrate our CastDet achieving superior\nopen-vocabulary detection performance, e.g., reaching 40.0 HM (Harmonic Mean),\nwhich outperforms previous methods Detic/ViLD by 26.9/21.1 on the VisDroneZSD\ndataset.",
            "author": [
                "Yan Li",
                "Weiwei Guo",
                "Dunyun He",
                "Jiaqi Zhou",
                "Yuze Gao",
                "Wenxian Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11646v1",
                "http://arxiv.org/pdf/2311.11646v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11644v1",
            "title": "Unraveling the Control Engineer's Craft with Neural Networks",
            "updated": "2023-11-20T10:22:38Z",
            "published": "2023-11-20T10:22:38Z",
            "summary": "Many industrial processes require suitable controllers to meet their\nperformance requirements. More often, a sophisticated digital twin is\navailable, which is a highly complex model that is a virtual representation of\na given physical process, whose parameters may not be properly tuned to capture\nthe variations in the physical process. In this paper, we present a sim2real,\ndirect data-driven controller tuning approach, where the digital twin is used\nto generate input-output data and suitable controllers for several\nperturbations in its parameters. State-of-the art neural-network architectures\nare then used to learn the controller tuning rule that maps input-output data\nonto the controller parameters, based on artificially generated data from\nperturbed versions of the digital twin. In this way, as far as we are aware, we\ntackle for the first time the problem of re-calibrating the controller by\nmeta-learning the tuning rule directly from data, thus practically replacing\nthe control engineer with a machine learning model. The benefits of this\nmethodology are illustrated via numerical simulations for several choices of\nneural-network architectures.",
            "author": [
                "Braghadeesh Lakshminarayanan",
                "Federico Dett\u00f9",
                "Cristian R. Rojas",
                "Simone Formentin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11644v1",
                "http://arxiv.org/pdf/2311.11644v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14725v1",
            "title": "Unsupervised learning of site percolation based on shuffled\n  configurations",
            "updated": "2023-11-20T10:21:50Z",
            "published": "2023-11-20T10:21:50Z",
            "summary": "In the field of statistical physics, machine learning has gained significant\npopularity and has achieved remarkable results in recent studies on phase\ntransitions.In this paper, we apply Principal Component Analysis (PCA) and\nAutoencoder(AE) based on Unsupervised learning to study the various\nconfigurations of the percolation model in equilibrium phase transition. In\ncertain phase transition models, such as the DP model in non-equilibrium phase\ntransitions, the order parameter is particle density. However, in some other\nphase transition models, such as the percolation model, it is not. This study\ninvolved randomizing and selecting percolation graphs to be used as input for a\nneural network, and analyzed the obtained results, indicating that the outputs\nof the single latent variable of AE and the first principal component of PCA\nare signals related to particle density.",
            "author": [
                "Dian Xu",
                "Shanshan Wang",
                "Feng Gao",
                "Wei Li",
                "Jianmin Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14725v1",
                "http://arxiv.org/pdf/2311.14725v1"
            ],
            "primary_category": "cond-mat.stat-mech",
            "category": [
                "cond-mat.stat-mech",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11642v2",
            "title": "Video Face Re-Aging: Toward Temporally Consistent Face Re-Aging",
            "updated": "2023-12-07T05:47:50Z",
            "published": "2023-11-20T10:01:13Z",
            "summary": "Video face re-aging deals with altering the apparent age of a person to the\ntarget age in videos. This problem is challenging due to the lack of paired\nvideo datasets maintaining temporal consistency in identity and age. Most\nre-aging methods process each image individually without considering the\ntemporal consistency of videos. While some existing works address the issue of\ntemporal coherence through video facial attribute manipulation in latent space,\nthey often fail to deliver satisfactory performance in age transformation. To\ntackle the issues, we propose (1) a novel synthetic video dataset that features\nsubjects across a diverse range of age groups; (2) a baseline architecture\ndesigned to validate the effectiveness of our proposed dataset, and (3) the\ndevelopment of three novel metrics tailored explicitly for evaluating the\ntemporal consistency of video re-aging techniques. Our comprehensive\nexperiments on public datasets, such as VFHQ and CelebV-HQ, show that our\nmethod outperforms the existing approaches in terms of both age transformation\nand temporal consistency.",
            "author": [
                "Abdul Muqeet",
                "Kyuchul Lee",
                "Bumsoo Kim",
                "Yohan Hong",
                "Hyungrae Lee",
                "Woonggon Kim",
                "KwangHee Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11642v2",
                "http://arxiv.org/pdf/2311.11642v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11639v1",
            "title": "Efficient learning of Sparse Pauli Lindblad models for fully connected\n  qubit topology",
            "updated": "2023-11-20T09:55:24Z",
            "published": "2023-11-20T09:55:24Z",
            "summary": "The challenge to achieve practical quantum computing considering current\nhardware size and gate fidelity is the sensitivity to errors and noise. Recent\nwork has shown that by learning the underlying noise model capturing qubit\ncross-talk, error mitigation can push the boundary of practical quantum\ncomputing. This has been accomplished using Sparse Pauli-Lindblad models only\non devices with a linear topology connectivity (i.e. superconducting qubit\ndevices). In this work we extend the theoretical requirement for learning such\nnoise models on hardware with full connectivity (i.e. ion trap devices).",
            "author": [
                "Jose Este Jaloveckas",
                "Minh Tham Pham Nguyen",
                "Lilly Palackal",
                "Jeanette Miriam Lorenz",
                "Hans Ehm"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11639v1",
                "http://arxiv.org/pdf/2311.11639v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "math-ph",
                "math.MP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12876v1",
            "title": "Energy efficiency in Edge TPU vs. embedded GPU for computer-aided\n  medical imaging segmentation and classification",
            "updated": "2023-11-20T09:38:56Z",
            "published": "2023-11-20T09:38:56Z",
            "summary": "In this work, we evaluate the energy usage of fully embedded medical\ndiagnosis aids based on both segmentation and classification of medical images\nimplemented on Edge TPU and embedded GPU processors. We use glaucoma diagnosis\nbased on color fundus images as an example to show the possibility of\nperforming segmentation and classification in real time on embedded boards and\nto highlight the different energy requirements of the studied implementations.\n  Several other works develop the use of segmentation and feature extraction\ntechniques to detect glaucoma, among many other pathologies, with deep neural\nnetworks. Memory limitations and low processing capabilities of embedded\naccelerated systems (EAS) limit their use for deep network-based system\ntraining. However, including specific acceleration hardware, such as NVIDIA's\nMaxwell GPU or Google's Edge TPU, enables them to perform inferences using\ncomplex pre-trained networks in very reasonable times.\n  In this study, we evaluate the timing and energy performance of two EAS\nequipped with Machine Learning (ML) accelerators executing an example\ndiagnostic tool developed in a previous work. For optic disc (OD) and cup (OC)\nsegmentation, the obtained prediction times per image are under 29 and 43 ms\nusing Edge TPUs and Maxwell GPUs, respectively. Prediction times for the\nclassification subsystem are lower than 10 and 14 ms for Edge TPUs and Maxwell\nGPUs, respectively. Regarding energy usage, in approximate terms, for OD\nsegmentation Edge TPUs and Maxwell GPUs use 38 and 190 mJ per image,\nrespectively. For fundus classification, Edge TPUs and Maxwell GPUs use 45 and\n70 mJ, respectively.",
            "author": [
                "Jos\u00e9 Mar\u00eda Rodr\u00edguez Corral",
                "Javier Civit-Masot",
                "Francisco Luna-Perej\u00f3n",
                "Ignacio D\u00edaz-Cano",
                "Arturo Morgado-Est\u00e9vez",
                "Manuel Dom\u00ednguez-Morales"
            ],
            "link": [
                "http://dx.doi.org/10.1016/j.engappai.2023.107298",
                "http://arxiv.org/abs/2311.12876v1",
                "http://arxiv.org/pdf/2311.12876v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11629v2",
            "title": "Generating Realistic Counterfactuals for Retinal Fundus and OCT Images\n  using Diffusion Models",
            "updated": "2023-12-04T17:01:20Z",
            "published": "2023-11-20T09:28:04Z",
            "summary": "Counterfactual reasoning is often used in clinical settings to explain\ndecisions or weigh alternatives. Therefore, for imaging based specialties such\nas ophthalmology, it would be beneficial to be able to create counterfactual\nimages, illustrating answers to questions like \"If the subject had had diabetic\nretinopathy, how would the fundus image have looked?\". Here, we demonstrate\nthat using a diffusion model in combination with an adversarially robust\nclassifier trained on retinal disease classification tasks enables the\ngeneration of highly realistic counterfactuals of retinal fundus images and\noptical coherence tomography (OCT) B-scans. The key to the realism of\ncounterfactuals is that these classifiers encode salient features indicative\nfor each disease class and can steer the diffusion model to depict disease\nsigns or remove disease-related lesions in a realistic way. In a user study,\ndomain experts also found the counterfactuals generated using our method\nsignificantly more realistic than counterfactuals generated from a previous\nmethod, and even indistinguishable from real images.",
            "author": [
                "Indu Ilanchezian",
                "Valentyn Boreiko",
                "Laura K\u00fchlewein",
                "Ziwei Huang",
                "Murat Se\u00e7kin Ayhan",
                "Matthias Hein",
                "Lisa Koch",
                "Philipp Berens"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11629v2",
                "http://arxiv.org/pdf/2311.11629v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11628v1",
            "title": "Incorporating LLM Priors into Tabular Learners",
            "updated": "2023-11-20T09:27:09Z",
            "published": "2023-11-20T09:27:09Z",
            "summary": "We present a method to integrate Large Language Models (LLMs) and traditional\ntabular data classification techniques, addressing LLMs challenges like data\nserialization sensitivity and biases. We introduce two strategies utilizing\nLLMs for ranking categorical variables and generating priors on correlations\nbetween continuous variables and targets, enhancing performance in few-shot\nscenarios. We focus on Logistic Regression, introducing MonotonicLR that\nemploys a non-linear monotonic function for mapping ordinals to cardinals while\npreserving LLM-determined orders. Validation against baseline models reveals\nthe superior performance of our approach, especially in low-data scenarios,\nwhile remaining interpretable.",
            "author": [
                "Max Zhu",
                "Sini\u0161a Stanivuk",
                "Andrija Petrovic",
                "Mladen Nikolic",
                "Pietro Lio"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11628v1",
                "http://arxiv.org/pdf/2311.11628v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12875v1",
            "title": "Nav-Q: Quantum Deep Reinforcement Learning for Collision-Free Navigation\n  of Self-Driving Cars",
            "updated": "2023-11-20T09:25:26Z",
            "published": "2023-11-20T09:25:26Z",
            "summary": "The challenge of collision-free navigation (CFN) for self-driving cars is an\nNP-hard problem addressed through Deep Reinforcement Learning (DRL). Despite\nthe effectiveness of DRL methods, their application demands significant\ncomputing resources and prolonged training periods to establish a resilient\nagent. On the other hand, quantum reinforcement learning algorithms have\nrecently demonstrated faster convergence and improved stability in simple,\nnon-real-world environments. However, their application in the real-world CFN\ndomain has not been explored, and their direct adaptation would require a\nquantum computing device onboard the vehicle for testing.\n  In this work, we propose Nav-Q, the first quantum-supported DRL algorithm for\nCFN of self-driving cars, that leverages quantum computation for improving the\ntraining performance without the requirement for onboard quantum hardware.\nNav-Q is based on the actor-critic approach, where the critic is implemented\nusing a hybrid quantum-classical algorithm suitable for near-term quantum\ndevices. We assess the performance of Nav-Q using the CARLA driving simulator,\na de facto standard benchmark for evaluating state-of-the-art DRL methods. Our\nempirical evaluations showcase that Nav-Q surpasses its classical counterpart\nnot only in terms of training stability but also, in certain instances, with\nrespect to the convergence rate when analyzing the Reward vs. Episode curve.\nThis enhancement is accomplished without negatively impacting the learned\npolicy by the agent. Furthermore, we assess Nav-Q in relation to effective\ndimension, unveiling that the incorporation of a quantum component results in a\nmodel possessing greater descriptive power compared to classical baselines.\nFinally, we evaluate the performance of Nav-Q using noisy quantum simulation,\nobserving that the quantum noise enhances the exploratory tendencies of the\nagent during training.",
            "author": [
                "Akash Sinha",
                "Antonio Macaluso",
                "Matthias Klusch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12875v1",
                "http://arxiv.org/pdf/2311.12875v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11626v1",
            "title": "A novel transformer-based approach for soil temperature prediction",
            "updated": "2023-11-20T09:20:26Z",
            "published": "2023-11-20T09:20:26Z",
            "summary": "Soil temperature is one of the most significant parameters that plays a\ncrucial role in glacier energy, dynamics of mass balance, processes of surface\nhydrological, coaction of glacier-atmosphere, nutrient cycling, ecological\nstability, the management of soil, water, and field crop. In this work, we\nintroduce a novel approach using transformer models for the purpose of\nforecasting soil temperature prediction. To the best of our knowledge, the\nusage of transformer models in this work is the very first attempt to predict\nsoil temperature. Experiments are carried out using six different FLUXNET\nstations by modeling them with five different transformer models, namely,\nVanilla Transformer, Informer, Autoformer, Reformer, and ETSformer. To\ndemonstrate the effectiveness of the proposed model, experiment results are\ncompared with both deep learning approaches and literature studies. Experiment\nresults show that the utilization of transformer models ensures a significant\ncontribution to the literature, thence determining the new state-of-the-art.",
            "author": [
                "Muhammet Mucahit Enes Yurtsever",
                "Ayhan Kucukmanisa",
                "Zeynep Hilal Kilimci"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11626v1",
                "http://arxiv.org/pdf/2311.11626v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CE",
                "physics.ao-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11605v1",
            "title": "Machine learning-based malware detection for IoT devices using\n  control-flow data",
            "updated": "2023-11-20T08:43:09Z",
            "published": "2023-11-20T08:43:09Z",
            "summary": "Embedded devices are specialised devices designed for one or only a few\npurposes. They are often part of a larger system, through wired or wireless\nconnection. Those embedded devices that are connected to other computers or\nembedded systems through the Internet are called Internet of Things (IoT for\nshort) devices.\n  With their widespread usage and their insufficient protection, these devices\nare increasingly becoming the target of malware attacks. Companies often cut\ncorners to save manufacturing costs or misconfigure when producing these\ndevices. This can be lack of software updates, ports left open or security\ndefects by design. Although these devices may not be as powerful as a regular\ncomputer, their large number makes them suitable candidates for botnets. Other\ntypes of IoT devices can even cause health problems since there are even\npacemakers connected to the Internet. This means, that without sufficient\ndefence, even directed assaults are possible against people.\n  The goal of this thesis project is to provide better security for these\ndevices with the help of machine learning algorithms and reverse engineering\ntools. Specifically, I study the applicability of control-flow related data of\nexecutables for malware detection. I present a malware detection method with\ntwo phases. The first phase extracts control-flow related data using static\nbinary analysis. The second phase classifies binary executables as either\nmalicious or benign using a neural network model. I train the model using a\ndataset of malicious and benign ARM applications.",
            "author": [
                "Gergely Hevesi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11605v1",
                "http://arxiv.org/pdf/2311.11605v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11604v1",
            "title": "CurriculumLoc: Enhancing Cross-Domain Geolocalization through\n  Multi-Stage Refinement",
            "updated": "2023-11-20T08:40:01Z",
            "published": "2023-11-20T08:40:01Z",
            "summary": "Visual geolocalization is a cost-effective and scalable task that involves\nmatching one or more query images, taken at some unknown location, to a set of\ngeo-tagged reference images. Existing methods, devoted to semantic features\nrepresentation, evolving towards robustness to a wide variety between query and\nreference, including illumination and viewpoint changes, as well as scale and\nseasonal variations. However, practical visual geolocalization approaches need\nto be robust in appearance changing and extreme viewpoint variation conditions,\nwhile providing accurate global location estimates. Therefore, inspired by\ncurriculum design, human learn general knowledge first and then delve into\nprofessional expertise. We first recognize semantic scene and then measure\ngeometric structure. Our approach, termed CurriculumLoc, involves a delicate\ndesign of multi-stage refinement pipeline and a novel keypoint detection and\ndescription with global semantic awareness and local geometric verification. We\nrerank candidates and solve a particular cross-domain perspective-n-point (PnP)\nproblem based on these keypoints and corresponding descriptors, position\nrefinement occurs incrementally. The extensive experimental results on our\ncollected dataset, TerraTrack and a benchmark dataset, ALTO, demonstrate that\nour approach results in the aforementioned desirable characteristics of a\npractical visual geolocalization solution. Additionally, we achieve new high\nrecall@1 scores of 62.6% and 94.5% on ALTO, with two different distances\nmetrics, respectively. Dataset, code and trained models are publicly available\non https://github.com/npupilab/CurriculumLoc.",
            "author": [
                "Boni Hu",
                "Lin Chen",
                "Runjian Chen",
                "Shuhui Bu",
                "Pengcheng Han",
                "Haowei Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11604v1",
                "http://arxiv.org/pdf/2311.11604v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11602v3",
            "title": "A Multi-In-Single-Out Network for Video Frame Interpolation without\n  Optical Flow",
            "updated": "2023-12-05T00:07:12Z",
            "published": "2023-11-20T08:29:55Z",
            "summary": "In general, deep learning-based video frame interpolation (VFI) methods have\npredominantly focused on estimating motion vectors between two input frames and\nwarping them to the target time. While this approach has shown impressive\nperformance for linear motion between two input frames, it exhibits limitations\nwhen dealing with occlusions and nonlinear movements. Recently, generative\nmodels have been applied to VFI to address these issues. However, as VFI is not\na task focused on generating plausible images, but rather on predicting\naccurate intermediate frames between two given frames, performance limitations\nstill persist. In this paper, we propose a multi-in-single-out (MISO) based VFI\nmethod that does not rely on motion vector estimation, allowing it to\neffectively model occlusions and nonlinear motion. Additionally, we introduce a\nnovel motion perceptual loss that enables MISO-VFI to better capture the\nspatio-temporal correlations within the video frames. Our MISO-VFI method\nachieves state-of-the-art results on VFI benchmarks Vimeo90K, Middlebury, and\nUCF101, with a significant performance gap compared to existing approaches.",
            "author": [
                "Jaemin Lee",
                "Minseok Seo",
                "Sangwoo Lee",
                "Hyobin Park",
                "Dong-Geol Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11602v3",
                "http://arxiv.org/pdf/2311.11602v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11596v1",
            "title": "High-performance cVEP-BCI under minimal calibration",
            "updated": "2023-11-20T08:20:51Z",
            "published": "2023-11-20T08:20:51Z",
            "summary": "The ultimate goal of brain-computer interfaces (BCIs) based on visual\nmodulation paradigms is to achieve high-speed performance without the burden of\nextensive calibration. Code-modulated visual evoked potential-based BCIs\n(cVEP-BCIs) modulated by broadband white noise (WN) offer various advantages,\nincluding increased communication speed, expanded encoding target capabilities,\nand enhanced coding flexibility. However, the complexity of the\nspatial-temporal patterns under broadband stimuli necessitates extensive\ncalibration for effective target identification in cVEP-BCIs. Consequently, the\ninformation transfer rate (ITR) of cVEP-BCI under limited calibration usually\nstays around 100 bits per minute (bpm), significantly lagging behind\nstate-of-the-art steady-state visual evoked potential-based BCIs (SSVEP-BCIs),\nwhich achieve rates above 200 bpm. To enhance the performance of cVEP-BCIs with\nminimal calibration, we devised an efficient calibration stage involving a\nbrief single-target flickering, lasting less than a minute, to extract\ngeneralizable spatial-temporal patterns. Leveraging the calibration data, we\ndeveloped two complementary methods to construct cVEP temporal patterns: the\nlinear modeling method based on the stimulus sequence and the transfer learning\ntechniques using cross-subject data. As a result, we achieved the highest ITR\nof 250 bpm under a minute of calibration, which has been shown to be comparable\nto the state-of-the-art SSVEP paradigms. In summary, our work significantly\nimproved the cVEP performance under few-shot learning, which is expected to\nexpand the practicality and usability of cVEP-BCIs.",
            "author": [
                "Yining Miao",
                "Nanlin Shi",
                "Changxing Huang",
                "Yonghao Song",
                "Xiaogang Chen",
                "Yijun Wang",
                "Xiaorong Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11596v1",
                "http://arxiv.org/pdf/2311.11596v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.IT",
                "eess.SP",
                "math.IT",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11592v1",
            "title": "Predicting urban tree cover from incomplete point labels and limited\n  background information",
            "updated": "2023-11-20T08:09:54Z",
            "published": "2023-11-20T08:09:54Z",
            "summary": "Trees inside cities are important for the urban microclimate, contributing\npositively to the physical and mental health of the urban dwellers. Despite\ntheir importance, often only limited information about city trees is available.\nTherefore in this paper, we propose a method for mapping urban trees in\nhigh-resolution aerial imagery using limited datasets and deep learning. Deep\nlearning has become best-practice for this task, however, existing approaches\nrely on large and accurately labelled training datasets, which can be difficult\nand expensive to obtain. However, often noisy and incomplete data may be\navailable that can be combined and utilized to solve more difficult tasks than\nthose datasets were intended for. This paper studies how to combine accurate\npoint labels of urban trees along streets with crowd-sourced annotations from\nan open geographic database to delineate city trees in remote sensing images, a\ntask which is challenging even for humans. To that end, we perform semantic\nsegmentation of very high resolution aerial imagery using a fully convolutional\nneural network. The main challenge is that our segmentation maps are sparsely\nannotated and incomplete. Small areas around the point labels of the street\ntrees coming from official and crowd-sourced data are marked as foreground\nclass. Crowd-sourced annotations of streets, buildings, etc. define the\nbackground class. Since the tree data is incomplete, we introduce a masking to\navoid class confusion. Our experiments in Hamburg, Germany, showed that the\nsystem is able to produce tree cover maps, not limited to trees along streets,\nwithout providing tree delineations. We evaluated the method on manually\nlabelled trees and show that performance drastically deteriorates if the open\ngeographic database is not used.",
            "author": [
                "Hui Zhang",
                "Ankit Kariryaa",
                "Venkanna Babu Guthula",
                "Christian Igel",
                "Stefan Oehmcke"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11592v1",
                "http://arxiv.org/pdf/2311.11592v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11590v1",
            "title": "Advancing Urban Renewal: An Automated Approach to Generating Historical\n  Arcade Facades with Stable Diffusion Models",
            "updated": "2023-11-20T08:03:12Z",
            "published": "2023-11-20T08:03:12Z",
            "summary": "Urban renewal and transformation processes necessitate the preservation of\nthe historical urban fabric, particularly in districts known for their\narchitectural and historical significance. These regions, with their diverse\narchitectural styles, have traditionally required extensive preliminary\nresearch, often leading to subjective results. However, the advent of machine\nlearning models has opened up new avenues for generating building facade\nimages. Despite this, creating high-quality images for historical district\nrenovations remains challenging, due to the complexity and diversity inherent\nin such districts. In response to these challenges, our study introduces a new\nmethodology for automatically generating images of historical arcade facades,\nutilizing Stable Diffusion models conditioned on textual descriptions. By\nclassifying and tagging a variety of arcade styles, we have constructed several\nrealistic arcade facade image datasets. We trained multiple low-rank adaptation\n(LoRA) models to control the stylistic aspects of the generated images,\nsupplemented by ControlNet models for improved precision and authenticity. Our\napproach has demonstrated high levels of precision, authenticity, and diversity\nin the generated images, showing promising potential for real-world urban\nrenewal projects. This new methodology offers a more efficient and accurate\nalternative to conventional design processes in urban renewal, bypassing issues\nof unconvincing image details, lack of precision, and limited stylistic\nvariety. Future research could focus on integrating this two-dimensional image\ngeneration with three-dimensional modeling techniques, providing a more\ncomprehensive solution for renovating architectural facades in historical\ndistricts.",
            "author": [
                "Zheyuan Kuang",
                "Jiaxin Zhang",
                "Yiying Huang",
                "Yunqin Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11590v1",
                "http://arxiv.org/pdf/2311.11590v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11587v2",
            "title": "AKConv: Convolutional Kernel with Arbitrary Sampled Shapes and Arbitrary\n  Number of Parameters",
            "updated": "2023-11-26T12:27:27Z",
            "published": "2023-11-20T07:54:54Z",
            "summary": "Neural networks based on convolutional operations have achieved remarkable\nresults in the field of deep learning, but there are two inherent flaws in\nstandard convolutional operations. On the one hand, the convolution operation\nbe confined to a local window and cannot capture information from other\nlocations, and its sampled shapes is fixed. On the other hand, the size of the\nconvolutional kernel is fixed to k $\\times$ k, which is a fixed square shape,\nand the number of parameters tends to grow squarely with size. It is obvious\nthat the shape and size of targets are various in different datasets and at\ndifferent locations. Convolutional kernels with fixed sample shapes and squares\ndo not adapt well to changing targets. In response to the above questions, the\nAlterable Kernel Convolution (AKConv) is explored in this work, which gives the\nconvolution kernel an arbitrary number of parameters and arbitrary sampled\nshapes to provide richer options for the trade-off between network overhead and\nperformance. In AKConv, we define initial positions for convolutional kernels\nof arbitrary size by means of a new coordinate generation algorithm. To adapt\nto changes for targets, we introduce offsets to adjust the shape of the samples\nat each position. Moreover, we explore the effect of the neural network by\nusing the AKConv with the same size and different initial sampled shapes.\nAKConv completes the process of efficient feature extraction by irregular\nconvolutional operations and brings more exploration options for convolutional\nsampling shapes. Object detection experiments on representative datasets\nCOCO2017, VOC 7+12 and VisDrone-DET2021 fully demonstrate the advantages of\nAKConv. AKConv can be used as a plug-and-play convolutional operation to\nreplace convolutional operations to improve network performance. The code for\nthe relevant tasks can be found at https://github.com/CV-ZhangXin/AKConv.",
            "author": [
                "Xin Zhang",
                "Yingze Song",
                "Tingting Song",
                "Degang Yang",
                "Yichen Ye",
                "Jie Zhou",
                "Liming Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11587v2",
                "http://arxiv.org/pdf/2311.11587v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11580v1",
            "title": "SeaDSC: A video-based unsupervised method for dynamic scene change\n  detection in unmanned surface vehicles",
            "updated": "2023-11-20T07:34:01Z",
            "published": "2023-11-20T07:34:01Z",
            "summary": "Recently, there has been an upsurge in the research on maritime vision, where\na lot of works are influenced by the application of computer vision for\nUnmanned Surface Vehicles (USVs). Various sensor modalities such as camera,\nradar, and lidar have been used to perform tasks such as object detection,\nsegmentation, object tracking, and motion planning. A large subset of this\nresearch is focused on the video analysis, since most of the current vessel\nfleets contain the camera's onboard for various surveillance tasks. Due to the\nvast abundance of the video data, video scene change detection is an initial\nand crucial stage for scene understanding of USVs. This paper outlines our\napproach to detect dynamic scene changes in USVs. To the best of our\nunderstanding, this work represents the first investigation of scene change\ndetection in the maritime vision application. Our objective is to identify\nsignificant changes in the dynamic scenes of maritime video data, particularly\nthose scenes that exhibit a high degree of resemblance. In our system for\ndynamic scene change detection, we propose completely unsupervised learning\nmethod. In contrast to earlier studies, we utilize a modified cutting-edge\ngenerative picture model called VQ-VAE-2 to train on multiple marine datasets,\naiming to enhance the feature extraction. Next, we introduce our innovative\nsimilarity scoring technique for directly calculating the level of similarity\nin a sequence of consecutive frames by utilizing grid calculation on retrieved\nfeatures. The experiments were conducted using a nautical video dataset called\nRoboWhaler to showcase the efficient performance of our technique.",
            "author": [
                "Linh Trinh",
                "Ali Anwar",
                "Siegfried Mercelis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11580v1",
                "http://arxiv.org/pdf/2311.11580v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11575v1",
            "title": "Testing multivariate normality by testing independence",
            "updated": "2023-11-20T07:19:52Z",
            "published": "2023-11-20T07:19:52Z",
            "summary": "We propose a simple multivariate normality test based on Kac-Bernstein's\ncharacterization, which can be conducted by utilising existing statistical\nindependence tests for sums and differences of data samples. We also perform\nits empirical investigation, which reveals that for high-dimensional data, the\nproposed approach may be more efficient than the alternative ones. The\naccompanying code repository is provided at \\url{https://shorturl.at/rtuy5}.",
            "author": [
                "Povilas Daniu\u0161is"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11575v1",
                "http://arxiv.org/pdf/2311.11575v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11570v1",
            "title": "Decoupled DETR For Few-shot Object Detection",
            "updated": "2023-11-20T07:10:39Z",
            "published": "2023-11-20T07:10:39Z",
            "summary": "Few-shot object detection (FSOD), an efficient method for addressing the\nsevere data-hungry problem, has been extensively discussed. Current works have\nsignificantly advanced the problem in terms of model and data. However, the\noverall performance of most FSOD methods still does not fulfill the desired\naccuracy. In this paper we improve the FSOD model to address the severe issue\nof sample imbalance and weak feature propagation. To alleviate modeling bias\nfrom data-sufficient base classes, we examine the effect of decoupling the\nparameters for classes with sufficient data and classes with few samples in\nvarious ways. We design a base-novel categories decoupled DETR (DeDETR) for\nFSOD. We also explore various types of skip connection between the encoder and\ndecoder for DETR. Besides, we notice that the best outputs could come from the\nintermediate layer of the decoder instead of the last layer; therefore, we\nbuild a unified decoder module that could dynamically fuse the decoder layers\nas the output feature. We evaluate our model on commonly used datasets such as\nPASCAL VOC and MSCOCO. Our results indicate that our proposed module could\nachieve stable improvements of 5% to 10% in both fine-tuning and meta-learning\nparadigms and has outperformed the highest score in recent works.",
            "author": [
                "Zeyu Shangguan",
                "Lian Huai",
                "Tong Liu",
                "Xingqun Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11570v1",
                "http://arxiv.org/pdf/2311.11570v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12874v1",
            "title": "SpecHD: Hyperdimensional Computing Framework for FPGA-based Mass\n  Spectrometry Clustering",
            "updated": "2023-11-20T06:42:37Z",
            "published": "2023-11-20T06:42:37Z",
            "summary": "Mass spectrometry-based proteomics is a key enabler for personalized\nhealthcare, providing a deep dive into the complex protein compositions of\nbiological systems. This technology has vast applications in biotechnology and\nbiomedicine but faces significant computational bottlenecks. Current\nmethodologies often require multiple hours or even days to process extensive\ndatasets, particularly in the domain of spectral clustering. To tackle these\ninefficiencies, we introduce SpecHD, a hyperdimensional computing (HDC)\nframework supplemented by an FPGA-accelerated architecture with integrated\nnear-storage preprocessing. Utilizing streamlined binary operations in an HDC\nenvironment, SpecHD capitalizes on the low-latency and parallel capabilities of\nFPGAs. This approach markedly improves clustering speed and efficiency, serving\nas a catalyst for real-time, high-throughput data analysis in future healthcare\napplications. Our evaluations demonstrate that SpecHD not only maintains but\noften surpasses existing clustering quality metrics while drastically cutting\ncomputational time. Specifically, it can cluster a large-scale human proteome\ndataset-comprising 25 million MS/MS spectra and 131 GB of MS data-in just 5\nminutes. With energy efficiency exceeding 31x and a speedup factor that spans a\nrange of 6x to 54x over existing state of-the-art solutions, SpecHD emerges as\na promising solution for the rapid analysis of mass spectrometry data with\ngreat implications for personalized healthcare.",
            "author": [
                "Sumukh Pinge",
                "Weihong Xu",
                "Jaeyoung Kang",
                "Tianqi Zhang",
                "Neima Moshiri",
                "Wout Bittremieux",
                "Tajana Rosing"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12874v1",
                "http://arxiv.org/pdf/2311.12874v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.AR",
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11558v1",
            "title": "A Deep-Genetic Algorithm (Deep-GA) Approach for High-Dimensional\n  Nonlinear Parabolic Partial Differential Equations",
            "updated": "2023-11-20T06:35:23Z",
            "published": "2023-11-20T06:35:23Z",
            "summary": "We propose a new method, called a deep-genetic algorithm (deep-GA), to\naccelerate the performance of the so-called deep-BSDE method, which is a deep\nlearning algorithm to solve high dimensional partial differential equations\nthrough their corresponding backward stochastic differential equations (BSDEs).\nRecognizing the sensitivity of the solver to the initial guess selection, we\nembed a genetic algorithm (GA) into the solver to optimize the selection. We\naim to achieve faster convergence for the nonlinear PDEs on a broader interval\nthan deep-BSDE. Our proposed method is applied to two nonlinear parabolic PDEs,\ni.e., the Black-Scholes (BS) equation with default risk and the\nHamilton-Jacobi-Bellman (HJB) equation. We compare the results of our method\nwith those of the deep-BSDE and show that our method provides comparable\naccuracy with significantly improved computational efficiency.",
            "author": [
                "Endah Rokhmati Merdika Putri",
                "Muhammad Luthfi Shahab",
                "Mohammad Iqbal",
                "Imam Mukhlash",
                "Amirul Hakam",
                "Lutfi Mardianto",
                "Hadi Susanto"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11558v1",
                "http://arxiv.org/pdf/2311.11558v1"
            ],
            "primary_category": "math.AP",
            "category": [
                "math.AP",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11557v1",
            "title": "Replay-enhanced Continual Reinforcement Learning",
            "updated": "2023-11-20T06:21:52Z",
            "published": "2023-11-20T06:21:52Z",
            "summary": "Replaying past experiences has proven to be a highly effective approach for\naverting catastrophic forgetting in supervised continual learning. However,\nsome crucial factors are still largely ignored, making it vulnerable to serious\nfailure, when used as a solution to forgetting in continual reinforcement\nlearning, even in the context of perfect memory where all data of previous\ntasks are accessible in the current task. On the one hand, since most\nreinforcement learning algorithms are not invariant to the reward scale, the\npreviously well-learned tasks (with high rewards) may appear to be more salient\nto the current learning process than the current task (with small initial\nrewards). This causes the agent to concentrate on those salient tasks at the\nexpense of generality on the current task. On the other hand, offline learning\non replayed tasks while learning a new task may induce a distributional shift\nbetween the dataset and the learned policy on old tasks, resulting in\nforgetting. In this paper, we introduce RECALL, a replay-enhanced method that\ngreatly improves the plasticity of existing replay-based methods on new tasks\nwhile effectively avoiding the recurrence of catastrophic forgetting in\ncontinual reinforcement learning. RECALL leverages adaptive normalization on\napproximate targets and policy distillation on old tasks to enhance generality\nand stability, respectively. Extensive experiments on the Continual World\nbenchmark show that RECALL performs significantly better than purely perfect\nmemory replay, and achieves comparable or better overall performance against\nstate-of-the-art continual learning methods.",
            "author": [
                "Tiantian Zhang",
                "Kevin Zehua Shen",
                "Zichuan Lin",
                "Bo Yuan",
                "Xueqian Wang",
                "Xiu Li",
                "Deheng Ye"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11557v1",
                "http://arxiv.org/pdf/2311.11557v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11552v1",
            "title": "Exploring Prompting Large Language Models as Explainable Metrics",
            "updated": "2023-11-20T06:06:22Z",
            "published": "2023-11-20T06:06:22Z",
            "summary": "This paper describes the IUST NLP Lab submission to the Prompting Large\nLanguage Models as Explainable Metrics Shared Task at the Eval4NLP 2023\nWorkshop on Evaluation & Comparison of NLP Systems. We have proposed a\nzero-shot prompt-based strategy for explainable evaluation of the summarization\ntask using Large Language Models (LLMs). The conducted experiments demonstrate\nthe promising potential of LLMs as evaluation metrics in Natural Language\nProcessing (NLP), particularly in the field of summarization. Both few-shot and\nzero-shot approaches are employed in these experiments. The performance of our\nbest provided prompts achieved a Kendall correlation of 0.477 with human\nevaluations in the text summarization task on the test data. Code and results\nare publicly available on GitHub.",
            "author": [
                "Ghazaleh Mahmoudi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11552v1",
                "http://arxiv.org/pdf/2311.11552v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11551v1",
            "title": "Adapt in Contexts: Retrieval-Augmented Domain Adaptation via In-Context\n  Learning",
            "updated": "2023-11-20T06:06:20Z",
            "published": "2023-11-20T06:06:20Z",
            "summary": "Large language models (LLMs) have showcased their capability with few-shot\ninference known as in-context learning. However, in-domain demonstrations are\nnot always readily available in real scenarios, leading to cross-domain\nin-context learning. Besides, LLMs are still facing challenges in long-tail\nknowledge in unseen and unfamiliar domains. The above limitations demonstrate\nthe necessity of Unsupervised Domain Adaptation (UDA). In this paper, we study\nthe UDA problem under an in-context learning setting to adapt language models\nfrom the source domain to the target domain without any target labels. The core\nidea is to retrieve a subset of cross-domain elements that are the most similar\nto the query, and elicit language model to adapt in an in-context manner by\nlearning both target domain distribution and the discriminative task signal\nsimultaneously with the augmented cross-domain in-context examples. We devise\ndifferent prompting and training strategies, accounting for different LM\narchitectures to learn the target distribution via language modeling. With\nextensive experiments on Sentiment Analysis (SA) and Named Entity Recognition\n(NER) tasks, we thoroughly study the effectiveness of ICL for domain transfer\nand demonstrate significant improvements over baseline models.",
            "author": [
                "Quanyu Long",
                "Wenya Wang",
                "Sinno Jialin Pan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11551v1",
                "http://arxiv.org/pdf/2311.11551v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11550v1",
            "title": "Abnormal traffic detection system in SDN based on deep learning hybrid\n  models",
            "updated": "2023-11-20T06:05:32Z",
            "published": "2023-11-20T06:05:32Z",
            "summary": "Software defined network (SDN) provides technical support for network\nconstruction in smart cities, However, the openness of SDN is also prone to\nmore network attacks. Traditional abnormal traffic detection methods have\ncomplex algorithms and find it difficult to detect abnormalities in the network\npromptly, which cannot meet the demand for abnormal detection in the SDN\nenvironment. Therefore, we propose an abnormal traffic detection system based\non deep learning hybrid model. The system adopts a hierarchical detection\ntechnique, which first achieves rough detection of abnormal traffic based on\nport information. Then it uses wavelet transform and deep learning techniques\nfor fine detection of all traffic data flowing through suspicious switches. The\nexperimental results show that the proposed detection method based on port\ninformation can quickly complete the approximate localization of the source of\nabnormal traffic. the accuracy, precision, and recall of the fine detection are\nsignificantly improved compared with the traditional method of abnormal traffic\ndetection in SDN.",
            "author": [
                "Kun Wang",
                "Yu Fua",
                "Xueyuan Duan",
                "Taotao Liu",
                "Jianqiao Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11550v1",
                "http://arxiv.org/pdf/2311.11550v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11549v1",
            "title": "Unearthing Common Inconsistency for Generalisable Deepfake Detection",
            "updated": "2023-11-20T06:04:09Z",
            "published": "2023-11-20T06:04:09Z",
            "summary": "Deepfake has emerged for several years, yet efficient detection techniques\ncould generalize over different manipulation methods require further research.\nWhile current image-level detection method fails to generalize to unseen\ndomains, owing to the domain-shift phenomenon brought by CNN's strong inductive\nbias towards Deepfake texture, video-level one shows its potential to have both\ngeneralization across multiple domains and robustness to compression. We argue\nthat although distinct face manipulation tools have different inherent bias,\nthey all disrupt the consistency between frames, which is a natural\ncharacteristic shared by authentic videos. Inspired by this, we proposed a\ndetection approach by capturing frame inconsistency that broadly exists in\ndifferent forgery techniques, termed unearthing-common-inconsistency (UCI).\nConcretely, the UCI network based on self-supervised contrastive learning can\nbetter distinguish temporal consistency between real and fake videos from\nmultiple domains. We introduced a temporally-preserved module method to\nintroduce spatial noise perturbations, directing the model's attention towards\ntemporal information. Subsequently, leveraging a multi-view cross-correlation\nlearning module, we extensively learn the disparities in temporal\nrepresentations between genuine and fake samples. Extensive experiments\ndemonstrate the generalization ability of our method on unseen Deepfake\ndomains.",
            "author": [
                "Beilin Chu",
                "Xuan Xu",
                "Weike You",
                "Linna Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11549v1",
                "http://arxiv.org/pdf/2311.11549v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12078v2",
            "title": "Fast Controllable Diffusion Models for Undersampled MRI Reconstruction",
            "updated": "2023-12-01T05:24:22Z",
            "published": "2023-11-20T05:58:05Z",
            "summary": "Supervised deep learning methods have shown promise in undersampled Magnetic\nResonance Imaging (MRI) reconstruction, but their requirement for paired data\nlimits their generalizability to the diverse MRI acquisition parameters.\nRecently, unsupervised controllable generative diffusion models have been\napplied to undersampled MRI reconstruction, without paired data or model\nretraining for different MRI acquisitions. However, diffusion models are\ngenerally slow in sampling and state-of-the-art acceleration techniques can\nlead to sub-optimal results when directly applied to the controllable\ngeneration process. This study introduces a new algorithm called\nPredictor-Projector-Noisor (PPN), which enhances and accelerates controllable\ngeneration of diffusion models for undersampled MRI reconstruction. Our results\ndemonstrate that PPN produces high-fidelity MR images that conform to\nundersampled k-space measurements with significantly shorter reconstruction\ntime than other controllable sampling methods. In addition, the unsupervised\nPPN accelerated diffusion models are adaptable to different MRI acquisition\nparameters, making them more practical for clinical use than supervised\nlearning techniques.",
            "author": [
                "Wei Jiang",
                "Zhuang Xiong",
                "Feng Liu",
                "Nan Ye",
                "Hongfu Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12078v2",
                "http://arxiv.org/pdf/2311.12078v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11544v1",
            "title": "Understanding Variation in Subpopulation Susceptibility to Poisoning\n  Attacks",
            "updated": "2023-11-20T05:35:40Z",
            "published": "2023-11-20T05:35:40Z",
            "summary": "Machine learning is susceptible to poisoning attacks, in which an attacker\ncontrols a small fraction of the training data and chooses that data with the\ngoal of inducing some behavior unintended by the model developer in the trained\nmodel. We consider a realistic setting in which the adversary with the ability\nto insert a limited number of data points attempts to control the model's\nbehavior on a specific subpopulation. Inspired by previous observations on\ndisparate effectiveness of random label-flipping attacks on different\nsubpopulations, we investigate the properties that can impact the effectiveness\nof state-of-the-art poisoning attacks against different subpopulations. For a\nfamily of 2-dimensional synthetic datasets, we empirically find that dataset\nseparability plays a dominant role in subpopulation vulnerability for less\nseparable datasets. However, well-separated datasets exhibit more dependence on\nindividual subpopulation properties. We further discover that a crucial\nsubpopulation property is captured by the difference in loss on the clean\ndataset between the clean model and a target model that misclassifies the\nsubpopulation, and a subpopulation is much easier to attack if the loss\ndifference is small. This property also generalizes to high-dimensional\nbenchmark datasets. For the Adult benchmark dataset, we show that we can find\nsemantically-meaningful subpopulation properties that are related to the\nsusceptibilities of a selected group of subpopulations. The results in this\npaper are accompanied by a fully interactive web-based visualization of\nsubpopulation poisoning attacks found at\nhttps://uvasrg.github.io/visualizing-poisoning",
            "author": [
                "Evan Rose",
                "Fnu Suya",
                "David Evans"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11544v1",
                "http://arxiv.org/pdf/2311.11544v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11542v1",
            "title": "Data-driven project planning: An integrated network learning and\n  constraint relaxation approach in favor of scheduling",
            "updated": "2023-11-20T05:13:17Z",
            "published": "2023-11-20T05:13:17Z",
            "summary": "Our focus is on projects, i.e., business processes, which are emerging as the\neconomic drivers of our times. Differently from day-to-day operational\nprocesses that do not require detailed planning, a project requires planning\nand resource-constrained scheduling for coordinating resources across sub- or\nrelated projects and organizations. A planner in charge of project planning has\nto select a set of activities to perform, determine their precedence\nconstraints, and schedule them according to temporal project constraints. We\nsuggest a data-driven project planning approach for classes of projects such as\ninfrastructure building and information systems development projects. A project\nnetwork is first learned from historical records. The discovered network\nrelaxes temporal constraints embedded in individual projects, thus uncovering\nwhere planning and scheduling flexibility can be exploited for greater benefit.\nThen, the network, which contains multiple project plan variations, from which\none has to be selected, is enriched by identifying decision rules and frequent\npaths. The planner can rely on the project network for: 1) decoding a project\nvariation such that it forms a new project plan, and 2) applying\nresource-constrained project scheduling procedures to determine the project's\nschedule and resource allocation. Using two real-world project datasets, we\nshow that the suggested approach may provide the planner with significant\nflexibility (up to a 26% reduction of the critical path of a real project) to\nadjust the project plan and schedule. We believe that the proposed approach can\nplay an important part in supporting decision making towards automated\ndata-driven project planning.",
            "author": [
                "Izack Cohen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11542v1",
                "http://arxiv.org/pdf/2311.11542v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11537v1",
            "title": "ADAPTER-RL: Adaptation of Any Agent using Reinforcement Learning",
            "updated": "2023-11-20T04:54:51Z",
            "published": "2023-11-20T04:54:51Z",
            "summary": "Deep Reinforcement Learning (DRL) agents frequently face challenges in\nadapting to tasks outside their training distribution, including issues with\nover-fitting, catastrophic forgetting and sample inefficiency. Although the\napplication of adapters has proven effective in supervised learning contexts\nsuch as natural language processing and computer vision, their potential within\nthe DRL domain remains largely unexplored. This paper delves into the\nintegration of adapters in reinforcement learning, presenting an innovative\nadaptation strategy that demonstrates enhanced training efficiency and\nimprovement of the base-agent, experimentally in the nanoRTS environment, a\nreal-time strategy (RTS) game simulation. Our proposed universal approach is\nnot only compatible with pre-trained neural networks but also with rule-based\nagents, offering a means to integrate human expertise.",
            "author": [
                "Yizhao Jin",
                "Greg Slabaugh",
                "Simon Lucas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11537v1",
                "http://arxiv.org/pdf/2311.11537v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11533v1",
            "title": "Event Camera Data Dense Pre-training",
            "updated": "2023-11-20T04:36:19Z",
            "published": "2023-11-20T04:36:19Z",
            "summary": "This paper introduces a self-supervised learning framework designed for\npre-training neural networks tailored to dense prediction tasks using event\ncamera data. Our approach utilizes solely event data for training.\n  Transferring achievements from dense RGB pre-training directly to event\ncamera data yields subpar performance. This is attributed to the spatial\nsparsity inherent in an event image (converted from event data), where many\npixels do not contain information. To mitigate this sparsity issue, we encode\nan event image into event patch features, automatically mine contextual\nsimilarity relationships among patches, group the patch features into\ndistinctive contexts, and enforce context-to-context similarities to learn\ndiscriminative event features.\n  For training our framework, we curate a synthetic event camera dataset\nfeaturing diverse scene and motion patterns. Transfer learning performance on\ndownstream dense prediction tasks illustrates the superiority of our method\nover state-of-the-art approaches. Notably, our single model secured the top\nposition in the challenging DSEC-Flow benchmark.",
            "author": [
                "Yan Yang",
                "Liyuan Pan",
                "Liu Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11533v1",
                "http://arxiv.org/pdf/2311.11533v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11532v1",
            "title": "Optimal Hyperparameter $\u03b5$ for Adaptive Stochastic Optimizers\n  through Gradient Histograms",
            "updated": "2023-11-20T04:34:19Z",
            "published": "2023-11-20T04:34:19Z",
            "summary": "Optimizers are essential components for successfully training deep neural\nnetwork models. In order to achieve the best performance from such models,\ndesigners need to carefully choose the optimizer hyperparameters. However, this\ncan be a computationally expensive and time-consuming process. Although it is\nknown that all optimizer hyperparameters must be tuned for maximum performance,\nthere is still a lack of clarity regarding the individual influence of minor\npriority hyperparameters, including the safeguard factor $\\epsilon$ and\nmomentum factor $\\beta$, in leading adaptive optimizers (specifically, those\nbased on the Adam optimizers). In this manuscript, we introduce a new framework\nbased on gradient histograms to analyze and justify important attributes of\nadaptive optimizers, such as their optimal performance and the relationships\nand dependencies among hyperparameters. Furthermore, we propose a novel\ngradient histogram-based algorithm that automatically estimates a reduced and\naccurate search space for the safeguard hyperparameter $\\epsilon$, where the\noptimal value can be easily found.",
            "author": [
                "Gustavo Silva",
                "Paul Rodriguez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11532v1",
                "http://arxiv.org/pdf/2311.11532v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11523v1",
            "title": "Chasing the break: Tracing the full evolution of a black hole X-ray\n  binary jet with multi-wavelength spectral modeling",
            "updated": "2023-11-20T04:03:55Z",
            "published": "2023-11-20T04:03:55Z",
            "summary": "Black hole X-ray binaries (BH XRBs) are ideal targets to study the connection\nbetween accretion inflow and jet outflow. Here we present quasi-simultaneous,\nmulti-wavelength observations of the Galactic black hole system MAXI J1820+070,\nthroughout its 2018-2019 outburst. Our data set includes coverage from the\nradio through X-ray bands from 17 different instruments/telescopes, and\nencompasses 19 epochs over a 7 month time period, resulting in one of the most\nwell-sampled multi-wavelength data sets of a BH XRB outburst to date. With our\ndata, we compile and model the broad-band spectra of this source using a\nphenomenological model that includes emission from the jet, companion star, and\naccretion flow. This modeling allows us to track the evolution of the spectral\nbreak in the jet spectrum, a key observable that samples the jet launching\nregion. We find that the spectral break location changes over at least\n$\\approx3$ orders of magnitude in electromagnetic frequency over this period.\nUsing these spectral break measurements, we link the full cycle of jet\nbehavior, including the rising, quenching, and re-ignition, to the changing\naccretion flow properties as the source evolves through its different accretion\nstates. Our analyses show a consistent jet behavior with other sources in\nsimilar phases of their outbursts, reinforcing that the jet quenching and\nrecovery may be a global feature of BH XRB systems in outburst. Our results\nalso provide valuable evidence supporting a close connection between the\ngeometry of the inner accretion flow and the base of the jet.",
            "author": [
                "Constanza Echibur\u00fa-Trujillo",
                "Alexandra J. Tetarenko",
                "Daryl Haggard",
                "Thomas D. Russell",
                "Karri I. I. Koljonen",
                "Arash Bahramian",
                "Jingyi Wang",
                "Michael Bremer",
                "Joe Bright",
                "Piergiorgio Casella",
                "David M. Russell",
                "Diego Altamirano",
                "M. Cristina Baglio",
                "Tomaso Belloni",
                "Chiara Ceccobello",
                "Stephane Corbel",
                "Maria Diaz Trigo",
                "Dipankar Maitra",
                "Aldrin Gabuya",
                "Elena Gallo",
                "Sebastian Heinz",
                "Jeroen Homan",
                "Erin Kara",
                "Elmar K\u00f6rding",
                "Fraser Lewis",
                "Matteo Lucchini",
                "Sera Markoff",
                "Simone Migliari",
                "James C. A. Miller-Jones",
                "Jerome Rodriguez",
                "Payaswini Saikia",
                "Craig L. Sarazin",
                "Tariq Shahbaz",
                "Gregory Sivakoff",
                "Roberto Soria",
                "Vincenzo Testa",
                "Bailey E. Tetarenko",
                "Valeriu Tudose"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11523v1",
                "http://arxiv.org/pdf/2311.11523v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11520v1",
            "title": "Liver Tumor Prediction with Advanced Attention Mechanisms Integrated\n  into a Depth-Based Variant Search Algorithm",
            "updated": "2023-11-20T03:51:39Z",
            "published": "2023-11-20T03:51:39Z",
            "summary": "In recent days, Deep Learning (DL) techniques have become an emerging\ntransformation in the field of machine learning, artificial intelligence,\ncomputer vision, and so on. Subsequently, researchers and industries have been\nhighly endorsed in the medical field, predicting and controlling diverse\ndiseases at specific intervals. Liver tumor prediction is a vital chore in\nanalyzing and treating liver diseases. This paper proposes a novel approach for\npredicting liver tumors using Convolutional Neural Networks (CNN) and a\ndepth-based variant search algorithm with advanced attention mechanisms\n(CNN-DS-AM). The proposed work aims to improve accuracy and robustness in\ndiagnosing and treating liver diseases. The anticipated model is assessed on a\nComputed Tomography (CT) scan dataset containing both benign and malignant\nliver tumors. The proposed approach achieved high accuracy in predicting liver\ntumors, outperforming other state-of-the-art methods. Additionally, advanced\nattention mechanisms were incorporated into the CNN model to enable the\nidentification and highlighting of regions of the CT scans most relevant to\npredicting liver tumors. The results suggest that incorporating attention\nmechanisms and a depth-based variant search algorithm into the CNN model is a\npromising approach for improving the accuracy and robustness of liver tumor\nprediction. It can assist radiologists in their diagnosis and treatment\nplanning. The proposed system achieved a high accuracy of 95.5% in predicting\nliver tumors, outperforming other state-of-the-art methods.",
            "author": [
                "P. Kalaiselvi",
                "S. Anusuya"
            ],
            "link": [
                "http://dx.doi.org/10.32604/cmc.2023.040264",
                "http://arxiv.org/abs/2311.11520v1",
                "http://arxiv.org/pdf/2311.11520v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11518v1",
            "title": "Multi-teacher Distillation for Multilingual Spelling Correction",
            "updated": "2023-11-20T03:44:32Z",
            "published": "2023-11-20T03:44:32Z",
            "summary": "Accurate spelling correction is a critical step in modern search interfaces,\nespecially in an era of mobile devices and speech-to-text interfaces. For\nservices that are deployed around the world, this poses a significant challenge\nfor multilingual NLP: spelling errors need to be caught and corrected in all\nlanguages, and even in queries that use multiple languages. In this paper, we\ntackle this challenge using multi-teacher distillation. On our approach, a\nmonolingual teacher model is trained for each language/locale, and these\nindividual models are distilled into a single multilingual student model\nintended to serve all languages/locales. In experiments using open-source data\nas well as user data from a worldwide search service, we show that this leads\nto highly effective spelling correction models that can meet the tight latency\nrequirements of deployed services.",
            "author": [
                "Jingfen Zhang",
                "Xuan Guo",
                "Sravan Bodapati",
                "Christopher Potts"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11518v1",
                "http://arxiv.org/pdf/2311.11518v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11512v1",
            "title": "Seeing through the Mask: Multi-task Generative Mask Decoupling Face\n  Recognition",
            "updated": "2023-11-20T03:23:03Z",
            "published": "2023-11-20T03:23:03Z",
            "summary": "The outbreak of COVID-19 pandemic make people wear masks more frequently than\never. Current general face recognition system suffers from serious performance\ndegradation,when encountering occluded scenes. The potential reason is that\nface features are corrupted by occlusions on key facial regions. To tackle this\nproblem, previous works either extract identity-related embeddings on feature\nlevel by additional mask prediction, or restore the occluded facial part by\ngenerative models. However, the former lacks visual results for model\ninterpretation, while the latter suffers from artifacts which may affect\ndownstream recognition. Therefore, this paper proposes a Multi-task gEnerative\nmask dEcoupling face Recognition (MEER) network to jointly handle these two\ntasks, which can learn occlusionirrelevant and identity-related representation\nwhile achieving unmasked face synthesis. We first present a novel mask\ndecoupling module to disentangle mask and identity information, which makes the\nnetwork obtain purer identity features from visible facial components. Then, an\nunmasked face is restored by a joint-training strategy, which will be further\nused to refine the recognition network with an id-preserving loss. Experiments\non masked face recognition under realistic and synthetic occlusions benchmarks\ndemonstrate that the MEER can outperform the state-ofthe-art methods.",
            "author": [
                "Zhaohui Wang",
                "Sufang Zhang",
                "Jianteng Peng",
                "Xinyi Wang",
                "Yandong Guo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11512v1",
                "http://arxiv.org/pdf/2311.11512v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11509v2",
            "title": "Token-Level Adversarial Prompt Detection Based on Perplexity Measures\n  and Contextual Information",
            "updated": "2023-11-27T06:53:03Z",
            "published": "2023-11-20T03:17:21Z",
            "summary": "In recent years, Large Language Models (LLM) have emerged as pivotal tools in\nvarious applications. However, these models are susceptible to adversarial\nprompt attacks, where attackers can carefully curate input strings that lead to\nundesirable outputs. The inherent vulnerability of LLMs stems from their\ninput-output mechanisms, especially when presented with intensely\nout-of-distribution (OOD) inputs. This paper proposes a token-level detection\nmethod to identify adversarial prompts, leveraging the LLM's capability to\npredict the next token's probability. We measure the degree of the model's\nperplexity and incorporate neighboring token information to encourage the\ndetection of contiguous adversarial prompt sequences. As a result, we propose\ntwo methods: one that identifies each token as either being part of an\nadversarial prompt or not, and another that estimates the probability of each\ntoken being part of an adversarial prompt.",
            "author": [
                "Zhengmian Hu",
                "Gang Wu",
                "Saayan Mitra",
                "Ruiyi Zhang",
                "Tong Sun",
                "Heng Huang",
                "Viswanathan Swaminathan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11509v2",
                "http://arxiv.org/pdf/2311.11509v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11501v1",
            "title": "MultiLoRA: Democratizing LoRA for Better Multi-Task Learning",
            "updated": "2023-11-20T02:59:18Z",
            "published": "2023-11-20T02:59:18Z",
            "summary": "LoRA achieves remarkable resource efficiency and comparable performance when\nadapting LLMs for specific tasks. Since ChatGPT demonstrated superior\nperformance on various tasks, there has been a growing desire to adapt one\nmodel for all tasks. However, the explicit low-rank of LoRA limits the\nadaptation performance in complex multi-task scenarios. LoRA is dominated by a\nsmall number of top singular vectors while fine-tuning decomposes into a set of\nless important unitary transforms. In this paper, we propose MultiLoRA for\nbetter multi-task adaptation by reducing the dominance of top singular vectors\nobserved in LoRA. MultiLoRA scales LoRA modules horizontally and change\nparameter initialization of adaptation matrices to reduce parameter dependency,\nthus yields more balanced unitary subspaces. We unprecedentedly construct\nspecialized training data by mixing datasets of instruction follow, natural\nlanguage understanding, world knowledge, to cover semantically and\nsyntactically different samples. With only 2.5% of additional parameters,\nMultiLoRA outperforms single LoRA counterparts and fine-tuning on multiple\nbenchmarks and model scales. Further investigation into weight update matrices\nof MultiLoRA exhibits reduced dependency on top singular vectors and more\ndemocratic unitary transform contributions.",
            "author": [
                "Yiming Wang",
                "Yu Lin",
                "Xiaodong Zeng",
                "Guannan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11501v1",
                "http://arxiv.org/pdf/2311.11501v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11500v1",
            "title": "Multi-component Predictions of Transient Solution Fields with Sequential\n  Deep Operator Network",
            "updated": "2023-11-20T02:59:10Z",
            "published": "2023-11-20T02:59:10Z",
            "summary": "The Deep Operator Network (DeepONet) structure has shown great potential in\napproximating complex solution operators with low generalization errors.\nRecently, a sequential DeepONet (S-DeepONet) was proposed to use sequential\nlearning models in the branch of DeepONet to predict final solutions given\ntime-dependent inputs. In this novel work, the S-DeepONet architecture is\nfurther extended by modifying the information combination mechanism between the\nbranch and trunk networks to simultaneously predict vector solutions with\nmultiple components at multiple time steps of the evolution history. Two\nexample problems, one on transient fluid flow and the other on path-dependent\nplastic loading were shown to demonstrate the capabilities of the model to\nhandle different physics problems. The use of a trained S-DeepONet model in\ninverse parameter identification via the genetic algorithm is shown to\ndemonstrate the application of the model. In almost all cases, the trained\nmodel achieved an $R^2$ value of above 0.99 and relative $L_2$ error of less\nthan 10\\% with only 3200 training data points, indicating superior accuracy.\nThe vector S-DeepONet model, having only 0.4\\% more parameters than a scalar\nmodel, can predict two output components simultaneously at an accuracy similar\nto the two independently trained scalar models with a 20.8\\% faster training\ntime. The S-DeepONet inference is at least three orders of magnitude faster\nthan direct numerical simulations, and inverse parameter identifications using\nthe trained model is highly efficient and accurate.",
            "author": [
                "Junyan He",
                "Shashank Kushwaha",
                "Jaewan Park",
                "Seid Koric",
                "Diab Abueidda",
                "Iwona Jasiuk"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11500v1",
                "http://arxiv.org/pdf/2311.11500v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11491v1",
            "title": "Interpretability in Machine Learning: on the Interplay with\n  Explainability, Predictive Performances and Models",
            "updated": "2023-11-20T02:31:08Z",
            "published": "2023-11-20T02:31:08Z",
            "summary": "Interpretability has recently gained attention in the field of machine\nlearning, for it is crucial when it comes to high-stakes decisions or\ntroubleshooting. This abstract concept is hard to grasp and has been\nassociated, over time, with many labels and preconceived ideas. In this\nposition paper, in order to clarify some misunderstandings regarding\ninterpretability, we discuss its relationship with significant concepts in\nmachine learning: explainability, predictive performances, and machine learning\nmodels. For instance, we challenge the idea that interpretability and\nexplainability are substitutes to one another, or that a fixed degree of\ninterpretability can be associated with a given machine learning model.",
            "author": [
                "Benjamin Leblanc",
                "Pascal Germain"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11491v1",
                "http://arxiv.org/pdf/2311.11491v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12075v1",
            "title": "BadCLIP: Dual-Embedding Guided Backdoor Attack on Multimodal Contrastive\n  Learning",
            "updated": "2023-11-20T02:21:49Z",
            "published": "2023-11-20T02:21:49Z",
            "summary": "Studying backdoor attacks is valuable for model copyright protection and\nenhancing defenses. While existing backdoor attacks have successfully infected\nmultimodal contrastive learning models such as CLIP, they can be easily\ncountered by specialized backdoor defenses for MCL models. This paper reveals\nthe threats in this practical scenario that backdoor attacks can remain\neffective even after defenses and introduces the \\emph{\\toolns} attack, which\nis resistant to backdoor detection and model fine-tuning defenses. To achieve\nthis, we draw motivations from the perspective of the Bayesian rule and propose\na dual-embedding guided framework for backdoor attacks. Specifically, we ensure\nthat visual trigger patterns approximate the textual target semantics in the\nembedding space, making it challenging to detect the subtle parameter\nvariations induced by backdoor learning on such natural trigger patterns.\nAdditionally, we optimize the visual trigger patterns to align the poisoned\nsamples with target vision features in order to hinder the backdoor unlearning\nthrough clean fine-tuning. Extensive experiments demonstrate that our attack\nsignificantly outperforms state-of-the-art baselines (+45.3% ASR) in the\npresence of SoTA backdoor defenses, rendering these mitigation and detection\nstrategies virtually ineffective. Furthermore, our approach effectively attacks\nsome more rigorous scenarios like downstream tasks. We believe that this paper\nraises awareness regarding the potential threats associated with the practical\napplication of multimodal contrastive learning and encourages the development\nof more robust defense mechanisms.",
            "author": [
                "Siyuan Liang",
                "Mingli Zhu",
                "Aishan Liu",
                "Baoyuan Wu",
                "Xiaochun Cao",
                "Ee-Chien Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12075v1",
                "http://arxiv.org/pdf/2311.12075v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11486v1",
            "title": "Perspectives on Privacy in the Post-Roe Era: A Mixed-Methods of Machine\n  Learning and Qualitative Analyses of Tweets",
            "updated": "2023-11-20T02:05:30Z",
            "published": "2023-11-20T02:05:30Z",
            "summary": "Abortion is a controversial topic that has long been debated in the US. With\nthe recent Supreme Court decision to overturn Roe v. Wade, access to safe and\nlegal reproductive care is once again in the national spotlight. A key issue\ncentral to this debate is patient privacy, as in the post-HITECH Act era it has\nbecome easier for medical records to be electronically accessed and shared.\nThis study analyzed a large Twitter dataset from May to December 2022 to\nexamine the public's reactions to Roe v. Wade's overruling and its implications\nfor privacy. Using a mixed-methods approach consisting of computational and\nqualitative content analysis, we found a wide range of concerns voiced from the\nconfidentiality of patient-physician information exchange to medical records\nbeing shared without patient consent. These findings may inform policy making\nand healthcare industry practices concerning medical privacy related to\nreproductive rights and women's health.",
            "author": [
                "Yawen Guo",
                "Rachael Zehrung",
                "Katie Genuario",
                "Xuan Lu",
                "Qiaozhu Mei",
                "Yunan Chen",
                "Kai Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11486v1",
                "http://arxiv.org/pdf/2311.11486v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11485v1",
            "title": "An NMF-Based Building Block for Interpretable Neural Networks With\n  Continual Learning",
            "updated": "2023-11-20T02:00:33Z",
            "published": "2023-11-20T02:00:33Z",
            "summary": "Existing learning methods often struggle to balance interpretability and\npredictive performance. While models like nearest neighbors and non-negative\nmatrix factorization (NMF) offer high interpretability, their predictive\nperformance on supervised learning tasks is often limited. In contrast, neural\nnetworks based on the multi-layer perceptron (MLP) support the modular\nconstruction of expressive architectures and tend to have better recognition\naccuracy but are often regarded as black boxes in terms of interpretability.\nOur approach aims to strike a better balance between these two aspects through\nthe use of a building block based on NMF that incorporates supervised neural\nnetwork training methods to achieve high predictive performance while retaining\nthe desirable interpretability properties of NMF. We evaluate our Predictive\nFactorized Coupling (PFC) block on small datasets and show that it achieves\ncompetitive predictive performance with MLPs while also offering improved\ninterpretability. We demonstrate the benefits of this approach in various\nscenarios, such as continual learning, training on non-i.i.d. data, and\nknowledge removal after training. Additionally, we show examples of using the\nPFC block to build more expressive architectures, including a fully-connected\nresidual network as well as a factorized recurrent neural network (RNN) that\nperforms competitively with vanilla RNNs while providing improved\ninterpretability. The PFC block uses an iterative inference algorithm that\nconverges to a fixed point, making it possible to trade off accuracy vs\ncomputation after training but also currently preventing its use as a general\nMLP replacement in some scenarios such as training on very large datasets. We\nprovide source code at https://github.com/bkvogel/pfc",
            "author": [
                "Brian K. Vogel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11485v1",
                "http://arxiv.org/pdf/2311.11485v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11483v1",
            "title": "A Multi-Center Study on the Adaptability of a Shared Foundation Model\n  for Electronic Health Records",
            "updated": "2023-11-20T01:58:27Z",
            "published": "2023-11-20T01:58:27Z",
            "summary": "Foundation models hold promise for transforming AI in healthcare by providing\nmodular components that are easily adaptable to downstream healthcare tasks,\nmaking AI development more scalable and cost-effective. Structured EHR\nfoundation models, trained on coded medical records from millions of patients,\ndemonstrated benefits including increased performance with fewer training\nlabels, and improved robustness to distribution shifts. However, questions\nremain on the feasibility of sharing these models across different hospitals\nand their performance for local task adaptation. This multi-center study\nexamined the adaptability of a recently released structured EHR foundation\nmodel ($FM_{SM}$), trained on longitudinal medical record data from 2.57M\nStanford Medicine patients. Experiments were conducted using EHR data at The\nHospital for Sick Children and MIMIC-IV. We assessed both adaptability via\ncontinued pretraining on local data, and task adaptability compared to\nbaselines of training models from scratch at each site, including a local\nfoundation model. We evaluated the performance of these models on 8 clinical\nprediction tasks. In both datasets, adapting the off-the-shelf $FM_{SM}$\nmatched the performance of GBM models locally trained on all data while\nproviding a 13% improvement in settings with few task-specific training labels.\nWith continued pretraining on local data, label efficiency substantially\nimproved, such that $FM_{SM}$ required fewer than 1% of training examples to\nmatch the fully trained GBM's performance. Continued pretraining was also 60 to\n90% more sample-efficient than training local foundation models from scratch.\nOur findings show that adapting shared EHR foundation models across hospitals\nprovides improved prediction performance at less cost, underscoring the utility\nof base foundation models as modular components to streamline the development\nof healthcare AI.",
            "author": [
                "Lin Lawrence Guo",
                "Jason Fries",
                "Ethan Steinberg",
                "Scott Lanyon Fleming",
                "Keith Morse",
                "Catherine Aftandilian",
                "Jose Posada",
                "Nigam Shah",
                "Lillian Sung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11483v1",
                "http://arxiv.org/pdf/2311.11483v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11476v1",
            "title": "Empowering remittance management in the digitised landscape: A real-time\n  Data-Driven Decision Support with predictive abilities for financial\n  transactions",
            "updated": "2023-11-20T01:04:04Z",
            "published": "2023-11-20T01:04:04Z",
            "summary": "The advent of Blockchain technology (BT) revolutionised the way remittance\ntransactions are recorded. Banks and remittance organisations have shown a\ngrowing interest in exploring blockchain's potential advantages over\ntraditional practices. This paper presents a data-driven predictive decision\nsupport approach as an innovative artefact designed for the blockchain-oriented\nremittance industry. Employing a theory-generating Design Science Research\n(DSR) approach, we have uncovered the emergence of predictive capabilities\ndriven by transactional big data. The artefact integrates predictive analytics\nand Machine Learning (ML) to enable real-time remittance monitoring, empowering\nmanagement decision-makers to address challenges in the uncertain digitised\nlandscape of blockchain-oriented remittance companies. Bridging the gap between\ntheory and practice, this research not only enhances the security of the\nremittance ecosystem but also lays the foundation for future predictive\ndecision support solutions, extending the potential of predictive analytics to\nother domains. Additionally, the generated theory from the artifact's\nimplementation enriches the DSR approach and fosters grounded and stakeholder\ntheory development in the information systems domain.",
            "author": [
                "Rashikala Weerawarna",
                "Shah J Miah"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11476v1",
                "http://arxiv.org/pdf/2311.11476v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11475v1",
            "title": "Gaussian Interpolation Flows",
            "updated": "2023-11-20T00:59:20Z",
            "published": "2023-11-20T00:59:20Z",
            "summary": "Gaussian denoising has emerged as a powerful principle for constructing\nsimulation-free continuous normalizing flows for generative modeling. Despite\ntheir empirical successes, theoretical properties of these flows and the\nregularizing effect of Gaussian denoising have remained largely unexplored. In\nthis work, we aim to address this gap by investigating the well-posedness of\nsimulation-free continuous normalizing flows built on Gaussian denoising.\nThrough a unified framework termed Gaussian interpolation flow, we establish\nthe Lipschitz regularity of the flow velocity field, the existence and\nuniqueness of the flow, and the Lipschitz continuity of the flow map and the\ntime-reversed flow map for several rich classes of target distributions. This\nanalysis also sheds light on the auto-encoding and cycle-consistency properties\nof Gaussian interpolation flows. Additionally, we delve into the stability of\nthese flows in source distributions and perturbations of the velocity field,\nusing the quadratic Wasserstein distance as a metric. Our findings offer\nvaluable insights into the learning techniques employed in Gaussian\ninterpolation flows for generative modeling, providing a solid theoretical\nfoundation for end-to-end error analyses of learning GIFs with empirical\nobservations.",
            "author": [
                "Yuan Gao",
                "Jian Huang",
                "Yuling Jiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11475v1",
                "http://arxiv.org/pdf/2311.11475v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11473v1",
            "title": "CSGNN: Conquering Noisy Node labels via Dynamic Class-wise Selection",
            "updated": "2023-11-20T00:57:30Z",
            "published": "2023-11-20T00:57:30Z",
            "summary": "Graph Neural Networks (GNNs) have emerged as a powerful tool for\nrepresentation learning on graphs, but they often suffer from overfitting and\nlabel noise issues, especially when the data is scarce or imbalanced. Different\nfrom the paradigm of previous methods that rely on single-node confidence, in\nthis paper, we introduce a novel Class-wise Selection for Graph Neural\nNetworks, dubbed CSGNN, which employs a neighbor-aggregated latent space to\nadaptively select reliable nodes across different classes. Specifically, 1) to\ntackle the class imbalance issue, we introduce a dynamic class-wise selection\nmechanism, leveraging the clustering technique to identify clean nodes based on\nthe neighbor-aggregated confidences. In this way, our approach can avoid the\npitfalls of biased sampling which is common with global threshold techniques.\n2) To alleviate the problem of noisy labels, built on the concept of the\nmemorization effect, CSGNN prioritizes learning from clean nodes before noisy\nones, thereby iteratively enhancing model performance while mitigating label\nnoise. Through extensive experiments, we demonstrate that CSGNN outperforms\nstate-of-the-art methods in terms of both effectiveness and robustness.",
            "author": [
                "Yifan Li",
                "Zhen Tan",
                "Kai Shu",
                "Zongsheng Cao",
                "Yu Kong",
                "Huan Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11473v1",
                "http://arxiv.org/pdf/2311.11473v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11463v1",
            "title": "Towards a Post-Market Monitoring Framework for Machine Learning-based\n  Medical Devices: A case study",
            "updated": "2023-11-20T00:15:16Z",
            "published": "2023-11-20T00:15:16Z",
            "summary": "After a machine learning (ML)-based system is deployed in clinical practice,\nperformance monitoring is important to ensure the safety and effectiveness of\nthe algorithm over time. The goal of this work is to highlight the complexity\nof designing a monitoring strategy and the need for a systematic framework that\ncompares the multitude of monitoring options. One of the main decisions is\nchoosing between using real-world (observational) versus interventional data.\nAlthough the former is the most convenient source of monitoring data, it\nexhibits well-known biases, such as confounding, selection, and missingness. In\nfact, when the ML algorithm interacts with its environment, the algorithm\nitself may be a primary source of bias. On the other hand, a carefully designed\ninterventional study that randomizes individuals can explicitly eliminate such\nbiases, but the ethics, feasibility, and cost of such an approach must be\ncarefully considered. Beyond the decision of the data source, monitoring\nstrategies vary in the performance criteria they track, the interpretability of\nthe test statistics, the strength of their assumptions, and their speed at\ndetecting performance decay. As a first step towards developing a framework\nthat compares the various monitoring options, we consider a case study of an\nML-based risk prediction algorithm for postoperative nausea and vomiting\n(PONV). Bringing together tools from causal inference and statistical process\ncontrol, we walk through the basic steps of defining candidate monitoring\ncriteria, describing potential sources of bias and the causal model, and\nspecifying and comparing candidate monitoring procedures. We hypothesize that\nthese steps can be applied more generally, as causal inference can address\nother sources of biases as well.",
            "author": [
                "Jean Feng",
                "Adarsh Subbaswamy",
                "Alexej Gossmann",
                "Harvineet Singh",
                "Berkman Sahiner",
                "Mi-Ok Kim",
                "Gene Pennello",
                "Nicholas Petrick",
                "Romain Pirracchio",
                "Fan Xia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11463v1",
                "http://arxiv.org/pdf/2311.11463v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12074v1",
            "title": "SecureBERT and LLAMA 2 Empowered Control Area Network Intrusion\n  Detection and Classification",
            "updated": "2023-11-19T23:49:08Z",
            "published": "2023-11-19T23:49:08Z",
            "summary": "Numerous studies have proved their effective strength in detecting Control\nArea Network (CAN) attacks. In the realm of understanding the human semantic\nspace, transformer-based models have demonstrated remarkable effectiveness.\nLeveraging pre-trained transformers has become a common strategy in various\nlanguage-related tasks, enabling these models to grasp human semantics more\ncomprehensively. To delve into the adaptability evaluation on pre-trained\nmodels for CAN intrusion detection, we have developed two distinct models:\nCAN-SecureBERT and CAN-LLAMA2. Notably, our CAN-LLAMA2 model surpasses the\nstate-of-the-art models by achieving an exceptional performance 0.999993 in\nterms of balanced accuracy, precision detection rate, F1 score, and a\nremarkably low false alarm rate of 3.10e-6. Impressively, the false alarm rate\nis 52 times smaller than that of the leading model, MTH-IDS (Multitiered Hybrid\nIntrusion Detection System). Our study underscores the promise of employing a\nLarge Language Model as the foundational model, while incorporating adapters\nfor other cybersecurity-related tasks and maintaining the model's inherent\nlanguage-related capabilities.",
            "author": [
                "Xuemei Li",
                "Huirong Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12074v1",
                "http://arxiv.org/pdf/2311.12074v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11457v1",
            "title": "Foundational Competencies and Responsibilities of a Research Software\n  Engineer",
            "updated": "2023-11-19T23:44:57Z",
            "published": "2023-11-19T23:44:57Z",
            "summary": "The term Research Software Engineer, or RSE, emerged a little over 10 years\nago as a way to represent individuals working in the research community but\nfocusing on software development. The term has been widely adopted and there\nare a number of high-level definitions of what an RSE is. However, the roles of\nRSEs vary depending on the institutional context they work in. At one end of\nthe spectrum, RSE roles may look similar to a traditional research role. At the\nother extreme, they resemble that of a software engineer in industry. Most RSE\nroles inhabit the space between these two extremes. Therefore, providing a\nstraightforward, comprehensive definition of what an RSE does and what\nexperience, skills and competencies are required to become one is challenging.\nIn this community paper we define the broad notion of what an RSE is, explore\nthe different types of work they undertake, and define a list of fundamental\ncompetencies as well as values that define the general profile of an RSE. On\nthis basis, we elaborate on the progression of these skills along different\ndimensions, looking at specific types of RSE roles, proposing recommendations\nfor organisations, and giving examples of future specialisations. An appendix\ndetails how existing curricula fit into this framework.",
            "author": [
                "Florian Goth",
                "Renato Alves",
                "Matthias Braun",
                "Leyla Jael Castro",
                "Gerasimos Chourdakis",
                "Simon Christ",
                "Jeremy Cohen",
                "Fredo Erxleben",
                "Jean-No\u00ebl Grad",
                "Magnus Hagdorn",
                "Toby Hodges",
                "Guido Juckeland",
                "Dominic Kempf",
                "Anna-Lena Lamprecht",
                "Jan Linxweiler",
                "Moritz Schwarzmeier",
                "Heidi Seibold",
                "Jan Philipp Thiele",
                "Harald von Waldow",
                "Samantha Wittke"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11457v1",
                "http://arxiv.org/pdf/2311.11457v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.CY",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11452v1",
            "title": "Physics-Enhanced TinyML for Real-Time Detection of Ground Magnetic\n  Anomalies",
            "updated": "2023-11-19T23:20:16Z",
            "published": "2023-11-19T23:20:16Z",
            "summary": "Space weather phenomena like geomagnetic disturbances (GMDs) and\ngeomagnetically induced currents (GICs) pose significant risks to critical\ntechnological infrastructure. While traditional predictive models, grounded in\nsimulation, hold theoretical robustness, they grapple with challenges, notably\nthe assimilation of imprecise data and extensive computational complexities. In\nrecent years, Tiny Machine Learning (TinyML) has been adopted to develop\nMachine Learning (ML)-enabled magnetometer systems for predicting real-time\nterrestrial magnetic perturbations as a proxy measure for GIC. While TinyML\noffers efficient, real-time data processing, its intrinsic limitations prevent\nthe utilization of robust methods with high computational needs. This paper\ndeveloped a physics-guided TinyML framework to address the above challenges.\nThis framework integrates physics-based regularization at the stages of model\ntraining and compression, thereby augmenting the reliability of predictions.\nThe developed pruning scheme within the framework harnesses the inherent\nphysical characteristics of the domain, striking a balance between model size\nand robustness. The study presents empirical results, drawing a comprehensive\ncomparison between the accuracy and reliability of the developed framework and\nits traditional counterpart. Such a comparative analysis underscores the\nprospective applicability of the developed framework in conceptualizing robust,\nML-enabled magnetometer systems for real-time space weather forecasting.",
            "author": [
                "Talha Siddique",
                "MD Shaad Mahmud"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11452v1",
                "http://arxiv.org/pdf/2311.11452v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11446v2",
            "title": "Weight Norm Control",
            "updated": "2023-11-21T01:42:54Z",
            "published": "2023-11-19T23:00:27Z",
            "summary": "We note that decoupled weight decay regularization is a particular case of\nweight norm control where the target norm of weights is set to 0. Any\noptimization method (e.g., Adam) which uses decoupled weight decay\nregularization (respectively, AdamW) can be viewed as a particular case of a\nmore general algorithm with weight norm control (respectively, AdamWN). We\nargue that setting the target norm of weights to 0 can be suboptimal and other\ntarget norm values can be considered. For instance, any training run where\nAdamW achieves a particular norm of weights can be challenged by AdamWN\nscheduled to achieve a comparable norm of weights. We discuss various\nimplications of introducing weight norm control instead of weight decay.",
            "author": [
                "Ilya Loshchilov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11446v2",
                "http://arxiv.org/pdf/2311.11446v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11441v1",
            "title": "Spot the Bot: Distinguishing Human-Written and Bot-Generated Texts Using\n  Clustering and Information Theory Techniques",
            "updated": "2023-11-19T22:29:15Z",
            "published": "2023-11-19T22:29:15Z",
            "summary": "With the development of generative models like GPT-3, it is increasingly more\nchallenging to differentiate generated texts from human-written ones. There is\na large number of studies that have demonstrated good results in bot\nidentification. However, the majority of such works depend on supervised\nlearning methods that require labelled data and/or prior knowledge about the\nbot-model architecture. In this work, we propose a bot identification algorithm\nthat is based on unsupervised learning techniques and does not depend on a\nlarge amount of labelled data. By combining findings in semantic analysis by\nclustering (crisp and fuzzy) and information techniques, we construct a robust\nmodel that detects a generated text for different types of bot. We find that\nthe generated texts tend to be more chaotic while literary works are more\ncomplex. We also demonstrate that the clustering of human texts results in\nfuzzier clusters in comparison to the more compact and well-separated clusters\nof bot-generated texts.",
            "author": [
                "Vasilii Gromov",
                "Quynh Nhu Dang"
            ],
            "link": [
                "http://dx.doi.org/10.1007/978-3-031-45170-6_3",
                "http://arxiv.org/abs/2311.11441v1",
                "http://arxiv.org/pdf/2311.11441v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11439v2",
            "title": "Improved Defect Detection and Classification Method for Advanced IC\n  Nodes by Using Slicing Aided Hyper Inference with Refinement Strategy",
            "updated": "2023-11-21T07:12:22Z",
            "published": "2023-11-19T22:24:19Z",
            "summary": "In semiconductor manufacturing, lithography has often been the manufacturing\nstep defining the smallest possible pattern dimensions. In recent years,\nprogress has been made towards high-NA (Numerical Aperture) EUVL\n(Extreme-Ultraviolet-Lithography) paradigm, which promises to advance pattern\nshrinking (2 nm node and beyond). However, a significant increase in stochastic\ndefects and the complexity of defect detection becomes more pronounced with\nhigh-NA. Present defect inspection techniques (both non-machine learning and\nmachine learning based), fail to achieve satisfactory performance at high-NA\ndimensions. In this work, we investigate the use of the Slicing Aided Hyper\nInference (SAHI) framework for improving upon current techniques. Using SAHI,\ninference is performed on size-increased slices of the SEM images. This leads\nto the object detector's receptive field being more effective in capturing\nsmall defect instances. First, the performance on previously investigated\nsemiconductor datasets is benchmarked across various configurations, and the\nSAHI approach is demonstrated to substantially enhance the detection of small\ndefects, by approx. 2x. Afterwards, we also demonstrated application of SAHI\nleads to flawless detection rates on a new test dataset, with scenarios not\nencountered during training, whereas previous trained models failed. Finally,\nwe formulate an extension of SAHI that does not significantly reduce\ntrue-positive predictions while eliminating false-positive predictions.",
            "author": [
                "Vic De Ridder",
                "Bappaditya Dey",
                "Victor Blanco",
                "Sandip Halder",
                "Bartel Van Waeyenberge"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11439v2",
                "http://arxiv.org/pdf/2311.11439v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11437v1",
            "title": "Decoding the Molecular Universe -- Workshop Report",
            "updated": "2023-11-19T22:17:40Z",
            "published": "2023-11-19T22:17:40Z",
            "summary": "On August 9-10, 2023, a workshop was convened at the Pacific Northwest\nNational Laboratory (PNNL) in Richland, WA that brought together a group of\ninternationally recognized experts in metabolomics, natural products discovery,\nchemical ecology, chemical and biological threat assessment, cheminformatics,\ncomputational chemistry, cloud computing, artificial intelligence, and novel\ntechnology development. These experts were invited to assess the value and\nfeasibility of a grand-scale project to create new technologies that would\nallow the identification and quantification of all small molecules, or to\ndecode the molecular universe. The Decoding the Molecular Universe project\nwould extend and complement the success of the Human Genome Project by\ndeveloping new capabilities and technologies to measure small molecules\n(defined as non-protein, non-polymer molecules less than 1500 Daltons) of any\norigin and generated in biological systems or produced abiotically. Workshop\nattendees 1) explored what new understanding of biological and environmental\nsystems could be revealed through the lens of small molecules; 2) characterized\nthe similarities in current needs and technical challenges between each science\nor mission area for unambiguous and comprehensive determination of the\ncomposition and quantities of small molecules of any sample; 3) determined the\nextent to which technologies or methods currently exist for unambiguously and\ncomprehensively determining the small molecule composition of any sample and in\na reasonable time; and 4) identified the attributes of the ideal technology or\napproach for universal small molecule measurement and identification. The\nworkshop concluded with a discussion of how a project of this scale could be\nundertaken, possible thrusts for the project, early proof-of-principle\napplications, and similar efforts upon which the project could be modeled.",
            "author": [
                "Thomas O. Metz",
                "Joshua N. Adkins",
                "Peter B. Armentrout",
                "Patrick Chain",
                "Fanny Chu",
                "Courtney D Corley",
                "John R. Cort",
                "Elizabeth Denis",
                "Daniel Drell",
                "Katherine R. Duncan",
                "Robert G. Ewing",
                "Facundo M. Fernandez",
                "Oliver Fiehn",
                "Neha Garg",
                "Stefan Grimme",
                "Christopher Henry",
                "Robert L. Hettich",
                "Tobias Kind",
                "Roger G. Linington",
                "Gary W. Miller",
                "Trent Northen",
                "Kirsten Overdahl",
                "Ari Patrinos",
                "Daniel Raftery",
                "Paul Rigor",
                "Richard D. Smith",
                "Jon Sobus",
                "Justin Teeguarden",
                "Akos Vertes",
                "Katrina Waters",
                "Bobbie-Jo Webb-Robertson",
                "Antony Williams",
                "David Wishart"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11437v1",
                "http://arxiv.org/pdf/2311.11437v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11436v1",
            "title": "Duality of Bures and Shape Distances with Implications for Comparing\n  Neural Representations",
            "updated": "2023-11-19T22:17:09Z",
            "published": "2023-11-19T22:17:09Z",
            "summary": "A multitude of (dis)similarity measures between neural network\nrepresentations have been proposed, resulting in a fragmented research\nlandscape. Most of these measures fall into one of two categories.\n  First, measures such as linear regression, canonical correlations analysis\n(CCA), and shape distances, all learn explicit mappings between neural units to\nquantify similarity while accounting for expected invariances. Second, measures\nsuch as representational similarity analysis (RSA), centered kernel alignment\n(CKA), and normalized Bures similarity (NBS) all quantify similarity in summary\nstatistics, such as stimulus-by-stimulus kernel matrices, which are already\ninvariant to expected symmetries. Here, we take steps towards unifying these\ntwo broad categories of methods by observing that the cosine of the Riemannian\nshape distance (from category 1) is equal to NBS (from category 2). We explore\nhow this connection leads to new interpretations of shape distances and NBS,\nand draw contrasts of these measures with CKA, a popular similarity measure in\nthe deep learning literature.",
            "author": [
                "Sarah E. Harvey",
                "Brett W. Larsen",
                "Alex H. Williams"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11436v1",
                "http://arxiv.org/pdf/2311.11436v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11435v2",
            "title": "Unveiling Public Perceptions: Machine Learning-Based Sentiment Analysis\n  of COVID-19 Vaccines in India",
            "updated": "2023-11-26T15:05:58Z",
            "published": "2023-11-19T22:14:48Z",
            "summary": "In March 2020, the World Health Organisation declared COVID-19 a global\npandemic as it spread to nearly every country. By mid-2021, India had\nintroduced three vaccines: Covishield, Covaxin, and Sputnik. To ensure\nsuccessful vaccination in a densely populated country like India, understanding\npublic sentiment was crucial. Social media, particularly Reddit with over 430\nmillion users, played a vital role in disseminating information. This study\nemploys data mining techniques to analyze Reddit data and gauge Indian\nsentiments towards COVID-19 vaccines. Using Python's Text Blob library,\ncomments are annotated to assess general sentiments. Results show that most\nReddit users in India expressed neutrality about vaccination, posing a\nchallenge for the Indian government's efforts to vaccinate a significant\nportion of the population.",
            "author": [
                "Milind Gupta",
                "Abhishek Kaushik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11435v2",
                "http://arxiv.org/pdf/2311.11435v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11429v1",
            "title": "Fast Heavy Inner Product Identification Between Weights and Inputs in\n  Neural Network Training",
            "updated": "2023-11-19T21:40:16Z",
            "published": "2023-11-19T21:40:16Z",
            "summary": "In this paper, we consider a heavy inner product identification problem,\nwhich generalizes the Light Bulb problem~(\\cite{prr89}): Given two sets $A\n\\subset \\{-1,+1\\}^d$ and $B \\subset \\{-1,+1\\}^d$ with $|A|=|B| = n$, if there\nare exact $k$ pairs whose inner product passes a certain threshold, i.e.,\n$\\{(a_1, b_1), \\cdots, (a_k, b_k)\\} \\subset A \\times B$ such that $\\forall i\n\\in [k], \\langle a_i,b_i \\rangle \\geq \\rho \\cdot d$, for a threshold $\\rho \\in\n(0,1)$, the goal is to identify those $k$ heavy inner products. We provide an\nalgorithm that runs in $O(n^{2 \\omega / 3+ o(1)})$ time to find the $k$ inner\nproduct pairs that surpass $\\rho \\cdot d$ threshold with high probability,\nwhere $\\omega$ is the current matrix multiplication exponent. By solving this\nproblem, our method speed up the training of neural networks with ReLU\nactivation function.",
            "author": [
                "Lianke Qin",
                "Saayan Mitra",
                "Zhao Song",
                "Yuanyuan Yang",
                "Tianyi Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11429v1",
                "http://arxiv.org/pdf/2311.11429v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11428v1",
            "title": "Self-interacting approximation to McKean-Vlasov long-time limit: a\n  Markov chain Monte Carlo method",
            "updated": "2023-11-19T21:37:56Z",
            "published": "2023-11-19T21:37:56Z",
            "summary": "For a certain class of McKean--Vlasov processes, we introduce proxy processes\nthat substitute the mean-field interaction with self-interaction, employing a\nweighted occupation measure. Our study encompasses two key achievements. First,\nwe demonstrate the ergodicity of the self-interacting dynamics, under broad\nconditions, by applying the reflection coupling method. Second, in scenarios\nwhere the drifts are negative intrinsic gradients of convex mean-field\npotential functionals, we use entropy and functional inequalities to\ndemonstrate that the stationary measures of the self-interacting processes\napproximate the invariant measures of the corresponding McKean--Vlasov\nprocesses. As an application, we show how to learn the optimal weights of a\ntwo-layer neural network by training a single neuron.",
            "author": [
                "Kai Du",
                "Zhenjie Ren",
                "Florin Suciu",
                "Songbo Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11428v1",
                "http://arxiv.org/pdf/2311.11428v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11427v1",
            "title": "Appearance Codes using Joint Embedding Learning of Multiple Modalities",
            "updated": "2023-11-19T21:24:34Z",
            "published": "2023-11-19T21:24:34Z",
            "summary": "The use of appearance codes in recent work on generative modeling has enabled\nnovel view renders with variable appearance and illumination, such as day-time\nand night-time renders of a scene. A major limitation of this technique is the\nneed to re-train new appearance codes for every scene on inference, so in this\nwork we address this problem proposing a framework that learns a joint\nembedding space for the appearance and structure of the scene by enforcing a\ncontrastive loss constraint between different modalities. We apply our\nframework to a simple Variational Auto-Encoder model on the RADIATE dataset\n\\cite{sheeny2021radiate} and qualitatively demonstrate that we can generate new\nrenders of night-time photos using day-time appearance codes without additional\noptimization iterations. Additionally, we compare our model to a baseline VAE\nthat uses the standard per-image appearance code technique and show that our\napproach achieves generations of similar quality without learning appearance\ncodes for any unseen images on inference.",
            "author": [
                "Alex Zhang",
                "Evan Dogariu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11427v1",
                "http://arxiv.org/pdf/2311.11427v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11424v1",
            "title": "Tensor-Aware Energy Accounting",
            "updated": "2023-11-19T21:06:00Z",
            "published": "2023-11-19T21:06:00Z",
            "summary": "With the rapid growth of Artificial Intelligence (AI) applications supported\nby deep learning (DL), the energy efficiency of these applications has an\nincreasingly large impact on sustainability. We introduce Smaragdine, a new\nenergy accounting system for tensor-based DL programs implemented with\nTensorFlow. At the heart of Smaragdine is a novel white-box methodology of\nenergy accounting: Smaragdine is aware of the internal structure of the DL\nprogram, which we call tensor-aware energy accounting. With Smaragdine, the\nenergy consumption of a DL program can be broken down into units aligned with\nits logical hierarchical decomposition structure. We apply Smaragdine for\nunderstanding the energy behavior of BERT, one of the most widely used language\nmodels. Layer-by-layer and tensor-by-tensor, Smaragdine is capable of\nidentifying the highest energy/power-consuming components of BERT. Furthermore,\nwe conduct two case studies on how Smaragdine supports downstream toolchain\nbuilding, one on the comparative energy impact of hyperparameter tuning of\nBERT, the other on the energy behavior evolution when BERT evolves to its next\ngeneration, ALBERT.",
            "author": [
                "Timur Babakol",
                "Yu David Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11424v1",
                "http://arxiv.org/pdf/2311.11424v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11423v1",
            "title": "Offline Reinforcement Learning for Wireless Network Optimization with\n  Mixture Datasets",
            "updated": "2023-11-19T21:02:17Z",
            "published": "2023-11-19T21:02:17Z",
            "summary": "The recent development of reinforcement learning (RL) has boosted the\nadoption of online RL for wireless radio resource management (RRM). However,\nonline RL algorithms require direct interactions with the environment, which\nmay be undesirable given the potential performance loss due to the unavoidable\nexploration in RL. In this work, we first investigate the use of \\emph{offline}\nRL algorithms in solving the RRM problem. We evaluate several state-of-the-art\noffline RL algorithms, including behavior constrained Q-learning (BCQ),\nconservative Q-learning (CQL), and implicit Q-learning (IQL), for a specific\nRRM problem that aims at maximizing a linear combination {of sum and}\n5-percentile rates via user scheduling. We observe that the performance of\noffline RL for the RRM problem depends critically on the behavior policy used\nfor data collection, and further propose a novel offline RL solution that\nleverages heterogeneous datasets collected by different behavior policies. We\nshow that with a proper mixture of the datasets, offline RL can produce a\nnear-optimal RL policy even when all involved behavior policies are highly\nsuboptimal.",
            "author": [
                "Kun Yang",
                "Cong Shen",
                "Jing Yang",
                "Shu-ping Yeh",
                "Jerry Sydir"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11423v1",
                "http://arxiv.org/pdf/2311.11423v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.LG",
                "cs.NI",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11422v1",
            "title": "Precision at the indistinguishability threshold: a method for evaluating\n  classification algorithms",
            "updated": "2023-11-19T20:47:39Z",
            "published": "2023-11-19T20:47:39Z",
            "summary": "There exist a wide range of single number metrics for assessing performance\nof classification algorithms, including AUC and the F1-score (Wikipedia lists\n17 such metrics, with 27 different names). In this article, I propose a new\nmetric to answer the following question: when an algorithm is tuned so that it\ncan no longer distinguish labelled cats from real cats, how often does a\nrandomly chosen image that has been labelled as containing a cat actually\ncontain a cat? The steps to construct this metric are as follows. First, we set\na threshold score such that when the algorithm is shown two randomly-chosen\nimages -- one that has a score greater than the threshold (i.e. a picture\nlabelled as containing a cat) and another from those pictures that really does\ncontain a cat -- the probability that the image with the highest score is the\none chosen from the set of real cat images is 50\\%. At this decision threshold,\nthe set of positively labelled images are indistinguishable from the set of\nimages which are positive. Then, as a second step, we measure performance by\nasking how often a randomly chosen picture from those labelled as containing a\ncat actually contains a cat. This metric can be thought of as {\\it precision at\nthe indistinguishability threshold}. While this new metric doesn't address the\ntradeoff between precision and recall inherent to all such metrics, I do show\nwhy this method avoids pitfalls that can occur when using, for example AUC, and\nit is better motivated than, for example, the F1-score.",
            "author": [
                "David J. T. Sumpter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11422v1",
                "http://arxiv.org/pdf/2311.11422v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11420v1",
            "title": "LifeLearner: Hardware-Aware Meta Continual Learning System for Embedded\n  Computing Platforms",
            "updated": "2023-11-19T20:39:35Z",
            "published": "2023-11-19T20:39:35Z",
            "summary": "Continual Learning (CL) allows applications such as user personalization and\nhousehold robots to learn on the fly and adapt to context. This is an important\nfeature when context, actions, and users change. However, enabling CL on\nresource-constrained embedded systems is challenging due to the limited labeled\ndata, memory, and computing capacity. In this paper, we propose LifeLearner, a\nhardware-aware meta continual learning system that drastically optimizes system\nresources (lower memory, latency, energy consumption) while ensuring high\naccuracy. Specifically, we (1) exploit meta-learning and rehearsal strategies\nto explicitly cope with data scarcity issues and ensure high accuracy, (2)\neffectively combine lossless and lossy compression to significantly reduce the\nresource requirements of CL and rehearsal samples, and (3) developed\nhardware-aware system on embedded and IoT platforms considering the hardware\ncharacteristics. As a result, LifeLearner achieves near-optimal CL performance,\nfalling short by only 2.8% on accuracy compared to an Oracle baseline. With\nrespect to the state-of-the-art (SOTA) Meta CL method, LifeLearner drastically\nreduces the memory footprint (by 178.7x), end-to-end latency by 80.8-94.2%, and\nenergy consumption by 80.9-94.2%. In addition, we successfully deployed\nLifeLearner on two edge devices and a microcontroller unit, thereby enabling\nefficient CL on resource-constrained platforms where it would be impractical to\nrun SOTA methods and the far-reaching deployment of adaptable CL in a\nubiquitous manner. Code is available at\nhttps://github.com/theyoungkwon/LifeLearner.",
            "author": [
                "Young D. Kwon",
                "Jagmohan Chauhan",
                "Hong Jia",
                "Stylianos I. Venieris",
                "Cecilia Mascolo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11420v1",
                "http://arxiv.org/pdf/2311.11420v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12071v1",
            "title": "Enhancing Low-dose CT Image Reconstruction by Integrating Supervised and\n  Unsupervised Learning",
            "updated": "2023-11-19T20:23:59Z",
            "published": "2023-11-19T20:23:59Z",
            "summary": "Traditional model-based image reconstruction (MBIR) methods combine forward\nand noise models with simple object priors. Recent application of deep learning\nmethods for image reconstruction provides a successful data-driven approach to\naddressing the challenges when reconstructing images with undersampled\nmeasurements or various types of noise. In this work, we propose a hybrid\nsupervised-unsupervised learning framework for X-ray computed tomography (CT)\nimage reconstruction. The proposed learning formulation leverages both sparsity\nor unsupervised learning-based priors and neural network reconstructors to\nsimulate a fixed-point iteration process. Each proposed trained block consists\nof a deterministic MBIR solver and a neural network. The information flows in\nparallel through these two reconstructors and is then optimally combined.\nMultiple such blocks are cascaded to form a reconstruction pipeline. We\ndemonstrate the efficacy of this learned hybrid model for low-dose CT image\nreconstruction with limited training data, where we use the NIH AAPM Mayo\nClinic Low Dose CT Grand Challenge dataset for training and testing. In our\nexperiments, we study combinations of supervised deep network reconstructors\nand MBIR solver with learned sparse representation-based priors or analytical\npriors. Our results demonstrate the promising performance of the proposed\nframework compared to recent low-dose CT reconstruction methods.",
            "author": [
                "Ling Chen",
                "Zhishen Huang",
                "Yong Long",
                "Saiprasad Ravishankar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12071v1",
                "http://arxiv.org/pdf/2311.12071v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11415v1",
            "title": "A Security Risk Taxonomy for Large Language Models",
            "updated": "2023-11-19T20:22:05Z",
            "published": "2023-11-19T20:22:05Z",
            "summary": "As large language models (LLMs) permeate more and more applications, an\nassessment of their associated security risks becomes increasingly necessary.\nThe potential for exploitation by malicious actors, ranging from disinformation\nto data breaches and reputation damage, is substantial. This paper addresses a\ngap in current research by focusing on the security risks posed by LLMs, which\nextends beyond the widely covered ethical and societal implications. Our work\nproposes a taxonomy of security risks along the user-model communication\npipeline, explicitly focusing on prompt-based attacks on LLMs. We categorize\nthe attacks by target and attack type within a prompt-based interaction scheme.\nThe taxonomy is reinforced with specific attack examples to showcase the\nreal-world impact of these risks. Through this taxonomy, we aim to inform the\ndevelopment of robust and secure LLM applications, enhancing their safety and\ntrustworthiness.",
            "author": [
                "Erik Derner",
                "Kristina Batisti\u010d",
                "Jan Zah\u00e1lka",
                "Robert Babu\u0161ka"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11415v1",
                "http://arxiv.org/pdf/2311.11415v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.CL",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11413v1",
            "title": "Large Pre-trained time series models for cross-domain Time series\n  analysis tasks",
            "updated": "2023-11-19T20:16:16Z",
            "published": "2023-11-19T20:16:16Z",
            "summary": "Large pre-trained models have been instrumental in significant advancements\nin domains like language and vision making model training for individual\ndownstream tasks more efficient as well as provide superior performance.\nHowever, tackling time-series analysis tasks usually involves designing and\ntraining a separate model from scratch leveraging training data and domain\nexpertise specific to the task. We tackle a significant challenge for\npre-training a general time-series model from multiple heterogeneous\ntime-series dataset: providing semantically useful inputs to models for\nmodeling time series of different dynamics from different domains. We observe\nthat partitioning time-series into segments as inputs to sequential models\nproduces semantically better inputs and propose a novel model LPTM that\nautomatically identifies optimal dataset-specific segmentation strategy\nleveraging self-supervised learning loss during pre-training. LPTM provides\nperformance similar to or better than domain-specific state-of-art model and is\nsignificantly more data and compute efficient taking up to 40% less data as\nwell as 50% less training time to achieve state-of-art performance in a wide\nrange of time-series analysis tasks from multiple disparate domain.",
            "author": [
                "Harshavardhan Kamarthi",
                "B. Aditya Prakash"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11413v1",
                "http://arxiv.org/pdf/2311.11413v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11412v1",
            "title": "Neural Quantum Embedding: Pushing the Limits of Quantum Supervised\n  Learning",
            "updated": "2023-11-19T19:58:33Z",
            "published": "2023-11-19T19:58:33Z",
            "summary": "Quantum embedding is indispensable for applying quantum machine learning\ntechniques to classical data, and has substantial impacts on performance\noutcomes. In this study, we present Neural Quantum Embedding (NQE), a method\nthat efficiently optimizes quantum embedding by leveraging classical deep\nlearning techniques. NQE enhances the lower bound of the empirical risk,\nleading to substantial improvements in classification performance. Moreover,\nNQE improves robustness against noise. To validate the effectiveness of NQE, we\nconduct experiments on IBM quantum devices for image data classification,\nresulting in a remarkable accuracy enhancement from 0.52 to 0.96. Numerical\nanalysis of the local effective dimension highlights that NQE improves the\ntrainability and generalization performance of quantum neural networks.\nFurthermore, NQE achieves improved generalization in the quantum kernel method,\nas evidenced by a reduction in the upper bound of the expected risk.",
            "author": [
                "Tak Hur",
                "Israel F. Araujo",
                "Daniel K. Park"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11412v1",
                "http://arxiv.org/pdf/2311.11412v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11410v1",
            "title": "Negotiated Representations for Machine Mearning Application",
            "updated": "2023-11-19T19:53:49Z",
            "published": "2023-11-19T19:53:49Z",
            "summary": "Overfitting is a phenomenon that occurs when a machine learning model is\ntrained for too long and focused too much on the exact fitness of the training\nsamples to the provided training labels and cannot keep track of the predictive\nrules that would be useful on the test data. This phenomenon is commonly\nattributed to memorization of particular samples, memorization of the noise,\nand forced fitness into a data set of limited samples by using a high number of\nneurons. While it is true that the model encodes various peculiarities as the\ntraining process continues, we argue that most of the overfitting occurs in the\nprocess of reconciling sharply defined membership ratios. In this study, we\npresent an approach that increases the classification accuracy of machine\nlearning models by allowing the model to negotiate output representations of\nthe samples with previously determined class labels. By setting up a\nnegotiation between the models interpretation of the inputs and the provided\nlabels, we not only increased average classification accuracy but also\ndecreased the rate of overfitting without applying any other regularization\ntricks. By implementing our negotiation paradigm approach to several low regime\nmachine learning problems by generating overfitting scenarios from publicly\navailable data sets such as CIFAR 10, CIFAR 100, and MNIST we have demonstrated\nthat the proposed paradigm has more capacity than its intended purpose. We are\nsharing the experimental results and inviting the machine learning community to\nexplore the limits of the proposed paradigm. We also aim to incentive the\ncommunity to exploit the negotiation paradigm to overcome the learning related\nchallenges in other research fields such as continual learning. The Python code\nof the experimental setup is uploaded to GitHub.",
            "author": [
                "Nuri Korhan",
                "Samet Bayram"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11410v1",
                "http://arxiv.org/pdf/2311.11410v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11397v1",
            "title": "Attention-based Multi-fidelity Machine Learning Model for Computational\n  Fractional Flow Reserve Assessment",
            "updated": "2023-11-19T18:42:34Z",
            "published": "2023-11-19T18:42:34Z",
            "summary": "Coronary Artery Disease (CAD) is one of the most common forms of heart\ndisease, which is caused by a buildup of atherosclerotic plaque (known as\nstenosis) in the coronary arteries, leading to insufficient supplement of\nblood, oxygen, and nutrients to the heart. Fractional Flow Reserve (FFR),\nmeasuring the pressure ratio between the aorta and distal coronary artery, is\nan invasive physiologic gold standard for assessing the severity of coronary\nartery stenosis. Despite its benefits, invasive FFR assessment is still\nunderutilized due to its high cost, time-consuming, experimental variability,\nand increased risk to patients. In this study, an attention-based\nmulti-fidelity machine learning model (AttMulFid) is proposed for\ncomputationally efficient and accurate FFR assessment with uncertainty\nmeasurement. Within AttMulFid, an autoencoder is utilized to intelligently\nselect geometric features from coronary arteries, with additional attention on\nthe key area. Results show that the geometric features are able to represent\nthe entirety of the geometric information and intelligently allocate attention\nbased on crucial properties of geometry. Furthermore, the AttMulFid is a\nfeasible approach for non-invasive, rapid, and accurate FFR assessment (with\n0.002s/simulation).",
            "author": [
                "Haizhou Yang",
                "C. Alberto Figueroa",
                "Krishna Garikipati"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11397v1",
                "http://arxiv.org/pdf/2311.11397v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11396v1",
            "title": "Towards interpretable-by-design deep learning algorithms",
            "updated": "2023-11-19T18:40:49Z",
            "published": "2023-11-19T18:40:49Z",
            "summary": "The proposed framework named IDEAL (Interpretable-by-design DEep learning\nALgorithms) recasts the standard supervised classification problem into a\nfunction of similarity to a set of prototypes derived from the training data,\nwhile taking advantage of existing latent spaces of large neural networks\nforming so-called Foundation Models (FM). This addresses the issue of\nexplainability (stage B) while retaining the benefits from the tremendous\nachievements offered by DL models (e.g., visual transformers, ViT) pre-trained\non huge data sets such as IG-3.6B + ImageNet-1K or LVD-142M (stage A). We show\nthat one can turn such DL models into conceptually simpler,\nexplainable-through-prototypes ones.\n  The key findings can be summarized as follows: (1) the proposed models are\ninterpretable through prototypes, mitigating the issue of confounded\ninterpretations, (2) the proposed IDEAL framework circumvents the issue of\ncatastrophic forgetting allowing efficient class-incremental learning, and (3)\nthe proposed IDEAL approach demonstrates that ViT architectures narrow the gap\nbetween finetuned and non-finetuned models allowing for transfer learning in a\nfraction of time \\textbf{without} finetuning of the feature space on a target\ndataset with iterative supervised methods.",
            "author": [
                "Plamen Angelov",
                "Dmitry Kangin",
                "Ziyang Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11396v1",
                "http://arxiv.org/pdf/2311.11396v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11390v1",
            "title": "Addressing the speed-accuracy simulation trade-off for adaptive spiking\n  neurons",
            "updated": "2023-11-19T18:21:45Z",
            "published": "2023-11-19T18:21:45Z",
            "summary": "The adaptive leaky integrate-and-fire (ALIF) model is fundamental within\ncomputational neuroscience and has been instrumental in studying our brains\n$\\textit{in silico}$. Due to the sequential nature of simulating these neural\nmodels, a commonly faced issue is the speed-accuracy trade-off: either\naccurately simulate a neuron using a small discretisation time-step (DT), which\nis slow, or more quickly simulate a neuron using a larger DT and incur a loss\nin simulation accuracy. Here we provide a solution to this dilemma, by\nalgorithmically reinterpreting the ALIF model, reducing the sequential\nsimulation complexity and permitting a more efficient parallelisation on GPUs.\nWe computationally validate our implementation to obtain over a $50\\times$\ntraining speedup using small DTs on synthetic benchmarks. We also obtained a\ncomparable performance to the standard ALIF implementation on different\nsupervised classification tasks - yet in a fraction of the training time.\nLastly, we showcase how our model makes it possible to quickly and accurately\nfit real electrophysiological recordings of cortical neurons, where very fine\nsub-millisecond DTs are crucial for capturing exact spike timing.",
            "author": [
                "Luke Taylor",
                "Andrew J King",
                "Nicol S Harper"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11390v1",
                "http://arxiv.org/pdf/2311.11390v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11388v2",
            "title": "Machine Culture",
            "updated": "2023-11-22T08:15:13Z",
            "published": "2023-11-19T18:12:21Z",
            "summary": "The ability of humans to create and disseminate culture is often credited as\nthe single most important factor of our success as a species. In this\nPerspective, we explore the notion of machine culture, culture mediated or\ngenerated by machines. We argue that intelligent machines simultaneously\ntransform the cultural evolutionary processes of variation, transmission, and\nselection. Recommender algorithms are altering social learning dynamics.\nChatbots are forming a new mode of cultural transmission, serving as cultural\nmodels. Furthermore, intelligent machines are evolving as contributors in\ngenerating cultural traits--from game strategies and visual art to scientific\nresults. We provide a conceptual framework for studying the present and\nanticipated future impact of machines on cultural evolution, and present a\nresearch agenda for the study of machine culture.",
            "author": [
                "Levin Brinkmann",
                "Fabian Baumann",
                "Jean-Fran\u00e7ois Bonnefon",
                "Maxime Derex",
                "Thomas F. M\u00fcller",
                "Anne-Marie Nussberger",
                "Agnieszka Czaplicka",
                "Alberto Acerbi",
                "Thomas L. Griffiths",
                "Joseph Henrich",
                "Joel Z. Leibo",
                "Richard McElreath",
                "Pierre-Yves Oudeyer",
                "Jonathan Stray",
                "Iyad Rahwan"
            ],
            "link": [
                "http://dx.doi.org/10.1038/s41562-023-01742-2",
                "http://arxiv.org/abs/2311.11388v2",
                "http://arxiv.org/pdf/2311.11388v2"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11385v1",
            "title": "Multi-Task Reinforcement Learning with Mixture of Orthogonal Experts",
            "updated": "2023-11-19T18:09:25Z",
            "published": "2023-11-19T18:09:25Z",
            "summary": "Multi-Task Reinforcement Learning (MTRL) tackles the long-standing problem of\nendowing agents with skills that generalize across a variety of problems. To\nthis end, sharing representations plays a fundamental role in capturing both\nunique and common characteristics of the tasks. Tasks may exhibit similarities\nin terms of skills, objects, or physical properties while leveraging their\nrepresentations eases the achievement of a universal policy. Nevertheless, the\npursuit of learning a shared set of diverse representations is still an open\nchallenge. In this paper, we introduce a novel approach for representation\nlearning in MTRL that encapsulates common structures among the tasks using\northogonal representations to promote diversity. Our method, named Mixture Of\nOrthogonal Experts (MOORE), leverages a Gram-Schmidt process to shape a shared\nsubspace of representations generated by a mixture of experts. When\ntask-specific information is provided, MOORE generates relevant representations\nfrom this shared subspace. We assess the effectiveness of our approach on two\nMTRL benchmarks, namely MiniGrid and MetaWorld, showing that MOORE surpasses\nrelated baselines and establishes a new state-of-the-art result on MetaWorld.",
            "author": [
                "Ahmed Hendawy",
                "Jan Peters",
                "Carlo D'Eramo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11385v1",
                "http://arxiv.org/pdf/2311.11385v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11384v1",
            "title": "PIMSAB: A Processing-In-Memory System with Spatially-Aware Communication\n  and Bit-Serial-Aware Computation",
            "updated": "2023-11-19T18:03:44Z",
            "published": "2023-11-19T18:03:44Z",
            "summary": "Bit-serial Processing-In-Memory (PIM) is an attractive paradigm for\naccelerator architectures, for parallel workloads such as Deep Learning (DL),\nbecause of its capability to achieve massive data parallelism at a low area\noverhead and provide orders-of-magnitude data movement savings by moving\ncomputational resources closer to the data. While many PIM architectures have\nbeen proposed, improvements are needed in communicating intermediate results to\nconsumer kernels, for communication between tiles at scale, for reduction\noperations, and for efficiently performing bit-serial operations with\nconstants.\n  We present PIMSAB, a scalable architecture that provides spatially aware\ncommunication network for efficient intra-tile and inter-tile data movement and\nprovides efficient computation support for generally inefficient bit-serial\ncompute patterns. Our architecture consists of a massive hierarchical array of\ncompute-enabled SRAMs (CRAMs) and is codesigned with a compiler to achieve high\nutilization. The key novelties of our architecture are: (1) providing efficient\nsupport for spatially-aware communication by providing local H-tree network for\nreductions, by adding explicit hardware for shuffling operands, and by\ndeploying systolic broadcasting, and (2) taking advantage of the divisible\nnature of bit-serial computations through adaptive precision, bit-slicing and\nefficient handling of constant operations.\n  When compared against a similarly provisioned modern Tensor Core GPU (NVIDIA\nA100), across common DL kernels and an end-to-end DL network (Resnet18), PIMSAB\noutperforms the GPU by 3x, and reduces energy by 4.2x. We compare PIMSAB with\nsimilarly provisioned state-of-the-art SRAM PIM (Duality Cache) and DRAM PIM\n(SIMDRAM) and observe a speedup of 3.7x and 3.88x respectively.",
            "author": [
                "Aman Arora",
                "Jian Weng",
                "Siyuan Ma",
                "Tony Nowatzki",
                "Lizy K. John"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11384v1",
                "http://arxiv.org/pdf/2311.11384v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12068v2",
            "title": "Enhancing Novel Object Detection via Cooperative Foundational Models",
            "updated": "2023-11-22T04:13:38Z",
            "published": "2023-11-19T17:28:28Z",
            "summary": "In this work, we address the challenging and emergent problem of novel object\ndetection (NOD), focusing on the accurate detection of both known and novel\nobject categories during inference. Traditional object detection algorithms are\ninherently closed-set, limiting their capability to handle NOD. We present a\nnovel approach to transform existing closed-set detectors into open-set\ndetectors. This transformation is achieved by leveraging the complementary\nstrengths of pre-trained foundational models, specifically CLIP and SAM,\nthrough our cooperative mechanism. Furthermore, by integrating this mechanism\nwith state-of-the-art open-set detectors such as GDINO, we establish new\nbenchmarks in object detection performance. Our method achieves 17.42 mAP in\nnovel object detection and 42.08 mAP for known objects on the challenging LVIS\ndataset. Adapting our approach to the COCO OVD split, we surpass the current\nstate-of-the-art by a margin of 7.2 $ \\text{AP}_{50} $ for novel classes. Our\ncode is available at\nhttps://github.com/rohit901/cooperative-foundational-models .",
            "author": [
                "Rohit Bharadwaj",
                "Muzammal Naseer",
                "Salman Khan",
                "Fahad Shahbaz Khan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12068v2",
                "http://arxiv.org/pdf/2311.12068v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00032v1",
            "title": "Revolutionizing Forensic Toolmark Analysis: An Objective and Transparent\n  Comparison Algorithm",
            "updated": "2023-11-19T17:21:41Z",
            "published": "2023-11-19T17:21:41Z",
            "summary": "Forensic toolmark comparisons are currently performed subjectively by humans,\nwhich leads to a lack of consistency and accuracy. There is little evidence\nthat examiners can determine whether pairs of marks were made by the same tool\nor different tools. There is also little evidence that they can make this\nclassification when marks are made under different conditions, such as\ndifferent angles of attack or direction of mark generation. We generate\noriginal toolmark data in 3D, extract the signal from each toolmarks, and train\nan algorithm to compare toolmark signals objectively. We find that toolmark\nsignals cluster by tool, and not by angle or direction. That is, the\nvariability within tool, regardless of angle/direction, is smaller than the\nvariability between tools. The known-match and known-non-match densities of the\nsimilarities of pairs of marks have a small overlap, even when accounting for\ndependencies in the data, making them a useful instrument for determining\nwhether a new pair of marks was made by the same tool. We provide a likelihood\nratio approach as a formal method for comparing toolmark signals with a measure\nof uncertainty. This empirically trained, open-source method can be used by\nforensic examiners to compare toolmarks objectively and thus improve the\nreliability of toolmark comparisons. This can, in turn, reduce miscarriages of\njustice in the criminal justice system.",
            "author": [
                "Maria Cuellar",
                "Sheng Gao",
                "Heike Hofmann"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00032v1",
                "http://arxiv.org/pdf/2312.00032v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11375v1",
            "title": "ML-LMCL: Mutual Learning and Large-Margin Contrastive Learning for\n  Improving ASR Robustness in Spoken Language Understanding",
            "updated": "2023-11-19T16:53:35Z",
            "published": "2023-11-19T16:53:35Z",
            "summary": "Spoken language understanding (SLU) is a fundamental task in the\ntask-oriented dialogue systems. However, the inevitable errors from automatic\nspeech recognition (ASR) usually impair the understanding performance and lead\nto error propagation. Although there are some attempts to address this problem\nthrough contrastive learning, they (1) treat clean manual transcripts and ASR\ntranscripts equally without discrimination in fine-tuning; (2) neglect the fact\nthat the semantically similar pairs are still pushed away when applying\ncontrastive learning; (3) suffer from the problem of Kullback-Leibler (KL)\nvanishing. In this paper, we propose Mutual Learning and Large-Margin\nContrastive Learning (ML-LMCL), a novel framework for improving ASR robustness\nin SLU. Specifically, in fine-tuning, we apply mutual learning and train two\nSLU models on the manual transcripts and the ASR transcripts, respectively,\naiming to iteratively share knowledge between these two models. We also\nintroduce a distance polarization regularizer to avoid pushing away the\nintra-cluster pairs as much as possible. Moreover, we use a cyclical annealing\nschedule to mitigate KL vanishing issue. Experiments on three datasets show\nthat ML-LMCL outperforms existing models and achieves new state-of-the-art\nperformance.",
            "author": [
                "Xuxin Cheng",
                "Bowen Cao",
                "Qichen Ye",
                "Zhihong Zhu",
                "Hongxiang Li",
                "Yuexian Zou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11375v1",
                "http://arxiv.org/pdf/2311.11375v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11372v1",
            "title": "Dynamic System Stability Verification Using Numerical Simulator",
            "updated": "2023-11-19T16:49:28Z",
            "published": "2023-11-19T16:49:28Z",
            "summary": "There are recent shifts in demand for design controllers from simplified to\ncomplex model-based. Although simplification approaches are successful in many\nareas of engineering control systems, high-fidelity simulation-based control\ndesign, for example, reinforcement learning, has been rising in robotics areas.\nOn the other hand, the lack of assurances about the stability and robustness of\nsimulation-based control design restricts its applications to safety-critical\nsystems. We develop computational methods to verify the stability and\nrobustness of safety-critical systems. By extending the inverse Lyapunov\ntheorem, we present a practical method to compute the constants required to\ncheck the exponential stability conditions of dynamic systems implemented in a\nnumerical simulator. It is shown that the norm-bound of the propagated states\nis a function of the numerical integration steps, where the numerical simulator\nmay include discontinuous jumps of states. The energy bounds for the transition\nstates are obtained based on the exponential stability assumption of the\ninverse Lyapunov theorem. Finally, a finite sampling algorithm provides the\ndeterministic stability guarantee for the continuous state space.",
            "author": [
                "Jongrae Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11372v1",
                "http://arxiv.org/pdf/2311.11372v1"
            ],
            "primary_category": "cs.SY",
            "category": [
                "cs.SY",
                "eess.SY",
                "math.DS",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11371v1",
            "title": "SOccDPT: Semi-Supervised 3D Semantic Occupancy from Dense Prediction\n  Transformers trained under memory constraints",
            "updated": "2023-11-19T16:47:51Z",
            "published": "2023-11-19T16:47:51Z",
            "summary": "We present SOccDPT, a memory-efficient approach for 3D semantic occupancy\nprediction from monocular image input using dense prediction transformers. To\naddress the limitations of existing methods trained on structured traffic\ndatasets, we train our model on unstructured datasets including the Indian\nDriving Dataset and Bengaluru Driving Dataset. Our semi-supervised training\npipeline allows SOccDPT to learn from datasets with limited labels by reducing\nthe requirement for manual labelling by substituting it with pseudo-ground\ntruth labels to produce our Bengaluru Semantic Occupancy Dataset. This broader\ntraining enhances our model's ability to handle unstructured traffic scenarios\neffectively. To overcome memory limitations during training, we introduce\npatch-wise training where we select a subset of parameters to train each epoch,\nreducing memory usage during auto-grad graph construction. In the context of\nunstructured traffic and memory-constrained training and inference, SOccDPT\noutperforms existing disparity estimation approaches as shown by the RMSE score\nof 9.1473, achieves a semantic segmentation IoU score of 46.02% and operates at\na competitive frequency of 69.47 Hz. We make our code and semantic occupancy\ndataset public.",
            "author": [
                "Aditya Nalgunda Ganesh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11371v1",
                "http://arxiv.org/pdf/2311.11371v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00798v1",
            "title": "A Turing Test: Are AI Chatbots Behaviorally Similar to Humans?",
            "updated": "2023-11-19T16:44:09Z",
            "published": "2023-11-19T16:44:09Z",
            "summary": "We administer a Turing Test to AI Chatbots. We examine how Chatbots behave in\na suite of classic behavioral games that are designed to elicit characteristics\nsuch as trust, fairness, risk-aversion, cooperation, \\textit{etc.}; as well as\na traditional Big-5 psychological survey that measures personality traits.\nChatGPT-4 passes the Turing Test in that it consistently exhibits human-like\nbehavioral and personality traits based on a comparison to the behavior of\nhundreds of thousands of humans from more than 50 countries. Chatbots also\nmodify their behavior based on previous experience and contexts ``as if'' they\nwere learning from the interactions, and change their behavior in response to\ndifferent framings of the same strategic situation. Their behaviors are often\ndistinct from average and modal human behaviors, in which case they tend to\nbehave on the more altruistic and cooperative end of the distribution. We\nestimate that they act as if they are maximizing an average of their own and\npartner's payoff.",
            "author": [
                "Qiaozhu Mei",
                "Yutong Xie",
                "Walter Yuan",
                "Matthew O. Jackson"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00798v1",
                "http://arxiv.org/pdf/2312.00798v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "91",
                "D.0; J.4; K.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11369v2",
            "title": "Optimal Locally Private Nonparametric Classification with Public Data",
            "updated": "2023-11-21T01:56:38Z",
            "published": "2023-11-19T16:35:01Z",
            "summary": "In this work, we investigate the problem of public data-assisted\nnon-interactive LDP (Local Differential Privacy) learning with a focus on\nnon-parametric classification. Under the posterior drift assumption, we for the\nfirst time derive the mini-max optimal convergence rate with LDP constraint.\nThen, we present a novel approach, the locally private classification tree,\nwhich attains the mini-max optimal convergence rate. Furthermore, we design a\ndata-driven pruning procedure that avoids parameter tuning and produces a fast\nconverging estimator. Comprehensive experiments conducted on synthetic and real\ndatasets show the superior performance of our proposed method. Both our\ntheoretical and experimental findings demonstrate the effectiveness of public\ndata compared to private data, which leads to practical suggestions for\nprioritizing non-private data collection.",
            "author": [
                "Yuheng Ma",
                "Hanfang Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11369v2",
                "http://arxiv.org/pdf/2311.11369v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11368v1",
            "title": "Self-Supervised Pretraining for Heterogeneous Hypergraph Neural Networks",
            "updated": "2023-11-19T16:34:56Z",
            "published": "2023-11-19T16:34:56Z",
            "summary": "Recently, pretraining methods for the Graph Neural Networks (GNNs) have been\nsuccessful at learning effective representations from unlabeled graph data.\nHowever, most of these methods rely on pairwise relations in the graph and do\nnot capture the underling higher-order relations between entities. Hypergraphs\nare versatile and expressive structures that can effectively model higher-order\nrelationships among entities in the data. Despite the efforts to adapt GNNs to\nhypergraphs (HyperGNN), there are currently no fully self-supervised\npretraining methods for HyperGNN on heterogeneous hypergraphs. In this paper,\nwe present SPHH, a novel self-supervised pretraining framework for\nheterogeneous HyperGNNs. Our method is able to effectively capture higher-order\nrelations among entities in the data in a self-supervised manner. SPHH is\nconsist of two self-supervised pretraining tasks that aim to simultaneously\nlearn both local and global representations of the entities in the hypergraph\nby using informative representations derived from the hypergraph structure.\nOverall, our work presents a significant advancement in the field of\nself-supervised pretraining of HyperGNNs, and has the potential to improve the\nperformance of various graph-based downstream tasks such as node classification\nand link prediction tasks which are mapped to hypergraph configuration. Our\nexperiments on two real-world benchmarks using four different HyperGNN models\nshow that our proposed SPHH framework consistently outperforms state-of-the-art\nbaselines in various downstream tasks. The results demonstrate that SPHH is\nable to improve the performance of various HyperGNN models in various\ndownstream tasks, regardless of their architecture or complexity, which\nhighlights the robustness of our framework.",
            "author": [
                "Abdalgader Abubaker",
                "Takanori Maehara",
                "Madhav Nimishakavi",
                "Vassilis Plachouras"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11368v1",
                "http://arxiv.org/pdf/2311.11368v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11367v1",
            "title": "Evidential Uncertainty Quantification: A Variance-Based Perspective",
            "updated": "2023-11-19T16:33:42Z",
            "published": "2023-11-19T16:33:42Z",
            "summary": "Uncertainty quantification of deep neural networks has become an active field\nof research and plays a crucial role in various downstream tasks such as active\nlearning. Recent advances in evidential deep learning shed light on the direct\nquantification of aleatoric and epistemic uncertainties with a single forward\npass of the model. Most traditional approaches adopt an entropy-based method to\nderive evidential uncertainty in classification, quantifying uncertainty at the\nsample level. However, the variance-based method that has been widely applied\nin regression problems is seldom used in the classification setting. In this\nwork, we adapt the variance-based approach from regression to classification,\nquantifying classification uncertainty at the class level. The variance\ndecomposition technique in regression is extended to class covariance\ndecomposition in classification based on the law of total covariance, and the\nclass correlation is also derived from the covariance. Experiments on\ncross-domain datasets are conducted to illustrate that the variance-based\napproach not only results in similar accuracy as the entropy-based one in\nactive domain adaptation but also brings information about class-wise\nuncertainties as well as between-class correlations. The code is available at\nhttps://github.com/KerryDRX/EvidentialADA. This alternative means of evidential\nuncertainty quantification will give researchers more options when class\nuncertainties and correlations are important in their applications.",
            "author": [
                "Ruxiao Duan",
                "Brian Caffo",
                "Harrison X. Bai",
                "Haris I. Sair",
                "Craig Jones"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11367v1",
                "http://arxiv.org/pdf/2311.11367v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14722v1",
            "title": "Zero-Shot Question Answering over Financial Documents using Large\n  Language Models",
            "updated": "2023-11-19T16:23:34Z",
            "published": "2023-11-19T16:23:34Z",
            "summary": "We introduce a large language model (LLM) based approach to answer complex\nquestions requiring multi-hop numerical reasoning over financial reports. While\nLLMs have exhibited remarkable performance on various natural language and\nreasoning tasks, complex reasoning problems often rely on few-shot prompts that\nrequire carefully crafted examples. In contrast, our approach uses novel\nzero-shot prompts that guide the LLM to encode the required reasoning into a\nPython program or a domain specific language. The generated program is then\nexecuted by a program interpreter, thus mitigating the limitations of LLM in\nperforming accurate arithmetic calculations.\n  We evaluate the proposed approach on three financial datasets using some of\nthe recently developed generative pretrained transformer (GPT) models and\nperform comparisons with various zero-shot baselines. The experimental results\ndemonstrate that our approach significantly improves the accuracy for all the\nLLMs over their respective baselines. We provide a detailed analysis of the\nresults, generating insights to support our findings. The success of our\napproach demonstrates the enormous potential to extract complex domain specific\nnumerical reasoning by designing zero-shot prompts to effectively exploit the\nknowledge embedded in LLMs.",
            "author": [
                "Karmvir Singh Phogat",
                "Chetan Harsha",
                "Sridhar Dasaratha",
                "Shashishekar Ramakrishna",
                "Sai Akhil Puranam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14722v1",
                "http://arxiv.org/pdf/2311.14722v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11364v1",
            "title": "Local environment-based machine learning for molecular adsorption energy\n  prediction",
            "updated": "2023-11-19T16:20:28Z",
            "published": "2023-11-19T16:20:28Z",
            "summary": "Most machine learning (ML) models in Materials Science are developed by\nglobal geometric features, often falling short in describing localized\ncharacteristics, like molecular adsorption on materials. In this study, we\nintroduce a local environment framework that extracts local features from\ncrystal structures to portray the environment surrounding specific adsorption\nsites. Upon OC20 database (~20,000 3D entries), we apply our local environment\nframework on several ML models, such as random forest, convolutional neural\nnetwork, and graph neural network. It is found that our framework achieves\nremarkable prediction accuracy in predicting molecular adsorption energy,\nsignificantly outperforming other examined global-environment-based models.\nMoreover, the employment of this framework reduces data requirements and\naugments computational speed, specifically for deep learning algorithms.\nFinally, we directly apply our Local Environment ResNet (LERN) on a small\n2DMatPedia database (~2,000 2D entries), which also achieves highly accurate\nprediction, demonstrating the model transferability and remarkable data\nefficiency. Overall, the prediction accuracy, data-utilization efficiency, and\ntransferability of our local-environment-based ML framework hold a promising\nhigh applicability across a broad molecular adsorption field, such as catalysis\nand sensor technologies.",
            "author": [
                "Yifan Li",
                "Yihan Wu",
                "Yuhang Han",
                "Qujie Lyu",
                "Hao Wu",
                "Xiuying Zhang",
                "Lei Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11364v1",
                "http://arxiv.org/pdf/2311.11364v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11362v1",
            "title": "Symmetry-invariant quantum machine learning force fields",
            "updated": "2023-11-19T16:15:53Z",
            "published": "2023-11-19T16:15:53Z",
            "summary": "Machine learning techniques are essential tools to compute efficient, yet\naccurate, force fields for atomistic simulations. This approach has recently\nbeen extended to incorporate quantum computational methods, making use of\nvariational quantum learning models to predict potential energy surfaces and\natomic forces from ab initio training data. However, the trainability and\nscalability of such models are still limited, due to both theoretical and\npractical barriers. Inspired by recent developments in geometric classical and\nquantum machine learning, here we design quantum neural networks that\nexplicitly incorporate, as a data-inspired prior, an extensive set of\nphysically relevant symmetries. We find that our invariant quantum learning\nmodels outperform their more generic counterparts on individual molecules of\ngrowing complexity. Furthermore, we study a water dimer as a minimal example of\na system with multiple components, showcasing the versatility of our proposed\napproach and opening the way towards larger simulations. Our results suggest\nthat molecular force fields generation can significantly profit from leveraging\nthe framework of geometric quantum machine learning, and that chemical systems\nrepresent, in fact, an interesting and rich playground for the development and\napplication of advanced quantum machine learning tools.",
            "author": [
                "Isabel Nha Minh Le",
                "Oriel Kiss",
                "Julian Schuhmacher",
                "Ivano Tavernelli",
                "Francesco Tacchino"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11362v1",
                "http://arxiv.org/pdf/2311.11362v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG",
                "physics.chem-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11349v1",
            "title": "Coverage-Validity-Aware Algorithmic Recourse",
            "updated": "2023-11-19T15:21:49Z",
            "published": "2023-11-19T15:21:49Z",
            "summary": "Algorithmic recourse emerges as a prominent technique to promote the\nexplainability, transparency and hence ethics of machine learning models.\nExisting algorithmic recourse approaches often assume an invariant predictive\nmodel; however, the predictive model is usually updated upon the arrival of new\ndata. Thus, a recourse that is valid respective to the present model may become\ninvalid for the future model. To resolve this issue, we propose a novel\nframework to generate a model-agnostic recourse that exhibits robustness to\nmodel shifts. Our framework first builds a coverage-validity-aware linear\nsurrogate of the nonlinear (black-box) model; then, the recourse is generated\nwith respect to the linear surrogate. We establish a theoretical connection\nbetween our coverage-validity-aware linear surrogate and the minimax\nprobability machines (MPM). We then prove that by prescribing different\ncovariance robustness, the proposed framework recovers popular regularizations\nfor MPM, including the $\\ell_2$-regularization and class-reweighting.\nFurthermore, we show that our surrogate pushes the approximate hyperplane\nintuitively, facilitating not only robust but also interpretable recourses. The\nnumerical results demonstrate the usefulness and robustness of our framework.",
            "author": [
                "Ngoc Bui",
                "Duy Nguyen",
                "Man-Chung Yue",
                "Viet Anh Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11349v1",
                "http://arxiv.org/pdf/2311.11349v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11343v1",
            "title": "A Generative Model for Accelerated Inverse Modelling Using a Novel\n  Embedding for Continuous Variables",
            "updated": "2023-11-19T15:03:19Z",
            "published": "2023-11-19T15:03:19Z",
            "summary": "In materials science, the challenge of rapid prototyping materials with\ndesired properties often involves extensive experimentation to find suitable\nmicrostructures. Additionally, finding microstructures for given properties is\ntypically an ill-posed problem where multiple solutions may exist. Using\ngenerative machine learning models can be a viable solution which also reduces\nthe computational cost. This comes with new challenges because, e.g., a\ncontinuous property variable as conditioning input to the model is required. We\ninvestigate the shortcomings of an existing method and compare this to a novel\nembedding strategy for generative models that is based on the binary\nrepresentation of floating point numbers. This eliminates the need for\nnormalization, preserves information, and creates a versatile embedding space\nfor conditioning the generative model. This technique can be applied to\ncondition a network on any number, to provide fine control over generated\nmicrostructure images, thereby contributing to accelerated materials design.",
            "author": [
                "S\u00e9bastien Bompas abd Stefan Sandfeld"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11343v1",
                "http://arxiv.org/pdf/2311.11343v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11342v1",
            "title": "On the Communication Complexity of Decentralized Bilevel Optimization",
            "updated": "2023-11-19T14:56:26Z",
            "published": "2023-11-19T14:56:26Z",
            "summary": "Decentralized bilevel optimization has been actively studied in the past few\nyears since it has widespread applications in machine learning. However,\nexisting algorithms suffer from large communication complexity caused by the\nestimation of stochastic hypergradient, limiting their application to\nreal-world tasks. To address this issue, we develop a novel decentralized\nstochastic bilevel gradient descent algorithm under the heterogeneous setting,\nwhich enjoys a small communication cost in each round and small communication\nrounds. As such, it can achieve a much better communication complexity than\nexisting algorithms. Moreover, we extend our algorithm to the more challenging\ndecentralized multi-level optimization. To the best of our knowledge, this is\nthe first time achieving these theoretical results under the heterogeneous\nsetting. At last, the experimental results confirm the efficacy of our\nalgorithm.",
            "author": [
                "Yihan Zhang",
                "My T. Thai",
                "Jie Wu",
                "Hongchang Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11342v1",
                "http://arxiv.org/pdf/2311.11342v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11340v1",
            "title": "RflyMAD: A Dataset for Multicopter Fault Detection and Health Assessment",
            "updated": "2023-11-19T14:52:45Z",
            "published": "2023-11-19T14:52:45Z",
            "summary": "This paper presents an open-source dataset RflyMAD, a Multicopter Abnomal\nDataset developed by Reliable Flight Control (Rfly) Group aiming to promote the\ndevelopment of research fields like fault detection and isolation (FDI) or\nhealth assessment (HA). The entire 114 GB dataset includes 11 types of faults\nunder 6 flight statuses which are adapted from ADS-33 file to cover more\noccasions in which the multicopters have different mobility levels when faults\noccur. In the total 5629 flight cases, the fault time is up to 3283 minutes,\nand there are 2566 cases for software-in-the-loop (SIL) simulation, 2566 cases\nfor hardware-in-the-loop (HIL) simulation and 497 cases for real flight. As it\ncontains simulation data based on RflySim and real flight data, it is possible\nto improve the quantity while increasing the data quality. In each case, there\nare ULog, Telemetry log, Flight information and processed files for researchers\nto use and check. The RflyMAD dataset could be used as a benchmark for fault\ndiagnosis methods and the support relationship between simulation data and real\nflight is verified through transfer learning methods. More methods as a\nbaseline will be presented in the future, and RflyMAD will be updated with more\ndata and types. In addition, the dataset and related toolkit can be accessed\nthrough https://rfly-openha.github.io/documents/4_resources/dataset.html.",
            "author": [
                "Xiangli Le",
                "Bo Jin",
                "Gen Cui",
                "Xunhua Dai",
                "Quan Quan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11340v1",
                "http://arxiv.org/pdf/2311.11340v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11335v1",
            "title": "Self-Distilled Representation Learning for Time Series",
            "updated": "2023-11-19T14:34:01Z",
            "published": "2023-11-19T14:34:01Z",
            "summary": "Self-supervised learning for time-series data holds potential similar to that\nrecently unleashed in Natural Language Processing and Computer Vision. While\nmost existing works in this area focus on contrastive learning, we propose a\nconceptually simple yet powerful non-contrastive approach, based on the\ndata2vec self-distillation framework. The core of our method is a\nstudent-teacher scheme that predicts the latent representation of an input time\nseries from masked views of the same time series. This strategy avoids strong\nmodality-specific assumptions and biases typically introduced by the design of\ncontrastive sample pairs. We demonstrate the competitiveness of our approach\nfor classification and forecasting as downstream tasks, comparing with\nstate-of-the-art self-supervised learning methods on the UCR and UEA archives\nas well as the ETT and Electricity datasets.",
            "author": [
                "Felix Pieper",
                "Konstantin Ditschuneit",
                "Martin Genzel",
                "Alexandra Lindt",
                "Johannes Otterbach"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11335v1",
                "http://arxiv.org/pdf/2311.11335v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11331v1",
            "title": "Portuguese FAQ for Financial Services",
            "updated": "2023-11-19T14:07:57Z",
            "published": "2023-11-19T14:07:57Z",
            "summary": "Scarcity of domain-specific data in the Portuguese financial domain has\ndisfavored the development of Natural Language Processing (NLP) applications.\nTo address this limitation, the present study advocates for the utilization of\nsynthetic data generated through data augmentation techniques. The\ninvestigation focuses on the augmentation of a dataset sourced from the Central\nBank of Brazil FAQ, employing techniques that vary in semantic similarity.\nSupervised and unsupervised tasks are conducted to evaluate the impact of\naugmented data on both low and high semantic similarity scenarios.\nAdditionally, the resultant dataset will be publicly disseminated on the\nHugging Face Datasets platform, thereby enhancing accessibility and fostering\nbroader engagement within the NLP research community.",
            "author": [
                "Paulo Finardi",
                "Wanderley M. Melo",
                "Edgard D. Medeiros Neto",
                "Alex F. Mansano",
                "Pablo B. Costa",
                "Vinicius F. Carid\u00e1"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11331v1",
                "http://arxiv.org/pdf/2311.11331v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11328v1",
            "title": "LABCAT: Locally adaptive Bayesian optimization using principal\n  component-aligned trust regions",
            "updated": "2023-11-19T13:56:24Z",
            "published": "2023-11-19T13:56:24Z",
            "summary": "Bayesian optimization (BO) is a popular method for optimizing expensive\nblack-box functions. BO has several well-documented shortcomings, including\ncomputational slowdown with longer optimization runs, poor suitability for\nnon-stationary or ill-conditioned objective functions, and poor convergence\ncharacteristics. Several algorithms have been proposed that incorporate local\nstrategies, such as trust regions, into BO to mitigate these limitations;\nhowever, none address all of them satisfactorily. To address these\nshortcomings, we propose the LABCAT algorithm, which extends trust-region-based\nBO by adding principal-component-aligned rotation and an adaptive rescaling\nstrategy based on the length-scales of a local Gaussian process surrogate model\nwith automatic relevance determination. Through extensive numerical experiments\nusing a set of synthetic test functions and the well-known COCO benchmarking\nsoftware, we show that the LABCAT algorithm outperforms several\nstate-of-the-art BO and other black-box optimization algorithms.",
            "author": [
                "E. Visser",
                "C. E. van Daalen",
                "J. C. Schoeman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11328v1",
                "http://arxiv.org/pdf/2311.11328v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11321v1",
            "title": "Bounds on Representation-Induced Confounding Bias for Treatment Effect\n  Estimation",
            "updated": "2023-11-19T13:31:30Z",
            "published": "2023-11-19T13:31:30Z",
            "summary": "State-of-the-art methods for conditional average treatment effect (CATE)\nestimation make widespread use of representation learning. Here, the idea is to\nreduce the variance of the low-sample CATE estimation by a (potentially\nconstrained) low-dimensional representation. However, low-dimensional\nrepresentations can lose information about the observed confounders and thus\nlead to bias, because of which the validity of representation learning for CATE\nestimation is typically violated. In this paper, we propose a new,\nrepresentation-agnostic framework for estimating bounds on the\nrepresentation-induced confounding bias that comes from dimensionality\nreduction (or other constraints on the representations) in CATE estimation.\nFirst, we establish theoretically under which conditions CATEs are\nnon-identifiable given low-dimensional (constrained) representations. Second,\nas our remedy, we propose to perform partial identification of CATEs or,\nequivalently, aim at estimating of lower and upper bounds of the\nrepresentation-induced confounding bias. We demonstrate the effectiveness of\nour bounds in a series of experiments. In sum, our framework is of direct\nrelevance in practice where the validity of CATE estimation is of importance.",
            "author": [
                "Valentyn Melnychuk",
                "Dennis Frauen",
                "Stefan Feuerriegel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11321v1",
                "http://arxiv.org/pdf/2311.11321v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11319v1",
            "title": "GeoSAM: Fine-tuning SAM with Sparse and Dense Visual Prompting for\n  Automated Segmentation of Mobility Infrastructure",
            "updated": "2023-11-19T13:28:01Z",
            "published": "2023-11-19T13:28:01Z",
            "summary": "The Segment Anything Model (SAM) has shown impressive performance when\napplied to natural image segmentation. However, it struggles with geographical\nimages like aerial and satellite imagery, especially when segmenting mobility\ninfrastructure including roads, sidewalks, and crosswalks. This inferior\nperformance stems from the narrow features of these objects, their textures\nblending into the surroundings, and interference from objects like trees,\nbuildings, vehicles, and pedestrians - all of which can disorient the model to\nproduce inaccurate segmentation maps. To address these challenges, we propose\nGeographical SAM (GeoSAM), a novel SAM-based framework that implements a\nfine-tuning strategy using the dense visual prompt from zero-shot learning, and\nthe sparse visual prompt from a pre-trained CNN segmentation model. The\nproposed GeoSAM outperforms existing approaches for geographical image\nsegmentation, specifically by 20%, 14.29%, and 17.65% for road infrastructure,\npedestrian infrastructure, and on average, respectively, representing a\nmomentous leap in leveraging foundation models to segment mobility\ninfrastructure including both road and pedestrian infrastructure in\ngeographical images.",
            "author": [
                "Rafi Ibn Sultan",
                "Chengyin Li",
                "Hui Zhu",
                "Prashant Khanduri",
                "Marco Brocanelli",
                "Dongxiao Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11319v1",
                "http://arxiv.org/pdf/2311.11319v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11315v1",
            "title": "TPTU-v2: Boosting Task Planning and Tool Usage of Large Language\n  Model-based Agents in Real-world Systems",
            "updated": "2023-11-19T12:37:30Z",
            "published": "2023-11-19T12:37:30Z",
            "summary": "Large Language Models (LLMs) have demonstrated proficiency in addressing\ntasks that necessitate a combination of task planning and the usage of external\ntools that require a blend of task planning and the utilization of external\ntools, such as APIs. However, real-world complex systems present three\nprevalent challenges concerning task planning and tool usage: (1) The real\nsystem usually has a vast array of APIs, so it is impossible to feed the\ndescriptions of all APIs to the prompt of LLMs as the token length is limited;\n(2) the real system is designed for handling complex tasks, and the base LLMs\ncan hardly plan a correct sub-task order and API-calling order for such tasks;\n(3) Similar semantics and functionalities among APIs in real systems create\nchallenges for both LLMs and even humans in distinguishing between them. In\nresponse, this paper introduces a comprehensive framework aimed at enhancing\nthe Task Planning and Tool Usage (TPTU) abilities of LLM-based agents operating\nwithin real-world systems. Our framework comprises three key components\ndesigned to address these challenges: (1) the API Retriever selects the most\npertinent APIs for the user task among the extensive array available; (2) LLM\nFinetuner tunes a base LLM so that the finetuned LLM can be more capable for\ntask planning and API calling; (3) the Demo Selector adaptively retrieves\ndifferent demonstrations related to hard-to-distinguish APIs, which is further\nused for in-context learning to boost the final performance. We validate our\nmethods using a real-world commercial system as well as an open-sourced\nacademic dataset, and the outcomes clearly showcase the efficacy of each\nindividual component as well as the integrated framework.",
            "author": [
                "Yilun Kong",
                "Jingqing Ruan",
                "Yihong Chen",
                "Bin Zhang",
                "Tianpeng Bao",
                "Shiwei Shi",
                "Guoqing Du",
                "Xiaoru Hu",
                "Hangyu Mao",
                "Ziyue Li",
                "Xingyu Zeng",
                "Rui Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11315v1",
                "http://arxiv.org/pdf/2311.11315v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11311v1",
            "title": "Actively Learning Numerical Relativity",
            "updated": "2023-11-19T12:25:19Z",
            "published": "2023-11-19T12:25:19Z",
            "summary": "Data analysis of gravitational waves detected by the Ligo-Virgo-Kagra\ncollaboration and future observatories relies on precise modelling of the\nsources. In order to build, calibrate and validate current models, we resort to\nexpensive simulations in Numerical Relativity (NR), the fully-fledged\nsimulation of Einstein's Equations. Since simulation costs and the\ndimensionality of parameter space are prohibitive to perform a dense coverage,\napproximate models interpolate among the available simulation data. We put\nforward the technique of Gaussian Process Active Learning (GPAL), an adaptive,\ndata-driven protocol, for parameter space exploration and training of\ngravitational wave approximants. We evaluate this proposal by studying a\ncomputationally inexpensive scenario, in which we calibrate the approximant\nTEOBResumS using the NR-informed model as a proxy for NR. In this case study,\nwe find that GPAL reduces the computational cost of training by a factor of 4\nwith respect to uniform or randomly distributed simulations. Moreover, we\nconsider a parallel implementation which reduces computational time, and hybrid\nstrategies which improve pre-calibrated models. The Gaussian Process regression\nemployed in this approach naturally endows the algorithm with notion of model\nuncertainty. We comment on the implications of this feature for data analysis.",
            "author": [
                "Tomas Andrade",
                "Rossella Gamba",
                "Juan Trenado"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11311v1",
                "http://arxiv.org/pdf/2311.11311v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "hep-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11306v2",
            "title": "UMAAF: Unveiling Aesthetics via Multifarious Attributes of Images",
            "updated": "2023-11-21T13:59:31Z",
            "published": "2023-11-19T11:57:01Z",
            "summary": "With the increasing prevalence of smartphones and websites, Image Aesthetic\nAssessment (IAA) has become increasingly crucial. While the significance of\nattributes in IAA is widely recognized, many attribute-based methods lack\nconsideration for the selection and utilization of aesthetic attributes. Our\ninitial step involves the acquisition of aesthetic attributes from both intra-\nand inter-perspectives. Within the intra-perspective, we extract the direct\nvisual attributes of images, constituting the absolute attribute. In the\ninter-perspective, our focus lies in modeling the relative score relationships\nbetween images within the same sequence, forming the relative attribute. Then,\nto better utilize image attributes in aesthetic assessment, we propose the\nUnified Multi-attribute Aesthetic Assessment Framework (UMAAF) to model both\nabsolute and relative attributes of images. For absolute attributes, we\nleverage multiple absolute-attribute perception modules and an\nabsolute-attribute interacting network. The absolute-attribute perception\nmodules are first pre-trained on several absolute-attribute learning tasks and\nthen used to extract corresponding absolute attribute features. The\nabsolute-attribute interacting network adaptively learns the weight of diverse\nabsolute-attribute features, effectively integrating them with generic\naesthetic features from various absolute-attribute perspectives and generating\nthe aesthetic prediction. To model the relative attribute of images, we\nconsider the relative ranking and relative distance relationships between\nimages in a Relative-Relation Loss function, which boosts the robustness of the\nUMAAF. Furthermore, UMAAF achieves state-of-the-art performance on TAD66K and\nAVA datasets, and multiple experiments demonstrate the effectiveness of each\nmodule and the model's alignment with human preference.",
            "author": [
                "Weijie Li",
                "Yitian Wan",
                "Xingjiao Wu",
                "Junjie Xu",
                "Cheng Jin",
                "Liang He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11306v2",
                "http://arxiv.org/pdf/2311.11306v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11305v3",
            "title": "Machine-Learning-Based Interatomic Potentials for Group IIB to VIA\n  Semiconductors: A Comparative Study of Universal and Independent Models",
            "updated": "2023-12-05T07:41:30Z",
            "published": "2023-11-19T11:49:43Z",
            "summary": "Rapid advancements in machine-learning methods have led to the emergence of\nmachine-learning-based interatomic potentials as a new cutting-edge tool for\nsimulating large systems with ab initio accuracy. Still, the community awaits\nuniversal inter-atomic models that can be applied to a wide range of materials\nwithout tuning neural network parameters. We develop a universal deep-learning\ninter-atomic potential (the DPA-Semi model) for 19 semiconductors ranging from\ngroup IIB to VIA, including Si, Ge, SiC, BAs, BN, AlN, AlP, AlAs, InP, InAs,\nInSb, GaN, GaP, GaAs, CdTe, InTe, CdSe, ZnS, and CdS. In addition, independent\ndeep potential models for each semiconductor are prepared for detailed\ncomparison. The training data are obtained by performing density functional\ntheory calculations with numerical atomic orbitals basis sets to reduce the\ncomputational costs. We systematically compare various properties of the solid\nand liquid phases of semiconductors between different machine-learning models.\nWe conclude that the DPA-Semi model owns an ab initio accuracy and can be\nregarded as a pre-trained model to study group IIB to VIA semiconductors.",
            "author": [
                "Jianchuan Liu",
                "Xingchen Zhang",
                "Yuzhi Zhang",
                "Duo Zhang",
                "Linfeng Zhang",
                "Mohan Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11305v3",
                "http://arxiv.org/pdf/2311.11305v3"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11303v1",
            "title": "Large Learning Rates Improve Generalization: But How Large Are We\n  Talking About?",
            "updated": "2023-11-19T11:36:35Z",
            "published": "2023-11-19T11:36:35Z",
            "summary": "Inspired by recent research that recommends starting neural networks training\nwith large learning rates (LRs) to achieve the best generalization, we explore\nthis hypothesis in detail. Our study clarifies the initial LR ranges that\nprovide optimal results for subsequent training with a small LR or weight\naveraging. We find that these ranges are in fact significantly narrower than\ngenerally assumed. We conduct our main experiments in a simplified setup that\nallows precise control of the learning rate hyperparameter and validate our key\nfindings in a more practical setting.",
            "author": [
                "Ekaterina Lobacheva",
                "Eduard Pockonechnyy",
                "Maxim Kodryan",
                "Dmitry Vetrov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11303v1",
                "http://arxiv.org/pdf/2311.11303v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11302v1",
            "title": "Exchanging Dual Encoder-Decoder: A New Strategy for Change Detection\n  with Semantic Guidance and Spatial Localization",
            "updated": "2023-11-19T11:30:43Z",
            "published": "2023-11-19T11:30:43Z",
            "summary": "Change detection is a critical task in earth observation applications.\nRecently, deep learning-based methods have shown promising performance and are\nquickly adopted in change detection. However, the widely used multiple encoder\nand single decoder (MESD) as well as dual encoder-decoder (DED) architectures\nstill struggle to effectively handle change detection well. The former has\nproblems of bitemporal feature interference in the feature-level fusion, while\nthe latter is inapplicable to intraclass change detection and multiview\nbuilding change detection. To solve these problems, we propose a new strategy\nwith an exchanging dual encoder-decoder structure for binary change detection\nwith semantic guidance and spatial localization. The proposed strategy solves\nthe problems of bitemporal feature inference in MESD by fusing bitemporal\nfeatures in the decision level and the inapplicability in DED by determining\nchanged areas using bitemporal semantic features. We build a binary change\ndetection model based on this strategy, and then validate and compare it with\n18 state-of-the-art change detection methods on six datasets in three\nscenarios, including intraclass change detection datasets (CDD, SYSU),\nsingle-view building change detection datasets (WHU, LEVIR-CD, LEVIR-CD+) and a\nmultiview building change detection dataset (NJDS). The experimental results\ndemonstrate that our model achieves superior performance with high efficiency\nand outperforms all benchmark methods with F1-scores of 97.77%, 83.07%, 94.86%,\n92.33%, 91.39%, 74.35% on CDD, SYSU, WHU, LEVIR-CD, LEVIR- CD+, and NJDS\ndatasets, respectively. The code of this work will be available at\nhttps://github.com/NJU-LHRS/official-SGSLN.",
            "author": [
                "Sijie Zhao",
                "Xueliang Zhang",
                "Pengfeng Xiao",
                "Guangjun He"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TGRS.2023.3327780",
                "http://arxiv.org/abs/2311.11302v1",
                "http://arxiv.org/pdf/2311.11302v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11298v1",
            "title": "Gradient enhanced multi-fidelity regression with neural networks:\n  application to turbulent flow reconstruction",
            "updated": "2023-11-19T11:18:02Z",
            "published": "2023-11-19T11:18:02Z",
            "summary": "A multi-fidelity regression model is proposed for combining multiple datasets\nwith different fidelities, particularly abundant low-fidelity data and scarce\nhigh-fidelity observations. The model builds upon recent multi-fidelity\nframeworks based on neural networks, which employ two distinct networks for\nlearning low- and high-fidelity data, and extends them by feeding the gradients\ninformation of low-fidelity data into the second network, while the gradients\nare computed using automatic differentiation with minimal computational\noverhead. The accuracy of the proposed framework is demonstrated through a\nvariety of benchmark examples, and it is shown that the proposed model performs\nbetter than conventional multi-fidelity neural network models that do not use\ngradient information. Additionally, the proposed model is applied to the\nchallenging case of turbulent flow reconstruction. In particular, we study the\neffectiveness of the model in reconstructing the instantaneous velocity field\nof the decaying of homogeneous isotropic turbulence given\nlow-resolution/low-fidelity data as well as small amount of\nhigh-resolution/high-fidelity data. The results indicate that the proposed\nmodel is able to reconstruct turbulent field and capture small scale structures\nwith good accuracy, making it suitable for more practical applications.",
            "author": [
                "Mohammad Hossein Saadat"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11298v1",
                "http://arxiv.org/pdf/2311.11298v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11293v1",
            "title": "From Categories to Classifier: Name-Only Continual Learning by Exploring\n  the Web",
            "updated": "2023-11-19T10:43:43Z",
            "published": "2023-11-19T10:43:43Z",
            "summary": "Continual Learning (CL) often relies on the availability of extensive\nannotated datasets, an assumption that is unrealistically time-consuming and\ncostly in practice. We explore a novel paradigm termed name-only continual\nlearning where time and cost constraints prohibit manual annotation. In this\nscenario, learners adapt to new category shifts using only category names\nwithout the luxury of annotated training data. Our proposed solution leverages\nthe expansive and ever-evolving internet to query and download uncurated\nwebly-supervised data for image classification. We investigate the reliability\nof our web data and find them comparable, and in some cases superior, to\nmanually annotated datasets. Additionally, we show that by harnessing the web,\nwe can create support sets that surpass state-of-the-art name-only\nclassification that create support sets using generative models or image\nretrieval from LAION-5B, achieving up to 25% boost in accuracy. When applied\nacross varied continual learning contexts, our method consistently exhibits a\nsmall performance gap in comparison to models trained on manually annotated\ndatasets. We present EvoTrends, a class-incremental dataset made from the web\nto capture real-world trends, created in just minutes. Overall, this paper\nunderscores the potential of using uncurated webly-supervised data to mitigate\nthe challenges associated with manual data labeling in continual learning.",
            "author": [
                "Ameya Prabhu",
                "Hasan Abed Al Kader Hammoud",
                "Ser-Nam Lim",
                "Bernard Ghanem",
                "Philip H. S. Torr",
                "Adel Bibi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11293v1",
                "http://arxiv.org/pdf/2311.11293v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11287v1",
            "title": "Tactile Active Inference Reinforcement Learning for Efficient Robotic\n  Manipulation Skill Acquisition",
            "updated": "2023-11-19T10:19:22Z",
            "published": "2023-11-19T10:19:22Z",
            "summary": "Robotic manipulation holds the potential to replace humans in the execution\nof tedious or dangerous tasks. However, control-based approaches are not\nsuitable due to the difficulty of formally describing open-world manipulation\nin reality, and the inefficiency of existing learning methods. Thus, applying\nmanipulation in a wide range of scenarios presents significant challenges. In\nthis study, we propose a novel method for skill learning in robotic\nmanipulation called Tactile Active Inference Reinforcement Learning\n(Tactile-AIRL), aimed at achieving efficient training. To enhance the\nperformance of reinforcement learning (RL), we introduce active inference,\nwhich integrates model-based techniques and intrinsic curiosity into the RL\nprocess. This integration improves the algorithm's training efficiency and\nadaptability to sparse rewards. Additionally, we utilize a vision-based tactile\nsensor to provide detailed perception for manipulation tasks. Finally, we\nemploy a model-based approach to imagine and plan appropriate actions through\nfree energy minimization. Simulation results demonstrate that our method\nachieves significantly high training efficiency in non-prehensile objects\npushing tasks. It enables agents to excel in both dense and sparse reward tasks\nwith just a few interaction episodes, surpassing the SAC baseline. Furthermore,\nwe conduct physical experiments on a gripper screwing task using our method,\nwhich showcases the algorithm's rapid learning capability and its potential for\npractical applications.",
            "author": [
                "Zihao Liu",
                "Xing Liu",
                "Yizhai Zhang",
                "Zhengxiong Liu",
                "Panfeng Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11287v1",
                "http://arxiv.org/pdf/2311.11287v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11286v1",
            "title": "Classification of Radio Galaxies with trainable COSFIRE filters",
            "updated": "2023-11-19T10:12:09Z",
            "published": "2023-11-19T10:12:09Z",
            "summary": "Radio galaxies exhibit a rich diversity of characteristics and emit radio\nemissions through a variety of radiation mechanisms, making their\nclassification into distinct types based on morphology a complex challenge. To\naddress this challenge effectively, we introduce an innovative approach for\nradio galaxy classification using COSFIRE filters. These filters possess the\nability to adapt to both the shape and orientation of prototype patterns within\nimages. The COSFIRE approach is explainable, learning-free, rotation-tolerant,\nefficient, and does not require a huge training set. To assess the efficacy of\nour method, we conducted experiments on a benchmark radio galaxy data set\ncomprising of 1180 training samples and 404 test samples. Notably, our approach\nachieved an average accuracy rate of 93.36\\%. This achievement outperforms\ncontemporary deep learning models, and it is the best result ever achieved on\nthis data set. Additionally, COSFIRE filters offer better computational\nperformance, $\\sim$20$\\times$ fewer operations than the DenseNet-based\ncompeting method (when comparing at the same accuracy). Our findings underscore\nthe effectiveness of the COSFIRE filter-based approach in addressing the\ncomplexities associated with radio galaxy classification. This research\ncontributes to advancing the field by offering a robust solution that\ntranscends the orientation challenges intrinsic to radio galaxy observations.\nOur method is versatile in that it is applicable to various image\nclassification approaches.",
            "author": [
                "Steven Ndungu",
                "Trienko Grobler",
                "Stefan J. Wijnholds Dimka Karastoyanova",
                "George Azzopardi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11286v1",
                "http://arxiv.org/pdf/2311.11286v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "cs.AI",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11285v1",
            "title": "TimeSQL: Improving Multivariate Time Series Forecasting with Multi-Scale\n  Patching and Smooth Quadratic Loss",
            "updated": "2023-11-19T10:05:50Z",
            "published": "2023-11-19T10:05:50Z",
            "summary": "Time series is a special type of sequence data, a sequence of real-valued\nrandom variables collected at even intervals of time. The real-world\nmultivariate time series comes with noises and contains complicated local and\nglobal temporal dynamics, making it difficult to forecast the future time\nseries given the historical observations. This work proposes a simple and\neffective framework, coined as TimeSQL, which leverages multi-scale patching\nand smooth quadratic loss (SQL) to tackle the above challenges. The multi-scale\npatching transforms the time series into two-dimensional patches with different\nlength scales, facilitating the perception of both locality and long-term\ncorrelations in time series. SQL is derived from the rational quadratic kernel\nand can dynamically adjust the gradients to avoid overfitting to the noises and\noutliers. Theoretical analysis demonstrates that, under mild conditions, the\neffect of the noises on the model with SQL is always smaller than that with\nMSE. Based on the two modules, TimeSQL achieves new state-of-the-art\nperformance on the eight real-world benchmark datasets. Further ablation\nstudies indicate that the key modules in TimeSQL could also enhance the results\nof other models for multivariate time series forecasting, standing as\nplug-and-play techniques.",
            "author": [
                "Site Mo",
                "Haoxin Wang",
                "Bixiong Li",
                "Songhai Fan",
                "Yuankai Wu",
                "Xianggen Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11285v1",
                "http://arxiv.org/pdf/2311.11285v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11282v1",
            "title": "Individual misinformation tagging reinforces echo chambers; Collective\n  tagging does not",
            "updated": "2023-11-19T09:52:44Z",
            "published": "2023-11-19T09:52:44Z",
            "summary": "Fears about the destabilizing impact of misinformation online have motivated\nindividuals and platforms to respond. Individuals have become empowered to\nchallenge others' online claims with fact-checks in pursuit of a healthier\ninformation ecosystem and to break down echo chambers of self-reinforcing\nopinion. Using Twitter data, here we show the consequences of individual\nmisinformation tagging: tagged posters had explored novel political information\nand expanded topical interests immediately prior, but being tagged caused\nposters to retreat into information bubbles. These unintended consequences were\nsoftened by a collective verification system for misinformation moderation. In\nTwitter's new platform, Community Notes, misinformation tagging was\npeer-reviewed by other fact-checkers before the exposure. With collective\nmisinformation tagging, posters were less likely to retreat from diverse\ninformation consumption. Detailed comparison suggests differences in toxicity,\nsentiment, readability, and delay in individual versus collective\nmisinformation tagging messages. These findings provide evidence for\ndifferential impacts from individual versus collective moderation strategies on\nthe diversity of information consumption and mobility across the information\necosystem.",
            "author": [
                "Junsol Kim",
                "Zhao Wang",
                "Haohan Shi",
                "Hsin-Keng Ling",
                "James Evans"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11282v1",
                "http://arxiv.org/pdf/2311.11282v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.HC",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11281v1",
            "title": "Multi-Timescale Control and Communications with Deep Reinforcement\n  Learning -- Part I: Communication-Aware Vehicle Control",
            "updated": "2023-11-19T09:51:58Z",
            "published": "2023-11-19T09:51:58Z",
            "summary": "An intelligent decision-making system enabled by Vehicle-to-Everything (V2X)\ncommunications is essential to achieve safe and efficient autonomous driving\n(AD), where two types of decisions have to be made at different timescales,\ni.e., vehicle control and radio resource allocation (RRA) decisions. The\ninterplay between RRA and vehicle control necessitates their collaborative\ndesign. In this two-part paper (Part I and Part II), taking platoon control\n(PC) as an example use case, we propose a joint optimization framework of\nmulti-timescale control and communications (MTCC) based on Deep Reinforcement\nLearning (DRL). In this paper (Part I), we first decompose the problem into a\ncommunication-aware DRL-based PC sub-problem and a control-aware DRL-based RRA\nsub-problem. Then, we focus on the PC sub-problem assuming an RRA policy is\ngiven, and propose the MTCC-PC algorithm to learn an efficient PC policy. To\nimprove the PC performance under random observation delay, the PC state space\nis augmented with the observation delay and PC action history. Moreover, the\nreward function with respect to the augmented state is defined to construct an\naugmented state Markov Decision Process (MDP). It is proved that the optimal\npolicy for the augmented state MDP is optimal for the original PC problem with\nobservation delay. Different from most existing works on communication-aware\ncontrol, the MTCC-PC algorithm is trained in a delayed environment generated by\nthe fine-grained embedded simulation of C-V2X communications rather than by a\nsimple stochastic delay model. Finally, experiments are performed to compare\nthe performance of MTCC-PC with those of the baseline DRL algorithms.",
            "author": [
                "Tong Liu",
                "Lei Lei",
                "Kan Zheng",
                "Xuemin",
                "Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11281v1",
                "http://arxiv.org/pdf/2311.11281v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11280v1",
            "title": "Multi-Timescale Control and Communications with Deep Reinforcement\n  Learning -- Part II: Control-Aware Radio Resource Allocation",
            "updated": "2023-11-19T09:50:21Z",
            "published": "2023-11-19T09:50:21Z",
            "summary": "In Part I of this two-part paper (Multi-Timescale Control and Communications\nwith Deep Reinforcement Learning -- Part I: Communication-Aware Vehicle\nControl), we decomposed the multi-timescale control and communications (MTCC)\nproblem in Cellular Vehicle-to-Everything (C-V2X) system into a\ncommunication-aware Deep Reinforcement Learning (DRL)-based platoon control\n(PC) sub-problem and a control-aware DRL-based radio resource allocation (RRA)\nsub-problem. We focused on the PC sub-problem and proposed the MTCC-PC\nalgorithm to learn an optimal PC policy given an RRA policy. In this paper\n(Part II), we first focus on the RRA sub-problem in MTCC assuming a PC policy\nis given, and propose the MTCC-RRA algorithm to learn the RRA policy.\nSpecifically, we incorporate the PC advantage function in the RRA reward\nfunction, which quantifies the amount of PC performance degradation caused by\nobservation delay. Moreover, we augment the state space of RRA with PC action\nhistory for a more well-informed RRA policy. In addition, we utilize reward\nshaping and reward backpropagation prioritized experience replay (RBPER)\ntechniques to efficiently tackle the multi-agent and sparse reward problems,\nrespectively. Finally, a sample- and computational-efficient training approach\nis proposed to jointly learn the PC and RRA policies in an iterative process.\nIn order to verify the effectiveness of the proposed MTCC algorithm, we\nperformed experiments using real driving data for the leading vehicle, where\nthe performance of MTCC is compared with those of the baseline DRL algorithms.",
            "author": [
                "Lei Lei",
                "Tong Liu",
                "Kan Zheng",
                "Xuemin",
                "Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11280v1",
                "http://arxiv.org/pdf/2311.11280v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11278v1",
            "title": "Transcending Forgery Specificity with Latent Space Augmentation for\n  Generalizable Deepfake Detection",
            "updated": "2023-11-19T09:41:10Z",
            "published": "2023-11-19T09:41:10Z",
            "summary": "Deepfake detection faces a critical generalization hurdle, with performance\ndeteriorating when there is a mismatch between the distributions of training\nand testing data. A broadly received explanation is the tendency of these\ndetectors to be overfitted to forgery-specific artifacts, rather than learning\nfeatures that are widely applicable across various forgeries. To address this\nissue, we propose a simple yet effective detector called LSDA\n(\\underline{L}atent \\underline{S}pace \\underline{D}ata\n\\underline{A}ugmentation), which is based on a heuristic idea: representations\nwith a wider variety of forgeries should be able to learn a more generalizable\ndecision boundary, thereby mitigating the overfitting of method-specific\nfeatures (see Figure. 1). Following this idea, we propose to enlarge the\nforgery space by constructing and simulating variations within and across\nforgery features in the latent space. This approach encompasses the acquisition\nof enriched, domain-specific features and the facilitation of smoother\ntransitions between different forgery types, effectively bridging domain gaps.\nOur approach culminates in refining a binary classifier that leverages the\ndistilled knowledge from the enhanced features, striving for a generalizable\ndeepfake detector. Comprehensive experiments show that our proposed method is\nsurprisingly effective and transcends state-of-the-art detectors across several\nwidely used benchmarks.",
            "author": [
                "Zhiyuan Yan",
                "Yuhao Luo",
                "Siwei Lyu",
                "Qingshan Liu",
                "Baoyuan Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11278v1",
                "http://arxiv.org/pdf/2311.11278v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11269v1",
            "title": "OperARtistry: An AR-based Interactive Application to Assist the Learning\n  of Chinese Traditional Opera (Xiqu) Makeup",
            "updated": "2023-11-19T08:47:20Z",
            "published": "2023-11-19T08:47:20Z",
            "summary": "Chinese Traditional Opera (Xiqu) is an important type of intangible cultural\nheritage and one key characteristic of Xiqu is its visual effects on face\nachieved via makeup. However, Xiqu makeup process, especially the eye-area\nmakeup process, is complex and time-consuming, which poses a learning challenge\nfor potential younger inheritors. We introduce OperARtistry, an interactive\napplication based on Augmented Reality (AR) that offers in-situ Xiqu makeup\nguidance for beginners. Our application provides a step-by-step guide for Xiqu\neye-area makeup, incorporating AR effects at each stage. Furthermore, we\nconducted an initial user study (n=6) to compare our approach with existing\nvideo-based tutorials to assess the effectiveness and usefulness of our\napproach. Our findings show that OperARtisty helped participants achieve\nhigh-quality eye-area makeup effects with less learning time.",
            "author": [
                "Zeyu Xiong",
                "Shihan Fu",
                "Mingming Fan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11269v1",
                "http://arxiv.org/pdf/2311.11269v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11262v1",
            "title": "Uncertainty quantification for noisy inputs-outputs in physics-informed\n  neural networks and neural operators",
            "updated": "2023-11-19T08:18:26Z",
            "published": "2023-11-19T08:18:26Z",
            "summary": "Uncertainty quantification (UQ) in scientific machine learning (SciML)\nbecomes increasingly critical as neural networks (NNs) are being widely adopted\nin addressing complex problems across various scientific disciplines.\nRepresentative SciML models are physics-informed neural networks (PINNs) and\nneural operators (NOs). While UQ in SciML has been increasingly investigated in\nrecent years, very few works have focused on addressing the uncertainty caused\nby the noisy inputs, such as spatial-temporal coordinates in PINNs and input\nfunctions in NOs. The presence of noise in the inputs of the models can pose\nsignificantly more challenges compared to noise in the outputs of the models,\nprimarily due to the inherent nonlinearity of most SciML algorithms. As a\nresult, UQ for noisy inputs becomes a crucial factor for reliable and\ntrustworthy deployment of these models in applications involving physical\nknowledge. To this end, we introduce a Bayesian approach to quantify\nuncertainty arising from noisy inputs-outputs in PINNs and NOs. We show that\nthis approach can be seamlessly integrated into PINNs and NOs, when they are\nemployed to encode the physical information. PINNs incorporate physics by\nincluding physics-informed terms via automatic differentiation, either in the\nloss function or the likelihood, and often take as input the spatial-temporal\ncoordinate. Therefore, the present method equips PINNs with the capability to\naddress problems where the observed coordinate is subject to noise. On the\nother hand, pretrained NOs are also commonly employed as equation-free\nsurrogates in solving differential equations and Bayesian inverse problems, in\nwhich they take functions as inputs. The proposed approach enables them to\nhandle noisy measurements for both input and output functions with UQ.",
            "author": [
                "Zongren Zou",
                "Xuhui Meng",
                "George Em Karniadakis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11262v1",
                "http://arxiv.org/pdf/2311.11262v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11261v1",
            "title": "Adversarial Prompt Tuning for Vision-Language Models",
            "updated": "2023-11-19T07:47:43Z",
            "published": "2023-11-19T07:47:43Z",
            "summary": "With the rapid advancement of multimodal learning, pre-trained\nVision-Language Models (VLMs) such as CLIP have demonstrated remarkable\ncapacities in bridging the gap between visual and language modalities. However,\nthese models remain vulnerable to adversarial attacks, particularly in the\nimage modality, presenting considerable security risks. This paper introduces\nAdversarial Prompt Tuning (AdvPT), a novel technique to enhance the adversarial\nrobustness of image encoders in VLMs. AdvPT innovatively leverages learnable\ntext prompts and aligns them with adversarial image embeddings, to address the\nvulnerabilities inherent in VLMs without the need for extensive parameter\ntraining or modification of the model architecture. We demonstrate that AdvPT\nimproves resistance against white-box and black-box adversarial attacks and\nexhibits a synergistic effect when combined with existing\nimage-processing-based defense techniques, further boosting defensive\ncapabilities. Comprehensive experimental analyses provide insights into\nadversarial prompt tuning, a novel paradigm devoted to improving resistance to\nadversarial images through textual input modifications, paving the way for\nfuture robust multimodal learning research. These findings open up new\npossibilities for enhancing the security of VLMs. Our code will be available\nupon publication of the paper.",
            "author": [
                "Jiaming Zhang",
                "Xingjun Ma",
                "Xin Wang",
                "Lingyu Qiu",
                "Jiaqi Wang",
                "Yu-Gang Jiang",
                "Jitao Sang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11261v1",
                "http://arxiv.org/pdf/2311.11261v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11258v1",
            "title": "Tensor networks for interpretable and efficient quantum-inspired machine\n  learning",
            "updated": "2023-11-19T07:37:38Z",
            "published": "2023-11-19T07:37:38Z",
            "summary": "It is a critical challenge to simultaneously gain high interpretability and\nefficiency with the current schemes of deep machine learning (ML). Tensor\nnetwork (TN), which is a well-established mathematical tool originating from\nquantum mechanics, has shown its unique advantages on developing efficient\n``white-box'' ML schemes. Here, we give a brief review on the inspiring\nprogresses made in TN-based ML. On one hand, interpretability of TN ML is\naccommodated with the solid theoretical foundation based on quantum information\nand many-body physics. On the other hand, high efficiency can be rendered from\nthe powerful TN representations and the advanced computational techniques\ndeveloped in quantum many-body physics. With the fast development on quantum\ncomputers, TN is expected to conceive novel schemes runnable on quantum\nhardware, heading towards the ``quantum artificial intelligence'' in the\nforthcoming future.",
            "author": [
                "Shi-Ju Ran",
                "Gang Su"
            ],
            "link": [
                "http://dx.doi.org/10.34133/icomputing.0061",
                "http://arxiv.org/abs/2311.11258v1",
                "http://arxiv.org/pdf/2311.11258v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11254v3",
            "title": "BOIS: Bayesian Optimization of Interconnected Systems",
            "updated": "2023-11-29T02:32:02Z",
            "published": "2023-11-19T06:44:13Z",
            "summary": "Bayesian optimization (BO) has proven to be an effective paradigm for the\nglobal optimization of expensive-to-sample systems. One of the main advantages\nof BO is its use of Gaussian processes (GPs) to characterize model uncertainty\nwhich can be leveraged to guide the learning and search process. However, BO\ntypically treats systems as black-boxes and this limits the ability to exploit\nstructural knowledge (e.g., physics and sparse interconnections). Composite\nfunctions of the form $f(x, y(x))$, wherein GP modeling is shifted from the\nperformance function $f$ to an intermediate function $y$, offer an avenue for\nexploiting structural knowledge. However, the use of composite functions in a\nBO framework is complicated by the need to generate a probability density for\n$f$ from the Gaussian density of $y$ calculated by the GP (e.g., when $f$ is\nnonlinear it is not possible to obtain a closed-form expression). Previous work\nhas handled this issue using sampling techniques; these are easy to implement\nand flexible but are computationally intensive. In this work, we introduce a\nnew paradigm which allows for the efficient use of composite functions in BO;\nthis uses adaptive linearizations of $f$ to obtain closed-form expressions for\nthe statistical moments of the composite function. We show that this simple\napproach (which we call BOIS) enables the exploitation of structural knowledge,\nsuch as that arising in interconnected systems as well as systems that embed\nmultiple GP models and combinations of physics and GP models. Using a chemical\nprocess optimization case study, we benchmark the effectiveness of BOIS against\nstandard BO and sampling approaches. Our results indicate that BOIS achieves\nperformance gains and accurately captures the statistics of composite\nfunctions.",
            "author": [
                "Leonardo D. Gonz\u00e1lez",
                "Victor M. Zavala"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11254v3",
                "http://arxiv.org/pdf/2311.11254v3"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11252v1",
            "title": "Submeter-level Land Cover Mapping of Japan",
            "updated": "2023-11-19T06:34:50Z",
            "published": "2023-11-19T06:34:50Z",
            "summary": "Deep learning has shown promising performance in submeter-level mapping\ntasks; however, the annotation cost of submeter-level imagery remains a\nchallenge, especially when applied on a large scale. In this paper, we present\nthe first submeter-level land cover mapping of Japan with eight classes, at a\nrelatively low annotation cost. We introduce a human-in-the-loop deep learning\nframework leveraging OpenEarthMap, a recently introduced benchmark dataset for\nglobal submeter-level land cover mapping, with a U-Net model that achieves\nnational-scale mapping with a small amount of additional labeled data. By\nadding a small amount of labeled data of areas or regions where a U-Net model\ntrained on OpenEarthMap clearly failed and retraining the model, an overall\naccuracy of 80\\% was achieved, which is a nearly 16 percentage point\nimprovement after retraining. Using aerial imagery provided by the Geospatial\nInformation Authority of Japan, we create land cover classification maps of\neight classes for the entire country of Japan. Our framework, with its low\nannotation cost and high-accuracy mapping results, demonstrates the potential\nto contribute to the automatic updating of national-scale land cover mapping\nusing submeter-level optical remote sensing data. The mapping results will be\nmade publicly available.",
            "author": [
                "Naoto Yokoya",
                "Junshi Xia",
                "Clifford Broni-Bediako"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11252v1",
                "http://arxiv.org/pdf/2311.11252v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11250v1",
            "title": "A Comprehensive Review on Sentiment Analysis: Tasks, Approaches and\n  Applications",
            "updated": "2023-11-19T06:29:41Z",
            "published": "2023-11-19T06:29:41Z",
            "summary": "Sentiment analysis (SA) is an emerging field in text mining. It is the\nprocess of computationally identifying and categorizing opinions expressed in a\npiece of text over different social media platforms. Social media plays an\nessential role in knowing the customer mindset towards a product, services, and\nthe latest market trends. Most organizations depend on the customer's response\nand feedback to upgrade their offered products and services. SA or opinion\nmining seems to be a promising research area for various domains. It plays a\nvital role in analyzing big data generated daily in structured and unstructured\nformats over the internet. This survey paper defines sentiment and its recent\nresearch and development in different domains, including voice, images, videos,\nand text. The challenges and opportunities of sentiment analysis are also\ndiscussed in the paper.\n  \\keywords{Sentiment Analysis, Machine Learning, Lexicon-based approach, Deep\nLearning, Natural Language Processing}",
            "author": [
                "Sudhanshu Kumar",
                "Partha Pratim Roy",
                "Debi Prosad Dogra",
                "Byung-Gyu Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11250v1",
                "http://arxiv.org/pdf/2311.11250v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11249v1",
            "title": "Open Set Dandelion Network for IoT Intrusion Detection",
            "updated": "2023-11-19T06:28:43Z",
            "published": "2023-11-19T06:28:43Z",
            "summary": "As IoT devices become widely, it is crucial to protect them from malicious\nintrusions. However, the data scarcity of IoT limits the applicability of\ntraditional intrusion detection methods, which are highly data-dependent. To\naddress this, in this paper we propose the Open-Set Dandelion Network (OSDN)\nbased on unsupervised heterogeneous domain adaptation in an open-set manner.\nThe OSDN model performs intrusion knowledge transfer from the knowledge-rich\nsource network intrusion domain to facilitate more accurate intrusion detection\nfor the data-scarce target IoT intrusion domain. Under the open-set setting, it\ncan also detect newly-emerged target domain intrusions that are not observed in\nthe source domain. To achieve this, the OSDN model forms the source domain into\na dandelion-like feature space in which each intrusion category is compactly\ngrouped and different intrusion categories are separated, i.e., simultaneously\nemphasising inter-category separability and intra-category compactness. The\ndandelion-based target membership mechanism then forms the target dandelion.\nThen, the dandelion angular separation mechanism achieves better inter-category\nseparability, and the dandelion embedding alignment mechanism further aligns\nboth dandelions in a finer manner. To promote intra-category compactness, the\ndiscriminating sampled dandelion mechanism is used. Assisted by the intrusion\nclassifier trained using both known and generated unknown intrusion knowledge,\na semantic dandelion correction mechanism emphasises easily-confused categories\nand guides better inter-category separability. Holistically, these mechanisms\nform the OSDN model that effectively performs intrusion knowledge transfer to\nbenefit IoT intrusion detection. Comprehensive experiments on several intrusion\ndatasets verify the effectiveness of the OSDN model, outperforming three\nstate-of-the-art baseline methods by 16.9%.",
            "author": [
                "Jiashu Wu",
                "Hao Dai",
                "Kenneth B. Kent",
                "Jerome Yen",
                "Chengzhong Xu",
                "Yang Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11249v1",
                "http://arxiv.org/pdf/2311.11249v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11238v1",
            "title": "AtomXR: Streamlined XR Prototyping with Natural Language and Immersive\n  Physical Interaction",
            "updated": "2023-11-19T05:52:25Z",
            "published": "2023-11-19T05:52:25Z",
            "summary": "As technological advancements in extended reality (XR) amplify the demand for\nmore XR content, traditional development processes face several challenges: 1)\na steep learning curve for inexperienced developers, 2) a disconnect between 2D\ndevelopment environments and 3D user experiences inside headsets, and 3) slow\niteration cycles due to context switching between development and testing\nenvironments. To address these challenges, we introduce AtomXR, a streamlined,\nimmersive, no-code XR prototyping tool designed to empower both experienced and\ninexperienced developers in creating applications using natural language,\neye-gaze, and touch interactions. AtomXR consists of: 1) AtomScript, a\nhigh-level human-interpretable scripting language for rapid prototyping, 2) a\nnatural language interface that integrates LLMs and multimodal inputs for\nAtomScript generation, and 3) an immersive in-headset authoring environment.\nEmpirical evaluation through two user studies offers insights into natural\nlanguage-based and immersive prototyping, and shows AtomXR provides significant\nimprovements in speed and user experience compared to traditional systems.",
            "author": [
                "Alice Cai",
                "Caine Ardayfio",
                "AnhPhu Nguyen",
                "Tica Lin",
                "Elena Glassman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11238v1",
                "http://arxiv.org/pdf/2311.11238v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI",
                "H.5.2; I.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11237v1",
            "title": "Implementation of AI Deep Learning Algorithm For Multi-Modal Sentiment\n  Analysis",
            "updated": "2023-11-19T05:49:39Z",
            "published": "2023-11-19T05:49:39Z",
            "summary": "A multi-modal emotion recognition method was established by combining\ntwo-channel convolutional neural network with ring network. This method can\nextract emotional information effectively and improve learning efficiency. The\nwords were vectorized with GloVe, and the word vector was input into the\nconvolutional neural network. Combining attention mechanism and maximum pool\nconverter BiSRU channel, the local deep emotion and pre-post sequential emotion\nsemantics are obtained. Finally, multiple features are fused and input as the\npolarity of emotion, so as to achieve the emotion analysis of the target.\nExperiments show that the emotion analysis method based on feature fusion can\neffectively improve the recognition accuracy of emotion data set and reduce the\nlearning time. The model has a certain generalization.",
            "author": [
                "Jiazhen Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11237v1",
                "http://arxiv.org/pdf/2311.11237v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11235v2",
            "title": "Unraveling the \"Anomaly\" in Time Series Anomaly Detection: A\n  Self-supervised Tri-domain Solution",
            "updated": "2023-11-27T01:15:06Z",
            "published": "2023-11-19T05:37:18Z",
            "summary": "The ongoing challenges in time series anomaly detection (TSAD), notably the\nscarcity of anomaly labels and the variability in anomaly lengths and shapes,\nhave led to the need for a more efficient solution. As limited anomaly labels\nhinder traditional supervised models in TSAD, various SOTA deep learning\ntechniques, such as self-supervised learning, have been introduced to tackle\nthis issue. However, they encounter difficulties handling variations in anomaly\nlengths and shapes, limiting their adaptability to diverse anomalies.\nAdditionally, many benchmark datasets suffer from the problem of having\nexplicit anomalies that even random functions can detect. This problem is\nexacerbated by ill-posed evaluation metrics, known as point adjustment (PA),\nwhich can result in inflated model performance. In this context, we propose a\nnovel self-supervised learning based Tri-domain Anomaly Detector (TriAD), which\naddresses these challenges by modeling features across three data domains -\ntemporal, frequency, and residual domains - without relying on anomaly labels.\nUnlike traditional contrastive learning methods, TriAD employs both\ninter-domain and intra-domain contrastive loss to learn common attributes among\nnormal data and differentiate them from anomalies. Additionally, our approach\ncan detect anomalies of varying lengths by integrating with a discord discovery\nalgorithm. It is worth noting that this study is the first to reevaluate the\ndeep learning potential in TSAD, utilizing both rigorously designed datasets\n(i.e., UCR Archive) and evaluation metrics (i.e., PA%K and affiliation).\nThrough experimental results on the UCR dataset, TriAD achieves an impressive\nthree-fold increase in PA%K based F1 scores over SOTA deep learning models, and\n50% increase of accuracy as compared to SOTA discord discovery algorithms.",
            "author": [
                "Yuting Sun",
                "Guansong Pang",
                "Guanhua Ye",
                "Tong Chen",
                "Xia Hu",
                "Hongzhi Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11235v2",
                "http://arxiv.org/pdf/2311.11235v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11228v1",
            "title": "A Universal Framework for Accurate and Efficient Geometric Deep Learning\n  of Molecular Systems",
            "updated": "2023-11-19T04:52:05Z",
            "published": "2023-11-19T04:52:05Z",
            "summary": "Molecular sciences address a wide range of problems involving molecules of\ndifferent types and sizes and their complexes. Recently, geometric deep\nlearning, especially Graph Neural Networks, has shown promising performance in\nmolecular science applications. However, most existing works often impose\ntargeted inductive biases to a specific molecular system, and are inefficient\nwhen applied to macromolecules or large-scale tasks, thereby limiting their\napplications to many real-world problems. To address these challenges, we\npresent PAMNet, a universal framework for accurately and efficiently learning\nthe representations of three-dimensional (3D) molecules of varying sizes and\ntypes in any molecular system. Inspired by molecular mechanics, PAMNet induces\na physics-informed bias to explicitly model local and non-local interactions\nand their combined effects. As a result, PAMNet can reduce expensive\noperations, making it time and memory efficient. In extensive benchmark\nstudies, PAMNet outperforms state-of-the-art baselines regarding both accuracy\nand efficiency in three diverse learning tasks: small molecule properties, RNA\n3D structures, and protein-ligand binding affinities. Our results highlight the\npotential for PAMNet in a broad range of molecular science applications.",
            "author": [
                "Shuo Zhang",
                "Yang Liu",
                "Lei Xie"
            ],
            "link": [
                "http://dx.doi.org/10.1038/s41598-023-46382-8",
                "http://arxiv.org/abs/2311.11228v1",
                "http://arxiv.org/pdf/2311.11228v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11227v1",
            "title": "FedRA: A Random Allocation Strategy for Federated Tuning to Unleash the\n  Power of Heterogeneous Clients",
            "updated": "2023-11-19T04:43:16Z",
            "published": "2023-11-19T04:43:16Z",
            "summary": "With the increasing availability of Foundation Models, federated tuning has\ngarnered attention in the field of federated learning, utilizing data and\ncomputation resources from multiple clients to collaboratively fine-tune\nfoundation models. However, in real-world federated scenarios, there often\nexist a multitude of heterogeneous clients with varying computation and\ncommunication resources, rendering them incapable of supporting the entire\nmodel fine-tuning process. In response to this challenge, we propose a novel\nfederated tuning algorithm, FedRA. The implementation of FedRA is\nstraightforward and can be seamlessly integrated into any transformer-based\nmodel without the need for further modification to the original model.\nSpecifically, in each communication round, FedRA randomly generates an\nallocation matrix. For resource-constrained clients, it reorganizes a small\nnumber of layers from the original model based on the allocation matrix and\nfine-tunes using LoRA. Subsequently, the server aggregates the updated LoRA\nparameters from the clients according to the current allocation matrix into the\ncorresponding layers of the original model. It is worth noting that FedRA also\nsupports scenarios where none of the clients can support the entire global\nmodel, which is an impressive advantage. We conduct experiments on two\nlarge-scale image datasets, DomainNet and NICO++, under various non-iid\nsettings. The results demonstrate that FedRA outperforms the compared methods\nsignificantly. The source code is available at\n\\url{https://github.com/leondada/FedRA}.",
            "author": [
                "Shangchao Su",
                "Bin Li",
                "Xiangyang Xue"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11227v1",
                "http://arxiv.org/pdf/2311.11227v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11225v2",
            "title": "TextGuard: Provable Defense against Backdoor Attacks on Text\n  Classification",
            "updated": "2023-11-25T02:59:46Z",
            "published": "2023-11-19T04:42:16Z",
            "summary": "Backdoor attacks have become a major security threat for deploying machine\nlearning models in security-critical applications. Existing research endeavors\nhave proposed many defenses against backdoor attacks. Despite demonstrating\ncertain empirical defense efficacy, none of these techniques could provide a\nformal and provable security guarantee against arbitrary attacks. As a result,\nthey can be easily broken by strong adaptive attacks, as shown in our\nevaluation. In this work, we propose TextGuard, the first provable defense\nagainst backdoor attacks on text classification. In particular, TextGuard first\ndivides the (backdoored) training data into sub-training sets, achieved by\nsplitting each training sentence into sub-sentences. This partitioning ensures\nthat a majority of the sub-training sets do not contain the backdoor trigger.\nSubsequently, a base classifier is trained from each sub-training set, and\ntheir ensemble provides the final prediction. We theoretically prove that when\nthe length of the backdoor trigger falls within a certain threshold, TextGuard\nguarantees that its prediction will remain unaffected by the presence of the\ntriggers in training and testing inputs. In our evaluation, we demonstrate the\neffectiveness of TextGuard on three benchmark text classification tasks,\nsurpassing the certification accuracy of existing certified defenses against\nbackdoor attacks. Furthermore, we propose additional strategies to enhance the\nempirical performance of TextGuard. Comparisons with state-of-the-art empirical\ndefenses validate the superiority of TextGuard in countering multiple backdoor\nattacks. Our code and data are available at\nhttps://github.com/AI-secure/TextGuard.",
            "author": [
                "Hengzhi Pei",
                "Jinyuan Jia",
                "Wenbo Guo",
                "Bo Li",
                "Dawn Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11225v2",
                "http://arxiv.org/pdf/2311.11225v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11224v2",
            "title": "ChatGPT at the Speed of Light: Optical Comb-Based Monolithic\n  Photonic-Electronic Linear-Algebra Accelerators",
            "updated": "2023-11-21T09:01:10Z",
            "published": "2023-11-19T04:38:56Z",
            "summary": "This paper proposes to adopt advanced monolithic silicon-photonics\nintegrated-circuits manufacturing capabilities to achieve a system-on-chip\nphotonic-electronic linear-algebra accelerator with the features of optical\ncomb-based broadband incoherent photo-detections and high-dimensional\noperations of consecutive matrix-matrix multiplications to enable substantial\nleaps in computation density and energy efficiency, with practical\nconsiderations of power/area overhead due to photonic-electronic on-chip\nconversions, integrations, and calibrations through holistic co-design\napproaches to support attention-head mechanism based deep-learning neural\nnetworks used in Large Language Models and other emergent applications.",
            "author": [
                "Tzu-Chien Hsueh",
                "Yeshaiahu Fainman",
                "Bill Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11224v2",
                "http://arxiv.org/pdf/2311.11224v2"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.ET",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11216v2",
            "title": "Valid Randomization Tests in Inexactly Matched Observational Studies via\n  Iterative Convex Programming",
            "updated": "2023-11-28T18:54:37Z",
            "published": "2023-11-19T03:53:03Z",
            "summary": "In causal inference, matching is one of the most widely used methods to mimic\na randomized experiment using observational (non-experimental) data. Ideally,\ntreated units are exactly matched with control units for the covariates so that\nthe treatments are as-if randomly assigned within each matched set, and valid\nrandomization tests for treatment effects can then be conducted as in a\nrandomized experiment. However, inexact matching typically exists, especially\nwhen there are continuous or many observed covariates or when unobserved\ncovariates exist. Previous matched observational studies routinely conducted\ndownstream randomization tests as if matching was exact, as long as the matched\ndatasets satisfied some prespecified balance criteria or passed some balance\ntests. Some recent studies showed that this routine practice could render a\nhighly inflated type-I error rate of randomization tests, especially when the\nsample size is large. To handle this problem, we propose an iterative convex\nprogramming framework for randomization tests with inexactly matched datasets.\nUnder some commonly used regularity conditions, we show that our approach can\nproduce valid randomization tests (i.e., robustly controlling the type-I error\nrate) for any inexactly matched datasets, even when unobserved covariates\nexist. Our framework allows the incorporation of flexible machine learning\nmodels to better extract information from covariate imbalance while robustly\ncontrolling the type-I error rate.",
            "author": [
                "Siyu Heng",
                "Yanxin Shen",
                "Pengyun Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11216v2",
                "http://arxiv.org/pdf/2311.11216v2"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11215v1",
            "title": "SPLAIN: Augmenting Cybersecurity Warnings with Reasons and Data",
            "updated": "2023-11-19T03:43:42Z",
            "published": "2023-11-19T03:43:42Z",
            "summary": "Effective cyber threat recognition and prevention demand comprehensible\nforecasting systems, as prior approaches commonly offer limited and,\nultimately, unconvincing information. We introduce Simplified Plaintext\nLanguage (SPLAIN), a natural language generator that converts warning data into\nuser-friendly cyber threat explanations. SPLAIN is designed to generate clear,\nactionable outputs, incorporating hierarchically organized explanatory details\nabout input data and system functionality. Given the inputs of individual\nsensor-induced forecasting signals and an overall warning from a fusion module,\nSPLAIN queries each signal for information on contributing sensors and data\nsignals. This collected data is processed into a coherent English explanation,\nencompassing forecasting, sensing, and data elements for user review. SPLAIN's\ntemplate-based approach ensures consistent warning structure and vocabulary.\nSPLAIN's hierarchical output structure allows each threat and its components to\nbe expanded to reveal underlying explanations on demand. Our conclusions\nemphasize the need for designers to specify the \"how\" and \"why\" behind cyber\nwarnings, advocate for simple structured templates in generating consistent\nexplanations, and recognize that direct causal links in Machine Learning\napproaches may not always be identifiable, requiring some explanations to focus\non general methodologies, such as model and training data.",
            "author": [
                "Vera A. Kazakova",
                "Jena D. Hwang",
                "Bonnie J. Dorr",
                "Yorick Wilks",
                "J. Blake Gage",
                "Alex Memory",
                "Mark A. Clark"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11215v1",
                "http://arxiv.org/pdf/2311.11215v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11212v1",
            "title": "Can We Utilize Pre-trained Language Models within Causal Discovery\n  Algorithms?",
            "updated": "2023-11-19T03:31:30Z",
            "published": "2023-11-19T03:31:30Z",
            "summary": "Scaling laws have allowed Pre-trained Language Models (PLMs) into the field\nof causal reasoning. Causal reasoning of PLM relies solely on text-based\ndescriptions, in contrast to causal discovery which aims to determine the\ncausal relationships between variables utilizing data. Recently, there has been\ncurrent research regarding a method that mimics causal discovery by aggregating\nthe outcomes of repetitive causal reasoning, achieved through specifically\ndesigned prompts. It highlights the usefulness of PLMs in discovering cause and\neffect, which is often limited by a lack of data, especially when dealing with\nmultiple variables. Conversely, the characteristics of PLMs which are that PLMs\ndo not analyze data and they are highly dependent on prompt design leads to a\ncrucial limitation for directly using PLMs in causal discovery. Accordingly,\nPLM-based causal reasoning deeply depends on the prompt design and carries out\nthe risk of overconfidence and false predictions in determining causal\nrelationships. In this paper, we empirically demonstrate the aforementioned\nlimitations of PLM-based causal reasoning through experiments on\nphysics-inspired synthetic data. Then, we propose a new framework that\nintegrates prior knowledge obtained from PLM with a causal discovery algorithm.\nThis is accomplished by initializing an adjacency matrix for causal discovery\nand incorporating regularization using prior knowledge. Our proposed framework\nnot only demonstrates improved performance through the integration of PLM and\ncausal discovery but also suggests how to leverage PLM-extracted prior\nknowledge with existing causal discovery algorithms.",
            "author": [
                "Chanhui Lee",
                "Juhyeon Kim",
                "Yongjun Jeong",
                "Juhyun Lyu",
                "Junghee Kim",
                "Sangmin Lee",
                "Sangjun Han",
                "Hyeokjun Choe",
                "Soyeon Park",
                "Woohyung Lim",
                "Sungbin Lim",
                "Sanghack Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11212v1",
                "http://arxiv.org/pdf/2311.11212v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "I.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11210v1",
            "title": "HiH: A Multi-modal Hierarchy in Hierarchy Network for Unconstrained Gait\n  Recognition",
            "updated": "2023-11-19T03:25:14Z",
            "published": "2023-11-19T03:25:14Z",
            "summary": "Gait recognition has achieved promising advances in controlled settings, yet\nit significantly struggles in unconstrained environments due to challenges such\nas view changes, occlusions, and varying walking speeds. Additionally, efforts\nto fuse multiple modalities often face limited improvements because of\ncross-modality incompatibility, particularly in outdoor scenarios. To address\nthese issues, we present a multi-modal Hierarchy in Hierarchy network (HiH)\nthat integrates silhouette and pose sequences for robust gait recognition. HiH\nfeatures a main branch that utilizes Hierarchical Gait Decomposer (HGD) modules\nfor depth-wise and intra-module hierarchical examination of general gait\npatterns from silhouette data. This approach captures motion hierarchies from\noverall body dynamics to detailed limb movements, facilitating the\nrepresentation of gait attributes across multiple spatial resolutions.\nComplementing this, an auxiliary branch, based on 2D joint sequences, enriches\nthe spatial and temporal aspects of gait analysis. It employs a Deformable\nSpatial Enhancement (DSE) module for pose-guided spatial attention and a\nDeformable Temporal Alignment (DTA) module for aligning motion dynamics through\nlearned temporal offsets. Extensive evaluations across diverse indoor and\noutdoor datasets demonstrate HiH's state-of-the-art performance, affirming a\nwell-balanced trade-off between accuracy and efficiency.",
            "author": [
                "Lei Wang",
                "Yinchi Ma",
                "Peng Luan",
                "Wei Yao",
                "Congcong Li",
                "Bo Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11210v1",
                "http://arxiv.org/pdf/2311.11210v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11209v1",
            "title": "3D Guidewire Shape Reconstruction from Monoplane Fluoroscopic Images",
            "updated": "2023-11-19T03:20:42Z",
            "published": "2023-11-19T03:20:42Z",
            "summary": "Endovascular navigation, essential for diagnosing and treating endovascular\ndiseases, predominantly hinges on fluoroscopic images due to the constraints in\nsensory feedback. Current shape reconstruction techniques for endovascular\nintervention often rely on either a priori information or specialized\nequipment, potentially subjecting patients to heightened radiation exposure.\nWhile deep learning holds potential, it typically demands extensive data. In\nthis paper, we propose a new method to reconstruct the 3D guidewire by\nutilizing CathSim, a state-of-the-art endovascular simulator, and a 3D\nFluoroscopy Guidewire Reconstruction Network (3D-FGRN). Our 3D-FGRN delivers\nresults on par with conventional triangulation from simulated monoplane\nfluoroscopic images. Our experiments accentuate the efficiency of the proposed\nnetwork, demonstrating it as a promising alternative to traditional methods.",
            "author": [
                "Tudor Jianu",
                "Baoru Huang",
                "Pierre Berthet-Rayne",
                "Sebastiano Fichera",
                "Anh Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11209v1",
                "http://arxiv.org/pdf/2311.11209v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11208v1",
            "title": "LogicNet: A Logical Consistency Embedded Face Attribute Learning Network",
            "updated": "2023-11-19T03:20:20Z",
            "published": "2023-11-19T03:20:20Z",
            "summary": "Ensuring logical consistency in predictions is a crucial yet overlooked\naspect in multi-attribute classification. We explore the potential reasons for\nthis oversight and introduce two pressing challenges to the field: 1) How can\nwe ensure that a model, when trained with data checked for logical consistency,\nyields predictions that are logically consistent? 2) How can we achieve the\nsame with data that hasn't undergone logical consistency checks? Minimizing\nmanual effort is also essential for enhancing automation. To address these\nchallenges, we introduce two datasets, FH41K and CelebA-logic, and propose\nLogicNet, an adversarial training framework that learns the logical\nrelationships between attributes. Accuracy of LogicNet surpasses that of the\nnext-best approach by 23.05%, 9.96%, and 1.71% on FH37K, FH41K, and\nCelebA-logic, respectively. In real-world case analysis, our approach can\nachieve a reduction of more than 50% in the average number of failed cases\ncompared to other methods.",
            "author": [
                "Haiyu Wu",
                "Sicong Tian",
                "Huayu Li",
                "Kevin W. Bowyer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11208v1",
                "http://arxiv.org/pdf/2311.11208v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11206v1",
            "title": "Robust Network Slicing: Multi-Agent Policies, Adversarial Attacks, and\n  Defensive Strategies",
            "updated": "2023-11-19T03:07:29Z",
            "published": "2023-11-19T03:07:29Z",
            "summary": "In this paper, we present a multi-agent deep reinforcement learning (deep RL)\nframework for network slicing in a dynamic environment with multiple base\nstations and multiple users. In particular, we propose a novel deep RL\nframework with multiple actors and centralized critic (MACC) in which actors\nare implemented as pointer networks to fit the varying dimension of input. We\nevaluate the performance of the proposed deep RL algorithm via simulations to\ndemonstrate its effectiveness. Subsequently, we develop a deep RL based jammer\nwith limited prior information and limited power budget. The goal of the jammer\nis to minimize the transmission rates achieved with network slicing and thus\ndegrade the network slicing agents' performance. We design a jammer with both\nlistening and jamming phases and address jamming location optimization as well\nas jamming channel optimization via deep RL. We evaluate the jammer at the\noptimized location, generating interference attacks in the optimized set of\nchannels by switching between the jamming phase and listening phase. We show\nthat the proposed jammer can significantly reduce the victims' performance\nwithout direct feedback or prior knowledge on the network slicing policies.\nFinally, we devise a Nash-equilibrium-supervised policy ensemble mixed strategy\nprofile for network slicing (as a defensive measure) and jamming. We evaluate\nthe performance of the proposed policy ensemble algorithm by applying on the\nnetwork slicing agents and the jammer agent in simulations to show its\neffectiveness.",
            "author": [
                "Feng Wang",
                "M. Cenk Gursoy",
                "Senem Velipasalar"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TMLCN.2023.3334236",
                "http://arxiv.org/abs/2311.11206v1",
                "http://arxiv.org/pdf/2311.11206v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11204v1",
            "title": "Collectively Simplifying Trajectories in a Database: A Query Accuracy\n  Driven Approach",
            "updated": "2023-11-19T03:04:30Z",
            "published": "2023-11-19T03:04:30Z",
            "summary": "Increasing and massive volumes of trajectory data are being accumulated that\nmay serve a variety of applications, such as mining popular routes or\nidentifying ridesharing candidates. As storing and querying massive trajectory\ndata is costly, trajectory simplification techniques have been introduced that\nintuitively aim to reduce the sizes of trajectories, thus reducing storage and\nspeeding up querying, while preserving as much information as possible.\nExisting techniques rely mainly on hand-crafted error measures when deciding\nwhich point to drop when simplifying a trajectory. While the hope may be that\nsuch simplification affects the subsequent usability of the data only\nminimally, the usability of the simplified data remains largely unexplored.\nInstead of using error measures that indirectly may to some extent yield\nsimplified trajectories with high usability, we adopt a direct approach to\nsimplification and present the first study of query accuracy driven trajectory\nsimplification, where the direct objective is to achieve a simplified\ntrajectory database that preserves the query accuracy of the original database\nas much as possible. Specifically, we propose a multi-agent reinforcement\nlearning based solution with two agents working cooperatively to collectively\nsimplify trajectories in a database while optimizing query usability. Extensive\nexperiments on four real-world trajectory datasets show that the solution is\ncapable of consistently outperforming baseline solutions over various query\ntypes and dynamics.",
            "author": [
                "Zheng Wang",
                "Cheng Long",
                "Gao Cong",
                "Christian S. Jensen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11204v1",
                "http://arxiv.org/pdf/2311.11204v1"
            ],
            "primary_category": "cs.DB",
            "category": [
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11202v1",
            "title": "Unmasking and Improving Data Credibility: A Study with Datasets for\n  Training Harmless Language Models",
            "updated": "2023-11-19T02:34:12Z",
            "published": "2023-11-19T02:34:12Z",
            "summary": "Language models have shown promise in various tasks but can be affected by\nundesired data during training, fine-tuning, or alignment. For example, if some\nunsafe conversations are wrongly annotated as safe ones, the model fine-tuned\non these samples may be harmful. Therefore, the correctness of annotations,\ni.e., the credibility of the dataset, is important. This study focuses on the\ncredibility of real-world datasets, including the popular benchmarks Jigsaw\nCivil Comments, Anthropic Harmless & Red Team, PKU BeaverTails & SafeRLHF, that\ncan be used for training a harmless language model. Given the cost and\ndifficulty of cleaning these datasets by humans, we introduce a systematic\nframework for evaluating the credibility of datasets, identifying label errors,\nand evaluating the influence of noisy labels in the curated language data,\nspecifically focusing on unsafe comments and conversation classification. With\nthe framework, we find and fix an average of 6.16% label errors in 11 datasets\nconstructed from the above benchmarks. The data credibility and downstream\nlearning performance can be remarkably improved by directly fixing label\nerrors, indicating the significance of cleaning existing real-world datasets.\nOpen-source: https://github.com/Docta-ai/docta.",
            "author": [
                "Zhaowei Zhu",
                "Jialu Wang",
                "Hao Cheng",
                "Yang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11202v1",
                "http://arxiv.org/pdf/2311.11202v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11200v1",
            "title": "Scale-free networks: improved inference",
            "updated": "2023-11-19T02:26:16Z",
            "published": "2023-11-19T02:26:16Z",
            "summary": "The power-law distribution plays a crucial role in complex networks as well\nas various applied sciences. Investigating whether the degree distribution of a\nnetwork follows a power-law distribution is an important concern. The commonly\nused inferential methods for estimating the model parameters often yield biased\nestimates, which can lead to the rejection of the hypothesis that a model\nconforms to a power-law. In this paper, we discuss improved methods that\nutilize Bayesian inference to obtain accurate estimates and precise credibility\nintervals. The inferential methods are derived for both continuous and discrete\ndistributions. These methods reveal that objective Bayesian approaches return\nnearly unbiased estimates for the parameters of both models. Notably, in the\ncontinuous case, we identify an explicit posterior distribution. This work\nenhances the power of goodness-of-fit tests, enabling us to accurately discern\nwhether a network or any other dataset adheres to a power-law distribution. We\napply the proposed approach to fit degree distributions for more than 5,000\nsynthetic networks and over 3,000 real networks. The results indicate that our\nmethod is more suitable in practice, as it yields a frequency of acceptance\nclose to the specified nominal level.",
            "author": [
                "Nixon Jerez-Lillo",
                "Francisco A. Rodrigues",
                "Pedro L. Ramos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11200v1",
                "http://arxiv.org/pdf/2311.11200v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph",
                "cond-mat.stat-mech",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11198v1",
            "title": "Self-Supervised Versus Supervised Training for Segmentation of Organoid\n  Images",
            "updated": "2023-11-19T01:57:55Z",
            "published": "2023-11-19T01:57:55Z",
            "summary": "The process of annotating relevant data in the field of digital microscopy\ncan be both time-consuming and especially expensive due to the required\ntechnical skills and human-expert knowledge. Consequently, large amounts of\nmicroscopic image data sets remain unlabeled, preventing their effective\nexploitation using deep-learning algorithms. In recent years it has been shown\nthat a lot of relevant information can be drawn from unlabeled data.\nSelf-supervised learning (SSL) is a promising solution based on learning\nintrinsic features under a pretext task that is similar to the main task\nwithout requiring labels. The trained result is transferred to the main task -\nimage segmentation in our case. A ResNet50 U-Net was first trained to restore\nimages of liver progenitor organoids from augmented images using the Structural\nSimilarity Index Metric (SSIM), alone, and using SSIM combined with L1 loss.\nBoth the encoder and decoder were trained in tandem. The weights were\ntransferred to another U-Net model designed for segmentation with frozen\nencoder weights, using Binary Cross Entropy, Dice, and Intersection over Union\n(IoU) losses. For comparison, we used the same U-Net architecture to train two\nsupervised models, one utilizing the ResNet50 encoder as well as a simple CNN.\nResults showed that self-supervised learning models using a 25\\% pixel drop or\nimage blurring augmentation performed better than the other augmentation\ntechniques using the IoU loss. When trained on only 114 images for the main\ntask, the self-supervised learning approach outperforms the supervised method\nachieving an F1-score of 0.85, with higher stability, in contrast to an F1=0.78\nscored by the supervised method. Furthermore, when trained with larger data\nsets (1,000 images), self-supervised learning is still able to perform better,\nachieving an F1-score of 0.92, contrasting to a score of 0.85 for the\nsupervised method.",
            "author": [
                "Asmaa Haja",
                "Eric Brouwer",
                "Lambert Schomaker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11198v1",
                "http://arxiv.org/pdf/2311.11198v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11194v1",
            "title": "Testing with Non-identically Distributed Samples",
            "updated": "2023-11-19T01:25:50Z",
            "published": "2023-11-19T01:25:50Z",
            "summary": "We examine the extent to which sublinear-sample property testing and\nestimation applies to settings where samples are independently but not\nidentically distributed. Specifically, we consider the following distributional\nproperty testing framework: Suppose there is a set of distributions over a\ndiscrete support of size $k$, $\\textbf{p}_1, \\textbf{p}_2,\\ldots,\\textbf{p}_T$,\nand we obtain $c$ independent draws from each distribution. Suppose the goal is\nto learn or test a property of the average distribution,\n$\\textbf{p}_{\\mathrm{avg}}$. This setup models a number of important practical\nsettings where the individual distributions correspond to heterogeneous\nentities -- either individuals, chronologically distinct time periods,\nspatially separated data sources, etc. From a learning standpoint, even with\n$c=1$ samples from each distribution, $\\Theta(k/\\varepsilon^2)$ samples are\nnecessary and sufficient to learn $\\textbf{p}_{\\mathrm{avg}}$ to within error\n$\\varepsilon$ in TV distance. To test uniformity or identity -- distinguishing\nthe case that $\\textbf{p}_{\\mathrm{avg}}$ is equal to some reference\ndistribution, versus has $\\ell_1$ distance at least $\\varepsilon$ from the\nreference distribution, we show that a linear number of samples in $k$ is\nnecessary given $c=1$ samples from each distribution. In contrast, for $c \\ge\n2$, we recover the usual sublinear sample testing of the i.i.d. setting: we\nshow that $O(\\sqrt{k}/\\varepsilon^2 + 1/\\varepsilon^4)$ samples are sufficient,\nmatching the optimal sample complexity in the i.i.d. case in the regime where\n$\\varepsilon \\ge k^{-1/4}$. Additionally, we show that in the $c=2$ case, there\nis a constant $\\rho > 0$ such that even in the linear regime with $\\rho k$\nsamples, no tester that considers the multiset of samples (ignoring which\nsamples were drawn from the same $\\textbf{p}_i$) can perform uniformity\ntesting.",
            "author": [
                "Shivam Garg",
                "Chirag Pabbaraju",
                "Kirankumar Shiragur",
                "Gregory Valiant"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11194v1",
                "http://arxiv.org/pdf/2311.11194v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.IT",
                "cs.LG",
                "math.IT",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12065v1",
            "title": "Few-Shot Classification & Segmentation Using Large Language Models Agent",
            "updated": "2023-11-19T00:33:41Z",
            "published": "2023-11-19T00:33:41Z",
            "summary": "The task of few-shot image classification and segmentation (FS-CS) requires\nthe classification and segmentation of target objects in a query image, given\nonly a few examples of the target classes. We introduce a method that utilises\nlarge language models (LLM) as an agent to address the FS-CS problem in a\ntraining-free manner. By making the LLM the task planner and off-the-shelf\nvision models the tools, the proposed method is capable of classifying and\nsegmenting target objects using only image-level labels. Specifically,\nchain-of-thought prompting and in-context learning guide the LLM to observe\nsupport images like human; vision models such as Segment Anything Model (SAM)\nand GPT-4Vision assist LLM understand spatial and semantic information at the\nsame time. Ultimately, the LLM uses its summarizing and reasoning capabilities\nto classify and segment the query image. The proposed method's modular\nframework makes it easily extendable. Our approach achieves state-of-the-art\nperformance on the Pascal-5i dataset.",
            "author": [
                "Tian Meng",
                "Yang Tao",
                "Wuliang Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12065v1",
                "http://arxiv.org/pdf/2311.12065v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11188v1",
            "title": "Generalized quantum Arimoto-Blahut algorithm and its application to\n  quantum information bottleneck",
            "updated": "2023-11-19T00:06:11Z",
            "published": "2023-11-19T00:06:11Z",
            "summary": "We generalize the quantum Arimoto-Blahut algorithm by Ramakrishnan et al.\n(IEEE Trans. IT, 67, 946 (2021)) to a function defined over a set of density\nmatrices with linear constraints. This algorithm has wider applicability.\nHence, we apply our algorithm to the quantum information bottleneck with three\nquantum systems, which can be used for quantum learning. We numerically compare\nour obtained algorithm with the existing algorithm by Grimsmo and Still (Phys.\nRev. A, 94, 012338 (2016)). Our numerical analysis shows that our algorithm is\nbetter than their algorithm.",
            "author": [
                "Masahito Hayashi",
                "Geng Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11188v1",
                "http://arxiv.org/pdf/2311.11188v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11185v1",
            "title": "Dueling Optimization with a Monotone Adversary",
            "updated": "2023-11-18T23:55:59Z",
            "published": "2023-11-18T23:55:59Z",
            "summary": "We introduce and study the problem of dueling optimization with a monotone\nadversary, which is a generalization of (noiseless) dueling convex\noptimization. The goal is to design an online algorithm to find a minimizer\n$\\mathbf{x}^{*}$ for a function $f\\colon X \\to \\mathbb{R}$, where $X \\subseteq\n\\mathbb{R}^d$. In each round, the algorithm submits a pair of guesses, i.e.,\n$\\mathbf{x}^{(1)}$ and $\\mathbf{x}^{(2)}$, and the adversary responds with any\npoint in the space that is at least as good as both guesses. The cost of each\nquery is the suboptimality of the worse of the two guesses; i.e., ${\\max}\n\\left( f(\\mathbf{x}^{(1)}), f(\\mathbf{x}^{(2)}) \\right) - f(\\mathbf{x}^{*})$.\nThe goal is to minimize the number of iterations required to find an\n$\\varepsilon$-optimal point and to minimize the total cost (regret) of the\nguesses over many rounds. Our main result is an efficient randomized algorithm\nfor several natural choices of the function $f$ and set $X$ that incurs cost\n$O(d)$ and iteration complexity $O(d\\log(1/\\varepsilon)^2)$. Moreover, our\ndependence on $d$ is asymptotically optimal, as we show examples in which any\nrandomized algorithm for this problem must incur $\\Omega(d)$ cost and iteration\ncomplexity.",
            "author": [
                "Avrim Blum",
                "Meghal Gupta",
                "Gene Li",
                "Naren Sarayu Manoj",
                "Aadirupa Saha",
                "Yuanyuan Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11185v1",
                "http://arxiv.org/pdf/2311.11185v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11184v1",
            "title": "Diverse Shape Completion via Style Modulated Generative Adversarial\n  Networks",
            "updated": "2023-11-18T23:40:20Z",
            "published": "2023-11-18T23:40:20Z",
            "summary": "Shape completion aims to recover the full 3D geometry of an object from a\npartial observation. This problem is inherently multi-modal since there can be\nmany ways to plausibly complete the missing regions of a shape. Such diversity\nwould be indicative of the underlying uncertainty of the shape and could be\npreferable for downstream tasks such as planning. In this paper, we propose a\nnovel conditional generative adversarial network that can produce many diverse\nplausible completions of a partially observed point cloud. To enable our\nnetwork to produce multiple completions for the same partial input, we\nintroduce stochasticity into our network via style modulation. By extracting\nstyle codes from complete shapes during training, and learning a distribution\nover them, our style codes can explicitly carry shape category information\nleading to better completions. We further introduce diversity penalties and\ndiscriminators at multiple scales to prevent conditional mode collapse and to\ntrain without the need for multiple ground truth completions for each partial\ninput. Evaluations across several synthetic and real datasets demonstrate that\nour method achieves significant improvements in respecting the partial\nobservations while obtaining greater diversity in completions.",
            "author": [
                "Wesley Khademi",
                "Li Fuxin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11184v1",
                "http://arxiv.org/pdf/2311.11184v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11182v1",
            "title": "Exponentially Convergent Algorithms for Supervised Matrix Factorization",
            "updated": "2023-11-18T23:24:02Z",
            "published": "2023-11-18T23:24:02Z",
            "summary": "Supervised matrix factorization (SMF) is a classical machine learning method\nthat simultaneously seeks feature extraction and classification tasks, which\nare not necessarily a priori aligned objectives. Our goal is to use SMF to\nlearn low-rank latent factors that offer interpretable, data-reconstructive,\nand class-discriminative features, addressing challenges posed by\nhigh-dimensional data. Training SMF model involves solving a nonconvex and\npossibly constrained optimization with at least three blocks of parameters.\nKnown algorithms are either heuristic or provide weak convergence guarantees\nfor special cases. In this paper, we provide a novel framework that 'lifts' SMF\nas a low-rank matrix estimation problem in a combined factor space and propose\nan efficient algorithm that provably converges exponentially fast to a global\nminimizer of the objective with arbitrary initialization under mild\nassumptions. Our framework applies to a wide range of SMF-type problems for\nmulti-class classification with auxiliary features. To showcase an application,\nwe demonstrate that our algorithm successfully identified well-known\ncancer-associated gene groups for various cancers.",
            "author": [
                "Joowon Lee",
                "Hanbaek Lyu",
                "Weixin Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11182v1",
                "http://arxiv.org/pdf/2311.11182v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11180v1",
            "title": "Nonsmooth Projection-Free Optimization with Functional Constraints",
            "updated": "2023-11-18T23:06:33Z",
            "published": "2023-11-18T23:06:33Z",
            "summary": "This paper presents a subgradient-based algorithm for constrained nonsmooth\nconvex optimization that does not require projections onto the feasible set.\nWhile the well-established Frank-Wolfe algorithm and its variants already avoid\nprojections, they are primarily designed for smooth objective functions. In\ncontrast, our proposed algorithm can handle nonsmooth problems with general\nconvex functional inequality constraints. It achieves an $\\epsilon$-suboptimal\nsolution in $\\mathcal{O}(\\epsilon^{-2})$ iterations, with each iteration\nrequiring only a single (potentially inexact) Linear Minimization Oracle (LMO)\ncall and a (possibly inexact) subgradient computation. This performance is\nconsistent with existing lower bounds. Similar performance is observed when\ndeterministic subgradients are replaced with stochastic subgradients. In the\nspecial case where there are no functional inequality constraints, our\nalgorithm competes favorably with a recent nonsmooth projection-free method\ndesigned for constraint-free problems. Our approach utilizes a simple\nseparation scheme in conjunction with a new Lagrange multiplier update rule.",
            "author": [
                "Kamiar Asgari",
                "Michael J. Neely"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11180v1",
                "http://arxiv.org/pdf/2311.11180v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "cs.SY",
                "eess.SY",
                "65K05, 65K10, 65K99, 90C25, 90C15, 90C25, 90C30"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11178v2",
            "title": "Active Prompt Learning in Vision Language Models",
            "updated": "2023-11-27T00:58:21Z",
            "published": "2023-11-18T22:42:16Z",
            "summary": "Pre-trained Vision Language Models (VLMs) have demonstrated notable progress\nin various zero-shot tasks, such as classification and retrieval. Despite their\nperformance, because improving performance on new tasks requires task-specific\nknowledge, their adaptation is essential. While labels are needed for the\nadaptation, acquiring them is typically expensive. To overcome this challenge,\nactive learning, a method of achieving a high performance by obtaining labels\nfor a small number of samples from experts, has been studied. Active learning\nprimarily focuses on selecting unlabeled samples for labeling and leveraging\nthem to train models. In this study, we pose the question, \"how can the\npre-trained VLMs be adapted under the active learning framework?\" In response\nto this inquiry, we observe that (1) simply applying a conventional active\nlearning framework to pre-trained VLMs even may degrade performance compared to\nrandom selection because of the class imbalance in labeling candidates, and (2)\nthe knowledge of VLMs can provide hints for achieving the balance before\nlabeling. Based on these observations, we devise a novel active learning\nframework for VLMs, denoted as PCB. To assess the effectiveness of our\napproach, we conduct experiments on seven different real-world datasets, and\nthe results demonstrate that PCB surpasses conventional active learning and\nrandom sampling methods.",
            "author": [
                "Jihwan Bang",
                "Sumyeong Ahn",
                "Jae-Gil Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11178v2",
                "http://arxiv.org/pdf/2311.11178v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11176v1",
            "title": "Morphology-Enhanced CAM-Guided SAM for weakly supervised Breast Lesion\n  Segmentation",
            "updated": "2023-11-18T22:06:04Z",
            "published": "2023-11-18T22:06:04Z",
            "summary": "Breast cancer diagnosis challenges both patients and clinicians, with early\ndetection being crucial for effective treatment. Ultrasound imaging plays a key\nrole in this, but its utility is hampered by the need for precise lesion\nsegmentation-a task that is both time-consuming and labor-intensive. To address\nthese challenges, we propose a new framework: a morphology-enhanced, Class\nActivation Map (CAM)-guided model, which is optimized using a computer vision\nfoundation model known as SAM. This innovative framework is specifically\ndesigned for weakly supervised lesion segmentation in early-stage breast\nultrasound images. Our approach uniquely leverages image-level annotations,\nwhich removes the requirement for detailed pixel-level annotation. Initially,\nwe perform a preliminary segmentation using breast lesion morphology knowledge.\nFollowing this, we accurately localize lesions by extracting semantic\ninformation through a CAM-based heatmap. These two elements are then fused\ntogether, serving as a prompt to guide the SAM in performing refined\nsegmentation. Subsequently, post-processing techniques are employed to rectify\ntopological errors made by the SAM. Our method not only simplifies the\nsegmentation process but also attains accuracy comparable to supervised\nlearning methods that rely on pixel-level annotation. Our framework achieves a\nDice score of 74.39% on the test set, demonstrating compareable performance\nwith supervised learning methods. Additionally, it outperforms a supervised\nlearning model, in terms of the Hausdorff distance, scoring 24.27 compared to\nDeeplabv3+'s 32.22. These experimental results showcase its feasibility and\nsuperior performance in integrating weakly supervised learning with SAM. The\ncode is made available at: https://github.com/YueXin18/MorSeg-CAM-SAM.",
            "author": [
                "Xin Yue",
                "Qing Zhao",
                "Jianqiang Li",
                "Xiaoling Liu",
                "Changwei Song",
                "Suqin Liu",
                "Guanghui Fu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11176v1",
                "http://arxiv.org/pdf/2311.11176v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11172v1",
            "title": "Low-Precision Floating-Point for Efficient On-Board Deep Neural Network\n  Processing",
            "updated": "2023-11-18T21:36:52Z",
            "published": "2023-11-18T21:36:52Z",
            "summary": "One of the major bottlenecks in high-resolution Earth Observation (EO) space\nsystems is the downlink between the satellite and the ground. Due to hardware\nlimitations, on-board power limitations or ground-station operation costs,\nthere is a strong need to reduce the amount of data transmitted. Various\nprocessing methods can be used to compress the data. One of them is the use of\non-board deep learning to extract relevant information in the data. However,\nmost ground-based deep neural network parameters and computations are performed\nusing single-precision floating-point arithmetic, which is not adapted to the\ncontext of on-board processing. We propose to rely on quantized neural networks\nand study how to combine low precision (mini) floating-point arithmetic with a\nQuantization-Aware Training methodology. We evaluate our approach with a\nsemantic segmentation task for ship detection using satellite images from the\nAirbus Ship dataset. Our results show that 6-bit floating-point quantization\nfor both weights and activations can compete with single-precision without\nsignificant accuracy degradation. Using a Thin U-Net 32 model, only a 0.3%\naccuracy degradation is observed with 6-bit minifloat quantization (a 6-bit\nequivalent integer-based approach leads to a 0.5% degradation). An initial\nhardware study also confirms the potential impact of such low-precision\nfloating-point designs, but further investigation at the scale of a full\ninference accelerator is needed before concluding whether they are relevant in\na practical on-board scenario.",
            "author": [
                "C\u00e9dric Gernigon",
                "Silviu-Ioan Filip",
                "Olivier Sentieys",
                "Cl\u00e9ment Coggiola",
                "Micka\u00ebl Bruno"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11172v1",
                "http://arxiv.org/pdf/2311.11172v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11169v1",
            "title": "Deep Coherence Learning: An Unsupervised Deep Beamformer for High\n  Quality Single Plane Wave Imaging in Medical Ultrasound",
            "updated": "2023-11-18T21:08:27Z",
            "published": "2023-11-18T21:08:27Z",
            "summary": "Plane wave imaging (PWI) in medical ultrasound is becoming an important\nreconstruction method with high frame rates and new clinical applications.\nRecently, single PWI based on deep learning (DL) has been studied to overcome\nlowered frame rates of traditional PWI with multiple PW transmissions. However,\ndue to the lack of appropriate ground truth images, DL-based PWI still remains\nchallenging for performance improvements. To address this issue, in this paper,\nwe propose a new unsupervised learning approach, i.e., deep coherence learning\n(DCL)-based DL beamformer (DL-DCL), for high-quality single PWI. In DL-DCL, the\nDL network is trained to predict highly correlated signals with a unique loss\nfunction from a set of PW data, and the trained DL model encourages\nhigh-quality PWI from low-quality single PW data. In addition, the DL-DCL\nframework based on complex baseband signals enables a universal beamformer. To\nassess the performance of DL-DCL, simulation, phantom and in vivo studies were\nconducted with public datasets, and it was compared with traditional\nbeamformers (i.e., DAS with 75-PWs and DMAS with 1-PW) and other DL-based\nmethods (i.e., supervised learning approach with 1-PW and generative\nadversarial network (GAN) with 1-PW). From the experiments, the proposed DL-DCL\nshowed comparable results with DMAS with 1-PW and DAS with 75-PWs in spatial\nresolution, and it outperformed all comparison methods in contrast resolution.\nThese results demonstrated that the proposed unsupervised learning approach can\naddress the inherent limitations of traditional PWIs based on DL, and it also\nshowed great potential in clinical settings with minimal artifacts.",
            "author": [
                "Hyunwoo Cho",
                "Seongjun Park",
                "Jinbum Kang",
                "Yangmo Yoo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11169v1",
                "http://arxiv.org/pdf/2311.11169v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11167v1",
            "title": "Benchmarking Machine Learning Models for Quantum Error Correction",
            "updated": "2023-11-18T21:01:38Z",
            "published": "2023-11-18T21:01:38Z",
            "summary": "Quantum Error Correction (QEC) is one of the fundamental problems in quantum\ncomputer systems, which aims to detect and correct errors in the data qubits\nwithin quantum computers. Due to the presence of unreliable data qubits in\nexisting quantum computers, implementing quantum error correction is a critical\nstep when establishing a stable quantum computer system. Recently, machine\nlearning (ML)-based approaches have been proposed to address this challenge.\nHowever, they lack a thorough understanding of quantum error correction. To\nbridge this research gap, we provide a new perspective to understand machine\nlearning-based QEC in this paper. We find that syndromes in the ancilla qubits\nresult from errors on connected data qubits, and distant ancilla qubits can\nprovide auxiliary information to rule out some incorrect predictions for the\ndata qubits. Therefore, to detect errors in data qubits, we must consider the\ninformation present in the long-range ancilla qubits. To the best of our\nknowledge, machine learning is less explored in the dependency relationship of\nQEC. To fill the blank, we curate a machine learning benchmark to assess the\ncapacity to capture long-range dependencies for quantum error correction. To\nprovide a comprehensive evaluation, we evaluate seven state-of-the-art deep\nlearning algorithms spanning diverse neural network architectures, such as\nconvolutional neural networks, graph neural networks, and graph transformers.\nOur exhaustive experiments reveal an enlightening trend: By enlarging the\nreceptive field to exploit information from distant ancilla qubits, the\naccuracy of QEC significantly improves. For instance, U-Net can improve CNN by\na margin of about 50%. Finally, we provide a comprehensive analysis that could\ninspire future research in this field. We will release the code when the paper\nis published.",
            "author": [
                "Tim Fu",
                "Yue Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11167v1",
                "http://arxiv.org/pdf/2311.11167v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11166v1",
            "title": "From Optimization to Control: Quasi Policy Iteration",
            "updated": "2023-11-18T21:00:14Z",
            "published": "2023-11-18T21:00:14Z",
            "summary": "Recent control algorithms for Markov decision processes (MDPs) have been\ndesigned using an implicit analogy with well-established optimization\nalgorithms. In this paper, we make this analogy explicit across four problem\nclasses with a unified solution characterization. This novel framework, in\nturn, allows for a systematic transformation of algorithms from one domain to\nthe other. In particular, we identify equivalent optimization and control\nalgorithms that have already been pointed out in the existing literature, but\nmostly in a scattered way. With this unifying framework in mind, we then\nexploit two linear structural constraints specific to MDPs for approximating\nthe Hessian in a second-order-type algorithm from optimization, namely,\nAnderson mixing. This leads to a novel first-order control algorithm that\nmodifies the standard value iteration (VI) algorithm by incorporating two new\ndirections and adaptive step sizes. While the proposed algorithm, coined as\nquasi-policy iteration, has the same computational complexity as VI, it\ninterestingly exhibits an empirical convergence behavior similar to policy\niteration with a very low sensitivity to the discount factor.",
            "author": [
                "Mohammad Amin Sharifi Kolarijani",
                "Peyman Mohajerin Esfahani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11166v1",
                "http://arxiv.org/pdf/2311.11166v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11164v1",
            "title": "Mitigating Exposure Bias in Discriminator Guided Diffusion Models",
            "updated": "2023-11-18T20:49:50Z",
            "published": "2023-11-18T20:49:50Z",
            "summary": "Diffusion Models have demonstrated remarkable performance in image\ngeneration. However, their demanding computational requirements for training\nhave prompted ongoing efforts to enhance the quality of generated images\nthrough modifications in the sampling process. A recent approach, known as\nDiscriminator Guidance, seeks to bridge the gap between the model score and the\ndata score by incorporating an auxiliary term, derived from a discriminator\nnetwork. We show that despite significantly improving sample quality, this\ntechnique has not resolved the persistent issue of Exposure Bias and we propose\nSEDM-G++, which incorporates a modified sampling approach, combining\nDiscriminator Guidance and Epsilon Scaling. Our proposed approach outperforms\nthe current state-of-the-art, by achieving an FID score of 1.73 on the\nunconditional CIFAR-10 dataset.",
            "author": [
                "Eleftherios Tsonis",
                "Paraskevi Tzouveli",
                "Athanasios Voulodimos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11164v1",
                "http://arxiv.org/pdf/2311.11164v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11159v1",
            "title": "Evaluating the Inclusiveness of Artificial Intelligence Software in\n  Enhancing Project Management Efficiency -- A Review",
            "updated": "2023-11-18T20:22:44Z",
            "published": "2023-11-18T20:22:44Z",
            "summary": "The rise of advanced technology in project management (PM) highlights a\ncrucial need for inclusiveness. This work examines the enhancement of both\ninclusivity and efficiency in PM through technological integration, focusing on\ndefining and measuring inclusiveness. This approach illuminates how\ninclusivity-centered technology can significantly elevate project outcomes. The\nresearch navigates through the challenges of achieving inclusivity, mainly\nbiases in learning databases and the design process of these technologies,\nassessment of transformative potential of these technologies, particularly in\nautomating tasks like data collection and analysis, thus enabling managers to\nprioritize human-centric aspects of projects. However, the integration of such\ntechnology transcends efficiency, indicating a paradigm shift in understanding\ntheir societal roles. This shift necessitates a new approach in the development\nof these systems to prevent perpetuating social inequalities. We proposed a\nmethodology involving criteria development for evaluating the inclusiveness and\neffectiveness of these technologies. This methodical approach is vital to\ncomprehensively address the challenges and limitations inherent in these\nsystems. Emphasizing the importance of inclusivity, the study advocates for a\nbalance between technological advancement and ethical considerations, calling\nfor a holistic understanding and regulation. In conclusion, the paper\nunderscores that while these technologies can significantly improve outcomes,\ntheir mindful integration, ensuring inclusivity, is paramount. This exploration\ninto the ethical and practical aspects of technology in PM contributes to a\nmore informed and balanced approach within the field.",
            "author": [
                "Vasileios Alevizos",
                "Ilias Georgousis",
                "Akebu Simasiku",
                "Sotiria Karypidou",
                "Antonis Messinis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11159v1",
                "http://arxiv.org/pdf/2311.11159v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11155v1",
            "title": "A quantum-assisted master clock in the sky: global synchronization from\n  satellites at sub-nanosecond precision",
            "updated": "2023-11-18T19:53:07Z",
            "published": "2023-11-18T19:53:07Z",
            "summary": "This article develops a protocol to synchronize clocks on board a network of\nsatellites equipped with quantum resources. We show that, in such a\nconstellation, satellites reinforce each other's sync capabilities, forming a\ncommon clock that is more stable and precise than its constituents. We envision\nthe resulting network as a master clock able to distribute time across the\nglobe, providing the basis for a future quantum global navigation satellite\nsystem or a space-based quantum network. As an example of its capabilities, we\nshow that a constellation of 50 satellites equipped with modest quantum\nresources, and distributed amongst 5 orbits at an altitude of 500 km, allows\nthe synchronization of clocks spread across the globe at sub-nanosecond\nprecision.",
            "author": [
                "Sage Ducoing",
                "Ivan Agullo",
                "James E. Troupe",
                "Stav Haldar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11155v1",
                "http://arxiv.org/pdf/2311.11155v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "gr-qc"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11153v1",
            "title": "Biarchetype analysis: simultaneous learning of observations and features\n  based on extremes",
            "updated": "2023-11-18T19:44:54Z",
            "published": "2023-11-18T19:44:54Z",
            "summary": "A new exploratory technique called biarchetype analysis is defined. We extend\narchetype analysis to find the archetypes of both observations and features\nsimultaneously. The idea of this new unsupervised machine learning tool is to\nrepresent observations and features by instances of pure types (biarchetypes)\nthat can be easily interpreted as they are mixtures of observations and\nfeatures. Furthermore, the observations and features are expressed as mixtures\nof the biarchetypes, which also helps understand the structure of the data. We\npropose an algorithm to solve biarchetype analysis. We show that biarchetype\nanalysis offers advantages over biclustering, especially in terms of\ninterpretability. This is because byarchetypes are extreme instances as opposed\nto the centroids returned by biclustering, which favors human understanding.\nBiarchetype analysis is applied to several machine learning problems to\nillustrate its usefulness.",
            "author": [
                "Aleix Alcacer",
                "Irene Epifanio",
                "Ximo Gual-Arnau"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11153v1",
                "http://arxiv.org/pdf/2311.11153v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11151v1",
            "title": "On the Hardness of Learning to Stabilize Linear Systems",
            "updated": "2023-11-18T19:34:56Z",
            "published": "2023-11-18T19:34:56Z",
            "summary": "Inspired by the work of Tsiamis et al. \\cite{tsiamis2022learning}, in this\npaper we study the statistical hardness of learning to stabilize linear\ntime-invariant systems. Hardness is measured by the number of samples required\nto achieve a learning task with a given probability. The work in\n\\cite{tsiamis2022learning} shows that there exist system classes that are hard\nto learn to stabilize with the core reason being the hardness of\nidentification. Here we present a class of systems that can be easy to\nidentify, thanks to a non-degenerate noise process that excites all modes, but\nthe sample complexity of stabilization still increases exponentially with the\nsystem dimension. We tie this result to the hardness of co-stabilizability for\nthis class of systems using ideas from robust control.",
            "author": [
                "Xiong Zeng",
                "Zexiang Liu",
                "Zhe Du",
                "Necmiye Ozay",
                "Mario Sznaier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11151v1",
                "http://arxiv.org/pdf/2311.11151v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11145v1",
            "title": "Benchmarking Feature Extractors for Reinforcement Learning-Based\n  Semiconductor Defect Localization",
            "updated": "2023-11-18T18:43:35Z",
            "published": "2023-11-18T18:43:35Z",
            "summary": "As semiconductor patterning dimensions shrink, more advanced Scanning\nElectron Microscopy (SEM) image-based defect inspection techniques are needed.\nRecently, many Machine Learning (ML)-based approaches have been proposed for\ndefect localization and have shown impressive results. These methods often rely\non feature extraction from a full SEM image and possibly a number of regions of\ninterest. In this study, we propose a deep Reinforcement Learning (RL)-based\napproach to defect localization which iteratively extracts features from\nincreasingly smaller regions of the input image. We compare the results of 18\nagents trained with different feature extractors. We discuss the advantages and\ndisadvantages of different feature extractors as well as the RL-based framework\nin general for semiconductor defect localization.",
            "author": [
                "Enrique Dehaerne",
                "Bappaditya Dey",
                "Sandip Halder",
                "Stefan De Gendt"
            ],
            "link": [
                "http://dx.doi.org/10.1109/ELMAR59410.2023.10253916",
                "http://arxiv.org/abs/2311.11145v1",
                "http://arxiv.org/pdf/2311.11145v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "I.4.9"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11138v1",
            "title": "Estimating Uncertainty in Landslide Segmentation Models",
            "updated": "2023-11-18T18:18:33Z",
            "published": "2023-11-18T18:18:33Z",
            "summary": "Landslides are a recurring, widespread hazard. Preparation and mitigation\nefforts can be aided by a high-quality, large-scale dataset that covers global\nat-risk areas. Such a dataset currently does not exist and is impossible to\nconstruct manually. Recent automated efforts focus on deep learning models for\nlandslide segmentation (pixel labeling) from satellite imagery. However, it is\nalso important to characterize the uncertainty or confidence levels of such\nsegmentations. Accurate and robust uncertainty estimates can enable low-cost\n(in terms of manual labor) oversight of auto-generated landslide databases to\nresolve errors, identify hard negative examples, and increase the size of\nlabeled training data. In this paper, we evaluate several methods for assessing\npixel-level uncertainty of the segmentation. Three methods that do not require\narchitectural changes were compared, including Pre-Threshold activations,\nMonte-Carlo Dropout and Test-Time Augmentation -- a method that measures the\nrobustness of predictions in the face of data augmentation. Experimentally, the\nquality of the latter method was consistently higher than the others across a\nvariety of models and metrics in our dataset.",
            "author": [
                "Savinay Nagendra",
                "Chaopeng Shen",
                "Daniel Kifer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11138v1",
                "http://arxiv.org/pdf/2311.11138v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11134v1",
            "title": "Creating a More Equitable Introductory Physics Classroom Through\n  Invitational Phrasing in Question Solicitation",
            "updated": "2023-11-18T17:54:34Z",
            "published": "2023-11-18T17:54:34Z",
            "summary": "Asking questions during class time is one form of participation not commonly\nemployed by members of underrepresented groups in large enrollment college\nclassrooms, even though the form of participation is highly conducive to\nstudent learning. To encourage students to ask questions, many instructors\ninitiate open question periods in their lectures with verbal solicitations\n(i.e., \"Questions?\"). Although several university centers for teaching and\nlearning, such as at UC Berkeley, and instructor reflections suggest that the\nscripts of question solicitations impact the frequency of questions returned by\nstudents, no literature exists to support this claim. This quasi-experimental\nscholarship of teaching and learning (SoTL) study conducted with the\nStudents-as-Partners model, observes the effect of a new solicitation script\nintegrated into an introductory physics lectures to improve question\nparticipation from students. While the new solicitation script did not change\nthe total number of questions asked by students in comparison to previous\nscripts, the number of questions asked by people who likely have gender\nidentities traditionally underrepresented in physics (i.e. all but cis-men)\nincreased significantly.",
            "author": [
                "David Frykenberg",
                "Brokk Toggerson",
                "Adena Calden",
                "Chris Ertl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11134v1",
                "http://arxiv.org/pdf/2311.11134v1"
            ],
            "primary_category": "physics.ed-ph",
            "category": [
                "physics.ed-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11126v1",
            "title": "Bayesian Neural Networks: A Min-Max Game Framework",
            "updated": "2023-11-18T17:17:15Z",
            "published": "2023-11-18T17:17:15Z",
            "summary": "Bayesian neural networks use random variables to describe the neural networks\nrather than deterministic neural networks and are mostly trained by variational\ninference which updates the mean and variance at the same time. Here, we\nformulate the Bayesian neural networks as a minimax game problem. We do the\nexperiments on the MNIST data set and the primary result is comparable to the\nexisting closed-loop transcription neural network. Finally, we reveal the\nconnections between Bayesian neural networks and closed-loop transcription\nneural networks, and show our framework is rather practical, and provide\nanother view of Bayesian neural networks.",
            "author": [
                "Junping Hong",
                "Ercan Engin Kuruoglu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11126v1",
                "http://arxiv.org/pdf/2311.11126v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12060v1",
            "title": "Pursing the Sparse Limitation of Spiking Deep Learning Structures",
            "updated": "2023-11-18T17:00:40Z",
            "published": "2023-11-18T17:00:40Z",
            "summary": "Spiking Neural Networks (SNNs), a novel brain-inspired algorithm, are\ngarnering increased attention for their superior computation and energy\nefficiency over traditional artificial neural networks (ANNs). To facilitate\ndeployment on memory-constrained devices, numerous studies have explored SNN\npruning. However, these efforts are hindered by challenges such as scalability\nchallenges in more complex architectures and accuracy degradation. Amidst these\nchallenges, the Lottery Ticket Hypothesis (LTH) emerges as a promising pruning\nstrategy. It posits that within dense neural networks, there exist winning\ntickets or subnetworks that are sparser but do not compromise performance. To\nexplore a more structure-sparse and energy-saving model, we investigate the\nunique synergy of SNNs with LTH and design two novel spiking winning tickets to\npush the boundaries of sparsity within SNNs. Furthermore, we introduce an\ninnovative algorithm capable of simultaneously identifying both weight and\npatch-level winning tickets, enabling the achievement of sparser structures\nwithout compromising on the final model's performance. Through comprehensive\nexperiments on both RGB-based and event-based datasets, we demonstrate that our\nspiking lottery ticket achieves comparable or superior performance even when\nthe model structure is extremely sparse.",
            "author": [
                "Hao Cheng",
                "Jiahang Cao",
                "Erjia Xiao",
                "Mengshu Sun",
                "Le Yang",
                "Jize Zhang",
                "Xue Lin",
                "Bhavya Kailkhura",
                "Kaidi Xu",
                "Renjing Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12060v1",
                "http://arxiv.org/pdf/2311.12060v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11114v1",
            "title": "Environment-Aware Dynamic Graph Learning for Out-of-Distribution\n  Generalization",
            "updated": "2023-11-18T16:31:10Z",
            "published": "2023-11-18T16:31:10Z",
            "summary": "Dynamic graph neural networks (DGNNs) are increasingly pervasive in\nexploiting spatio-temporal patterns on dynamic graphs. However, existing works\nfail to generalize under distribution shifts, which are common in real-world\nscenarios. As the generation of dynamic graphs is heavily influenced by latent\nenvironments, investigating their impacts on the out-of-distribution (OOD)\ngeneralization is critical. However, it remains unexplored with the following\ntwo major challenges: (1) How to properly model and infer the complex\nenvironments on dynamic graphs with distribution shifts? (2) How to discover\ninvariant patterns given inferred spatio-temporal environments? To solve these\nchallenges, we propose a novel Environment-Aware dynamic Graph LEarning (EAGLE)\nframework for OOD generalization by modeling complex coupled environments and\nexploiting spatio-temporal invariant patterns. Specifically, we first design\nthe environment-aware EA-DGNN to model environments by multi-channel\nenvironments disentangling. Then, we propose an environment instantiation\nmechanism for environment diversification with inferred distributions. Finally,\nwe discriminate spatio-temporal invariant patterns for out-of-distribution\nprediction by the invariant pattern recognition mechanism and perform\nfine-grained causal interventions node-wisely with a mixture of instantiated\nenvironment samples. Experiments on real-world and synthetic dynamic graph\ndatasets demonstrate the superiority of our method against state-of-the-art\nbaselines under distribution shifts. To the best of our knowledge, we are the\nfirst to study OOD generalization on dynamic graphs from the environment\nlearning perspective.",
            "author": [
                "Haonan Yuan",
                "Qingyun Sun",
                "Xingcheng Fu",
                "Ziwei Zhang",
                "Cheng Ji",
                "Hao Peng",
                "Jianxin Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11114v1",
                "http://arxiv.org/pdf/2311.11114v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11109v1",
            "title": "6G Fresnel Spot Beamfocusing using Large-Scale Metasurfaces: A\n  Distributed DRL-Based Approach",
            "updated": "2023-11-18T15:50:41Z",
            "published": "2023-11-18T15:50:41Z",
            "summary": "In this paper, we introduce the concept of spot beamfocusing (SBF) in the\nFresnel zone through extremely large-scale programmable metasurfaces (ELPMs) as\na key enabling technology for 6G networks. A smart SBF scheme aims to\nadaptively concentrate the aperture's radiating power exactly at a desired\nfocal point (DFP) in the 3D space utilizing some Machine Learning (ML) method.\nThis offers numerous advantages for next-generation networks including\nefficient wireless power transfer (WPT), interference mitigation, reduced RF\npollution, and improved information security. SBF necessitates ELPMs with\nprecise channel state information (CSI) for all ELPM elements. However,\nobtaining exact CSI for ELPMs is not feasible in all environments; we alleviate\nthis by proposing an adaptive novel CSI-independent ML scheme based on the TD3\ndeep-reinforcement-learning (DRL) method. While the proposed ML-based scheme is\nwell-suited for relatively small-size arrays, the computational complexity is\nunaffordable for ELPMs. To overcome this limitation, we introduce a modular\nhighly scalable structure composed of multiple sub-arrays, each equipped with a\nTD3-DRL optimizer. This setup enables collaborative optimization of the\nradiated power at the DFP, significantly reducing computational complexity\nwhile enhancing learning speed. The proposed structures benefits in terms of 3D\nspot-like power distribution, convergence rate, and scalability are validated\nthrough simulation results.",
            "author": [
                "Mehdi Monemi",
                "Mohammad Amir Fallah",
                "Mehdi Rasti",
                "Matti Latva-Aho"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11109v1",
                "http://arxiv.org/pdf/2311.11109v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11108v1",
            "title": "Auxiliary Losses for Learning Generalizable Concept-based Models",
            "updated": "2023-11-18T15:50:07Z",
            "published": "2023-11-18T15:50:07Z",
            "summary": "The increasing use of neural networks in various applications has lead to\nincreasing apprehensions, underscoring the necessity to understand their\noperations beyond mere final predictions. As a solution to enhance model\ntransparency, Concept Bottleneck Models (CBMs) have gained popularity since\ntheir introduction. CBMs essentially limit the latent space of a model to\nhuman-understandable high-level concepts. While beneficial, CBMs have been\nreported to often learn irrelevant concept representations that consecutively\ndamage model performance. To overcome the performance trade-off, we propose\ncooperative-Concept Bottleneck Model (coop-CBM). The concept representation of\nour model is particularly meaningful when fine-grained concept labels are\nabsent. Furthermore, we introduce the concept orthogonal loss (COL) to\nencourage the separation between the concept representations and to reduce the\nintra-concept distance. This paper presents extensive experiments on real-world\ndatasets for image classification tasks, namely CUB, AwA2, CelebA and TIL. We\nalso study the performance of coop-CBM models under various distributional\nshift settings. We show that our proposed method achieves higher accuracy in\nall distributional shift settings even compared to the black-box models with\nthe highest concept accuracy.",
            "author": [
                "Ivaxi Sheth",
                "Samira Ebrahimi Kahou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11108v1",
                "http://arxiv.org/pdf/2311.11108v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11106v1",
            "title": "ShapeMaker: Self-Supervised Joint Shape Canonicalization, Segmentation,\n  Retrieval and Deformation",
            "updated": "2023-11-18T15:44:57Z",
            "published": "2023-11-18T15:44:57Z",
            "summary": "In this paper, we present ShapeMaker, a unified self-supervised learning\nframework for joint shape canonicalization, segmentation, retrieval and\ndeformation. Given a partially-observed object in an arbitrary pose, we first\ncanonicalize the object by extracting point-wise affine-invariant features,\ndisentangling inherent structure of the object with its pose and size. These\nlearned features are then leveraged to predict semantically consistent part\nsegmentation and corresponding part centers. Next, our lightweight retrieval\nmodule aggregates the features within each part as its retrieval token and\ncompare all the tokens with source shapes from a pre-established database to\nidentify the most geometrically similar shape. Finally, we deform the retrieved\nshape in the deformation module to tightly fit the input object by harnessing\npart center guided neural cage deformation. The key insight of ShapeMaker is\nthe simultaneous training of the four highly-associated processes:\ncanonicalization, segmentation, retrieval, and deformation, leveraging\ncross-task consistency losses for mutual supervision. Extensive experiments on\nsynthetic datasets PartNet, ComplementMe, and real-world dataset Scan2CAD\ndemonstrate that ShapeMaker surpasses competitors by a large margin. Codes will\nbe released soon.",
            "author": [
                "Yan Di",
                "Chenyangguang Zhang",
                "Chaowei Wang",
                "Ruida Zhang",
                "Guangyao Zhai",
                "Yanyan Li",
                "Bowen Fu",
                "Xiangyang Ji",
                "Shan Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11106v1",
                "http://arxiv.org/pdf/2311.11106v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11101v1",
            "title": "$\\varepsilon$-fractional Core Stability in Hedonic Games",
            "updated": "2023-11-18T15:30:29Z",
            "published": "2023-11-18T15:30:29Z",
            "summary": "Hedonic Games (HGs) are a classical framework modeling coalition formation of\nstrategic agents guided by their individual preferences. According to these\npreferences, it is desirable that a coalition structure (i.e. a partition of\nagents into coalitions) satisfies some form of stability. The most well-known\nand natural of such notions is arguably core-stability. Informally, a partition\nis core-stable if no subset of agents would like to deviate by regrouping in a\nso-called core-blocking coalition. Unfortunately, core-stable partitions seldom\nexist and even when they do, it is often computationally intractable to find\none. To circumvent these problems, we propose the notion of\n$\\varepsilon$-fractional core-stability, where at most an\n$\\varepsilon$-fraction of all possible coalitions is allowed to core-block. It\nturns out that such a relaxation may guarantee both existence and\npolynomial-time computation. Specifically, we design efficient algorithms\nreturning an $\\varepsilon$-fractional core-stable partition, with $\\varepsilon$\nexponentially decreasing in the number of agents, for two fundamental classes\nof HGs: Simple Fractional and Anonymous. From a probabilistic point of view,\nbeing the definition of $\\varepsilon$-fractional core equivalent to requiring\nthat uniformly sampled coalitions core-block with probability lower than\n$\\varepsilon$, we further extend the definition to handle more complex sampling\ndistributions. Along this line, when valuations have to be learned from samples\nin a PAC-learning fashion, we give positive and negative results on which\ndistributions allow the efficient computation of outcomes that are\n$\\varepsilon$-fractional core-stable with arbitrarily high confidence.",
            "author": [
                "Simone Fioravanti",
                "Michele Flammini",
                "Bojana Kodric",
                "Giovanna Varricchio"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11101v1",
                "http://arxiv.org/pdf/2311.11101v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11099v1",
            "title": "Introducing NCL-SM: A Fully Annotated Dataset of Images from Human\n  Skeletal Muscle Biopsies",
            "updated": "2023-11-18T15:18:38Z",
            "published": "2023-11-18T15:18:38Z",
            "summary": "Single cell analysis of skeletal muscle (SM) tissue is a fundamental tool for\nunderstanding many neuromuscular disorders. For this analysis to be reliable\nand reproducible, identification of individual fibres within microscopy images\n(segmentation) of SM tissue should be precise. There is currently no tool or\npipeline that makes automatic and precise segmentation and curation of images\nof SM tissue cross-sections possible. Biomedical scientists in this field rely\non custom tools and general machine learning (ML) models, both followed by\nlabour intensive and subjective manual interventions to get the segmentation\nright. We believe that automated, precise, reproducible segmentation is\npossible by training ML models. However, there are currently no good quality,\npublicly available annotated imaging datasets available for ML model training.\nIn this paper we release NCL-SM: a high quality bioimaging dataset of 46 human\ntissue sections from healthy control subjects and from patients with\ngenetically diagnosed muscle pathology. These images include $>$ 50k manually\nsegmented muscle fibres (myofibres). In addition we also curated high quality\nmyofibres and annotated reasons for rejecting low quality myofibres and regions\nin SM tissue images, making this data completely ready for downstream analysis.\nThis, we believe, will pave the way for development of a fully automatic\npipeline that identifies individual myofibres within images of tissue sections\nand, in particular, also classifies individual myofibres that are fit for\nfurther analysis.",
            "author": [
                "Atif Khan",
                "Conor Lawless",
                "Amy Vincent",
                "Charlotte Warren",
                "Valeria Di Leo",
                "Tiago Gomes",
                "A. Stephen McGough"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11099v1",
                "http://arxiv.org/pdf/2311.11099v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "q-bio.TO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11097v1",
            "title": "Radiology Report Generation Using Transformers Conditioned with\n  Non-imaging Data",
            "updated": "2023-11-18T14:52:26Z",
            "published": "2023-11-18T14:52:26Z",
            "summary": "Medical image interpretation is central to most clinical applications such as\ndisease diagnosis, treatment planning, and prognostication. In clinical\npractice, radiologists examine medical images and manually compile their\nfindings into reports, which can be a time-consuming process. Automated\napproaches to radiology report generation, therefore, can reduce radiologist\nworkload and improve efficiency in the clinical pathway. While recent\ndeep-learning approaches for automated report generation from medical images\nhave seen some success, most studies have relied on image-derived features\nalone, ignoring non-imaging patient data. Although a few studies have included\nthe word-level contexts along with the image, the use of patient demographics\nis still unexplored. This paper proposes a novel multi-modal transformer\nnetwork that integrates chest x-ray (CXR) images and associated patient\ndemographic information, to synthesise patient-specific radiology reports. The\nproposed network uses a convolutional neural network to extract visual features\nfrom CXRs and a transformer-based encoder-decoder network that combines the\nvisual features with semantic text embeddings of patient demographic\ninformation, to synthesise full-text radiology reports. Data from two public\ndatabases were used to train and evaluate the proposed approach. CXRs and\nreports were extracted from the MIMIC-CXR database and combined with\ncorresponding patients' data MIMIC-IV. Based on the evaluation metrics used\nincluding patient demographic information was found to improve the quality of\nreports generated using the proposed approach, relative to a baseline network\ntrained using CXRs alone. The proposed approach shows potential for enhancing\nradiology report generation by leveraging rich patient metadata and combining\nsemantic text embeddings derived thereof, with medical image-derived visual\nfeatures.",
            "author": [
                "Nurbanu Aksoy",
                "Nishant Ravikumar",
                "Alejandro F Frangi"
            ],
            "link": [
                "http://dx.doi.org/10.1117/12.2653672",
                "http://arxiv.org/abs/2311.11097v1",
                "http://arxiv.org/pdf/2311.11097v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11096v1",
            "title": "On the Out of Distribution Robustness of Foundation Models in Medical\n  Image Segmentation",
            "updated": "2023-11-18T14:52:10Z",
            "published": "2023-11-18T14:52:10Z",
            "summary": "Constructing a robust model that can effectively generalize to test samples\nunder distribution shifts remains a significant challenge in the field of\nmedical imaging. The foundational models for vision and language, pre-trained\non extensive sets of natural image and text data, have emerged as a promising\napproach. It showcases impressive learning abilities across different tasks\nwith the need for only a limited amount of annotated samples. While numerous\ntechniques have focused on developing better fine-tuning strategies to adapt\nthese models for specific domains, we instead examine their robustness to\ndomain shifts in the medical image segmentation task. To this end, we compare\nthe generalization performance to unseen domains of various pre-trained models\nafter being fine-tuned on the same in-distribution dataset and show that\nfoundation-based models enjoy better robustness than other architectures. From\nhere, we further developed a new Bayesian uncertainty estimation for frozen\nmodels and used them as an indicator to characterize the model's performance on\nout-of-distribution (OOD) data, proving particularly beneficial for real-world\napplications. Our experiments not only reveal the limitations of current\nindicators like accuracy on the line or agreement on the line commonly used in\nnatural image applications but also emphasize the promise of the introduced\nBayesian uncertainty. Specifically, lower uncertainty predictions usually tend\nto higher out-of-distribution (OOD) performance.",
            "author": [
                "Duy Minh Ho Nguyen",
                "Tan Ngoc Pham",
                "Nghiem Tuong Diep",
                "Nghi Quoc Phan",
                "Quang Pham",
                "Vinh Tong",
                "Binh T. Nguyen",
                "Ngan Hoang Le",
                "Nhat Ho",
                "Pengtao Xie",
                "Daniel Sonntag",
                "Mathias Niepert"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11096v1",
                "http://arxiv.org/pdf/2311.11096v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11094v1",
            "title": "User-Centric Interactive AI for Distributed Diffusion Model-based\n  AI-Generated Content",
            "updated": "2023-11-18T14:49:04Z",
            "published": "2023-11-18T14:49:04Z",
            "summary": "Distributed Artificial Intelligence-Generated Content (AIGC) has attracted\nincreasing attention. However, it faces two significant challenges: how to\nmaximize the subjective Quality of Experience (QoE) and how to enhance the\nenergy efficiency, which are particularly pronounced in widely adopted\nGenerative Diffusion Model (GDM)-based AIGC services for image generation. In\nthis paper, we propose a novel user-centric Interactive AI (IAI) approach for\nservice management, with a distributed GDM-based AIGC framework, prioritizing\nefficient and collaborative GDM deployment. Specifically, we restructure the\nGDM's inference process, i.e., the denoising chain, to enable users'\nsemantically similar prompts to share a portion of diffusion steps.\nFurthermore, to maximize the users' subjective QoE, we propose an IAI approach,\ni.e., Reinforcement Learning With Large Language Models Interaction (RLLI),\nwhich utilizes Large Language Model (LLM)-empowered generative agents to\nreplicate users interaction, providing real-time and subjective QoE feedback\nthat reflects a spectrum of user personalities. Lastly, we present the\nGDM-based Deep Deterministic Policy Gradient (G-DDPG) algorithm, adapted to the\nproposed RLLI framework, for effective communication and computing resource\nallocation while considering user subjective personalities and dynamic wireless\nenvironments in decision-making. Simulation results show that G-DDPG can\nincrease the sum QoE by 15%, compared with the conventional DDPG algorithm.",
            "author": [
                "Hongyang Du",
                "Ruichen Zhang",
                "Dusit Niyato",
                "Jiawen Kang",
                "Zehui Xiong",
                "Shuguang Cui",
                "Xuemin Shen",
                "Dong In Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11094v1",
                "http://arxiv.org/pdf/2311.11094v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11093v1",
            "title": "Flat Minima in Linear Estimation and an Extended Gauss Markov Theorem",
            "updated": "2023-11-18T14:45:06Z",
            "published": "2023-11-18T14:45:06Z",
            "summary": "We consider the problem of linear estimation, and establish an extension of\nthe Gauss-Markov theorem, in which the bias operator is allowed to be non-zero\nbut bounded with respect to a matrix norm of Schatten type. We derive simple\nand explicit formulas for the optimal estimator in the cases of Nuclear and\nSpectral norms (with the Frobenius case recovering ridge regression).\nAdditionally, we analytically derive the generalization error in multiple\nrandom matrix ensembles, and compare with Ridge regression. Finally, we conduct\nan extensive simulation study, in which we show that the cross-validated\nNuclear and Spectral regressors can outperform Ridge in several circumstances.",
            "author": [
                "Simon Segert"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11093v1",
                "http://arxiv.org/pdf/2311.11093v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11091v1",
            "title": "Deep Tensor Network",
            "updated": "2023-11-18T14:41:33Z",
            "published": "2023-11-18T14:41:33Z",
            "summary": "In this paper, we delve into the foundational principles of tensor\ncategories, harnessing the universal property of the tensor product to pioneer\nnovel methodologies in deep network architectures. Our primary contribution is\nthe introduction of the Tensor Attention and Tensor Interaction Mechanism, a\ngroundbreaking approach that leverages the tensor category to enhance the\ncomputational efficiency and the expressiveness of deep networks, and can even\nbe generalized into the quantum realm.",
            "author": [
                "Yifan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11091v1",
                "http://arxiv.org/pdf/2311.11091v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11090v1",
            "title": "Beyond Images: An Integrative Multi-modal Approach to Chest X-Ray Report\n  Generation",
            "updated": "2023-11-18T14:37:53Z",
            "published": "2023-11-18T14:37:53Z",
            "summary": "Image-to-text radiology report generation aims to automatically produce\nradiology reports that describe the findings in medical images. Most existing\nmethods focus solely on the image data, disregarding the other patient\ninformation accessible to radiologists. In this paper, we present a novel\nmulti-modal deep neural network framework for generating chest X-rays reports\nby integrating structured patient data, such as vital signs and symptoms,\nalongside unstructured clinical notes.We introduce a conditioned\ncross-multi-head attention module to fuse these heterogeneous data modalities,\nbridging the semantic gap between visual and textual data. Experiments\ndemonstrate substantial improvements from using additional modalities compared\nto relying on images alone. Notably, our model achieves the highest reported\nperformance on the ROUGE-L metric compared to relevant state-of-the-art models\nin the literature. Furthermore, we employed both human evaluation and clinical\nsemantic similarity measurement alongside word-overlap metrics to improve the\ndepth of quantitative analysis. A human evaluation, conducted by a\nboard-certified radiologist, confirms the model's accuracy in identifying\nhigh-level findings, however, it also highlights that more improvement is\nneeded to capture nuanced details and clinical context.",
            "author": [
                "Nurbanu Aksoy",
                "Serge Sharoff",
                "Selcuk Baser",
                "Nishant Ravikumar",
                "Alejandro F Frangi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11090v1",
                "http://arxiv.org/pdf/2311.11090v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11088v1",
            "title": "Combining EEG and NLP Features for Predicting Students' Lecture\n  Comprehension using Ensemble Classification",
            "updated": "2023-11-18T14:35:26Z",
            "published": "2023-11-18T14:35:26Z",
            "summary": "Electroencephalography (EEG) and Natural Language Processing (NLP) can be\napplied for education to measure students' comprehension in classroom lectures;\ncurrently, the two measures have been used separately. In this work, we propose\na classification framework for predicting students' lecture comprehension in\ntwo tasks: (i) students' confusion after listening to the simulated lecture and\n(ii) the correctness of students' responses to the post-lecture assessment. The\nproposed framework includes EEG and NLP feature extraction, processing, and\nclassification. EEG and NLP features are extracted to construct integrated\nfeatures obtained from recorded EEG signals and sentence-level syntactic\nanalysis, which provide information about specific biomarkers and sentence\nstructures. An ensemble stacking classification method -- a combination of\nmultiple individual models that produces an enhanced predictive model -- is\nstudied to learn from the features to make predictions accurately. Furthermore,\nwe also utilized subjective confusion ratings as another integrated feature to\nenhance classification performance. By doing so, experiment results show that\nthis framework performs better than the baselines, which achieved F1 up to 0.65\nfor predicting confusion and 0.78 for predicting correctness, highlighting that\nutilizing this has helped improve the classification performance.",
            "author": [
                "Phantharach Natnithikarat",
                "Theerawit Wilaiprasitporn",
                "Supavit Kongwudhikunakorn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11088v1",
                "http://arxiv.org/pdf/2311.11088v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11086v1",
            "title": "LightBTSeg: A lightweight breast tumor segmentation model using\n  ultrasound images via dual-path joint knowledge distillation",
            "updated": "2023-11-18T14:25:40Z",
            "published": "2023-11-18T14:25:40Z",
            "summary": "The accurate segmentation of breast tumors is an important prerequisite for\nlesion detection, which has significant clinical value for breast tumor\nresearch. The mainstream deep learning-based methods have achieved a\nbreakthrough. However, these high-performance segmentation methods are\nformidable to implement in clinical scenarios since they always embrace high\ncomputation complexity, massive parameters, slow inference speed, and huge\nmemory consumption. To tackle this problem, we propose LightBTSeg, a dual-path\njoint knowledge distillation framework, for lightweight breast tumor\nsegmentation. Concretely, we design a double-teacher model to represent the\nfine-grained feature of breast ultrasound according to different semantic\nfeature realignments of benign and malignant breast tumors. Specifically, we\nleverage the bottleneck architecture to reconstruct the original Attention\nU-Net. It is regarded as a lightweight student model named Simplified U-Net.\nThen, the prior knowledge of benign and malignant categories is utilized to\ndesign the teacher network combined dual-path joint knowledge distillation,\nwhich distills the knowledge from cumbersome benign and malignant teachers to a\nlightweight student model. Extensive experiments conducted on breast ultrasound\nimages (Dataset BUSI) and Breast Ultrasound Dataset B (Dataset B) datasets\ndemonstrate that LightBTSeg outperforms various counterparts.",
            "author": [
                "Hongjiang Guo",
                "Shengwen Wang",
                "Hao Dang",
                "Kangle Xiao",
                "Yaru Yang",
                "Wenpei Liu",
                "Tongtong Liu",
                "Yiying Wan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11086v1",
                "http://arxiv.org/pdf/2311.11086v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11085v1",
            "title": "Compositional Fusion of Signals in Data Embedding",
            "updated": "2023-11-18T14:20:56Z",
            "published": "2023-11-18T14:20:56Z",
            "summary": "Embeddings in AI convert symbolic structures into fixed-dimensional vectors,\neffectively fusing multiple signals. However, the nature of this fusion in\nreal-world data is often unclear. To address this, we introduce two methods:\n(1) Correlation-based Fusion Detection, measuring correlation between known\nattributes and embeddings, and (2) Additive Fusion Detection, viewing\nembeddings as sums of individual vectors representing attributes.\n  Applying these methods, word embeddings were found to combine semantic and\nmorphological signals. BERT sentence embeddings were decomposed into individual\nword vectors of subject, verb and object. In the knowledge graph-based\nrecommender system, user embeddings, even without training on demographic data,\nexhibited signals of demographics like age and gender.\n  This study highlights that embeddings are fusions of multiple signals, from\nWord2Vec components to demographic hints in graph embeddings.",
            "author": [
                "Zhijin Guo",
                "Zhaozhen Xu",
                "Martha Lewis",
                "Nello Cristianini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11085v1",
                "http://arxiv.org/pdf/2311.11085v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11083v1",
            "title": "ECLM: Efficient Edge-Cloud Collaborative Learning with Continuous\n  Environment Adaptation",
            "updated": "2023-11-18T14:10:09Z",
            "published": "2023-11-18T14:10:09Z",
            "summary": "Pervasive mobile AI applications primarily employ one of the two learning\nparadigms: cloud-based learning (with powerful large models) or on-device\nlearning (with lightweight small models). Despite their own advantages, neither\nparadigm can effectively handle dynamic edge environments with frequent data\ndistribution shifts and on-device resource fluctuations, inevitably suffering\nfrom performance degradation. In this paper, we propose ECLM, an edge-cloud\ncollaborative learning framework for rapid model adaptation for dynamic edge\nenvironments. We first propose a novel block-level model decomposition design\nto decompose the original large cloud model into multiple combinable modules.\nBy flexibly combining a subset of the modules, this design enables the\nderivation of compact, task-specific sub-models for heterogeneous edge devices\nfrom the large cloud model, and the seamless integration of new knowledge\nlearned on these devices into the cloud model periodically. As such, ECLM\nensures that the cloud model always provides up-to-date sub-models for edge\ndevices. We further propose an end-to-end learning framework that incorporates\nthe modular model design into an efficient model adaptation pipeline including\nan offline on-cloud model prototyping and training stage, and an online\nedge-cloud collaborative adaptation stage. Extensive experiments over various\ndatasets demonstrate that ECLM significantly improves model performance (e.g.,\n18.89% accuracy increase) and resource efficiency (e.g., 7.12x communication\ncost reduction) in adapting models to dynamic edge environments by efficiently\ncollaborating the edge and the cloud models.",
            "author": [
                "Yan Zhuang",
                "Zhenzhe Zheng",
                "Yunfeng Shao",
                "Bingshuai Li",
                "Fan Wu",
                "Guihai Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11083v1",
                "http://arxiv.org/pdf/2311.11083v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11080v1",
            "title": "DSCom: A Data-Driven Self-Adaptive Community-Based Framework for\n  Influence Maximization in Social Networks",
            "updated": "2023-11-18T14:03:43Z",
            "published": "2023-11-18T14:03:43Z",
            "summary": "Influence maximization aims to find a subset of seeds that maximize the\ninfluence spread under a given budget. In this paper, we mainly address the\ndata-driven version of this problem, where the diffusion model is not given but\nneeds to be inferred from the history cascades. Several previous works have\naddressed this topic in a statistical way and provided efficient algorithms\nwith theoretical guarantee. However, in their settings, though the diffusion\nparameters are inferred, they still need users to preset the diffusion model,\nwhich can be an intractable problem in real-world practices. In this paper, we\nreformulate the problem on the attributed network and leverage the node\nattributes to estimate the closeness between the connected nodes. Specifically,\nwe propose a machine learning-based framework, named DSCom, to address this\nproblem in a heuristic way. Under this framework, we first infer the users'\nrelationship from the diffusion dataset through attention mechanism and then\nleverage spectral clustering to overcome the influence overlap problem in the\nlack of exact diffusion formula. Compared to the previous theoretical works, we\ncarefully designed empirical experiments with parameterized diffusion models\nbased on real-world social networks, which prove the efficiency and\neffectiveness of our algorithm.",
            "author": [
                "Yuxin Zuo",
                "Haojia Sun",
                "Yongyi Hu",
                "Jianxiong Guo",
                "Xiaofeng Gao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11080v1",
                "http://arxiv.org/pdf/2311.11080v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12056v1",
            "title": "Kuro Siwo: 12.1 billion $m^2$ under the water. A global multi-temporal\n  satellite dataset for rapid flood mapping",
            "updated": "2023-11-18T13:55:05Z",
            "published": "2023-11-18T13:55:05Z",
            "summary": "Global floods, exacerbated by climate change, pose severe threats to human\nlife, infrastructure, and the environment. This urgency is highlighted by\nrecent catastrophic events in Pakistan and New Zealand, underlining the\ncritical need for precise flood mapping for guiding restoration efforts,\nunderstanding vulnerabilities, and preparing for future events. While Synthetic\nAperture Radar (SAR) offers day-and-night, all-weather imaging capabilities,\nharnessing it for deep learning is hindered by the absence of a large annotated\ndataset. To bridge this gap, we introduce Kuro Siwo, a meticulously curated\nmulti-temporal dataset, spanning 32 flood events globally. Our dataset maps\nmore than 63 billion m2 of land, with 12.1 billion of them being either a\nflooded area or a permanent water body. Kuro Siwo stands out for its\nunparalleled annotation quality to facilitate rapid flood mapping in a\nsupervised setting. We also augment learning by including a large unlabeled set\nof SAR samples, aimed at self-supervised pretraining. We provide an extensive\nbenchmark and strong baselines for a diverse set of flood events from Europe,\nAmerica, Africa and Australia. Our benchmark demonstrates the quality of Kuro\nSiwo annotations, training models that can achieve $\\approx$ 85% and $\\approx$\n87% in F1-score for flooded areas and general water detection respectively.\nThis work calls on the deep learning community to develop solution-driven\nalgorithms for rapid flood mapping, with the potential to aid civil protection\nand humanitarian agencies amid climate change challenges. Our code and data\nwill be made available at https://github.com/Orion-AI-Lab/KuroSiwo",
            "author": [
                "Nikolaos Ioannis Bountos",
                "Maria Sdraka",
                "Angelos Zavras",
                "Ilektra Karasante",
                "Andreas Karavias",
                "Themistocles Herekakis",
                "Angeliki Thanasou",
                "Dimitrios Michail",
                "Ioannis Papoutsis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12056v1",
                "http://arxiv.org/pdf/2311.12056v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "eess.IV",
                "I.2; I.4; I.5.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11077v1",
            "title": "Adapters: A Unified Library for Parameter-Efficient and Modular Transfer\n  Learning",
            "updated": "2023-11-18T13:53:26Z",
            "published": "2023-11-18T13:53:26Z",
            "summary": "We introduce Adapters, an open-source library that unifies\nparameter-efficient and modular transfer learning in large language models. By\nintegrating 10 diverse adapter methods into a unified interface, Adapters\noffers ease of use and flexible configuration. Our library allows researchers\nand practitioners to leverage adapter modularity through composition blocks,\nenabling the design of complex adapter setups. We demonstrate the library's\nefficacy by evaluating its performance against full fine-tuning on various NLP\ntasks. Adapters provides a powerful tool for addressing the challenges of\nconventional fine-tuning paradigms and promoting more efficient and modular\ntransfer learning. The library is available via https://adapterhub.ml/adapters.",
            "author": [
                "Clifton Poth",
                "Hannah Sterz",
                "Indraneil Paul",
                "Sukannya Purkayastha",
                "Leon Engl\u00e4nder",
                "Timo Imhof",
                "Ivan Vuli\u0107",
                "Sebastian Ruder",
                "Iryna Gurevych",
                "Jonas Pfeiffer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11077v1",
                "http://arxiv.org/pdf/2311.11077v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11074v1",
            "title": "The Persian Piano Corpus: A Collection Of Instrument-Based Feature\n  Extracted Data Considering Dastgah",
            "updated": "2023-11-18T13:45:40Z",
            "published": "2023-11-18T13:45:40Z",
            "summary": "The research in the field of music is rapidly growing, and this trend\nemphasizes the need for comprehensive data. Though researchers have made an\neffort to contribute their own datasets, many data collections lack the\nrequisite inclusivity for comprehensive study because they are frequently\nfocused on particular components of music or other specific topics. We have\nendeavored to address data scarcity by employing an instrument-based approach\nto provide a complete corpus related to the Persian piano. Our piano corpus\nincludes relevant labels for Persian music mode (Dastgah) and comprehensive\nmetadata, allowing for utilization in various popular research areas. The\nfeatures extracted from 2022 Persian piano pieces in The Persian Piano Corpus\n(PPC) have been collected and made available to researchers, aiming for a more\nthorough understanding of Persian music and the role of the piano in it in\nsubsequent steps.",
            "author": [
                "Parsa Rasouli",
                "Azam Bastanfard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11074v1",
                "http://arxiv.org/pdf/2311.11074v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "cs.MM",
                "eess.AS",
                "E.0; I.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11073v1",
            "title": "Community-Aware Efficient Graph Contrastive Learning via Personalized\n  Self-Training",
            "updated": "2023-11-18T13:45:21Z",
            "published": "2023-11-18T13:45:21Z",
            "summary": "In recent years, graph contrastive learning (GCL) has emerged as one of the\noptimal solutions for various supervised tasks at the node level. However, for\nunsupervised and structure-related tasks such as community detection, current\nGCL algorithms face difficulties in acquiring the necessary community-level\ninformation, resulting in poor performance. In addition, general contrastive\nlearning algorithms improve the performance of downstream tasks by increasing\nthe number of negative samples, which leads to severe class collision and\nunfairness of community detection. To address above issues, we propose a novel\nCommunity-aware Efficient Graph Contrastive Learning Framework (CEGCL) to\njointly learn community partition and node representations in an end-to-end\nmanner. Specifically, we first design a personalized self-training (PeST)\nstrategy for unsupervised scenarios, which enables our model to capture precise\ncommunity-level personalized information in a graph. With the benefit of the\nPeST, we alleviate class collision and unfairness without sacrificing the\noverall model performance. Furthermore, the aligned graph clustering (AlGC) is\nemployed to obtain the community partition. In this module, we align the\nclustering space of our downstream task with that in PeST to achieve more\nconsistent node embeddings. Finally, we demonstrate the effectiveness of our\nmodel for community detection both theoretically and experimentally. Extensive\nexperimental results also show that our CEGCL exhibits state-of-the-art\nperformance on three benchmark datasets with different scales.",
            "author": [
                "Yuecheng Li",
                "Yanming Hu",
                "Lele Fu",
                "Chuan Chen",
                "Lei Yang",
                "Zibin Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11073v1",
                "http://arxiv.org/pdf/2311.11073v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11071v1",
            "title": "SBTRec- A Transformer Framework for Personalized Tour Recommendation\n  Problem with Sentiment Analysis",
            "updated": "2023-11-18T13:30:01Z",
            "published": "2023-11-18T13:30:01Z",
            "summary": "When traveling to an unfamiliar city for holidays, tourists often rely on\nguidebooks, travel websites, or recommendation systems to plan their daily\nitineraries and explore popular points of interest (POIs). However, these\napproaches may lack optimization in terms of time feasibility, localities, and\nuser preferences. In this paper, we propose the SBTRec algorithm: a BERT-based\nTrajectory Recommendation with sentiment analysis, for recommending\npersonalized sequences of POIs as itineraries. The key contributions of this\nwork include analyzing users' check-ins and uploaded photos to understand the\nrelationship between POI visits and distance. We introduce SBTRec, which\nencompasses sentiment analysis to improve recommendation accuracy by\nunderstanding users' preferences and satisfaction levels from reviews and\ncomments about different POIs. Our proposed algorithms are evaluated against\nother sequence prediction methods using datasets from 8 cities. The results\ndemonstrate that SBTRec achieves an average F1 score of 61.45%, outperforming\nbaseline algorithms.\n  The paper further discusses the flexibility of the SBTRec algorithm, its\nability to adapt to different scenarios and cities without modification, and\nits potential for extension by incorporating additional information for more\nreliable predictions. Overall, SBTRec provides personalized and relevant POI\nrecommendations, enhancing tourists' overall trip experiences. Future work\nincludes fine-tuning personalized embeddings for users, with evaluation of\nusers' comments on POIs,~to further enhance prediction accuracy.",
            "author": [
                "Ngai Lam Ho",
                "Roy Ka-Wei Lee",
                "Kwan Hui Lim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11071v1",
                "http://arxiv.org/pdf/2311.11071v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11065v1",
            "title": "Enhancing Transformer-Based Segmentation for Breast Cancer Diagnosis\n  using Auto-Augmentation and Search Optimisation Techniques",
            "updated": "2023-11-18T13:08:09Z",
            "published": "2023-11-18T13:08:09Z",
            "summary": "Breast cancer remains a critical global health challenge, necessitating early\nand accurate detection for effective treatment. This paper introduces a\nmethodology that combines automated image augmentation selection (RandAugment)\nwith search optimisation strategies (Tree-based Parzen Estimator) to identify\noptimal values for the number of image augmentations and the magnitude of their\nassociated augmentation parameters, leading to enhanced segmentation\nperformance. We empirically validate our approach on breast cancer histology\nslides, focusing on the segmentation of cancer cells. A comparative analysis of\nstate-of-the-art transformer-based segmentation models is conducted, including\nSegFormer, PoolFormer, and MaskFormer models, to establish a comprehensive\nbaseline, before applying the augmentation methodology. Our results show that\nthe proposed methodology leads to segmentation models that are more resilient\nto variations in histology slides whilst maintaining high levels of\nsegmentation performance, and show improved segmentation of the tumour class\nwhen compared to previous research. Our best result after applying the\naugmentations is a Dice Score of 84.08 and an IoU score of 72.54 when\nsegmenting the tumour class. The primary contribution of this paper is the\ndevelopment of a methodology that enhances segmentation performance while\nensuring model robustness to data variances. This has significant implications\nfor medical practitioners, enabling the development of more effective machine\nlearning models for clinical applications to identify breast cancer cells from\nhistology slides. Furthermore, the codebase accompanying this research will be\nreleased upon publication. This will facilitate further research and\napplication development based on our methodology, thereby amplifying its\nimpact.",
            "author": [
                "Leon Hamnett",
                "Mary Adewunmi",
                "Modinat Abayomi",
                "Kayode Raheem",
                "Fahad Ahmed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11065v1",
                "http://arxiv.org/pdf/2311.11065v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11058v1",
            "title": "Tactics2D: A Multi-agent Reinforcement Learning Environment for Driving\n  Decision-making",
            "updated": "2023-11-18T12:31:34Z",
            "published": "2023-11-18T12:31:34Z",
            "summary": "Tactics2D is an open-source multi-agent reinforcement learning library with a\nPython backend. Its goal is to provide a convenient toolset for researchers to\ndevelop decision-making algorithms for autonomous driving. The library includes\ndiverse traffic scenarios implemented as gym-based environments equipped with\nmulti-sensory capabilities and violation detection for traffic rules.\nAdditionally, it features a reinforcement learning baseline tested with\nreasonable evaluation metrics. Tactics2D is highly modular and customizable.\nThe source code of Tactics2D is available at\nhttps://github.com/WoodOxen/Tactics2D.",
            "author": [
                "Yueyuan Li",
                "Songan Zhang",
                "Mingyang Jiang",
                "Xingyuan Chen",
                "Ming Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11058v1",
                "http://arxiv.org/pdf/2311.11058v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11057v1",
            "title": "Challenges in data-based geospatial modeling for environmental research\n  and practice",
            "updated": "2023-11-18T12:30:49Z",
            "published": "2023-11-18T12:30:49Z",
            "summary": "With the rise of electronic data, particularly Earth observation data,\ndata-based geospatial modelling using machine learning (ML) has gained\npopularity in environmental research. Accurate geospatial predictions are vital\nfor domain research based on ecosystem monitoring and quality assessment and\nfor policy-making and action planning, considering effective management of\nnatural resources. The accuracy and computation speed of ML has generally\nproved efficient. However, many questions have yet to be addressed to obtain\nprecise and reproducible results suitable for further use in both research and\npractice. A better understanding of the ML concepts applicable to geospatial\nproblems enhances the development of data science tools providing transparent\ninformation crucial for making decisions on global challenges such as biosphere\ndegradation and climate change. This survey reviews common nuances in\ngeospatial modelling, such as imbalanced data, spatial autocorrelation,\nprediction errors, model generalisation, domain specificity, and uncertainty\nestimation. We provide an overview of techniques and popular programming tools\nto overcome or account for the challenges. We also discuss prospects for\ngeospatial Artificial Intelligence in environmental applications.",
            "author": [
                "Diana Koldasbayeva",
                "Polina Tregubova",
                "Mikhail Gasanov",
                "Alexey Zaytsev",
                "Anna Petrovskaia",
                "Evgeny Burnaev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11057v1",
                "http://arxiv.org/pdf/2311.11057v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11056v1",
            "title": "A Survey of Simulators for Autonomous Driving: Taxonomy, Challenges, and\n  Evaluation Metrics",
            "updated": "2023-11-18T12:30:41Z",
            "published": "2023-11-18T12:30:41Z",
            "summary": "Simulators have irreplaceable importance for the research and development of\nautonomous driving. Besides saving resources, labor, and time, simulation is\nthe only feasible way to reproduce many severe accident scenarios. Despite\ntheir widespread adoption across academia and industry, there is an absence in\nthe evolutionary trajectory of simulators and critical discourse on their\nlimitations.\n  To bridge the gap in research, this paper conducts an in-depth review of\nsimulators for autonomous driving. It delineates the three-decade development\ninto three stages: specialized development period, gap period, and\ncomprehensive development, from which it detects a trend of implementing\ncomprehensive functionalities and open-source accessibility. Then it classifies\nthe simulators by functions, identifying five categories: traffic flow\nsimulator, vehicle dynamics simulator, scenario editor, sensory data generator,\nand driving strategy validator. Simulators that amalgamate diverse features are\ndefined as comprehensive simulators. By investigating commercial and\nopen-source simulators, this paper reveals that the critical issues faced by\nsimulators primarily revolve around fidelity and efficiency concerns. This\npaper justifies that enhancing the realism of adverse weather simulation,\nautomated map reconstruction, and interactive traffic participants will bolster\ncredibility. Concurrently, headless simulation and multiple-speed simulation\ntechniques will exploit the theoretic advantages. Moreover, this paper delves\ninto potential solutions for the identified issues. It explores qualitative and\nquantitative evaluation metrics to assess the simulator's performance. This\npaper guides users to find suitable simulators efficiently and provides\ninstructive suggestions for developers to improve simulator efficacy\npurposefully.",
            "author": [
                "Yueyuan Li",
                "Wei Yuan",
                "Weihao Yan",
                "Qiyuan Shen",
                "Chunxiang Wang",
                "Ming Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11056v1",
                "http://arxiv.org/pdf/2311.11056v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11055v1",
            "title": "Designing Interpretable ML System to Enhance Trustworthy AI in\n  Healthcare: A Systematic Review of the Last Decade to A Proposed Robust\n  Framework",
            "updated": "2023-11-18T12:29:18Z",
            "published": "2023-11-18T12:29:18Z",
            "summary": "AI-based medical technologies, including wearables, telemedicine, LLMs, and\ndigital care twins, significantly impact healthcare. Ensuring AI results are\naccurate and interpretable is crucial, especially for clinicians. This paper\nreviews processes and challenges of interpretable ML (IML) and explainable AI\n(XAI) in healthcare. Objectives include reviewing XAI processes, methods,\napplications, and challenges, with a focus on quality control. The IML process\nis classified into data pre-processing interpretability, interpretable\nmodeling, and post-processing interpretability. The paper aims to establish the\nimportance of robust interpretability in healthcare through experimental\nresults, providing insights for creating communicable clinician-AI tools.\nResearch questions, eligibility criteria, and goals were identified following\nPRISMA and PICO methods. PubMed, Scopus, and Web of Science were systematically\nsearched using specific strings. The survey introduces a step-by-step roadmap\nfor implementing XAI in clinical applications, addressing existing gaps and\nacknowledging XAI model limitations.",
            "author": [
                "Elham Nasarian",
                "Roohallah Alizadehsani",
                "U. Rajendra Acharyac",
                "d Kwok-Leung Tsui"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11055v1",
                "http://arxiv.org/pdf/2311.11055v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11050v1",
            "title": "Functional Neural Network Control Chart",
            "updated": "2023-11-18T12:15:58Z",
            "published": "2023-11-18T12:15:58Z",
            "summary": "In many Industry 4.0 data analytics applications, quality characteristic data\nacquired from manufacturing processes are better modeled as functions, often\nreferred to as profiles. In practice, there are situations where a scalar\nquality characteristic, referred to also as the response, is influenced by one\nor more variables in the form of functional data, referred to as functional\ncovariates. To adjust the monitoring of the scalar response by the effect of\nthis additional information, a new profile monitoring strategy is proposed on\nthe residuals obtained from the functional neural network, which is able to\nlearn a possibly nonlinear relationship between the scalar response and the\nfunctional covariates. An extensive Monte Carlo simulation study is performed\nto assess the performance of the proposed method with respect to other control\ncharts that appeared in the literature before. Finally, a case study in the\nrailway industry is presented with the aim of monitoring the heating,\nventilation and air conditioning systems installed onboard passenger trains.",
            "author": [
                "Murat Kulahci",
                "Antonio Lepore",
                "Biagio Palumbo",
                "Gianluca Sposito"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11050v1",
                "http://arxiv.org/pdf/2311.11050v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11047v1",
            "title": "CLIPSwarm: Converting text into formations of robots",
            "updated": "2023-11-18T11:46:42Z",
            "published": "2023-11-18T11:46:42Z",
            "summary": "We present CLIPSwarm, an algorithm to generate robot swarm formations from\nnatural language descriptions. CLIPSwarm receives an input text and finds the\nposition of the robots to form a shape that corresponds to the given text. To\ndo so, we implement a variation of the Montecarlo particle filter to obtain a\nmatching formation iteratively. In every iteration, we generate a set of new\nformations and evaluate their Clip Similarity with the given text, selecting\nthe best formations according to this metric. This metric is obtained using\nClip, [1], an existing foundation model trained to encode images and texts into\nvectors within a common latent space. The comparison between these vectors\ndetermines how likely the given text describes the shapes. Our initial proof of\nconcept shows the potential of this solution to generate robot swarm formations\njust from natural language descriptions and demonstrates a novel application of\nfoundation models, such as CLIP, in the field of multi-robot systems. In this\nfirst approach, we create formations using a Convex-Hull approach. Next steps\ninclude more robust and generic representation and optimization steps in the\nprocess of obtaining a suitable swarm formation.",
            "author": [
                "Pablo Pueyo",
                "Eduardo Montijano",
                "Ana C. Murillo",
                "Mac Schwager"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11047v1",
                "http://arxiv.org/pdf/2311.11047v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11046v1",
            "title": "DenseNet and Support Vector Machine classifications of major depressive\n  disorder using vertex-wise cortical features",
            "updated": "2023-11-18T11:46:25Z",
            "published": "2023-11-18T11:46:25Z",
            "summary": "Major depressive disorder (MDD) is a complex psychiatric disorder that\naffects the lives of hundreds of millions of individuals around the globe. Even\ntoday, researchers debate if morphological alterations in the brain are linked\nto MDD, likely due to the heterogeneity of this disorder. The application of\ndeep learning tools to neuroimaging data, capable of capturing complex\nnon-linear patterns, has the potential to provide diagnostic and predictive\nbiomarkers for MDD. However, previous attempts to demarcate MDD patients and\nhealthy controls (HC) based on segmented cortical features via linear machine\nlearning approaches have reported low accuracies. In this study, we used\nglobally representative data from the ENIGMA-MDD working group containing an\nextensive sample of people with MDD (N=2,772) and HC (N=4,240), which allows a\ncomprehensive analysis with generalizable results. Based on the hypothesis that\nintegration of vertex-wise cortical features can improve classification\nperformance, we evaluated the classification of a DenseNet and a Support Vector\nMachine (SVM), with the expectation that the former would outperform the\nlatter. As we analyzed a multi-site sample, we additionally applied the ComBat\nharmonization tool to remove potential nuisance effects of site. We found that\nboth classifiers exhibited close to chance performance (balanced accuracy\nDenseNet: 51%; SVM: 53%), when estimated on unseen sites. Slightly higher\nclassification performance (balanced accuracy DenseNet: 58%; SVM: 55%) was\nfound when the cross-validation folds contained subjects from all sites,\nindicating site effect. In conclusion, the integration of vertex-wise\nmorphometric features and the use of the non-linear classifier did not lead to\nthe differentiability between MDD and HC. Our results support the notion that\nMDD classification on this combination of features and classifiers is\nunfeasible.",
            "author": [
                "Vladimir Belov",
                "Tracy Erwin-Grabner",
                "Ling-Li Zeng",
                "Christopher R. K. Ching",
                "Andre Aleman",
                "Alyssa R. Amod",
                "Zeynep Basgoze",
                "Francesco Benedetti",
                "Bianca Besteher",
                "Katharina Brosch",
                "Robin B\u00fclow",
                "Romain Colle",
                "Colm G. Connolly",
                "Emmanuelle Corruble",
                "Baptiste Couvy-Duchesne",
                "Kathryn Cullen",
                "Udo Dannlowski",
                "Christopher G. Davey",
                "Annemiek Dols",
                "Jan Ernsting",
                "Jennifer W. Evans",
                "Lukas Fisch",
                "Paola Fuentes-Claramonte",
                "Ali Saffet Gonul",
                "Ian H. Gotlib",
                "Hans J. Grabe",
                "Nynke A. Groenewold",
                "Dominik Grotegerd",
                "Tim Hahn",
                "J. Paul Hamilton",
                "Laura K. M. Han",
                "Ben J Harrison",
                "Tiffany C. Ho",
                "Neda Jahanshad",
                "Alec J. Jamieson",
                "Andriana Karuk",
                "Tilo Kircher",
                "Bonnie Klimes-Dougan",
                "Sheri-Michelle Koopowitz",
                "Thomas Lancaster",
                "Ramona Leenings",
                "Meng Li",
                "David E. J. Linden",
                "Frank P. MacMaster",
                "David M. A. Mehler",
                "Susanne Meinert",
                "Elisa Melloni",
                "Bryon A. Mueller",
                "Benson Mwangi",
                "Igor Nenadi\u0107",
                "Amar Ojha",
                "Yasumasa Okamoto",
                "Mardien L. Oudega",
                "Brenda W. J. H. Penninx",
                "Sara Poletti",
                "Edith Pomarol-Clotet",
                "Maria J. Portella",
                "Elena Pozzi",
                "Joaquim Radua",
                "Elena Rodr\u00edguez-Cano",
                "Matthew D. Sacchet",
                "Raymond Salvador",
                "Anouk Schrantee",
                "Kang Sim",
                "Jair C. Soares",
                "Aleix Solanes",
                "Dan J. Stein",
                "Frederike Stein",
                "Aleks Stolicyn",
                "Sophia I. Thomopoulos",
                "Yara J. Toenders",
                "Aslihan Uyar-Demir",
                "Eduard Vieta",
                "Yolanda Vives-Gilabert",
                "Henry V\u00f6lzke",
                "Martin Walter",
                "Heather C. Whalley",
                "Sarah Whittle",
                "Nils Winter",
                "Katharina Wittfeld",
                "Margaret J. Wright",
                "Mon-Ju Wu",
                "Tony T. Yang",
                "Carlos Zarate",
                "Dick J. Veltman",
                "Lianne Schmaal",
                "Paul M. Thompson",
                "Roberto Goya-Maldonado"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11046v1",
                "http://arxiv.org/pdf/2311.11046v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11045v2",
            "title": "Orca 2: Teaching Small Language Models How to Reason",
            "updated": "2023-11-21T19:43:31Z",
            "published": "2023-11-18T11:44:52Z",
            "summary": "Orca 1 learns from rich signals, such as explanation traces, allowing it to\noutperform conventional instruction-tuned models on benchmarks like BigBench\nHard and AGIEval. In Orca 2, we continue exploring how improved training\nsignals can enhance smaller LMs' reasoning abilities. Research on training\nsmall LMs has often relied on imitation learning to replicate the output of\nmore capable models. We contend that excessive emphasis on imitation may\nrestrict the potential of smaller models. We seek to teach small LMs to employ\ndifferent solution strategies for different tasks, potentially different from\nthe one used by the larger model. For example, while larger models might\nprovide a direct answer to a complex task, smaller models may not have the same\ncapacity. In Orca 2, we teach the model various reasoning techniques\n(step-by-step, recall then generate, recall-reason-generate, direct answer,\netc.). More crucially, we aim to help the model learn to determine the most\neffective solution strategy for each task. We evaluate Orca 2 using a\ncomprehensive set of 15 diverse benchmarks (corresponding to approximately 100\ntasks and over 36,000 unique prompts). Orca 2 significantly surpasses models of\nsimilar size and attains performance levels similar or better to those of\nmodels 5-10x larger, as assessed on complex tasks that test advanced reasoning\nabilities in zero-shot settings. make Orca 2 weights publicly available at\naka.ms/orca-lm to support research on the development, evaluation, and\nalignment of smaller LMs",
            "author": [
                "Arindam Mitra",
                "Luciano Del Corro",
                "Shweti Mahajan",
                "Andres Codas",
                "Clarisse Simoes",
                "Sahaj Agarwal",
                "Xuxi Chen",
                "Anastasia Razdaibiedina",
                "Erik Jones",
                "Kriti Aggarwal",
                "Hamid Palangi",
                "Guoqing Zheng",
                "Corby Rosset",
                "Hamed Khanpour",
                "Ahmed Awadallah"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11045v2",
                "http://arxiv.org/pdf/2311.11045v2"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11029v1",
            "title": "Geometric Data Augmentations to Mitigate Distribution Shifts in Pollen\n  Classification from Microscopic Images",
            "updated": "2023-11-18T10:35:18Z",
            "published": "2023-11-18T10:35:18Z",
            "summary": "Distribution shifts are characterized by differences between the training and\ntest data distributions. They can significantly reduce the accuracy of machine\nlearning models deployed in real-world scenarios. This paper explores the\ndistribution shift problem when classifying pollen grains from microscopic\nimages collected in the wild with a low-cost camera sensor. We leverage the\ndomain knowledge that geometric features are highly important for accurate\npollen identification and introduce two novel geometric image augmentation\ntechniques to significantly narrow the accuracy gap between the model\nperformance on the train and test datasets. In particular, we show that\nTenengrad and ImageToSketch filters are highly effective to balance the shape\nand texture information while leaving out unimportant details that may confuse\nthe model. Extensive evaluations on various model architectures demonstrate a\nconsistent improvement of the model generalization to field data of up to 14%\nachieved by the geometric augmentation techniques when compared to a wide range\nof standard image augmentations. The approach is validated through an ablation\nstudy using pollen hydration tests to recover the shape of dry pollen grains.\nThe proposed geometric augmentations also receive the highest scores according\nto the affinity and diversity measures from the literature.",
            "author": [
                "Nam Cao",
                "Olga Saukh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11029v1",
                "http://arxiv.org/pdf/2311.11029v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11021v1",
            "title": "Secure Software Development: Issues and Challenges",
            "updated": "2023-11-18T09:44:48Z",
            "published": "2023-11-18T09:44:48Z",
            "summary": "In recent years, technology has advanced considerably with the introduction\nof many systems including advanced robotics, big data analytics, cloud\ncomputing, machine learning and many more. The opportunities to exploit the yet\nto come security that comes with these systems are going toe to toe with new\nreleases of security protocols to combat this exploitation to provide a secure\nsystem. The digitization of our lives proves to solve our human problems as\nwell as improve quality of life but because it is digitalized, information and\ntechnology could be misused for other malicious gains. Hackers aim to steal the\ndata of innocent people to use it for other causes such as identity fraud,\nscams and many more. This issue can be corrected during the software\ndevelopment life cycle, integrating security across the development phases, and\ntesting of the software is done early to reduce the number of vulnerabilities\nthat might or might not heavily impact an organisation depending on the range\nof the attack. The goal of a secured system software is to prevent such\nexploitations from ever happening by conducting a system life cycle where\nthrough planning and testing is done to maximise security while maintaining\nfunctionality of the system. In this paper, we are going to discuss the recent\ntrends in security for system development as well as our predictions and\nsuggestions to improve the current security practices in this industry.",
            "author": [
                "Sam Wen Ping",
                "Jeffrey Cheok Jun Wah",
                "Lee Wen Jie",
                "Jeremy Bong Yong Han",
                "Saira Muzafar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11021v1",
                "http://arxiv.org/pdf/2311.11021v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11019v1",
            "title": "Hyperbolic Space with Hierarchical Margin Boosts Fine-Grained Learning\n  from Coarse Labels",
            "updated": "2023-11-18T09:42:03Z",
            "published": "2023-11-18T09:42:03Z",
            "summary": "Learning fine-grained embeddings from coarse labels is a challenging task due\nto limited label granularity supervision, i.e., lacking the detailed\ndistinctions required for fine-grained tasks. The task becomes even more\ndemanding when attempting few-shot fine-grained recognition, which holds\npractical significance in various applications. To address these challenges, we\npropose a novel method that embeds visual embeddings into a hyperbolic space\nand enhances their discriminative ability with a hierarchical cosine margins\nmanner. Specifically, the hyperbolic space offers distinct advantages,\nincluding the ability to capture hierarchical relationships and increased\nexpressive power, which favors modeling fine-grained objects. Based on the\nhyperbolic space, we further enforce relatively large/small similarity margins\nbetween coarse/fine classes, respectively, yielding the so-called hierarchical\ncosine margins manner. While enforcing similarity margins in the regular\nEuclidean space has become popular for deep embedding learning, applying it to\nthe hyperbolic space is non-trivial and validating the benefit for\ncoarse-to-fine generalization is valuable. Extensive experiments conducted on\nfive benchmark datasets showcase the effectiveness of our proposed method,\nyielding state-of-the-art results surpassing competing methods.",
            "author": [
                "Shu-Lin Xu",
                "Yifan Sun",
                "Faen Zhang",
                "Anqi Xu",
                "Xiu-Shen Wei",
                "Yi Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11019v1",
                "http://arxiv.org/pdf/2311.11019v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11018v1",
            "title": "SORTAD: Self-Supervised Optimized Random Transformations for Anomaly\n  Detection in Tabular Data",
            "updated": "2023-11-18T09:15:58Z",
            "published": "2023-11-18T09:15:58Z",
            "summary": "We consider a self-supervised approach to anomaly detection in tabular data.\nRandom transformations are applied to the data, and then each transformation is\nidentified based on its output. These predicted transformations are used to\nidentify anomalies. In tabular data this approach faces many challenges that\nare related to the uncorrelated nature of the data. These challenges affect the\ntransformations that should be used, as well as the use of their predictions.\nTo this end, we propose SORTAD, a novel algorithm that is tailor-made to solve\nthese challenges. SORTAD optimally chooses random transformations that help the\nclassification process, and have a scoring function that is more sensitive to\nthe changes in the transformations classification prediction encountered in\ntabular data. SORTAD achieved state-of-the-art results on multiple commonly\nused anomaly detection data sets, as well as in the overall results across all\ndata sets tested.",
            "author": [
                "Guy Hay",
                "Pablo Liberman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11018v1",
                "http://arxiv.org/pdf/2311.11018v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "I.5.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12049v1",
            "title": "Energizing Federated Learning via Filter-Aware Attention",
            "updated": "2023-11-18T09:09:38Z",
            "published": "2023-11-18T09:09:38Z",
            "summary": "Federated learning (FL) is a promising distributed paradigm, eliminating the\nneed for data sharing but facing challenges from data heterogeneity.\nPersonalized parameter generation through a hypernetwork proves effective, yet\nexisting methods fail to personalize local model structures. This leads to\nredundant parameters struggling to adapt to diverse data distributions. To\naddress these limitations, we propose FedOFA, utilizing personalized orthogonal\nfilter attention for parameter recalibration. The core is the Two-stream\nFilter-aware Attention (TFA) module, meticulously designed to extract\npersonalized filter-aware attention maps, incorporating Intra-Filter Attention\n(IntraFa) and Inter-Filter Attention (InterFA) streams. These streams enhance\nrepresentation capability and explore optimal implicit structures for local\nmodels. Orthogonal regularization minimizes redundancy by averting\ninter-correlation between filters. Furthermore, we introduce an\nAttention-Guided Pruning Strategy (AGPS) for communication efficiency. AGPS\nselectively retains crucial neurons while masking redundant ones, reducing\ncommunication costs without performance sacrifice. Importantly, FedOFA operates\non the server side, incurring no additional computational cost on the client,\nmaking it advantageous in communication-constrained scenarios. Extensive\nexperiments validate superior performance over state-of-the-art approaches,\nwith code availability upon paper acceptance.",
            "author": [
                "Ziyuan Yang",
                "Zerui Shao",
                "Huijie Huangfu",
                "Hui Yu",
                "Andrew Beng Jin Teoh",
                "Xiaoxiao Li",
                "Hongming Shan",
                "Yi Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12049v1",
                "http://arxiv.org/pdf/2311.12049v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12048v1",
            "title": "One Size Fits All for Semantic Shifts: Adaptive Prompt Tuning for\n  Continual Learning",
            "updated": "2023-11-18T08:55:08Z",
            "published": "2023-11-18T08:55:08Z",
            "summary": "In real-world continual learning scenarios, tasks often exhibit intricate and\nunpredictable semantic shifts, posing challenges for fixed prompt management\nstrategies. We identify the inadequacy of universal and specific prompting in\nhandling these dynamic shifts. Universal prompting is ineffective for tasks\nwith abrupt semantic changes, while specific prompting struggles with\noverfitting under mild semantic shifts. To overcome these limitations, we\npropose an adaptive prompting approach that tailors minimal yet sufficient\nprompts based on the task semantics. Our methodology, SemPrompt, incorporates a\ntwo-level semantic grouping process: macroscopic semantic assignment and\nmicroscopic semantic refinement. This process ensures optimal prompt\nutilization for varying task semantics, improving the efficiency and\neffectiveness of learning in real-world CL settings. Our experimental results\ndemonstrate that SemPrompt consistently outperforms existing methods in\nadapting to diverse semantic shifts in tasks.",
            "author": [
                "Doyoung Kim",
                "Susik Yoon",
                "Dongmin Park",
                "Youngjun Lee",
                "Hwanjun Song",
                "Jihwan Bang",
                "Jae-Gil Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12048v1",
                "http://arxiv.org/pdf/2311.12048v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11014v1",
            "title": "Lesion Search with Self-supervised Learning",
            "updated": "2023-11-18T08:51:25Z",
            "published": "2023-11-18T08:51:25Z",
            "summary": "Content-based image retrieval (CBIR) with self-supervised learning (SSL)\naccelerates clinicians' interpretation of similar images without manual\nannotations. We develop a CBIR from the contrastive learning SimCLR and\nincorporate a generalized-mean (GeM) pooling followed by L2 normalization to\nclassify lesion types and retrieve similar images before clinicians' analysis.\nResults have shown improved performance. We additionally build an open-source\napplication for image analysis and retrieval. The application is easy to\nintegrate, relieving manual efforts and suggesting the potential to support\nclinicians' everyday activities.",
            "author": [
                "Kristin Qi",
                "Jiali Cheng",
                "Daniel Haehn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11014v1",
                "http://arxiv.org/pdf/2311.11014v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11013v2",
            "title": "Implicit Event-RGBD Neural SLAM",
            "updated": "2023-11-21T06:18:25Z",
            "published": "2023-11-18T08:48:58Z",
            "summary": "Implicit neural SLAM has achieved remarkable progress recently. Nevertheless,\nexisting methods face significant challenges in non-ideal scenarios, such as\nmotion blur or lighting variation, which often leads to issues like convergence\nfailures, localization drifts, and distorted mapping. To address these\nchallenges, we propose $\\textbf{EN-SLAM}$, the first event-RGBD implicit neural\nSLAM framework, which effectively leverages the high rate and high dynamic\nrange advantages of event data for tracking and mapping. Specifically, EN-SLAM\nproposes a differentiable CRF (Camera Response Function) rendering technique to\ngenerate distinct RGB and event camera data via a shared radiance field, which\nis optimized by learning a unified implicit representation with the captured\nevent and RGBD supervision. Moreover, based on the temporal difference property\nof events, we propose a temporal aggregating optimization strategy for the\nevent joint tracking and global bundle adjustment, capitalizing on the\nconsecutive difference constraints of events, significantly enhancing tracking\naccuracy and robustness. Finally, we construct the simulated dataset\n$\\textbf{DEV-Indoors}$ and real captured dataset $\\textbf{DEV-Reals}$\ncontaining 6 scenes, 17 sequences with practical motion blur and lighting\nchanges for evaluations. Experimental results show that our method outperforms\nthe SOTA methods in both tracking ATE and mapping ACC with a real-time $17$ FPS\nin various challenging environments. The code and dataset will be released\nsoon.",
            "author": [
                "Delin Qu",
                "Chi Yan",
                "Dong Wang",
                "Jie Yin",
                "Dan Xu",
                "Bin Zhao",
                "Xuelong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11013v2",
                "http://arxiv.org/pdf/2311.11013v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11012v1",
            "title": "Bit Cipher -- A Simple yet Powerful Word Representation System that\n  Integrates Efficiently with Language Models",
            "updated": "2023-11-18T08:47:35Z",
            "published": "2023-11-18T08:47:35Z",
            "summary": "While Large Language Models (LLMs) become ever more dominant, classic\npre-trained word embeddings sustain their relevance through computational\nefficiency and nuanced linguistic interpretation. Drawing from recent studies\ndemonstrating that the convergence of GloVe and word2vec optimizations all tend\ntowards log-co-occurrence matrix variants, we construct a novel word\nrepresentation system called Bit-cipher that eliminates the need of\nbackpropagation while leveraging contextual information and hyper-efficient\ndimensionality reduction techniques based on unigram frequency, providing\nstrong interpretability, alongside efficiency. We use the bit-cipher algorithm\nto train word vectors via a two-step process that critically relies on a\nhyperparameter -- bits -- that controls the vector dimension. While the first\nstep trains the bit-cipher, the second utilizes it under two different\naggregation modes -- summation or concatenation -- to produce contextually rich\nrepresentations from word co-occurrences. We extend our investigation into\nbit-cipher's efficacy, performing probing experiments on part-of-speech (POS)\ntagging and named entity recognition (NER) to assess its competitiveness with\nclassic embeddings like word2vec and GloVe. Additionally, we explore its\napplicability in LM training and fine-tuning. By replacing embedding layers\nwith cipher embeddings, our experiments illustrate the notable efficiency of\ncipher in accelerating the training process and attaining better optima\ncompared to conventional training paradigms. Experiments on the integration of\nbit-cipher embedding layers with Roberta, T5, and OPT, prior to or as a\nsubstitute for fine-tuning, showcase a promising enhancement to transfer\nlearning, allowing rapid model convergence while preserving competitive\nperformance.",
            "author": [
                "Haoran Zhao",
                "Jake Ryland Williams"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11012v1",
                "http://arxiv.org/pdf/2311.11012v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11011v1",
            "title": "PAIReD jet: A multi-pronged resonance tagging strategy across all\n  Lorentz boosts",
            "updated": "2023-11-18T08:29:49Z",
            "published": "2023-11-18T08:29:49Z",
            "summary": "We propose a new approach of jet-based event reconstruction that aims to\noptimally exploit correlations between the products of a hadronic multi-pronged\ndecay across all Lorentz boost regimes. The new approach utilizes clustered\nsmall-radius jets as seeds to define unconventional jets, referred to as PAIReD\njets. The constituents of these jets are subsequently used as inputs to machine\nlearning-based algorithms to identify the flavor content of the jet. We\ndemonstrate that this approach achieves higher efficiencies in the\nreconstruction of signal events containing heavy-flavor jets compared to other\nevent reconstruction strategies at all Lorentz boost regimes. Classifiers\ntrained on PAIReD jets also have significantly better background rejections\ncompared to those based on traditional event reconstruction approaches using\nsmall-radius jets at low Lorentz boost regimes. The combined effect of a higher\nsignal reconstruction efficiency and better classification performance results\nin a two to four times stronger rejection of light-flavor jets compared to\nconventional strategies at low Lorentz-boosts, and rejection rates similar to\nclassifiers based on large-radius multi-pronged jets at high Lorentz-boost\nregimes.",
            "author": [
                "Spandan Mondal",
                "Gaetano Barone",
                "Alexander Schmidt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11011v1",
                "http://arxiv.org/pdf/2311.11011v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex",
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11009v1",
            "title": "Joyful: Joint Modality Fusion and Graph Contrastive Learning for\n  Multimodal Emotion Recognition",
            "updated": "2023-11-18T08:21:42Z",
            "published": "2023-11-18T08:21:42Z",
            "summary": "Multimodal emotion recognition aims to recognize emotions for each utterance\nof multiple modalities, which has received increasing attention for its\napplication in human-machine interaction. Current graph-based methods fail to\nsimultaneously depict global contextual features and local diverse uni-modal\nfeatures in a dialogue. Furthermore, with the number of graph layers\nincreasing, they easily fall into over-smoothing. In this paper, we propose a\nmethod for joint modality fusion and graph contrastive learning for multimodal\nemotion recognition (Joyful), where multimodality fusion, contrastive learning,\nand emotion recognition are jointly optimized. Specifically, we first design a\nnew multimodal fusion mechanism that can provide deep interaction and fusion\nbetween the global contextual and uni-modal specific features. Then, we\nintroduce a graph contrastive learning framework with inter-view and intra-view\ncontrastive losses to learn more distinguishable representations for samples\nwith different sentiments. Extensive experiments on three benchmark datasets\nindicate that Joyful achieved state-of-the-art (SOTA) performance compared to\nall baselines.",
            "author": [
                "Dongyuan Li",
                "Yusong Wang",
                "Kotaro Funakoshi",
                "Manabu Okumura"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11009v1",
                "http://arxiv.org/pdf/2311.11009v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11007v1",
            "title": "Constraint-aware Policy for Compliant Manipulation",
            "updated": "2023-11-18T08:07:29Z",
            "published": "2023-11-18T08:07:29Z",
            "summary": "Robot manipulation in a physically-constrained environment requires compliant\nmanipulation. Compliant manipulation is a manipulation skill to adjust hand\nmotion based on the force imposed by the environment. Recently, reinforcement\nlearning (RL) has been applied to solve household operations involving\ncompliant manipulation. However, previous RL methods have primarily focused on\ndesigning a policy for a specific operation that limits their applicability and\nrequires separate training for every new operation. We propose a\nconstraint-aware policy that is applicable to various unseen manipulations by\ngrouping several manipulations together based on the type of physical\nconstraint involved. The type of physical constraint determines the\ncharacteristic of the imposed force direction; thus, a generalized policy is\ntrained in the environment and reward designed on the basis of this\ncharacteristic. This paper focuses on two types of physical constraints:\nprismatic and revolute joints. Experiments demonstrated that the same policy\ncould successfully execute various compliant-manipulation operations, both in\nthe simulation and reality. We believe this study is the first step toward\nrealizing a generalized household-robot.",
            "author": [
                "Daichi Saito",
                "Kazuhiro Sasabuchi",
                "Naoki Wake",
                "Atsushi Kanehira",
                "Jun Takamatsu",
                "Hideki Koike",
                "Katsushi Ikeuchi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11007v1",
                "http://arxiv.org/pdf/2311.11007v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11004v1",
            "title": "A Foundation Model for Cell Segmentation",
            "updated": "2023-11-18T07:55:09Z",
            "published": "2023-11-18T07:55:09Z",
            "summary": "Cells are the fundamental unit of biological organization, and identifying\nthem in imaging data - cell segmentation - is a critical task for various\ncellular imaging experiments. While deep learning methods have led to\nsubstantial progress on this problem, models that have seen wide use are\nspecialist models that work well for specific domains. Methods that have\nlearned the general notion of \"what is a cell\" and can identify them across\ndifferent domains of cellular imaging data have proven elusive. In this work,\nwe present CellSAM, a foundation model for cell segmentation that generalizes\nacross diverse cellular imaging data. CellSAM builds on top of the Segment\nAnything Model (SAM) by developing a prompt engineering approach to mask\ngeneration. We train an object detector, CellFinder, to automatically detect\ncells and prompt SAM to generate segmentations. We show that this approach\nallows a single model to achieve state-of-the-art performance for segmenting\nimages of mammalian cells (in tissues and cell culture), yeast, and bacteria\ncollected with various imaging modalities. To enable accessibility, we\nintegrate CellSAM into DeepCell Label to further accelerate human-in-the-loop\nlabeling strategies for cellular imaging data. A deployed version of CellSAM is\navailable at https://label-dev.deepcell.org/.",
            "author": [
                "Uriah Israel",
                "Markus Marks",
                "Rohit Dilip",
                "Qilin Li",
                "Morgan Schwartz",
                "Elora Pradhan",
                "Edward Pao",
                "Shenyi Li",
                "Alexander Pearson-Goulart",
                "Pietro Perona",
                "Georgia Gkioxari",
                "Ross Barnowski",
                "Yisong Yue",
                "David Van Valen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11004v1",
                "http://arxiv.org/pdf/2311.11004v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11003v1",
            "title": "Wasserstein Convergence Guarantees for a General Class of Score-Based\n  Generative Models",
            "updated": "2023-11-18T07:53:22Z",
            "published": "2023-11-18T07:53:22Z",
            "summary": "Score-based generative models (SGMs) is a recent class of deep generative\nmodels with state-of-the-art performance in many applications. In this paper,\nwe establish convergence guarantees for a general class of SGMs in\n2-Wasserstein distance, assuming accurate score estimates and smooth\nlog-concave data distribution. We specialize our result to several concrete\nSGMs with specific choices of forward processes modelled by stochastic\ndifferential equations, and obtain an upper bound on the iteration complexity\nfor each model, which demonstrates the impacts of different choices of the\nforward processes. We also provide a lower bound when the data distribution is\nGaussian. Numerically, we experiment SGMs with different forward processes,\nsome of which are newly proposed in this paper, for unconditional image\ngeneration on CIFAR-10. We find that the experimental results are in good\nagreement with our theoretical predictions on the iteration complexity, and the\nmodels with our newly proposed forward processes can outperform existing\nmodels.",
            "author": [
                "Xuefeng Gao",
                "Hoang M. Nguyen",
                "Lingjiong Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11003v1",
                "http://arxiv.org/pdf/2311.11003v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.PR",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.11001v1",
            "title": "Gendec: A Machine Learning-based Framework for Gender Detection from\n  Japanese Names",
            "updated": "2023-11-18T07:46:59Z",
            "published": "2023-11-18T07:46:59Z",
            "summary": "Every human has their own name, a fundamental aspect of their identity and\ncultural heritage. The name often conveys a wealth of information, including\ndetails about an individual's background, ethnicity, and, especially, their\ngender. By detecting gender through the analysis of names, researchers can\nunlock valuable insights into linguistic patterns and cultural norms, which can\nbe applied to practical applications. Hence, this work presents a novel dataset\nfor Japanese name gender detection comprising 64,139 full names in romaji,\nhiragana, and kanji forms, along with their biological genders. Moreover, we\npropose Gendec, a framework for gender detection from Japanese names that\nleverages diverse approaches, including traditional machine learning techniques\nor cutting-edge transfer learning models, to predict the gender associated with\nJapanese names accurately. Through a thorough investigation, the proposed\nframework is expected to be effective and serve potential applications in\nvarious domains.",
            "author": [
                "Duong Tien Pham",
                "Luan Thanh Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.11001v1",
                "http://arxiv.org/pdf/2311.11001v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10998v1",
            "title": "Learning Scene Context Without Images",
            "updated": "2023-11-18T07:27:25Z",
            "published": "2023-11-18T07:27:25Z",
            "summary": "Teaching machines of scene contextual knowledge would enable them to interact\nmore effectively with the environment and to anticipate or predict objects that\nmay not be immediately apparent in their perceptual field. In this paper, we\nintroduce a novel transformer-based approach called $LMOD$ ( Label-based\nMissing Object Detection) to teach scene contextual knowledge to machines using\nan attention mechanism. A distinctive aspect of the proposed approach is its\nreliance solely on labels from image datasets to teach scene context, entirely\neliminating the need for the actual image itself. We show how scene-wide\nrelationships among different objects can be learned using a self-attention\nmechanism. We further show that the contextual knowledge gained from label\nbased learning can enhance performance of other visual based object detection\nalgorithm.",
            "author": [
                "Amirreza Rouhi",
                "David Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10998v1",
                "http://arxiv.org/pdf/2311.10998v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10996v2",
            "title": "BrainZ-BP: A Non-invasive Cuff-less Blood Pressure Estimation Approach\n  Leveraging Brain Bio-impedance and Electrocardiogram",
            "updated": "2023-11-23T05:08:16Z",
            "published": "2023-11-18T07:10:32Z",
            "summary": "Accurate and continuous blood pressure (BP) monitoring is essential to the\nearly prevention of cardiovascular diseases. Non-invasive and cuff-less BP\nestimation algorithm has gained much attention in recent years. Previous\nstudies have demonstrated that brain bio-impedance (BIOZ) is a promising\ntechnique for non-invasive intracranial pressure (ICP) monitoring. Clinically,\ntreatment for patients with traumatic brain injuries (TBI) requires monitoring\nthe ICP and BP of patients simultaneously. Estimating BP by brain BIOZ directly\ncan reduce the number of sensors attached to the patients, thus improving their\ncomfort. To address the issues, in this study, we explore the feasibility of\nleveraging brain BIOZ for BP estimation and propose a novel cuff-less BP\nestimation approach called BrainZ-BP. Two electrodes are placed on the forehead\nand occipital bone of the head in the anterior-posterior direction for brain\nBIOZ measurement. Various features including pulse transit time and\nmorphological features of brain BIOZ are extracted and fed into four regression\nmodels for BP estimation. Results show that the mean absolute error, root mean\nsquare error, and correlation coefficient of random forest regression model are\n2.17 mmHg, 3.91 mmHg, and 0.90 for systolic pressure estimation, and are 1.71\nmmHg, 3.02 mmHg, and 0.89 for diastolic pressure estimation. The presented\nBrainZ-BP can be applied in the brain BIOZ-based ICP monitoring scenario to\nmonitor BP simultaneously.",
            "author": [
                "Bufang Yang",
                "Le Liu",
                "Wenxuan Wu",
                "Mengliang Zhou",
                "Hongxing Liu",
                "Xinbao Ning"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10996v2",
                "http://arxiv.org/pdf/2311.10996v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10992v1",
            "title": "Towards Robust and Accurate Visual Prompting",
            "updated": "2023-11-18T07:00:56Z",
            "published": "2023-11-18T07:00:56Z",
            "summary": "Visual prompting, an efficient method for transfer learning, has shown its\npotential in vision tasks. However, previous works focus exclusively on VP from\nstandard source models, it is still unknown how it performs under the scenario\nof a robust source model: Whether a visual prompt derived from a robust model\ncan inherit the robustness while suffering from the generalization performance\ndecline, albeit for a downstream dataset that is different from the source\ndataset? In this work, we get an affirmative answer of the above question and\ngive an explanation on the visual representation level. Moreover, we introduce\na novel technique named Prompt Boundary Loose (PBL) to effectively mitigates\nthe suboptimal results of visual prompt on standard accuracy without losing (or\neven significantly improving) its adversarial robustness when using a robust\nmodel as source model. Extensive experiments across various datasets show that\nour findings are universal and demonstrate the significant benefits of our\nproposed method.",
            "author": [
                "Qi Li",
                "Liangzhi Li",
                "Zhouqiang Jiang",
                "Bowen Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10992v1",
                "http://arxiv.org/pdf/2311.10992v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10988v1",
            "title": "Expanding Scene Graph Boundaries: Fully Open-vocabulary Scene Graph\n  Generation via Visual-Concept Alignment and Retention",
            "updated": "2023-11-18T06:49:17Z",
            "published": "2023-11-18T06:49:17Z",
            "summary": "Scene Graph Generation (SGG) offers a structured representation critical in\nmany computer vision applications. Traditional SGG approaches, however, are\nlimited by a closed-set assumption, restricting their ability to recognize only\npredefined object and relation categories. To overcome this, we categorize SGG\nscenarios into four distinct settings based on the node and edge: Closed-set\nSGG, Open Vocabulary (object) Detection-based SGG (OvD-SGG), Open Vocabulary\nRelation-based SGG (OvR-SGG), and Open Vocabulary Detection + Relation-based\nSGG (OvD+R-SGG). While object-centric open vocabulary SGG has been studied\nrecently, the more challenging problem of relation-involved open-vocabulary SGG\nremains relatively unexplored. To fill this gap, we propose a unified framework\nnamed OvSGTR towards fully open vocabulary SGG from a holistic view. The\nproposed framework is an end-toend transformer architecture, which learns a\nvisual-concept alignment for both nodes and edges, enabling the model to\nrecognize unseen categories. For the more challenging settings of\nrelation-involved open vocabulary SGG, the proposed approach integrates\nrelation-aware pre-training utilizing image-caption data and retains\nvisual-concept alignment through knowledge distillation. Comprehensive\nexperimental results on the Visual Genome benchmark demonstrate the\neffectiveness and superiority of the proposed framework.",
            "author": [
                "Zuyao Chen",
                "Jinlin Wu",
                "Zhen Lei",
                "Zhaoxiang Zhang",
                "Changwen Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10988v1",
                "http://arxiv.org/pdf/2311.10988v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10986v3",
            "title": "EdgeFM: Leveraging Foundation Model for Open-set Learning on the Edge",
            "updated": "2023-11-23T04:44:00Z",
            "published": "2023-11-18T06:40:39Z",
            "summary": "Deep Learning (DL) models have been widely deployed on IoT devices with the\nhelp of advancements in DL algorithms and chips. However, the limited resources\nof edge devices make these on-device DL models hard to be generalizable to\ndiverse environments and tasks. Although the recently emerged foundation models\n(FMs) show impressive generalization power, how to effectively leverage the\nrich knowledge of FMs on resource-limited edge devices is still not explored.\nIn this paper, we propose EdgeFM, a novel edge-cloud cooperative system with\nopen-set recognition capability. EdgeFM selectively uploads unlabeled data to\nquery the FM on the cloud and customizes the specific knowledge and\narchitectures for edge models. Meanwhile, EdgeFM conducts dynamic model\nswitching at run-time taking into account both data uncertainty and dynamic\nnetwork variations, which ensures the accuracy always close to the original FM.\nWe implement EdgeFM using two FMs on two edge platforms. We evaluate EdgeFM on\nthree public datasets and two self-collected datasets. Results show that EdgeFM\ncan reduce the end-to-end latency up to 3.2x and achieve 34.3% accuracy\nincrease compared with the baseline.",
            "author": [
                "Bufang Yang",
                "Lixing He",
                "Neiwen Ling",
                "Zhenyu Yan",
                "Guoliang Xing",
                "Xian Shuai",
                "Xiaozhe Ren",
                "Xin Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10986v3",
                "http://arxiv.org/pdf/2311.10986v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10983v1",
            "title": "Multiple View Geometry Transformers for 3D Human Pose Estimation",
            "updated": "2023-11-18T06:32:40Z",
            "published": "2023-11-18T06:32:40Z",
            "summary": "In this work, we aim to improve the 3D reasoning ability of Transformers in\nmulti-view 3D human pose estimation. Recent works have focused on end-to-end\nlearning-based transformer designs, which struggle to resolve geometric\ninformation accurately, particularly during occlusion. Instead, we propose a\nnovel hybrid model, MVGFormer, which has a series of geometric and appearance\nmodules organized in an iterative manner. The geometry modules are\nlearning-free and handle all viewpoint-dependent 3D tasks geometrically which\nnotably improves the model's generalization ability. The appearance modules are\nlearnable and are dedicated to estimating 2D poses from image signals\nend-to-end which enables them to achieve accurate estimates even when occlusion\noccurs, leading to a model that is both accurate and generalizable to new\ncameras and geometries. We evaluate our approach for both in-domain and\nout-of-domain settings, where our model consistently outperforms\nstate-of-the-art methods, and especially does so by a significant margin in the\nout-of-domain setting. We will release the code and models:\nhttps://github.com/XunshanMan/MVGFormer.",
            "author": [
                "Ziwei Liao",
                "Jialiang Zhu",
                "Chunyu Wang",
                "Han Hu",
                "Steven L. Waslander"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10983v1",
                "http://arxiv.org/pdf/2311.10983v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10976v1",
            "title": "First M87 Event Horizon Telescope Results. IX. Detection of Near-horizon\n  Circular Polarization",
            "updated": "2023-11-18T05:23:09Z",
            "published": "2023-11-18T05:23:09Z",
            "summary": "Event Horizon Telescope (EHT) observations have revealed a bright ring of\nemission around the supermassive black hole at the center of the M87 galaxy.\nEHT images in linear polarization have further identified a coherent spiral\npattern around the black hole, produced from ordered magnetic fields threading\nthe emitting plasma. Here, we present the first analysis of circular\npolarization using EHT data, acquired in 2017, which can potentially provide\nadditional insights into the magnetic fields and plasma composition near the\nblack hole. Interferometric closure quantities provide convincing evidence for\nthe presence of circularly polarized emission on event-horizon scales. We\nproduce images of the circular polarization using both traditional and newly\ndeveloped methods. All methods find a moderate level of resolved circular\npolarization across the image ($\\langle|v|\\rangle < 3.7\\%$), consistent with\nthe low image-integrated circular polarization fraction measured by the ALMA\narray ($|v_{\\rm int}| < 1\\%$). Despite this broad agreement, the methods show\nsubstantial variation in the morphology of the circularly polarized emission,\nindicating that our conclusions are strongly dependent upon the imaging\nassumptions because of the limited baseline coverage, uncertain telescope gain\ncalibration, and weakly polarized signal. We include this upper limit in an\nupdated comparison to general relativistic magnetohydrodynamic (GRMHD)\nsimulation models. This analysis reinforces the previously reported preference\nfor magnetically arrested accretion flow models. We find that most simulations\nnaturally produce a low level of circular polarization consistent with our\nupper limit, and that Faraday conversion is likely the dominant production\nmechanism for circular polarization at 230 GHz in M87*.",
            "author": [
                "The Event Horizon Telescope Collaboration"
            ],
            "link": [
                "http://dx.doi.org/10.3847/2041-8213/acff70",
                "http://arxiv.org/abs/2311.10976v1",
                "http://arxiv.org/pdf/2311.10976v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10972v1",
            "title": "Polynomial-Time Solutions for ReLU Network Training: A Complexity\n  Classification via Max-Cut and Zonotopes",
            "updated": "2023-11-18T04:41:07Z",
            "published": "2023-11-18T04:41:07Z",
            "summary": "We investigate the complexity of training a two-layer ReLU neural network\nwith weight decay regularization. Previous research has shown that the optimal\nsolution of this problem can be found by solving a standard cone-constrained\nconvex program. Using this convex formulation, we prove that the hardness of\napproximation of ReLU networks not only mirrors the complexity of the Max-Cut\nproblem but also, in certain special cases, exactly corresponds to it. In\nparticular, when $\\epsilon\\leq\\sqrt{84/83}-1\\approx 0.006$, we show that it is\nNP-hard to find an approximate global optimizer of the ReLU network objective\nwith relative error $\\epsilon$ with respect to the objective value. Moreover,\nwe develop a randomized algorithm which mirrors the Goemans-Williamson rounding\nof semidefinite Max-Cut relaxations. To provide polynomial-time approximations,\nwe classify training datasets into three categories: (i) For orthogonal\nseparable datasets, a precise solution can be obtained in polynomial-time. (ii)\nWhen there is a negative correlation between samples of different classes, we\ngive a polynomial-time approximation with relative error $\\sqrt{\\pi/2}-1\\approx\n0.253$. (iii) For general datasets, the degree to which the problem can be\napproximated in polynomial-time is governed by a geometric factor that controls\nthe diameter of two zonotopes intrinsic to the dataset. To our knowledge, these\nresults present the first polynomial-time approximation guarantees along with\nfirst hardness of approximation results for regularized ReLU networks.",
            "author": [
                "Yifei Wang",
                "Mert Pilanci"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10972v1",
                "http://arxiv.org/pdf/2311.10972v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10965v1",
            "title": "(Nearest) Neighbors You Can Rely On: Formally Verified k-d Tree\n  Construction and Search in Coq",
            "updated": "2023-11-18T04:27:07Z",
            "published": "2023-11-18T04:27:07Z",
            "summary": "The k-d tree is a classic binary space-partitioning tree used to organize\npoints in k-dimensional space. While used in computational geometry and\ngraphics, the data structure has a long history of application in nearest\nneighbor search. The objective of the nearest neighbor search problem is to\nefficiently find the closest point(s) to a given query point, and is the basis,\nin turn, of common machine learning techniques. We present in this paper a case\nstudy in the certified implementation, using the Coq proof assistant, of k-d\ntree construction from a set of data and the accompanying K-nearest neighbors\nsearch algorithm. Our experience demonstrates an intuitive method for\nspecifying properties of these algorithms using the notion of list\npermutations.",
            "author": [
                "Nadeem Abdul Hamid"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10965v1",
                "http://arxiv.org/pdf/2311.10965v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.CG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10963v1",
            "title": "Learning Deterministic Finite Automata from Confidence Oracles",
            "updated": "2023-11-18T04:21:05Z",
            "published": "2023-11-18T04:21:05Z",
            "summary": "We discuss the problem of learning a deterministic finite automaton (DFA)\nfrom a confidence oracle. That is, we are given access to an oracle $Q$ with\nincomplete knowledge of some target language $L$ over an alphabet $\\Sigma$; the\noracle maps a string $x\\in\\Sigma^*$ to a score in the interval $[-1,1]$\nindicating its confidence that the string is in the language. The\ninterpretation is that the sign of the score signifies whether $x\\in L$, while\nthe magnitude $|Q(x)|$ represents the oracle's confidence. Our goal is to learn\na DFA representation of the oracle that preserves the information that it is\nconfident in. The learned DFA should closely match the oracle wherever it is\nhighly confident, but it need not do this when the oracle is less sure of\nitself.",
            "author": [
                "Wilson Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10963v1",
                "http://arxiv.org/pdf/2311.10963v1"
            ],
            "primary_category": "cs.FL",
            "category": [
                "cs.FL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10962v1",
            "title": "Classification Methods Based on Machine Learning for the Analysis of\n  Fetal Health Data",
            "updated": "2023-11-18T04:01:46Z",
            "published": "2023-11-18T04:01:46Z",
            "summary": "The persistent battle to decrease childhood mortality serves as a commonly\nemployed benchmark for gauging advancements in the field of medicine. Globally,\nthe under-5 mortality rate stands at approximately 5 million, with a\nsignificant portion of these deaths being avoidable. Given the significance of\nthis problem, Machine learning-based techniques have emerged as a prominent\ntool for assessing fetal health. In this work, we have analyzed the\nclassification performance of various machine learning models for fetal health\nanalysis. Classification performance of various machine learning models, such\nas support vector machine (SVM), random forest(RF), and attentive interpretable\ntabular learning (TabNet) have been assessed on fetal health. Moreover,\ndimensionality reduction techniques, such as Principal component analysis (PCA)\nand Linear discriminant analysis (LDA) have been implemented to obtain better\nclassification performance with less number of features. A TabNet model on a\nfetal health dataset provides a classification accuracy of 94.36%. In general,\nthis technology empowers doctors and healthcare experts to achieve precise\nfetal health classification and identify the most influential features in the\nprocess.",
            "author": [
                "Binod Regmi",
                "Chiranjibi Shah"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10962v1",
                "http://arxiv.org/pdf/2311.10962v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12872v1",
            "title": "The Case for Universal Basic Computing Power",
            "updated": "2023-11-18T03:27:47Z",
            "published": "2023-11-18T03:27:47Z",
            "summary": "The Universal Basic Computing Power (UBCP) initiative ensures global, free\naccess to a set amount of computing power specifically for AI research and\ndevelopment (R&D). This initiative comprises three key elements. First, UBCP\nmust be cost free, with its usage limited to AI R&D and minimal additional\nconditions. Second, UBCP should continually incorporate the state of the art AI\nadvancements, including efficiently distilled, compressed, and deployed\ntraining data, foundational models, benchmarks, and governance tools. Lastly,\nit's essential for UBCP to be universally accessible, ensuring convenience for\nall users. We urge major stakeholders in AI development large platforms, open\nsource contributors, and policymakers to prioritize the UBCP initiative.",
            "author": [
                "Yue Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12872v1",
                "http://arxiv.org/pdf/2311.12872v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10954v1",
            "title": "Taxonomic analysis of asteroids with artificial neural networks",
            "updated": "2023-11-18T03:27:26Z",
            "published": "2023-11-18T03:27:26Z",
            "summary": "We study the surface composition of asteroids with visible and/or infrared\nspectroscopy. For example, asteroid taxonomy is based on the spectral features\nor multiple color indices in visible and near-infrared wavelengths. The\ncomposition of asteroids gives key information to understand their origin and\nevolution. However, we lack compositional information for faint asteroids due\nto limits of ground-based observational instruments. In the near future, the\nChinese Space Survey telescope (CSST) will provide multiple colors and\nspectroscopic data for asteroids of apparent magnitude brighter than 25 mag and\n23 mag, respectively. For the aim of analysis of the CSST spectroscopic data,\nwe applied an algorithm using artificial neural networks (ANNs) to establish a\npreliminary classification model for asteroid taxonomy according to the design\nof the survey module of CSST. Using the SMASS II spectra and the Bus-Binzel\ntaxonomy system, our ANN classification tool composed of 5 individual ANNs is\nconstructed, and the accuracy of this classification system is higher than 92\n%. As the first application of our ANN tool, 64 spectra of 42 asteroids\nobtained in 2006 and 2007 by us with the 2.16-m telescope in the Xinglong\nstation (Observatory Code 327) of National Astronomical Observatory of China\nare analyzed. The predicted labels of these spectra using our ANN tool are\nfound to be reasonable when compared to their known taxonomic labels.\nConsidering the accuracy and stability, our ANN tool can be applied to analyse\nthe CSST asteroid spectra in the future.",
            "author": [
                "Nanping Luo",
                "Xiaobin Wang",
                "Shenghong Gu",
                "Antti Penttil\u00e4",
                "Karri Muinonen",
                "Yisi Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10954v1",
                "http://arxiv.org/pdf/2311.10954v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10953v1",
            "title": "HungerGist: An Interpretable Predictive Model for Food Insecurity",
            "updated": "2023-11-18T03:17:51Z",
            "published": "2023-11-18T03:17:51Z",
            "summary": "The escalating food insecurity in Africa, caused by factors such as war,\nclimate change, and poverty, demonstrates the critical need for advanced early\nwarning systems. Traditional methodologies, relying on expert-curated data\nencompassing climate, geography, and social disturbances, often fall short due\nto data limitations, hindering comprehensive analysis and potential discovery\nof new predictive factors. To address this, this paper introduces \"HungerGist\",\na multi-task deep learning model utilizing news texts and NLP techniques. Using\na corpus of over 53,000 news articles from nine African countries over four\nyears, we demonstrate that our model, trained solely on news data, outperforms\nthe baseline method trained on both traditional risk factors and human-curated\nkeywords. In addition, our method has the ability to detect critical texts that\ncontain interpretable signals known as \"gists.\" Moreover, our examination of\nthese gists indicates that this approach has the potential to reveal latent\nfactors that would otherwise remain concealed in unstructured texts.",
            "author": [
                "Yongsu Ahn",
                "Muheng Yan",
                "Yu-Ru Lin",
                "Zian Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10953v1",
                "http://arxiv.org/pdf/2311.10953v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10947v1",
            "title": "RecExplainer: Aligning Large Language Models for Recommendation Model\n  Interpretability",
            "updated": "2023-11-18T03:05:43Z",
            "published": "2023-11-18T03:05:43Z",
            "summary": "Recommender systems are widely used in various online services, with\nembedding-based models being particularly popular due to their expressiveness\nin representing complex signals. However, these models often lack\ninterpretability, making them less reliable and transparent for both users and\ndevelopers. With the emergence of large language models (LLMs), we find that\ntheir capabilities in language expression, knowledge-aware reasoning, and\ninstruction following are exceptionally powerful. Based on this, we propose a\nnew model interpretation approach for recommender systems, by using LLMs as\nsurrogate models and learn to mimic and comprehend target recommender models.\nSpecifically, we introduce three alignment methods: behavior alignment,\nintention alignment, and hybrid alignment. Behavior alignment operates in the\nlanguage space, representing user preferences and item information as text to\nlearn the recommendation model's behavior; intention alignment works in the\nlatent space of the recommendation model, using user and item representations\nto understand the model's behavior; hybrid alignment combines both language and\nlatent spaces for alignment training. To demonstrate the effectiveness of our\nmethods, we conduct evaluation from two perspectives: alignment effect, and\nexplanation generation ability on three public datasets. Experimental results\nindicate that our approach effectively enables LLMs to comprehend the patterns\nof recommendation models and generate highly credible recommendation\nexplanations.",
            "author": [
                "Yuxuan Lei",
                "Jianxun Lian",
                "Jing Yao",
                "Xu Huang",
                "Defu Lian",
                "Xing Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10947v1",
                "http://arxiv.org/pdf/2311.10947v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10943v1",
            "title": "Partially Randomizing Transformer Weights for Dialogue Response\n  Diversity",
            "updated": "2023-11-18T02:40:11Z",
            "published": "2023-11-18T02:40:11Z",
            "summary": "Despite recent progress in generative open-domain dialogue, the issue of low\nresponse diversity persists. Prior works have addressed this issue via either\nnovel objective functions, alternative learning approaches such as variational\nframeworks, or architectural extensions such as the Randomized Link (RL)\nTransformer. However, these approaches typically entail either additional\ndifficulties during training/inference, or a significant increase in model size\nand complexity. Hence, we propose the \\underline{Pa}rtially\n\\underline{Ra}ndomized trans\\underline{Former} (PaRaFormer), a simple extension\nof the transformer which involves freezing the weights of selected layers after\nrandom initialization. Experimental results reveal that the performance of the\nPaRaformer is comparable to that of the aforementioned approaches, despite not\nentailing any additional training difficulty or increase in model complexity.",
            "author": [
                "Jing Yang Lee",
                "Kong Aik Lee",
                "Woon-Seng Gan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10943v1",
                "http://arxiv.org/pdf/2311.10943v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10940v1",
            "title": "Practical Estimation of Ensemble Accuracy",
            "updated": "2023-11-18T02:31:36Z",
            "published": "2023-11-18T02:31:36Z",
            "summary": "Ensemble learning combines several individual models to obtain better\ngeneralization performance. In this work we present a practical method for\nestimating the joint power of several classifiers which differs from existing\napproaches by {\\em not relying on labels}, hence enabling the work in\nunsupervised setting of huge datasets. It differs from existing methods which\ndefine a \"diversity measure\".\n  The heart of the method is a combinatorial bound on the number of mistakes\nthe ensemble is likely to make. The bound can be efficiently approximated in\ntime linear in the number of samples. Thus allowing an efficient search for a\ncombination of classifiers that are likely to produce higher joint accuracy.\nMoreover, having the bound applicable to unlabeled data makes it both accurate\nand practical in modern setting of unsupervised learning. We demonstrate the\nmethod on popular large-scale face recognition datasets which provide a useful\nplayground for fine-grain classification tasks using noisy data over many\nclasses.\n  The proposed framework fits neatly in trending practices of unsupervised\nlearning. It is a measure of the inherent independence of a set of classifiers\nnot relying on extra information such as another classifier or labeled data.",
            "author": [
                "Simi Haber",
                "Yonatan Wexler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10940v1",
                "http://arxiv.org/pdf/2311.10940v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10937v1",
            "title": "Bridging Data-Driven and Knowledge-Driven Approaches for Safety-Critical\n  Scenario Generation in Automated Vehicle Validation",
            "updated": "2023-11-18T02:11:14Z",
            "published": "2023-11-18T02:11:14Z",
            "summary": "Automated driving vehicles~(ADV) promise to enhance driving efficiency and\nsafety, yet they face intricate challenges in safety-critical scenarios. As a\nresult, validating ADV within generated safety-critical scenarios is essential\nfor both development and performance evaluations. This paper investigates the\ncomplexities of employing two major scenario-generation solutions: data-driven\nand knowledge-driven methods. Data-driven methods derive scenarios from\nrecorded datasets, efficiently generating scenarios by altering the existing\nbehavior or trajectories of traffic participants but often falling short in\nconsidering ADV perception; knowledge-driven methods provide effective coverage\nthrough expert-designed rules, but they may lead to inefficiency in generating\nsafety-critical scenarios within that coverage. To overcome these challenges,\nwe introduce BridgeGen, a safety-critical scenario generation framework,\ndesigned to bridge the benefits of both methodologies. Specifically, by\nutilizing ontology-based techniques, BridgeGen models the five scenario layers\nin the operational design domain (ODD) from knowledge-driven methods, ensuring\nbroad coverage, and incorporating data-driven strategies to efficiently\ngenerate safety-critical scenarios. An optimized scenario generation toolkit is\ndeveloped within BridgeGen. This expedites the crafting of safety-critical\nscenarios through a combination of traditional optimization and reinforcement\nlearning schemes. Extensive experiments conducted using Carla simulator\ndemonstrate the effectiveness of BridgeGen in generating diverse\nsafety-critical scenarios.",
            "author": [
                "Kunkun Hao",
                "Lu Liu",
                "Wen Cui",
                "Jianxing Zhang",
                "Songyang Yan",
                "Yuxi Pan",
                "Zijiang Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10937v1",
                "http://arxiv.org/pdf/2311.10937v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10935v1",
            "title": "Short-term Volatility Estimation for High Frequency Trades using\n  Gaussian processes (GPs)",
            "updated": "2023-11-18T02:03:48Z",
            "published": "2023-11-18T02:03:48Z",
            "summary": "The fundamental theorem behind financial markets is that stock prices are\nintrinsically complex and stochastic. One of the complexities is the volatility\nassociated with stock prices. Volatility is a tendency for prices to change\nunexpectedly [1]. Price volatility is often detrimental to the return\neconomics, and thus, investors should factor it in whenever making investment\ndecisions, choices, and temporal or permanent moves. It is, therefore, crucial\nto make necessary and regular short and long-term stock price volatility\nforecasts for the safety and economics of investors returns. These forecasts\nshould be accurate and not misleading. Different models and methods, such as\nARCH GARCH models, have been intuitively implemented to make such forecasts.\nHowever, such traditional means fail to capture the short-term volatility\nforecasts effectively. This paper, therefore, investigates and implements a\ncombination of numeric and probabilistic models for short-term volatility and\nreturn forecasting for high-frequency trades. The essence is that one-day-ahead\nvolatility forecasts were made with Gaussian Processes (GPs) applied to the\noutputs of a Numerical market prediction (NMP) model. Firstly, the stock price\ndata from NMP was corrected by a GP. Since it is not easy to set price limits\nin a market due to its free nature and randomness, a Censored GP was used to\nmodel the relationship between the corrected stock prices and returns.\nForecasting errors were evaluated using the implied and estimated data.",
            "author": [
                "Leonard Mushunje",
                "Maxwell Mashasha",
                "Edina Chandiwana"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10935v1",
                "http://arxiv.org/pdf/2311.10935v1"
            ],
            "primary_category": "q-fin.ST",
            "category": [
                "q-fin.ST",
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10933v1",
            "title": "Representing visual classification as a linear combination of words",
            "updated": "2023-11-18T02:00:20Z",
            "published": "2023-11-18T02:00:20Z",
            "summary": "Explainability is a longstanding challenge in deep learning, especially in\nhigh-stakes domains like healthcare. Common explainability methods highlight\nimage regions that drive an AI model's decision. Humans, however, heavily rely\non language to convey explanations of not only \"where\" but \"what\".\nAdditionally, most explainability approaches focus on explaining individual AI\npredictions, rather than describing the features used by an AI model in\ngeneral. The latter would be especially useful for model and dataset auditing,\nand potentially even knowledge generation as AI is increasingly being used in\nnovel tasks. Here, we present an explainability strategy that uses a\nvision-language model to identify language-based descriptors of a visual\nclassification task. By leveraging a pre-trained joint embedding space between\nimages and text, our approach estimates a new classification task as a linear\ncombination of words, resulting in a weight for each word that indicates its\nalignment with the vision-based classifier. We assess our approach using two\nmedical imaging classification tasks, where we find that the resulting\ndescriptors largely align with clinical knowledge despite a lack of\ndomain-specific language training. However, our approach also identifies the\npotential for 'shortcut connections' in the public datasets used. Towards a\nfunctional measure of explainability, we perform a pilot reader study where we\nfind that the AI-identified words can enable non-expert humans to perform a\nspecialized medical task at a non-trivial level. Altogether, our results\nemphasize the potential of using multimodal foundational models to deliver\nintuitive, language-based explanations of visual tasks.",
            "author": [
                "Shobhit Agarwal",
                "Yevgeniy R. Semenov",
                "William Lotter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10933v1",
                "http://arxiv.org/pdf/2311.10933v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.CV",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10927v1",
            "title": "Near-Optimal Fair Resource Allocation for Strategic Agents without\n  Money: A Data-Driven Approach",
            "updated": "2023-11-18T01:21:54Z",
            "published": "2023-11-18T01:21:54Z",
            "summary": "We study learning-based design of fair allocation mechanisms for divisible\nresources, using proportional fairness (PF) as a benchmark. The learning\nsetting is a significant departure from the classic mechanism design\nliterature, in that, we need to learn fair mechanisms solely from data. In\nparticular, we consider the challenging problem of learning one-shot allocation\nmechanisms -- without the use of money -- that incentivize strategic agents to\nbe truthful when reporting their valuations. It is well-known that the\nmechanism that directly seeks to optimize PF is not incentive compatible,\nmeaning that the agents can potentially misreport their preferences to gain\nincreased allocations. We introduce the notion of \"exploitability\" of a\nmechanism to measure the relative gain in utility from misreport, and make the\nfollowing important contributions in the paper: (i) Using sophisticated\ntechniques inspired by differentiable convex programming literature, we design\na numerically efficient approach for computing the exploitability of the PF\nmechanism. This novel contribution enables us to quantify the gap that needs to\nbe bridged to approximate PF via incentive compatible mechanisms. (ii) Next, we\nmodify the PF mechanism to introduce a trade-off between fairness and\nexploitability. By properly controlling this trade-off using data, we show that\nour proposed mechanism, ExPF-Net, provides a strong approximation to the PF\nmechanism while maintaining low exploitability. This mechanism, however, comes\nwith a high computational cost. (iii) To address the computational challenges,\nwe propose another mechanism ExS-Net, which is end-to-end parameterized by a\nneural network. ExS-Net enjoys similar (slightly inferior) performance and\nsignificantly accelerated training and inference time performance. (iv)\nExtensive numerical simulations demonstrate the robustness and efficacy of the\nproposed mechanisms.",
            "author": [
                "Sihan Zeng",
                "Sujay Bhatt",
                "Eleonora Kreacic",
                "Parisa Hassanzadeh",
                "Alec Koppel",
                "Sumitra Ganesh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10927v1",
                "http://arxiv.org/pdf/2311.10927v1"
            ],
            "primary_category": "cs.GT",
            "category": [
                "cs.GT",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12871v1",
            "title": "An Embodied Generalist Agent in 3D World",
            "updated": "2023-11-18T01:21:38Z",
            "published": "2023-11-18T01:21:38Z",
            "summary": "Leveraging massive knowledge and learning schemes from large language models\n(LLMs), recent machine learning models show notable successes in building\ngeneralist agents that exhibit the capability of general-purpose task solving\nin diverse domains, including natural language processing, computer vision, and\nrobotics. However, a significant challenge remains as these models exhibit\nlimited ability in understanding and interacting with the 3D world. We argue\nthis limitation significantly hinders the current models from performing\nreal-world tasks and further achieving general intelligence. To this end, we\nintroduce an embodied multi-modal and multi-task generalist agent that excels\nin perceiving, grounding, reasoning, planning, and acting in the 3D world. Our\nproposed agent, referred to as LEO, is trained with shared LLM-based model\narchitectures, objectives, and weights in two stages: (i) 3D vision-language\nalignment and (ii) 3D vision-language-action instruction tuning. To facilitate\nthe training, we meticulously curate and generate an extensive dataset\ncomprising object-level and scene-level multi-modal tasks with exceeding scale\nand complexity, necessitating a deep understanding of and interaction with the\n3D world. Through rigorous experiments, we demonstrate LEO's remarkable\nproficiency across a wide spectrum of tasks, including 3D captioning, question\nanswering, embodied reasoning, embodied navigation, and robotic manipulation.\nOur ablation results further provide valuable insights for the development of\nfuture embodied generalist agents.",
            "author": [
                "Jiangyong Huang",
                "Silong Yong",
                "Xiaojian Ma",
                "Xiongkun Linghu",
                "Puhao Li",
                "Yan Wang",
                "Qing Li",
                "Song-Chun Zhu",
                "Baoxiong Jia",
                "Siyuan Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12871v1",
                "http://arxiv.org/pdf/2311.12871v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10926v1",
            "title": "Finding the Needle in a Haystack: Detecting Bug Occurrences in Gameplay\n  Videos",
            "updated": "2023-11-18T01:14:18Z",
            "published": "2023-11-18T01:14:18Z",
            "summary": "The presence of bugs in video games can bring significant consequences for\ndevelopers. To avoid these consequences, developers can leverage gameplay\nvideos to identify and fix these bugs. Video hosting websites such as YouTube\nprovide access to millions of game videos, including videos that depict bug\noccurrences, but the large amount of content can make finding bug instances\nchallenging. We present an automated approach that uses machine learning to\npredict whether a segment of a gameplay video contains the depiction of a bug.\nWe analyzed 4,412 segments of 198 gameplay videos to predict whether a segment\ncontains an instance of a bug. Additionally, we investigated how our approach\nperforms when applied across different specific genres of video games and on\nvideos from the same game. We also analyzed the videos in the dataset to\ninvestigate what characteristics of the visual features might explain the\nclassifier's prediction. Finally, we conducted a user study to examine the\nbenefits of our automated approach against a manual analysis. Our findings\nindicate that our approach is effective at detecting segments of a video that\ncontain bugs, achieving a high F1 score of 0.88, outperforming the current\nstate-of-the-art technique for bug classification of gameplay video segments.",
            "author": [
                "Andrew Truelove",
                "Shiyue Rong",
                "Eduardo Santana de Almeida",
                "Iftekhar Ahmed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10926v1",
                "http://arxiv.org/pdf/2311.10926v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10921v1",
            "title": "Compact and Intuitive Airfoil Parameterization Method through\n  Physics-aware Variational Autoencoder",
            "updated": "2023-11-18T00:30:03Z",
            "published": "2023-11-18T00:30:03Z",
            "summary": "Airfoil shape optimization plays a critical role in the design of\nhigh-performance aircraft. However, the high-dimensional nature of airfoil\nrepresentation causes the challenging problem known as the \"curse of\ndimensionality\". To overcome this problem, numerous airfoil parameterization\nmethods have been developed, which can be broadly classified as\npolynomial-based and data-driven approaches. Each of these methods has\ndesirable characteristics such as flexibility, parsimony, feasibility, and\nintuitiveness, but a single approach that encompasses all of these attributes\nhas yet to be found. For example, polynomial-based methods struggle to balance\nparsimony and flexibility, while data-driven methods lack in feasibility and\nintuitiveness. In recent years, generative models, such as generative\nadversarial networks and variational autoencoders, have shown promising\npotential in airfoil parameterization. However, these models still face\nchallenges related to intuitiveness due to their black-box nature. To address\nthis issue, we developed a novel airfoil parameterization method using\nphysics-aware variational autoencoder. The proposed method not only explicitly\nseparates the generation of thickness and camber distributions to produce\nsmooth and non-intersecting airfoils, thereby improving feasibility, but it\nalso directly aligns its latent dimensions with geometric features of the\nairfoil, significantly enhancing intuitiveness. Finally, extensive comparative\nstudies were performed to demonstrate the effectiveness of our approach.",
            "author": [
                "Yu-Eop Kang",
                "Dawoon Lee",
                "Kwanjung Yee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10921v1",
                "http://arxiv.org/pdf/2311.10921v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10919v1",
            "title": "PACOL: Poisoning Attacks Against Continual Learners",
            "updated": "2023-11-18T00:20:57Z",
            "published": "2023-11-18T00:20:57Z",
            "summary": "Continual learning algorithms are typically exposed to untrusted sources that\ncontain training data inserted by adversaries and bad actors. An adversary can\ninsert a small number of poisoned samples, such as mislabeled samples from\npreviously learned tasks, or intentional adversarial perturbed samples, into\nthe training datasets, which can drastically reduce the model's performance. In\nthis work, we demonstrate that continual learning systems can be manipulated by\nmalicious misinformation and present a new category of data poisoning attacks\nspecific for continual learners, which we refer to as {\\em Poisoning Attacks\nAgainst Continual Learners} (PACOL). The effectiveness of labeling flipping\nattacks inspires PACOL; however, PACOL produces attack samples that do not\nchange the sample's label and produce an attack that causes catastrophic\nforgetting. A comprehensive set of experiments shows the vulnerability of\ncommonly used generative replay and regularization-based continual learning\napproaches against attack methods. We evaluate the ability of label-flipping\nand a new adversarial poison attack, namely PACOL proposed in this work, to\nforce the continual learning system to forget the knowledge of a learned\ntask(s). More specifically, we compared the performance degradation of\ncontinual learning systems trained on benchmark data streams with and without\npoisoning attacks. Moreover, we discuss the stealthiness of the attacks in\nwhich we test the success rate of data sanitization defense and other outlier\ndetection-based defenses for filtering out adversarial samples.",
            "author": [
                "Huayu Li",
                "Gregory Ditzler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10919v1",
                "http://arxiv.org/pdf/2311.10919v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10910v1",
            "title": "GAN-supervised Seismic Data Reconstruction: An Enhanced-Learning for\n  Improved Generalization",
            "updated": "2023-11-17T23:35:34Z",
            "published": "2023-11-17T23:35:34Z",
            "summary": "Seismic data interpolation plays a crucial role in subsurface imaging,\nenabling accurate analysis and interpretation throughout the seismic processing\nworkflow. Despite the widespread exploration of deep supervised learning\nmethods for seismic data reconstruction, several challenges still remain open.\nParticularly, the requirement of extensive training data and poor domain\ngeneralization due to the seismic survey's variability poses significant\nissues. To overcome these limitations, this paper introduces a\ndeep-learning-based seismic data reconstruction approach that leverages data\nredundancy. This method involves a two-stage training process. First, an\nadversarial generative network (GAN) is trained using synthetic seismic data,\nenabling the extraction and learning of their primary and local seismic\ncharacteristics. Second, a reconstruction network is trained with synthetic\ndata generated by the GAN, which dynamically adjusts the noise and distortion\nlevel at each epoch to promote feature diversity. This approach enhances the\ngeneralization capabilities of the reconstruction network by allowing control\nover the generation of seismic patterns from the latent space of the GAN,\nthereby reducing the dependency on large seismic databases. Experimental\nresults on field and synthetic seismic datasets both pre-stack and post-stack\nshow that the proposed method outperforms the baseline supervised learning and\nunsupervised approaches such as deep seismic prior and internal learning, by up\nto 8 dB of PSNR.",
            "author": [
                "Paul Goyes-Penafiel",
                "Leon Suarez-Rodriguez",
                "Claudia Correa",
                "Henry Arguello"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10910v1",
                "http://arxiv.org/pdf/2311.10910v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10908v1",
            "title": "Equivariant Neural Operator Learning with Graphon Convolution",
            "updated": "2023-11-17T23:28:22Z",
            "published": "2023-11-17T23:28:22Z",
            "summary": "We propose a general architecture that combines the coefficient learning\nscheme with a residual operator layer for learning mappings between continuous\nfunctions in the 3D Euclidean space. Our proposed model is guaranteed to\nachieve SE(3)-equivariance by design. From the graph spectrum view, our method\ncan be interpreted as convolution on graphons (dense graphs with infinitely\nmany nodes), which we term InfGCN. By leveraging both the continuous graphon\nstructure and the discrete graph structure of the input data, our model can\neffectively capture the geometric information while preserving equivariance.\nThrough extensive experiments on large-scale electron density datasets, we\nobserved that our model significantly outperformed the current state-of-the-art\narchitectures. Multiple ablation studies were also carried out to demonstrate\nthe effectiveness of the proposed architecture.",
            "author": [
                "Chaoran Cheng",
                "Jian Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10908v1",
                "http://arxiv.org/pdf/2311.10908v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10906v1",
            "title": "Thermodynamic Susceptibilities for a Unitary Fermi Gas",
            "updated": "2023-11-17T23:05:35Z",
            "published": "2023-11-17T23:05:35Z",
            "summary": "The unitary Fermi gas provides a unique window into both cold atom\nexperiments and neutron star properties. There are major challenges in\ndetermining the physical properties within a neutron star, both experimentally\nand theoretically. However, there is a region within the crust of a neutron\nstar that resembles a gas of fermions that is recreated in a cold atom\nlaboratory. This is the so-called unitary Fermi gas characterized by a large\nnegative scattering length and small effective range. We set out to calculate\nfrom first principles certain transport coefficients that appear at second\norder in the hydrodynamic expansion. These particular transport coefficients\nare obtained from two point correlation functions in flat space that do not\nrequire analytic continuation from Euclidean to Minkowski space. We are\nmotivated by the potential to learn about neutron star properties from cold\natom experiments.",
            "author": [
                "Max Weiner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10906v1",
                "http://arxiv.org/pdf/2311.10906v1"
            ],
            "primary_category": "nucl-th",
            "category": [
                "nucl-th"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10904v1",
            "title": "Closely-Spaced Object Classification Using MuyGPyS",
            "updated": "2023-11-17T22:52:46Z",
            "published": "2023-11-17T22:52:46Z",
            "summary": "Accurately detecting rendezvous and proximity operations (RPO) is crucial for\nunderstanding how objects are behaving in the space domain. However, detecting\nclosely-spaced objects (CSO) is challenging for ground-based optical space\ndomain awareness (SDA) algorithms as two objects close together along the\nline-of-sight can appear blended as a single object within the point-spread\nfunction (PSF) of the optical system. Traditional machine learning methods can\nbe useful for differentiating between singular objects and closely-spaced\nobjects, but many methods require large training sample sizes or high\nsignal-to-noise conditions. The quality and quantity of realistic data make\nprobabilistic classification methods a superior approach, as they are better\nsuited to handle these data inadequacies. We present CSO classification results\nusing the Gaussian process python package, MuyGPyS, and examine classification\naccuracy as a function of angular separation and magnitude difference between\nthe simulated satellites. This orbit-independent analysis is done on highly\naccurate simulated SDA images that emulate realistic ground-based\ncommercial-of-the-shelf (COTS) optical sensor observations of CSOs. We find\nthat MuyGPyS outperforms traditional machine learning methods, especially under\nmore challenging circumstances.",
            "author": [
                "Kerianne Pruett",
                "Nathan McNaughton",
                "Michael Schneider"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10904v1",
                "http://arxiv.org/pdf/2311.10904v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "physics.data-an",
                "physics.ins-det"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12045v1",
            "title": "Using Guided Transfer Learning to Predispose AI Agent to Learn\n  Efficiently from Small RNA-sequencing Datasets",
            "updated": "2023-11-17T22:47:46Z",
            "published": "2023-11-17T22:47:46Z",
            "summary": "Given the increasing availability of RNA-seq data and its complex and\nheterogeneous nature, there has been growing interest in applying AI/machine\nlearning methodologies to work with such data modalities. However, because\nomics data is characterized by high dimensionality and low sample size (HDLSS),\ncurrent attempts at integrating AI in this domain require significant human\nguidance and expertise to mitigate overfitting. In this work we look at how\ntransfer learning can be improved to learn from small RNA-seq sample sizes\nwithout significant human interference. The strategy is to gain general prior\nknowledge about a particular domain of data (e.g. RNA-seq data) by pre-training\non a general task with a large aggregate of data, then fine-tuning to various\nspecific, downstream target tasks in the same domain. Because previous attempts\nhave shown traditional transfer learning failing on HLDSS, we propose to\nimprove performance by using Guided Transfer Learning (GTL). Collaborating with\nRobots Go Mental, the AI we deploy here not only learns good initial parameters\nduring pre-training, but also learns inductive biases that affect how the AI\nlearns downstream tasks. In this approach, we first pre-trained on recount3\ndata, a collection of over 400,000 mouse RNA-seq samples sourced from thousands\nof individual studies. With such a large collection, patterns of expression\nbetween the ~30,000 genes in mammalian systems were pre-determined. Such\npatterns were sufficient for the pre-trained AI agent to efficiently learn new\ndownstream tasks involving RNA-seq datasets with very low sample sizes and\nperformed notably better on few-shot learning tasks compared to the same model\nwithout pre-training.",
            "author": [
                "Kevin Li",
                "Danko Nikoli\u0107",
                "Vjekoslav Nikoli\u0107",
                "Davor Andri\u0107",
                "Lauren M. Sanders",
                "Sylvain V. Costes"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12045v1",
                "http://arxiv.org/pdf/2311.12045v1"
            ],
            "primary_category": "q-bio.GN",
            "category": [
                "q-bio.GN"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10900v1",
            "title": "A powerful rank-based correction to multiple testing under positive\n  dependency",
            "updated": "2023-11-17T22:44:22Z",
            "published": "2023-11-17T22:44:22Z",
            "summary": "We develop a novel multiple hypothesis testing correction with family-wise\nerror rate (FWER) control that efficiently exploits positive dependencies\nbetween potentially correlated statistical hypothesis tests. Our proposed\nalgorithm $\\texttt{max-rank}$ is conceptually straight-forward, relying on the\nuse of a $\\max$-operator in the rank domain of computed test statistics. We\ncompare our approach to the frequently employed Bonferroni correction,\ntheoretically and empirically demonstrating its superiority over Bonferroni in\nthe case of existing positive dependency, and its equivalence otherwise. Our\nadvantage over Bonferroni increases as the number of tests rises, and we\nmaintain high statistical power whilst ensuring FWER control. We specifically\nframe our algorithm in the context of parallel permutation testing, a scenario\nthat arises in our primary application of conformal prediction, a recently\npopularized approach for quantifying uncertainty in complex predictive\nsettings.",
            "author": [
                "Alexander Timans",
                "Christoph-Nikolas Straehle",
                "Kaspar Sakmann",
                "Eric Nalisnick"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10900v1",
                "http://arxiv.org/pdf/2311.10900v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10899v2",
            "title": "Extraction and Summarization of Explicit Video Content using Multi-Modal\n  Deep Learning",
            "updated": "2023-11-21T02:16:27Z",
            "published": "2023-11-17T22:44:05Z",
            "summary": "With the increase in video-sharing platforms across the internet, it is\ndifficult for humans to moderate the data for explicit content. Hence, an\nautomated pipeline to scan through video data for explicit content has become\nthe need of the hour. We propose a novel pipeline that uses multi-modal deep\nlearning to first extract the explicit segments of input videos and then\nsummarize their content using text to determine its age appropriateness and age\nrating. We also evaluate our pipeline's effectiveness in the end using standard\nmetrics.",
            "author": [
                "Shaunak Joshi",
                "Raghav Gaggar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10899v2",
                "http://arxiv.org/pdf/2311.10899v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG",
                "I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10892v1",
            "title": "The Hidden Linear Structure in Score-Based Models and its Application",
            "updated": "2023-11-17T22:25:07Z",
            "published": "2023-11-17T22:25:07Z",
            "summary": "Score-based models have achieved remarkable results in the generative\nmodeling of many domains. By learning the gradient of smoothed data\ndistribution, they can iteratively generate samples from complex distribution\ne.g. natural images.\n  However, is there any universal structure in the gradient field that will\neventually be learned by any neural network? Here, we aim to find such\nstructures through a normative analysis of the score function.\n  First, we derived the closed-form solution to the scored-based model with a\nGaussian score. We claimed that for well-trained diffusion models, the learned\nscore at a high noise scale is well approximated by the linear score of\nGaussian. We demonstrated this through empirical validation of pre-trained\nimages diffusion model and theoretical analysis of the score function. This\nfinding enabled us to precisely predict the initial diffusion trajectory using\nthe analytical solution and to accelerate image sampling by 15-30\\% by skipping\nthe initial phase without sacrificing image quality. Our finding of the linear\nstructure in the score-based model has implications for better model design and\ndata pre-processing.",
            "author": [
                "Binxu Wang",
                "John J. Vastola"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10892v1",
                "http://arxiv.org/pdf/2311.10892v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG",
                "cs.NA",
                "cs.NE",
                "math.NA",
                "stat.CO",
                "I.3.3; I.5.1; G.1.7; I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00030v1",
            "title": "Artificial Intelligence in Sustainable Vertical Farming",
            "updated": "2023-11-17T22:15:41Z",
            "published": "2023-11-17T22:15:41Z",
            "summary": "As global challenges of population growth, climate change, and resource\nscarcity intensify, the agricultural landscape is at a critical juncture.\nSustainable vertical farming emerges as a transformative solution to address\nthese challenges by maximizing crop yields in controlled environments. This\nparadigm shift necessitates the integration of cutting-edge technologies, with\nArtificial Intelligence (AI) at the forefront. The paper provides a\ncomprehensive exploration of the role of AI in sustainable vertical farming,\ninvestigating its potential, challenges, and opportunities. The review\nsynthesizes the current state of AI applications, encompassing machine\nlearning, computer vision, the Internet of Things (IoT), and robotics, in\noptimizing resource usage, automating tasks, and enhancing decision-making. It\nidentifies gaps in research, emphasizing the need for optimized AI models,\ninterdisciplinary collaboration, and the development of explainable AI in\nagriculture. The implications extend beyond efficiency gains, considering\neconomic viability, reduced environmental impact, and increased food security.\nThe paper concludes by offering insights for stakeholders and suggesting\navenues for future research, aiming to guide the integration of AI technologies\nin sustainable vertical farming for a resilient and sustainable future in\nagriculture.",
            "author": [
                "Hribhu Chowdhury",
                "Debo Brata Paul Argha",
                "Md Ashik Ahmed"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00030v1",
                "http://arxiv.org/pdf/2312.00030v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10887v1",
            "title": "Point Cloud Self-supervised Learning via 3D to Multi-view Masked\n  Autoencoder",
            "updated": "2023-11-17T22:10:03Z",
            "published": "2023-11-17T22:10:03Z",
            "summary": "In recent years, the field of 3D self-supervised learning has witnessed\nsignificant progress, resulting in the emergence of Multi-Modality Masked\nAutoEncoders (MAE) methods that leverage both 2D images and 3D point clouds for\npre-training. However, a notable limitation of these approaches is that they do\nnot fully utilize the multi-view attributes inherent in 3D point clouds, which\nis crucial for a deeper understanding of 3D structures. Building upon this\ninsight, we introduce a novel approach employing a 3D to multi-view masked\nautoencoder to fully harness the multi-modal attributes of 3D point clouds. To\nbe specific, our method uses the encoded tokens from 3D masked point clouds to\ngenerate original point clouds and multi-view depth images across various\nposes. This approach not only enriches the model's comprehension of geometric\nstructures but also leverages the inherent multi-modal properties of point\nclouds. Our experiments illustrate the effectiveness of the proposed method for\ndifferent tasks and under different settings. Remarkably, our method\noutperforms state-of-the-art counterparts by a large margin in a variety of\ndownstream tasks, including 3D object classification, few-shot learning, part\nsegmentation, and 3D object detection. Code will be available at:\nhttps://github.com/Zhimin-C/Multiview-MAE",
            "author": [
                "Zhimin Chen",
                "Yingwei Li",
                "Longlong Jing",
                "Liang Yang",
                "Bing Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10887v1",
                "http://arxiv.org/pdf/2311.10887v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10886v1",
            "title": "A Whole New Ball Game: A Primal Accelerated Method for Matrix Games and\n  Minimizing the Maximum of Smooth Functions",
            "updated": "2023-11-17T22:07:18Z",
            "published": "2023-11-17T22:07:18Z",
            "summary": "We design algorithms for minimizing $\\max_{i\\in[n]} f_i(x)$ over a\n$d$-dimensional Euclidean or simplex domain. When each $f_i$ is $1$-Lipschitz\nand $1$-smooth, our method computes an $\\epsilon$-approximate solution using\n$\\widetilde{O}(n \\epsilon^{-1/3} + \\epsilon^{-2})$ gradient and function\nevaluations, and $\\widetilde{O}(n \\epsilon^{-4/3})$ additional runtime. For\nlarge $n$, our evaluation complexity is optimal up to polylogarithmic factors.\nIn the special case where each $f_i$ is linear -- which corresponds to finding\na near-optimal primal strategy in a matrix game -- our method finds an\n$\\epsilon$-approximate solution in runtime $\\widetilde{O}(n (d/\\epsilon)^{2/3}\n+ nd + d\\epsilon^{-2})$. For $n>d$ and $\\epsilon=1/\\sqrt{n}$ this improves over\nall existing first-order methods. When additionally $d = \\omega(n^{8/11})$ our\nruntime also improves over all known interior point methods.\n  Our algorithm combines three novel primitives: (1) A dynamic data structure\nwhich enables efficient stochastic gradient estimation in small $\\ell_2$ or\n$\\ell_1$ balls. (2) A mirror descent algorithm tailored to our data structure\nimplementing an oracle which minimizes the objective over these balls. (3) A\nsimple ball oracle acceleration framework suitable for non-Euclidean geometry.",
            "author": [
                "Yair Carmon",
                "Arun Jambulapati",
                "Yujia Jin",
                "Aaron Sidford"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10886v1",
                "http://arxiv.org/pdf/2311.10886v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10879v1",
            "title": "Pre- to Post-Contrast Breast MRI Synthesis for Enhanced Tumour\n  Segmentation",
            "updated": "2023-11-17T21:48:41Z",
            "published": "2023-11-17T21:48:41Z",
            "summary": "Despite its benefits for tumour detection and treatment, the administration\nof contrast agents in dynamic contrast-enhanced MRI (DCE-MRI) is associated\nwith a range of issues, including their invasiveness, bioaccumulation, and a\nrisk of nephrogenic systemic fibrosis. This study explores the feasibility of\nproducing synthetic contrast enhancements by translating pre-contrast\nT1-weighted fat-saturated breast MRI to their corresponding first DCE-MRI\nsequence leveraging the capabilities of a generative adversarial network (GAN).\nAdditionally, we introduce a Scaled Aggregate Measure (SAMe) designed for\nquantitatively evaluating the quality of synthetic data in a principled manner\nand serving as a basis for selecting the optimal generative model. We assess\nthe generated DCE-MRI data using quantitative image quality metrics and apply\nthem to the downstream task of 3D breast tumour segmentation. Our results\nhighlight the potential of post-contrast DCE-MRI synthesis in enhancing the\nrobustness of breast tumour segmentation models via data augmentation. Our code\nis available at https://github.com/RichardObi/pre_post_synthesis.",
            "author": [
                "Richard Osuala",
                "Smriti Joshi",
                "Apostolia Tsirikoglou",
                "Lidia Garrucho",
                "Walter H. L. Pinaya",
                "Oliver Diaz",
                "Karim Lekadir"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10879v1",
                "http://arxiv.org/pdf/2311.10879v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10876v1",
            "title": "MSPB: a longitudinal multi-sensor dataset with phenotypic trait\n  measurements from honey bees",
            "updated": "2023-11-17T21:35:09Z",
            "published": "2023-11-17T21:35:09Z",
            "summary": "We present a longitudinal multi-sensor dataset collected from honey bee\ncolonies (Apis mellifera) with rich phenotypic measurements. Data were\ncontinuously collected between May-2020 and April-2021 from 53 hives located at\ntwo apiaries in Qu\\'ebec, Canada. The sensor data included audio features,\ntemperature, and relative humidity. The phenotypic measurements contained\nbeehive population, number of brood cells (eggs, larva and pupa), Varroa\ndestructor infestation levels, defensive and hygienic behaviors, honey yield,\nand winter mortality. Our study is amongst the first to provide a wide variety\nof phenotypic trait measurements annotated by apicultural science experts,\nwhich facilitate a broader scope of analysis. We first summarize the data\ncollection procedure, sensor data pre-processing steps, and data composition.\nWe then provide an overview of the phenotypic data distribution as well as a\nvisualization of the sensor data patterns. Lastly, we showcase several hive\nmonitoring applications based on sensor data analysis and machine learning,\nsuch as winter mortality prediction, hive population estimation, and the\npresence of an active and laying queen.",
            "author": [
                "Yi Zhu",
                "Mahsa Abdollahi",
                "S\u00e9gol\u00e8ne Maucourt",
                "Nico Coallier",
                "Heitor R. Guimar\u00e3es",
                "Pierre Giovenazzo",
                "Tiago H. Falk"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10876v1",
                "http://arxiv.org/pdf/2311.10876v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10873v1",
            "title": "Multi-entity Video Transformers for Fine-Grained Video Representation\n  Learning",
            "updated": "2023-11-17T21:23:12Z",
            "published": "2023-11-17T21:23:12Z",
            "summary": "The area of temporally fine-grained video representation learning aims to\ngenerate frame-by-frame representations for temporally dense tasks. In this\nwork, we advance the state-of-the-art for this area by re-examining the design\nof transformer architectures for video representation learning. A salient\naspect of our self-supervised method is the improved integration of spatial\ninformation in the temporal pipeline by representing multiple entities per\nframe. Prior works use late fusion architectures that reduce frames to a single\ndimensional vector before any cross-frame information is shared, while our\nmethod represents each frame as a group of entities or tokens. Our Multi-entity\nVideo Transformer (MV-Former) architecture achieves state-of-the-art results on\nmultiple fine-grained video benchmarks. MV-Former leverages image features from\nself-supervised ViTs, and employs several strategies to maximize the utility of\nthe extracted features while also avoiding the need to fine-tune the complex\nViT backbone. This includes a Learnable Spatial Token Pooling strategy, which\nis used to identify and extract features for multiple salient regions per\nframe. Our experiments show that MV-Former not only outperforms previous\nself-supervised methods, but also surpasses some prior works that use\nadditional supervision or training data. When combined with additional\npre-training data from Kinetics-400, MV-Former achieves a further performance\nboost. The code for MV-Former is available at\nhttps://github.com/facebookresearch/video_rep_learning.",
            "author": [
                "Matthew Walmer",
                "Rose Kanjirathinkal",
                "Kai Sheng Tai",
                "Keyur Muzumdar",
                "Taipeng Tian",
                "Abhinav Shrivastava"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10873v1",
                "http://arxiv.org/pdf/2311.10873v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10869v2",
            "title": "Evolutionary algorithms as an alternative to backpropagation for\n  supervised training of Biophysical Neural Networks and Neural ODEs",
            "updated": "2023-11-21T02:49:07Z",
            "published": "2023-11-17T20:59:57Z",
            "summary": "Training networks consisting of biophysically accurate neuron models could\nallow for new insights into how brain circuits can organize and solve tasks. We\nbegin by analyzing the extent to which the central algorithm for neural network\nlearning -- stochastic gradient descent through backpropagation (BP) -- can be\nused to train such networks. We find that properties of biophysically based\nneural network models needed for accurate modelling such as stiffness, high\nnonlinearity and long evaluation timeframes relative to spike times makes BP\nunstable and divergent in a variety of cases. To address these instabilities\nand inspired by recent work, we investigate the use of \"gradient-estimating\"\nevolutionary algorithms (EAs) for training biophysically based neural networks.\nWe find that EAs have several advantages making them desirable over direct BP,\nincluding being forward-pass only, robust to noisy and rigid losses, allowing\nfor discrete loss formulations, and potentially facilitating a more global\nexploration of parameters. We apply our method to train a recurrent network of\nMorris-Lecar neuron models on a stimulus integration and working memory task,\nand show how it can succeed in cases where direct BP is inapplicable. To expand\non the viability of EAs in general, we apply them to a general neural ODE\nproblem and a stiff neural ODE benchmark and find again that EAs can\nout-perform direct BP here, especially for the over-parameterized regime. Our\nfindings suggest that biophysical neurons could provide useful benchmarks for\ntesting the limits of BP-adjacent methods, and demonstrate the viability of EAs\nfor training networks with complex components.",
            "author": [
                "James Hazelden",
                "Yuhan Helena Liu",
                "Eli Shlizerman",
                "Eric Shea-Brown"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10869v2",
                "http://arxiv.org/pdf/2311.10869v2"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10863v3",
            "title": "Verified Compositional Neuro-Symbolic Control for Stochastic Systems\n  with Temporal Logic Tasks",
            "updated": "2023-11-22T03:01:59Z",
            "published": "2023-11-17T20:51:24Z",
            "summary": "Several methods have been proposed recently to learn neural network (NN)\ncontrollers for autonomous agents, with unknown and stochastic dynamics, tasked\nwith complex missions captured by Linear Temporal Logic (LTL). Due to the\nsample-inefficiency of the majority of these works, compositional learning\nmethods have been proposed decomposing the LTL specification into smaller\nsub-tasks. Then, separate controllers are learned and composed to satisfy the\noriginal task. A key challenge within these approaches is that they often lack\nsafety guarantees or the provided guarantees are impractical. This paper aims\nto address this challenge. Particularly, we consider autonomous systems with\nunknown and stochastic dynamics and LTL-encoded tasks. We assume that the\nsystem is equipped with a finite set of base skills modeled by trained NN\nfeedback controllers. Our goal is to check if there exists a temporal\ncomposition of the trained NN controllers - and if so, to compute it - that\nwill yield a composite system behavior that satisfies the assigned LTL task\nwith probability one. We propose a new approach that relies on a novel\nintegration of automata theory and data-driven reachability analysis tools for\nNN-controlled stochastic systems. The resulting neuro-symbolic controller\nallows the agent to generate safe behaviors for unseen complex temporal logic\ntasks in a zero-shot fashion by leveraging its base skills. We show correctness\nof the proposed method and we provide conditions under which it is complete. To\nthe best of our knowledge, this is the first work that designs verified\ntemporal compositions of NN controllers for unknown and stochastic systems.\nFinally, we provide extensive numerical simulations and hardware experiments on\nrobot navigation tasks to demonstrate the proposed method.",
            "author": [
                "Jun Wang",
                "Haojun Chen",
                "Zihe Sun",
                "Yiannis Kantaros"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10863v3",
                "http://arxiv.org/pdf/2311.10863v3"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12043v1",
            "title": "Efficient Domain Adaptation via Generative Prior for 3D Infant Pose\n  Estimation",
            "updated": "2023-11-17T20:49:37Z",
            "published": "2023-11-17T20:49:37Z",
            "summary": "Although 3D human pose estimation has gained impressive development in recent\nyears, only a few works focus on infants, that have different bone lengths and\nalso have limited data. Directly applying adult pose estimation models\ntypically achieves low performance in the infant domain and suffers from\nout-of-distribution issues. Moreover, the limitation of infant pose data\ncollection also heavily constrains the efficiency of learning-based models to\nlift 2D poses to 3D. To deal with the issues of small datasets, domain\nadaptation and data augmentation are commonly used techniques. Following this\nparadigm, we take advantage of an optimization-based method that utilizes\ngenerative priors to predict 3D infant keypoints from 2D keypoints without the\nneed of large training data. We further apply a guided diffusion model to\ndomain adapt 3D adult pose to infant pose to supplement small datasets.\nBesides, we also prove that our method, ZeDO-i, could attain efficient domain\nadaptation, even if only a small number of data is given. Quantitatively, we\nclaim that our model attains state-of-the-art MPJPE performance of 43.6 mm on\nthe SyRIP dataset and 21.2 mm on the MINI-RGBD dataset.",
            "author": [
                "Zhuoran Zhou",
                "Zhongyu Jiang",
                "Wenhao Chai",
                "Cheng-Yen Yang",
                "Lei Li",
                "Jenq-Neng Hwang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12043v1",
                "http://arxiv.org/pdf/2311.12043v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10859v1",
            "title": "A Quadratic Speedup in Finding Nash Equilibria of Quantum Zero-Sum Games",
            "updated": "2023-11-17T20:38:38Z",
            "published": "2023-11-17T20:38:38Z",
            "summary": "Recent developments in domains such as non-local games, quantum interactive\nproofs, and quantum generative adversarial networks have renewed interest in\nquantum game theory and, specifically, quantum zero-sum games. Central to\nclassical game theory is the efficient algorithmic computation of Nash\nequilibria, which represent optimal strategies for both players. In 2008, Jain\nand Watrous proposed the first classical algorithm for computing equilibria in\nquantum zero-sum games using the Matrix Multiplicative Weight Updates (MMWU)\nmethod to achieve a convergence rate of $\\mathcal{O}(d/\\epsilon^2)$ iterations\nto $\\epsilon$-Nash equilibria in the $4^d$-dimensional spectraplex. In this\nwork, we propose a hierarchy of quantum optimization algorithms that generalize\nMMWU via an extra-gradient mechanism. Notably, within this proposed hierarchy,\nwe introduce the Optimistic Matrix Multiplicative Weights Update (OMMWU)\nalgorithm and establish its average-iterate convergence complexity as\n$\\mathcal{O}(d/\\epsilon)$ iterations to $\\epsilon$-Nash equilibria. This\nquadratic speed-up relative to Jain and Watrous' original algorithm sets a new\nbenchmark for computing $\\epsilon$-Nash equilibria in quantum zero-sum games.",
            "author": [
                "Francisca Vasconcelos",
                "Emmanouil-Vasileios Vlatakis-Gkaragkounis",
                "Panayotis Mertikopoulos",
                "Georgios Piliouras",
                "Michael I. Jordan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10859v1",
                "http://arxiv.org/pdf/2311.10859v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.GT",
                "cs.LG",
                "math.OC",
                "primary 91A05, 81Q93, secondary 68Q32, 91A26, 37N40,"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10857v1",
            "title": "WATUNet: A Deep Neural Network for Segmentation of Volumetric Sweep\n  Imaging Ultrasound",
            "updated": "2023-11-17T20:32:37Z",
            "published": "2023-11-17T20:32:37Z",
            "summary": "Objective. Limited access to breast cancer diagnosis globally leads to\ndelayed treatment. Ultrasound, an effective yet underutilized method, requires\nspecialized training for sonographers, which hinders its widespread use.\nApproach. Volume sweep imaging (VSI) is an innovative approach that enables\nuntrained operators to capture high-quality ultrasound images. Combined with\ndeep learning, like convolutional neural networks (CNNs), it can potentially\ntransform breast cancer diagnosis, enhancing accuracy, saving time and costs,\nand improving patient outcomes. The widely used UNet architecture, known for\nmedical image segmentation, has limitations, such as vanishing gradients and a\nlack of multi-scale feature extraction and selective region attention. In this\nstudy, we present a novel segmentation model known as Wavelet_Attention_UNet\n(WATUNet). In this model, we incorporate wavelet gates (WGs) and attention\ngates (AGs) between the encoder and decoder instead of a simple connection to\novercome the limitations mentioned, thereby improving model performance. Main\nresults. Two datasets are utilized for the analysis. The public \"Breast\nUltrasound Images\" (BUSI) dataset of 780 images and a VSI dataset of 3818\nimages. Both datasets contained segmented lesions categorized into three types:\nno mass, benign mass, and malignant mass. Our segmentation results show\nsuperior performance compared to other deep networks. The proposed algorithm\nattained a Dice coefficient of 0.94 and an F1 score of 0.94 on the VSI dataset\nand scored 0.93 and 0.94 on the public dataset, respectively.",
            "author": [
                "Donya Khaledyan",
                "Thomas J. Marini",
                "Avice OConnell",
                "Steven Meng",
                "Jonah Kan",
                "Galen Brennan",
                "Yu Zhao",
                "Timothy M. Baran",
                "Kevin J. Parker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10857v1",
                "http://arxiv.org/pdf/2311.10857v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10847v2",
            "title": "Token-Level Adaptation of LoRA Adapters for Downstream Task\n  Generalization",
            "updated": "2023-12-01T06:38:18Z",
            "published": "2023-11-17T20:07:54Z",
            "summary": "This paper introduces a method for adapting LoRA adapters in smaller-sized\nlanguage models to arbitrary downstream tasks. Unlike standard\nmixture-of-expert architectures, our method employs a gradient-free routing\nfunction to choose a weighted combination of experts without increasing the\ncompute requirements for training or inference. The results show that\ntoken-level adaptation of LoRA adapters outperforms the base Llama-2-7b model\nacross mathematical (GSM8K), scientific (ARC-Challenge), reading comprehension\n(SQuAD), and coding (CodeAlpaca-20k) tasks. Further evaluations also show that\nthe average performance of token-level adaptation outperforms individual models\nfine-tuned for each of the tasks with the best performance observed in\nadaptation of every-other token during inference. The code for this study is\nmade available through a public repository.",
            "author": [
                "Joshua Belofsky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10847v2",
                "http://arxiv.org/pdf/2311.10847v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10845v1",
            "title": "Domain Generalization of 3D Object Detection by Density-Resampling",
            "updated": "2023-11-17T20:01:29Z",
            "published": "2023-11-17T20:01:29Z",
            "summary": "Point-cloud-based 3D object detection suffers from performance degradation\nwhen encountering data with novel domain gaps. To tackle it, the single-domain\ngeneralization (SDG) aims to generalize the detection model trained in a\nlimited single source domain to perform robustly on unexplored domains. In this\npaper, we propose an SDG method to improve the generalizability of 3D object\ndetection to unseen target domains. Unlike prior SDG works for 3D object\ndetection solely focusing on data augmentation, our work introduces a novel\ndata augmentation method and contributes a new multi-task learning strategy in\nthe methodology. Specifically, from the perspective of data augmentation, we\ndesign a universal physical-aware density-based data augmentation (PDDA) method\nto mitigate the performance loss stemming from diverse point densities. From\nthe learning methodology viewpoint, we develop a multi-task learning for 3D\nobject detection: during source training, besides the main standard detection\ntask, we leverage an auxiliary self-supervised 3D scene restoration task to\nenhance the comprehension of the encoder on background and foreground details\nfor better recognition and detection of objects. Furthermore, based on the\nauxiliary self-supervised task, we propose the first test-time adaptation\nmethod for domain generalization of 3D object detection, which efficiently\nadjusts the encoder's parameters to adapt to unseen target domains during\ntesting time, to further bridge domain gaps. Extensive cross-dataset\nexperiments covering \"Car\", \"Pedestrian\", and \"Cyclist\" detections, demonstrate\nour method outperforms state-of-the-art SDG methods and even overpass\nunsupervised domain adaptation methods under some circumstances. The code will\nbe made publicly available.",
            "author": [
                "Shuangzhi Li",
                "Lei Ma",
                "Xingyu Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10845v1",
                "http://arxiv.org/pdf/2311.10845v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10835v1",
            "title": "Accelerating L-shaped Two-stage Stochastic SCUC with Learning Integrated\n  Benders Decomposition",
            "updated": "2023-11-17T19:31:40Z",
            "published": "2023-11-17T19:31:40Z",
            "summary": "Benders decomposition is widely used to solve large mixed-integer problems.\nThis paper takes advantage of machine learning and proposes enhanced variants\nof Benders decomposition for solving two-stage stochastic security-constrained\nunit commitment (SCUC). The problem is decomposed into a master problem and\nsubproblems corresponding to a load scenario. The goal is to reduce the\ncomputational costs and memory usage of Benders decomposition by creating\ntighter cuts and reducing the size of the master problem. Three approaches are\nproposed, namely regression Benders, classification Benders, and\nregression-classification Benders. A regressor reads load profile scenarios and\npredicts subproblem objective function proxy variables to form tighter cuts for\nthe master problem. A criterion is defined to measure the level of usefulness\nof cuts with respect to their contribution to lower bound improvement. Useful\ncuts that contain the necessary information to form the feasible region are\nidentified with and without a classification learner. Useful cuts are\niteratively added to the master problem, and non-useful cuts are discarded to\nreduce the computational burden of each Benders iteration. Simulation studies\non multiple test systems show the effectiveness of the proposed learning-aided\nBenders decomposition for solving two-stage SCUC as compared to conventional\nmulti-cut Benders decomposition.",
            "author": [
                "Fouad Hasan",
                "Amin Kargarian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10835v1",
                "http://arxiv.org/pdf/2311.10835v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10833v1",
            "title": "Generative AI has lowered the barriers to computational social sciences",
            "updated": "2023-11-17T19:24:39Z",
            "published": "2023-11-17T19:24:39Z",
            "summary": "Generative artificial intelligence (AI) has revolutionized the field of\ncomputational social science, unleashing new possibilities for analyzing\nmultimodal data, especially for scholars who may not have extensive programming\nexpertise. This breakthrough carries profound implications for the realm of\nsocial sciences. Firstly, generative AI can significantly enhance the\nproductivity of social scientists by automating the generation, annotation, and\ndebugging of code. Secondly, it empowers researchers to delve into\nsophisticated data analysis through the innovative use of prompt engineering.\nLastly, the educational sphere of computational social science stands to\nbenefit immensely from these tools, given their exceptional ability to annotate\nand elucidate complex codes for learners, thereby simplifying the learning\nprocess and making the technology more accessible.",
            "author": [
                "Yongjun Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10833v1",
                "http://arxiv.org/pdf/2311.10833v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10832v1",
            "title": "Exploring Machine Learning Models for Federated Learning: A Review of\n  Approaches, Performance, and Limitations",
            "updated": "2023-11-17T19:23:21Z",
            "published": "2023-11-17T19:23:21Z",
            "summary": "In the growing world of artificial intelligence, federated learning is a\ndistributed learning framework enhanced to preserve the privacy of individuals'\ndata. Federated learning lays the groundwork for collaborative research in\nareas where the data is sensitive. Federated learning has several implications\nfor real-world problems. In times of crisis, when real-time decision-making is\ncritical, federated learning allows multiple entities to work collectively\nwithout sharing sensitive data. This distributed approach enables us to\nleverage information from multiple sources and gain more diverse insights. This\npaper is a systematic review of the literature on privacy-preserving machine\nlearning in the last few years based on the Preferred Reporting Items for\nSystematic Reviews and Meta-Analyses (PRISMA) guidelines. Specifically, we have\npresented an extensive review of supervised/unsupervised machine learning\nalgorithms, ensemble methods, meta-heuristic approaches, blockchain technology,\nand reinforcement learning used in the framework of federated learning, in\naddition to an overview of federated learning applications. This paper reviews\nthe literature on the components of federated learning and its applications in\nthe last few years. The main purpose of this work is to provide researchers and\npractitioners with a comprehensive overview of federated learning from the\nmachine learning point of view. A discussion of some open problems and future\nresearch directions in federated learning is also provided.",
            "author": [
                "Elaheh Jafarigol",
                "Theodore Trafalis",
                "Talayeh Razzaghi",
                "Mona Zamankhani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10832v1",
                "http://arxiv.org/pdf/2311.10832v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10823v1",
            "title": "High precision accelerator for our hybrid model of the redshift space\n  power spectrum",
            "updated": "2023-11-17T19:03:47Z",
            "published": "2023-11-17T19:03:47Z",
            "summary": "Upcoming Large Scale Structure surveys aim to achieve an unprecedented level\nof precision in measuring galaxy clustering. However, accurately modeling these\nstatistics may require theoretical templates that go beyond second-order\nperturbation theory, especially for achieving precision at smaller scales. In\nour previous work, we introduced a hybrid model for the redshift space power\nspectrum of galaxies. This model combines second-order templates with N-body\nsimulations to capture the influence of scale-independent parameters on the\ngalaxy power spectrum. However, the impact of scale-dependent parameters was\naddressed by precomputing a set of input statistics derived from\ncomputationally expensive N-body simulations. As a result, exploring the\nscale-dependent parameter space was not feasible in this approach. To address\nthis challenge, we present an accelerated methodology that utilizes Gaussian\nprocesses, a machine learning technique, to emulate these input statistics. Our\nemulators exhibit remarkable accuracy, achieving reliable results with just 13\nN-body simulations for training. We reproduce all necessary input statistics\nfor a set of test simulations with an error of approximately 0.1 per cent in\nthe parameter space within $5\\sigma$ of the Planck predictions, specifically\nfor scales around $k > 0.1$ $h$Mpc$^{-1}$. Following the training of our\nemulators, we can predict all inputs for our hybrid model in approximately\n0.2,seconds at a specified redshift. Given that performing 13 N-body\nsimulations is a manageable task, our present methodology enables us to\nconstruct efficient and highly accurate models of the galaxy power spectra\nwithin a manageable time frame.",
            "author": [
                "M. Icaza-Lizaola",
                "Yong-Seon Song",
                "Minji Oh",
                "Yi Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10823v1",
                "http://arxiv.org/pdf/2311.10823v1"
            ],
            "primary_category": "astro-ph.CO",
            "category": [
                "astro-ph.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10822v1",
            "title": "Gradients and frequency profiles of quantum re-uploading models",
            "updated": "2023-11-17T19:01:43Z",
            "published": "2023-11-17T19:01:43Z",
            "summary": "Quantum re-uploading models have been extensively investigated as a form of\nmachine learning within the context of variational quantum algorithms. Their\ntrainability and expressivity are not yet fully understood and are critical to\ntheir performance. In this work, we address trainability through the lens of\nthe magnitude of the gradients of the cost function. We prove bounds for the\ndifferences between gradients of the better-studied data-less parameterized\nquantum circuits and re-uploading models. We coin the concept of {\\sl\nabsorption witness} to quantify such difference. For the expressivity, we prove\nthat quantum re-uploading models output functions with vanishing high-frequency\ncomponents and upper-bounded derivatives with respect to data. As a\nconsequence, such functions present limited sensitivity to fine details, which\nprotects against overfitting. We performed numerical experiments extending the\ntheoretical results to more relaxed and realistic conditions. Overall, future\ndesigns of quantum re-uploading models will benefit from the strengthened\nknowledge delivered by the uncovering of absorption witnesses and vanishing\nhigh frequencies.",
            "author": [
                "Alice Barthe",
                "Adri\u00e1n P\u00e9rez-Salinas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10822v1",
                "http://arxiv.org/pdf/2311.10822v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10813v3",
            "title": "A Language Agent for Autonomous Driving",
            "updated": "2023-11-27T20:53:35Z",
            "published": "2023-11-17T18:59:56Z",
            "summary": "Human-level driving is an ultimate goal of autonomous driving. Conventional\napproaches formulate autonomous driving as a perception-prediction-planning\nframework, yet their systems do not capitalize on the inherent reasoning\nability and experiential knowledge of humans. In this paper, we propose a\nfundamental paradigm shift from current pipelines, exploiting Large Language\nModels (LLMs) as a cognitive agent to integrate human-like intelligence into\nautonomous driving systems. Our approach, termed Agent-Driver, transforms the\ntraditional autonomous driving pipeline by introducing a versatile tool library\naccessible via function calls, a cognitive memory of common sense and\nexperiential knowledge for decision-making, and a reasoning engine capable of\nchain-of-thought reasoning, task planning, motion planning, and\nself-reflection. Powered by LLMs, our Agent-Driver is endowed with intuitive\ncommon sense and robust reasoning capabilities, thus enabling a more nuanced,\nhuman-like approach to autonomous driving. We evaluate our approach on the\nlarge-scale nuScenes benchmark, and extensive experiments substantiate that our\nAgent-Driver significantly outperforms the state-of-the-art driving methods by\na large margin. Our approach also demonstrates superior interpretability and\nfew-shot learning ability to these methods. Code will be released.",
            "author": [
                "Jiageng Mao",
                "Junjie Ye",
                "Yuxi Qian",
                "Marco Pavone",
                "Yue Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10813v3",
                "http://arxiv.org/pdf/2311.10813v3"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10710v1",
            "title": "Machine learning phase transitions: Connections to the Fisher\n  information",
            "updated": "2023-11-17T18:59:35Z",
            "published": "2023-11-17T18:59:35Z",
            "summary": "Despite the widespread use and success of machine-learning techniques for\ndetecting phase transitions from data, their working principle and fundamental\nlimits remain elusive. Here, we explain the inner workings and identify\npotential failure modes of these techniques by rooting popular machine-learning\nindicators of phase transitions in information-theoretic concepts. Using tools\nfrom information geometry, we prove that several machine-learning indicators of\nphase transitions approximate the square root of the system's (quantum) Fisher\ninformation from below -- a quantity that is known to indicate phase\ntransitions but is often difficult to compute from data. We numerically\ndemonstrate the quality of these bounds for phase transitions in classical and\nquantum systems.",
            "author": [
                "Julian Arnold",
                "Niels L\u00f6rch",
                "Flemming Holtorf",
                "Frank Sch\u00e4fer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10710v1",
                "http://arxiv.org/pdf/2311.10710v1"
            ],
            "primary_category": "cond-mat.dis-nn",
            "category": [
                "cond-mat.dis-nn",
                "cs.LG",
                "quant-ph",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10709v1",
            "title": "Emu Video: Factorizing Text-to-Video Generation by Explicit Image\n  Conditioning",
            "updated": "2023-11-17T18:59:04Z",
            "published": "2023-11-17T18:59:04Z",
            "summary": "We present Emu Video, a text-to-video generation model that factorizes the\ngeneration into two steps: first generating an image conditioned on the text,\nand then generating a video conditioned on the text and the generated image. We\nidentify critical design decisions--adjusted noise schedules for diffusion, and\nmulti-stage training--that enable us to directly generate high quality and high\nresolution videos, without requiring a deep cascade of models as in prior work.\nIn human evaluations, our generated videos are strongly preferred in quality\ncompared to all prior work--81% vs. Google's Imagen Video, 90% vs. Nvidia's\nPYOCO, and 96% vs. Meta's Make-A-Video. Our model outperforms commercial\nsolutions such as RunwayML's Gen2 and Pika Labs. Finally, our factorizing\napproach naturally lends itself to animating images based on a user's text\nprompt, where our generations are preferred 96% over prior work.",
            "author": [
                "Rohit Girdhar",
                "Mannat Singh",
                "Andrew Brown",
                "Quentin Duval",
                "Samaneh Azadi",
                "Sai Saketh Rambhatla",
                "Akbar Shah",
                "Xi Yin",
                "Devi Parikh",
                "Ishan Misra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10709v1",
                "http://arxiv.org/pdf/2311.10709v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10708v1",
            "title": "SelfEval: Leveraging the discriminative nature of generative models for\n  evaluation",
            "updated": "2023-11-17T18:58:16Z",
            "published": "2023-11-17T18:58:16Z",
            "summary": "In this work, we show that text-to-image generative models can be 'inverted'\nto assess their own text-image understanding capabilities in a completely\nautomated manner.\n  Our method, called SelfEval, uses the generative model to compute the\nlikelihood of real images given text prompts, making the generative model\ndirectly applicable to discriminative tasks.\n  Using SelfEval, we repurpose standard datasets created for evaluating\nmultimodal text-image discriminative models to evaluate generative models in a\nfine-grained manner: assessing their performance on attribute binding, color\nrecognition, counting, shape recognition, spatial understanding.\n  To the best of our knowledge SelfEval is the first automated metric to show a\nhigh degree of agreement for measuring text-faithfulness with the gold-standard\nhuman evaluations across multiple models and benchmarks.\n  Moreover, SelfEval enables us to evaluate generative models on challenging\ntasks such as Winoground image-score where they demonstrate competitive\nperformance to discriminative models.\n  We also show severe drawbacks of standard automated metrics such as\nCLIP-score to measure text faithfulness on benchmarks such as DrawBench, and\nhow SelfEval sidesteps these issues.\n  We hope SelfEval enables easy and reliable automated evaluation for diffusion\nmodels.",
            "author": [
                "Sai Saketh Rambhatla",
                "Ishan Misra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10708v1",
                "http://arxiv.org/pdf/2311.10708v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10707v1",
            "title": "Multimodal Representation Learning by Alternating Unimodal Adaptation",
            "updated": "2023-11-17T18:57:40Z",
            "published": "2023-11-17T18:57:40Z",
            "summary": "Multimodal learning, which integrates data from diverse sensory modes, plays\na pivotal role in artificial intelligence. However, existing multimodal\nlearning methods often struggle with challenges where some modalities appear\nmore dominant than others during multimodal learning, resulting in suboptimal\nperformance. To address this challenge, we propose MLA (Multimodal Learning\nwith Alternating Unimodal Adaptation). MLA reframes the conventional joint\nmultimodal learning process by transforming it into an alternating unimodal\nlearning process, thereby minimizing interference between modalities.\nSimultaneously, it captures cross-modal interactions through a shared head,\nwhich undergoes continuous optimization across different modalities. This\noptimization process is controlled by a gradient modification mechanism to\nprevent the shared head from losing previously acquired information. During the\ninference phase, MLA utilizes a test-time uncertainty-based model fusion\nmechanism to integrate multimodal information. Extensive experiments are\nconducted on five diverse datasets, encompassing scenarios with complete\nmodalities and scenarios with missing modalities. These experiments demonstrate\nthe superiority of MLA over competing prior approaches.",
            "author": [
                "Xiaohui Zhang",
                "Jaehong Yoon",
                "Mohit Bansal",
                "Huaxiu Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10707v1",
                "http://arxiv.org/pdf/2311.10707v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10812v1",
            "title": "SplatArmor: Articulated Gaussian splatting for animatable humans from\n  monocular RGB videos",
            "updated": "2023-11-17T18:47:07Z",
            "published": "2023-11-17T18:47:07Z",
            "summary": "We propose SplatArmor, a novel approach for recovering detailed and\nanimatable human models by `armoring' a parameterized body model with 3D\nGaussians. Our approach represents the human as a set of 3D Gaussians within a\ncanonical space, whose articulation is defined by extending the skinning of the\nunderlying SMPL geometry to arbitrary locations in the canonical space. To\naccount for pose-dependent effects, we introduce a SE(3) field, which allows us\nto capture both the location and anisotropy of the Gaussians. Furthermore, we\npropose the use of a neural color field to provide color regularization and 3D\nsupervision for the precise positioning of these Gaussians. We show that\nGaussian splatting provides an interesting alternative to neural rendering\nbased methods by leverging a rasterization primitive without facing any of the\nnon-differentiability and optimization challenges typically faced in such\napproaches. The rasterization paradigms allows us to leverage forward skinning,\nand does not suffer from the ambiguities associated with inverse skinning and\nwarping. We show compelling results on the ZJU MoCap and People Snapshot\ndatasets, which underscore the effectiveness of our method for controllable\nhuman synthesis.",
            "author": [
                "Rohit Jena",
                "Ganesh Subramanian Iyer",
                "Siddharth Choudhary",
                "Brandon Smith",
                "Pratik Chaudhari",
                "James Gee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10812v1",
                "http://arxiv.org/pdf/2311.10812v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10701v1",
            "title": "SpACNN-LDVAE: Spatial Attention Convolutional Latent Dirichlet\n  Variational Autoencoder for Hyperspectral Pixel Unmixing",
            "updated": "2023-11-17T18:45:00Z",
            "published": "2023-11-17T18:45:00Z",
            "summary": "The Hyperspectral Unxming problem is to find the pure spectral signal of the\nunderlying materials (endmembers) and their proportions (abundances). The\nproposed method builds upon the recently proposed method, Latent Dirichlet\nVariational Autoencoder (LDVAE). It assumes that abundances can be encoded as\nDirichlet Distributions while mixed pixels and endmembers are represented by\nMultivariate Normal Distributions. However, LDVAE does not leverage spatial\ninformation present in an HSI; we propose an Isotropic CNN encoder with spatial\nattention to solve the hyperspectral unmixing problem. We evaluated our model\non Samson, Hydice Urban, Cuprite, and OnTech-HSI-Syn-21 datasets. Our model\nalso leverages the transfer learning paradigm for Cuprite Dataset, where we\ntrain the model on synthetic data and evaluate it on real-world data. We are\nable to observe the improvement in the results for the endmember extraction and\nabundance estimation by incorporating the spatial information. Code can be\nfound at https://github.com/faisalqureshi/cnn-ldvae",
            "author": [
                "Soham Chitnis",
                "Kiran Mantripragada",
                "Faisal Z. Qureshi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10701v1",
                "http://arxiv.org/pdf/2311.10701v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10699v1",
            "title": "Using linear initialisation to improve speed of convergence and\n  fully-trained error in Autoencoders",
            "updated": "2023-11-17T18:43:32Z",
            "published": "2023-11-17T18:43:32Z",
            "summary": "Good weight initialisation is an important step in successful training of\nArtificial Neural Networks. Over time a number of improvements have been\nproposed to this process. In this paper we introduce a novel weight\ninitialisation technique called the Straddled Matrix Initialiser. This\ninitialisation technique is motivated by our assumption that major,\nglobal-scale relationships in data are linear with only smaller effects\nrequiring complex non-linearities. Combination of Straddled Matrix and ReLU\nactivation function initialises a Neural Network as a de facto linear model,\nwhich we postulate should be a better starting point for optimisation given our\nassumptions. We test this by training autoencoders on three datasets using\nStraddled Matrix and seven other state-of-the-art weight initialisation\ntechniques. In all our experiments the Straddeled Matrix Initialiser clearly\noutperforms all other methods.",
            "author": [
                "Marcel Marais",
                "Mate Hartstein",
                "George Cevora"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10699v1",
                "http://arxiv.org/pdf/2311.10699v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10811v1",
            "title": "A novel post-hoc explanation comparison metric and applications",
            "updated": "2023-11-17T18:35:13Z",
            "published": "2023-11-17T18:35:13Z",
            "summary": "Explanatory systems make the behavior of machine learning models more\ntransparent, but are often inconsistent. To quantify the differences between\nexplanatory systems, this paper presents the Shreyan Distance, a novel metric\nbased on the weighted difference between ranked feature importance lists\nproduced by such systems. This paper uses the Shreyan Distance to compare two\nexplanatory systems, SHAP and LIME, for both regression and classification\nlearning tasks. Because we find that the average Shreyan Distance varies\nsignificantly between these two tasks, we conclude that consistency between\nexplainers not only depends on inherent properties of the explainers\nthemselves, but also the type of learning task. This paper further contributes\nthe XAISuite library, which integrates the Shreyan distance algorithm into\nmachine learning pipelines.",
            "author": [
                "Shreyan Mitra",
                "Leilani Gilpin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10811v1",
                "http://arxiv.org/pdf/2311.10811v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "I.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10697v1",
            "title": "PEFT-MedAware: Large Language Model for Medical Awareness",
            "updated": "2023-11-17T18:32:17Z",
            "published": "2023-11-17T18:32:17Z",
            "summary": "Chat models are capable of answering a wide range of questions, however, the\naccuracy of their responses is highly uncertain. In this research, we propose a\nspecialized PEFT-MedAware model where we utilize parameter-efficient\nfine-tuning (PEFT) to enhance the Falcon-1b large language model on specialized\nMedQuAD data consisting of 16,407 medical QA pairs, leveraging only 0.44% of\nits trainable parameters to enhance computational efficiency. The paper adopts\ndata preprocessing and PEFT to optimize model performance, complemented by a\nBitsAndBytesConfig for efficient transformer training. The resulting model was\ncapable of outperforming other LLMs in medical question-answering tasks in\nspecific domains with greater accuracy utilizing limited computational\nresources making it suitable for deployment in resource-constrained\nenvironments. We propose further improvements through expanded datasets, larger\nmodels, and feedback mechanisms for sustained medical relevancy. Our work\nhighlights the efficiency gains and specialized capabilities of PEFT in medical\nAI, outpacing standard models in precision without extensive resource demands.\nThe proposed model and data are released for research purposes only.",
            "author": [
                "Keivalya Pandya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10697v1",
                "http://arxiv.org/pdf/2311.10697v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10696v1",
            "title": "Versatile Medical Image Segmentation Learned from Multi-Source Datasets\n  via Model Self-Disambiguation",
            "updated": "2023-11-17T18:28:32Z",
            "published": "2023-11-17T18:28:32Z",
            "summary": "A versatile medical image segmentation model applicable to imaging data\ncollected with diverse equipment and protocols can facilitate model deployment\nand maintenance. However, building such a model typically requires a large,\ndiverse, and fully annotated dataset, which is rarely available due to the\nlabor-intensive and costly data curation. In this study, we develop a\ncost-efficient method by harnessing readily available data with partially or\neven sparsely annotated segmentation labels. We devise strategies for model\nself-disambiguation, prior knowledge incorporation, and imbalance mitigation to\naddress challenges associated with inconsistently labeled data from various\nsources, including label ambiguity and imbalances across modalities, datasets,\nand segmentation labels. Experimental results on a multi-modal dataset compiled\nfrom eight different sources for abdominal organ segmentation have demonstrated\nour method's effectiveness and superior performance over alternative\nstate-of-the-art methods, highlighting its potential for optimizing the use of\nexisting annotated data and reducing the annotation efforts for new data to\nfurther enhance model capability.",
            "author": [
                "Xiaoyang Chen",
                "Hao Zheng",
                "Yuemeng Li",
                "Yuncong Ma",
                "Liang Ma",
                "Hongming Li",
                "Yong Fan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10696v1",
                "http://arxiv.org/pdf/2311.10696v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10680v1",
            "title": "Optimal Embedding Dimension for Sparse Subspace Embeddings",
            "updated": "2023-11-17T18:01:58Z",
            "published": "2023-11-17T18:01:58Z",
            "summary": "A random $m\\times n$ matrix $S$ is an oblivious subspace embedding (OSE) with\nparameters $\\epsilon>0$, $\\delta\\in(0,1/3)$ and $d\\leq m\\leq n$, if for any\n$d$-dimensional subspace $W\\subseteq R^n$,\n  $P\\big(\\,\\forall_{x\\in W}\\ (1+\\epsilon)^{-1}\\|x\\|\\leq\\|Sx\\|\\leq\n(1+\\epsilon)\\|x\\|\\,\\big)\\geq 1-\\delta.$\n  It is known that the embedding dimension of an OSE must satisfy $m\\geq d$,\nand for any $\\theta > 0$, a Gaussian embedding matrix with $m\\geq (1+\\theta) d$\nis an OSE with $\\epsilon = O_\\theta(1)$. However, such optimal embedding\ndimension is not known for other embeddings. Of particular interest are sparse\nOSEs, having $s\\ll m$ non-zeros per column, with applications to problems such\nas least squares regression and low-rank approximation.\n  We show that, given any $\\theta > 0$, an $m\\times n$ random matrix $S$ with\n$m\\geq (1+\\theta)d$ consisting of randomly sparsified $\\pm1/\\sqrt s$ entries\nand having $s= O(\\log^4(d))$ non-zeros per column, is an oblivious subspace\nembedding with $\\epsilon = O_{\\theta}(1)$. Our result addresses the main open\nquestion posed by Nelson and Nguyen (FOCS 2013), who conjectured that sparse\nOSEs can achieve $m=O(d)$ embedding dimension, and it improves on\n$m=O(d\\log(d))$ shown by Cohen (SODA 2016). We use this to construct the first\noblivious subspace embedding with $O(d)$ embedding dimension that can be\napplied faster than current matrix multiplication time, and to obtain an\noptimal single-pass algorithm for least squares regression. We further extend\nour results to construct even sparser non-oblivious embeddings, leading to the\nfirst subspace embedding with low distortion $\\epsilon=o(1)$ and optimal\nembedding dimension $m=O(d/\\epsilon^2)$ that can be applied in current matrix\nmultiplication time.",
            "author": [
                "Shabarish Chenakkod",
                "Micha\u0142 Derezi\u0144ski",
                "Xiaoyu Dong",
                "Mark Rudelson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10680v1",
                "http://arxiv.org/pdf/2311.10680v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG",
                "cs.NA",
                "math.NA",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10678v1",
            "title": "Distilling and Retrieving Generalizable Knowledge for Robot Manipulation\n  via Language Corrections",
            "updated": "2023-11-17T18:00:20Z",
            "published": "2023-11-17T18:00:20Z",
            "summary": "Today's robot policies exhibit subpar performance when faced with the\nchallenge of generalizing to novel environments. Human corrective feedback is a\ncrucial form of guidance to enable such generalization. However, adapting to\nand learning from online human corrections is a non-trivial endeavor: not only\ndo robots need to remember human feedback over time to retrieve the right\ninformation in new settings and reduce the intervention rate, but also they\nwould need to be able to respond to feedback that can be arbitrary corrections\nabout high-level human preferences to low-level adjustments to skill\nparameters. In this work, we present Distillation and Retrieval of Online\nCorrections (DROC), a large language model (LLM)-based system that can respond\nto arbitrary forms of language feedback, distill generalizable knowledge from\ncorrections, and retrieve relevant past experiences based on textual and visual\nsimilarity for improving performance in novel settings. DROC is able to respond\nto a sequence of online language corrections that address failures in both\nhigh-level task plans and low-level skill primitives. We demonstrate that DROC\neffectively distills the relevant information from the sequence of online\ncorrections in a knowledge base and retrieves that knowledge in settings with\nnew task or object instances. DROC outperforms other techniques that directly\ngenerate robot code via LLMs by using only half of the total number of\ncorrections needed in the first round and requires little to no corrections\nafter two iterations. We show further results, videos, prompts and code on\nhttps://sites.google.com/stanford.edu/droc .",
            "author": [
                "Lihan Zha",
                "Yuchen Cui",
                "Li-Heng Lin",
                "Minae Kwon",
                "Montserrat Gonzalez Arenas",
                "Andy Zeng",
                "Fei Xia",
                "Dorsa Sadigh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10678v1",
                "http://arxiv.org/pdf/2311.10678v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10808v1",
            "title": "Multiparameter Persistent Homology for Molecular Property Prediction",
            "updated": "2023-11-17T17:57:56Z",
            "published": "2023-11-17T17:57:56Z",
            "summary": "In this study, we present a novel molecular fingerprint generation method\nbased on multiparameter persistent homology. This approach reveals the latent\nstructures and relationships within molecular geometry, and detects topological\nfeatures that exhibit persistence across multiple scales along multiple\nparameters, such as atomic mass, partial charge, and bond type, and can be\nfurther enhanced by incorporating additional parameters like ionization energy,\nelectron affinity, chirality and orbital hybridization. The proposed\nfingerprinting method provides fresh perspectives on molecular structure that\nare not easily discernible from single-parameter or single-scale analysis.\nBesides, in comparison with traditional graph neural networks, multiparameter\npersistent homology has the advantage of providing a more comprehensive and\ninterpretable characterization of the topology of the molecular data. We have\nestablished theoretical stability guarantees for multiparameter persistent\nhomology, and have conducted extensive experiments on the Lipophilicity,\nFreeSolv, and ESOL datasets to demonstrate its effectiveness in predicting\nmolecular properties.",
            "author": [
                "Andac Demir",
                "Bulent Kiziltan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10808v1",
                "http://arxiv.org/pdf/2311.10808v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.LG",
                "math.AT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10671v1",
            "title": "Fuse It or Lose It: Deep Fusion for Multimodal Simulation-Based\n  Inference",
            "updated": "2023-11-17T17:43:11Z",
            "published": "2023-11-17T17:43:11Z",
            "summary": "We present multimodal neural posterior estimation (MultiNPE), a method to\nintegrate heterogeneous data from different sources in simulation-based\ninference with neural networks. Inspired by advances in attention-based deep\nfusion learning, it empowers researchers to analyze data from different domains\nand infer the parameters of complex mathematical models with increased\naccuracy. We formulate different multimodal fusion approaches for MultiNPE\n(early, late, and hybrid) and evaluate their performance in three challenging\nnumerical experiments. MultiNPE not only outperforms na\\\"ive baselines on a\nbenchmark model, but also achieves superior inference on representative\nscientific models from neuroscience and cardiology. In addition, we\nsystematically investigate the impact of partially missing data on the\ndifferent fusion strategies. Across our different experiments, late and hybrid\nfusion techniques emerge as the methods of choice for practical applications of\nmultimodal simulation-based inference.",
            "author": [
                "Marvin Schmitt",
                "Stefan T. Radev",
                "Paul-Christian B\u00fcrkner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10671v1",
                "http://arxiv.org/pdf/2311.10671v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10665v1",
            "title": "Online Calibration of Deep Learning Sub-Models for Hybrid Numerical\n  Modeling Systems",
            "updated": "2023-11-17T17:36:26Z",
            "published": "2023-11-17T17:36:26Z",
            "summary": "Artificial intelligence and deep learning are currently reshaping numerical\nsimulation frameworks by introducing new modeling capabilities. These\nframeworks are extensively investigated in the context of model correction and\nparameterization where they demonstrate great potential and often outperform\ntraditional physical models. Most of these efforts in defining hybrid dynamical\nsystems follow {offline} learning strategies in which the neural\nparameterization (called here sub-model) is trained to output an ideal\ncorrection. Yet, these hybrid models can face hard limitations when defining\nwhat should be a relevant sub-model response that would translate into a good\nforecasting performance. End-to-end learning schemes, also referred to as\nonline learning, could address such a shortcoming by allowing the deep learning\nsub-models to train on historical data. However, defining end-to-end training\nschemes for the calibration of neural sub-models in hybrid systems requires\nworking with an optimization problem that involves the solver of the physical\nequations. Online learning methodologies thus require the numerical model to be\ndifferentiable, which is not the case for most modeling systems. To overcome\nthis difficulty and bypass the differentiability challenge of physical models,\nwe present an efficient and practical online learning approach for hybrid\nsystems. The method, called EGA for Euler Gradient Approximation, assumes an\nadditive neural correction to the physical model, and an explicit Euler\napproximation of the gradients. We demonstrate that the EGA converges to the\nexact gradients in the limit of infinitely small time steps. Numerical\nexperiments are performed on various case studies, including prototypical\nocean-atmosphere dynamics. Results show significant improvements over offline\nlearning, highlighting the potential of end-to-end online learning for hybrid\nmodeling.",
            "author": [
                "Said Ouala",
                "Bertrand Chapron",
                "Fabrice Collard",
                "Lucile Gaultier",
                "Ronan Fablet"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10665v1",
                "http://arxiv.org/pdf/2311.10665v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10664v1",
            "title": "Reprogramming Self-supervised Learning-based Speech Representations for\n  Speaker Anonymization",
            "updated": "2023-11-17T17:35:25Z",
            "published": "2023-11-17T17:35:25Z",
            "summary": "Current speaker anonymization methods, especially with self-supervised\nlearning (SSL) models, require massive computational resources when hiding\nspeaker identity. This paper proposes an effective and parameter-efficient\nspeaker anonymization method based on recent End-to-End model reprogramming\ntechnology. To improve the anonymization performance, we first extract speaker\nrepresentation from large SSL models as the speaker identifies. To hide the\nspeaker's identity, we reprogram the speaker representation by adapting the\nspeaker to a pseudo domain. Extensive experiments are carried out on the\nVoicePrivacy Challenge (VPC) 2022 datasets to demonstrate the effectiveness of\nour proposed parameter-efficient learning anonymization methods. Additionally,\nwhile achieving comparable performance with the VPC 2022 strong baseline 1.b,\nour approach consumes less computational resources during anonymization.",
            "author": [
                "Xiaojiao Chen",
                "Sheng Li",
                "Jiyi Li",
                "Hao Huang",
                "Yang Cao",
                "Liang He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10664v1",
                "http://arxiv.org/pdf/2311.10664v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10656v1",
            "title": "LE-SSL-MOS: Self-Supervised Learning MOS Prediction with Listener\n  Enhancement",
            "updated": "2023-11-17T17:20:45Z",
            "published": "2023-11-17T17:20:45Z",
            "summary": "Recently, researchers have shown an increasing interest in automatically\npredicting the subjective evaluation for speech synthesis systems. This\nprediction is a challenging task, especially on the out-of-domain test set. In\nthis paper, we proposed a novel fusion model for MOS prediction that combines\nsupervised and unsupervised approaches. In the supervised aspect, we developed\nan SSL-based predictor called LE-SSL-MOS. The LE-SSL-MOS utilizes pre-trained\nself-supervised learning models and further improves prediction accuracy by\nutilizing the opinion scores of each utterance in the listener enhancement\nbranch. In the unsupervised aspect, two steps are contained: we fine-tuned the\nunit language model (ULM) using highly intelligible domain data to improve the\ncorrelation of an unsupervised metric - SpeechLMScore. Another is that we\nutilized ASR confidence as a new metric with the help of ensemble learning. To\nour knowledge, this is the first architecture that fuses supervised and\nunsupervised methods for MOS prediction. With these approaches, our\nexperimental results on the VoiceMOS Challenge 2023 show that LE-SSL-MOS\nperforms better than the baseline. Our fusion system achieved an absolute\nimprovement of 13% over LE-SSL-MOS on the noisy and enhanced speech track. Our\nsystem ranked 1st and 2nd, respectively, in the French speech synthesis track\nand the challenge's noisy and enhanced speech track.",
            "author": [
                "Zili Qi",
                "Xinhui Hu",
                "Wangjin Zhou",
                "Sheng Li",
                "Hao Wu",
                "Jian Lu",
                "Xinkang Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10656v1",
                "http://arxiv.org/pdf/2311.10656v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10653v1",
            "title": "Learning Realistic Joint Space Boundaries for Range of Motion Analysis\n  of Healthy and Impaired Human Arms",
            "updated": "2023-11-17T17:14:42Z",
            "published": "2023-11-17T17:14:42Z",
            "summary": "A realistic human kinematic model that satisfies anatomical constraints is\nessential for human-robot interaction, biomechanics and robot-assisted\nrehabilitation. Modeling realistic joint constraints, however, is challenging\nas human arm motion is constrained by joint limits, inter- and intra-joint\ndependencies, self-collisions, individual capabilities and muscular or\nneurological constraints which are difficult to represent. Hence, physicians\nand researchers have relied on simple box-constraints, ignoring important\nanatomical factors. In this paper, we propose a data-driven method to learn\nrealistic anatomically constrained upper-limb range of motion (RoM) boundaries\nfrom motion capture data. This is achieved by fitting a one-class support\nvector machine to a dataset of upper-limb joint space exploration motions with\nan efficient hyper-parameter tuning scheme. Our approach outperforms similar\nworks focused on valid RoM learning. Further, we propose an impairment index\n(II) metric that offers a quantitative assessment of capability/impairment when\ncomparing healthy and impaired arms. We validate the metric on healthy subjects\nphysically constrained to emulate hemiplegia and different disability levels as\nstroke patients.",
            "author": [
                "Shafagh Keyvanian",
                "Michelle J. Johnson",
                "Nadia Figueroa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10653v1",
                "http://arxiv.org/pdf/2311.10653v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10651v1",
            "title": "3D-TexSeg: Unsupervised Segmentation of 3D Texture using Mutual\n  Transformer Learning",
            "updated": "2023-11-17T17:13:14Z",
            "published": "2023-11-17T17:13:14Z",
            "summary": "Analysis of the 3D Texture is indispensable for various tasks, such as\nretrieval, segmentation, classification, and inspection of sculptures, knitted\nfabrics, and biological tissues. A 3D texture is a locally repeated surface\nvariation independent of the surface's overall shape and can be determined\nusing the local neighborhood and its characteristics. Existing techniques\ntypically employ computer vision techniques that analyze a 3D mesh globally,\nderive features, and then utilize the obtained features for retrieval or\nclassification. Several traditional and learning-based methods exist in the\nliterature, however, only a few are on 3D texture, and nothing yet, to the best\nof our knowledge, on the unsupervised schemes. This paper presents an original\nframework for the unsupervised segmentation of the 3D texture on the mesh\nmanifold. We approach this problem as binary surface segmentation, partitioning\nthe mesh surface into textured and non-textured regions without prior\nannotation. We devise a mutual transformer-based system comprising a label\ngenerator and a cleaner. The two models take geometric image representations of\nthe surface mesh facets and label them as texture or non-texture across an\niterative mutual learning scheme. Extensive experiments on three publicly\navailable datasets with diverse texture patterns demonstrate that the proposed\nframework outperforms standard and SOTA unsupervised techniques and competes\nreasonably with supervised methods.",
            "author": [
                "Iyyakutti Iyappan Ganapathi",
                "Fayaz Ali",
                "Sajid Javed",
                "Syed Sadaf Ali",
                "Naoufel Werghi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10651v1",
                "http://arxiv.org/pdf/2311.10651v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10648v1",
            "title": "Self-trained Panoptic Segmentation",
            "updated": "2023-11-17T17:06:59Z",
            "published": "2023-11-17T17:06:59Z",
            "summary": "Panoptic segmentation is an important computer vision task which combines\nsemantic and instance segmentation. It plays a crucial role in domains of\nmedical image analysis, self-driving vehicles, and robotics by providing a\ncomprehensive understanding of visual environments. Traditionally, deep\nlearning panoptic segmentation models have relied on dense and accurately\nannotated training data, which is expensive and time consuming to obtain.\nRecent advancements in self-supervised learning approaches have shown great\npotential in leveraging synthetic and unlabelled data to generate pseudo-labels\nusing self-training to improve the performance of instance and semantic\nsegmentation models. The three available methods for self-supervised panoptic\nsegmentation use proposal-based transformer architectures which are\ncomputationally expensive, complicated and engineered for specific tasks. The\naim of this work is to develop a framework to perform embedding-based\nself-supervised panoptic segmentation using self-training in a\nsynthetic-to-real domain adaptation problem setting.",
            "author": [
                "Shourya Verma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10648v1",
                "http://arxiv.org/pdf/2311.10648v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10645v1",
            "title": "User Dynamics-Aware Edge Caching and Computing for Mobile Virtual\n  Reality",
            "updated": "2023-11-17T17:01:09Z",
            "published": "2023-11-17T17:01:09Z",
            "summary": "In this paper, we present a novel content caching and delivery approach for\nmobile virtual reality (VR) video streaming. The proposed approach aims to\nmaximize VR video streaming performance, i.e., minimizing video frame missing\nrate, by proactively caching popular VR video chunks and adaptively scheduling\ncomputing resources at an edge server based on user and network dynamics.\nFirst, we design a scalable content placement scheme for deciding which video\nchunks to cache at the edge server based on tradeoffs between computing and\ncaching resource consumption. Second, we propose a machine learning-assisted VR\nvideo delivery scheme, which allocates computing resources at the edge server\nto satisfy video delivery requests from multiple VR headsets. A Whittle\nindex-based method is adopted to reduce the video frame missing rate by\nidentifying network and user dynamics with low signaling overhead. Simulation\nresults demonstrate that the proposed approach can significantly improve VR\nvideo streaming performance over conventional caching and computing resource\nscheduling strategies.",
            "author": [
                "Mushu Li",
                "Jie Gao",
                "Conghao Zhou",
                "Xuemin Shen",
                "Weihua Zhuang"
            ],
            "link": [
                "http://dx.doi.org/10.1109/JSTSP.2023.3276595",
                "http://arxiv.org/abs/2311.10645v1",
                "http://arxiv.org/pdf/2311.10645v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.MM",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10642v3",
            "title": "Rethinking Attention: Exploring Shallow Feed-Forward Neural Networks as\n  an Alternative to Attention Layers in Transformers",
            "updated": "2023-11-29T10:41:36Z",
            "published": "2023-11-17T16:58:52Z",
            "summary": "This work presents an analysis of the effectiveness of using standard shallow\nfeed-forward networks to mimic the behavior of the attention mechanism in the\noriginal Transformer model, a state-of-the-art architecture for\nsequence-to-sequence tasks. We substitute key elements of the attention\nmechanism in the Transformer with simple feed-forward networks, trained using\nthe original components via knowledge distillation. Our experiments, conducted\non the IWSLT2017 dataset, reveal the capacity of these \"attentionless\nTransformers\" to rival the performance of the original architecture. Through\nrigorous ablation studies, and experimenting with various replacement network\ntypes and sizes, we offer insights that support the viability of our approach.\nThis not only sheds light on the adaptability of shallow feed-forward networks\nin emulating attention mechanisms but also underscores their potential to\nstreamline complex architectures for sequence-to-sequence tasks.",
            "author": [
                "Vukasin Bozic",
                "Danilo Dordevic",
                "Daniele Coppola",
                "Joseph Thommes",
                "Sidak Pal Singh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10642v3",
                "http://arxiv.org/pdf/2311.10642v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10641v1",
            "title": "Image-Domain Material Decomposition for Dual-energy CT using\n  Unsupervised Learning with Data-fidelity Loss",
            "updated": "2023-11-17T16:58:16Z",
            "published": "2023-11-17T16:58:16Z",
            "summary": "Background: Dual-energy CT (DECT) and material decomposition play vital roles\nin quantitative medical imaging. However, the decomposition process may suffer\nfrom significant noise amplification, leading to severely degraded image\nsignal-to-noise ratios (SNRs). While existing iterative algorithms perform\nnoise suppression using different image priors, these heuristic image priors\ncannot accurately represent the features of the target image manifold. Although\ndeep learning-based decomposition methods have been reported, these methods are\nin the supervised-learning framework requiring paired data for training, which\nis not readily available in clinical settings.\n  Purpose: This work aims to develop an unsupervised-learning framework with\ndata-measurement consistency for image-domain material decomposition in DECT.",
            "author": [
                "Junbo Peng",
                "Chih-Wei Chang",
                "Huiqiao Xie",
                "Richard L. J. Qiu",
                "Justin Roper",
                "Tonghe Wang",
                "Beth Bradshaw",
                "Xiangyang Tang",
                "Xiaofeng Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10641v1",
                "http://arxiv.org/pdf/2311.10641v1"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10640v1",
            "title": "Multi-delay arterial spin-labeled perfusion estimation with biophysics\n  simulation and deep learning",
            "updated": "2023-11-17T16:55:14Z",
            "published": "2023-11-17T16:55:14Z",
            "summary": "Purpose: To develop biophysics-based method for estimating perfusion Q from\narterial spin labeling (ASL) images using deep learning. Methods: A 3D U-Net\n(QTMnet) was trained to estimate perfusion from 4D tracer propagation images.\nThe network was trained and tested on simulated 4D tracer concentration data\nbased on artificial vasculature structure generated by constrained constructive\noptimization (CCO) method. The trained network was further tested in a\nsynthetic brain ASL image based on vasculature network extracted from magnetic\nresonance (MR) angiography. The estimations from both trained network and a\nconventional kinetic model were compared in ASL images acquired from eight\nhealthy volunteers. Results: QTMnet accurately reconstructed perfusion Q from\nconcentration data. Relative error of the synthetic brain ASL image was 7.04%\nfor perfusion Q, lower than the error using single-delay ASL model: 25.15% for\nQ, and multi-delay ASL model: 12.62% for perfusion Q. Conclusion: QTMnet\nprovides accurate estimation on perfusion parameters and is a promising\napproach as a clinical ASL MRI image processing pipeline.",
            "author": [
                "Renjiu Hu",
                "Qihao Zhang",
                "Pascal Spincemaille",
                "Thanh D. Nguyen",
                "Yi Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10640v1",
                "http://arxiv.org/pdf/2311.10640v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10639v1",
            "title": "Mathematical morphology on directional data",
            "updated": "2023-11-17T16:51:04Z",
            "published": "2023-11-17T16:51:04Z",
            "summary": "We define morphological operators and filters for directional images whose\npixel values are unit vectors. This requires an ordering relation for unit\nvectors which is obtained by using depth functions. They provide a\ncentre-outward ordering with respect to a specified centre vector. We apply our\noperators on synthetic directional images and compare them with classical\nmorphological operators for grey-scale images. As application examples, we\nenhance the fault region in a compressed glass foam and segment misaligned\nfibre regions of glass fibre reinforced polymers.",
            "author": [
                "Konstantin Hauch",
                "Claudia Redenbach"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10639v1",
                "http://arxiv.org/pdf/2311.10639v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10638v1",
            "title": "Concept-free Causal Disentanglement with Variational Graph Auto-Encoder",
            "updated": "2023-11-17T16:50:00Z",
            "published": "2023-11-17T16:50:00Z",
            "summary": "In disentangled representation learning, the goal is to achieve a compact\nrepresentation that consists of all interpretable generative factors in the\nobservational data. Learning disentangled representations for graphs becomes\nincreasingly important as graph data rapidly grows. Existing approaches often\nrely on Variational Auto-Encoder (VAE) or its causal structure learning-based\nrefinement, which suffer from sub-optimality in VAEs due to the independence\nfactor assumption and unavailability of concept labels, respectively. In this\npaper, we propose an unsupervised solution, dubbed concept-free causal\ndisentanglement, built on a theoretically provable tight upper bound\napproximating the optimal factor. This results in an SCM-like causal structure\nmodeling that directly learns concept structures from data. Based on this idea,\nwe propose Concept-free Causal VGAE (CCVGAE) by incorporating a novel causal\ndisentanglement layer into Variational Graph Auto-Encoder. Furthermore, we\nprove concept consistency under our concept-free causal disentanglement\nframework, hence employing it to enhance the meta-learning framework, called\nconcept-free causal Meta-Graph (CC-Meta-Graph). We conduct extensive\nexperiments to demonstrate the superiority of the proposed models: CCVGAE and\nCC-Meta-Graph, reaching up to $29\\%$ and $11\\%$ absolute improvements over\nbaselines in terms of AUC, respectively.",
            "author": [
                "Jingyun Feng",
                "Lin Zhang",
                "Lili Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10638v1",
                "http://arxiv.org/pdf/2311.10638v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10635v1",
            "title": "Ex2Vec: Characterizing Users and Items from the Mere Exposure Effect",
            "updated": "2023-11-17T16:42:57Z",
            "published": "2023-11-17T16:42:57Z",
            "summary": "The traditional recommendation framework seeks to connect user and content,\nby finding the best match possible based on users past interaction. However, a\ngood content recommendation is not necessarily similar to what the user has\nchosen in the past. As humans, users naturally evolve, learn, forget, get\nbored, they change their perspective of the world and in consequence, of the\nrecommendable content. One well known mechanism that affects user interest is\nthe Mere Exposure Effect: when repeatedly exposed to stimuli, users' interest\ntends to rise with the initial exposures, reaching a peak, and gradually\ndecreasing thereafter, resulting in an inverted-U shape. Since previous\nresearch has shown that the magnitude of the effect depends on a number of\ninteresting factors such as stimulus complexity and familiarity, leveraging\nthis effect is a way to not only improve repeated recommendation but to gain a\nmore in-depth understanding of both users and stimuli. In this work we present\n(Mere) Exposure2Vec (Ex2Vec) our model that leverages the Mere Exposure Effect\nin repeat consumption to derive user and item characterization and track user\ninterest evolution. We validate our model through predicting future music\nconsumption based on repetition and discuss its implications for recommendation\nscenarios where repetition is common.",
            "author": [
                "Bruno Sguerra",
                "Viet-Anh Tran",
                "Romain Hennequin"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3604915.3608856",
                "http://arxiv.org/abs/2311.10635v1",
                "http://arxiv.org/pdf/2311.10635v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10633v1",
            "title": "Predicting the Probability of Collision of a Satellite with Space\n  Debris: A Bayesian Machine Learning Approach",
            "updated": "2023-11-17T16:41:35Z",
            "published": "2023-11-17T16:41:35Z",
            "summary": "Space is becoming more crowded in Low Earth Orbit due to increased space\nactivity. Such a dense space environment increases the risk of collisions\nbetween space objects endangering the whole space population. Therefore, the\nneed to consider collision avoidance as part of routine operations is evident\nto satellite operators. Current procedures rely on the analysis of multiple\ncollision warnings by human analysts. However, with the continuous growth of\nthe space population, this manual approach may become unfeasible, highlighting\nthe importance of automation in risk assessment. In 2019, ESA launched a\ncompetition to study the feasibility of applying machine learning in collision\nrisk estimation and released a dataset that contained sequences of Conjunction\nData Messages (CDMs) in support of real close encounters. The competition\nresults showed that the naive forecast and its variants are strong predictors\nfor this problem, which suggests that the CDMs may follow the Markov property.\nThe proposed work investigates this theory by benchmarking Hidden Markov Models\n(HMM) in predicting the risk of collision between two resident space objects by\nusing one feature of the entire dataset: the sequence of the probability in the\nCDMs. In addition, Bayesian statistics are used to infer a joint distribution\nfor the parameters of the models, which allows the development of robust and\nreliable probabilistic predictive models that can incorporate physical or prior\nknowledge about the problem within a rigorous theoretical framework and\nprovides prediction uncertainties that nicely reflect the accuracy of the\npredicted risk. This work shows that the implemented HMM outperforms the naive\nsolution in some metrics, which further adds to the idea that the collision\nwarnings may be Markovian and suggests that this is a powerful method to be\nfurther explored.",
            "author": [
                "Jo\u00e3o Sim\u00f5es Catulo",
                "Cl\u00e1udia Soares",
                "Marta Guimar\u00e3es"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10633v1",
                "http://arxiv.org/pdf/2311.10633v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10617v1",
            "title": "Astronomical Images Quality Assessment with Automated Machine Learning",
            "updated": "2023-11-17T16:14:11Z",
            "published": "2023-11-17T16:14:11Z",
            "summary": "Electronically Assisted Astronomy consists in capturing deep sky images with\na digital camera coupled to a telescope to display views of celestial objects\nthat would have been invisible through direct observation. This practice\ngenerates a large quantity of data, which may then be enhanced with dedicated\nimage editing software after observation sessions. In this study, we show how\nImage Quality Assessment can be useful for automatically rating astronomical\nimages, and we also develop a dedicated model by using Automated Machine\nLearning.",
            "author": [
                "Olivier Parisot",
                "Pierrick Bruneau",
                "Patrik Hitzelberger"
            ],
            "link": [
                "http://dx.doi.org/10.5220/0012073800003541",
                "http://arxiv.org/abs/2311.10617v1",
                "http://arxiv.org/pdf/2311.10617v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10610v1",
            "title": "A Poincar\u00e9 Inequality and Consistency Results for Signal Sampling on\n  Large Graphs",
            "updated": "2023-11-17T16:04:31Z",
            "published": "2023-11-17T16:04:31Z",
            "summary": "Large-scale graph machine learning is challenging as the complexity of\nlearning models scales with the graph size. Subsampling the graph is a viable\nalternative, but sampling on graphs is nontrivial as graphs are non-Euclidean.\nExisting graph sampling techniques require not only computing the spectra of\nlarge matrices but also repeating these computations when the graph changes,\ne.g., grows. In this paper, we introduce a signal sampling theory for a type of\ngraph limit -- the graphon. We prove a Poincar\\'e inequality for graphon\nsignals and show that complements of node subsets satisfying this inequality\nare unique sampling sets for Paley-Wiener spaces of graphon signals. Exploiting\nconnections with spectral clustering and Gaussian elimination, we prove that\nsuch sampling sets are consistent in the sense that unique sampling sets on a\nconvergent graph sequence converge to unique sampling sets on the graphon. We\nthen propose a related graphon signal sampling algorithm for large graphs, and\ndemonstrate its good empirical performance on graph machine learning tasks.",
            "author": [
                "Thien Le",
                "Luana Ruiz",
                "Stefanie Jegelka"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10610v1",
                "http://arxiv.org/pdf/2311.10610v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10609v1",
            "title": "Scaling TabPFN: Sketching and Feature Selection for Tabular Prior-Data\n  Fitted Networks",
            "updated": "2023-11-17T16:04:27Z",
            "published": "2023-11-17T16:04:27Z",
            "summary": "Tabular classification has traditionally relied on supervised algorithms,\nwhich estimate the parameters of a prediction model using its training data.\nRecently, Prior-Data Fitted Networks (PFNs) such as TabPFN have successfully\nlearned to classify tabular data in-context: the model parameters are designed\nto classify new samples based on labelled training samples given after the\nmodel training. While such models show great promise, their applicability to\nreal-world data remains limited due to the computational scale needed. Here we\nstudy the following question: given a pre-trained PFN for tabular data, what is\nthe best way to summarize the labelled training samples before feeding them to\nthe model? We conduct an initial investigation of sketching and\nfeature-selection methods for TabPFN, and note certain key differences between\nit and conventionally fitted tabular models.",
            "author": [
                "Benjamin Feuer",
                "Chinmay Hegde",
                "Niv Cohen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10609v1",
                "http://arxiv.org/pdf/2311.10609v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DB"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10607v1",
            "title": "Active Inference on the Edge: A Design Study",
            "updated": "2023-11-17T16:03:04Z",
            "published": "2023-11-17T16:03:04Z",
            "summary": "Machine Learning (ML) is a common tool to interpret and predict the behavior\nof distributed computing systems, e.g., to optimize the task distribution\nbetween devices. As more and more data is created by Internet of Things (IoT)\ndevices, data processing and ML training are carried out by edge devices in\nclose proximity. To ensure Quality of Service (QoS) throughout these\noperations, systems are supervised and dynamically adapted with the help of ML.\nHowever, as long as ML models are not retrained, they fail to capture gradual\nshifts in the variable distribution, leading to an inaccurate view of the\nsystem state. Moreover, as the prediction accuracy decreases, the reporting\ndevice should actively resolve uncertainties to improve the model's precision.\nSuch a level of self-determination could be provided by Active Inference (ACI)\n-- a concept from neuroscience that describes how the brain constantly predicts\nand evaluates sensory information to decrease long-term surprise. We\nencompassed these concepts in a single action-perception cycle, which we\nimplemented for distributed agents in a smart manufacturing use case. As a\nresult, we showed how our ACI agent was able to quickly and traceably solve an\noptimization problem while fulfilling QoS requirements.",
            "author": [
                "Boris Sedlak",
                "Victor Casamayor Pujol",
                "Praveen Kumar Donta",
                "Schahram Dustdar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10607v1",
                "http://arxiv.org/pdf/2311.10607v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.AI",
                "cs.DC",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10605v1",
            "title": "CA-Jaccard: Camera-aware Jaccard Distance for Person Re-identification",
            "updated": "2023-11-17T16:01:06Z",
            "published": "2023-11-17T16:01:06Z",
            "summary": "Person re-identification (re-ID) is a challenging task that aims to learn\ndiscriminative features for person retrieval. In person re-ID, Jaccard distance\nis a widely used distance metric, especially in re-ranking and clustering\nscenarios. However, we discover that camera variation has a significant\nnegative impact on the reliability of Jaccard distance. In particular, Jaccard\ndistance calculates the distance based on the overlap of relevant neighbors.\nDue to camera variation, intra-camera samples dominate the relevant neighbors,\nwhich reduces the reliability of the neighbors by introducing intra-camera\nnegative samples and excluding inter-camera positive samples. To overcome this\nproblem, we propose a novel camera-aware Jaccard (CA-Jaccard) distance that\nleverages camera information to enhance the reliability of Jaccard distance.\nSpecifically, we introduce camera-aware k-reciprocal nearest neighbors (CKRNNs)\nto find k-reciprocal nearest neighbors on the intra-camera and inter-camera\nranking lists, which improves the reliability of relevant neighbors and\nguarantees the contribution of inter-camera samples in the overlap. Moreover,\nwe propose a camera-aware local query expansion (CLQE) to exploit camera\nvariation as a strong constraint to mine reliable samples in relevant neighbors\nand assign these samples higher weights in overlap to further improve the\nreliability. Our CA-Jaccard distance is simple yet effective and can serve as a\ngeneral distance metric for person re-ID methods with high reliability and low\ncomputational cost. Extensive experiments demonstrate the effectiveness of our\nmethod.",
            "author": [
                "Yiyu Chen",
                "Zheyi Fan",
                "Zhaoru Chen",
                "Yixuan Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10605v1",
                "http://arxiv.org/pdf/2311.10605v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10597v1",
            "title": "Designing Reconfigurable Intelligent Systems with Markov Blankets",
            "updated": "2023-11-17T15:49:56Z",
            "published": "2023-11-17T15:49:56Z",
            "summary": "Compute Continuum (CC) systems comprise a vast number of devices distributed\nover computational tiers. Evaluating business requirements, i.e., Service Level\nObjectives (SLOs), requires collecting data from all those devices; if SLOs are\nviolated, devices must be reconfigured to ensure correct operation. If done\ncentrally, this dramatically increases the number of devices and variables that\nmust be considered, while creating an enormous communication overhead. To\naddress this, we (1) introduce a causality filter based on Markov blankets (MB)\nthat limits the number of variables that each device must track, (2) evaluate\nSLOs decentralized on a device basis, and (3) infer optimal device\nconfiguration for fulfilling SLOs. We evaluated our methodology by analyzing\nvideo stream transformations and providing device configurations that ensure\nthe Quality of Service (QoS). The devices thus perceived their environment and\nacted accordingly -- a form of decentralized intelligence.",
            "author": [
                "Boris Sedlak",
                "Victor Casamayor Pujol",
                "Praveen Kumar Donta",
                "Schahram Dustdar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10597v1",
                "http://arxiv.org/pdf/2311.10597v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.AI",
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10596v1",
            "title": "Hashing it Out: Predicting Unhealthy Conversations on Twitter",
            "updated": "2023-11-17T15:49:11Z",
            "published": "2023-11-17T15:49:11Z",
            "summary": "Personal attacks in the context of social media conversations often lead to\nfast-paced derailment, leading to even more harmful exchanges being made.\nState-of-the-art systems for the detection of such conversational derailment\noften make use of deep learning approaches for prediction purposes. In this\npaper, we show that an Attention-based BERT architecture, pre-trained on a\nlarge Twitter corpus and fine-tuned on our task, is efficient and effective in\nmaking such predictions. This model shows clear advantages in performance to\nthe existing LSTM model we use as a baseline. Additionally, we show that this\nimpressive performance can be attained through fine-tuning on a relatively\nsmall, novel dataset, particularly after mitigating overfitting issues through\nsynthetic oversampling techniques. By introducing the first transformer based\nmodel for forecasting conversational events on Twitter, this work lays the\nfoundation for a practical tool to encourage better interactions on one of the\nmost ubiquitous social media platforms.",
            "author": [
                "Steven Leung",
                "Filippos Papapolyzos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10596v1",
                "http://arxiv.org/pdf/2311.10596v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10591v1",
            "title": "FOCAL: A Cost-Aware Video Dataset for Active Learning",
            "updated": "2023-11-17T15:46:09Z",
            "published": "2023-11-17T15:46:09Z",
            "summary": "In this paper, we introduce the FOCAL (Ford-OLIVES Collaboration on Active\nLearning) dataset which enables the study of the impact of annotation-cost\nwithin a video active learning setting. Annotation-cost refers to the time it\ntakes an annotator to label and quality-assure a given video sequence. A\npractical motivation for active learning research is to minimize\nannotation-cost by selectively labeling informative samples that will maximize\nperformance within a given budget constraint. However, previous work in video\nactive learning lacks real-time annotation labels for accurately assessing cost\nminimization and instead operates under the assumption that annotation-cost\nscales linearly with the amount of data to annotate. This assumption does not\ntake into account a variety of real-world confounding factors that contribute\nto a nonlinear cost such as the effect of an assistive labeling tool and the\nvariety of interactions within a scene such as occluded objects, weather, and\nmotion of objects. FOCAL addresses this discrepancy by providing real\nannotation-cost labels for 126 video sequences across 69 unique city scenes\nwith a variety of weather, lighting, and seasonal conditions. We also introduce\na set of conformal active learning algorithms that take advantage of the\nsequential structure of video data in order to achieve a better trade-off\nbetween annotation-cost and performance while also reducing floating point\noperations (FLOPS) overhead by at least 77.67%. We show how these approaches\nbetter reflect how annotations on videos are done in practice through a\nsequence selection framework. We further demonstrate the advantage of these\napproaches by introducing two performance-cost metrics and show that the best\nconformal active learning method is cheaper than the best traditional active\nlearning method by 113 hours.",
            "author": [
                "Kiran Kokilepersaud",
                "Yash-Yee Logan",
                "Ryan Benkert",
                "Chen Zhou",
                "Mohit Prabhushankar",
                "Ghassan AlRegib",
                "Enrique Corona",
                "Kunjan Singh",
                "Mostafa Parchami"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10591v1",
                "http://arxiv.org/pdf/2311.10591v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10590v1",
            "title": "EduGym: An Environment Suite for Reinforcement Learning Education",
            "updated": "2023-11-17T15:45:00Z",
            "published": "2023-11-17T15:45:00Z",
            "summary": "Due to the empirical success of reinforcement learning, an increasing number\nof students study the subject. However, from our practical teaching experience,\nwe see students entering the field (bachelor, master and early PhD) often\nstruggle. On the one hand, textbooks and (online) lectures provide the\nfundamentals, but students find it hard to translate between equations and\ncode. On the other hand, public codebases do provide practical examples, but\nthe implemented algorithms tend to be complex, and the underlying test\nenvironments contain multiple reinforcement learning challenges at once.\nAlthough this is realistic from a research perspective, it often hinders\neducational conceptual understanding. To solve this issue we introduce EduGym,\na set of educational reinforcement learning environments and associated\ninteractive notebooks tailored for education. Each EduGym environment is\nspecifically designed to illustrate a certain aspect/challenge of reinforcement\nlearning (e.g., exploration, partial observability, stochasticity, etc.), while\nthe associated interactive notebook explains the challenge and its possible\nsolution approaches, connecting equations and code in a single document. An\nevaluation among RL students and researchers shows 86% of them think EduGym is\na useful tool for reinforcement learning education. All notebooks are available\nfrom https://sites.google.com/view/edu-gym/home, while the full software\npackage can be installed from https://github.com/RLG-Leiden/edugym.",
            "author": [
                "Thomas M. Moerland",
                "Matthias M\u00fcller-Brockhausen",
                "Zhao Yang",
                "Andrius Bernatavicius",
                "Koen Ponse",
                "Tom Kouwenhoven",
                "Andreas Sauter",
                "Michiel van der Meer",
                "Bram Renting",
                "Aske Plaat"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10590v1",
                "http://arxiv.org/pdf/2311.10590v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CY",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10582v1",
            "title": "Human motion trajectory prediction using the Social Force Model for\n  real-time and low computational cost applications",
            "updated": "2023-11-17T15:32:21Z",
            "published": "2023-11-17T15:32:21Z",
            "summary": "Human motion trajectory prediction is a very important functionality for\nhuman-robot collaboration, specifically in accompanying, guiding, or\napproaching tasks, but also in social robotics, self-driving vehicles, or\nsecurity systems. In this paper, a novel trajectory prediction model, Social\nForce Generative Adversarial Network (SoFGAN), is proposed. SoFGAN uses a\nGenerative Adversarial Network (GAN) and Social Force Model (SFM) to generate\ndifferent plausible people trajectories reducing collisions in a scene.\nFurthermore, a Conditional Variational Autoencoder (CVAE) module is added to\nemphasize the destination learning. We show that our method is more accurate in\nmaking predictions in UCY or BIWI datasets than most of the current\nstate-of-the-art models and also reduces collisions in comparison to other\napproaches. Through real-life experiments, we demonstrate that the model can be\nused in real-time without GPU's to perform good quality predictions with a low\ncomputational cost.",
            "author": [
                "Oscar Gil",
                "Alberto Sanfeliu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10582v1",
                "http://arxiv.org/pdf/2311.10582v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10580v1",
            "title": "Implicit Maximum a Posteriori Filtering via Adaptive Optimization",
            "updated": "2023-11-17T15:30:44Z",
            "published": "2023-11-17T15:30:44Z",
            "summary": "Bayesian filtering approximates the true underlying behavior of a\ntime-varying system by inverting an explicit generative model to convert noisy\nmeasurements into state estimates. This process typically requires either\nstorage, inversion, and multiplication of large matrices or Monte Carlo\nestimation, neither of which are practical in high-dimensional state spaces\nsuch as the weight spaces of artificial neural networks. Here, we frame the\nstandard Bayesian filtering problem as optimization over a time-varying\nobjective. Instead of maintaining matrices for the filtering equations or\nsimulating particles, we specify an optimizer that defines the Bayesian filter\nimplicitly. In the linear-Gaussian setting, we show that every Kalman filter\nhas an equivalent formulation using K steps of gradient descent. In the\nnonlinear setting, our experiments demonstrate that our framework results in\nfilters that are effective, robust, and scalable to high-dimensional systems,\ncomparing well against the standard toolbox of Bayesian filtering solutions. We\nsuggest that it is easier to fine-tune an optimizer than it is to specify the\ncorrect filtering equations, making our framework an attractive option for\nhigh-dimensional filtering problems.",
            "author": [
                "Gianluca M. Bencomo",
                "Jake C. Snell",
                "Thomas L. Griffiths"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10580v1",
                "http://arxiv.org/pdf/2311.10580v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10579v1",
            "title": "Graph Neural Networks for Pressure Estimation in Water Distribution\n  Systems",
            "updated": "2023-11-17T15:30:12Z",
            "published": "2023-11-17T15:30:12Z",
            "summary": "Pressure and flow estimation in Water Distribution Networks (WDN) allows\nwater management companies to optimize their control operations. For many\nyears, mathematical simulation tools have been the most common approach to\nreconstructing an estimate of the WDN hydraulics. However, pure physics-based\nsimulations involve several challenges, e.g. partially observable data, high\nuncertainty, and extensive manual configuration. Thus, data-driven approaches\nhave gained traction to overcome such limitations. In this work, we combine\nphysics-based modeling and Graph Neural Networks (GNN), a data-driven approach,\nto address the pressure estimation problem. First, we propose a new data\ngeneration method using a mathematical simulation but not considering temporal\npatterns and including some control parameters that remain untouched in\nprevious works; this contributes to a more diverse training data. Second, our\ntraining strategy relies on random sensor placement making our GNN-based\nestimation model robust to unexpected sensor location changes. Third, a\nrealistic evaluation protocol considers real temporal patterns and additionally\ninjects the uncertainties intrinsic to real-world scenarios. Finally, a\nmulti-graph pre-training strategy allows the model to be reused for pressure\nestimation in unseen target WDNs. Our GNN-based model estimates the pressure of\na large-scale WDN in The Netherlands with a MAE of 1.94mH$_2$O and a MAPE of\n7%, surpassing the performance of previous studies. Likewise, it outperformed\nprevious approaches on other WDN benchmarks, showing a reduction of absolute\nerror up to approximately 52% in the best cases.",
            "author": [
                "Huy Truong",
                "Andr\u00e9s Tello",
                "Alexander Lazovik",
                "Victoria Degeler"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10579v1",
                "http://arxiv.org/pdf/2311.10579v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12041v1",
            "title": "Automated Detection of hidden Damages and Impurities in Aluminum Die\n  Casting Materials and Fibre-Metal Laminates using Low-quality X-ray\n  Radiography, Synthetic X-ray Data Augmentation by Simulation, and Machine\n  Learning",
            "updated": "2023-11-17T15:22:20Z",
            "published": "2023-11-17T15:22:20Z",
            "summary": "Detection and characterization of hidden defects, impurities, and damages in\nlayered composites like Fibre laminates, e.g., Fibre Metal Laminates (FML), as\nwell as in monolithic materials, e.g., aluminum die casting materials, is still\na challenge. This work discusses methods and challenges in data-driven modeling\nof automated damage and defect detectors using X-ray single- and\nmulti-projection (CT) images. Three main issues are identified: Data and\nfeature variance, data feature labeling (for supervised machine learning), and\nthe missing ground truth. It will be shown that only simulation of data can\ndeliver a ground truth data set and accurate labeling. Noise has significant\nimpact on the feature detection and will be discussed. Data-driven feature\ndetectors are implemented with semantic pixel- or z-profile Convolutional\nNeural Networks and LSTM Auto-encoders. Data is measured with three different\ndevices: A low-quality and low-cost (Low-Q), a mid- and a high-quality\n(micro-CT, Mid-/High-Q) device. The goals of this work are the training of\nrobust and generalized feature detectors with synthetic data and the transition\nfrom High- and Mid-Q laboratory measuring technologies towards in-field usable\ntechnologies and methods.",
            "author": [
                "Stefan Bosse",
                "Dirk Lehmhus"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12041v1",
                "http://arxiv.org/pdf/2311.12041v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10572v1",
            "title": "SSB: Simple but Strong Baseline for Boosting Performance of Open-Set\n  Semi-Supervised Learning",
            "updated": "2023-11-17T15:14:40Z",
            "published": "2023-11-17T15:14:40Z",
            "summary": "Semi-supervised learning (SSL) methods effectively leverage unlabeled data to\nimprove model generalization. However, SSL models often underperform in\nopen-set scenarios, where unlabeled data contain outliers from novel categories\nthat do not appear in the labeled set. In this paper, we study the challenging\nand realistic open-set SSL setting, where the goal is to both correctly\nclassify inliers and to detect outliers. Intuitively, the inlier classifier\nshould be trained on inlier data only. However, we find that inlier\nclassification performance can be largely improved by incorporating\nhigh-confidence pseudo-labeled data, regardless of whether they are inliers or\noutliers. Also, we propose to utilize non-linear transformations to separate\nthe features used for inlier classification and outlier detection in the\nmulti-task learning framework, preventing adverse effects between them.\nAdditionally, we introduce pseudo-negative mining, which further boosts outlier\ndetection performance. The three ingredients lead to what we call Simple but\nStrong Baseline (SSB) for open-set SSL. In experiments, SSB greatly improves\nboth inlier classification and outlier detection performance, outperforming\nexisting methods by a large margin. Our code will be released at\nhttps://github.com/YUE-FAN/SSB.",
            "author": [
                "Yue Fan",
                "Anna Kukleva",
                "Dengxin Dai",
                "Bernt Schiele"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10572v1",
                "http://arxiv.org/pdf/2311.10572v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10571v1",
            "title": "Direct Amortized Likelihood Ratio Estimation",
            "updated": "2023-11-17T15:10:35Z",
            "published": "2023-11-17T15:10:35Z",
            "summary": "We introduce a new amortized likelihood ratio estimator for likelihood-free\nsimulation-based inference (SBI). Our estimator is simple to train and\nestimates the likelihood ratio using a single forward pass of the neural\nestimator. Our approach directly computes the likelihood ratio between two\ncompeting parameter sets which is different from the previous approach of\ncomparing two neural network output values. We refer to our model as the direct\nneural ratio estimator (DNRE). As part of introducing the DNRE, we derive a\ncorresponding Monte Carlo estimate of the posterior. We benchmark our new ratio\nestimator and compare to previous ratio estimators in the literature. We show\nthat our new ratio estimator often outperforms these previous approaches. As a\nfurther contribution, we introduce a new derivative estimator for likelihood\nratio estimators that enables us to compare likelihood-free Hamiltonian Monte\nCarlo (HMC) with random-walk Metropolis-Hastings (MH). We show that HMC is\nequally competitive, which has not been previously shown. Finally, we include a\nnovel real-world application of SBI by using our neural ratio estimator to\ndesign a quadcopter. Code is available at https://github.com/SRI-CSL/dnre.",
            "author": [
                "Adam D. Cobb",
                "Brian Matejek",
                "Daniel Elenius",
                "Anirban Roy",
                "Susmit Jha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10571v1",
                "http://arxiv.org/pdf/2311.10571v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "stat.CO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12040v1",
            "title": "TransCDR: a deep learning model for enhancing the generalizability of\n  cancer drug response prediction through transfer learning and multimodal data\n  fusion for drug representation",
            "updated": "2023-11-17T14:55:12Z",
            "published": "2023-11-17T14:55:12Z",
            "summary": "Accurate and robust drug response prediction is of utmost importance in\nprecision medicine. Although many models have been developed to utilize the\nrepresentations of drugs and cancer cell lines for predicting cancer drug\nresponses (CDR), their performances can be improved by addressing issues such\nas insufficient data modality, suboptimal fusion algorithms, and poor\ngeneralizability for novel drugs or cell lines. We introduce TransCDR, which\nuses transfer learning to learn drug representations and fuses multi-modality\nfeatures of drugs and cell lines by a self-attention mechanism, to predict the\nIC50 values or sensitive states of drugs on cell lines. We are the first to\nsystematically evaluate the generalization of the CDR prediction model to novel\n(i.e., never-before-seen) compound scaffolds and cell line clusters. TransCDR\nshows better generalizability than 8 state-of-the-art models. TransCDR\noutperforms its 5 variants that train drug encoders (i.e., RNN and AttentiveFP)\nfrom scratch under various scenarios. The most critical contributors among\nmultiple drug notations and omics profiles are Extended Connectivity\nFingerprint and genetic mutation. Additionally, the attention-based fusion\nmodule further enhances the predictive performance of TransCDR. TransCDR,\ntrained on the GDSC dataset, demonstrates strong predictive performance on the\nexternal testing set CCLE. It is also utilized to predict missing CDRs on GDSC.\nMoreover, we investigate the biological mechanisms underlying drug response by\nclassifying 7,675 patients from TCGA into drug-sensitive or drug-resistant\ngroups, followed by a Gene Set Enrichment Analysis. TransCDR emerges as a\npotent tool with significant potential in drug response prediction. The source\ncode and data can be accessed at https://github.com/XiaoqiongXia/TransCDR.",
            "author": [
                "Xiaoqiong Xia",
                "Chaoyu Zhu",
                "Yuqi Shan",
                "Fan Zhong",
                "Lei Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12040v1",
                "http://arxiv.org/pdf/2311.12040v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10558v1",
            "title": "Machine Learning Assisted Characterization of Labyrinthine Pattern\n  Transitions",
            "updated": "2023-11-17T14:47:52Z",
            "published": "2023-11-17T14:47:52Z",
            "summary": "We present a comprehensive approach to characterizing labyrinthine structures\nthat often emerge as a final steady state in pattern forming systems. We employ\nmachine learning based pattern recognition techniques to identify the types and\nlocations of topological defects of the local stripe ordering to augment\nconventional Fourier analysis. A pair distribution function analysis of the\ntopological defects reveals subtle differences between labyrinthine structures\nwhich are beyond the conventional characterization methods. We utilize our\napproach to highlight a clear morphological transition between two zero-field\nlabyrinthine structures in single crystal Bi substituted Yttrium Iron Garnet\nfilms. An energy landscape picture is proposed to understand the athermal\ndynamics that governs the observed morphological transition. Our work\ndemonstrates that machine learning based recognition techniques enable novel\nstudies of rich and complex labyrinthine type structures universal to many\npattern formation systems.",
            "author": [
                "Kotaro Shimizu",
                "Vinicius Yu Okubo",
                "Rose Knight",
                "Ziyuan Wang",
                "Joseph Burton",
                "Hae Yong Kim",
                "Gia-Wei Chern",
                "B. S. Shivaram"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10558v1",
                "http://arxiv.org/pdf/2311.10558v1"
            ],
            "primary_category": "cond-mat.soft",
            "category": [
                "cond-mat.soft",
                "cond-mat.dis-nn",
                "cond-mat.str-el"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10550v1",
            "title": "RONAALP: Reduced-Order Nonlinear Approximation with Active Learning\n  Procedure",
            "updated": "2023-11-17T14:32:43Z",
            "published": "2023-11-17T14:32:43Z",
            "summary": "Many engineering applications rely on the evaluation of expensive, non-linear\nhigh-dimensional functions. In this paper, we propose the RONAALP algorithm\n(Reduced Order Nonlinear Approximation with Active Learning Procedure) to\nincrementally learn a fast and accurate reduced-order surrogate model of a\ntarget function on-the-fly as the application progresses. First, the\ncombination of nonlinear auto-encoder, community clustering and radial basis\nfunction networks allows to learn an efficient and compact surrogate model with\nlimited training data. Secondly, the active learning procedure overcome any\nextrapolation issue when evaluating the surrogate model outside of its initial\ntraining range during the online stage. This results in generalizable, fast and\naccurate reduced-order models of high-dimensional functions. The method is\ndemonstrated on three direct numerical simulations of hypersonic flows in\nchemical nonequilibrium. Accurate simulations of these flows rely on detailed\nthermochemical gas models that dramatically increase the cost of such\ncalculations. Using RONAALP to learn a reduced-order thermodynamic model\nsurrogate on-the-fly, the cost of such simulation was reduced by up to 75%\nwhile maintaining an error of less than 10% on relevant quantities of interest.",
            "author": [
                "Cl\u00e9ment Scherding",
                "Georgios Rigas",
                "Denis Sipp",
                "Peter J Schmid",
                "Taraneh Sayadi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10550v1",
                "http://arxiv.org/pdf/2311.10550v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10807v1",
            "title": "SENetV2: Aggregated dense layer for channelwise and global\n  representations",
            "updated": "2023-11-17T14:10:57Z",
            "published": "2023-11-17T14:10:57Z",
            "summary": "Convolutional Neural Networks (CNNs) have revolutionized image classification\nby extracting spatial features and enabling state-of-the-art accuracy in\nvision-based tasks. The squeeze and excitation network proposed module gathers\nchannelwise representations of the input. Multilayer perceptrons (MLP) learn\nglobal representation from the data and in most image classification models\nused to learn extracted features of the image. In this paper, we introduce a\nnovel aggregated multilayer perceptron, a multi-branch dense layer, within the\nSqueeze excitation residual module designed to surpass the performance of\nexisting architectures. Our approach leverages a combination of squeeze\nexcitation network module with dense layers. This fusion enhances the network's\nability to capture channel-wise patterns and have global knowledge, leading to\na better feature representation. This proposed model has a negligible increase\nin parameters when compared to SENet. We conduct extensive experiments on\nbenchmark datasets to validate the model and compare them with established\narchitectures. Experimental results demonstrate a remarkable increase in the\nclassification accuracy of the proposed model.",
            "author": [
                "Mahendran Narayanan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10807v1",
                "http://arxiv.org/pdf/2311.10807v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10806v1",
            "title": "SEA++: Multi-Graph-based High-Order Sensor Alignment for Multivariate\n  Time-Series Unsupervised Domain Adaptation",
            "updated": "2023-11-17T13:54:18Z",
            "published": "2023-11-17T13:54:18Z",
            "summary": "Unsupervised Domain Adaptation (UDA) methods have been successful in reducing\nlabel dependency by minimizing the domain discrepancy between a labeled source\ndomain and an unlabeled target domain. However, these methods face challenges\nwhen dealing with Multivariate Time-Series (MTS) data. MTS data typically\nconsist of multiple sensors, each with its own unique distribution. This\ncharacteristic makes it hard to adapt existing UDA methods, which mainly focus\non aligning global features while overlooking the distribution discrepancies at\nthe sensor level, to reduce domain discrepancies for MTS data. To address this\nissue, a practical domain adaptation scenario is formulated as Multivariate\nTime-Series Unsupervised Domain Adaptation (MTS-UDA). In this paper, we propose\nSEnsor Alignment (SEA) for MTS-UDA, aiming to reduce domain discrepancy at both\nthe local and global sensor levels. At the local sensor level, we design\nendo-feature alignment, which aligns sensor features and their correlations\nacross domains. To reduce domain discrepancy at the global sensor level, we\ndesign exo-feature alignment that enforces restrictions on global sensor\nfeatures. We further extend SEA to SEA++ by enhancing the endo-feature\nalignment. Particularly, we incorporate multi-graph-based high-order alignment\nfor both sensor features and their correlations. Extensive empirical results\nhave demonstrated the state-of-the-art performance of our SEA and SEA++ on\npublic MTS datasets for MTS-UDA.",
            "author": [
                "Yucheng Wang",
                "Yuecong Xu",
                "Jianfei Yang",
                "Min Wu",
                "Xiaoli Li",
                "Lihua Xie",
                "Zhenghua Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10806v1",
                "http://arxiv.org/pdf/2311.10806v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10805v1",
            "title": "Towards a Standardized Reinforcement Learning Framework for AAM\n  Contingency Management",
            "updated": "2023-11-17T13:54:02Z",
            "published": "2023-11-17T13:54:02Z",
            "summary": "Advanced Air Mobility (AAM) is the next generation of air transportation that\nincludes new entrants such as electric vertical takeoff and landing (eVTOL)\naircraft, increasingly autonomous flight operations, and small UAS package\ndelivery. With these new vehicles and operational concepts comes a desire to\nincrease densities far beyond what occurs today in and around urban areas, to\nutilize new battery technology, and to move toward more autonomously-piloted\naircraft. To achieve these goals, it becomes essential to introduce new safety\nmanagement system capabilities that can rapidly assess risk as it evolves\nacross a span of complex hazards and, if necessary, mitigate risk by executing\nappropriate contingencies via supervised or automated decision-making during\nflights. Recently, reinforcement learning has shown promise for real-time\ndecision making across a wide variety of applications including contingency\nmanagement. In this work, we formulate the contingency management problem as a\nMarkov Decision Process (MDP) and integrate the contingency management MDP into\nthe AAM-Gym simulation framework. This enables rapid prototyping of\nreinforcement learning algorithms and evaluation of existing systems, thus\nproviding a community benchmark for future algorithm development. We report\nbaseline statistical information for the environment and provide example\nperformance metrics.",
            "author": [
                "Luis E. Alvarez",
                "Marc W. Brittain",
                "Kara Breeden"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10805v1",
                "http://arxiv.org/pdf/2311.10805v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10525v1",
            "title": "Utilizing VQ-VAE for End-to-End Health Indicator Generation in\n  Predicting Rolling Bearing RUL",
            "updated": "2023-11-17T13:45:31Z",
            "published": "2023-11-17T13:45:31Z",
            "summary": "The prediction of the remaining useful life (RUL) of rolling bearings is a\npivotal issue in industrial production. A crucial approach to tackling this\nissue involves transforming vibration signals into health indicators (HI) to\naid model training. This paper presents an end-to-end HI construction method,\nvector quantised variational autoencoder (VQ-VAE), which addresses the need for\ndimensionality reduction of latent variables in traditional unsupervised\nlearning methods such as autoencoder. Moreover, concerning the inadequacy of\ntraditional statistical metrics in reflecting curve fluctuations accurately,\ntwo novel statistical metrics, mean absolute distance (MAD) and mean variance\n(MV), are introduced. These metrics accurately depict the fluctuation patterns\nin the curves, thereby indicating the model's accuracy in discerning similar\nfeatures. On the PMH2012 dataset, methods employing VQ-VAE for label\nconstruction achieved lower values for MAD and MV. Furthermore, the ASTCN\nprediction model trained with VQ-VAE labels demonstrated commendable\nperformance, attaining the lowest values for MAD and MV.",
            "author": [
                "Junliang Wang",
                "Qinghua Zhang",
                "Guanhua Zhu",
                "Guoxi Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10525v1",
                "http://arxiv.org/pdf/2311.10525v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10517v1",
            "title": "Mind the map! Accounting for existing map information when estimating\n  online HDMaps from sensor data",
            "updated": "2023-11-17T13:40:10Z",
            "published": "2023-11-17T13:40:10Z",
            "summary": "Online High Definition Map (HDMap) estimation from sensors offers a low-cost\nalternative to manually acquired HDMaps. As such, it promises to lighten costs\nfor already HDMap-reliant Autonomous Driving systems, and potentially even\nspread their use to new systems. In this paper, we propose to improve online\nHDMap estimation by accounting for already existing maps. We identify 3\nreasonable types of useful existing maps (minimalist, noisy, and outdated). We\nalso introduce MapEX, a novel online HDMap estimation framework that accounts\nfor existing maps. MapEX achieves this by encoding map elements into query\ntokens and by refining the matching algorithm used to train classic query based\nmap estimation models. We demonstrate that MapEX brings significant\nimprovements on the nuScenes dataset. For instance, MapEX - given noisy maps -\nimproves by 38% over the MapTRv2 detector it is based on and by 16% over the\ncurrent SOTA.",
            "author": [
                "R\u00e9my Sun",
                "Li Yang",
                "Diane Lingrand",
                "Fr\u00e9d\u00e9ric Precioso"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10517v1",
                "http://arxiv.org/pdf/2311.10517v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10512v1",
            "title": "Causal Fairness-Guided Dataset Reweighting using Neural Networks",
            "updated": "2023-11-17T13:31:19Z",
            "published": "2023-11-17T13:31:19Z",
            "summary": "The importance of achieving fairness in machine learning models cannot be\noverstated. Recent research has pointed out that fairness should be examined\nfrom a causal perspective, and several fairness notions based on the on Pearl's\ncausal framework have been proposed. In this paper, we construct a reweighting\nscheme of datasets to address causal fairness. Our approach aims at mitigating\nbias by considering the causal relationships among variables and incorporating\nthem into the reweighting process. The proposed method adopts two neural\nnetworks, whose structures are intentionally used to reflect the structures of\na causal graph and of an interventional graph. The two neural networks can\napproximate the causal model of the data, and the causal model of\ninterventions. Furthermore, reweighting guided by a discriminator is applied to\nachieve various fairness notions. Experiments on real-world datasets show that\nour method can achieve causal fairness on the data while remaining close to the\noriginal data for downstream tasks.",
            "author": [
                "Xuan Zhao",
                "Klaus Broelemann",
                "Salvatore Ruggieri",
                "Gjergji Kasneci"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10512v1",
                "http://arxiv.org/pdf/2311.10512v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10507v1",
            "title": "Combining astrophysical datasets with CRUMB",
            "updated": "2023-11-17T13:17:54Z",
            "published": "2023-11-17T13:17:54Z",
            "summary": "At present, the field of astronomical machine learning lacks widely-used\nbenchmarking datasets; most research employs custom-made datasets which are\noften not publicly released, making comparisons between models difficult. In\nthis paper we present CRUMB, a publicly-available image dataset of\nFanaroff-Riley galaxies constructed from four \"parent\" datasets extant in the\nliterature. In addition to providing the largest image dataset of these\ngalaxies, CRUMB uses a two-tier labelling system: a \"basic\" label for\nclassification and a \"complete\" label which provides the original class labels\nused in the four parent datasets, allowing for disagreements in an image's\nclass between different datasets to be preserved and selective access to\nsources from any desired combination of the parent datasets.",
            "author": [
                "Fiona A. M. Porter",
                "Anna M. M. Scaife"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10507v1",
                "http://arxiv.org/pdf/2311.10507v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10501v1",
            "title": "Collaborative Word-based Pre-trained Item Representation for\n  Transferable Recommendation",
            "updated": "2023-11-17T13:02:25Z",
            "published": "2023-11-17T13:02:25Z",
            "summary": "Item representation learning (IRL) plays an essential role in recommender\nsystems, especially for sequential recommendation. Traditional sequential\nrecommendation models usually utilize ID embeddings to represent items, which\nare not shared across different domains and lack the transferable ability.\nRecent studies use pre-trained language models (PLM) for item text embeddings\n(text-based IRL) that are universally applicable across domains. However, the\nexisting text-based IRL is unaware of the important collaborative filtering\n(CF) information. In this paper, we propose CoWPiRec, an approach of\nCollaborative Word-based Pre-trained item representation for Recommendation. To\neffectively incorporate CF information into text-based IRL, we convert the\nitem-level interaction data to a word graph containing word-level\ncollaborations. Subsequently, we design a novel pre-training task to align the\nword-level semantic- and CF-related item representation. Extensive experimental\nresults on multiple public datasets demonstrate that compared to\nstate-of-the-art transferable sequential recommenders, CoWPiRec achieves\nsignificantly better performances in both fine-tuning and zero-shot settings\nfor cross-scenario recommendation and effectively alleviates the cold-start\nissue. The code is available at: https://github.com/ysh-1998/CoWPiRec.",
            "author": [
                "Shenghao Yang",
                "Chenyang Wang",
                "Yankai Liu",
                "Kangping Xu",
                "Weizhi Ma",
                "Yiqun Liu",
                "Min Zhang",
                "Haitao Zeng",
                "Junlan Feng",
                "Chao Deng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10501v1",
                "http://arxiv.org/pdf/2311.10501v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10500v2",
            "title": "From Principle to Practice: Vertical Data Minimization for Machine\n  Learning",
            "updated": "2023-11-22T14:42:12Z",
            "published": "2023-11-17T13:01:09Z",
            "summary": "Aiming to train and deploy predictive models, organizations collect large\namounts of detailed client data, risking the exposure of private information in\nthe event of a breach. To mitigate this, policymakers increasingly demand\ncompliance with the data minimization (DM) principle, restricting data\ncollection to only that data which is relevant and necessary for the task.\nDespite regulatory pressure, the problem of deploying machine learning models\nthat obey DM has so far received little attention. In this work, we address\nthis challenge in a comprehensive manner. We propose a novel vertical DM (vDM)\nworkflow based on data generalization, which by design ensures that no\nfull-resolution client data is collected during training and deployment of\nmodels, benefiting client privacy by reducing the attack surface in case of a\nbreach. We formalize and study the corresponding problem of finding\ngeneralizations that both maximize data utility and minimize empirical privacy\nrisk, which we quantify by introducing a diverse set of policy-aligned\nadversarial scenarios. Finally, we propose a range of baseline vDM algorithms,\nas well as Privacy-aware Tree (PAT), an especially effective vDM algorithm that\noutperforms all baselines across several settings. We plan to release our code\nas a publicly available library, helping advance the standardization of DM for\nmachine learning. Overall, we believe our work can help lay the foundation for\nfurther exploration and adoption of DM principles in real-world applications.",
            "author": [
                "Robin Staab",
                "Nikola Jovanovi\u0107",
                "Mislav Balunovi\u0107",
                "Martin Vechev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10500v2",
                "http://arxiv.org/pdf/2311.10500v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00795v1",
            "title": "Talent-Interview: Web-Client Cheating Detection for Online Exams",
            "updated": "2023-11-17T12:59:28Z",
            "published": "2023-11-17T12:59:28Z",
            "summary": "Online exams are more attractive after the Covid-19 pandemic. Furthermore,\nduring recruitment, online exams are used. However, there are more cheating\npossibilities for online exams. Assigning a proctor for each exam increases\ncost. At this point, automatic proctor systems detect possible cheating status.\nThis article proposes an end-to-end system and submodules to get better results\nfor online proctoring. Object detection, face recognition, human voice\ndetection, and segmentation are used in our system. Furthermore, our proposed\nmodel works on the PCs of users, meaning a client-based system. So, server cost\nis eliminated. As far as we know, it is the first time the client-based online\nproctoring system has been used for recruitment. Online exams are more\nattractive after the Covid-19 pandemic. Furthermore, during recruitment, online\nexams are used. However, there are more cheating possibilities for online\nexams. Assigning a proctor for each exam increases cost. At this point,\nautomatic proctor systems detect possible cheating status. This article\nproposes an end-to-end system and submodules to get better results for online\nproctoring. Object detection, face recognition, human voice detection, and\nsegmentation are used in our system. Furthermore, our proposed model works on\nthe PCs of users, meaning a client-based system. So, server cost is eliminated.\nAs far as we know, it is the first time the client-based online proctoring\nsystem has been used for recruitment. Furthermore, this cheating system works\nat https://www.talent-interview.com/tr/.",
            "author": [
                "Mert Ege",
                "Mustafa Ceyhan"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00795v1",
                "http://arxiv.org/pdf/2312.00795v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10489v2",
            "title": "Handling Overlapping Asymmetric Datasets -- A Twice Penalized P-Spline\n  Approach",
            "updated": "2023-11-20T13:37:58Z",
            "published": "2023-11-17T12:41:07Z",
            "summary": "Overlapping asymmetric datasets are common in data science and pose questions\nof how they can be incorporated together into a predictive analysis. In\nhealthcare datasets there is often a small amount of information that is\navailable for a larger number of patients such as an electronic health record,\nhowever a small number of patients may have had extensive further testing.\nCommon solutions such as missing imputation can often be unwise if the smaller\ncohort is significantly different in scale to the larger sample, therefore the\naim of this research is to develop a new method which can model the smaller\ncohort against a particular response, whilst considering the larger cohort\nalso. Motivated by non-parametric models, and specifically flexible smoothing\ntechniques via generalized additive models, we model a twice penalized P-Spline\napproximation method to firstly prevent over/under-fitting of the smaller\ncohort and secondly to consider the larger cohort. This second penalty is\ncreated through discrepancies in the marginal value of covariates that exist in\nboth the smaller and larger cohorts. Through data simulations, parameter\ntunings and model adaptations to consider a continuous and binary response, we\nfind our twice penalized approach offers an enhanced fit over a linear B-Spline\nand once penalized P-Spline approximation. Applying to a real-life dataset\nrelating to a person's risk of developing Non-Alcoholic Steatohepatitis, we see\nan improved model fit performance of over 65%. Areas for future work within\nthis space include adapting our method to not require dimensionality reduction\nand also consider parametric modelling methods. However, to our knowledge this\nis the first work to propose additional marginal penalties in a flexible\nregression of which we can report a vastly improved model fit that is able to\nconsider asymmetric datasets, without the need for missing data imputation.",
            "author": [
                "Matthew McTeer",
                "Robin Henderson",
                "Quentin M Anstee",
                "Paolo Missier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10489v2",
                "http://arxiv.org/pdf/2311.10489v2"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10484v1",
            "title": "Learning Agile Locomotion on Risky Terrains",
            "updated": "2023-11-17T12:32:57Z",
            "published": "2023-11-17T12:32:57Z",
            "summary": "Quadruped robots have shown remarkable mobility on various terrains through\nreinforcement learning. Yet, in the presence of sparse footholds and risky\nterrains such as stepping stones and balance beams, which require precise foot\nplacement to avoid falls, model-based approaches are often used. In this paper,\nwe show that end-to-end reinforcement learning can also enable the robot to\ntraverse risky terrains with dynamic motions. To this end, our approach\ninvolves training a generalist policy for agile locomotion on disorderly and\nsparse stepping stones before transferring its reusable knowledge to various\nmore challenging terrains by finetuning specialist policies from it. Given that\nthe robot needs to rapidly adapt its velocity on these terrains, we formulate\nthe task as a navigation task instead of the commonly used velocity tracking\nwhich constrains the robot's behavior and propose an exploration strategy to\novercome sparse rewards and achieve high robustness. We validate our proposed\nmethod through simulation and real-world experiments on an ANYmal-D robot\nachieving peak forward velocity of >= 2.5 m/s on sparse stepping stones and\nnarrow balance beams. Video: youtu.be/Z5X0J8OH6z4",
            "author": [
                "Chong Zhang",
                "Nikita Rudin",
                "David Hoeller",
                "Marco Hutter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10484v1",
                "http://arxiv.org/pdf/2311.10484v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10483v1",
            "title": "Towards General Loop Invariant Generation via Coordinating Symbolic\n  Execution and Large Language Models",
            "updated": "2023-11-17T12:27:16Z",
            "published": "2023-11-17T12:27:16Z",
            "summary": "Loop invariants, essential for program verification, are challenging to\nauto-generate especially for programs incorporating complex memory\nmanipulations. Existing approaches for generating loop invariants rely on fixed\nsets or templates, hampering adaptability to real-world programs. Recent\nefforts have explored machine learning for loop invariant generation, but the\nlack of labeled data and the need for efficient generation are still\ntroublesome. We consider the advent of the large language model (LLM) presents\na promising solution, which can analyze the separation logic assertions after\nsymbolic execution to infer loop invariants. To overcome the data scarcity\nissue, we propose a self-supervised learning paradigm to fine-tune LLM, using\nthe split-and-reassembly of predicates to create an auxiliary task and generate\nrich synthetic data for offline training. Meanwhile, the proposed interactive\nsystem between LLM and traditional verification tools provides an efficient\nonline querying process for unseen programs. Our framework can readily extend\nto new data structures or multi-loop programs since our framework only needs\nthe definitions of different separation logic predicates, aiming to bridge the\ngap between existing capabilities and requirements of loop invariant generation\nin practical scenarios. Experiments across diverse memory-manipulated programs\nhave demonstrated the performance of our proposed method compared to the\nbaselines with respect to efficiency and effectiveness.",
            "author": [
                "Chang Liu",
                "Xiwei Wu",
                "Yuan Feng",
                "Qinxiang Cao",
                "Junchi Yan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10483v1",
                "http://arxiv.org/pdf/2311.10483v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10472v1",
            "title": "End-to-end autoencoding architecture for the simultaneous generation of\n  medical images and corresponding segmentation masks",
            "updated": "2023-11-17T11:56:53Z",
            "published": "2023-11-17T11:56:53Z",
            "summary": "Despite the increasing use of deep learning in medical image segmentation,\nacquiring sufficient training data remains a challenge in the medical field. In\nresponse, data augmentation techniques have been proposed; however, the\ngeneration of diverse and realistic medical images and their corresponding\nmasks remains a difficult task, especially when working with insufficient\ntraining sets. To address these limitations, we present an end-to-end\narchitecture based on the Hamiltonian Variational Autoencoder (HVAE). This\napproach yields an improved posterior distribution approximation compared to\ntraditional Variational Autoencoders (VAE), resulting in higher image\ngeneration quality. Our method outperforms generative adversarial architectures\nunder data-scarce conditions, showcasing enhancements in image quality and\nprecise tumor mask synthesis. We conduct experiments on two publicly available\ndatasets, MICCAI's Brain Tumor Segmentation Challenge (BRATS), and Head and\nNeck Tumor Segmentation Challenge (HECKTOR), demonstrating the effectiveness of\nour method on different medical imaging modalities.",
            "author": [
                "Aghiles Kebaili",
                "J\u00e9r\u00f4me Lapuyade-Lahorgue",
                "Pierre Vera",
                "Su Ruan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10472v1",
                "http://arxiv.org/pdf/2311.10472v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10471v1",
            "title": "Regions are Who Walk Them: a Large Pre-trained Spatiotemporal Model\n  Based on Human Mobility for Ubiquitous Urban Sensing",
            "updated": "2023-11-17T11:55:11Z",
            "published": "2023-11-17T11:55:11Z",
            "summary": "User profiling and region analysis are two tasks of significant commercial\nvalue. However, in practical applications, modeling different features\ntypically involves four main steps: data preparation, data processing, model\nestablishment, evaluation, and optimization. This process is time-consuming and\nlabor-intensive. Repeating this workflow for each feature results in abundant\ndevelopment time for tasks and a reduced overall volume of task development.\nIndeed, human mobility data contains a wealth of information. Several\nsuccessful cases suggest that conducting in-depth analysis of population\nmovement data could potentially yield meaningful profiles about users and\nareas. Nonetheless, most related works have not thoroughly utilized the\nsemantic information within human mobility data and trained on a fixed number\nof the regions. To tap into the rich information within population movement,\nbased on the perspective that Regions Are Who walk them, we propose a large\nspatiotemporal model based on trajectories (RAW). It possesses the following\ncharacteristics: 1) Tailored for trajectory data, introducing a GPT-like\nstructure with a parameter count of up to 1B; 2) Introducing a spatiotemporal\nfine-tuning module, interpreting trajectories as collection of users to derive\narbitrary region embedding. This framework allows rapid task development based\non the large spatiotemporal model. We conducted extensive experiments to\nvalidate the effectiveness of our proposed large spatiotemporal model. It's\nevident that our proposed method, relying solely on human mobility data without\nadditional features, exhibits a certain level of relevance in user profiling\nand region analysis. Moreover, our model showcases promising predictive\ncapabilities in trajectory generation tasks based on the current state,\noffering the potential for further innovative work utilizing this large\nspatiotemporal model.",
            "author": [
                "Ruixing Zhang",
                "Liangzhe Han",
                "Leilei Sun",
                "Yunqi Liu",
                "Jibin Wang",
                "Weifeng Lv"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10471v1",
                "http://arxiv.org/pdf/2311.10471v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "68T30"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10468v1",
            "title": "Using Cooperative Game Theory to Prune Neural Networks",
            "updated": "2023-11-17T11:48:10Z",
            "published": "2023-11-17T11:48:10Z",
            "summary": "We show how solution concepts from cooperative game theory can be used to\ntackle the problem of pruning neural networks.\n  The ever-growing size of deep neural networks (DNNs) increases their\nperformance, but also their computational requirements. We introduce a method\ncalled Game Theory Assisted Pruning (GTAP), which reduces the neural network's\nsize while preserving its predictive accuracy. GTAP is based on eliminating\nneurons in the network based on an estimation of their joint impact on the\nprediction quality through game theoretic solutions. Specifically, we use a\npower index akin to the Shapley value or Banzhaf index, tailored using a\nprocedure similar to Dropout (commonly used to tackle overfitting problems in\nmachine learning).\n  Empirical evaluation of both feedforward networks and convolutional neural\nnetworks shows that this method outperforms existing approaches in the achieved\ntradeoff between the number of parameters and model accuracy.",
            "author": [
                "Mauricio Diaz-Ortiz Jr",
                "Benjamin Kempinski",
                "Daphne Cornelisse",
                "Yoram Bachrach",
                "Tal Kachman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10468v1",
                "http://arxiv.org/pdf/2311.10468v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CE",
                "cs.GT",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10467v1",
            "title": "NISQ-Compatible Error Correction of Quantum Data Using Modified\n  Dissipative Quantum Neural Networks",
            "updated": "2023-11-17T11:47:38Z",
            "published": "2023-11-17T11:47:38Z",
            "summary": "Using a dissipative quantum neural network (DQNN) accompanied by conjugate\nlayers, we upgrade the performance of the existing quantum auto-encoder (QAE)\nnetwork as a quantum denoiser of a noisy m-qubit GHZ state. Our new denoising\narchitecture requires a much smaller number of learning parameters, which can\ndecrease the training time, especially when a deep or stacked DQNN is needed to\napproach the highest fidelity in the Noisy Intermediate-Scale Quantum (NISQ)\nera. In QAE, we reduce the connection between the hidden layer's qubits and the\noutput's qubits to modify the decoder. The Renyi entropy of the hidden and\noutput qubits' states is analyzed with respect to other qubits during learning\niterations. During the learning process, if the hidden layer remains connected\nto the input layers, the network can almost perfectly denoise unseen noisy data\nwith a different underlying noise distribution using the learning parameters\nacquired from training data.",
            "author": [
                "Armin Ahmadkhaniha",
                "Marzieh Bathaee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10467v1",
                "http://arxiv.org/pdf/2311.10467v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10466v1",
            "title": "Mixed Reality UI Adaptations with Inaccurate and Incomplete Objectives",
            "updated": "2023-11-17T11:45:46Z",
            "published": "2023-11-17T11:45:46Z",
            "summary": "This position paper outlines a new approach to adapting 3D user interface\n(UI) layouts given the complex nature of end-user preferences. Current\noptimization techniques, which mainly rely on weighted sum methods, can be\ninflexible and result in unsatisfactory adaptations. We propose using\nmulti-objective optimization and interactive preference elicitation to provide\nsemi-automated, flexible, and effective adaptations of 3D UIs. Our approach is\ndemonstrated using an example of single-element 3D layout adaptation with\nergonomic objectives. Future work is needed to address questions around the\npresentation and selection of optimal solutions, the impact on cognitive load,\nand the integration of preference learning. We conclude that, to make adaptive\n3D UIs truly effective, we must acknowledge the limitations of our optimization\nobjectives and techniques and emphasize the importance of user control.",
            "author": [
                "Christoph Albert Johns",
                "Jo\u00e3o Marcelo Evangelista Belo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10466v1",
                "http://arxiv.org/pdf/2311.10466v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10463v1",
            "title": "Correlation-Distance Graph Learning for Treatment Response Prediction\n  from rs-fMRI",
            "updated": "2023-11-17T11:34:01Z",
            "published": "2023-11-17T11:34:01Z",
            "summary": "Resting-state fMRI (rs-fMRI) functional connectivity (FC) analysis provides\nvaluable insights into the relationships between different brain regions and\ntheir potential implications for neurological or psychiatric disorders.\nHowever, specific design efforts to predict treatment response from rs-fMRI\nremain limited due to difficulties in understanding the current brain state and\nthe underlying mechanisms driving the observed patterns, which limited the\nclinical application of rs-fMRI. To overcome that, we propose a graph learning\nframework that captures comprehensive features by integrating both correlation\nand distance-based similarity measures under a contrastive loss. This approach\nresults in a more expressive framework that captures brain dynamic features at\ndifferent scales and enables more accurate prediction of treatment response.\nOur experiments on the chronic pain and depersonalization disorder datasets\ndemonstrate that our proposed method outperforms current methods in different\nscenarios. To the best of our knowledge, we are the first to explore the\nintegration of distance-based and correlation-based neural similarity into\ngraph learning for treatment response prediction.",
            "author": [
                "Xiatian Zhang",
                "Sisi Zheng",
                "Hubert P. H. Shum",
                "Haozheng Zhang",
                "Nan Song",
                "Mingkang Song",
                "Hongxiao Jia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10463v1",
                "http://arxiv.org/pdf/2311.10463v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10456v1",
            "title": "Accurate and Fast Fischer-Tropsch Reaction Microkinetics using PINNs",
            "updated": "2023-11-17T11:21:09Z",
            "published": "2023-11-17T11:21:09Z",
            "summary": "Microkinetics allows detailed modelling of chemical transformations occurring\nin many industrially relevant reactions. Traditional way of solving the\nmicrokinetics model for Fischer-Tropsch synthesis (FTS) becomes inefficient\nwhen it comes to more advanced real-time applications. In this work, we address\nthese challenges by using physics-informed neural networks(PINNs) for modelling\nFTS microkinetics. We propose a computationally efficient and accurate method,\nenabling the ultra-fast solution of the existing microkinetics models in\nrealistic process conditions. The proposed PINN model computes the fraction of\nvacant catalytic sites, a key quantity in FTS microkinetics, with median\nrelative error (MRE) of 0.03%, and the FTS product formation rates with MRE of\n0.1%. Compared to conventional equation solvers, the model achieves up to 1E+06\ntimes speed-up when running on GPUs, thus being fast enough for multi-scale and\nmulti-physics reactor modelling and enabling its applications in real-time\nprocess control and optimization.",
            "author": [
                "Harshil Patel",
                "Aniruddha Panda",
                "Tymofii Nikolaienko",
                "Stanislav Jaso",
                "Alejandro Lopez",
                "Kaushic Kalyanaraman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10456v1",
                "http://arxiv.org/pdf/2311.10456v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "physics.chem-ph",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10448v1",
            "title": "DeepClean: Machine Unlearning on the Cheap by Resetting Privacy\n  Sensitive Weights using the Fisher Diagonal",
            "updated": "2023-11-17T11:03:13Z",
            "published": "2023-11-17T11:03:13Z",
            "summary": "Machine learning models trained on sensitive or private data can\ninadvertently memorize and leak that information. Machine unlearning seeks to\nretroactively remove such details from model weights to protect privacy. We\ncontribute a lightweight unlearning algorithm that leverages the Fisher\nInformation Matrix (FIM) for selective forgetting. Prior work in this area\nrequires full retraining or large matrix inversions, which are computationally\nexpensive. Our key insight is that the diagonal elements of the FIM, which\nmeasure the sensitivity of log-likelihood to changes in weights, contain\nsufficient information for effective forgetting. Specifically, we compute the\nFIM diagonal over two subsets -- the data to retain and forget -- for all\ntrainable weights. This diagonal representation approximates the complete FIM\nwhile dramatically reducing computation. We then use it to selectively update\nweights to maximize forgetting of the sensitive subset while minimizing impact\non the retained subset. Experiments show that our algorithm can successfully\nforget any randomly selected subsets of training data across neural network\narchitectures. By leveraging the FIM diagonal, our approach provides an\ninterpretable, lightweight, and efficient solution for machine unlearning with\npractical privacy benefits.",
            "author": [
                "Jiaeli Shi",
                "Najah Ghalyan",
                "Kostis Gourgoulias",
                "John Buford",
                "Sean Moran"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10448v1",
                "http://arxiv.org/pdf/2311.10448v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10441v1",
            "title": "Retrieving positions of closely packed sub-wavelength nanoparticles from\n  their diffraction patterns",
            "updated": "2023-11-17T10:36:27Z",
            "published": "2023-11-17T10:36:27Z",
            "summary": "Distinguishing two objects or point sources located closer than the Rayleigh\ndistance is impossible in conventional microscopy. Understandably, the task\nbecomes increasingly harder with a growing number of particles placed in close\nproximity. It has been recently demonstrated that subwavelength nanoparticles\nin closely packed clusters can be counted by AI-enabled analysis of the\ndiffraction patterns of coherent light scattered by the cluster. Here we show\nthat deep learning analysis can determine the actual position of the\nnanoparticle in the cluster of subwavelength particles from a sing-shot\ndiffraction pattern even if they are separated by distances below the Rayleigh\nresolution limit of a conventional microscope.",
            "author": [
                "Benquan Wang",
                "Ruyi An",
                "Eng Aik Chan",
                "Giorgio Adamo",
                "Jin-Kyu So",
                "Yewen Li",
                "Zexiang Shen",
                "Bo An",
                "Nikolay I. Zheludev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10441v1",
                "http://arxiv.org/pdf/2311.10441v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10438v1",
            "title": "Simultaneous Synthesis and Verification of Neural Control Barrier\n  Functions through Branch-and-Bound Verification-in-the-loop Training",
            "updated": "2023-11-17T10:31:07Z",
            "published": "2023-11-17T10:31:07Z",
            "summary": "Control Barrier Functions (CBFs) that provide formal safety guarantees have\nbeen widely used for safety-critical systems. However, it is non-trivial to\ndesign a CBF. Utilizing neural networks as CBFs has shown great success, but it\nnecessitates their certification as CBFs. In this work, we leverage bound\npropagation techniques and the Branch-and-Bound scheme to efficiently verify\nthat a neural network satisfies the conditions to be a CBF over the continuous\nstate space. To accelerate training, we further present a framework that embeds\nthe verification scheme into the training loop to synthesize and verify a\nneural CBF simultaneously. In particular, we employ the verification scheme to\nidentify partitions of the state space that are not guaranteed to satisfy the\nCBF conditions and expand the training dataset by incorporating additional data\nfrom these partitions. The neural network is then optimized using the augmented\ndataset to meet the CBF conditions. We show that for a non-linear\ncontrol-affine system, our framework can efficiently certify a neural network\nas a CBF and render a larger safe set than state-of-the-art neural CBF works.\nWe further employ our learned neural CBF to derive a safe controller to\nillustrate the practical use of our framework.",
            "author": [
                "Xinyu Wang",
                "Luzia Knoedler",
                "Frederik Baymler Mathiesen",
                "Javier Alonso-Mora"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10438v1",
                "http://arxiv.org/pdf/2311.10438v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10430v1",
            "title": "Deep Residual CNN for Multi-Class Chest Infection Diagnosis",
            "updated": "2023-11-17T10:05:10Z",
            "published": "2023-11-17T10:05:10Z",
            "summary": "The advent of deep learning has significantly propelled the capabilities of\nautomated medical image diagnosis, providing valuable tools and resources in\nthe realm of healthcare and medical diagnostics. This research delves into the\ndevelopment and evaluation of a Deep Residual Convolutional Neural Network\n(CNN) for the multi-class diagnosis of chest infections, utilizing chest X-ray\nimages. The implemented model, trained and validated on a dataset amalgamated\nfrom diverse sources, demonstrated a robust overall accuracy of 93%. However,\nnuanced disparities in performance across different classes, particularly\nFibrosis, underscored the complexity and challenges inherent in automated\nmedical image diagnosis. The insights derived pave the way for future research,\nfocusing on enhancing the model's proficiency in classifying conditions that\npresent more subtle and nuanced visual features in the images, as well as\noptimizing and refining the model architecture and training process. This paper\nprovides a comprehensive exploration into the development, implementation, and\nevaluation of the model, offering insights and directions for future research\nand development in the field.",
            "author": [
                "Ryan Donghan Kwon",
                "Dohyun Lim",
                "Yoonha Lee",
                "Seung Won Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10430v1",
                "http://arxiv.org/pdf/2311.10430v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10803v1",
            "title": "Robustness Enhancement in Neural Networks with Alpha-Stable Training\n  Noise",
            "updated": "2023-11-17T10:00:47Z",
            "published": "2023-11-17T10:00:47Z",
            "summary": "With the increasing use of deep learning on data collected by non-perfect\nsensors and in non-perfect environments, the robustness of deep learning\nsystems has become an important issue. A common approach for obtaining\nrobustness to noise has been to train deep learning systems with data augmented\nwith Gaussian noise. In this work, we challenge the common choice of Gaussian\nnoise and explore the possibility of stronger robustness for non-Gaussian\nimpulsive noise, specifically alpha-stable noise. Justified by the Generalized\nCentral Limit Theorem and evidenced by observations in various application\nareas, alpha-stable noise is widely present in nature. By comparing the testing\naccuracy of models trained with Gaussian noise and alpha-stable noise on data\ncorrupted by different noise, we find that training with alpha-stable noise is\nmore effective than Gaussian noise, especially when the dataset is corrupted by\nimpulsive noise, thus improving the robustness of the model. The generality of\nthis conclusion is validated through experiments conducted on various deep\nlearning models with image and time series datasets, and other benchmark\ncorrupted datasets. Consequently, we propose a novel data augmentation method\nthat replaces Gaussian noise, which is typically added to the training data,\nwith alpha-stable noise.",
            "author": [
                "Xueqiong Yuan",
                "Jipeng Li",
                "Ercan Engin Kuruo\u011flu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10803v1",
                "http://arxiv.org/pdf/2311.10803v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10421v1",
            "title": "Maintenance Techniques for Anomaly Detection AIOps Solutions",
            "updated": "2023-11-17T09:54:35Z",
            "published": "2023-11-17T09:54:35Z",
            "summary": "Anomaly detection techniques are essential in automating the monitoring of IT\nsystems and operations. These techniques imply that machine learning algorithms\nare trained on operational data corresponding to a specific period of time and\nthat they are continuously evaluated on newly emerging data. Operational data\nis constantly changing over time, which affects the performance of deployed\nanomaly detection models. Therefore, continuous model maintenance is required\nto preserve the performance of anomaly detectors over time. In this work, we\nanalyze two different anomaly detection model maintenance techniques in terms\nof the model update frequency, namely blind model retraining and informed model\nretraining. We further investigate the effects of updating the model by\nretraining it on all the available data (full-history approach) and on only the\nnewest data (sliding window approach). Moreover, we investigate whether a data\nchange monitoring tool is capable of determining when the anomaly detection\nmodel needs to be updated through retraining.",
            "author": [
                "Lorena Poenaru-Olaru",
                "Natalia Karpova",
                "Luis Cruz",
                "Jan Rellermeyer",
                "Arie van Deursen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10421v1",
                "http://arxiv.org/pdf/2311.10421v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10418v1",
            "title": "DynaPipe: Optimizing Multi-task Training through Dynamic Pipelines",
            "updated": "2023-11-17T09:48:45Z",
            "published": "2023-11-17T09:48:45Z",
            "summary": "Multi-task model training has been adopted to enable a single deep neural\nnetwork model (often a large language model) to handle multiple tasks (e.g.,\nquestion answering and text summarization). Multi-task training commonly\nreceives input sequences of highly different lengths due to the diverse\ncontexts of different tasks. Padding (to the same sequence length) or packing\n(short examples into long sequences of the same length) is usually adopted to\nprepare input samples for model training, which is nonetheless not space or\ncomputation efficient. This paper proposes a dynamic micro-batching approach to\ntackle sequence length variation and enable efficient multi-task model\ntraining. We advocate pipeline-parallel training of the large model with\nvariable-length micro-batches, each of which potentially comprises a different\nnumber of samples. We optimize micro-batch construction using a dynamic\nprogramming-based approach, and handle micro-batch execution time variation\nthrough dynamic pipeline and communication scheduling, enabling highly\nefficient pipeline training. Extensive evaluation on the FLANv2 dataset\ndemonstrates up to 4.39x higher training throughput when training T5, and 3.25x\nwhen training GPT, as compared with packing-based baselines. DynaPipe's source\ncode is publicly available at\nhttps://github.com/awslabs/optimizing-multitask-training-through-dynamic-pipelines.",
            "author": [
                "Chenyu Jiang",
                "Zhen Jia",
                "Shuai Zheng",
                "Yida Wang",
                "Chuan Wu"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3627703.3629585",
                "http://arxiv.org/abs/2311.10418v1",
                "http://arxiv.org/pdf/2311.10418v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10416v1",
            "title": "Meta-DSP: A Meta-Learning Approach for Data-Driven Nonlinear\n  Compensation in High-Speed Optical Fiber Systems",
            "updated": "2023-11-17T09:42:42Z",
            "published": "2023-11-17T09:42:42Z",
            "summary": "Non-linear effects in long-haul, high-speed optical fiber systems\nsignificantly hinder channel capacity. While the Digital Backward Propagation\nalgorithm (DBP) with adaptive filter (ADF) can mitigate these effects, it\nsuffers from an overwhelming computational complexity. Recent solutions have\nincorporated deep neural networks in a data-driven strategy to alleviate this\ncomplexity in the DBP model. However, these models are often limited to a\nspecific symbol rate and channel number, necessitating retraining for different\nsettings, their performance declines significantly under high-speed and\nhigh-power conditions. We introduce Meta-DSP, a novel data-driven nonlinear\ncompensation model based on meta-learning that processes multi-modal data\nacross diverse transmission rates, power levels, and channel numbers. This not\nonly enhances signal quality but also substantially reduces the complexity of\nthe nonlinear processing algorithm. Our model delivers a 0.7 dB increase in the\nQ-factor over Electronic Dispersion Compensation (EDC), and compared to DBP, it\ncurtails computational complexity by a factor of ten while retaining comparable\nperformance. From the perspective of the entire signal processing system, the\ncore idea of Meta-DSP can be employed in any segment of the overall\ncommunication system to enhance the model's scalability and generalization\nperformance. Our research substantiates Meta-DSP's proficiency in addressing\nthe critical parameters defining optical communication networks.",
            "author": [
                "Xinyu Xiao",
                "Zhennan Zhou",
                "Bin Dong",
                "Dingjiong Ma",
                "Li Zhou",
                "Jie Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10416v1",
                "http://arxiv.org/pdf/2311.10416v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10408v1",
            "title": "Deep Learning based CNN Model for Classification and Detection of\n  Individuals Wearing Face Mask",
            "updated": "2023-11-17T09:24:04Z",
            "published": "2023-11-17T09:24:04Z",
            "summary": "In response to the global COVID-19 pandemic, there has been a critical demand\nfor protective measures, with face masks emerging as a primary safeguard. The\napproach involves a two-fold strategy: first, recognizing the presence of a\nface by detecting faces, and second, identifying masks on those faces. This\nproject utilizes deep learning to create a model that can detect face masks in\nreal-time streaming video as well as images. Face detection, a facet of object\ndetection, finds applications in diverse fields such as security, biometrics,\nand law enforcement. Various detector systems worldwide have been developed and\nimplemented, with convolutional neural networks chosen for their superior\nperformance accuracy and speed in object detection. Experimental results attest\nto the model's excellent accuracy on test data. The primary focus of this\nresearch is to enhance security, particularly in sensitive areas. The research\npaper proposes a rapid image pre-processing method with masks centred on faces.\nEmploying feature extraction and Convolutional Neural Network, the system\nclassifies and detects individuals wearing masks. The research unfolds in three\nstages: image pre-processing, image cropping, and image classification,\ncollectively contributing to the identification of masked faces. Continuous\nsurveillance through webcams or CCTV cameras ensures constant monitoring,\ntriggering a security alert if a person is detected without a mask.",
            "author": [
                "R. Chinnaiyan",
                "Iyyappan M",
                "Al Raiyan Shariff A",
                "Kondaveeti Sai",
                "Mallikarjunaiah B M",
                "P Bharath"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10408v1",
                "http://arxiv.org/pdf/2311.10408v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10801v2",
            "title": "Reinforcement Learning with Maskable Stock Representation for Portfolio\n  Management in Customizable Stock Pools",
            "updated": "2023-11-21T17:11:55Z",
            "published": "2023-11-17T09:16:59Z",
            "summary": "Portfolio management (PM) is a fundamental financial trading task, which\nexplores the optimal periodical reallocation of capitals into different stocks\nto pursue long-term profits. Reinforcement learning (RL) has recently shown its\npotential to train profitable agents for PM through interacting with financial\nmarkets. However, existing work mostly focuses on fixed stock pools, which is\ninconsistent with investors' practical demand. Specifically, the target stock\npool of different investors varies dramatically due to their discrepancy on\nmarket states and individual investors may temporally adjust stocks they desire\nto trade (e.g., adding one popular stocks), which lead to customizable stock\npools (CSPs). Existing RL methods require to retrain RL agents even with a tiny\nchange of the stock pool, which leads to high computational cost and unstable\nperformance. To tackle this challenge, we propose EarnMore, a rEinforcement\nleARNing framework with Maskable stOck REpresentation to handle PM with CSPs\nthrough one-shot training in a global stock pool (GSP). Specifically, we first\nintroduce a mechanism to mask out the representation of the stocks outside the\ntarget pool. Second, we learn meaningful stock representations through a\nself-supervised masking and reconstruction process. Third, a re-weighting\nmechanism is designed to make the portfolio concentrate on favorable stocks and\nneglect the stocks outside the target pool. Through extensive experiments on 8\nsubset stock pools of the US stock market, we demonstrate that EarnMore\nsignificantly outperforms 14 state-of-the-art baselines in terms of 6 popular\nfinancial metrics with over 40% improvement on profit.",
            "author": [
                "Wentao Zhang",
                "Yilei Zhao",
                "Shuo Sun",
                "Jie Ying",
                "Yonggang Xie",
                "Zitao Song",
                "Xinrun Wang",
                "Bo An"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10801v2",
                "http://arxiv.org/pdf/2311.10801v2"
            ],
            "primary_category": "q-fin.PM",
            "category": [
                "q-fin.PM",
                "cs.AI",
                "cs.CE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10406v1",
            "title": "Decentralized Energy Marketplace via NFTs and AI-based Agents",
            "updated": "2023-11-17T09:15:43Z",
            "published": "2023-11-17T09:15:43Z",
            "summary": "The paper introduces an advanced Decentralized Energy Marketplace (DEM)\nintegrating blockchain technology and artificial intelligence to manage energy\nexchanges among smart homes with energy storage systems. The proposed framework\nuses Non-Fungible Tokens (NFTs) to represent unique energy profiles in a\ntransparent and secure trading environment. Leveraging Federated Deep\nReinforcement Learning (FDRL), the system promotes collaborative and adaptive\nenergy management strategies, maintaining user privacy. A notable innovation is\nthe use of smart contracts, ensuring high efficiency and integrity in energy\ntransactions. Extensive evaluations demonstrate the system's scalability and\nthe effectiveness of the FDRL method in optimizing energy distribution. This\nresearch significantly contributes to developing sophisticated decentralized\nsmart grid infrastructures. Our approach broadens potential blockchain and AI\napplications in sustainable energy systems and addresses incentive alignment\nand transparency challenges in traditional energy trading mechanisms. The\nimplementation of this paper is publicly accessible at\n\\url{https://github.com/RasoulNik/DEM}.",
            "author": [
                "Rasoul Nikbakht",
                "Farhana Javed",
                "Farhad Rezazadeh",
                "Nikolaos Bartzoudis",
                "Josep Mangues-Bafalluy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10406v1",
                "http://arxiv.org/pdf/2311.10406v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10399v1",
            "title": "Optimized Deep Learning Models for AUV Seabed Image Analysis",
            "updated": "2023-11-17T09:00:44Z",
            "published": "2023-11-17T09:00:44Z",
            "summary": "Using autonomous underwater vehicles, or AUVs, has completely changed how we\ngather data from the ocean floor. AUV innovation has advanced significantly,\nespecially in the analysis of images, due to the increasing need for accurate\nand efficient seafloor mapping. This blog post provides a detailed summary and\ncomparison of the most current advancements in AUV seafloor image processing.\nWe will go into the realm of undersea technology, covering everything through\ncomputer and algorithmic advancements to advances in sensors and cameras. After\nreading this page through to the end, you will have a solid understanding of\nthe most up-to-date techniques and tools for using AUVs to process seabed\nphotos and how they could further our comprehension of the ocean floor",
            "author": [
                "Rajesh Sharma R",
                "Akey Sungheetha",
                "Chinnaiyan R"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10399v1",
                "http://arxiv.org/pdf/2311.10399v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10388v1",
            "title": "Automatic Smart Contract Comment Generation via Large Language Models\n  and In-Context Learning",
            "updated": "2023-11-17T08:31:09Z",
            "published": "2023-11-17T08:31:09Z",
            "summary": "The previous smart contract code comment (SCC) generation approaches can be\ndivided into two categories: fine-tuning paradigm-based approaches and\ninformation retrieval-based approaches. However, for the fine-tuning\nparadigm-based approaches, the performance may be limited by the quality of the\ngathered dataset for the downstream task and they may have knowledge-forgetting\nissues. While for the information retrieval-based approaches, it is difficult\nfor them to generate high-quality comments if similar code does not exist in\nthe historical repository. Therefore we want to utilize the domain knowledge\nrelated to SCC generation in large language models (LLMs) to alleviate the\ndisadvantages of these two types of approaches. In this study, we propose an\napproach SCCLLM based on LLMs and in-context learning. Specifically, in the\ndemonstration selection phase, SCCLLM retrieves the top-k code snippets from\nthe historical corpus by considering syntax, semantics, and lexical\ninformation. In the in-context learning phase, SCCLLM utilizes the retrieved\ncode snippets as demonstrations, which can help to utilize the related\nknowledge for this task. We select a large corpus from a smart contract\ncommunity Etherscan.io as our experimental subject. Extensive experimental\nresults show the effectiveness of SCCLLM when compared with baselines in\nautomatic evaluation and human evaluation.",
            "author": [
                "Junjie Zhao",
                "Xiang Chen",
                "Guang Yang",
                "Yiheng Shen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10388v1",
                "http://arxiv.org/pdf/2311.10388v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10387v1",
            "title": "A Bridge between Dynamical Systems and Machine Learning: Engineered\n  Ordinary Differential Equations as Classification Algorithm (EODECA)",
            "updated": "2023-11-17T08:30:41Z",
            "published": "2023-11-17T08:30:41Z",
            "summary": "In a world increasingly reliant on machine learning, the interpretability of\nthese models remains a substantial challenge, with many equating their\nfunctionality to an enigmatic black box. This study seeks to bridge machine\nlearning and dynamical systems. Recognizing the deep parallels between dense\nneural networks and dynamical systems, particularly in the light of\nnon-linearities and successive transformations, this manuscript introduces the\nEngineered Ordinary Differential Equations as Classification Algorithms\n(EODECAs). Uniquely designed as neural networks underpinned by continuous\nordinary differential equations, EODECAs aim to capitalize on the\nwell-established toolkit of dynamical systems. Unlike traditional deep learning\nmodels, which often suffer from opacity, EODECAs promise both high\nclassification performance and intrinsic interpretability. They are naturally\ninvertible, granting them an edge in understanding and transparency over their\ncounterparts. By bridging these domains, we hope to usher in a new era of\nmachine learning models where genuine comprehension of data processes\ncomplements predictive prowess.",
            "author": [
                "Raffaele Marino",
                "Lorenzo Giambagli",
                "Lorenzo Chicchi",
                "Lorenzo Buffoni",
                "Duccio Fanelli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10387v1",
                "http://arxiv.org/pdf/2311.10387v1"
            ],
            "primary_category": "cond-mat.dis-nn",
            "category": [
                "cond-mat.dis-nn",
                "cond-mat.stat-mech",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10800v1",
            "title": "The Next 700 ML-Enabled Compiler Optimizations",
            "updated": "2023-11-17T08:27:17Z",
            "published": "2023-11-17T08:27:17Z",
            "summary": "There is a growing interest in enhancing compiler optimizations with ML\nmodels, yet interactions between compilers and ML frameworks remain\nchallenging. Some optimizations require tightly coupled models and compiler\ninternals,raising issues with modularity, performance and framework\nindependence. Practical deployment and transparency for the end-user are also\nimportant concerns. We propose ML-Compiler-Bridge to enable ML model\ndevelopment within a traditional Python framework while making end-to-end\nintegration with an optimizing compiler possible and efficient. We evaluate it\non both research and production use cases, for training and inference, over\nseveral optimization problems, multiple compilers and its versions, and gym\ninfrastructures.",
            "author": [
                "S. VenkataKeerthy",
                "Siddharth Jain",
                "Umesh Kalvakuntla",
                "Pranav Sai Gorantla",
                "Rajiv Shailesh Chitale",
                "Eugene Brevdo",
                "Albert Cohen",
                "Mircea Trofin",
                "Ramakrishna Upadrasta"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10800v1",
                "http://arxiv.org/pdf/2311.10800v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL",
                "cs.LG",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10385v1",
            "title": "Delete My Account: Impact of Data Deletion on Machine Learning\n  Classifiers",
            "updated": "2023-11-17T08:23:17Z",
            "published": "2023-11-17T08:23:17Z",
            "summary": "Users are more aware than ever of the importance of their own data, thanks to\nreports about security breaches and leaks of private, often sensitive data in\nrecent years. Additionally, the GDPR has been in effect in the European Union\nfor over three years and many people have encountered its effects in one way or\nanother. Consequently, more and more users are actively protecting their\npersonal data. One way to do this is to make of the right to erasure guaranteed\nin the GDPR, which has potential implications for a number of different fields,\nsuch as big data and machine learning.\n  Our paper presents an in-depth analysis about the impact of the use of the\nright to erasure on the performance of machine learning models on\nclassification tasks. We conduct various experiments utilising different\ndatasets as well as different machine learning algorithms to analyse a variety\nof deletion behaviour scenarios. Due to the lack of credible data on actual\nuser behaviour, we make reasonable assumptions for various deletion modes and\nbiases and provide insight into the effects of different plausible scenarios\nfor right to erasure usage on data quality of machine learning. Our results\nshow that the impact depends strongly on the amount of data deleted, the\nparticular characteristics of the dataset and the bias chosen for deletion and\nassumptions on user behaviour.",
            "author": [
                "Tobias Dam",
                "Maximilian Henzl",
                "Lukas Daniel Klausner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10385v1",
                "http://arxiv.org/pdf/2311.10385v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10382v1",
            "title": "Single-Shot and Multi-Shot Feature Learning for Multi-Object Tracking",
            "updated": "2023-11-17T08:17:49Z",
            "published": "2023-11-17T08:17:49Z",
            "summary": "Multi-Object Tracking (MOT) remains a vital component of intelligent video\nanalysis, which aims to locate targets and maintain a consistent identity for\neach target throughout a video sequence. Existing works usually learn a\ndiscriminative feature representation, such as motion and appearance, to\nassociate the detections across frames, which are easily affected by mutual\nocclusion and background clutter in practice. In this paper, we propose a\nsimple yet effective two-stage feature learning paradigm to jointly learn\nsingle-shot and multi-shot features for different targets, so as to achieve\nrobust data association in the tracking process. For the detections without\nbeing associated, we design a novel single-shot feature learning module to\nextract discriminative features of each detection, which can efficiently\nassociate targets between adjacent frames. For the tracklets being lost several\nframes, we design a novel multi-shot feature learning module to extract\ndiscriminative features of each tracklet, which can accurately refind these\nlost targets after a long period. Once equipped with a simple data association\nlogic, the resulting VisualTracker can perform robust MOT based on the\nsingle-shot and multi-shot feature representations. Extensive experimental\nresults demonstrate that our method has achieved significant improvements on\nMOT17 and MOT20 datasets while reaching state-of-the-art performance on\nDanceTrack dataset.",
            "author": [
                "Yizhe Li",
                "Sanping Zhou",
                "Zheng Qin",
                "Le Wang",
                "Jinjun Wang",
                "Nanning Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10382v1",
                "http://arxiv.org/pdf/2311.10382v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10380v1",
            "title": "MSE-Nets: Multi-annotated Semi-supervised Ensemble Networks for\n  Improving Segmentation of Medical Image with Ambiguous Boundaries",
            "updated": "2023-11-17T08:14:24Z",
            "published": "2023-11-17T08:14:24Z",
            "summary": "Medical image segmentation annotations exhibit variations among experts due\nto the ambiguous boundaries of segmented objects and backgrounds in medical\nimages. Although using multiple annotations for each image in the\nfully-supervised has been extensively studied for training deep models,\nobtaining a large amount of multi-annotated data is challenging due to the\nsubstantial time and manpower costs required for segmentation annotations,\nresulting in most images lacking any annotations. To address this, we propose\nMulti-annotated Semi-supervised Ensemble Networks (MSE-Nets) for learning\nsegmentation from limited multi-annotated and abundant unannotated data.\nSpecifically, we introduce the Network Pairwise Consistency Enhancement (NPCE)\nmodule and Multi-Network Pseudo Supervised (MNPS) module to enhance MSE-Nets\nfor the segmentation task by considering two major factors: (1) to optimize the\nutilization of all accessible multi-annotated data, the NPCE separates\n(dis)agreement annotations of multi-annotated data at the pixel level and\nhandles agreement and disagreement annotations in different ways, (2) to\nmitigate the introduction of imprecise pseudo-labels, the MNPS extends the\ntraining data by leveraging consistent pseudo-labels from unannotated data.\nFinally, we improve confidence calibration by averaging the predictions of base\nnetworks. Experiments on the ISIC dataset show that we reduced the demand for\nmulti-annotated data by 97.75\\% and narrowed the gap with the best\nfully-supervised baseline to just a Jaccard index of 4\\%. Furthermore, compared\nto other semi-supervised methods that rely only on a single annotation or a\ncombined fusion approach, the comprehensive experimental results on ISIC and\nRIGA datasets demonstrate the superior performance of our proposed method in\nmedical image segmentation with ambiguous boundaries.",
            "author": [
                "Shuai Wang",
                "Tengjin Weng",
                "Jingyi Wang",
                "Yang Shen",
                "Zhidong Zhao",
                "Yixiu Liu",
                "Pengfei Jiao",
                "Zhiming Cheng",
                "Yaqi Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10380v1",
                "http://arxiv.org/pdf/2311.10380v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10375v1",
            "title": "Quantum Data Encoding: A Comparative Analysis of Classical-to-Quantum\n  Mapping Techniques and Their Impact on Machine Learning Accuracy",
            "updated": "2023-11-17T08:00:08Z",
            "published": "2023-11-17T08:00:08Z",
            "summary": "This research explores the integration of quantum data embedding techniques\ninto classical machine learning (ML) algorithms, aiming to assess the\nperformance enhancements and computational implications across a spectrum of\nmodels. We explore various classical-to-quantum mapping methods, ranging from\nbasis encoding, angle encoding to amplitude encoding for encoding classical\ndata, we conducted an extensive empirical study encompassing popular ML\nalgorithms, including Logistic Regression, K-Nearest Neighbors, Support Vector\nMachines and ensemble methods like Random Forest, LightGBM, AdaBoost, and\nCatBoost. Our findings reveal that quantum data embedding contributes to\nimproved classification accuracy and F1 scores, particularly notable in models\nthat inherently benefit from enhanced feature representation. We observed\nnuanced effects on running time, with low-complexity models exhibiting moderate\nincreases and more computationally intensive models experiencing discernible\nchanges. Notably, ensemble methods demonstrated a favorable balance between\nperformance gains and computational overhead. This study underscores the\npotential of quantum data embedding in enhancing classical ML models and\nemphasizes the importance of weighing performance improvements against\ncomputational costs. Future research directions may involve refining quantum\nencoding processes to optimize computational efficiency and exploring\nscalability for real-world applications. Our work contributes to the growing\nbody of knowledge at the intersection of quantum computing and classical\nmachine learning, offering insights for researchers and practitioners seeking\nto harness the advantages of quantum-inspired techniques in practical\nscenarios.",
            "author": [
                "Minati Rath",
                "Hema Date"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10375v1",
                "http://arxiv.org/pdf/2311.10375v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10373v1",
            "title": "FOAL: Fine-grained Contrastive Learning for Cross-domain Aspect\n  Sentiment Triplet Extraction",
            "updated": "2023-11-17T07:56:01Z",
            "published": "2023-11-17T07:56:01Z",
            "summary": "Aspect Sentiment Triplet Extraction (ASTE) has achieved promising results\nwhile relying on sufficient annotation data in a specific domain. However, it\nis infeasible to annotate data for each individual domain. We propose to\nexplore ASTE in the cross-domain setting, which transfers knowledge from a\nresource-rich source domain to a resource-poor target domain, thereby\nalleviating the reliance on labeled data in the target domain. To effectively\ntransfer the knowledge across domains and extract the sentiment triplets\naccurately, we propose a method named Fine-grained cOntrAstive Learning (FOAL)\nto reduce the domain discrepancy and preserve the discriminability of each\ncategory. Experiments on six transfer pairs show that FOAL achieves 6%\nperformance gains and reduces the domain discrepancy significantly compared\nwith strong baselines. Our code will be publicly available once accepted.",
            "author": [
                "Ting Xu",
                "Zhen Wu",
                "Huiyun Yang",
                "Xinyu Dai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10373v1",
                "http://arxiv.org/pdf/2311.10373v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10799v1",
            "title": "Adaptive Modelling Approach for Row-Type Dependent Predictive Analysis\n  (RTDPA): A Framework for Designing Machine Learning Models for Credit Risk\n  Analysis in Banking Sector",
            "updated": "2023-11-17T07:49:32Z",
            "published": "2023-11-17T07:49:32Z",
            "summary": "In many real-world datasets, rows may have distinct characteristics and\nrequire different modeling approaches for accurate predictions. In this paper,\nwe propose an adaptive modeling approach for row-type dependent predictive\nanalysis(RTDPA). Our framework enables the development of models that can\neffectively handle diverse row types within a single dataset. Our dataset from\nXXX bank contains two different risk categories, personal loan and agriculture\nloan. each of them are categorised into four classes standard, sub-standard,\ndoubtful and loss. We performed tailored data pre processing and feature\nengineering to different row types. We selected traditional machine learning\npredictive models and advanced ensemble techniques. Our findings indicate that\nall predictive approaches consistently achieve a precision rate of no less than\n90%. For RTDPA, the algorithms are applied separately for each row type,\nallowing the models to capture the specific patterns and characteristics of\neach row type. This approach enables targeted predictions based on the row\ntype, providing a more accurate and tailored classification for the given\ndataset.Additionally, the suggested model consistently offers decision makers\nvaluable and enduring insights that are strategic in nature in banking sector.",
            "author": [
                "Minati Rath",
                "Hema Date"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10799v1",
                "http://arxiv.org/pdf/2311.10799v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-fin.RM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10370v1",
            "title": "Few-shot Message-Enhanced Contrastive Learning for Graph Anomaly\n  Detection",
            "updated": "2023-11-17T07:49:20Z",
            "published": "2023-11-17T07:49:20Z",
            "summary": "Graph anomaly detection plays a crucial role in identifying exceptional\ninstances in graph data that deviate significantly from the majority. It has\ngained substantial attention in various domains of information security,\nincluding network intrusion, financial fraud, and malicious comments, et al.\nExisting methods are primarily developed in an unsupervised manner due to the\nchallenge in obtaining labeled data. For lack of guidance from prior knowledge\nin unsupervised manner, the identified anomalies may prove to be data noise or\nindividual data instances. In real-world scenarios, a limited batch of labeled\nanomalies can be captured, making it crucial to investigate the few-shot\nproblem in graph anomaly detection. Taking advantage of this potential, we\npropose a novel few-shot Graph Anomaly Detection model called FMGAD (Few-shot\nMessage-Enhanced Contrastive-based Graph Anomaly Detector). FMGAD leverages a\nself-supervised contrastive learning strategy within and across views to\ncapture intrinsic and transferable structural representations. Furthermore, we\npropose the Deep-GNN message-enhanced reconstruction module, which extensively\nexploits the few-shot label information and enables long-range propagation to\ndisseminate supervision signals to deeper unlabeled nodes. This module in turn\nassists in the training of self-supervised contrastive learning. Comprehensive\nexperimental results on six real-world datasets demonstrate that FMGAD can\nachieve better performance than other state-of-the-art methods, regardless of\nartificially injected anomalies or domain-organic anomalies.",
            "author": [
                "Fan Xu",
                "Nan Wang",
                "Xuezhi Wen",
                "Meiqi Gao",
                "Chaoqun Guo",
                "Xibin Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10370v1",
                "http://arxiv.org/pdf/2311.10370v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10368v1",
            "title": "Disruption Predictor Based on Convolutional Autoencoder and Its\n  Cross-tokamak Deployment Strategy Study",
            "updated": "2023-11-17T07:40:47Z",
            "published": "2023-11-17T07:40:47Z",
            "summary": "Deploying data-driven disruption predictors across different tokamak devices\nis challenging due to their inherent differences. This study addresses some\nchallenges of cross-tokamak deployment for data-driven plasma disruption\npredictors. Current predictors primarily employ supervised learning methods and\nrequire a balanced dataset of disruption and non-disruption shots. However,\nobtaining disruption shots for future tokamaks is extremely costly, resulting\nin imbalanced training datasets. Imbalance leads to reduced or even ineffective\nperformance of supervised learning predictors. To solve this problem, we\npropose the Enhanced Convolutional Autoencoder Anomaly Detection (E-CAAD)\npredictor, which can be trained using disruption precursor samples when\ndisruption shots occur. This model not only overcomes the sample imbalance\nproblem in supervised learning predictors but also overcomes the inefficient\ndataset utilization faced by traditional anomaly detection predictors that\ncannot use disruption precursor samples for training, making it more suitable\nfor the unpredictable datasets of future tokamaks. Compared to traditional\nanomaly detection predictor, the E-CAAD predictor performs better in disruption\nprediction and is deployed faster on new devices. Additionally, we explore\nstrategies to accelerate deployment of E-CAAD predictor on the new device by\nusing data from existing devices, with a focus on achieving good performance\nusing minimal new device data during the initial operation stages. Two\ndeployment strategies are presented: mixing data from existing devices and\nfine-tuning the predictor trained on existing devices. Our comparisons indicate\nthat rational utilization of data from existing devices expedites deployment.\nNotably, the fine-tuning strategy yields the fastest deployment on new device\namong the proposed strategies.",
            "author": [
                "Xinkun Ai",
                "Wei Zheng",
                "Ming Zhang",
                "Yonghua Ding",
                "Dalong Chen",
                "Zhongyong Chen",
                "Chengshuo Shen",
                "Bihao Guo",
                "Nengchao Wang",
                "Zhoujun Yang",
                "Zhipeng Chen",
                "Yuan Pan",
                "Biao Shen",
                "Binjia Xiao",
                "J-TEXT team"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10368v1",
                "http://arxiv.org/pdf/2311.10368v1"
            ],
            "primary_category": "physics.plasm-ph",
            "category": [
                "physics.plasm-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10367v1",
            "title": "Exploring the Relationship between In-Context Learning and Instruction\n  Tuning",
            "updated": "2023-11-17T07:40:46Z",
            "published": "2023-11-17T07:40:46Z",
            "summary": "In-Context Learning (ICL) and Instruction Tuning (IT) are two primary\nparadigms of adopting Large Language Models (LLMs) to downstream applications.\nHowever, they are significantly different. In ICL, a set of demonstrations are\nprovided at inference time but the LLM's parameters are not updated. In IT, a\nset of demonstrations are used to tune LLM's parameters in training time but no\ndemonstrations are used at inference time. Although a growing body of\nliterature has explored ICL and IT, studies on these topics have largely been\nconducted in isolation, leading to a disconnect between these two paradigms. In\nthis work, we explore the relationship between ICL and IT by examining how the\nhidden states of LLMs change in these two paradigms. Through carefully designed\nexperiments conducted with LLaMA-2 (7B and 13B), we find that ICL is implicit\nIT. In other words, ICL changes an LLM's hidden states as if the demonstrations\nwere used to instructionally tune the model. Furthermore, the convergence\nbetween ICL and IT is largely contingent upon several factors related to the\nprovided demonstrations. Overall, this work offers a unique perspective to\nexplore the connection between ICL and IT and sheds light on understanding the\nbehaviors of LLM.",
            "author": [
                "Hanyu Duan",
                "Yixuan Tang",
                "Yi Yang",
                "Ahmed Abbasi",
                "Kar Yan Tam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10367v1",
                "http://arxiv.org/pdf/2311.10367v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10366v1",
            "title": "Breaking Temporal Consistency: Generating Video Universal Adversarial\n  Perturbations Using Image Models",
            "updated": "2023-11-17T07:39:42Z",
            "published": "2023-11-17T07:39:42Z",
            "summary": "As video analysis using deep learning models becomes more widespread, the\nvulnerability of such models to adversarial attacks is becoming a pressing\nconcern. In particular, Universal Adversarial Perturbation (UAP) poses a\nsignificant threat, as a single perturbation can mislead deep learning models\non entire datasets. We propose a novel video UAP using image data and image\nmodel. This enables us to take advantage of the rich image data and image\nmodel-based studies available for video applications. However, there is a\nchallenge that image models are limited in their ability to analyze the\ntemporal aspects of videos, which is crucial for a successful video attack. To\naddress this challenge, we introduce the Breaking Temporal Consistency (BTC)\nmethod, which is the first attempt to incorporate temporal information into\nvideo attacks using image models. We aim to generate adversarial videos that\nhave opposite patterns to the original. Specifically, BTC-UAP minimizes the\nfeature similarity between neighboring frames in videos. Our approach is simple\nbut effective at attacking unseen video models. Additionally, it is applicable\nto videos of varying lengths and invariant to temporal shifts. Our approach\nsurpasses existing methods in terms of effectiveness on various datasets,\nincluding ImageNet, UCF-101, and Kinetics-400.",
            "author": [
                "Hee-Seon Kim",
                "Minji Son",
                "Minbeom Kim",
                "Myung-Joon Kwon",
                "Changick Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10366v1",
                "http://arxiv.org/pdf/2311.10366v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10365v1",
            "title": "Dates Fruit Disease Recognition using Machine Learning",
            "updated": "2023-11-17T07:37:41Z",
            "published": "2023-11-17T07:37:41Z",
            "summary": "Many countries such as Saudi Arabia, Morocco and Tunisia are among the top\nexporters and consumers of palm date fruits. Date fruit production plays a\nmajor role in the economies of the date fruit exporting countries. Date fruits\nare susceptible to disease just like any fruit and early detection and\nintervention can end up saving the produce. However, with the vast farming\nlands, it is nearly impossible for farmers to observe date trees on a frequent\nbasis for early disease detection. In addition, even with human observation the\nprocess is prone to human error and increases the date fruit cost. With the\nrecent advances in computer vision, machine learning, drone technology, and\nother technologies; an integrated solution can be proposed for the automatic\ndetection of date fruit disease. In this paper, a hybrid features based method\nwith the standard classifiers is proposed based on the extraction of L*a*b\ncolor features, statistical features, and Discrete Wavelet Transform (DWT)\ntexture features for the early detection and classification of date fruit\ndisease. A dataset was developed for this work consisting of 871 images divided\ninto the following classes; Healthy date, Initial stage of disease,\nMalnourished date, and Parasite infected. The extracted features were input to\ncommon classifiers such as the Random Forest (RF), Multilayer Perceptron (MLP),\nNa\\\"ive Bayes (NB), and Fuzzy Decision Trees (FDT). The highest average\naccuracy was achieved when combining the L*a*b, Statistical, and DWT Features.",
            "author": [
                "Ghassen Ben Brahim",
                "Jaafar Alghazo",
                "Ghazanfar Latif",
                "Khalid Alnujaidi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10365v1",
                "http://arxiv.org/pdf/2311.10365v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10363v1",
            "title": "Quantum-Assisted Simulation: A Framework for Designing Machine Learning\n  Models in the Quantum Computing Domain",
            "updated": "2023-11-17T07:33:42Z",
            "published": "2023-11-17T07:33:42Z",
            "summary": "Machine learning (ML) models are trained using historical data to classify\nnew, unseen data. However, traditional computing resources often struggle to\nhandle the immense amount of data, commonly known as Big Data, within a\nreasonable timeframe. Quantum computing (QC) provides a novel approach to\ninformation processing. Quantum algorithms have the potential to process\nclassical data exponentially faster than classical computing. By mapping\nquantum machine learning (QML) algorithms into the quantum mechanical domain,\nwe can potentially achieve exponential improvements in data processing speed,\nreduced resource requirements, and enhanced accuracy and efficiency. In this\narticle, we delve into both the QC and ML fields, exploring the interplay of\nideas between them, as well as the current capabilities and limitations of\nhardware. We investigate the history of quantum computing, examine existing QML\nalgorithms, and aim to present a simplified procedure for setting up\nsimulations of QML algorithms, making it accessible and understandable for\nreaders. Furthermore, we conducted simulations on a dataset using both machine\nlearning and quantum machine learning approaches. We then proceeded to compare\ntheir respective performances by utilizing a quantum simulator.",
            "author": [
                "Minati Rath",
                "Hema Date"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10363v1",
                "http://arxiv.org/pdf/2311.10363v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10798v1",
            "title": "INSPECT: A Multimodal Dataset for Pulmonary Embolism Diagnosis and\n  Prognosis",
            "updated": "2023-11-17T07:28:16Z",
            "published": "2023-11-17T07:28:16Z",
            "summary": "Synthesizing information from multiple data sources plays a crucial role in\nthe practice of modern medicine. Current applications of artificial\nintelligence in medicine often focus on single-modality data due to a lack of\npublicly available, multimodal medical datasets. To address this limitation, we\nintroduce INSPECT, which contains de-identified longitudinal records from a\nlarge cohort of patients at risk for pulmonary embolism (PE), along with ground\ntruth labels for multiple outcomes. INSPECT contains data from 19,402 patients,\nincluding CT images, radiology report impression sections, and structured\nelectronic health record (EHR) data (i.e. demographics, diagnoses, procedures,\nvitals, and medications). Using INSPECT, we develop and release a benchmark for\nevaluating several baseline modeling approaches on a variety of important PE\nrelated tasks. We evaluate image-only, EHR-only, and multimodal fusion models.\nTrained models and the de-identified dataset are made available for\nnon-commercial use under a data use agreement. To the best of our knowledge,\nINSPECT is the largest multimodal dataset integrating 3D medical imaging and\nEHR for reproducible methods evaluation and research.",
            "author": [
                "Shih-Cheng Huang",
                "Zepeng Huo",
                "Ethan Steinberg",
                "Chia-Chun Chiang",
                "Matthew P. Lungren",
                "Curtis P. Langlotz",
                "Serena Yeung",
                "Nigam H. Shah",
                "Jason A. Fries"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10798v1",
                "http://arxiv.org/pdf/2311.10798v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10359v2",
            "title": "FIKIT: Priority-Based Real-time GPU Multi-tasking Scheduling with Kernel\n  Identification",
            "updated": "2023-11-24T14:59:37Z",
            "published": "2023-11-17T07:25:18Z",
            "summary": "Highly parallelized workloads like machine learning training, inferences and\ngeneral HPC tasks are greatly accelerated using GPU devices. In a cloud\ncomputing cluster, serving a GPU's computation power through multi-tasks\nsharing is highly demanded since there are always more task requests than the\nnumber of GPU available. Existing GPU sharing solutions focus on reducing\ntask-level waiting time or task-level switching costs when multiple jobs\ncompeting for a single GPU. Non-stopped computation requests come with\ndifferent priorities, having non-symmetric impact on QoS for sharing a GPU\ndevice. Existing work missed the kernel-level optimization opportunity brought\nby this setting. To address this problem, we present a novel kernel-level\nscheduling strategy called FIKIT: Filling Inter-kernel Idle Time. FIKIT\nincorporates task-level priority information, fine-grained kernel\nidentification, and kernel measurement, allowing low priorities task's\nexecution during high priority task's inter-kernel idle time. Thereby, filling\nthe GPU's device runtime fully, and reduce overall GPU sharing impact to cloud\nservices. Across a set of ML models, the FIKIT based inference system\naccelerated high priority tasks by 1.33 to 14.87 times compared to the JCT in\nGPU sharing mode, and more than half of the cases are accelerated by more than\n3.5 times. Alternatively, under preemptive sharing, the low-priority tasks have\na comparable to default GPU sharing mode JCT, with a 0.84 to 1 times ratio. We\nfurther limit the kernel measurement and runtime fine-grained kernel scheduling\noverhead to less than 10%.",
            "author": [
                "Wenqing Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10359v2",
                "http://arxiv.org/pdf/2311.10359v2"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10356v1",
            "title": "Garment Recovery with Shape and Deformation Priors",
            "updated": "2023-11-17T07:06:21Z",
            "published": "2023-11-17T07:06:21Z",
            "summary": "While modeling people wearing tight-fitting clothing has made great strides\nin recent years, loose-fitting clothing remains a challenge. We propose a\nmethod that delivers realistic garment models from real-world images,\nregardless of garment shape or deformation. To this end, we introduce a fitting\napproach that utilizes shape and deformation priors learned from synthetic data\nto accurately capture garment shapes and deformations, including large ones.\nNot only does our approach recover the garment geometry accurately, it also\nyields models that can be directly used by downstream applications such as\nanimation and simulation.",
            "author": [
                "Ren Li",
                "Corentin Dumery",
                "Beno\u00eet Guillard",
                "Pascal Fua"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10356v1",
                "http://arxiv.org/pdf/2311.10356v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10797v1",
            "title": "TaCo: Enhancing Cross-Lingual Transfer for Low-Resource Languages in\n  LLMs through Translation-Assisted Chain-of-Thought Processes",
            "updated": "2023-11-17T06:55:32Z",
            "published": "2023-11-17T06:55:32Z",
            "summary": "LLMs such as ChatGPT and PaLM can be utilized to train on a new language and\nrevitalize low-resource languages. However, it is evidently very costly to\npretrain pr fine-tune LLMs to adopt new languages. Another challenge is the\nlimitation of benchmark datasets and the metrics used to measure the\nperformance of models in multilingual settings. This paper proposes\ncost-effective solutions to both of the aforementioned challenges. We introduce\nthe Multilingual Instruction-Tuning Dataset (MITS), which is comprised of the\ntranslation of Alpaca-52K, Dolly-15K, and Vicuna Benchmark in 132 languages.\nAlso, we propose a new method called \\emph{TaCo: Translation-Assisted\nCross-Linguality}, which make uses of translation in a chain-of-thought process\nto instruction-tune LLMs on a new languages through a curriculum learning\nprocess. As a proof of concept, we experimented with the instruction-tuned\nGuanaco-33B model and performed further instruction tuning using the TaCo\nmethod in three low-resource languages and one high-resource language. Our\nresults show that the TaCo method impresses the GPT-4 with 82% for a\nlow-resource language in the Vicuna Benchmark dataset, and boosts performance\nby double in contrast to the performance of instruction tuning only. Our\nresults show that TaCo is a promising method for creating multilingual LLMs,\neven for low-resource languages. We have released our datasets and the model\nadapters, and encourage the research community to make use of these resources\ntowards advancing work on multilingual LLMs.",
            "author": [
                "Bibek Upadhayay",
                "Vahid Behzadan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10797v1",
                "http://arxiv.org/pdf/2311.10797v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10353v1",
            "title": "Quantifying Subspace Entanglement with Geometric Measures",
            "updated": "2023-11-17T06:54:48Z",
            "published": "2023-11-17T06:54:48Z",
            "summary": "Determining whether a quantum subspace is entangled and quantifying its\nentanglement level remains a fundamental challenge in quantum information\nscience. This paper introduces a geometric measure of $r$-bounded rank,\n$E_r(S)$, for a given subspace $S$. This measure, derived from the established\ngeometric measure of entanglement, is tailored to assess the entanglement\nwithin $S$. It not only provides a benchmark for quantifying the entanglement\nlevel but also sheds light on the subspace's ability to preserve such\nentanglement. Utilizing non-convex optimization techniques from the domain of\nmachine learning, our method effectively calculates $E_r(S)$ in various\nscenarios. Showcasing strong performance in comparison to existing hierarchical\nand PPT relaxation techniques, our approach is notable for its accuracy,\ncomputational efficiency, and wide-ranging applicability. This versatile and\neffective tool paves the way for numerous new applications in quantum\ninformation science. It is particularly useful in validating highly entangled\nsubspaces in bipartite systems, determining the border rank of multipartite\nstates, and identifying genuinely or completely entangled subspaces. Our\napproach offers a fresh perspective for quantifying entanglement, while also\nshedding light on the intricate structure of quantum entanglement.",
            "author": [
                "Xuanran Zhu",
                "Chao Zhang",
                "Bei Zeng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10353v1",
                "http://arxiv.org/pdf/2311.10353v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10352v1",
            "title": "Joint Sensing and Communication Optimization in Target-Mounted\n  STARS-Assisted Vehicular Networks: A MADRL Approach",
            "updated": "2023-11-17T06:51:44Z",
            "published": "2023-11-17T06:51:44Z",
            "summary": "The utilization of integrated sensing and communication (ISAC) technology has\nthe potential to enhance the communication performance of road side units\n(RSUs) through the active sensing of target vehicles. Furthermore, installing a\nsimultaneous transmitting and reflecting surface (STARS) on the target vehicle\ncan provide an extra boost to the reflection of the echo signal, thereby\nimproving the communication quality for in-vehicle users. However, the design\nof this target-mounted STARS system exhibits significant challenges, such as\nlimited information sharing and distributed STARS control. In this paper, we\npropose an end-to-end multi-agent deep reinforcement learning (MADRL) framework\nto tackle the challenges of joint sensing and communication optimization in the\nconsidered target-mounted STARS assisted vehicle networks. By deploying agents\non both RSU and vehicle, the MADRL framework enables RSU and vehicle to perform\nbeam prediction and STARS pre-configuration using their respective local\ninformation. To ensure efficient and stable learning for continuous\ndecision-making, we employ the multi-agent soft actor critic (MASAC) algorithm\nand the multi-agent proximal policy optimization (MAPPO) algorithm on the\nproposed MADRL framework. Extensive experimental results confirm the\neffectiveness of our proposed MADRL framework in improving both sensing and\ncommunication performance through the utilization of target-mounted STARS.\nFinally, we conduct a comparative analysis and comparison of the two proposed\nalgorithms under various environmental conditions.",
            "author": [
                "Haocheng Zhang",
                "Rang Liu",
                "Ming Li",
                "Wei Wang",
                "Qian Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10352v1",
                "http://arxiv.org/pdf/2311.10352v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10351v1",
            "title": "Galaxy stellar and total mass estimation using machine learning",
            "updated": "2023-11-17T06:46:39Z",
            "published": "2023-11-17T06:46:39Z",
            "summary": "Conventional galaxy mass estimation methods suffer from model assumptions and\ndegeneracies. Machine learning, which reduces the reliance on such assumptions,\ncan be used to determine how well present-day observations can yield\npredictions for the distributions of stellar and dark matter. In this work, we\nuse a general sample of galaxies from the TNG100 simulation to investigate the\nability of multi-branch convolutional neural network (CNN) based machine\nlearning methods to predict the central (i.e., within $1-2$ effective radii)\nstellar and total masses, and the stellar mass-to-light ratio $M_*/L$. These\nmodels take galaxy images and spatially-resolved mean velocity and velocity\ndispersion maps as inputs. Such CNN-based models can in general break the\ndegeneracy between baryonic and dark matter in the sense that the model can\nmake reliable predictions on the individual contributions of each component.\nFor example, with $r$-band images and two galaxy kinematic maps as inputs, our\nmodel predicting $M_*/L$ has a prediction uncertainty of 0.04 dex. Moreover, to\ninvestigate which (global) features significantly contribute to the correct\npredictions of the properties above, we utilize a gradient boosting machine. We\nfind that galaxy luminosity dominates the prediction of all masses in the\ncentral regions, with stellar velocity dispersion coming next. We also\ninvestigate the main contributing features when predicting stellar and dark\nmatter mass fractions ($f_*$, $f_{\\rm DM}$) and the dark matter mass $M_{DM}$,\nand discuss the underlying astrophysics.",
            "author": [
                "Jiani Chu",
                "Hongming Tang",
                "Dandan Xu",
                "Shengdong Lu",
                "Richard Long"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10351v1",
                "http://arxiv.org/pdf/2311.10351v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10349v1",
            "title": "Pseudo Label-Guided Data Fusion and Output Consistency for\n  Semi-Supervised Medical Image Segmentation",
            "updated": "2023-11-17T06:36:43Z",
            "published": "2023-11-17T06:36:43Z",
            "summary": "Supervised learning algorithms based on Convolutional Neural Networks have\nbecome the benchmark for medical image segmentation tasks, but their\neffectiveness heavily relies on a large amount of labeled data. However,\nannotating medical image datasets is a laborious and time-consuming process.\nInspired by semi-supervised algorithms that use both labeled and unlabeled data\nfor training, we propose the PLGDF framework, which builds upon the mean\nteacher network for segmenting medical images with less annotation. We propose\na novel pseudo-label utilization scheme, which combines labeled and unlabeled\ndata to augment the dataset effectively. Additionally, we enforce the\nconsistency between different scales in the decoder module of the segmentation\nnetwork and propose a loss function suitable for evaluating the consistency.\nMoreover, we incorporate a sharpening operation on the predicted results,\nfurther enhancing the accuracy of the segmentation.\n  Extensive experiments on three publicly available datasets demonstrate that\nthe PLGDF framework can largely improve performance by incorporating the\nunlabeled data. Meanwhile, our framework yields superior performance compared\nto six state-of-the-art semi-supervised learning methods. The codes of this\nstudy are available at https://github.com/ortonwang/PLGDF.",
            "author": [
                "Tao Wang",
                "Yuanbin Chen",
                "Xinlin Zhang",
                "Yuanbo Zhou",
                "Junlin Lan",
                "Bizhe Bai",
                "Tao Tan",
                "Min Du",
                "Qinquan Gao",
                "Tong Tong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10349v1",
                "http://arxiv.org/pdf/2311.10349v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10343v1",
            "title": "Enhancing Student Engagement in Online Learning through Facial\n  Expression Analysis and Complex Emotion Recognition using Deep Learning",
            "updated": "2023-11-17T06:07:54Z",
            "published": "2023-11-17T06:07:54Z",
            "summary": "In response to the COVID-19 pandemic, traditional physical classrooms have\ntransitioned to online environments, necessitating effective strategies to\nensure sustained student engagement. A significant challenge in online teaching\nis the absence of real-time feedback from teachers on students learning\nprogress. This paper introduces a novel approach employing deep learning\ntechniques based on facial expressions to assess students engagement levels\nduring online learning sessions. Human emotions cannot be adequately conveyed\nby a student using only the basic emotions, including anger, disgust, fear,\njoy, sadness, surprise, and neutrality. To address this challenge, proposed a\ngeneration of four complex emotions such as confusion, satisfaction,\ndisappointment, and frustration by combining the basic emotions. These complex\nemotions are often experienced simultaneously by students during the learning\nsession. To depict these emotions dynamically,utilized a continuous stream of\nimage frames instead of discrete images. The proposed work utilized a\nConvolutional Neural Network (CNN) model to categorize the fundamental\nemotional states of learners accurately. The proposed CNN model demonstrates\nstrong performance, achieving a 95% accuracy in precise categorization of\nlearner emotions.",
            "author": [
                "Rekha R Nair",
                "Tina Babu",
                "Pavithra K"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10343v1",
                "http://arxiv.org/pdf/2311.10343v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10341v1",
            "title": "Federated Knowledge Graph Completion via Latent Embedding Sharing and\n  Tensor Factorization",
            "updated": "2023-11-17T06:03:56Z",
            "published": "2023-11-17T06:03:56Z",
            "summary": "Knowledge graphs (KGs), which consist of triples, are inherently incomplete\nand always require completion procedure to predict missing triples. In\nreal-world scenarios, KGs are distributed across clients, complicating\ncompletion tasks due to privacy restrictions. Many frameworks have been\nproposed to address the issue of federated knowledge graph completion. However,\nthe existing frameworks, including FedE, FedR, and FEKG, have certain\nlimitations. = FedE poses a risk of information leakage, FedR's optimization\nefficacy diminishes when there is minimal overlap among relations, and FKGE\nsuffers from computational costs and mode collapse issues. To address these\nissues, we propose a novel method, i.e., Federated Latent Embedding Sharing\nTensor factorization (FLEST), which is a novel approach using federated tensor\nfactorization for KG completion. FLEST decompose the embedding matrix and\nenables sharing of latent dictionary embeddings to lower privacy risks.\nEmpirical results demonstrate FLEST's effectiveness and efficiency, offering a\nbalanced solution between performance and privacy. FLEST expands the\napplication of federated tensor factorization in KG completion tasks.",
            "author": [
                "Maolin Wang",
                "Dun Zeng",
                "Zenglin Xu",
                "Ruocheng Guo",
                "Xiangyu Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10341v1",
                "http://arxiv.org/pdf/2311.10341v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10339v1",
            "title": "A2XP: Towards Private Domain Generalization",
            "updated": "2023-11-17T05:49:50Z",
            "published": "2023-11-17T05:49:50Z",
            "summary": "Deep Neural Networks (DNNs) have become pivotal in various fields, especially\nin computer vision, outperforming previous methodologies. A critical challenge\nin their deployment is the bias inherent in data across different domains, such\nas image style, and environmental conditions, leading to domain gaps. This\nnecessitates techniques for learning general representations from biased\ntraining data, known as domain generalization. This paper presents Attend to\neXpert Prompts (A2XP), a novel approach for domain generalization that\npreserves the privacy and integrity of the network architecture. A2XP consists\nof two phases: Expert Adaptation and Domain Generalization. In the first phase,\nprompts for each source domain are optimized to guide the model towards the\noptimal direction. In the second phase, two embedder networks are trained to\neffectively amalgamate these expert prompts, aiming for an optimal output. Our\nextensive experiments demonstrate that A2XP achieves state-of-the-art results\nover existing non-private domain generalization methods. The experimental\nresults validate that the proposed approach not only tackles the domain\ngeneralization challenge in DNNs but also offers a privacy-preserving,\nefficient solution to the broader field of computer vision.",
            "author": [
                "Geunhyeok Yu",
                "Hyoseok Hwang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10339v1",
                "http://arxiv.org/pdf/2311.10339v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10337v1",
            "title": "Scalable Edge Clustering of Dynamic Graphs via Weighted Line Graphs",
            "updated": "2023-11-17T05:48:20Z",
            "published": "2023-11-17T05:48:20Z",
            "summary": "Timestamped relational datasets consisting of records between pairs of\nentities are ubiquitous in data and network science. For applications like\npeer-to-peer communication, email, social network interactions, and computer\nnetwork security, it makes sense to organize these records into groups based on\nhow and when they are occurring. Weighted line graphs offer a natural way to\nmodel how records are related in such datasets but for large real-world graph\ntopologies the complexity of building and utilizing the line graph is\nprohibitive. We present an algorithm to cluster the edges of a dynamic graph\nvia the associated line graph without forming it explicitly.\n  We outline a novel hierarchical dynamic graph edge clustering approach that\nefficiently breaks massive relational datasets into small sets of edges\ncontaining events at various timescales. This is in stark contrast to\ntraditional graph clustering algorithms that prioritize highly connected\ncommunity structures. Our approach relies on constructing a sufficient subgraph\nof a weighted line graph and applying a hierarchical agglomerative clustering.\nThis work draws particular inspiration from HDBSCAN.\n  We present a parallel algorithm and show that it is able to break\nbillion-scale dynamic graphs into small sets that correlate in topology and\ntime. The entire clustering process for a graph with $O(10 \\text{ billion})$\nedges takes just a few minutes of run time on 256 nodes of a distributed\ncompute environment. We argue how the output of the edge clustering is useful\nfor a multitude of data visualization and powerful machine learning tasks, both\ninvolving the original massive dynamic graph data and/or the non-relational\nmetadata. Finally, we demonstrate its use on a real-world large-scale directed\ndynamic graph and describe how it can be extended to dynamic hypergraphs and\ngraphs with unstructured data living on vertices and edges.",
            "author": [
                "Michael Ostroski",
                "Geoffrey Sanders",
                "Trevor Steil",
                "Roger Pearce"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10337v1",
                "http://arxiv.org/pdf/2311.10337v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.DC",
                "cs.SI",
                "05C90, 68R10, 68W10, 68W15, 68W40, 68T09",
                "I.5.3; E.1"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10336v1",
            "title": "Cooperative Perception with Learning-Based V2V communications",
            "updated": "2023-11-17T05:41:23Z",
            "published": "2023-11-17T05:41:23Z",
            "summary": "Cooperative perception has been widely used in autonomous driving to\nalleviate the inherent limitation of single automated vehicle perception. To\nenable cooperation, vehicle-to-vehicle (V2V) communication plays an\nindispensable role. This work analyzes the performance of cooperative\nperception accounting for communications channel impairments. Different fusion\nmethods and channel impairments are evaluated. A new late fusion scheme is\nproposed to leverage the robustness of intermediate features. In order to\ncompress the data size incurred by cooperation, a convolution neural\nnetwork-based autoencoder is adopted. Numerical results demonstrate that\nintermediate fusion is more robust to channel impairments than early fusion and\nlate fusion, when the SNR is greater than 0 dB. Also, the proposed fusion\nscheme outperforms the conventional late fusion using detection outputs, and\nautoencoder provides a good compromise between detection accuracy and bandwidth\nusage.",
            "author": [
                "Chenguang Liu",
                "Yunfei Chen",
                "Jianjun Chen",
                "Ryan Payton",
                "Michael Riley",
                "Shuang-Hua Yang"
            ],
            "link": [
                "http://dx.doi.org/10.1109/LWC.2023.3295612",
                "http://arxiv.org/abs/2311.10336v1",
                "http://arxiv.org/pdf/2311.10336v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10329v1",
            "title": "High-fidelity Person-centric Subject-to-Image Synthesis",
            "updated": "2023-11-17T05:03:53Z",
            "published": "2023-11-17T05:03:53Z",
            "summary": "Current subject-driven image generation methods encounter significant\nchallenges in person-centric image generation. The reason is that they learn\nthe semantic scene and person generation by fine-tuning a common pre-trained\ndiffusion, which involves an irreconcilable training imbalance. Precisely, to\ngenerate realistic persons, they need to sufficiently tune the pre-trained\nmodel, which inevitably causes the model to forget the rich semantic scene\nprior and makes scene generation over-fit to the training data. Moreover, even\nwith sufficient fine-tuning, these methods can still not generate high-fidelity\npersons since joint learning of the scene and person generation also lead to\nquality compromise. In this paper, we propose Face-diffuser, an effective\ncollaborative generation pipeline to eliminate the above training imbalance and\nquality compromise. Specifically, we first develop two specialized pre-trained\ndiffusion models, i.e., Text-driven Diffusion Model (TDM) and Subject-augmented\nDiffusion Model (SDM), for scene and person generation, respectively. The\nsampling process is divided into three sequential stages, i.e., semantic scene\nconstruction, subject-scene fusion, and subject enhancement. The first and last\nstages are performed by TDM and SDM respectively. The subject-scene fusion\nstage, that is the collaboration achieved through a novel and highly effective\nmechanism, Saliency-adaptive Noise Fusion (SNF). Specifically, it is based on\nour key observation that there exists a robust link between classifier-free\nguidance responses and the saliency of generated images. In each time step, SNF\nleverages the unique strengths of each model and allows for the spatial\nblending of predicted noises from both models automatically in a saliency-aware\nmanner. Extensive experiments confirm the impressive effectiveness and\nrobustness of the Face-diffuser.",
            "author": [
                "Yibin Wang",
                "Weizhong Zhang",
                "Jianwei Zheng",
                "Cheng Jin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10329v1",
                "http://arxiv.org/pdf/2311.10329v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10328v1",
            "title": "TransONet: Automatic Segmentation of Vasculature in Computed Tomographic\n  Angiograms Using Deep Learning",
            "updated": "2023-11-17T04:59:08Z",
            "published": "2023-11-17T04:59:08Z",
            "summary": "Pathological alterations in the human vascular system underlie many chronic\ndiseases, such as atherosclerosis and aneurysms. However, manually analyzing\ndiagnostic images of the vascular system, such as computed tomographic\nangiograms (CTAs) is a time-consuming and tedious process. To address this\nissue, we propose a deep learning model to segment the vascular system in CTA\nimages of patients undergoing surgery for peripheral arterial disease (PAD).\nOur study focused on accurately segmenting the vascular system (1) from the\ndescending thoracic aorta to the iliac bifurcation and (2) from the descending\nthoracic aorta to the knees in CTA images using deep learning techniques. Our\napproach achieved average Dice accuracies of 93.5% and 80.64% in test dataset\nfor (1) and (2), respectively, highlighting its high accuracy and potential\nclinical utility. These findings demonstrate the use of deep learning\ntechniques as a valuable tool for medical professionals to analyze the health\nof the vascular system efficiently and accurately. Please visit the GitHub page\nfor this paper at https://github.com/pip-alireza/TransOnet.",
            "author": [
                "Alireza Bagheri Rajeoni",
                "Breanna Pederson",
                "Ali Firooz",
                "Hamed Abdollahi",
                "Andrew K. Smith",
                "Daniel G. Clair",
                "Susan M. Lessner",
                "Homayoun Valafar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10328v1",
                "http://arxiv.org/pdf/2311.10328v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.CV",
                "cs.LG",
                "I.4.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10795v1",
            "title": "How False Data Affects Machine Learning Models in Electrochemistry?",
            "updated": "2023-11-17T04:30:31Z",
            "published": "2023-11-17T04:30:31Z",
            "summary": "Recently, the selection of machine learning model based on only the data\ndistribution without concerning the noise of the data. This study aims to\ndistinguish, which models perform well under noisy data, and establish whether\nstacking machine learning models actually provide robustness to otherwise\nweak-to-noise models. The electrochemical data were tested with 12 standalone\nmodels and stacking model. This includes XGB, LGBM, RF, GB, ADA, NN, ELAS,\nLASS, RIDGE, SVM, KNN, DT, and the stacking model. It is found that linear\nmodels handle noise well with the average error of (slope) to 1.75 F g-1 up to\nerror per 100% percent noise added; but it suffers from prediction accuracy due\nto having an average of 60.19 F g-1 estimated at minimal error at 0% noise\nadded. Tree-based models fail in terms of noise handling (average slope is\n55.24 F g-1 at 100% percent noise), but it can provide higher prediction\naccuracy (lowest error of 23.9 F g-1) than that of linear. To address the\ncontroversial between prediction accuracy and error handling, the stacking\nmodel was constructed, which is not only show high accuracy (intercept of 25.03\nF g-1), but it also exhibits good noise handling (slope of 43.58 F g-1), making\nstacking models a relatively low risk and viable choice for beginner and\nexperienced machine learning research in electrochemistry. Even though neural\nnetworks (NN) are gaining popularity in the electrochemistry field. However,\nthis study presents that NN is not suitable for electrochemical data, and\nimproper tuning resulting in a model that is susceptible to noise. Thus, STACK\nmodels should provide better benefits in that even with untuned base models,\nthey can achieve an accurate and noise-tolerant model. Overall, this work\nprovides insight into machine learning model selection for electrochemical\ndata, which should aid the understanding of data science in chemistry context.",
            "author": [
                "Krittapong Deshsorna",
                "Luckhana Lawtrakul",
                "Pawin Iamprasertkun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10795v1",
                "http://arxiv.org/pdf/2311.10795v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "physics.chem-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10322v1",
            "title": "Clustering Techniques for Stable Linear Dynamical Systems with\n  applications to Hard Disk Drives",
            "updated": "2023-11-17T04:24:52Z",
            "published": "2023-11-17T04:24:52Z",
            "summary": "In Robust Control and Data Driven Robust Control design methodologies,\nmultiple plant transfer functions or a family of transfer functions are\nconsidered and a common controller is designed such that all the plants that\nfall into this family are stabilized. Though the plants are stabilized, the\ncontroller might be sub-optimal for each of the plants when the variations in\nthe plants are large. This paper presents a way of clustering stable linear\ndynamical systems for the design of robust controllers within each of the\nclusters such that the controllers are optimal for each of the clusters. First\na k-medoids algorithm for hard clustering will be presented for stable Linear\nTime Invariant (LTI) systems and then a Gaussian Mixture Models (GMM)\nclustering for a special class of LTI systems, common for Hard Disk Drive\nplants, will be presented.",
            "author": [
                "Nikhil Potu Surya Prakash",
                "Joohwan Seo",
                "Jongeun Choi",
                "Roberto Horowitz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10322v1",
                "http://arxiv.org/pdf/2311.10322v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.AI",
                "cs.LG",
                "cs.SY",
                "math.DS",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10321v2",
            "title": "Towards Machine Learning-based Quantitative Hyperspectral Image Guidance\n  for Brain Tumor Resection",
            "updated": "2023-11-24T19:59:28Z",
            "published": "2023-11-17T04:15:27Z",
            "summary": "Complete resection of malignant gliomas is hampered by the difficulty in\ndistinguishing tumor cells at the infiltration zone. Fluorescence guidance with\n5-ALA assists in reaching this goal. Using hyperspectral imaging, previous work\ncharacterized five fluorophores' emission spectra in most human brain tumors.\nIn this paper, the effectiveness of these five spectra was explored for\ndifferent tumor and tissue classification tasks in 184 patients (891\nhyperspectral measurements) harboring low- (n=30) and high-grade gliomas\n(n=115), non-glial primary brain tumors (n=19), radiation necrosis (n=2),\nmiscellaneous (n=10) and metastases (n=8). Four machine learning models were\ntrained to classify tumor type, grade, glioma margins and IDH mutation. Using\nrandom forests and multi-layer perceptrons, the classifiers achieved average\ntest accuracies of 84-87%, 96%, 86%, and 93% respectively. All five fluorophore\nabundances varied between tumor margin types and tumor grades (p < 0.01). For\ntissue type, at least four of the five fluorophore abundances were found to be\nsignificantly different (p < 0.01) between all classes. These results\ndemonstrate the fluorophores' differing abundances in different tissue classes,\nas well as the value of the five fluorophores as potential optical biomarkers,\nopening new opportunities for intraoperative classification systems in\nfluorescence-guided neurosurgery.",
            "author": [
                "David Black",
                "Declan Byrne",
                "Anna Walke",
                "Sidong Liu",
                "Antonio Di leva",
                "Sadahiro Kaneko",
                "Walter Stummer",
                "Septimiu Salcudean",
                "Eric Suero Molina"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10321v2",
                "http://arxiv.org/pdf/2311.10321v2"
            ],
            "primary_category": "q-bio.TO",
            "category": [
                "q-bio.TO",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10320v1",
            "title": "Learning transformer-based heterogeneously salient graph representation\n  for multimodal fusion classification of hyperspectral image and LiDAR data",
            "updated": "2023-11-17T04:06:20Z",
            "published": "2023-11-17T04:06:20Z",
            "summary": "Data collected by different modalities can provide a wealth of complementary\ninformation, such as hyperspectral image (HSI) to offer rich spectral-spatial\nproperties, synthetic aperture radar (SAR) to provide structural information\nabout the Earth's surface, and light detection and ranging (LiDAR) to cover\naltitude information about ground elevation. Therefore, a natural idea is to\ncombine multimodal images for refined and accurate land-cover interpretation.\nAlthough many efforts have been attempted to achieve multi-source remote\nsensing image classification, there are still three issues as follows: 1)\nindiscriminate feature representation without sufficiently considering modal\nheterogeneity, 2) abundant features and complex computations associated with\nmodeling long-range dependencies, and 3) overfitting phenomenon caused by\nsparsely labeled samples. To overcome the above barriers, a transformer-based\nheterogeneously salient graph representation (THSGR) approach is proposed in\nthis paper. First, a multimodal heterogeneous graph encoder is presented to\nencode distinctively non-Euclidean structural features from heterogeneous data.\nThen, a self-attention-free multi-convolutional modulator is designed for\neffective and efficient long-term dependency modeling. Finally, a mean forward\nis put forward in order to avoid overfitting. Based on the above structures,\nthe proposed model is able to break through modal gaps to obtain differentiated\ngraph representation with competitive time cost, even for a small fraction of\ntraining samples. Experiments and analyses on three benchmark datasets with\nvarious state-of-the-art (SOTA) methods show the performance of the proposed\napproach.",
            "author": [
                "Jiaqi Yang",
                "Bo Du",
                "Liangpei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10320v1",
                "http://arxiv.org/pdf/2311.10320v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10319v1",
            "title": "Shifting to Machine Supervision: Annotation-Efficient Semi and\n  Self-Supervised Learning for Automatic Medical Image Segmentation and\n  Classification",
            "updated": "2023-11-17T04:04:29Z",
            "published": "2023-11-17T04:04:29Z",
            "summary": "Advancements in clinical treatment and research are limited by supervised\nlearning techniques that rely on large amounts of annotated data, an expensive\ntask requiring many hours of clinical specialists' time. In this paper, we\npropose using self-supervised and semi-supervised learning. These techniques\nperform an auxiliary task that is label-free, scaling up machine-supervision is\neasier compared with fully-supervised techniques. This paper proposes S4MI\n(Self-Supervision and Semi-Supervision for Medical Imaging), our pipeline to\nleverage advances in self and semi-supervision learning. We benchmark them on\nthree medical imaging datasets to analyze their efficacy for classification and\nsegmentation. This advancement in self-supervised learning with 10% annotation\nperformed better than 100% annotation for the classification of most datasets.\nThe semi-supervised approach yielded favorable outcomes for segmentation,\noutperforming the fully-supervised approach by using 50% fewer labels in all\nthree datasets.",
            "author": [
                "Pranav Singh",
                "Raviteja Chukkapalli",
                "Shravan Chaudhari",
                "Luoyao Chen",
                "Mei Chen",
                "Jinqian Pan",
                "Craig Smuda",
                "Jacopo Cirrone"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10319v1",
                "http://arxiv.org/pdf/2311.10319v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10318v1",
            "title": "Nonparametric Teaching for Multiple Learners",
            "updated": "2023-11-17T04:04:11Z",
            "published": "2023-11-17T04:04:11Z",
            "summary": "We study the problem of teaching multiple learners simultaneously in the\nnonparametric iterative teaching setting, where the teacher iteratively\nprovides examples to the learner for accelerating the acquisition of a target\nconcept. This problem is motivated by the gap between current single-learner\nteaching setting and the real-world scenario of human instruction where a\nteacher typically imparts knowledge to multiple students. Under the new problem\nformulation, we introduce a novel framework -- Multi-learner Nonparametric\nTeaching (MINT). In MINT, the teacher aims to instruct multiple learners, with\neach learner focusing on learning a scalar-valued target model. To achieve\nthis, we frame the problem as teaching a vector-valued target model and extend\nthe target model space from a scalar-valued reproducing kernel Hilbert space\nused in single-learner scenarios to a vector-valued space. Furthermore, we\ndemonstrate that MINT offers significant teaching speed-up over repeated\nsingle-learner teaching, particularly when the multiple learners can\ncommunicate with each other. Lastly, we conduct extensive experiments to\nvalidate the practicality and efficiency of MINT.",
            "author": [
                "Chen Zhang",
                "Xiaofeng Cao",
                "Weiyang Liu",
                "Ivor Tsang",
                "James Kwok"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10318v1",
                "http://arxiv.org/pdf/2311.10318v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10316v1",
            "title": "Graph Sparsifications using Neural Network Assisted Monte Carlo Tree\n  Search",
            "updated": "2023-11-17T03:59:50Z",
            "published": "2023-11-17T03:59:50Z",
            "summary": "Graph neural networks have been successful for machine learning, as well as\nfor combinatorial and graph problems such as the Subgraph Isomorphism Problem\nand the Traveling Salesman Problem. We describe an approach for computing graph\nsparsifiers by combining a graph neural network and Monte Carlo Tree Search. We\nfirst train a graph neural network that takes as input a partial solution and\nproposes a new node to be added as output. This neural network is then used in\na Monte Carlo search to compute a sparsifier. The proposed method consistently\noutperforms several standard approximation algorithms on different types of\ngraphs and often finds the optimal solution.",
            "author": [
                "Alvin Chiu",
                "Mithun Ghosh",
                "Reyan Ahmed",
                "Kwang-Sung Jun",
                "Stephen Kobourov",
                "Michael T. Goodrich"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10316v1",
                "http://arxiv.org/pdf/2311.10316v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10315v1",
            "title": "Interpretable Modeling of Single-cell perturbation Responses to Novel\n  Drugs Using Cycle Consistence Learning",
            "updated": "2023-11-17T03:58:59Z",
            "published": "2023-11-17T03:58:59Z",
            "summary": "Phenotype-based screening has attracted much attention for identifying\ncell-active compounds. Transcriptional and proteomic profiles of cell\npopulation or single cells are informative phenotypic measures of cellular\nresponses to perturbations. In this paper, we proposed a deep learning\nframework based on encoder-decoder architecture that maps the initial cellular\nstates to a latent space, in which we assume the effects of drug perturbation\non cellular states follow linear additivity. Next, we introduced the cycle\nconsistency constraints to enforce that initial cellular state subjected to\ndrug perturbations would produce the perturbed cellular responses, and,\nconversely, removal of drug perturbation from the perturbed cellular states\nwould restore the initial cellular states. The cycle consistency constraints\nand linear modeling in latent space enable to learn interpretable and\ntransferable drug perturbation representations, so that our model can predict\ncellular response to unseen drugs. We validated our model on three different\ntypes of datasets, including bulk transcriptional responses, bulk proteomic\nresponses, and single-cell transcriptional responses to drug perturbations. The\nexperimental results show that our model achieves better performance than\nexisting state-of-the-art methods.",
            "author": [
                "Wei Huang",
                "Aichun Zhu",
                "Hui Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10315v1",
                "http://arxiv.org/pdf/2311.10315v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10311v1",
            "title": "Joint channel estimation and data detection in massive MIMO systems\n  based on diffusion models",
            "updated": "2023-11-17T03:44:33Z",
            "published": "2023-11-17T03:44:33Z",
            "summary": "We propose a joint channel estimation and data detection algorithm for\nmassive multilple-input multiple-output systems based on diffusion models. Our\nproposed method solves the blind inverse problem by sampling from the joint\nposterior distribution of the symbols and channels and computing an approximate\nmaximum a posteriori estimation. To achieve this, we construct a diffusion\nprocess that models the joint distribution of the channels and symbols given\nnoisy observations, and then run the reverse process to generate the samples. A\nunique contribution of the algorithm is to include the discrete prior\ndistribution of the symbols and a learned prior for the channels. Indeed, this\nis key as it allows a more efficient exploration of the joint search space and,\ntherefore, enhances the sampling process. Through numerical experiments, we\ndemonstrate that our method yields a lower normalized mean squared error than\ncompeting approaches and reduces the pilot overhead.",
            "author": [
                "Nicolas Zilberstein",
                "Ananthram Swami",
                "Santiago Segarra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10311v1",
                "http://arxiv.org/pdf/2311.10311v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00794v1",
            "title": "Informative Priors Improve the Reliability of Multimodal Clinical Data\n  Classification",
            "updated": "2023-11-17T03:44:15Z",
            "published": "2023-11-17T03:44:15Z",
            "summary": "Machine learning-aided clinical decision support has the potential to\nsignificantly improve patient care. However, existing efforts in this domain\nfor principled quantification of uncertainty have largely been limited to\napplications of ad-hoc solutions that do not consistently improve reliability.\nIn this work, we consider stochastic neural networks and design a tailor-made\nmultimodal data-driven (M2D2) prior distribution over network parameters. We\nuse simple and scalable Gaussian mean-field variational inference to train a\nBayesian neural network using the M2D2 prior. We train and evaluate the\nproposed approach using clinical time-series data in MIMIC-IV and corresponding\nchest X-ray images in MIMIC-CXR for the classification of acute care\nconditions. Our empirical results show that the proposed method produces a more\nreliable predictive model compared to deterministic and Bayesian neural network\nbaselines.",
            "author": [
                "L. Julian Lechuga Lopez",
                "Tim G. J. Rudner",
                "Farah E. Shamout"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00794v1",
                "http://arxiv.org/pdf/2312.00794v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CY",
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10309v1",
            "title": "Imagination-augmented Hierarchical Reinforcement Learning for Safe and\n  Interactive Autonomous Driving in Urban Environments",
            "updated": "2023-11-17T03:41:22Z",
            "published": "2023-11-17T03:41:22Z",
            "summary": "Hierarchical reinforcement learning (HRL) has led to remarkable achievements\nin diverse fields. However, existing HRL algorithms still cannot be applied to\nreal-world navigation tasks. These tasks require an agent to perform\nsafety-aware behaviors and interact with surrounding objects in dynamic\nenvironments. In addition, an agent in these tasks should perform consistent\nand structured exploration as they are long-horizon and have complex structures\nwith diverse objects and task-specific rules. Designing HRL agents that can\nhandle these challenges in real-world navigation tasks is an open problem. In\nthis paper, we propose imagination-augmented HRL (IAHRL), a new and general\nnavigation algorithm that allows an agent to learn safe and interactive\nbehaviors in real-world navigation tasks. Our key idea is to train a\nhierarchical agent in which a high-level policy infers interactions by\ninterpreting behaviors imagined with low-level policies. Specifically, the\nhigh-level policy is designed with a permutation-invariant attention mechanism\nto determine which low-level policy generates the most interactive behavior,\nand the low-level policies are implemented with an optimization-based behavior\nplanner to generate safe and structured behaviors following task-specific\nrules. To evaluate our algorithm, we introduce five complex urban driving\ntasks, which are among the most challenging real-world navigation tasks. The\nexperimental results indicate that our hierarchical agent performs safety-aware\nbehaviors and properly interacts with surrounding vehicles, achieving higher\nsuccess rates and lower average episode steps than baselines in urban driving\ntasks.",
            "author": [
                "Sang-Hyun Lee",
                "Yoonjae Jung",
                "Seung-Woo Seo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10309v1",
                "http://arxiv.org/pdf/2311.10309v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10306v1",
            "title": "MPSeg : Multi-Phase strategy for coronary artery Segmentation",
            "updated": "2023-11-17T03:33:09Z",
            "published": "2023-11-17T03:33:09Z",
            "summary": "Accurate segmentation of coronary arteries is a pivotal process in assessing\ncardiovascular diseases. However, the intricate structure of the cardiovascular\nsystem presents significant challenges for automatic segmentation, especially\nwhen utilizing methodologies like the SYNTAX Score, which relies extensively on\ndetailed structural information for precise risk stratification. To address\nthese difficulties and cater to this need, we present MPSeg, an innovative\nmulti-phase strategy designed for coronary artery segmentation. Our approach\nspecifically accommodates these structural complexities and adheres to the\nprinciples of the SYNTAX Score. Initially, our method segregates vessels into\ntwo categories based on their unique morphological characteristics: Left\nCoronary Artery (LCA) and Right Coronary Artery (RCA). Specialized ensemble\nmodels are then deployed for each category to execute the challenging\nsegmentation task. Due to LCA's higher complexity over RCA, a refinement model\nis utilized to scrutinize and correct initial class predictions on segmented\nareas. Notably, our approach demonstrated exceptional effectiveness when\nevaluated in the Automatic Region-based Coronary Artery Disease diagnostics\nusing x-ray angiography imagEs (ARCADE) Segmentation Detection Algorithm\nchallenge at MICCAI 2023.",
            "author": [
                "Jonghoe Ku",
                "Yong-Hee Lee",
                "Junsup Shin",
                "In Kyu Lee",
                "Hyun-Woo Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10306v1",
                "http://arxiv.org/pdf/2311.10306v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10305v1",
            "title": "Semi-supervised ViT knowledge distillation network with style transfer\n  normalization for colorectal liver metastases survival prediction",
            "updated": "2023-11-17T03:32:11Z",
            "published": "2023-11-17T03:32:11Z",
            "summary": "Colorectal liver metastases (CLM) significantly impact colon cancer patients,\ninfluencing survival based on systemic chemotherapy response. Traditional\nmethods like tumor grading scores (e.g., tumor regression grade - TRG) for\nprognosis suffer from subjectivity, time constraints, and expertise demands.\nCurrent machine learning approaches often focus on radiological data, yet the\nrelevance of histological images for survival predictions, capturing intricate\ntumor microenvironment characteristics, is gaining recognition. To address\nthese limitations, we propose an end-to-end approach for automated prognosis\nprediction using histology slides stained with H&E and HPS. We first employ a\nGenerative Adversarial Network (GAN) for slide normalization to reduce staining\nvariations and improve the overall quality of the images that are used as input\nto our prediction pipeline. We propose a semi-supervised model to perform\ntissue classification from sparse annotations, producing feature maps. We use\nan attention-based approach that weighs the importance of different slide\nregions in producing the final classification results. We exploit the extracted\nfeatures for the metastatic nodules and surrounding tissue to train a prognosis\nmodel. In parallel, we train a vision Transformer (ViT) in a knowledge\ndistillation framework to replicate and enhance the performance of the\nprognosis prediction. In our evaluation on a clinical dataset of 258 patients,\nour approach demonstrates superior performance with c-indexes of 0.804 (0.014)\nfor OS and 0.733 (0.014) for TTR. Achieving 86.9% to 90.3% accuracy in\npredicting TRG dichotomization and 78.5% to 82.1% accuracy for the 3-class TRG\nclassification task, our approach outperforms comparative methods. Our proposed\npipeline can provide automated prognosis for pathologists and oncologists, and\ncan greatly promote precision medicine progress in managing CLM patients.",
            "author": [
                "Mohamed El Amine Elforaici",
                "Emmanuel Montagnon",
                "Francisco Perdigon Romero",
                "William Trung Le",
                "Feryel Azzi",
                "Dominique Trudel",
                "Bich Nguyen",
                "Simon Turcotte",
                "An Tang",
                "Samuel Kadoury"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10305v1",
                "http://arxiv.org/pdf/2311.10305v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10300v1",
            "title": "Supervised structure learning",
            "updated": "2023-11-17T03:18:55Z",
            "published": "2023-11-17T03:18:55Z",
            "summary": "This paper concerns structure learning or discovery of discrete generative\nmodels. It focuses on Bayesian model selection and the assimilation of training\ndata or content, with a special emphasis on the order in which data are\ningested. A key move - in the ensuing schemes - is to place priors on the\nselection of models, based upon expected free energy. In this setting, expected\nfree energy reduces to a constrained mutual information, where the constraints\ninherit from priors over outcomes (i.e., preferred outcomes). The resulting\nscheme is first used to perform image classification on the MNIST dataset to\nillustrate the basic idea, and then tested on a more challenging problem of\ndiscovering models with dynamics, using a simple sprite-based visual\ndisentanglement paradigm and the Tower of Hanoi (cf., blocks world) problem. In\nthese examples, generative models are constructed autodidactically to recover\n(i.e., disentangle) the factorial structure of latent states - and their\ncharacteristic paths or dynamics.",
            "author": [
                "Karl J. Friston",
                "Lancelot Da Costa",
                "Alexander Tschantz",
                "Alex Kiefer",
                "Tommaso Salvatori",
                "Victorita Neacsu",
                "Magnus Koudahl",
                "Conor Heins",
                "Noor Sajid",
                "Dimitrije Markovic",
                "Thomas Parr",
                "Tim Verbelen",
                "Christopher L Buckley"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10300v1",
                "http://arxiv.org/pdf/2311.10300v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10293v1",
            "title": "Hierarchical Pruning of Deep Ensembles with Focal Diversity",
            "updated": "2023-11-17T02:48:20Z",
            "published": "2023-11-17T02:48:20Z",
            "summary": "Deep neural network ensembles combine the wisdom of multiple deep neural\nnetworks to improve the generalizability and robustness over individual\nnetworks. It has gained increasing popularity to study deep ensemble techniques\nin the deep learning community. Some mission-critical applications utilize a\nlarge number of deep neural networks to form deep ensembles to achieve desired\naccuracy and resilience, which introduces high time and space costs for\nensemble execution. However, it still remains a critical challenge whether a\nsmall subset of the entire deep ensemble can achieve the same or better\ngeneralizability and how to effectively identify these small deep ensembles for\nimproving the space and time efficiency of ensemble execution. This paper\npresents a novel deep ensemble pruning approach, which can efficiently identify\nsmaller deep ensembles and provide higher ensemble accuracy than the entire\ndeep ensemble of a large number of member networks. Our hierarchical ensemble\npruning approach (HQ) leverages three novel ensemble pruning techniques. First,\nwe show that the focal diversity metrics can accurately capture the\ncomplementary capacity of the member networks of an ensemble, which can guide\nensemble pruning. Second, we design a focal diversity based hierarchical\npruning approach, which will iteratively find high quality deep ensembles with\nlow cost and high accuracy. Third, we develop a focal diversity consensus\nmethod to integrate multiple focal diversity metrics to refine ensemble pruning\nresults, where smaller deep ensembles can be effectively identified to offer\nhigh accuracy, high robustness and high efficiency. Evaluated using popular\nbenchmark datasets, we demonstrate that the proposed hierarchical ensemble\npruning approach can effectively identify high quality deep ensembles with\nbetter generalizability while being more time and space efficient in ensemble\ndecision making.",
            "author": [
                "Yanzhao Wu",
                "Ka-Ho Chow",
                "Wenqi Wei",
                "Ling Liu"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3633286",
                "http://arxiv.org/abs/2311.10293v1",
                "http://arxiv.org/pdf/2311.10293v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10291v1",
            "title": "Leveraging Function Space Aggregation for Federated Learning at Scale",
            "updated": "2023-11-17T02:37:10Z",
            "published": "2023-11-17T02:37:10Z",
            "summary": "The federated learning paradigm has motivated the development of methods for\naggregating multiple client updates into a global server model, without sharing\nclient data. Many federated learning algorithms, including the canonical\nFederated Averaging (FedAvg), take a direct (possibly weighted) average of the\nclient parameter updates, motivated by results in distributed optimization. In\nthis work, we adopt a function space perspective and propose a new algorithm,\nFedFish, that aggregates local approximations to the functions learned by\nclients, using an estimate based on their Fisher information. We evaluate\nFedFish on realistic, large-scale cross-device benchmarks. While the\nperformance of FedAvg can suffer as client models drift further apart, we\ndemonstrate that FedFish is more robust to longer local training. Our\nevaluation across several settings in image and language benchmarks shows that\nFedFish outperforms FedAvg as local training epochs increase. Further, FedFish\nresults in global networks that are more amenable to efficient personalization\nvia local fine-tuning on the same or shifted data distributions. For instance,\nfederated pretraining on the C4 dataset, followed by few-shot personalization\non Stack Overflow, results in a 7% improvement in next-token prediction by\nFedFish over FedAvg.",
            "author": [
                "Nikita Dhawan",
                "Nicole Mitchell",
                "Zachary Charles",
                "Zachary Garrett",
                "Gintare Karolina Dziugaite"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10291v1",
                "http://arxiv.org/pdf/2311.10291v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10793v2",
            "title": "Traffic Sign Interpretation in Real Road Scene",
            "updated": "2023-11-28T10:23:46Z",
            "published": "2023-11-17T02:30:36Z",
            "summary": "Most existing traffic sign-related works are dedicated to detecting and\nrecognizing part of traffic signs individually, which fails to analyze the\nglobal semantic logic among signs and may convey inaccurate traffic\ninstruction. Following the above issues, we propose a traffic sign\ninterpretation (TSI) task, which aims to interpret global semantic interrelated\ntraffic signs (e.g.,~driving instruction-related texts, symbols, and guide\npanels) into a natural language for providing accurate instruction support to\nautonomous or assistant driving. Meanwhile, we design a multi-task learning\narchitecture for TSI, which is responsible for detecting and recognizing\nvarious traffic signs and interpreting them into a natural language like a\nhuman. Furthermore, the absence of a public TSI available dataset prompts us to\nbuild a traffic sign interpretation dataset, namely TSI-CN. The dataset\nconsists of real road scene images, which are captured from the highway and the\nurban way in China from a driver's perspective. It contains rich location\nlabels of texts, symbols, and guide panels, and the corresponding natural\nlanguage description labels. Experiments on TSI-CN demonstrate that the TSI\ntask is achievable and the TSI architecture can interpret traffic signs from\nscenes successfully even if there is a complex semantic logic among signs. The\nTSI-CN dataset and the source code of the TSI architecture will be publicly\navailable after the revision process.",
            "author": [
                "Chuang Yang",
                "Kai Zhuang",
                "Mulin Chen",
                "Haozhao Ma",
                "Xu Han",
                "Tao Han",
                "Changxing Guo",
                "Han Han",
                "Bingxuan Zhao",
                "Qi Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10793v2",
                "http://arxiv.org/pdf/2311.10793v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10792v1",
            "title": "Attention Mechanism for Lithium-Ion Battery Lifespan Prediction:\n  Temporal and Cyclic Attention",
            "updated": "2023-11-17T02:30:19Z",
            "published": "2023-11-17T02:30:19Z",
            "summary": "Accurately predicting the lifespan of lithium-ion batteries (LIBs) is pivotal\nfor optimizing usage and preventing accidents. Previous studies in constructing\nprediction models often relied on inputs challenging to measure in real-time\noperations and failed to capture intra-cycle and inter-cycle data patterns,\nessential features for accurate predictions, comprehensively. In this study, we\nemploy attention mechanisms (AM) to develop data-driven models for predicting\nLIB lifespan using easily measurable inputs such as voltage, current,\ntemperature, and capacity data. The developed model integrates recurrent neural\nnetwork (RNN) and convolutional neural network (CNN) components, featuring two\ntypes of attention mechanisms: temporal attention (TA) and cyclic attention\n(CA). The inclusion of TA aims to identify important time steps within each\ncycle by scoring the hidden states of the RNN, whereas CA strives to capture\nkey features of inter-cycle correlations through self-attention (SA). This\nenhances model accuracy and elucidates critical features in the input data. To\nvalidate our method, we apply it to publicly available cycling data consisting\nof three batches of cycling modes. The calculated TA scores highlight the rest\nphase as a key characteristic distinguishing LIB data among different batches.\nAdditionally, CA scores reveal variations in the importance of cycles across\nbatches. By leveraging CA scores, we explore the potential to reduce the number\nof cycles in the input data. The single-head and multi-head attentions enable\nus to decrease the input dimension from 100 to 50 and 30 cycles, respectively.",
            "author": [
                "Jaewook Lee",
                "Seongmin Heo",
                "Jay H. Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10792v1",
                "http://arxiv.org/pdf/2311.10792v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10791v1",
            "title": "Modality-invariant and Specific Prompting for Multimodal Human\n  Perception Understanding",
            "updated": "2023-11-17T02:22:01Z",
            "published": "2023-11-17T02:22:01Z",
            "summary": "Understanding human perceptions presents a formidable multimodal challenge\nfor computers, encompassing aspects such as sentiment tendencies and sense of\nhumor. While various methods have recently been introduced to extract\nmodality-invariant and specific information from diverse modalities, with the\ngoal of enhancing the efficacy of multimodal learning, few works emphasize this\naspect in large language models. In this paper, we introduce a novel multimodal\nprompt strategy tailored for tuning large language models. Our method assesses\nthe correlation among different modalities and isolates the modality-invariant\nand specific components, which are then utilized for prompt tuning. This\napproach enables large language models to efficiently and effectively\nassimilate information from various modalities. Furthermore, our strategy is\ndesigned with scalability in mind, allowing the integration of features from\nany modality into pretrained large language models. Experimental results on\npublic datasets demonstrate that our proposed method significantly improves\nperformance compared to previous methods.",
            "author": [
                "Hao Sun",
                "Ziwei Niu",
                "Xinyao Yu",
                "Jiaqing Liu",
                "Yen-Wei Chen",
                "Lanfen Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10791v1",
                "http://arxiv.org/pdf/2311.10791v1"
            ],
            "primary_category": "cs.MM",
            "category": [
                "cs.MM",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10284v1",
            "title": "From \"Thumbs Up\" to \"10 out of 10\": Reconsidering Scalar Feedback in\n  Interactive Reinforcement Learning",
            "updated": "2023-11-17T02:14:08Z",
            "published": "2023-11-17T02:14:08Z",
            "summary": "Learning from human feedback is an effective way to improve robotic learning\nin exploration-heavy tasks. Compared to the wide application of binary human\nfeedback, scalar human feedback has been used less because it is believed to be\nnoisy and unstable. In this paper, we compare scalar and binary feedback, and\ndemonstrate that scalar feedback benefits learning when properly handled. We\ncollected binary or scalar feedback respectively from two groups of\ncrowdworkers on a robot task. We found that when considering how consistently a\nparticipant labeled the same data, scalar feedback led to less consistency than\nbinary feedback; however, the difference vanishes if small mismatches are\nallowed. Additionally, scalar and binary feedback show no significant\ndifferences in their correlations with key Reinforcement Learning targets. We\nthen introduce Stabilizing TEacher Assessment DYnamics (STEADY) to improve\nlearning from scalar feedback. Based on the idea that scalar feedback is\nmuti-distributional, STEADY re-constructs underlying positive and negative\nfeedback distributions and re-scales scalar feedback based on feedback\nstatistics. We show that models trained with \\textit{scalar feedback + STEADY }\noutperform baselines, including binary feedback and raw scalar feedback, in a\nrobot reaching task with non-expert human feedback. Our results show that both\nbinary feedback and scalar feedback are dynamic, and scalar feedback is a\npromising signal for use in interactive Reinforcement Learning.",
            "author": [
                "Hang Yu",
                "Reuben M. Aronson",
                "Katherine H. Allen",
                "Elaine Schaertl Short"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10284v1",
                "http://arxiv.org/pdf/2311.10284v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10281v1",
            "title": "SSASS: Semi-Supervised Approach for Stenosis Segmentation",
            "updated": "2023-11-17T02:01:19Z",
            "published": "2023-11-17T02:01:19Z",
            "summary": "Coronary artery stenosis is a critical health risk, and its precise\nidentification in Coronary Angiography (CAG) can significantly aid medical\npractitioners in accurately evaluating the severity of a patient's condition.\nThe complexity of coronary artery structures combined with the inherent noise\nin X-ray images poses a considerable challenge to this task. To tackle these\nobstacles, we introduce a semi-supervised approach for cardiovascular stenosis\nsegmentation. Our strategy begins with data augmentation, specifically tailored\nto replicate the structural characteristics of coronary arteries. We then apply\na pseudo-label-based semi-supervised learning technique that leverages the data\ngenerated through our augmentation process. Impressively, our approach\ndemonstrated an exceptional performance in the Automatic Region-based Coronary\nArtery Disease diagnostics using x-ray angiography imagEs (ARCADE) Stenosis\nDetection Algorithm challenge by utilizing a single model instead of relying on\nan ensemble of multiple models. This success emphasizes our method's capability\nand efficiency in providing an automated solution for accurately assessing\nstenosis severity from medical imaging data.",
            "author": [
                "In Kyu Lee",
                "Junsup Shin",
                "Yong-Hee Lee",
                "Jonghoe Ku",
                "Hyun-Woo Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10281v1",
                "http://arxiv.org/pdf/2311.10281v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10278v1",
            "title": "Physics-Enhanced Multi-fidelity Learning for Optical Surface Imprint",
            "updated": "2023-11-17T01:55:15Z",
            "published": "2023-11-17T01:55:15Z",
            "summary": "Human fingerprints serve as one unique and powerful characteristic for each\nperson, from which policemen can recognize the identity. Similar to humans,\nmany natural bodies and intrinsic mechanical qualities can also be uniquely\nidentified from surface characteristics. To measure the elasto-plastic\nproperties of one material, one formally sharp indenter is pushed into the\nmeasured body under constant force and retracted, leaving a unique residual\nimprint of the minute size from several micrometers to nanometers. However, one\ngreat challenge is how to map the optical image of this residual imprint into\nthe real wanted mechanical properties, i.e., the tensile force curve. In this\npaper, we propose a novel method to use multi-fidelity neural networks (MFNN)\nto solve this inverse problem. We first actively train the NN model via pure\nsimulation data, and then bridge the sim-to-real gap via transfer learning. The\nmost innovative part is that we use NN to dig out the unknown physics and also\nimplant the known physics into the transfer learning framework, thus highly\nimproving the model stability and decreasing the data requirement. This work\nserves as one great example of applying machine learning into the real\nexperimental research, especially under the constraints of data limitation and\nfidelity variance.",
            "author": [
                "Yongchao Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10278v1",
                "http://arxiv.org/pdf/2311.10278v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10277v1",
            "title": "Sobol Sequence Optimization for Hardware-Efficient Vector Symbolic\n  Architectures",
            "updated": "2023-11-17T01:48:07Z",
            "published": "2023-11-17T01:48:07Z",
            "summary": "Hyperdimensional computing (HDC) is an emerging computing paradigm with\nsignificant promise for efficient and robust learning. In HDC, objects are\nencoded with high-dimensional vector symbolic sequences called hypervectors.\nThe quality of hypervectors, defined by their distribution and independence,\ndirectly impacts the performance of HDC systems. Despite a large body of work\non the processing parts of HDC systems, little to no attention has been paid to\ndata encoding and the quality of hypervectors. Most prior studies have\ngenerated hypervectors using inherent random functions, such as MATLAB`s or\nPython`s random function. This work introduces an optimization technique for\ngenerating hypervectors by employing quasi-random sequences. These sequences\nhave recently demonstrated their effectiveness in achieving accurate and\nlow-discrepancy data encoding in stochastic computing systems. The study\noutlines the optimization steps for utilizing Sobol sequences to produce\nhigh-quality hypervectors in HDC systems. An optimization algorithm is proposed\nto select the most suitable Sobol sequences for generating minimally correlated\nhypervectors, particularly in applications related to symbol-oriented\narchitectures. The performance of the proposed technique is evaluated in\ncomparison to two traditional approaches of generating hypervectors based on\nlinear-feedback shift registers and MATLAB random function. The evaluation is\nconducted for two applications: (i) language and (ii) headline classification.\nOur experimental results demonstrate accuracy improvements of up to 10.79%,\ndepending on the vector size. Additionally, the proposed encoding hardware\nexhibits reduced energy consumption and a superior area-delay product.",
            "author": [
                "Sercan Aygun",
                "M. Hassan Najafi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10277v1",
                "http://arxiv.org/pdf/2311.10277v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10271v1",
            "title": "Prompt Pool based Class-Incremental Continual Learning for Dialog State\n  Tracking",
            "updated": "2023-11-17T01:33:05Z",
            "published": "2023-11-17T01:33:05Z",
            "summary": "Continual learning is crucial for dialog state tracking (DST) in dialog\nsystems, since requirements from users for new functionalities are often\nencountered. However, most of existing continual learning methods for DST\nrequire task identities during testing, which is a severe limit in real-world\napplications. In this paper, we aim to address continual learning of DST in the\nclass-incremental scenario (namely the task identity is unknown in testing).\nInspired by the recently emerging prompt tuning method that performs well on\ndialog systems, we propose to use the prompt pool method, where we maintain a\npool of key-value paired prompts and select prompts from the pool according to\nthe distance between the dialog history and the prompt keys. The proposed\nmethod can automatically identify tasks and select appropriate prompts during\ntesting. We conduct experiments on Schema-Guided Dialog dataset (SGD) and\nanother dataset collected from a real-world dialog application. Experiment\nresults show that the prompt pool method achieves much higher joint goal\naccuracy than the baseline. After combining with a rehearsal buffer, the model\nperformance can be further improved.",
            "author": [
                "Hong Liu",
                "Yucheng Cai",
                "Yuan Zhou",
                "Zhijian Ou",
                "Yi Huang",
                "Junlan Feng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10271v1",
                "http://arxiv.org/pdf/2311.10271v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10270v1",
            "title": "Multiscale Hodge Scattering Networks for Data Analysis",
            "updated": "2023-11-17T01:30:43Z",
            "published": "2023-11-17T01:30:43Z",
            "summary": "We propose new scattering networks for signals measured on simplicial\ncomplexes, which we call \\emph{Multiscale Hodge Scattering Networks} (MHSNs).\nOur construction is based on multiscale basis dictionaries on simplicial\ncomplexes, i.e., the $\\kappa$-GHWT and $\\kappa$-HGLET, which we recently\ndeveloped for simplices of dimension $\\kappa \\in \\N$ in a given simplicial\ncomplex by generalizing the node-based Generalized Haar-Walsh Transform (GHWT)\nand Hierarchical Graph Laplacian Eigen Transform (HGLET). The $\\kappa$-GHWT and\nthe $\\kk$-HGLET both form redundant sets (i.e., dictionaries) of multiscale\nbasis vectors and the corresponding expansion coefficients of a given signal.\nOur MHSNs use a layered structure analogous to a convolutional neural network\n(CNN) to cascade the moments of the modulus of the dictionary coefficients. The\nresulting features are invariant to reordering of the simplices (i.e., node\npermutation of the underlying graphs). Importantly, the use of multiscale basis\ndictionaries in our MHSNs admits a natural pooling operation that is akin to\nlocal pooling in CNNs, and which may be performed either locally or per-scale.\nThese pooling operations are harder to define in both traditional scattering\nnetworks based on Morlet wavelets, and geometric scattering networks based on\nDiffusion Wavelets. As a result, we are able to extract a rich set of\ndescriptive yet robust features that can be used along with very simple machine\nlearning methods (i.e., logistic regression or support vector machines) to\nachieve high-accuracy classification systems with far fewer parameters to train\nthan most modern graph neural networks. Finally, we demonstrate the usefulness\nof our MHSNs in three distinct types of problems: signal classification, domain\n(i.e., graph/simplex) classification, and molecular dynamics prediction.",
            "author": [
                "Naoki Saito",
                "Stefan C. Schonsheck",
                "Eugene Shvarts"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10270v1",
                "http://arxiv.org/pdf/2311.10270v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "cs.SI",
                "eess.SP",
                "math.NA",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10269v1",
            "title": "Interpretable pap smear cell representation for cervical cancer\n  screening",
            "updated": "2023-11-17T01:29:16Z",
            "published": "2023-11-17T01:29:16Z",
            "summary": "Screening is critical for prevention and early detection of cervical cancer\nbut it is time-consuming and laborious. Supervised deep convolutional neural\nnetworks have been developed to automate pap smear screening and the results\nare promising. However, the interest in using only normal samples to train deep\nneural networks has increased owing to class imbalance problems and\nhigh-labeling costs that are both prevalent in healthcare. In this study, we\nintroduce a method to learn explainable deep cervical cell representations for\npap smear cytology images based on one class classification using variational\nautoencoders. Findings demonstrate that a score can be calculated for cell\nabnormality without training models with abnormal samples and localize\nabnormality to interpret our results with a novel metric based on absolute\ndifference in cross entropy in agglomerative clustering. The best model that\ndiscriminates squamous cell carcinoma (SCC) from normals gives 0.908 +- 0.003\narea under operating characteristic curve (AUC) and one that discriminates\nhigh-grade epithelial lesion (HSIL) 0.920 +- 0.002 AUC. Compared to other\nclustering methods, our method enhances the V-measure and yields higher\nhomogeneity scores, which more effectively isolate different abnormality\nregions, aiding in the interpretation of our results. Evaluation using in-house\nand additional open dataset show that our model can discriminate abnormality\nwithout the need of additional training of deep models.",
            "author": [
                "Yu Ando",
                "Nora Jee-Young Park and",
                "Gun Oh Chong",
                "Seokhwan Ko",
                "Donghyeon Lee",
                "Junghwan Cho",
                "Hyungsoo Han"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10269v1",
                "http://arxiv.org/pdf/2311.10269v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10267v1",
            "title": "Energy and Carbon Considerations of Fine-Tuning BERT",
            "updated": "2023-11-17T01:27:01Z",
            "published": "2023-11-17T01:27:01Z",
            "summary": "Despite the popularity of the `pre-train then fine-tune' paradigm in the NLP\ncommunity, existing work quantifying energy costs and associated carbon\nemissions has largely focused on language model pre-training. Although a single\npre-training run draws substantially more energy than fine-tuning, fine-tuning\nis performed more frequently by many more individual actors, and thus must be\naccounted for when considering the energy and carbon footprint of NLP. In order\nto better characterize the role of fine-tuning in the landscape of energy and\ncarbon emissions in NLP, we perform a careful empirical study of the\ncomputational costs of fine-tuning across tasks, datasets, hardware\ninfrastructure and measurement modalities. Our experimental results allow us to\nplace fine-tuning energy and carbon costs into perspective with respect to\npre-training and inference, and outline recommendations to NLP researchers and\npractitioners who wish to improve their fine-tuning energy efficiency.",
            "author": [
                "Xiaorong Wang",
                "Clara Na",
                "Emma Strubell",
                "Sorelle Friedler",
                "Sasha Luccioni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10267v1",
                "http://arxiv.org/pdf/2311.10267v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10266v1",
            "title": "Diagnosing and Debiasing Corpus-Based Political Bias and Insults in GPT2",
            "updated": "2023-11-17T01:20:08Z",
            "published": "2023-11-17T01:20:08Z",
            "summary": "The training of large language models (LLMs) on extensive, unfiltered corpora\nsourced from the internet is a common and advantageous practice. Consequently,\nLLMs have learned and inadvertently reproduced various types of biases,\nincluding violent, offensive, and toxic language. However, recent research\nshows that generative pretrained transformer (GPT) language models can\nrecognize their own biases and detect toxicity in generated content, a process\nreferred to as self-diagnosis. In response, researchers have developed a\ndecoding algorithm that allows LLMs to self-debias, or reduce their likelihood\nof generating harmful text. This study investigates the efficacy of the\ndiagnosing-debiasing approach in mitigating two additional types of biases:\ninsults and political bias. These biases are often used interchangeably in\ndiscourse, despite exhibiting potentially dissimilar semantic and syntactic\nproperties. We aim to contribute to the ongoing effort of investigating the\nethical and social implications of human-AI interaction.",
            "author": [
                "Ambri Ma",
                "Arnav Kumar",
                "Brett Zeligson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10266v1",
                "http://arxiv.org/pdf/2311.10266v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10263v1",
            "title": "Stable Differentiable Causal Discovery",
            "updated": "2023-11-17T01:14:24Z",
            "published": "2023-11-17T01:14:24Z",
            "summary": "Inferring causal relationships as directed acyclic graphs (DAGs) is an\nimportant but challenging problem. Differentiable Causal Discovery (DCD) is a\npromising approach to this problem, framing the search as a continuous\noptimization. But existing DCD methods are numerically unstable, with poor\nperformance beyond tens of variables. In this paper, we propose Stable\nDifferentiable Causal Discovery (SDCD), a new method that improves previous DCD\nmethods in two ways: (1) It employs an alternative constraint for acyclicity;\nthis constraint is more stable, both theoretically and empirically, and fast to\ncompute. (2) It uses a training procedure tailored for sparse causal graphs,\nwhich are common in real-world scenarios. We first derive SDCD and prove its\nstability and correctness. We then evaluate it with both observational and\ninterventional data and on both small-scale and large-scale settings. We find\nthat SDCD outperforms existing methods in both convergence speed and accuracy\nand can scale to thousands of variables.",
            "author": [
                "Achille Nazaret",
                "Justin Hong",
                "Elham Azizi",
                "David Blei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10263v1",
                "http://arxiv.org/pdf/2311.10263v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10261v1",
            "title": "Vision meets mmWave Radar: 3D Object Perception Benchmark for Autonomous\n  Driving",
            "updated": "2023-11-17T01:07:37Z",
            "published": "2023-11-17T01:07:37Z",
            "summary": "Sensor fusion is crucial for an accurate and robust perception system on\nautonomous vehicles. Most existing datasets and perception solutions focus on\nfusing cameras and LiDAR. However, the collaboration between camera and radar\nis significantly under-exploited. The incorporation of rich semantic\ninformation from the camera, and reliable 3D information from the radar can\npotentially achieve an efficient, cheap, and portable solution for 3D object\nperception tasks. It can also be robust to different lighting or all-weather\ndriving scenarios due to the capability of mmWave radars. In this paper, we\nintroduce the CRUW3D dataset, including 66K synchronized and well-calibrated\ncamera, radar, and LiDAR frames in various driving scenarios. Unlike other\nlarge-scale autonomous driving datasets, our radar data is in the format of\nradio frequency (RF) tensors that contain not only 3D location information but\nalso spatio-temporal semantic information. This kind of radar format can enable\nmachine learning models to generate more reliable object perception results\nafter interacting and fusing the information or features between the camera and\nradar.",
            "author": [
                "Yizhou Wang",
                "Jen-Hao Cheng",
                "Jui-Te Huang",
                "Sheng-Yao Kuan",
                "Qiqian Fu",
                "Chiming Ni",
                "Shengyu Hao",
                "Gaoang Wang",
                "Guanbin Xing",
                "Hui Liu",
                "Jenq-Neng Hwang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10261v1",
                "http://arxiv.org/pdf/2311.10261v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10256v2",
            "title": "Exploring User Perceptions of Virtual Reality Scene Design in Metaverse\n  Learning Environments",
            "updated": "2023-11-21T23:52:32Z",
            "published": "2023-11-17T00:56:55Z",
            "summary": "Metaverse learning environments allow for a seamless and intuitive transition\nbetween activities compared to Virtual Reality (VR) learning environments, due\nto their interconnected design. The design of VR scenes is important for\ncreating effective learning experiences in the Metaverse. However, there is\nlimited research on the impact of different design elements on user's learning\nexperiences in VR scenes. To address this, a study was conducted with 16\nparticipants who interacted with two VR scenes, each with varying design\nelements such as style, color, texture, object, and background, while watching\na short tutorial. Participant rankings of the scenes for learning were obtained\nusing a seven-point Likert scale, and the Mann-Whitney U test was used to\nvalidate differences in preference between the scenes. The results showed a\nsignificant difference in preference between the scenes. Further analysis using\nthe NASA TLX questionnaire was conducted to examine the impact of this\ndifference on cognitive load, and participant feedback was also considered. The\nstudy emphasizes the importance of careful VR scene design to improve the\nuser's learning experience.",
            "author": [
                "Rahatara Ferdousi",
                "Mohammed Faisal",
                "Fedwa Laamarti",
                "Chunsheng Yang",
                "Abdulmotaleb El Saddik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10256v2",
                "http://arxiv.org/pdf/2311.10256v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.MM",
                "K.3; J.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10255v1",
            "title": "FREE: The Foundational Semantic Recognition for Modeling Environmental\n  Ecosystems",
            "updated": "2023-11-17T00:53:09Z",
            "published": "2023-11-17T00:53:09Z",
            "summary": "Modeling environmental ecosystems is critical for the sustainability of our\nplanet, but is extremely challenging due to the complex underlying processes\ndriven by interactions amongst a large number of physical variables. As many\nvariables are difficult to measure at large scales, existing works often\nutilize a combination of observable features and locally available measurements\nor modeled values as input to build models for a specific study region and time\nperiod. This raises a fundamental question in advancing the modeling of\nenvironmental ecosystems: how to build a general framework for modeling the\ncomplex relationships amongst various environmental data over space and time?\nIn this paper, we introduce a new framework, FREE, which maps available\nenvironmental data into a text space and then converts the traditional\npredictive modeling task in environmental science to the semantic recognition\nproblem. The proposed FREE framework leverages recent advances in Large\nLanguage Models (LLMs) to supplement the original input features with natural\nlanguage descriptions. This facilitates capturing the data semantics and also\nallows harnessing the irregularities of input features. When used for long-term\nprediction, FREE has the flexibility to incorporate newly collected\nobservations to enhance future prediction. The efficacy of FREE is evaluated in\nthe context of two societally important real-world applications, predicting\nstream water temperature in the Delaware River Basin and predicting annual corn\nyield in Illinois and Iowa. Beyond the superior predictive performance over\nmultiple baseline methods, FREE is shown to be more data- and\ncomputation-efficient as it can be pre-trained on simulated data generated by\nphysics-based models.",
            "author": [
                "Shiyuan Luo",
                "Juntong Ni",
                "Shengyu Chen",
                "Runlong Yu",
                "Yiqun Xie",
                "Licheng Liu",
                "Zhenong Jin",
                "Huaxiu Yao",
                "Xiaowei Jia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10255v1",
                "http://arxiv.org/pdf/2311.10255v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10790v1",
            "title": "Degeneration of kernel regression with Matern kernels into low-order\n  polynomial regression in high dimension",
            "updated": "2023-11-17T00:46:54Z",
            "published": "2023-11-17T00:46:54Z",
            "summary": "Kernel methods such as kernel ridge regression and Gaussian process\nregressions with Matern type kernels have been increasingly used, in\nparticular, to fit potential energy surfaces (PES) and density functionals, and\nfor materials informatics. When the dimensionality of the feature space is\nhigh, these methods are used with necessarily sparse data. In this regime, the\noptimal length parameter of a Matern-type kernel tends to become so large that\nthe method effectively degenerates into a low-order polynomial regression and\ntherefore loses any advantage over such regression. This is demonstrated\ntheoretically as well as numerically on the examples of six- and\nfifteen-dimensional molecular PES using squared exponential and simple\nexponential kernels. The results shed additional light on the success of\npolynomial approximations such as PIP for medium size molecules and on the\nimportance of orders-of-coupling based models for preserving the advantages of\nkernel methods with Matern type kernels or on the use of physically-motivated\n(reproducing) kernels.",
            "author": [
                "Sergei Manzhos",
                "Manabu Ihara"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10790v1",
                "http://arxiv.org/pdf/2311.10790v1"
            ],
            "primary_category": "physics.comp-ph",
            "category": [
                "physics.comp-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10251v2",
            "title": "UniMOS: A Universal Framework For Multi-Organ Segmentation Over\n  Label-Constrained Datasets",
            "updated": "2023-11-20T01:59:11Z",
            "published": "2023-11-17T00:44:56Z",
            "summary": "Machine learning models for medical images can help physicians diagnose and\nmanage diseases. However, due to the fact that medical image annotation\nrequires a great deal of manpower and expertise, as well as the fact that\nclinical departments perform image annotation based on task orientation, there\nis the problem of having fewer medical image annotation data with more\nunlabeled data and having many datasets that annotate only a single organ. In\nthis paper, we present UniMOS, the first universal framework for achieving the\nutilization of fully and partially labeled images as well as unlabeled images.\nSpecifically, we construct a Multi-Organ Segmentation (MOS) module over\nfully/partially labeled data as the basenet and designed a new target adaptive\nloss. Furthermore, we incorporate a semi-supervised training module that\ncombines consistent regularization and pseudolabeling techniques on unlabeled\ndata, which significantly improves the segmentation of unlabeled data.\nExperiments show that the framework exhibits excellent performance in several\nmedical image segmentation tasks compared to other advanced methods, and also\nsignificantly improves data utilization and reduces annotation cost. Code and\nmodels are available at: https://github.com/lw8807001/UniMOS.",
            "author": [
                "Can Li",
                "Sheng Shao",
                "Junyi Qu",
                "Shuchao Pang",
                "Mehmet A. Orgun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10251v2",
                "http://arxiv.org/pdf/2311.10251v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10248v1",
            "title": "FedTruth: Byzantine-Robust and Backdoor-Resilient Federated Learning\n  Framework",
            "updated": "2023-11-17T00:39:59Z",
            "published": "2023-11-17T00:39:59Z",
            "summary": "Federated Learning (FL) enables collaborative machine learning model training\nacross multiple parties without sharing raw data. However, FL's distributed\nnature allows malicious clients to impact model training through Byzantine or\nbackdoor attacks, using erroneous model updates. Existing defenses measure the\ndeviation of each update from a 'ground-truth model update.' They often rely on\na benign root dataset on the server or use trimmed mean or median for clipping,\nboth methods having limitations.\n  We introduce FedTruth, a robust defense against model poisoning in FL.\nFedTruth doesn't assume specific data distributions nor requires a benign root\ndataset. It estimates a global model update with dynamic aggregation weights,\nconsidering contributions from all benign clients. Empirical studies\ndemonstrate FedTruth's efficacy in mitigating the impacts of poisoned updates\nfrom both Byzantine and backdoor attacks.",
            "author": [
                "Sheldon C. Ebron Jr.",
                "Kan Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10248v1",
                "http://arxiv.org/pdf/2311.10248v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10246v1",
            "title": "Surprisal Driven $k$-NN for Robust and Interpretable Nonparametric\n  Learning",
            "updated": "2023-11-17T00:35:38Z",
            "published": "2023-11-17T00:35:38Z",
            "summary": "Nonparametric learning is a fundamental concept in machine learning that aims\nto capture complex patterns and relationships in data without making strong\nassumptions about the underlying data distribution. Owing to simplicity and\nfamiliarity, one of the most well-known algorithms under this paradigm is the\n$k$-nearest neighbors ($k$-NN) algorithm. Driven by the usage of machine\nlearning in safety-critical applications, in this work, we shed new light on\nthe traditional nearest neighbors algorithm from the perspective of information\ntheory and propose a robust and interpretable framework for tasks such as\nclassification, regression, and anomaly detection using a single model. Instead\nof using a traditional distance measure which needs to be scaled and\ncontextualized, we use a novel formulation of \\textit{surprisal} (amount of\ninformation required to explain the difference between the observed and\nexpected result). Finally, we demonstrate this architecture's capability to\nperform at-par or above the state-of-the-art on classification, regression, and\nanomaly detection tasks using a single model with enhanced interpretability by\nproviding novel concepts for characterizing data and predictions.",
            "author": [
                "Amartya Banerjee",
                "Christopher J. Hazard",
                "Jacob Beel",
                "Cade Mack",
                "Jack Xia",
                "Michael Resnick",
                "Will Goddin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10246v1",
                "http://arxiv.org/pdf/2311.10246v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10789v1",
            "title": "Stratified-NMF for Heterogeneous Data",
            "updated": "2023-11-17T00:34:41Z",
            "published": "2023-11-17T00:34:41Z",
            "summary": "Non-negative matrix factorization (NMF) is an important technique for\nobtaining low dimensional representations of datasets. However, classical NMF\ndoes not take into account data that is collected at different times or in\ndifferent locations, which may exhibit heterogeneity. We resolve this problem\nby solving a modified NMF objective, Stratified-NMF, that simultaneously learns\nstrata-dependent statistics and a shared topics matrix. We develop\nmultiplicative update rules for this novel objective and prove convergence of\nthe objective. Then, we experiment on synthetic data to demonstrate the\nefficiency and accuracy of the method. Lastly, we apply our method to three\nreal world datasets and empirically investigate their learned features.",
            "author": [
                "James Chapman",
                "Yotam Yaniv",
                "Deanna Needell"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10789v1",
                "http://arxiv.org/pdf/2311.10789v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NA",
                "math.NA",
                "G.1.6; I.5.3; I.5.4"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10788v1",
            "title": "Efficient Temporally-Aware DeepFake Detection using H.264 Motion Vectors",
            "updated": "2023-11-17T00:21:02Z",
            "published": "2023-11-17T00:21:02Z",
            "summary": "Video DeepFakes are fake media created with Deep Learning (DL) that\nmanipulate a person's expression or identity. Most current DeepFake detection\nmethods analyze each frame independently, ignoring inconsistencies and\nunnatural movements between frames. Some newer methods employ optical flow\nmodels to capture this temporal aspect, but they are computationally expensive.\nIn contrast, we propose using the related but often ignored Motion Vectors\n(MVs) and Information Masks (IMs) from the H.264 video codec, to detect\ntemporal inconsistencies in DeepFakes. Our experiments show that this approach\nis effective and has minimal computational costs, compared with per-frame\nRGB-only methods. This could lead to new, real-time temporally-aware DeepFake\ndetection methods for video calls and streaming.",
            "author": [
                "Peter Gr\u00f6nquist",
                "Yufan Ren",
                "Qingyi He",
                "Alessio Verardo",
                "Sabine S\u00fcsstrunk"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10788v1",
                "http://arxiv.org/pdf/2311.10788v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "I.5.4; I.4.8; I.2.10; I.4.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10242v2",
            "title": "Advancements in Generative AI: A Comprehensive Review of GANs, GPT,\n  Autoencoders, Diffusion Model, and Transformers",
            "updated": "2023-11-21T23:01:29Z",
            "published": "2023-11-17T00:08:19Z",
            "summary": "The launch of ChatGPT has garnered global attention, marking a significant\nmilestone in the field of Generative Artificial Intelligence. While Generative\nAI has been in effect for the past decade, the introduction of ChatGPT has\nignited a new wave of research and innovation in the AI domain. This surge in\ninterest has led to the development and release of numerous cutting-edge tools,\nsuch as Bard, Stable Diffusion, DALL-E, Make-A-Video, Runway ML, and Jukebox,\namong others. These tools exhibit remarkable capabilities, encompassing tasks\nranging from text generation and music composition, image creation, video\nproduction, code generation, and even scientific work. They are built upon\nvarious state-of-the-art models, including Stable Diffusion, transformer models\nlike GPT-3 (recent GPT-4), variational autoencoders, and generative adversarial\nnetworks. This advancement in Generative AI presents a wealth of exciting\nopportunities and, simultaneously, unprecedented challenges. Throughout this\npaper, we have explored these state-of-the-art models, the diverse array of\ntasks they can accomplish, the challenges they pose, and the promising future\nof Generative Artificial Intelligence.",
            "author": [
                "Staphord Bengesi",
                "Hoda El-Sayed",
                "Md Kamruzzaman Sarker",
                "Yao Houkpati",
                "John Irungu",
                "Timothy Oladunni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10242v2",
                "http://arxiv.org/pdf/2311.10242v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10237v1",
            "title": "PINE: Efficient Norm-Bound Verification for Secret-Shared Vectors",
            "updated": "2023-11-16T23:54:21Z",
            "published": "2023-11-16T23:54:21Z",
            "summary": "Secure aggregation of high-dimensional vectors is a fundamental primitive in\nfederated statistics and learning. A two-server system such as PRIO allows for\nscalable aggregation of secret-shared vectors. Adversarial clients might try to\nmanipulate the aggregate, so it is important to ensure that each\n(secret-shared) contribution is well-formed. In this work, we focus on the\nimportant and well-studied goal of ensuring that each contribution vector has\nbounded Euclidean norm. Existing protocols for ensuring bounded-norm\ncontributions either incur a large communication overhead, or only allow for\napproximate verification of the norm bound. We propose Private Inexpensive Norm\nEnforcement (PINE): a new protocol that allows exact norm verification with\nlittle communication overhead. For high-dimensional vectors, our approach has a\ncommunication overhead of a few percent, compared to the 16-32x overhead of\nprevious approaches.",
            "author": [
                "Guy N. Rothblum",
                "Eran Omri",
                "Junye Chen",
                "Kunal Talwar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10237v1",
                "http://arxiv.org/pdf/2311.10237v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10235v1",
            "title": "Data-Driven LQR using Reinforcement Learning and Quadratic Neural\n  Networks",
            "updated": "2023-11-16T23:49:43Z",
            "published": "2023-11-16T23:49:43Z",
            "summary": "This paper introduces a novel data-driven approach to design a linear\nquadratic regulator (LQR) using a reinforcement learning (RL) algorithm that\ndoes not require a system model. The key contribution is to perform policy\niteration (PI) by designing the policy evaluator as a two-layer quadratic\nneural network (QNN). This network is trained through convex optimization. To\nthe best of our knowledge, this is the first time that a QNN trained through\nconvex optimization is employed as the Q-function approximator (QFA). The main\nadvantage is that the QNN's input-output mapping has an analytical expression\nas a quadratic form, which can then be used to obtain an analytical expression\nfor policy improvement. This is in stark contrast to the available techniques\nin the literature that must train a second neural network to obtain policy\nimprovement. The article establishes the convergence of the learning algorithm\nto the optimal control, provided the system is controllable and one starts from\na stabilitzing policy. A quadrotor example demonstrates the effectiveness of\nthe proposed approach.",
            "author": [
                "Soroush Asri",
                "Luis Rodrigues"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10235v1",
                "http://arxiv.org/pdf/2311.10235v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10234v1",
            "title": "The Analysis and Extraction of Structure from Organizational Charts",
            "updated": "2023-11-16T23:49:05Z",
            "published": "2023-11-16T23:49:05Z",
            "summary": "Organizational charts, also known as org charts, are critical representations\nof an organization's structure and the hierarchical relationships between its\ncomponents and positions. However, manually extracting information from org\ncharts can be error-prone and time-consuming. To solve this, we present an\nautomated and end-to-end approach that uses computer vision, deep learning, and\nnatural language processing techniques. Additionally, we propose a metric to\nevaluate the completeness and hierarchical accuracy of the extracted\ninformation. This approach has the potential to improve organizational\nrestructuring and resource utilization by providing a clear and concise\nrepresentation of the organizational structure. Our study lays a foundation for\nfurther research on the topic of hierarchical chart analysis.",
            "author": [
                "Nikhil Manali",
                "David Doermann",
                "Mahesh Desai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10234v1",
                "http://arxiv.org/pdf/2311.10234v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10224v1",
            "title": "CV-Attention UNet: Attention-based UNet for 3D Cerebrovascular\n  Segmentation of Enhanced TOF-MRA Images",
            "updated": "2023-11-16T22:31:05Z",
            "published": "2023-11-16T22:31:05Z",
            "summary": "Due to the lack of automated methods, to diagnose cerebrovascular disease,\ntime-of-flight magnetic resonance angiography (TOF-MRA) is assessed visually,\nmaking it time-consuming. The commonly used encoder-decoder architectures for\ncerebrovascular segmentation utilize redundant features, eventually leading to\nthe extraction of low-level features multiple times. Additionally,\nconvolutional neural networks (CNNs) suffer from performance degradation when\nthe batch size is small, and deeper networks experience the vanishing gradient\nproblem. Methods: In this paper, we attempt to solve these limitations and\npropose the 3D cerebrovascular attention UNet method, named CV-AttentionUNet,\nfor precise extraction of brain vessel images. We proposed a sequence of\npreprocessing techniques followed by deeply supervised UNet to improve the\naccuracy of segmentation of the brain vessels leading to a stroke. To combine\nthe low and high semantics, we applied the attention mechanism. This mechanism\nfocuses on relevant associations and neglects irrelevant anatomical\ninformation. Furthermore, the inclusion of deep supervision incorporates\ndifferent levels of features that prove to be beneficial for network\nconvergence. Results: We demonstrate the efficiency of the proposed method by\ncross-validating with an unlabeled dataset, which was further labeled by us. We\nbelieve that the novelty of this algorithm lies in its ability to perform well\non both labeled and unlabeled data with image processing-based enhancement. The\nresults indicate that our method performed better than the existing\nstate-of-the-art methods on the TubeTK dataset. Conclusion: The proposed method\nwill help in accurate segmentation of cerebrovascular structure leading to\nstroke",
            "author": [
                "Syed Farhan Abbas",
                "Nguyen Thanh Duc",
                "Yoonguu Song",
                "Kyungwon Kim",
                "Boreom Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10224v1",
                "http://arxiv.org/pdf/2311.10224v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10223v1",
            "title": "Asymptotically Fair Participation in Machine Learning Models: an Optimal\n  Control Perspective",
            "updated": "2023-11-16T22:28:38Z",
            "published": "2023-11-16T22:28:38Z",
            "summary": "The performance of state-of-the-art machine learning models often\ndeteriorates when testing on demographics that are under-represented in the\ntraining dataset. This problem has predominately been studied in a supervised\nlearning setting where the data distribution is static. However, real-world\napplications often involve distribution shifts caused by the deployed models.\nFor instance, the performance disparity against monitory users can lead to a\nhigh customer churn rate, thus the available data provided by active users are\nskewed due to the lack of minority users. This feedback effect further\nexacerbates the disparity among different demographic groups in future steps.\nTo address this issue, we propose asymptotically fair participation as a\ncondition to maintain long-term model performance over all demographic groups.\nIn this work, we aim to address the problem of achieving asymptotically fair\nparticipation via optimal control formulation. Moreover, we design a surrogate\nretention system based on existing literature on evolutionary population\ndynamics to approximate the dynamics of distribution shifts on active user\ncounts, from which the objective of achieving asymptotically fair participation\nis formulated as an optimal control problem, and the control variables are\nconsidered as the model parameters. We apply an efficient implementation of\nPontryagin's maximum principle to estimate the optimal control solution. To\nevaluate the effectiveness of the proposed method, we design a generic\nsimulation environment that simulates the population dynamics of the feedback\neffect between user retention and model performance. When we deploy the\nresulting models to the simulation environment, the optimal control solution\naccounts for long-term planning and leads to superior performance compared with\nexisting baseline methods.",
            "author": [
                "Zhuotong Chen",
                "Qianxiao Li",
                "Zheng Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10223v1",
                "http://arxiv.org/pdf/2311.10223v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10787v1",
            "title": "Assurance for Deployed Continual Learning Systems",
            "updated": "2023-11-16T22:22:13Z",
            "published": "2023-11-16T22:22:13Z",
            "summary": "The future success of the Navy will depend, in part, on artificial\nintelligence. In practice, many artificially intelligent algorithms, and in\nparticular deep learning models, rely on continual learning to maintain\nperformance in dynamic environments. The software requires adaptation to\nmaintain its initial level of performance in unseen situations. However, if not\nmonitored properly, continual learning may lead to several issues including\ncatastrophic forgetting in which a trained model forgets previously learned\ntasks when being retrained on new data. The authors created a new framework for\nsafely performing continual learning with the goal of pairing this safety\nframework with a deep learning computer vision algorithm to allow for safe and\nhigh-performing automatic deck tracking on carriers and amphibious assault\nships. The safety framework includes several features, such as an ensemble of\nconvolutional neural networks to perform image classification, a manager to\nrecord confidences and determine the best answer from the ensemble, a model of\nthe environment to predict when the system may fail to meet minimum performance\nmetrics, a performance monitor to log system and domain performance and check\nagainst requirements, and a retraining component to update the ensemble and\nmanager to maintain performance. The authors validated the proposed method\nusing extensive simulation studies based on dynamic image classification. The\nauthors showed the safety framework could probabilistically detect out of\ndistribution data. The results also show the framework can detect when the\nsystem is no longer performing safely and can significantly extend the working\nenvelope of an image classifier.",
            "author": [
                "Ari Goodman",
                "Ryan O'Shea",
                "Noam Hirschorn",
                "Hubert Chrostowski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10787v1",
                "http://arxiv.org/pdf/2311.10787v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10207v1",
            "title": "Stella Nera: Achieving 161 TOp/s/W with Multiplier-free DNN Acceleration\n  based on Approximate Matrix Multiplication",
            "updated": "2023-11-16T21:43:05Z",
            "published": "2023-11-16T21:43:05Z",
            "summary": "From classical HPC to deep learning, MatMul is at the heart of today's\ncomputing. The recent Maddness method approximates MatMul without the need for\nmultiplication by using a hash-based version of product quantization (PQ)\nindexing into a look-up table (LUT). Stella Nera is the first Maddness\naccelerator and it achieves 15x higher area efficiency (GMAC/s/mm^2) and more\nthan 25x higher energy efficiency (TMAC/s/W) than direct MatMul accelerators\nimplemented in the same technology. The hash function is a decision tree, which\nallows for an efficient hardware implementation as the multiply-accumulate\noperations are replaced by decision tree passes and LUT lookups. The entire\nMaddness MatMul can be broken down into parts that allow an effective\nimplementation with small computing units and memories, allowing it to reach\nextreme efficiency while remaining generically applicable for MatMul tasks. In\na commercial 14nm technology and scaled to 3nm, we achieve an energy efficiency\nof 161 TOp/s/W@0.55V with a Top-1 accuracy on CIFAR-10 of more than 92.5% using\nResNet9.",
            "author": [
                "Jannis Sch\u00f6nleber",
                "Lukas Cavigelli",
                "Renzo Andri",
                "Matteo Perotti",
                "Luca Benini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10207v1",
                "http://arxiv.org/pdf/2311.10207v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.CV",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10206v1",
            "title": "Bayes in the age of intelligent machines",
            "updated": "2023-11-16T21:39:54Z",
            "published": "2023-11-16T21:39:54Z",
            "summary": "The success of methods based on artificial neural networks in creating\nintelligent machines seems like it might pose a challenge to explanations of\nhuman cognition in terms of Bayesian inference. We argue that this is not the\ncase, and that in fact these systems offer new opportunities for Bayesian\nmodeling. Specifically, we argue that Bayesian models of cognition and\nartificial neural networks lie at different levels of analysis and are\ncomplementary modeling approaches, together offering a way to understand human\ncognition that spans these levels. We also argue that the same perspective can\nbe applied to intelligent machines, where a Bayesian approach may be uniquely\nvaluable in understanding the behavior of large, opaque artificial neural\nnetworks that are trained on proprietary data.",
            "author": [
                "Thomas L. Griffiths",
                "Jian-Qiao Zhu",
                "Erin Grant",
                "R. Thomas McCoy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10206v1",
                "http://arxiv.org/pdf/2311.10206v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10205v1",
            "title": "A case study of multi-modal, multi-institutional data management for the\n  combinatorial materials science community",
            "updated": "2023-11-16T21:36:48Z",
            "published": "2023-11-16T21:36:48Z",
            "summary": "Although the convergence of high-performance computing, automation, and\nmachine learning has significantly altered the materials design timeline,\ntransformative advances in functional materials and acceleration of their\ndesign will require addressing the deficiencies that currently exist in\nmaterials informatics, particularly a lack of standardized experimental data\nmanagement. The challenges associated with experimental data management are\nespecially true for combinatorial materials science, where advancements in\nautomation of experimental workflows have produced datasets that are often too\nlarge and too complex for human reasoning. The data management challenge is\nfurther compounded by the multi-modal and multi-institutional nature of these\ndatasets, as they tend to be distributed across multiple institutions and can\nvary substantially in format, size, and content. To adequately map a materials\ndesign space from such datasets, an ideal materials data infrastructure would\ncontain data and metadata describing i) synthesis and processing conditions,\nii) characterization results, and iii) property and performance measurements.\nHere, we present a case study for the development of such a dashboard that\nenables standardized organization, analysis, and visualization of a large data\nlake consisting of combinatorial datasets of synthesis and processing\nconditions, X-ray diffraction patterns, and materials property measurements.\nWhile this dashboard was developed specifically for data-driven thermoelectric\nmaterials discovery, we envision the adaptation of this prototype to other\nmaterials applications, and, more ambitiously, future integration into an\nall-encompassing materials data management infrastructure.",
            "author": [
                "Sarah I. Allec",
                "Eric S. Muckley",
                "Nathan S. Johnson",
                "Andrew S. Lee",
                "James E. Saal",
                "Logan Ward",
                "Apurva Mehta"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10205v1",
                "http://arxiv.org/pdf/2311.10205v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10203v1",
            "title": "Adaptive Optimization Algorithms for Machine Learning",
            "updated": "2023-11-16T21:22:47Z",
            "published": "2023-11-16T21:22:47Z",
            "summary": "Machine learning assumes a pivotal role in our data-driven world. The\nincreasing scale of models and datasets necessitates quick and reliable\nalgorithms for model training. This dissertation investigates adaptivity in\nmachine learning optimizers. The ensuing chapters are dedicated to various\nfacets of adaptivity, including: 1. personalization and user-specific models\nvia personalized loss, 2. provable post-training model adaptations via\nmeta-learning, 3. learning unknown hyperparameters in real time via\nhyperparameter variance reduction, 4. fast O(1/k^2) global convergence of\nsecond-order methods via stepsized Newton method regardless of the\ninitialization and choice basis, 5. fast and scalable second-order methods via\nlow-dimensional updates. This thesis contributes novel insights, introduces new\nalgorithms with improved convergence guarantees, and improves analyses of\npopular practical algorithms.",
            "author": [
                "Slavom\u00edr Hanzely"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10203v1",
                "http://arxiv.org/pdf/2311.10203v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10201v1",
            "title": "Fused Breadth-First Probabilistic Traversals on Distributed GPU Systems",
            "updated": "2023-11-16T21:17:42Z",
            "published": "2023-11-16T21:17:42Z",
            "summary": "Probabilistic breadth-first traversals (BPTs) are used in many network\nscience and graph machine learning applications. In this paper, we are\nmotivated by the application of BPTs in stochastic diffusion-based graph\nproblems such as influence maximization. These applications heavily rely on\nBPTs to implement a Monte-Carlo sampling step for their approximations. Given\nthe large sampling complexity, stochasticity of the diffusion process, and the\ninherent irregularity in real-world graph topologies, efficiently parallelizing\nthese BPTs remains significantly challenging.\n  In this paper, we present a new algorithm to fuse massive number of\nconcurrently executing BPTs with random starts on the input graph. Our\nalgorithm is designed to fuse BPTs by combining separate traversals into a\nunified frontier on distributed multi-GPU systems. To show the general\napplicability of the fused BPT technique, we have incorporated it into two\nstate-of-the-art influence maximization parallel implementations (gIM and\nRipples). Our experiments on up to 4K nodes of the OLCF Frontier supercomputer\n($32,768$ GPUs and $196$K CPU cores) show strong scaling behavior, and that\nfused BPTs can improve the performance of these implementations up to\n34$\\times$ (for gIM) and ~360$\\times$ (for Ripples).",
            "author": [
                "Reece Neff",
                "Mostafa Eghbali Zarch",
                "Marco Minutoli",
                "Mahantesh Halappanavar",
                "Antonino Tumeo",
                "Ananth Kalyanaraman",
                "Michela Becchi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10201v1",
                "http://arxiv.org/pdf/2311.10201v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10199v1",
            "title": "Generative AI in Undergraduate Information Technology Education --\n  Insights from nine courses",
            "updated": "2023-11-16T21:12:22Z",
            "published": "2023-11-16T21:12:22Z",
            "summary": "The increasing use of digital teaching and emerging technologies,\nparticularly AI-based tools, such as ChatGPT, is presenting an inevitable and\nsignificant impact on higher education. The capability of processing and\ngenerating text could bring change to several areas, such as learning\nassessments or learning experiences. Besides the negative impact, i.e exam\ncheating, we also see a positive side that ChatGPT can bring to education. This\nresearch article aims to contribute to the current debate on ChatGPT by\nsystematic reflection and experience reported from nine bachelor IT courses at\na Norwegian university. We conducted inductive empirical research with\nreflective notes and focused groups of lecturers from nine different IT\ncourses. The findings were thematically organized with numerous use cases in\nteaching IT subjects. Our discussion highlights the disruptive implications of\nAI assistant usage in higher education and emphasizes the need for educators to\nshape this transformation.",
            "author": [
                "Anh Nguyen Duc",
                "Tor L\u00f8nnestad",
                "Ingrid Sundb\u00f8",
                "Marius Rohde Johannessen",
                "Veralia Gabriela",
                "Salah Uddin Ahmed",
                "Rania El-Gazzar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10199v1",
                "http://arxiv.org/pdf/2311.10199v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10197v1",
            "title": "You Cannot Escape Me: Detecting Evasions of SIEM Rules in Enterprise\n  Networks",
            "updated": "2023-11-16T21:05:12Z",
            "published": "2023-11-16T21:05:12Z",
            "summary": "Cyberattacks have grown into a major risk for organizations, with common\nconsequences being data theft, sabotage, and extortion. Since preventive\nmeasures do not suffice to repel attacks, timely detection of successful\nintruders is crucial to stop them from reaching their final goals. For this\npurpose, many organizations utilize Security Information and Event Management\n(SIEM) systems to centrally collect security-related events and scan them for\nattack indicators using expert-written detection rules. However, as we show by\nanalyzing a set of widespread SIEM detection rules, adversaries can evade\nalmost half of them easily, allowing them to perform common malicious actions\nwithin an enterprise network without being detected. To remedy these critical\ndetection blind spots, we propose the idea of adaptive misuse detection, which\nutilizes machine learning to compare incoming events to SIEM rules on the one\nhand and known-benign events on the other hand to discover successful evasions.\nBased on this idea, we present AMIDES, an open-source proof-of-concept adaptive\nmisuse detection system. Using four weeks of SIEM events from a large\nenterprise network and more than 500 hand-crafted evasions, we show that AMIDES\nsuccessfully detects a majority of these evasions without any false alerts. In\naddition, AMIDES eases alert analysis by assessing which rules were evaded. Its\ncomputational efficiency qualifies AMIDES for real-world operation and hence\nenables organizations to significantly reduce detection blind spots with\nmoderate effort.",
            "author": [
                "Rafael Uetz",
                "Marco Herzog",
                "Louis Hackl\u00e4nder",
                "Simon Schwarz",
                "Martin Henze"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10197v1",
                "http://arxiv.org/pdf/2311.10197v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10193v1",
            "title": "Investigating the Use of Traveltime and Reflection Tomography for Deep\n  Learning-Based Sound-Speed Estimation in Ultrasound Computed Tomography",
            "updated": "2023-11-16T20:55:00Z",
            "published": "2023-11-16T20:55:00Z",
            "summary": "Ultrasound computed tomography (USCT) is actively being developed to quantify\nacoustic tissue properties such as the speed-of-sound (SOS). Although\nfull-waveform inversion (FWI) is an effective method for accurate SOS\nreconstruction, it can be computationally challenging for large-scale problems.\nDeep learning-based image-to-image learned reconstruction (IILR) methods are\nbeing investigated as scalable and computationally efficient alternatives. This\nstudy investigates the impact of the chosen input modalities on IILR methods\nfor high-resolution SOS reconstruction in USCT. The selected modalities are\ntraveltime tomography (TT) and reflection tomography (RT), which produce a\nlow-resolution SOS map and a reflectivity map, respectively. These modalities\nhave been chosen for their lower computational cost relative to FWI and their\ncapacity to provide complementary information: TT offers a direct -- while low\nresolution -- SOS measure, while RT reveals tissue boundary information.\nSystematic analyses were facilitated by employing a stylized USCT imaging\nsystem with anatomically realistic numerical breast phantoms. Within this\ntestbed, a supervised convolutional neural network (CNN) was trained to map\ndual-channel (TT and RT images) to a high-resolution SOS map. Moreover, the CNN\nwas fine-tuned using a weighted reconstruction loss that prioritized tumor\nregions to address tumor underrepresentation in the training dataset. To\nunderstand the benefits of employing dual-channel inputs, single-input CNNs\nwere trained separately using inputs from each modality alone (TT or RT). The\nmethods were assessed quantitatively using normalized root mean squared error\nand structural similarity index measure for reconstruction accuracy and\nreceiver operating characteristic analysis to assess signal detection-based\nperformance measures.",
            "author": [
                "Gangwon Jeong",
                "Fu Li",
                "Umberto Villa",
                "Mark A. Anastasio"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10193v1",
                "http://arxiv.org/pdf/2311.10193v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10188v1",
            "title": "Gate modulation of the hole singlet-triplet qubit frequency in germanium",
            "updated": "2023-11-16T20:33:52Z",
            "published": "2023-11-16T20:33:52Z",
            "summary": "Spin qubits in germanium gate-defined quantum dots have made considerable\nprogress within the last few years, partially due to their strong spin-orbit\ncoupling and site-dependent $g$-tensors. While this characteristic of the\n$g$-factors removes the need for micromagnets and allows for the possibility of\nall-electric qubit control, relying on these $g$-tensors necessitates the need\nto understand their sensitivity to the confinement potential that defines the\nquantum dots. Here, we demonstrate a $S-T\\_$ qubit whose frequency is a strong\nfunction of the voltage applied to the barrier gate shared by the quantum dots.\nWe find a $g$-factor that can be approximately increased by an order of\nmagnitude adjusting the barrier gate voltage only by 12 mV. We attribute the\nstrong dependence to a variable strain profile in our device. This work not\nonly reinforces previous findings that site-dependent $g$-tensors in germanium\ncan be utilized for qubit manipulation, but reveals the sensitivity and\ntunability these $g$-tensors have to the electrostatic confinement of the\nquantum dot.",
            "author": [
                "John Rooney",
                "Zhentao Luo",
                "Lucas E. A. Stehouwer",
                "Giordano Scappucci",
                "Menno Veldhorst",
                "Hong-Wen Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10188v1",
                "http://arxiv.org/pdf/2311.10188v1"
            ],
            "primary_category": "cond-mat.mes-hall",
            "category": [
                "cond-mat.mes-hall"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10177v1",
            "title": "Towards Improving Robustness Against Common Corruptions using Mixture of\n  Class Specific Experts",
            "updated": "2023-11-16T20:09:47Z",
            "published": "2023-11-16T20:09:47Z",
            "summary": "Neural networks have demonstrated significant accuracy across various\ndomains, yet their vulnerability to subtle input alterations remains a\npersistent challenge. Conventional methods like data augmentation, while\neffective to some extent, fall short in addressing unforeseen corruptions,\nlimiting the adaptability of neural networks in real-world scenarios. In\nresponse, this paper introduces a novel paradigm known as the Mixture of\nClass-Specific Expert Architecture. The approach involves disentangling feature\nlearning for individual classes, offering a nuanced enhancement in scalability\nand overall performance. By training dedicated network segments for each class\nand subsequently aggregating their outputs, the proposed architecture aims to\nmitigate vulnerabilities associated with common neural network structures. The\nstudy underscores the importance of comprehensive evaluation methodologies,\nadvocating for the incorporation of benchmarks like the common corruptions\nbenchmark. This inclusion provides nuanced insights into the vulnerabilities of\nneural networks, especially concerning their generalization capabilities and\nrobustness to unforeseen distortions. The research aligns with the broader\nobjective of advancing the development of highly robust learning systems\ncapable of nuanced reasoning across diverse and challenging real-world\nscenarios. Through this contribution, the paper aims to foster a deeper\nunderstanding of neural network limitations and proposes a practical approach\nto enhance their resilience in the face of evolving and unpredictable\nconditions.",
            "author": [
                "Shashank Kotyan",
                "Danilo Vasconcellos Vargas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10177v1",
                "http://arxiv.org/pdf/2311.10177v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10170v1",
            "title": "Improving Unimodal Inference with Multimodal Transformers",
            "updated": "2023-11-16T19:53:35Z",
            "published": "2023-11-16T19:53:35Z",
            "summary": "This paper proposes an approach for improving performance of unimodal models\nwith multimodal training. Our approach involves a multi-branch architecture\nthat incorporates unimodal models with a multimodal transformer-based branch.\nBy co-training these branches, the stronger multimodal branch can transfer its\nknowledge to the weaker unimodal branches through a multi-task objective,\nthereby improving the performance of the resulting unimodal models. We evaluate\nour approach on tasks of dynamic hand gesture recognition based on RGB and\nDepth, audiovisual emotion recognition based on speech and facial video, and\naudio-video-text based sentiment analysis. Our approach outperforms the\nconventionally trained unimodal counterparts. Interestingly, we also observe\nthat optimization of the unimodal branches improves the multimodal branch,\ncompared to a similar multimodal model trained from scratch.",
            "author": [
                "Kateryna Chumachenko",
                "Alexandros Iosifidis",
                "Moncef Gabbouj"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10170v1",
                "http://arxiv.org/pdf/2311.10170v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10162v1",
            "title": "K-space Cold Diffusion: Learning to Reconstruct Accelerated MRI without\n  Noise",
            "updated": "2023-11-16T19:34:18Z",
            "published": "2023-11-16T19:34:18Z",
            "summary": "Deep learning-based MRI reconstruction models have achieved superior\nperformance these days. Most recently, diffusion models have shown remarkable\nperformance in image generation, in-painting, super-resolution, image editing\nand more. As a generalized diffusion model, cold diffusion further broadens the\nscope and considers models built around arbitrary image transformations such as\nblurring, down-sampling, etc. In this paper, we propose a k-space cold\ndiffusion model that performs image degradation and restoration in k-space\nwithout the need for Gaussian noise. We provide comparisons with multiple deep\nlearning-based MRI reconstruction models and perform tests on a well-known\nlarge open-source MRI dataset. Our results show that this novel way of\nperforming degradation can generate high-quality reconstruction images for\naccelerated MRI.",
            "author": [
                "Guoyao Shen",
                "Mengyu Li",
                "Chad W. Farris",
                "Stephan Anderson",
                "Xin Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10162v1",
                "http://arxiv.org/pdf/2311.10162v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10156v1",
            "title": "Algebraic Topological Networks via the Persistent Local Homology Sheaf",
            "updated": "2023-11-16T19:24:20Z",
            "published": "2023-11-16T19:24:20Z",
            "summary": "In this work, we introduce a novel approach based on algebraic topology to\nenhance graph convolution and attention modules by incorporating local\ntopological properties of the data. To do so, we consider the framework of\nsheaf neural networks, which has been previously leveraged to incorporate\nadditional structure into graph neural networks' features and construct more\nexpressive, non-isotropic messages. Specifically, given an input simplicial\ncomplex (e.g. generated by the cliques of a graph or the neighbors in a point\ncloud), we construct its local homology sheaf, which assigns to each node the\nvector space of its local homology. The intermediate features of our networks\nlive in these vector spaces and we leverage the associated sheaf Laplacian to\nconstruct more complex linear messages between them. Moreover, we extend this\napproach by considering the persistent version of local homology associated\nwith a weighted simplicial complex (e.g., built from pairwise distances of\nnodes embeddings). This i) solves the problem of the lack of a natural choice\nof basis for the local homology vector spaces and ii) makes the sheaf itself\ndifferentiable, which enables our models to directly optimize the topology of\ntheir intermediate features.",
            "author": [
                "Gabriele Cesa",
                "Arash Behboodi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10156v1",
                "http://arxiv.org/pdf/2311.10156v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.AT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10155v1",
            "title": "Exploring Emotions in EEG: Deep Learning Approach with Feature Fusion",
            "updated": "2023-11-16T19:19:56Z",
            "published": "2023-11-16T19:19:56Z",
            "summary": "Emotion is an intricate physiological response that plays a crucial role in\nhow we respond and cooperate with others in our daily affairs. Numerous\nexperiments have been evolved to recognize emotion, however still require\nexploration to intensify the performance. To enhance the performance of\neffective emotion recognition, this study proposes a subject-dependent robust\nend-to-end emotion recognition system based on a 1D convolutional neural\nnetwork (1D-CNN). We evaluate the\nSJTU\\footnote{\\href{https://en.wikipedia.org/wiki/Shanghai_Jiao_Tong_University}{Shanghai\nJiao Tong University(SJTU)}} Emotion EEG Dataset SEED-V with five emotions\n(happy, sad, neural, fear, and disgust). To begin with, we utilize the Fast\nFourier Transform (FFT) to decompose the raw EEG signals into six frequency\nbands and extract the power spectrum feature from the frequency bands. After\nthat, we combine the extracted power spectrum feature with eye movement and\ndifferential entropy (DE) features. Finally, for classification, we apply the\ncombined data to our proposed system. Consequently, it attains 99.80\\% accuracy\nwhich surpasses each prior state-of-the-art system.",
            "author": [
                "Danastan Tasaouf Mridula",
                "Abu Ahmed Ferdaus",
                "Tanmoy Sarkar Pias"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10155v1",
                "http://arxiv.org/pdf/2311.10155v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10093v2",
            "title": "The Chosen One: Consistent Characters in Text-to-Image Diffusion Models",
            "updated": "2023-11-27T15:58:30Z",
            "published": "2023-11-16T18:59:51Z",
            "summary": "Recent advances in text-to-image generation models have unlocked vast\npotential for visual creativity. However, these models struggle with generation\nof consistent characters, a crucial aspect for numerous real-world applications\nsuch as story visualization, game development asset design, advertising, and\nmore. Current methods typically rely on multiple pre-existing images of the\ntarget character or involve labor-intensive manual processes. In this work, we\npropose a fully automated solution for consistent character generation, with\nthe sole input being a text prompt. We introduce an iterative procedure that,\nat each stage, identifies a coherent set of images sharing a similar identity\nand extracts a more consistent identity from this set. Our quantitative\nanalysis demonstrates that our method strikes a better balance between prompt\nalignment and identity consistency compared to the baseline methods, and these\nfindings are reinforced by a user study. To conclude, we showcase several\npractical applications of our approach. Project page is available at\nhttps://omriavrahami.com/the-chosen-one",
            "author": [
                "Omri Avrahami",
                "Amir Hertz",
                "Yael Vinker",
                "Moab Arar",
                "Shlomi Fruchter",
                "Ohad Fried",
                "Daniel Cohen-Or",
                "Dani Lischinski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10093v2",
                "http://arxiv.org/pdf/2311.10093v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10091v1",
            "title": "Adaptive Shells for Efficient Neural Radiance Field Rendering",
            "updated": "2023-11-16T18:58:55Z",
            "published": "2023-11-16T18:58:55Z",
            "summary": "Neural radiance fields achieve unprecedented quality for novel view\nsynthesis, but their volumetric formulation remains expensive, requiring a huge\nnumber of samples to render high-resolution images. Volumetric encodings are\nessential to represent fuzzy geometry such as foliage and hair, and they are\nwell-suited for stochastic optimization. Yet, many scenes ultimately consist\nlargely of solid surfaces which can be accurately rendered by a single sample\nper pixel. Based on this insight, we propose a neural radiance formulation that\nsmoothly transitions between volumetric- and surface-based rendering, greatly\naccelerating rendering speed and even improving visual fidelity. Our method\nconstructs an explicit mesh envelope which spatially bounds a neural volumetric\nrepresentation. In solid regions, the envelope nearly converges to a surface\nand can often be rendered with a single sample. To this end, we generalize the\nNeuS formulation with a learned spatially-varying kernel size which encodes the\nspread of the density, fitting a wide kernel to volume-like regions and a tight\nkernel to surface-like regions. We then extract an explicit mesh of a narrow\nband around the surface, with width determined by the kernel size, and\nfine-tune the radiance field within this band. At inference time, we cast rays\nagainst the mesh and evaluate the radiance field only within the enclosed\nregion, greatly reducing the number of samples required. Experiments show that\nour approach enables efficient rendering at very high fidelity. We also\ndemonstrate that the extracted envelope enables downstream applications such as\nanimation and simulation.",
            "author": [
                "Zian Wang",
                "Tianchang Shen",
                "Merlin Nimier-David",
                "Nicholas Sharp",
                "Jun Gao",
                "Alexander Keller",
                "Sanja Fidler",
                "Thomas M\u00fcller",
                "Zan Gojcic"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10091v1",
                "http://arxiv.org/pdf/2311.10091v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.GR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10090v3",
            "title": "JaxMARL: Multi-Agent RL Environments in JAX",
            "updated": "2023-11-20T15:51:07Z",
            "published": "2023-11-16T18:58:43Z",
            "summary": "Benchmarks play an important role in the development of machine learning\nalgorithms. For example, research in reinforcement learning (RL) has been\nheavily influenced by available environments and benchmarks. However, RL\nenvironments are traditionally run on the CPU, limiting their scalability with\ntypical academic compute. Recent advancements in JAX have enabled the wider use\nof hardware acceleration to overcome these computational hurdles, enabling\nmassively parallel RL training pipelines and environments. This is particularly\nuseful for multi-agent reinforcement learning (MARL) research. First of all,\nmultiple agents must be considered at each environment step, adding\ncomputational burden, and secondly, the sample complexity is increased due to\nnon-stationarity, decentralised partial observability, or other MARL\nchallenges. In this paper, we present JaxMARL, the first open-source code base\nthat combines ease-of-use with GPU enabled efficiency, and supports a large\nnumber of commonly used MARL environments as well as popular baseline\nalgorithms. When considering wall clock time, our experiments show that per-run\nour JAX-based training pipeline is up to 12500x faster than existing\napproaches. This enables efficient and thorough evaluations, with the potential\nto alleviate the evaluation crisis of the field. We also introduce and\nbenchmark SMAX, a vectorised, simplified version of the popular StarCraft\nMulti-Agent Challenge, which removes the need to run the StarCraft II game\nengine. This not only enables GPU acceleration, but also provides a more\nflexible MARL environment, unlocking the potential for self-play,\nmeta-learning, and other future applications in MARL. We provide code at\nhttps://github.com/flairox/jaxmarl.",
            "author": [
                "Alexander Rutherford",
                "Benjamin Ellis",
                "Matteo Gallici",
                "Jonathan Cook",
                "Andrei Lupu",
                "Gardar Ingvarsson",
                "Timon Willi",
                "Akbir Khan",
                "Christian Schroeder de Witt",
                "Alexandra Souly",
                "Saptarashmi Bandyopadhyay",
                "Mikayel Samvelyan",
                "Minqi Jiang",
                "Robert Tjarko Lange",
                "Shimon Whiteson",
                "Bruno Lacerda",
                "Nick Hawes",
                "Tim Rocktaschel",
                "Chris Lu",
                "Jakob Nicolaus Foerster"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10090v3",
                "http://arxiv.org/pdf/2311.10090v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10089v1",
            "title": "Emu Edit: Precise Image Editing via Recognition and Generation Tasks",
            "updated": "2023-11-16T18:55:58Z",
            "published": "2023-11-16T18:55:58Z",
            "summary": "Instruction-based image editing holds immense potential for a variety of\napplications, as it enables users to perform any editing operation using a\nnatural language instruction. However, current models in this domain often\nstruggle with accurately executing user instructions. We present Emu Edit, a\nmulti-task image editing model which sets state-of-the-art results in\ninstruction-based image editing. To develop Emu Edit we train it to multi-task\nacross an unprecedented range of tasks, such as region-based editing, free-form\nediting, and Computer Vision tasks, all of which are formulated as generative\ntasks. Additionally, to enhance Emu Edit's multi-task learning abilities, we\nprovide it with learned task embeddings which guide the generation process\ntowards the correct edit type. Both these elements are essential for Emu Edit's\noutstanding performance. Furthermore, we show that Emu Edit can generalize to\nnew tasks, such as image inpainting, super-resolution, and compositions of\nediting tasks, with just a few labeled examples. This capability offers a\nsignificant advantage in scenarios where high-quality samples are scarce.\nLastly, to facilitate a more rigorous and informed assessment of instructable\nimage editing models, we release a new challenging and versatile benchmark that\nincludes seven different image editing tasks.",
            "author": [
                "Shelly Sheynin",
                "Adam Polyak",
                "Uriel Singer",
                "Yuval Kirstain",
                "Amit Zohar",
                "Oron Ashual",
                "Devi Parikh",
                "Yaniv Taigman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10089v1",
                "http://arxiv.org/pdf/2311.10089v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10085v1",
            "title": "A Computationally Efficient Sparsified Online Newton Method",
            "updated": "2023-11-16T18:44:22Z",
            "published": "2023-11-16T18:44:22Z",
            "summary": "Second-order methods hold significant promise for enhancing the convergence\nof deep neural network training; however, their large memory and computational\ndemands have limited their practicality. Thus there is a need for scalable\nsecond-order methods that can efficiently train large models. In this paper, we\nintroduce the Sparsified Online Newton (SONew) method, a memory-efficient\nsecond-order algorithm that yields a sparsified yet effective preconditioner.\nThe algorithm emerges from a novel use of the LogDet matrix divergence measure;\nwe combine it with sparsity constraints to minimize regret in the online convex\noptimization framework. Empirically, we test our method on large scale\nbenchmarks of up to 1B parameters. We achieve up to 30% faster convergence,\n3.4% relative improvement in validation performance, and 80% relative\nimprovement in training loss, in comparison to memory efficient optimizers\nincluding first order methods. Powering the method is a surprising fact --\nimposing structured sparsity patterns, like tridiagonal and banded structure,\nrequires little to no overhead, making it as efficient and parallelizable as\nfirst-order methods. In wall-clock time, tridiagonal SONew is only about 3%\nslower per step than first-order methods but gives overall gains due to much\nfaster convergence. In contrast, one of the state-of-the-art (SOTA)\nmemory-intensive second-order methods, Shampoo, is unable to scale to large\nbenchmarks. Additionally, while Shampoo necessitates significant engineering\nefforts to scale to large benchmarks, SONew offers a more straightforward\nimplementation, increasing its practical appeal. SONew code is available at:\nhttps://github.com/devvrit/SONew",
            "author": [
                "Fnu Devvrit",
                "Sai Surya Duvvuri",
                "Rohan Anil",
                "Vineet Gupta",
                "Cho-Jui Hsieh",
                "Inderjit Dhillon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10085v1",
                "http://arxiv.org/pdf/2311.10085v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10785v1",
            "title": "Text Sanitization Beyond Specific Domains: Zero-Shot Redaction &\n  Substitution with Large Language Models",
            "updated": "2023-11-16T18:42:37Z",
            "published": "2023-11-16T18:42:37Z",
            "summary": "In the context of information systems, text sanitization techniques are used\nto identify and remove sensitive data to comply with security and regulatory\nrequirements. Even though many methods for privacy preservation have been\nproposed, most of them are focused on the detection of entities from specific\ndomains (e.g., credit card numbers, social security numbers), lacking\ngenerality and requiring customization for each desirable domain. Moreover,\nremoving words is, in general, a drastic measure, as it can degrade text\ncoherence and contextual information. Less severe measures include substituting\na word for a safe alternative, yet it can be challenging to automatically find\nmeaningful substitutions. We present a zero-shot text sanitization technique\nthat detects and substitutes potentially sensitive information using Large\nLanguage Models. Our evaluation shows that our method excels at protecting\nprivacy while maintaining text coherence and contextual information, preserving\ndata utility for downstream tasks.",
            "author": [
                "Federico Albanese",
                "Daniel Ciolek",
                "Nicolas D'Ippolito"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10785v1",
                "http://arxiv.org/pdf/2311.10785v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10081v1",
            "title": "DRESS: Instructing Large Vision-Language Models to Align and Interact\n  with Humans via Natural Language Feedback",
            "updated": "2023-11-16T18:37:29Z",
            "published": "2023-11-16T18:37:29Z",
            "summary": "We present DRESS, a large vision language model (LVLM) that innovatively\nexploits Natural Language feedback (NLF) from Large Language Models to enhance\nits alignment and interactions by addressing two key limitations in the\nstate-of-the-art LVLMs. First, prior LVLMs generally rely only on the\ninstruction finetuning stage to enhance alignment with human preferences.\nWithout incorporating extra feedback, they are still prone to generate\nunhelpful, hallucinated, or harmful responses. Second, while the visual\ninstruction tuning data is generally structured in a multi-turn dialogue\nformat, the connections and dependencies among consecutive conversational turns\nare weak. This reduces the capacity for effective multi-turn interactions. To\ntackle these, we propose a novel categorization of the NLF into two key types:\ncritique and refinement. The critique NLF identifies the strengths and\nweaknesses of the responses and is used to align the LVLMs with human\npreferences. The refinement NLF offers concrete suggestions for improvement and\nis adopted to improve the interaction ability of the LVLMs-- which focuses on\nLVLMs' ability to refine responses by incorporating feedback in multi-turn\ninteractions. To address the non-differentiable nature of NLF, we generalize\nconditional reinforcement learning for training. Our experimental results\ndemonstrate that DRESS can generate more helpful (9.76%), honest (11.52%), and\nharmless (21.03%) responses, and more effectively learn from feedback during\nmulti-turn interactions compared to SOTA LVMLs.",
            "author": [
                "Yangyi Chen",
                "Karan Sikka",
                "Michael Cogswell",
                "Heng Ji",
                "Ajay Divakaran"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10081v1",
                "http://arxiv.org/pdf/2311.10081v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10057v3",
            "title": "The Song Describer Dataset: a Corpus of Audio Captions for\n  Music-and-Language Evaluation",
            "updated": "2023-11-22T21:22:11Z",
            "published": "2023-11-16T17:52:21Z",
            "summary": "We introduce the Song Describer dataset (SDD), a new crowdsourced corpus of\nhigh-quality audio-caption pairs, designed for the evaluation of\nmusic-and-language models. The dataset consists of 1.1k human-written natural\nlanguage descriptions of 706 music recordings, all publicly accessible and\nreleased under Creative Common licenses. To showcase the use of our dataset, we\nbenchmark popular models on three key music-and-language tasks (music\ncaptioning, text-to-music generation and music-language retrieval). Our\nexperiments highlight the importance of cross-dataset evaluation and offer\ninsights into how researchers can use SDD to gain a broader understanding of\nmodel performance.",
            "author": [
                "Ilaria Manco",
                "Benno Weck",
                "SeungHeon Doh",
                "Minz Won",
                "Yixiao Zhang",
                "Dmitry Bogdanov",
                "Yusong Wu",
                "Ke Chen",
                "Philip Tovstogan",
                "Emmanouil Benetos",
                "Elio Quinton",
                "Gy\u00f6rgy Fazekas",
                "Juhan Nam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10057v3",
                "http://arxiv.org/pdf/2311.10057v3"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.AI",
                "cs.CL",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10054v1",
            "title": "Is \"A Helpful Assistant\" the Best Role for Large Language Models? A\n  Systematic Evaluation of Social Roles in System Prompts",
            "updated": "2023-11-16T17:48:55Z",
            "published": "2023-11-16T17:48:55Z",
            "summary": "Prompting serves as the major way humans interact with Large Language Models\n(LLM). Commercial AI systems commonly define the role of the LLM in system\nprompts. For example, ChatGPT uses \"You are a helpful assistant\" as part of the\ndefault system prompt. But is \"a helpful assistant\" the best role for LLMs? In\nthis study, we present a systematic evaluation of how social roles in system\nprompts affect model performance. We curate a list of 162 roles covering 6\ntypes of interpersonal relationships and 8 types of occupations. Through\nextensive analysis of 3 popular LLMs and 2457 questions, we show that adding\ninterpersonal roles in prompts consistently improves the models' performance\nover a range of questions. Moreover, while we find that using gender-neutral\nroles and specifying the role as the audience leads to better performances,\npredicting which role leads to the best performance remains a challenging task,\nand that frequency, similarity, and perplexity do not fully explain the effect\nof social roles on model performances. Our results can help inform the design\nof system prompts for AI systems. Code and data are available at\nhttps://github.com/Jiaxin-Pei/Prompting-with-Social-Roles.",
            "author": [
                "Mingqian Zheng",
                "Jiaxin Pei",
                "David Jurgens"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10054v1",
                "http://arxiv.org/pdf/2311.10054v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10053v1",
            "title": "Near-optimal Closed-loop Method via Lyapunov Damping for Convex\n  Optimization",
            "updated": "2023-11-16T17:48:06Z",
            "published": "2023-11-16T17:48:06Z",
            "summary": "We introduce an autonomous system with closed-loop damping for first-order\nconvex optimization. While, to this day, optimal rates of convergence are only\nachieved by non-autonomous methods via open-loop damping (e.g., Nesterov's\nalgorithm), we show that our system is the first one featuring a closed-loop\ndamping while exhibiting a rate arbitrarily close to the optimal one. We do so\nby coupling the damping and the speed of convergence of the system via a\nwell-chosen Lyapunov function. We then derive a practical first-order algorithm\ncalled LYDIA by discretizing our system, and present numerical experiments\nsupporting our theoretical findings.",
            "author": [
                "Severin Maier",
                "Camille Castera",
                "Peter Ochs"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10053v1",
                "http://arxiv.org/pdf/2311.10053v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "math.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10051v1",
            "title": "Tabular Few-Shot Generalization Across Heterogeneous Feature Spaces",
            "updated": "2023-11-16T17:45:59Z",
            "published": "2023-11-16T17:45:59Z",
            "summary": "Despite the prevalence of tabular datasets, few-shot learning remains\nunder-explored within this domain. Existing few-shot methods are not directly\napplicable to tabular datasets due to varying column relationships, meanings,\nand permutational invariance. To address these challenges, we propose FLAT-a\nnovel approach to tabular few-shot learning, encompassing knowledge sharing\nbetween datasets with heterogeneous feature spaces. Utilizing an encoder\ninspired by Dataset2Vec, FLAT learns low-dimensional embeddings of datasets and\ntheir individual columns, which facilitate knowledge transfer and\ngeneralization to previously unseen datasets. A decoder network parametrizes\nthe predictive target network, implemented as a Graph Attention Network, to\naccommodate the heterogeneous nature of tabular datasets. Experiments on a\ndiverse collection of 118 UCI datasets demonstrate FLAT's successful\ngeneralization to new tabular datasets and a considerable improvement over the\nbaselines.",
            "author": [
                "Max Zhu",
                "Katarzyna Kobalczyk",
                "Andrija Petrovic",
                "Mladen Nikolic",
                "Mihaela van der Schaar",
                "Boris Delibasic",
                "Petro Lio"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10051v1",
                "http://arxiv.org/pdf/2311.10051v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10049v2",
            "title": "Inherently Interpretable Time Series Classification via Multiple\n  Instance Learning",
            "updated": "2023-11-23T14:46:49Z",
            "published": "2023-11-16T17:45:37Z",
            "summary": "Conventional Time Series Classification (TSC) methods are often black boxes\nthat obscure inherent interpretation of their decision-making processes. In\nthis work, we leverage Multiple Instance Learning (MIL) to overcome this issue,\nand propose a new framework called MILLET: Multiple Instance Learning for\nLocally Explainable Time series classification. We apply MILLET to existing\ndeep learning TSC models and show how they become inherently interpretable\nwithout compromising (and in some cases, even improving) predictive\nperformance. We evaluate MILLET on 85 UCR TSC datasets and also present a novel\nsynthetic dataset that is specially designed to facilitate interpretability\nevaluation. On these datasets, we show MILLET produces sparse explanations\nquickly that are of higher quality than other well-known interpretability\nmethods. To the best of our knowledge, our work with MILLET, which is available\non GitHub (https://github.com/JAEarly/MILTimeSeriesClassification), is the\nfirst to develop general MIL methods for TSC and apply them to an extensive\nvariety of domains",
            "author": [
                "Joseph Early",
                "Gavin KC Cheung",
                "Kurt Cutajar",
                "Hanting Xie",
                "Jas Kandola",
                "Niall Twomey"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10049v2",
                "http://arxiv.org/pdf/2311.10049v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10041v1",
            "title": "Interpretable Reinforcement Learning for Robotics and Continuous Control",
            "updated": "2023-11-16T17:37:46Z",
            "published": "2023-11-16T17:37:46Z",
            "summary": "Interpretability in machine learning is critical for the safe deployment of\nlearned policies across legally-regulated and safety-critical domains. While\ngradient-based approaches in reinforcement learning have achieved tremendous\nsuccess in learning policies for continuous control problems such as robotics\nand autonomous driving, the lack of interpretability is a fundamental barrier\nto adoption. We propose Interpretable Continuous Control Trees (ICCTs), a\ntree-based model that can be optimized via modern, gradient-based,\nreinforcement learning approaches to produce high-performing, interpretable\npolicies. The key to our approach is a procedure for allowing direct\noptimization in a sparse decision-tree-like representation. We validate ICCTs\nagainst baselines across six domains, showing that ICCTs are capable of\nlearning policies that parity or outperform baselines by up to 33% in\nautonomous driving scenarios while achieving a 300x-600x reduction in the\nnumber of parameters against deep learning baselines. We prove that ICCTs can\nserve as universal function approximators and display analytically that ICCTs\ncan be verified in linear time. Furthermore, we deploy ICCTs in two realistic\ndriving domains, based on interstate Highway-94 and 280 in the US. Finally, we\nverify ICCT's utility with end-users and find that ICCTs are rated easier to\nsimulate, quicker to validate, and more interpretable than neural networks.",
            "author": [
                "Rohan Paleja",
                "Letian Chen",
                "Yaru Niu",
                "Andrew Silva",
                "Zhaoxin Li",
                "Songan Zhang",
                "Chace Ritchie",
                "Sugju Choi",
                "Kimberlee Chestnut Chang",
                "Hongtei Eric Tseng",
                "Yan Wang",
                "Subramanya Nageshrao",
                "Matthew Gombolay"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10041v1",
                "http://arxiv.org/pdf/2311.10041v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10036v2",
            "title": "Dynamic CBCT Imaging using Prior Model-Free Spatiotemporal Implicit\n  Neural Representation (PMF-STINR)",
            "updated": "2023-12-04T15:59:47Z",
            "published": "2023-11-16T17:34:32Z",
            "summary": "Dynamic cone-beam computed tomography (CBCT) can capture\nhigh-spatial-resolution, time-varying images for motion monitoring, patient\nsetup, and adaptive planning of radiotherapy. However, dynamic CBCT\nreconstruction is an extremely ill-posed spatiotemporal inverse problem, as\neach CBCT volume in the dynamic sequence is only captured by one or a few X-ray\nprojections. We developed a machine learning-based technique, prior-model-free\nspatiotemporal implicit neural representation (PMF-STINR), to reconstruct\ndynamic CBCTs from sequentially acquired X-ray projections. PMF-STINR employs a\njoint image reconstruction and registration approach to address the\nunder-sampling challenge. Specifically, PMF-STINR uses spatial implicit neural\nrepresentation to reconstruct a reference CBCT volume, and it applies temporal\nINR to represent the intra-scan dynamic motion with respect to the reference\nCBCT to yield dynamic CBCTs. PMF-STINR couples the temporal INR with a\nlearning-based B-spline motion model to capture time-varying deformable motion\nduring the reconstruction. Compared with previous methods, the spatial INR, the\ntemporal INR, and the B-spline model of PMF-STINR are all learned on the fly\nduring reconstruction in a one-shot fashion, without using any patient-specific\nprior knowledge or motion sorting/binning. PMF-STINR was evaluated via digital\nphantom simulations, physical phantom measurements, and a multi-institutional\npatient dataset featuring various imaging protocols (half-fan/full-fan, full\nsampling/sparse sampling, different energy and mAs settings, etc.). The results\nshowed that the one-shot learning-based PMF-STINR can accurately and robustly\nreconstruct dynamic CBCTs and capture highly irregular motion with high\ntemporal (~0.1s) resolution and sub-millimeter accuracy. It can be a promising\ntool for motion management by offering richer motion information than\ntraditional 4D-CBCTs.",
            "author": [
                "Hua-Chieh Shao",
                "Mengke Tielige",
                "Tinsu Pan",
                "You Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10036v2",
                "http://arxiv.org/pdf/2311.10036v2"
            ],
            "primary_category": "physics.med-ph",
            "category": [
                "physics.med-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10026v1",
            "title": "Guaranteeing Control Requirements via Reward Shaping in Reinforcement\n  Learning",
            "updated": "2023-11-16T17:14:26Z",
            "published": "2023-11-16T17:14:26Z",
            "summary": "In addressing control problems such as regulation and tracking through\nreinforcement learning, it is often required to guarantee that the acquired\npolicy meets essential performance and stability criteria such as a desired\nsettling time and steady-state error prior to deployment. Motivated by this\nnecessity, we present a set of results and a systematic reward shaping\nprocedure that (i) ensures the optimal policy generates trajectories that align\nwith specified control requirements and (ii) allows to assess whether any given\npolicy satisfies them. We validate our approach through comprehensive numerical\nexperiments conducted in two representative environments from OpenAI Gym: the\nInverted Pendulum swing-up problem and the Lunar Lander. Utilizing both tabular\nand deep reinforcement learning methods, our experiments consistently affirm\nthe efficacy of our proposed framework, highlighting its effectiveness in\nensuring policy adherence to the prescribed control requirements.",
            "author": [
                "Francesco De Lellis",
                "Marco Coraggio",
                "Giovanni Russo",
                "Mirco Musolesi",
                "Mario di Bernardo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10026v1",
                "http://arxiv.org/pdf/2311.10026v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10025v1",
            "title": "A Novel Neural Network-Based Federated Learning System for Imbalanced\n  and Non-IID Data",
            "updated": "2023-11-16T17:14:07Z",
            "published": "2023-11-16T17:14:07Z",
            "summary": "With the growth of machine learning techniques, privacy of data of users has\nbecome a major concern. Most of the machine learning algorithms rely heavily on\nlarge amount of data which may be collected from various sources. Collecting\nthese data yet maintaining privacy policies has become one of the most\nchallenging tasks for the researchers. To combat this issue, researchers have\nintroduced federated learning, where a prediction model is learnt by ensuring\nthe privacy of data of clients data. However, the prevalent federated learning\nalgorithms possess an accuracy and efficiency trade-off, especially for non-IID\ndata. In this research, we propose a centralized, neural network-based\nfederated learning system. The centralized algorithm incorporates micro-level\nparallel processing inspired by the traditional mini-batch algorithm where the\nclient devices and the server handle the forward and backward propagation\nrespectively. We also devise a semi-centralized version of our proposed\nalgorithm. This algorithm takes advantage of edge computing for minimizing the\nload from the central server, where clients handle both the forward and\nbackward propagation while sacrificing the overall train time to some extent.\nWe evaluate our proposed systems on five well-known benchmark datasets and\nachieve satisfactory performance in a reasonable time across various data\ndistribution settings as compared to some existing benchmark algorithms.",
            "author": [
                "Mahfuzur Rahman Chowdhury",
                "Muhammad Ibrahim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10025v1",
                "http://arxiv.org/pdf/2311.10025v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10023v1",
            "title": "Online Optimization for Network Resource Allocation and Comparison with\n  Reinforcement Learning Techniques",
            "updated": "2023-11-16T17:08:27Z",
            "published": "2023-11-16T17:08:27Z",
            "summary": "We tackle in this paper an online network resource allocation problem with\njob transfers. The network is composed of many servers connected by\ncommunication links. The system operates in discrete time; at each time slot,\nthe administrator reserves resources at servers for future job requests, and a\ncost is incurred for the reservations made. Then, after receptions, the jobs\nmay be transferred between the servers to best accommodate the demands. This\nincurs an additional transport cost. Finally, if a job request cannot be\nsatisfied, there is a violation that engenders a cost to pay for the blocked\njob. We propose a randomized online algorithm based on the exponentially\nweighted method. We prove that our algorithm enjoys a sub-linear in time\nregret, which indicates that the algorithm is adapting and learning from its\nexperiences and is becoming more efficient in its decision-making as it\naccumulates more data. Moreover, we test the performance of our algorithm on\nartificial data and compare it against a reinforcement learning method where we\nshow that our proposed method outperforms the latter.",
            "author": [
                "Ahmed Sid-Ali",
                "Ioannis Lambadaris",
                "Yiqiang Q. Zhao",
                "Gennady Shaikhet",
                "Amirhossein Asgharnia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10023v1",
                "http://arxiv.org/pdf/2311.10023v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10018v1",
            "title": "On the Overconfidence Problem in Semantic 3D Mapping",
            "updated": "2023-11-16T17:02:34Z",
            "published": "2023-11-16T17:02:34Z",
            "summary": "Semantic 3D mapping, the process of fusing depth and image segmentation\ninformation between multiple views to build 3D maps annotated with object\nclasses in real-time, is a recent topic of interest. This paper highlights the\nfusion overconfidence problem, in which conventional mapping methods assign\nhigh confidence to the entire map even when they are incorrect, leading to\nmiscalibrated outputs. Several methods to improve uncertainty calibration at\ndifferent stages in the fusion pipeline are presented and compared on the\nScanNet dataset. We show that the most widely used Bayesian fusion strategy is\namong the worst calibrated, and propose a learned pipeline that combines fusion\nand calibration, GLFS, which achieves simultaneously higher accuracy and 3D map\ncalibration while retaining real-time capability. We further illustrate the\nimportance of map calibration on a downstream task by showing that\nincorporating proper semantic fusion on a modular ObjectNav agent improves its\nsuccess rates. Our code will be provided on Github for reproducibility upon\nacceptance.",
            "author": [
                "Joao Marcos Correia Marques",
                "Albert Zhai",
                "Shenlong Wang",
                "Kris Hauser"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10018v1",
                "http://arxiv.org/pdf/2311.10018v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.RO",
                "I.2.9; I.2.10"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10012v1",
            "title": "Finding Real-World Orbital Motion Laws from Data",
            "updated": "2023-11-16T16:53:52Z",
            "published": "2023-11-16T16:53:52Z",
            "summary": "A novel approach is presented for discovering PDEs that govern the motion of\nsatellites in space. The method is based on SINDy, a data-driven technique\ncapable of identifying the underlying dynamics of complex physical systems from\ntime series data. SINDy is utilized to uncover PDEs that describe the laws of\nphysics in space, which are non-deterministic and influenced by various factors\nsuch as drag or the reference area (related to the attitude of the satellite).\nIn contrast to prior works, the physically interpretable coordinate system is\nmaintained, and no dimensionality reduction technique is applied to the data.\nBy training the model with multiple representative trajectories of LEO -\nencompassing various inclinations, eccentricities, and altitudes - and testing\nit with unseen orbital motion patterns, a mean error of around 140 km for the\npositions and 0.12 km/s for the velocities is achieved. The method offers the\nadvantage of delivering interpretable, accurate, and complex models of orbital\nmotion that can be employed for propagation or as inputs to predictive models\nfor other variables of interest, such as atmospheric drag or the probability of\ncollision in an encounter with a spacecraft or space objects. In conclusion,\nthe work demonstrates the promising potential of using SINDy to discover the\nequations governing the behaviour of satellites in space. The technique has\nbeen successfully applied to uncover PDEs describing the motion of satellites\nin LEO with high accuracy. The method possesses several advantages over\ntraditional models, including the ability to provide physically interpretable,\naccurate, and complex models of orbital motion derived from high-entropy\ndatasets. These models can be utilised for propagation or as inputs to\npredictive models for other variables of interest.",
            "author": [
                "Jo\u00e3o Funenga",
                "Marta Guimar\u00e3es",
                "Henrique Costa",
                "Cl\u00e1udia Soares"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10012v1",
                "http://arxiv.org/pdf/2311.10012v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "astro-ph.EP",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10127v1",
            "title": "Learning interactions to boost human creativity with bandits and GPT-4",
            "updated": "2023-11-16T16:53:17Z",
            "published": "2023-11-16T16:53:17Z",
            "summary": "This paper considers how interactions with AI algorithms can boost human\ncreative thought. We employ a psychological task that demonstrates limits on\nhuman creativity, namely semantic feature generation: given a concept name,\nrespondents must list as many of its features as possible. Human participants\ntypically produce only a fraction of the features they know before getting\n\"stuck.\" In experiments with humans and with a language AI (GPT-4) we contrast\nbehavior in the standard task versus a variant in which participants can ask\nfor algorithmically-generated hints. Algorithm choice is administered by a\nmulti-armed bandit whose reward indicates whether the hint helped generating\nmore features. Humans and the AI show similar benefits from hints, and\nremarkably, bandits learning from AI responses prefer the same prompting\nstrategy as those learning from human behavior. The results suggest that\nstrategies for boosting human creativity via computer interactions can be\nlearned by bandits run on groups of simulated participants.",
            "author": [
                "Ara Vartanian",
                "Xiaoxi Sun",
                "Yun-Shiuan Chuang",
                "Siddharth Suresh",
                "Xiaojin Zhu",
                "Timothy T. Rogers"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10127v1",
                "http://arxiv.org/pdf/2311.10127v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10002v1",
            "title": "Straggler-resilient Federated Learning: Tackling Computation\n  Heterogeneity with Layer-wise Partial Model Training in Mobile Edge Network",
            "updated": "2023-11-16T16:30:04Z",
            "published": "2023-11-16T16:30:04Z",
            "summary": "Federated Learning (FL) enables many resource-limited devices to train a\nmodel collaboratively without data sharing. However, many existing works focus\non model-homogeneous FL, where the global and local models are the same size,\nignoring the inherently heterogeneous computational capabilities of different\ndevices and restricting resource-constrained devices from contributing to FL.\nIn this paper, we consider model-heterogeneous FL and propose Federated Partial\nModel Training (FedPMT), where devices with smaller computational capabilities\nwork on partial models (subsets of the global model) and contribute to the\nglobal model. Different from Dropout-based partial model generation, which\nremoves neurons in hidden layers at random, model training in FedPMT is\nachieved from the back-propagation perspective. As such, all devices in FedPMT\nprioritize the most crucial parts of the global model. Theoretical analysis\nshows that the proposed partial model training design has a similar convergence\nrate to the widely adopted Federated Averaging (FedAvg) algorithm,\n$\\mathcal{O}(1/T)$, with the sub-optimality gap enlarged by a constant factor\nrelated to the model splitting design in FedPMT. Empirical results show that\nFedPMT significantly outperforms the existing benchmark FedDrop. Meanwhile,\ncompared to the popular model-homogeneous benchmark, FedAvg, FedPMT reaches the\nlearning target in a shorter completion time, thus achieving a better trade-off\nbetween learning accuracy and completion time.",
            "author": [
                "Hongda Wu",
                "Ping Wang",
                "C V Aswartha Narayana"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10002v1",
                "http://arxiv.org/pdf/2311.10002v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09998v1",
            "title": "DeepEMD: A Transformer-based Fast Estimation of the Earth Mover's\n  Distance",
            "updated": "2023-11-16T16:14:58Z",
            "published": "2023-11-16T16:14:58Z",
            "summary": "The Earth Mover's Distance (EMD) is the measure of choice between point\nclouds. However the computational cost to compute it makes it prohibitive as a\ntraining loss, and the standard approach is to use a surrogate such as the\nChamfer distance. We propose an attention-based model to compute an accurate\napproximation of the EMD that can be used as a training loss for generative\nmodels. To get the necessary accurate estimation of the gradients we train our\nmodel to explicitly compute the matching between point clouds instead of EMD\nitself. We cast this new objective as the estimation of an attention matrix\nthat approximates the ground truth matching matrix. Experiments show that this\nmodel provides an accurate estimate of the EMD and its gradient with a wall\nclock speed-up of more than two orders of magnitude with respect to the exact\nHungarian matching algorithm and one order of magnitude with respect to the\nstandard approximate Sinkhorn algorithm, allowing in particular to train a\npoint cloud VAE with the EMD itself. Extensive evaluation show the remarkable\nbehaviour of this model when operating out-of-distribution, a key requirement\nfor a distance surrogate. Finally, the model generalizes very well to point\nclouds during inference several times larger than during training.",
            "author": [
                "Atul Kumar Sinha",
                "Francois Fleuret"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09998v1",
                "http://arxiv.org/pdf/2311.09998v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09997v1",
            "title": "Co-data Learning for Bayesian Additive Regression Trees",
            "updated": "2023-11-16T16:14:39Z",
            "published": "2023-11-16T16:14:39Z",
            "summary": "Medical prediction applications often need to deal with small sample sizes\ncompared to the number of covariates. Such data pose problems for prediction\nand variable selection, especially when the covariate-response relationship is\ncomplicated. To address these challenges, we propose to incorporate co-data,\ni.e. external information on the covariates, into Bayesian additive regression\ntrees (BART), a sum-of-trees prediction model that utilizes priors on the tree\nparameters to prevent overfitting. To incorporate co-data, an empirical Bayes\n(EB) framework is developed that estimates, assisted by a co-data model, prior\ncovariate weights in the BART model. The proposed method can handle multiple\ntypes of co-data simultaneously. Furthermore, the proposed EB framework enables\nthe estimation of the other hyperparameters of BART as well, rendering an\nappealing alternative to cross-validation. We show that the method finds\nrelevant covariates and that it improves prediction compared to default BART in\nsimulations. If the covariate-response relationship is nonlinear, the method\nbenefits from the flexibility of BART to outperform regression-based co-data\nlearners. Finally, the use of co-data enhances prediction in an application to\ndiffuse large B-cell lymphoma prognosis based on clinical covariates, gene\nmutations, DNA translocations, and DNA copy number data.\n  Keywords: Bayesian additive regression trees; Empirical Bayes; Co-data;\nHigh-dimensional data; Omics; Prediction",
            "author": [
                "Jeroen M. Goedhart",
                "Thomas Klausch",
                "Jurriaan Janssen",
                "Mark A. van de Wiel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09997v1",
                "http://arxiv.org/pdf/2311.09997v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09989v1",
            "title": "Xputer: Bridging Data Gaps with NMF, XGBoost, and a Streamlined GUI\n  Experience",
            "updated": "2023-11-16T16:07:19Z",
            "published": "2023-11-16T16:07:19Z",
            "summary": "The rapid proliferation of data across diverse fields has accentuated the\nimportance of accurate imputation for missing values. This task is crucial for\nensuring data integrity and deriving meaningful insights. In response to this\nchallenge, we present Xputer, a novel imputation tool that adeptly integrates\nNon-negative Matrix Factorization (NMF) with the predictive strengths of\nXGBoost. One of Xputer's standout features is its versatility: it supports zero\nimputation, enables hyperparameter optimization through Optuna, and allows\nusers to define the number of iterations. For enhanced user experience and\naccessibility, we have equipped Xputer with an intuitive Graphical User\nInterface (GUI) ensuring ease of handling, even for those less familiar with\ncomputational tools. In performance benchmarks, Xputer not only rivals the\ncomputational speed of established tools such as IterativeImputer but also\noften outperforms them in terms of imputation accuracy. Furthermore, Xputer\nautonomously handles a diverse spectrum of data types, including categorical,\ncontinuous, and Boolean, eliminating the need for prior preprocessing. Given\nits blend of performance, flexibility, and user-friendly design, Xputer emerges\nas a state-of-the-art solution in the realm of data imputation.",
            "author": [
                "Saleena Younus",
                "Lars R\u00f6nnstrand",
                "Julhash U. Kazi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09989v1",
                "http://arxiv.org/pdf/2311.09989v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.QM",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10784v1",
            "title": "ExFake: Towards an Explainable Fake News Detection Based on Content and\n  Social Context Information",
            "updated": "2023-11-16T15:57:58Z",
            "published": "2023-11-16T15:57:58Z",
            "summary": "ExFake is an explainable fake news detection system based on content and\ncontext-level information. It is concerned with the veracity analysis of online\nposts based on their content, social context (i.e., online users' credibility\nand historical behaviour), and data coming from trusted entities such as\nfact-checking websites and named entities. Unlike state-of-the-art systems, an\nExplainable AI (XAI) assistant is also adopted to help online social networks\n(OSN) users develop good reflexes when faced with any doubted information that\nspreads on social networks. The trustworthiness of OSN users is also addressed\nby assigning a credibility score to OSN users, as OSN users are one of the main\nculprits for spreading fake news. Experimental analysis on a real-world dataset\ndemonstrates that ExFake significantly outperforms other baseline methods for\nfake news detection.",
            "author": [
                "Sabrine Amri",
                "Henri-Cedric Mputu Boleilanga",
                "Esma A\u00efmeur"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10784v1",
                "http://arxiv.org/pdf/2311.10784v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09974v1",
            "title": "From Pretext to Purpose: Batch-Adaptive Self-Supervised Learning",
            "updated": "2023-11-16T15:47:49Z",
            "published": "2023-11-16T15:47:49Z",
            "summary": "In recent years, self-supervised contrastive learning has emerged as a\ndistinguished paradigm in the artificial intelligence landscape. It facilitates\nunsupervised feature learning through contrastive delineations at the instance\nlevel. However, crafting an effective self-supervised paradigm remains a\npivotal challenge within this field. This paper delves into two crucial factors\nimpacting self-supervised contrastive learning-bach size and pretext tasks, and\nfrom a data processing standpoint, proposes an adaptive technique of batch\nfusion. The proposed method, via dimensionality reduction and reconstruction of\nbatch data, enables formerly isolated individual data to partake in intra-batch\ncommunication through the Embedding Layer. Moreover, it adaptively amplifies\nthe self-supervised feature encoding capability as the training progresses. We\nconducted a linear classification test of this method based on the classic\ncontrastive learning framework on ImageNet-1k. The empirical findings\nillustrate that our approach achieves state-of-the-art performance under\nequitable comparisons. Benefiting from its \"plug-and-play\" characteristics, we\nfurther explored other contrastive learning methods. On the ImageNet-100,\ncompared to the original performance, the top1 has seen a maximum increase of\n1.25%. We suggest that the proposed method may contribute to the advancement of\ndata-driven self-supervised learning research, bringing a fresh perspective to\nthis community.",
            "author": [
                "Jiansong Zhang",
                "Peizhong Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09974v1",
                "http://arxiv.org/pdf/2311.09974v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09965v1",
            "title": "SurgPLAN: Surgical Phase Localization Network for Phase Recognition",
            "updated": "2023-11-16T15:39:01Z",
            "published": "2023-11-16T15:39:01Z",
            "summary": "Surgical phase recognition is crucial to providing surgery understanding in\nsmart operating rooms. Despite great progress in automatic surgical phase\nrecognition, most existing methods are still restricted by two problems. First,\nthese methods cannot capture discriminative visual features for each frame and\nmotion information with simple 2D networks. Second, the frame-by-frame\nrecognition paradigm degrades the performance due to unstable predictions\nwithin each phase, termed as phase shaking. To address these two challenges, we\npropose a Surgical Phase LocAlization Network, named SurgPLAN, to facilitate a\nmore accurate and stable surgical phase recognition with the principle of\ntemporal detection. Specifically, we first devise a Pyramid SlowFast (PSF)\narchitecture to serve as the visual backbone to capture multi-scale spatial and\ntemporal features by two branches with different frame sampling rates.\nMoreover, we propose a Temporal Phase Localization (TPL) module to generate the\nphase prediction based on temporal region proposals, which ensures accurate and\nconsistent predictions within each surgical phase. Extensive experiments\nconfirm the significant advantages of our SurgPLAN over frame-by-frame\napproaches in terms of both accuracy and stability.",
            "author": [
                "Xingjian Luo",
                "You Pang",
                "Zhen Chen",
                "Jinlin Wu",
                "Zongmin Zhang",
                "Zhen Lei",
                "Hongbin Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09965v1",
                "http://arxiv.org/pdf/2311.09965v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09962v1",
            "title": "Self-supervised learning of multi-omics embeddings in the low-label,\n  high-data regime",
            "updated": "2023-11-16T15:32:22Z",
            "published": "2023-11-16T15:32:22Z",
            "summary": "Contrastive, self-supervised learning (SSL) is used to train a model that\npredicts cancer type from miRNA, mRNA or RPPA expression data. This model, a\npretrained FT-Transformer, is shown to outperform XGBoost and CatBoost,\nstandard benchmarks for tabular data, when labelled samples are scarce but the\nnumber of unlabelled samples is high. This is despite the fact that the\ndatasets we use have $\\mathcal{O}(10^{1})$ classes and\n$\\mathcal{O}(10^{2})-\\mathcal{O}(10^{4})$ features. After demonstrating the\nefficacy of our chosen method of self-supervised pretraining, we investigate\nSSL for multi-modal models. A late-fusion model is proposed, where each omics\nis passed through its own sub-network, the outputs of which are averaged and\npassed to the pretraining or downstream objective function. Multi-modal\npretraining is shown to improve predictions from a single omics, and we argue\nthat this is useful for datasets with many unlabelled multi-modal samples, but\nfew labelled unimodal samples. Additionally, we show that pretraining each\nomics-specific module individually is highly effective. This enables the\napplication of the proposed model in a variety of contexts where a large amount\nof unlabelled data is available from each omics, but only a few labelled\nsamples.",
            "author": [
                "Christian John Hurry",
                "Emma Slade"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09962v1",
                "http://arxiv.org/pdf/2311.09962v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09952v1",
            "title": "Score-based generative models learn manifold-like structures with\n  constrained mixing",
            "updated": "2023-11-16T15:15:15Z",
            "published": "2023-11-16T15:15:15Z",
            "summary": "How do score-based generative models (SBMs) learn the data distribution\nsupported on a low-dimensional manifold? We investigate the score model of a\ntrained SBM through its linear approximations and subspaces spanned by local\nfeature vectors. During diffusion as the noise decreases, the local\ndimensionality increases and becomes more varied between different sample\nsequences. Importantly, we find that the learned vector field mixes samples by\na non-conservative field within the manifold, although it denoises with normal\nprojections as if there is an energy function in off-manifold directions. At\neach noise level, the subspace spanned by the local features overlap with an\neffective density function. These observations suggest that SBMs can flexibly\nmix samples with the learned score field while carefully maintaining a\nmanifold-like structure of the data distribution.",
            "author": [
                "Li Kevin Wenliang",
                "Ben Moran"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09952v1",
                "http://arxiv.org/pdf/2311.09952v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09948v1",
            "title": "Hijacking Large Language Models via Adversarial In-Context Learning",
            "updated": "2023-11-16T15:01:48Z",
            "published": "2023-11-16T15:01:48Z",
            "summary": "In-context learning (ICL) has emerged as a powerful paradigm leveraging LLMs\nfor specific tasks by utilizing labeled examples as demonstrations in the\nprecondition prompts. Despite its promising performance, ICL suffers from\ninstability with the choice and arrangement of examples. Additionally, crafted\nadversarial attacks pose a notable threat to the robustness of ICL. However,\nexisting attacks are either easy to detect, rely on external models, or lack\nspecificity towards ICL. To address these issues, this work introduces a novel\ntransferable attack for ICL, aiming to hijack LLMs to generate the targeted\nresponse. The proposed LLM hijacking attack leverages a gradient-based prompt\nsearch method to learn and append imperceptible adversarial suffixes to the\nin-context demonstrations. Extensive experimental results on various tasks and\ndatasets demonstrate the effectiveness of our LLM hijacking attack, resulting\nin a distracted attention towards adversarial tokens, consequently leading to\nthe targeted unwanted outputs.",
            "author": [
                "Yao Qiang",
                "Xiangyu Zhou",
                "Dongxiao Zhu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09948v1",
                "http://arxiv.org/pdf/2311.09948v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09947v1",
            "title": "Natural Disaster Analysis using Satellite Imagery and Social-Media Data\n  for Emergency Response Situations",
            "updated": "2023-11-16T15:01:26Z",
            "published": "2023-11-16T15:01:26Z",
            "summary": "Disaster Management is one of the most promising research areas because of\nits significant economic, environmental and social repercussions. This research\nfocuses on analyzing different types of data (pre and post satellite images and\ntwitter data) related to disaster management for in-depth analysis of\nlocation-wise emergency requirements. This research has been divided into two\nstages, namely, satellite image analysis and twitter data analysis followed by\nintegration using location. The first stage involves pre and post disaster\nsatellite image analysis of the location using multi-class land cover\nsegmentation technique based on U-Net architecture. The second stage focuses on\nmapping the region with essential information about the disaster situation and\nimmediate requirements for relief operations. The severely affected regions are\ndemarcated and twitter data is extracted using keywords respective to that\nlocation. The extraction of situational information from a large corpus of raw\ntweets adopts Content Word based Tweet Summarization (COWTS) technique. An\nintegration of these modules using real-time location-based mapping and\nfrequency analysis technique gathers multi-dimensional information in the\nadvent of disaster occurrence such as the Kerala and Mississippi floods that\nwere analyzed and validated as test cases. The novelty of this research lies in\nthe application of segmented satellite images for disaster relief using\nhighlighted land cover changes and integration of twitter data by mapping these\nregion-specific filters for obtaining a complete overview of the disaster.",
            "author": [
                "Sukeerthi Mandyam",
                "Shanmuga Priya MG",
                "Shalini Suresh",
                "Kavitha Srinivasan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09947v1",
                "http://arxiv.org/pdf/2311.09947v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09942v1",
            "title": "Harnessing Transformers: A Leap Forward in Lung Cancer Image Detection",
            "updated": "2023-11-16T14:50:42Z",
            "published": "2023-11-16T14:50:42Z",
            "summary": "This paper discusses the role of Transfer Learning (TL) and transformers in\ncancer detection based on image analysis. With the enormous evolution of cancer\npatients, the identification of cancer cells in a patient's body has emerged as\na trend in the field of Artificial Intelligence (AI). This process involves\nanalyzing medical images, such as Computed Tomography (CT) scans and Magnetic\nResonance Imaging (MRIs), to identify abnormal growths that may help in cancer\ndetection. Many techniques and methods have been realized to improve the\nquality and performance of cancer classification and detection, such as TL,\nwhich allows the transfer of knowledge from one task to another with the same\ntask or domain. TL englobes many methods, particularly those used in image\nanalysis, such as transformers and Convolutional Neural Network (CNN) models\ntrained on the ImageNet dataset. This paper analyzes and criticizes each method\nof TL based on image analysis and compares the results of each method, showing\nthat transformers have achieved the best results with an accuracy of 97.41% for\ncolon cancer detection and 94.71% for Histopathological Lung cancer. Future\ndirections for cancer detection based on image analysis are also discussed.",
            "author": [
                "Amine Bechar",
                "Youssef Elmir",
                "Rafik Medjoudj",
                "Yassine Himeur",
                "Abbes Amira"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09942v1",
                "http://arxiv.org/pdf/2311.09942v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09933v2",
            "title": "Heuristic Learning for Co-Design Scheme of Optimal Sequential Attack",
            "updated": "2023-11-17T02:40:49Z",
            "published": "2023-11-16T14:39:08Z",
            "summary": "This paper considers a novel co-design problem of the optimal\n\\textit{sequential} attack, whose attack strategy changes with the time series,\nand in which the \\textit{sequential} attack selection strategy and\n\\textit{sequential} attack signal are simultaneously designed. Different from\nthe existing attack design works that separately focus on attack subsets or\nattack signals, the joint design of the attack strategy poses a huge challenge\ndue to the deep coupling relation between the \\textit{sequential} attack\nselection strategy and \\textit{sequential} attack signal. In this manuscript,\nwe decompose the sequential co-design problem into two equivalent sub-problems.\nSpecifically, we first derive an analytical closed-form expression between the\noptimal attack signal and the sequential attack selection strategy.\nFurthermore, we prove the finite-time inverse convergence of the critical\nparameters in the injected optimal attack signal by discrete-time Lyapunov\nanalysis, which enables the efficient off-line design of the attack signal and\nsaves computing resources. Finally, we exploit its relationship to design a\nheuristic two-stage learning-based joint attack algorithm (HTL-JA), which can\naccelerate realization of the attack target compared to the one-stage\nproximal-policy-optimization-based (PPO) algorithm. Extensive simulations are\nconducted to show the effectiveness of the injected optimal sequential attack.",
            "author": [
                "Xiaoyu Luo",
                "Haoxuan Pan",
                "Chongrong Fang",
                "Chengcheng Zhao",
                "Peng Cheng",
                "Jianping He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09933v2",
                "http://arxiv.org/pdf/2311.09933v2"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09930v2",
            "title": "A Framework for Monitoring and Retraining Language Models in Real-World\n  Applications",
            "updated": "2023-11-17T09:23:20Z",
            "published": "2023-11-16T14:32:18Z",
            "summary": "In the Machine Learning (ML) model development lifecycle, training candidate\nmodels using an offline holdout dataset and identifying the best model for the\ngiven task is only the first step. After the deployment of the selected model,\ncontinuous model monitoring and model retraining is required in many real-world\napplications. There are multiple reasons for retraining, including data or\nconcept drift, which may be reflected on the model performance as monitored by\nan appropriate metric. Another motivation for retraining is the acquisition of\nincreasing amounts of data over time, which may be used to retrain and improve\nthe model performance even in the absence of drifts. We examine the impact of\nvarious retraining decision points on crucial factors, such as model\nperformance and resource utilization, in the context of Multilabel\nClassification models. We explain our key decision points and propose a\nreference framework for designing an effective model retraining strategy.",
            "author": [
                "Jaykumar Kasundra",
                "Claudia Schulz",
                "Melicaalsadat Mirsafian",
                "Stavroula Skylaki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09930v2",
                "http://arxiv.org/pdf/2311.09930v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09922v1",
            "title": "Fast multiplication by two's complement addition of numbers represented\n  as a set of polynomial radix 2 indexes, stored as an integer list for\n  massively parallel computation",
            "updated": "2023-11-16T14:21:13Z",
            "published": "2023-11-16T14:21:13Z",
            "summary": "We demonstrate a multiplication method based on numbers represented as set of\npolynomial radix 2 indices stored as an integer list. The 'polynomial integer\nindex multiplication' method is a set of algorithms implemented in python code.\nWe demonstrate the method to be faster than both the Number Theoretic Transform\n(NTT) and Karatsuba for multiplication within a certain bit range. Also\nimplemented in python code for comparison purposes with the polynomial radix 2\ninteger method. We demonstrate that it is possible to express any integer or\nreal number as a list of integer indices, representing a finite series in base\ntwo. The finite series of integer index representation of a number can then be\nstored and distributed across multiple CPUs / GPUs. We show that operations of\naddition and multiplication can be applied as two's complement additions\noperating on the index integer representations and can be fully distributed\nacross a given CPU / GPU architecture. We demonstrate fully distributed\narithmetic operations such that the 'polynomial integer index multiplication'\nmethod overcomes the current limitation of parallel multiplication methods. Ie,\nthe need to share common core memory and common disk for the calculation of\nresults and intermediate results.",
            "author": [
                "Mark Stocks"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09922v1",
                "http://arxiv.org/pdf/2311.09922v1"
            ],
            "primary_category": "cs.MS",
            "category": [
                "cs.MS",
                "cs.DC",
                "cs.DS",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09921v1",
            "title": "Revisiting GW200129 with machine learning noise mitigation: it is\n  (still) precessing",
            "updated": "2023-11-16T14:21:11Z",
            "published": "2023-11-16T14:21:11Z",
            "summary": "GW200129 is claimed to be the first-ever observation of the spin-disk orbital\nprecession detected with gravitational waves (GWs) from an individual binary\nsystem. However, this claim warrants a cautious evaluation because the GW event\ncoincided with a broadband noise disturbance in LIGO Livingston caused by the\n45 MHz electro-optic modulator system. In this paper, we present a\nstate-of-the-art neural network that is able to model and mitigate the\nbroadband noise from the LIGO Livingston interferometer. We also demonstrate\nthat our neural network mitigates the noise better than the algorithm used by\nthe LIGO-Virgo-KAGRA collaboration. Finally, we re-analyse GW200129 with the\nimproved data quality and show that the evidence for precession is still\nobserved.",
            "author": [
                "Ronaldas Macas",
                "Andrew Lundgren",
                "Gregory Ashton"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09921v1",
                "http://arxiv.org/pdf/2311.09921v1"
            ],
            "primary_category": "gr-qc",
            "category": [
                "gr-qc",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10782v1",
            "title": "A BERT based Ensemble Approach for Sentiment Classification of Customer\n  Reviews and its Application to Nudge Marketing in e-Commerce",
            "updated": "2023-11-16T14:18:24Z",
            "published": "2023-11-16T14:18:24Z",
            "summary": "According to the literature, Product reviews are an important source of\ninformation for customers to support their buying decision. Product reviews\nimprove customer trust and loyalty. Reviews help customers in understanding\nwhat other customers think about a particular product and helps in driving\npurchase decisions. Therefore, for an e-commerce platform it is important to\nunderstand the sentiments in customer reviews to understand their products and\nservices, and it also allows them to potentially create positive consumer\ninteraction as well as long lasting relationships. Reviews also provide\ninnovative ways to market the products for an ecommerce company. One such\napproach is Nudge Marketing. Nudge marketing is a subtle way for an ecommerce\ncompany to help their customers make better decisions without hesitation.",
            "author": [
                "Sayan Putatunda",
                "Anwesha Bhowmik",
                "Girish Thiruvenkadam",
                "Rahul Ghosh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10782v1",
                "http://arxiv.org/pdf/2311.10782v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09891v1",
            "title": "On some elusive aspects of databases hindering AI based discovery: A\n  case study on superconducting materials",
            "updated": "2023-11-16T13:38:00Z",
            "published": "2023-11-16T13:38:00Z",
            "summary": "It stands to reason that the amount and the quality of big data is of key\nimportance for setting up accurate AI-driven models. Nonetheless, we believe\nthere are still critical roadblocks in the inherent generation of databases,\nthat are often underestimated and poorly discussed in the literature. In our\nview, such issues can seriously hinder the AI-based discovery process, even\nwhen high quality, sufficiently large and highly reputable data sources are\navailable. Here, considering superconducting and thermoelectric materials as\ntwo representative case studies, we specifically discuss three aspects, namely\nintrinsically biased sample selection, possible hidden variables, disparate\ndata age. Importantly, to our knowledge, we suggest and test a first strategy\ncapable of detecting and quantifying the presence of the intrinsic data bias.",
            "author": [
                "Giovanni Trezza",
                "Eliodoro Chiavazzo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09891v1",
                "http://arxiv.org/pdf/2311.09891v1"
            ],
            "primary_category": "cond-mat.other",
            "category": [
                "cond-mat.other",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16169v1",
            "title": "Understanding the Effectiveness of Large Language Models in Detecting\n  Security Vulnerabilities",
            "updated": "2023-11-16T13:17:20Z",
            "published": "2023-11-16T13:17:20Z",
            "summary": "Security vulnerabilities in modern software are prevalent and harmful. While\nautomated vulnerability detection tools have made promising progress, their\nscalability and applicability remain challenging. Recently, Large Language\nModels (LLMs), such as GPT-4 and CodeLlama, have demonstrated remarkable\nperformance on code-related tasks. However, it is unknown whether such LLMs can\ndo complex reasoning over code. In this work, we explore whether pre-trained\nLLMs can detect security vulnerabilities and address the limitations of\nexisting tools. We evaluate the effectiveness of pre-trained LLMs on a set of\nfive diverse security benchmarks spanning two languages, Java and C/C++, and\nincluding code samples from synthetic and real-world projects. We evaluate the\neffectiveness of LLMs in terms of their performance, explainability, and\nrobustness.\n  By designing a series of effective prompting strategies, we obtain the best\nresults on the synthetic datasets with GPT-4: F1 scores of 0.79 on OWASP, 0.86\non Juliet Java, and 0.89 on Juliet C/C++. Expectedly, the performance of LLMs\ndrops on the more challenging real-world datasets: CVEFixes Java and CVEFixes\nC/C++, with GPT-4 reporting F1 scores of 0.48 and 0.62, respectively. We show\nthat LLMs can often perform better than existing static analysis and deep\nlearning-based vulnerability detection tools, especially for certain classes of\nvulnerabilities. Moreover, LLMs also often provide reliable explanations,\nidentifying the vulnerable data flows in code. We find that fine-tuning smaller\nLLMs can outperform the larger LLMs on synthetic datasets but provide limited\ngains on real-world datasets. When subjected to adversarial attacks on code,\nLLMs show mild degradation, with average accuracy reduction of up to 12.67%.\nFinally, we share our insights and recommendations for future work on\nleveraging LLMs for vulnerability detection.",
            "author": [
                "Avishree Khare",
                "Saikat Dutta",
                "Ziyang Li",
                "Alaia Solko-Breslin",
                "Rajeev Alur",
                "Mayur Naik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16169v1",
                "http://arxiv.org/pdf/2311.16169v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.PL",
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09878v1",
            "title": "Safety Aware Autonomous Path Planning Using Model Predictive\n  Reinforcement Learning for Inland Waterways",
            "updated": "2023-11-16T13:12:58Z",
            "published": "2023-11-16T13:12:58Z",
            "summary": "In recent years, interest in autonomous shipping in urban waterways has\nincreased significantly due to the trend of keeping cars and trucks out of city\ncenters. Classical approaches such as Frenet frame based planning and potential\nfield navigation often require tuning of many configuration parameters and\nsometimes even require a different configuration depending on the situation. In\nthis paper, we propose a novel path planning approach based on reinforcement\nlearning called Model Predictive Reinforcement Learning (MPRL). MPRL calculates\na series of waypoints for the vessel to follow. The environment is represented\nas an occupancy grid map, allowing us to deal with any shape of waterway and\nany number and shape of obstacles. We demonstrate our approach on two scenarios\nand compare the resulting path with path planning using a Frenet frame and path\nplanning based on a proximal policy optimization (PPO) agent. Our results show\nthat MPRL outperforms both baselines in both test scenarios. The PPO based\napproach was not able to reach the goal in either scenario while the Frenet\nframe approach failed in the scenario consisting of a corner with obstacles.\nMPRL was able to safely (collision free) navigate to the goal in both of the\ntest scenarios.",
            "author": [
                "Astrid Vanneste",
                "Simon Vanneste",
                "Olivier Vasseur",
                "Robin Janssens",
                "Mattias Billast",
                "Ali Anwar",
                "Kevin Mets",
                "Tom De Schepper",
                "Siegfried Mercelis",
                "Peter Hellinckx"
            ],
            "link": [
                "http://dx.doi.org/10.1109/IECON49645.2022.9968678",
                "http://arxiv.org/abs/2311.09878v1",
                "http://arxiv.org/pdf/2311.09878v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10126v1",
            "title": "I&S-ViT: An Inclusive & Stable Method for Pushing the Limit of\n  Post-Training ViTs Quantization",
            "updated": "2023-11-16T13:07:47Z",
            "published": "2023-11-16T13:07:47Z",
            "summary": "Albeit the scalable performance of vision transformers (ViTs), the dense\ncomputational costs (training & inference) undermine their position in\nindustrial applications. Post-training quantization (PTQ), tuning ViTs with a\ntiny dataset and running in a low-bit format, well addresses the cost issue but\nunluckily bears more performance drops in lower-bit cases. In this paper, we\nintroduce I&S-ViT, a novel method that regulates the PTQ of ViTs in an\ninclusive and stable fashion. I&S-ViT first identifies two issues in the PTQ of\nViTs: (1) Quantization inefficiency in the prevalent log2 quantizer for\npost-Softmax activations; (2) Rugged and magnified loss landscape in\ncoarse-grained quantization granularity for post-LayerNorm activations. Then,\nI&S-ViT addresses these issues by introducing: (1) A novel shift-uniform-log2\nquantizer (SULQ) that incorporates a shift mechanism followed by uniform\nquantization to achieve both an inclusive domain representation and accurate\ndistribution approximation; (2) A three-stage smooth optimization strategy\n(SOS) that amalgamates the strengths of channel-wise and layer-wise\nquantization to enable stable learning. Comprehensive evaluations across\ndiverse vision tasks validate I&S-ViT' superiority over existing PTQ of ViTs\nmethods, particularly in low-bit scenarios. For instance, I&S-ViT elevates the\nperformance of 3-bit ViT-B by an impressive 50.68%.",
            "author": [
                "Yunshan Zhong",
                "Jiawei Hu",
                "Mingbao Lin",
                "Mengzhao Chen",
                "Rongrong Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10126v1",
                "http://arxiv.org/pdf/2311.10126v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09860v1",
            "title": "GSAP-NER: A Novel Task, Corpus, and Baseline for Scholarly Entity\n  Extraction Focused on Machine Learning Models and Datasets",
            "updated": "2023-11-16T12:43:02Z",
            "published": "2023-11-16T12:43:02Z",
            "summary": "Named Entity Recognition (NER) models play a crucial role in various NLP\ntasks, including information extraction (IE) and text understanding. In\nacademic writing, references to machine learning models and datasets are\nfundamental components of various computer science publications and necessitate\naccurate models for identification. Despite the advancements in NER, existing\nground truth datasets do not treat fine-grained types like ML model and model\narchitecture as separate entity types, and consequently, baseline models cannot\nrecognize them as such. In this paper, we release a corpus of 100 manually\nannotated full-text scientific publications and a first baseline model for 10\nentity types centered around ML models and datasets. In order to provide a\nnuanced understanding of how ML models and datasets are mentioned and utilized,\nour dataset also contains annotations for informal mentions like \"our\nBERT-based model\" or \"an image CNN\". You can find the ground truth dataset and\ncode to replicate model training at https://data.gesis.org/gsap/gsap-ner.",
            "author": [
                "Wolfgang Otto",
                "Matth\u00e4us Zloch",
                "Lu Gan",
                "Saurav Karmakar",
                "Stefan Dietze"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09860v1",
                "http://arxiv.org/pdf/2311.09860v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09858v1",
            "title": "Polynomially Over-Parameterized Convolutional Neural Networks Contain\n  Structured Strong Winning Lottery Tickets",
            "updated": "2023-11-16T12:38:45Z",
            "published": "2023-11-16T12:38:45Z",
            "summary": "The Strong Lottery Ticket Hypothesis (SLTH) states that randomly-initialised\nneural networks likely contain subnetworks that perform well without any\ntraining. Although unstructured pruning has been extensively studied in this\ncontext, its structured counterpart, which can deliver significant\ncomputational and memory efficiency gains, has been largely unexplored. One of\nthe main reasons for this gap is the limitations of the underlying mathematical\ntools used in formal analyses of the SLTH. In this paper, we overcome these\nlimitations: we leverage recent advances in the multidimensional generalisation\nof the Random Subset-Sum Problem and obtain a variant that admits the\nstochastic dependencies that arise when addressing structured pruning in the\nSLTH. We apply this result to prove, for a wide class of random Convolutional\nNeural Networks, the existence of structured subnetworks that can approximate\nany sufficiently smaller network.\n  This result provides the first sub-exponential bound around the SLTH for\nstructured pruning, opening up new avenues for further research on the\nhypothesis and contributing to the understanding of the role of\nover-parameterization in deep learning.",
            "author": [
                "Arthur da Cunha",
                "Francesco d'Amore",
                "Emanuele Natale"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09858v1",
                "http://arxiv.org/pdf/2311.09858v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09856v1",
            "title": "Contribution Evaluation in Federated Learning: Examining Current\n  Approaches",
            "updated": "2023-11-16T12:32:44Z",
            "published": "2023-11-16T12:32:44Z",
            "summary": "Federated Learning (FL) has seen increasing interest in cases where entities\nwant to collaboratively train models while maintaining privacy and governance\nover their data. In FL, clients with private and potentially heterogeneous data\nand compute resources come together to train a common model without raw data\never leaving their locale. Instead, the participants contribute by sharing\nlocal model updates, which, naturally, differ in quality. Quantitatively\nevaluating the worth of these contributions is termed the Contribution\nEvaluation (CE) problem. We review current CE approaches from the underlying\nmathematical framework to efficiently calculate a fair value for each client.\nFurthermore, we benchmark some of the most promising state-of-the-art\napproaches, along with a new one we introduce, on MNIST and CIFAR-10, to\nshowcase their differences. Designing a fair and efficient CE method, while a\nsmall part of the overall FL system design, is tantamount to the mainstream\nadoption of FL.",
            "author": [
                "Vasilis Siomos",
                "Jonathan Passerat-Palmbach"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09856v1",
                "http://arxiv.org/pdf/2311.09856v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09854v1",
            "title": "SurvTimeSurvival: Survival Analysis On The Patient With Multiple\n  Visits/Records",
            "updated": "2023-11-16T12:30:14Z",
            "published": "2023-11-16T12:30:14Z",
            "summary": "The accurate prediction of survival times for patients with severe diseases\nremains a critical challenge despite recent advances in artificial\nintelligence. This study introduces \"SurvTimeSurvival: Survival Analysis On\nPatients With Multiple Visits/Records\", utilizing the Transformer model to not\nonly handle the complexities of time-varying covariates but also covariates\ndata. We also tackle the data sparsity issue common to survival analysis\ndatasets by integrating synthetic data generation into the learning process of\nour model. We show that our method outperforms state-of-the-art deep learning\napproaches on both covariates and time-varying covariates datasets. Our\napproach aims not only to enhance the understanding of individual patient\nsurvival trajectories across various medical conditions, thereby improving\nprediction accuracy, but also to play a pivotal role in designing clinical\ntrials and creating new treatments.",
            "author": [
                "Hung Le",
                "Ong Eng-Jon",
                "Bober Miroslaw"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09854v1",
                "http://arxiv.org/pdf/2311.09854v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.NA",
                "math.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09852v1",
            "title": "Short vs. Long-term Coordination of Drones: When Distributed\n  Optimization Meets Deep Reinforcement Learning",
            "updated": "2023-11-16T12:28:31Z",
            "published": "2023-11-16T12:28:31Z",
            "summary": "Swarms of smart drones, with the support of charging technology, can provide\ncompleting sensing capabilities in Smart Cities, such as traffic monitoring and\ndisaster response. Existing approaches, including distributed optimization and\ndeep reinforcement learning (DRL), aim to coordinate drones to achieve\ncost-effective, high-quality navigation, sensing, and recharging. However, they\nhave distinct challenges: short-term optimization struggles to provide\nsustained benefits, while long-term DRL lacks scalability, resilience, and\nflexibility. To bridge this gap, this paper introduces a new progressive\napproach that encompasses the planning and selection based on distributed\noptimization, as well as DRL-based flying direction scheduling. Extensive\nexperiment with datasets generated from realisitic urban mobility demonstrate\nthe outstanding performance of the proposed solution in traffic monitoring\ncompared to three baseline methods.",
            "author": [
                "Chuhao Qin",
                "Evangelos Pournaras"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09852v1",
                "http://arxiv.org/pdf/2311.09852v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.LG",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09851v1",
            "title": "Urban traffic congestion control: a DeePC change",
            "updated": "2023-11-16T12:26:55Z",
            "published": "2023-11-16T12:26:55Z",
            "summary": "Urban traffic congestion remains a pressing challenge in our rapidly\nexpanding cities, despite the abundance of available data and the efforts of\npolicymakers. By leveraging behavioral system theory and data-driven control,\nthis paper exploits the DeePC algorithm in the context of urban traffic control\nperformed via dynamic traffic lights. To validate our approach, we consider a\nhigh-fidelity case study using the state-of-the-art simulation software package\nSimulation of Urban MObility (SUMO). Preliminary results indicate that DeePC\noutperforms existing approaches across various key metrics, including travel\ntime and CO$_2$ emissions, demonstrating its potential for effective traffic\nmanagement",
            "author": [
                "Alessio Rimoldi",
                "Carlo Cenedese",
                "Alberto Padoan",
                "Florian D\u00f6rfler",
                "John Lygeros"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09851v1",
                "http://arxiv.org/pdf/2311.09851v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09850v1",
            "title": "Semantic-Relay-Aided Text Transmission: Placement Optimization and\n  Bandwidth Allocation",
            "updated": "2023-11-16T12:23:49Z",
            "published": "2023-11-16T12:23:49Z",
            "summary": "Semantic communication has emerged as a promising technology to break the\nShannon limit by extracting the meaning of source data and sending relevant\nsemantic information only. However, some mobile devices may have limited\ncomputation and storage resources, which renders it difficult to deploy and\nimplement the resource-demanding deep learning based semantic encoder/decoder.\nTo tackle this challenge, we propose in this paper a new semantic relay\n(SemRelay), which is equipped with a semantic receiver for assisting text\ntransmission from a resource-abundant base station (BS) to a\nresource-constrained mobile device. Specifically, the SemRelay first decodes\nthe semantic information sent by the BS (with a semantic transmitter) and then\nforwards it to the user by adopting conventional bit transmission, hence\neffectively improving the text transmission efficiency. We formulate an\noptimization problem to maximize the achievable (effective) bit rate by jointly\ndesigning the SemRelay placement and bandwidth allocation. Although this\nproblem is non-convex and generally difficult to solve, we propose an efficient\npenalty-based algorithm to obtain a high-quality suboptimal solution. Numerical\nresults show the close-to-optimal performance of the proposed algorithm as well\nas significant rate performance gain of the proposed SemRelay over conventional\ndecode-and-forward relay.",
            "author": [
                "Tianyu Liu",
                "Changsheng You",
                "Zeyang Hu",
                "Chenyu Wu",
                "Yi Gong",
                "Kaibin Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09850v1",
                "http://arxiv.org/pdf/2311.09850v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09848v1",
            "title": "Diffusion-Augmented Neural Processes",
            "updated": "2023-11-16T12:21:06Z",
            "published": "2023-11-16T12:21:06Z",
            "summary": "Over the last few years, Neural Processes have become a useful modelling tool\nin many application areas, such as healthcare and climate sciences, in which\ndata are scarce and prediction uncertainty estimates are indispensable.\nHowever, the current state of the art in the field (AR CNPs; Bruinsma et al.,\n2023) presents a few issues that prevent its widespread deployment. This work\nproposes an alternative, diffusion-based approach to NPs which, through\nconditioning on noised datasets, addresses many of these limitations, whilst\nalso exceeding SOTA performance.",
            "author": [
                "Lorenzo Bonito",
                "James Requeima",
                "Aliaksandra Shysheya",
                "Richard E. Turner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09848v1",
                "http://arxiv.org/pdf/2311.09848v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09847v1",
            "title": "Overcoming Data Scarcity in Biomedical Imaging with a Foundational\n  Multi-Task Model",
            "updated": "2023-11-16T12:20:25Z",
            "published": "2023-11-16T12:20:25Z",
            "summary": "Foundational models, pretrained on a large scale, have demonstrated\nsubstantial success across non-medical domains. However, training these models\ntypically requires large, comprehensive datasets, which contrasts with the\nsmaller and more heterogeneous datasets common in biomedical imaging. Here, we\npropose a multi-task learning strategy that decouples the number of training\ntasks from memory requirements. We trained a Universal bioMedical PreTrained\nmodel (UMedPT) on a multi-task database including tomographic, microscopic, and\nX-ray images, with various labelling strategies such as classification,\nsegmentation, and object detection. The UMedPT foundational model outperformed\nImageNet pretraining and the previous state-of-the-art models. For tasks\nrelated to the pretraining database, it maintained its performance with only 1%\nof the original training data and without fine-tuning. For out-of-domain tasks\nit required not more than 50% of the original training data. In an external\nindependent validation imaging features extracted using UMedPT proved to be a\nnew standard for cross-center transferability.",
            "author": [
                "Raphael Sch\u00e4fer",
                "Till Nicke",
                "Henning H\u00f6fener",
                "Annkristin Lange",
                "Dorit Merhof",
                "Friedrich Feuerhake",
                "Volkmar Schulz",
                "Johannes Lotz",
                "Fabian Kiessling"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09847v1",
                "http://arxiv.org/pdf/2311.09847v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09846v1",
            "title": "GroupMixer: Patch-based Group Convolutional Neural Network for Breast\n  Cancer Detection from Histopathological Images",
            "updated": "2023-11-16T12:19:48Z",
            "published": "2023-11-16T12:19:48Z",
            "summary": "Diagnosis of breast cancer malignancy at the early stages is a crucial step\nfor controlling its side effects. Histopathological analysis provides a unique\nopportunity for malignant breast cancer detection. However, such a task would\nbe tedious and time-consuming for the histopathologists. Deep Neural Networks\nenable us to learn informative features directly from raw histopathological\nimages without manual feature extraction. Although Convolutional Neural\nNetworks (CNNs) have been the dominant architectures in the computer vision\nrealm, Transformer-based architectures have shown promising results in\ndifferent computer vision tasks. Although harnessing the capability of\nTransformer-based architectures for medical image analysis seems interesting,\nthese architectures are large, have a significant number of trainable\nparameters, and require large datasets to be trained on, which are usually rare\nin the medical domain. It has been claimed and empirically proved that at least\npart of the superior performance of Transformer-based architectures in Computer\nVision domain originates from patch embedding operation. In this paper, we\nborrowed the previously introduced idea of integrating a fully Convolutional\nNeural Network architecture with Patch Embedding operation and presented an\nefficient CNN architecture for breast cancer malignancy detection from\nhistopathological images. Despite the number of parameters that is\nsignificantly smaller than other methods, the accuracy performance metrics\nachieved 97.65%, 98.92%, 99.21%, and 98.01% for 40x, 100x, 200x, and 400x\nmagnifications respectively. We took a step forward and modified the\narchitecture using Group Convolution and Channel Shuffling ideas and reduced\nthe number of trainable parameters even more with a negligible decline in\nperformance and achieved 95.42%, 98.16%, 96.05%, and 97.92% accuracy for the\nmentioned magnifications respectively.",
            "author": [
                "Ardavan Modarres",
                "Erfan Ebrahim Esfahani",
                "Mahsa Bahrami"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09846v1",
                "http://arxiv.org/pdf/2311.09846v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09841v1",
            "title": "Leveraging LLMs in Scholarly Knowledge Graph Question Answering",
            "updated": "2023-11-16T12:13:49Z",
            "published": "2023-11-16T12:13:49Z",
            "summary": "This paper presents a scholarly Knowledge Graph Question Answering (KGQA)\nthat answers bibliographic natural language questions by leveraging a large\nlanguage model (LLM) in a few-shot manner. The model initially identifies the\ntop-n similar training questions related to a given test question via a\nBERT-based sentence encoder and retrieves their corresponding SPARQL. Using the\ntop-n similar question-SPARQL pairs as an example and the test question creates\na prompt. Then pass the prompt to the LLM and generate a SPARQL. Finally, runs\nthe SPARQL against the underlying KG - ORKG (Open Research KG) endpoint and\nreturns an answer. Our system achieves an F1 score of 99.0%, on SciQA - one of\nthe Scholarly-QALD-23 challenge benchmarks.",
            "author": [
                "Tilahun Abedissa Taffa",
                "Ricardo Usbeck"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09841v1",
                "http://arxiv.org/pdf/2311.09841v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.DB",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09835v1",
            "title": "ML-Bench: Large Language Models Leverage Open-source Libraries for\n  Machine Learning Tasks",
            "updated": "2023-11-16T12:03:21Z",
            "published": "2023-11-16T12:03:21Z",
            "summary": "Large language models have shown promising performance in code generation\nbenchmarks. However, a considerable divide exists between these benchmark\nachievements and their practical applicability, primarily attributed to\nreal-world programming's reliance on pre-existing libraries. Instead of\nevaluating LLMs to code from scratch, this work aims to propose a new\nevaluation setup where LLMs use open-source libraries to finish machine\nlearning tasks. Therefore, we propose ML-Bench, an expansive benchmark\ndeveloped to assess the effectiveness of LLMs in leveraging existing functions\nin open-source libraries. Consisting of 10044 samples spanning 130 tasks over\n14 notable machine learning GitHub repositories. In this setting, given a\nspecific machine learning task instruction and the accompanying README in a\ncodebase, an LLM is tasked to generate code to accomplish the task. This\nnecessitates the comprehension of long and language-code interleaved documents,\nas well as the understanding of complex cross-file code structures, introducing\nnew challenges. Notably, while GPT-4 exhibits remarkable improvement over other\nLLMs, it manages to accomplish only 39.73\\% of the tasks, leaving a huge space\nfor improvement. We address these challenges by proposing ML-Agent, designed to\neffectively navigate the codebase, locate documentation, retrieve code, and\ngenerate executable code. Empirical results demonstrate that ML-Agent, built\nupon GPT-4, results in further improvements. Code, data, and models are\navailable at \\url{https://ml-bench.github.io/}.",
            "author": [
                "Yuliang Liu",
                "Xiangru Tang",
                "Zefan Cai",
                "Junjie Lu",
                "Yichi Zhang",
                "Yanjun Shao",
                "Zexuan Deng",
                "Helan Hu",
                "Zengxian Yang",
                "Kaikai An",
                "Ruijun Huang",
                "Shuzheng Si",
                "Sheng Chen",
                "Haozhe Zhao",
                "Zhengliang Li",
                "Liang Chen",
                "Yiming Zong",
                "Yan Wang",
                "Tianyu Liu",
                "Zhiwei Jiang",
                "Baobao Chang",
                "Yujia Qin",
                "Wangchunshu Zhou",
                "Yilun Zhao",
                "Arman Cohan",
                "Mark Gerstein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09835v1",
                "http://arxiv.org/pdf/2311.09835v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09825v1",
            "title": "Human Still Wins over LLM: An Empirical Study of Active Learning on\n  Domain-Specific Annotation Tasks",
            "updated": "2023-11-16T11:51:13Z",
            "published": "2023-11-16T11:51:13Z",
            "summary": "Large Language Models (LLMs) have demonstrated considerable advances, and\nseveral claims have been made about their exceeding human performance. However,\nin real-world tasks, domain knowledge is often required. Low-resource learning\nmethods like Active Learning (AL) have been proposed to tackle the cost of\ndomain expert annotation, raising this question: Can LLMs surpass compact\nmodels trained with expert annotations in domain-specific tasks? In this work,\nwe conduct an empirical experiment on four datasets from three different\ndomains comparing SOTA LLMs with small models trained on expert annotations\nwith AL. We found that small models can outperform GPT-3.5 with a few hundreds\nof labeled data, and they achieve higher or similar performance with GPT-4\ndespite that they are hundreds time smaller. Based on these findings, we posit\nthat LLM predictions can be used as a warmup method in real-world applications\nand human experts remain indispensable in tasks involving data annotation\ndriven by domain-specific knowledge.",
            "author": [
                "Yuxuan Lu",
                "Bingsheng Yao",
                "Shao Zhang",
                "Yun Wang",
                "Peng Zhang",
                "Tun Lu",
                "Toby Jia-Jun Li",
                "Dakuo Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09825v1",
                "http://arxiv.org/pdf/2311.09825v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09819v1",
            "title": "PWISeg: Point-based Weakly-supervised Instance Segmentation for Surgical\n  Instruments",
            "updated": "2023-11-16T11:48:29Z",
            "published": "2023-11-16T11:48:29Z",
            "summary": "In surgical procedures, correct instrument counting is essential. Instance\nsegmentation is a location method that locates not only an object's bounding\nbox but also each pixel's specific details. However, obtaining mask-level\nannotations is labor-intensive in instance segmentation. To address this issue,\nwe propose a novel yet effective weakly-supervised surgical instrument instance\nsegmentation approach, named Point-based Weakly-supervised Instance\nSegmentation (PWISeg). PWISeg adopts an FCN-based architecture with\npoint-to-box and point-to-mask branches to model the relationships between\nfeature points and bounding boxes, as well as feature points and segmentation\nmasks on FPN, accomplishing instrument detection and segmentation jointly in a\nsingle model. Since mask level annotations are hard to available in the real\nworld, for point-to-mask training, we introduce an unsupervised projection\nloss, utilizing the projected relation between predicted masks and bboxes as\nsupervision signal. On the other hand, we annotate a few pixels as the key\npixel for each instrument. Based on this, we further propose a key pixel\nassociation loss and a key pixel distribution loss, driving the point-to-mask\nbranch to generate more accurate segmentation predictions. To comprehensively\nevaluate this task, we unveil a novel surgical instrument dataset with manual\nannotations, setting up a benchmark for further research. Our comprehensive\nresearch trial validated the superior performance of our PWISeg. The results\nshow that the accuracy of surgical instrument segmentation is improved,\nsurpassing most methods of instance segmentation via weakly supervised bounding\nboxes. This improvement is consistently observed in our proposed dataset and\nwhen applied to the public HOSPI-Tools dataset.",
            "author": [
                "Zhen Sun",
                "Huan Xu",
                "Jinlin Wu",
                "Zhen Chen",
                "Zhen Lei",
                "Hongbin Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09819v1",
                "http://arxiv.org/pdf/2311.09819v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09817v1",
            "title": "Neural-Logic Human-Object Interaction Detection",
            "updated": "2023-11-16T11:47:53Z",
            "published": "2023-11-16T11:47:53Z",
            "summary": "The interaction decoder utilized in prevalent Transformer-based HOI detectors\ntypically accepts pre-composed human-object pairs as inputs. Though achieving\nremarkable performance, such paradigm lacks feasibility and cannot explore\nnovel combinations over entities during decoding. We present L OGIC HOI, a new\nHOI detector that leverages neural-logic reasoning and Transformer to infer\nfeasible interactions between entities. Specifically, we modify the\nself-attention mechanism in vanilla Transformer, enabling it to reason over the\n<human, action, object> triplet and constitute novel interactions. Meanwhile,\nsuch reasoning process is guided by two crucial properties for understanding\nHOI: affordances (the potential actions an object can facilitate) and proxemics\n(the spatial relations between humans and objects). We formulate these two\nproperties in first-order logic and ground them into continuous space to\nconstrain the learning process of our approach, leading to improved performance\nand zero-shot generalization capabilities. We evaluate L OGIC HOI on V-COCO and\nHICO-DET under both normal and zero-shot setups, achieving significant\nimprovements over existing methods.",
            "author": [
                "Liulei Li",
                "Jianan Wei",
                "Wenguan Wang",
                "Yi Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09817v1",
                "http://arxiv.org/pdf/2311.09817v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09816v1",
            "title": "Performance Trade-offs of Watermarking Large Language Models",
            "updated": "2023-11-16T11:44:58Z",
            "published": "2023-11-16T11:44:58Z",
            "summary": "Amidst growing concerns of large language models (LLMs) being misused for\ngenerating misinformation or completing homework assignments, watermarking has\nemerged as an effective solution for distinguishing human-written and\nLLM-generated text. A prominent watermarking strategy is to embed a signal into\ngenerated text by upsampling a (pseudorandomly-chosen) subset of tokens at\nevery generation step. Although this signal is imperceptible to a human reader,\nit is detectable through statistical testing. However, implanting such signals\nalters the model's output distribution and can have unintended effects when\nwatermarked LLMs are used for downstream applications. In this work, we\nevaluate the performance of watermarked LLMs on a diverse suite of tasks,\nincluding text classification, textual entailment, reasoning, question\nanswering, translation, summarization, and language modeling. We find that\nwatermarking has negligible impact on the performance of tasks posed as k-class\nclassification problems in the average case. However, the accuracy can plummet\nto that of a random classifier for some scenarios (that occur with\nnon-negligible probability). Tasks that are cast as multiple-choice questions\nand short-form generation are surprisingly unaffected by watermarking. For\nlong-form generation tasks, including summarization and translation, we see a\ndrop of 15-20% in the performance due to watermarking. Our findings highlight\nthe trade-offs that users should be cognizant of when using watermarked models,\nand point to cases where future research could improve existing trade-offs.",
            "author": [
                "Anirudh Ajith",
                "Sameer Singh",
                "Danish Pruthi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09816v1",
                "http://arxiv.org/pdf/2311.09816v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09811v1",
            "title": "Runtime Verification of Learning Properties for Reinforcement Learning\n  Algorithms",
            "updated": "2023-11-16T11:34:37Z",
            "published": "2023-11-16T11:34:37Z",
            "summary": "Reinforcement learning (RL) algorithms interact with their environment in a\ntrial-and-error fashion. Such interactions can be expensive, inefficient, and\ntimely when learning on a physical system rather than in a simulation. This\nwork develops new runtime verification techniques to predict when the learning\nphase has not met or will not meet qualitative and timely expectations. This\npaper presents three verification properties concerning the quality and\ntimeliness of learning in RL algorithms. With each property, we propose design\nsteps for monitoring and assessing the properties during the system's\noperation.",
            "author": [
                "Tommaso Mannucci",
                "Julio de Oliveira Filho"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.395.15",
                "http://arxiv.org/abs/2311.09811v1",
                "http://arxiv.org/pdf/2311.09811v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09809v1",
            "title": "Comparing Differentiable Logics for Learning Systems: A Research Preview",
            "updated": "2023-11-16T11:33:08Z",
            "published": "2023-11-16T11:33:08Z",
            "summary": "Extensive research on formal verification of machine learning (ML) systems\nindicates that learning from data alone often fails to capture underlying\nbackground knowledge. A variety of verifiers have been developed to ensure that\na machine-learnt model satisfies correctness and safety properties, however,\nthese verifiers typically assume a trained network with fixed weights.\nML-enabled autonomous systems are required to not only detect incorrect\npredictions, but should also possess the ability to self-correct, continuously\nimproving and adapting. A promising approach for creating ML models that\ninherently satisfy constraints is to encode background knowledge as logical\nconstraints that guide the learning process via so-called differentiable\nlogics. In this research preview, we compare and evaluate various logics from\nthe literature in weakly-supervised contexts, presenting our findings and\nhighlighting open problems for future work. Our experimental results are\nbroadly consistent with results reported previously in literature; however,\nlearning with differentiable logics introduces a new hyperparameter that is\ndifficult to tune and has significant influence on the effectiveness of the\nlogics.",
            "author": [
                "Thomas Flinkow",
                "Barak A. Pearlmutter",
                "Rosemary Monahan"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.395.3",
                "http://arxiv.org/abs/2311.09809v1",
                "http://arxiv.org/pdf/2311.09809v1"
            ],
            "primary_category": "cs.LO",
            "category": [
                "cs.LO",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09808v1",
            "title": "PixT3: Pixel-based Table To Text generation",
            "updated": "2023-11-16T11:32:47Z",
            "published": "2023-11-16T11:32:47Z",
            "summary": "Table-to-Text has been traditionally approached as a linear language to text\nproblem. However, visually represented tables are rich in visual information\nand serve as a concise, effective form of representing data and its\nrelationships. When using text-based approaches, after the linearization\nprocess, this information is either lost or represented in a space inefficient\nmanner. This inefficiency has remained a constant challenge for text-based\napproaches making them struggle with large tables. In this paper, we\ndemonstrate that image representation of tables are more space-efficient than\nthe typical textual linearizations, and multi-modal approaches are competitive\nin Table-to-Text tasks. We present PixT3, a multimodal table-to-text model that\noutperforms the state-of-the-art (SotA) in the ToTTo benchmark in a pure\nTable-to-Text setting while remaining competitive in controlled Table-to-Text\nscenarios. It also generalizes better in unseen datasets, outperforming ToTTo\nSotA in all generation settings. Additionally, we introduce a new intermediate\ntraining curriculum to reinforce table structural awareness, leading to\nimproved generation and overall faithfulness of the models.",
            "author": [
                "I\u00f1igo Alonso",
                "Eneko Agirre",
                "Mirella Lapata"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09808v1",
                "http://arxiv.org/pdf/2311.09808v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09806v2",
            "title": "EvaSurf: Efficient View-Aware Implicit Textured Surface Reconstruction\n  on Mobile Devices",
            "updated": "2023-11-18T07:30:54Z",
            "published": "2023-11-16T11:30:56Z",
            "summary": "Reconstructing real-world 3D objects has numerous applications in computer\nvision, such as virtual reality, video games, and animations. Ideally, 3D\nreconstruction methods should generate high-fidelity results with 3D\nconsistency in real-time. Traditional methods match pixels between images using\nphoto-consistency constraints or learned features, while differentiable\nrendering methods like Neural Radiance Fields (NeRF) use differentiable volume\nrendering or surface-based representation to generate high-fidelity scenes.\nHowever, these methods require excessive runtime for rendering, making them\nimpractical for daily applications. To address these challenges, we present\n$\\textbf{EvaSurf}$, an $\\textbf{E}$fficient $\\textbf{V}$iew-$\\textbf{A}$ware\nimplicit textured $\\textbf{Surf}$ace reconstruction method on mobile devices.\nIn our method, we first employ an efficient surface-based model with a\nmulti-view supervision module to ensure accurate mesh reconstruction. To enable\nhigh-fidelity rendering, we learn an implicit texture embedded with a set of\nGaussian lobes to capture view-dependent information. Furthermore, with the\nexplicit geometry and the implicit texture, we can employ a lightweight neural\nshader to reduce the expense of computation and further support real-time\nrendering on common mobile devices. Extensive experiments demonstrate that our\nmethod can reconstruct high-quality appearance and accurate mesh on both\nsynthetic and real-world datasets. Moreover, our method can be trained in just\n1-2 hours using a single GPU and run on mobile devices at over 40 FPS (Frames\nPer Second), with a final package required for rendering taking up only 40-50\nMB.",
            "author": [
                "Jingnan Gao",
                "Zhuo Chen",
                "Yichao Yan",
                "Bowen Pan",
                "Zhe Wang",
                "Jiangjing Lyu",
                "Xiaokang Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09806v2",
                "http://arxiv.org/pdf/2311.09806v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09803v1",
            "title": "Learning effects in variable autonomy human-robot systems: how much\n  training is enough?",
            "updated": "2023-11-16T11:26:51Z",
            "published": "2023-11-16T11:26:51Z",
            "summary": "This paper investigates learning effects and human operator training\npractices in variable autonomy robotic systems. These factors are known to\naffect performance of a human-robot system and are frequently overlooked. We\npresent the results from an experiment inspired by a search and rescue scenario\nin which operators remotely controlled a mobile robot with either\nHuman-Initiative (HI) or Mixed-Initiative (MI) control. Evidence suggests\nlearning in terms of primary navigation task and secondary (distractor) task\nperformance. Further evidence is provided that MI and HI performance in a pure\nnavigation task is equal. Lastly, guidelines are proposed for experimental\ndesign and operator training practices.",
            "author": [
                "Manolis Chiou",
                "Mohammed Talha",
                "Rustam Stolkin"
            ],
            "link": [
                "http://dx.doi.org/10.1109/SMC.2019.8914558",
                "http://arxiv.org/abs/2311.09803v1",
                "http://arxiv.org/pdf/2311.09803v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09793v1",
            "title": "Fossil 2.0: Formal Certificate Synthesis for the Verification and\n  Control of Dynamical Models",
            "updated": "2023-11-16T11:18:21Z",
            "published": "2023-11-16T11:18:21Z",
            "summary": "This paper presents Fossil 2.0, a new major release of a software tool for\nthe synthesis of certificates (e.g., Lyapunov and barrier functions) for\ndynamical systems modelled as ordinary differential and difference equations.\nFossil 2.0 is much improved from its original release, including new\ninterfaces, a significantly expanded certificate portfolio, controller\nsynthesis and enhanced extensibility. We present these new features as part of\nthis tool paper. Fossil implements a counterexample-guided inductive synthesis\n(CEGIS) loop ensuring the soundness of the method. Our tool uses neural\nnetworks as templates to generate candidate functions, which are then formally\nproven by an SMT solver acting as an assertion verifier. Improvements with\nrespect to the first release include a wider range of certificates, synthesis\nof control laws, and support for discrete-time models.",
            "author": [
                "Alec Edwards",
                "Andrea Peruffo",
                "Alessandro Abate"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09793v1",
                "http://arxiv.org/pdf/2311.09793v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.LO",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09790v3",
            "title": "Breaking Boundaries: Balancing Performance and Robustness in Deep\n  Wireless Traffic Forecasting",
            "updated": "2023-11-28T15:53:00Z",
            "published": "2023-11-16T11:10:38Z",
            "summary": "Balancing the trade-off between accuracy and robustness is a long-standing\nchallenge in time series forecasting. While most of existing robust algorithms\nhave achieved certain suboptimal performance on clean data, sustaining the same\nperformance level in the presence of data perturbations remains extremely hard.\nIn this paper, we study a wide array of perturbation scenarios and propose\nnovel defense mechanisms against adversarial attacks using real-world telecom\ndata. We compare our strategy against two existing adversarial training\nalgorithms under a range of maximal allowed perturbations, defined using\n$\\ell_{\\infty}$-norm, $\\in [0.1,0.4]$. Our findings reveal that our hybrid\nstrategy, which is composed of a classifier to detect adversarial examples, a\ndenoiser to eliminate noise from the perturbed data samples, and a standard\nforecaster, achieves the best performance on both clean and perturbed data. Our\noptimal model can retain up to $92.02\\%$ the performance of the original\nforecasting model in terms of Mean Squared Error (MSE) on clean data, while\nbeing more robust than the standard adversarially trained models on perturbed\ndata. Its MSE is 2.71$\\times$ and 2.51$\\times$ lower than those of comparing\nmethods on normal and perturbed data, respectively. In addition, the components\nof our models can be trained in parallel, resulting in better computational\nefficiency. Our results indicate that we can optimally balance the trade-off\nbetween the performance and robustness of forecasting models by improving the\nclassifier and denoiser, even in the presence of sophisticated and destructive\npoisoning attacks.",
            "author": [
                "Romain Ilbert",
                "Thai V. Hoang",
                "Zonghua Zhang",
                "Themis Palpanas"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3605772.3624002",
                "http://arxiv.org/abs/2311.09790v3",
                "http://arxiv.org/pdf/2311.09790v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR",
                "68T05, 62M10, 68T01",
                "I.2.6; I.2.4; K.6.5"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12130v1",
            "title": "Formal Verification of Long Short-Term Memory based Audio Classifiers: A\n  Star based Approach",
            "updated": "2023-11-16T11:04:17Z",
            "published": "2023-11-16T11:04:17Z",
            "summary": "Formally verifying audio classification systems is essential to ensure\naccurate signal classification across real-world applications like\nsurveillance, automotive voice commands, and multimedia content management,\npreventing potential errors with serious consequences. Drawing from recent\nresearch, this study advances the utilization of star-set-based formal\nverification, extended through reachability analysis, tailored explicitly for\nLong Short-Term Memory architectures and their Convolutional variations within\nthe audio classification domain. By conceptualizing the classification process\nas a sequence of set operations, the star set-based reachability approach\nstreamlines the exploration of potential operational states attainable by the\nsystem. The paper serves as an encompassing case study, validating and\nverifying sequence audio classification analytics within real-world contexts.\nIt accentuates the necessity for robustness verification to ensure precise and\ndependable predictions, particularly in light of the impact of noise on the\naccuracy of output classifications.",
            "author": [
                "Neelanjana Pal",
                "Taylor T Johnson"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.395.12",
                "http://arxiv.org/abs/2311.12130v1",
                "http://arxiv.org/pdf/2311.12130v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09782v1",
            "title": "More Samples or More Prompt Inputs? Exploring Effective In-Context\n  Sampling for LLM Few-Shot Prompt Engineering",
            "updated": "2023-11-16T11:02:49Z",
            "published": "2023-11-16T11:02:49Z",
            "summary": "While most existing works on LLM prompt-engineering focus only on how to\nselect a better set of data samples inside one single prompt input (In-Context\nLearning or ICL), why can't we design and leverage multiple prompt inputs\ntogether to further improve the LLM performance? In this work, we propose\nIn-Context Sampling (ICS), a low-resource LLM prompt-engineering technique to\nproduce the most confident prediction results by optimizing the construction of\nmultiple ICL prompt inputs. Extensive experiments with two SOTA LLMs (FlanT5-XL\nand Mistral-7B) on three NLI datasets (e-SNLI, Multi-NLI, and ANLI) illustrate\nthat ICS can consistently enhance LLM's prediction performance and confidence.\nAn ablation study suggests that a diversity-based ICS strategy may further\nimprove LLM's performance, which sheds light on a new yet promising future\nresearch direction.",
            "author": [
                "Bingsheng Yao",
                "Guiming Chen",
                "Ruishi Zou",
                "Yuxuan Lu",
                "Jiachen Li",
                "Shao Zhang",
                "Sijia Liu",
                "James Hendler",
                "Dakuo Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09782v1",
                "http://arxiv.org/pdf/2311.09782v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10780v1",
            "title": "Extending Neural Network Verification to a Larger Family of Piece-wise\n  Linear Activation Functions",
            "updated": "2023-11-16T11:01:39Z",
            "published": "2023-11-16T11:01:39Z",
            "summary": "In this paper, we extend an available neural network verification technique\nto support a wider class of piece-wise linear activation functions.\nFurthermore, we extend the algorithms, which provide in their original form\nexact respectively over-approximative results for bounded input sets\nrepresented as start sets, to allow also unbounded input set. We implemented\nour algorithms and demonstrated their effectiveness in some case studies.",
            "author": [
                "L\u00e1szl\u00f3 Antal",
                "Hana Masara",
                "Erika \u00c1brah\u00e1m"
            ],
            "link": [
                "http://dx.doi.org/10.4204/EPTCS.395.4",
                "http://arxiv.org/abs/2311.10780v1",
                "http://arxiv.org/pdf/2311.10780v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.LO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10122v2",
            "title": "Video-LLaVA: Learning United Visual Representation by Alignment Before\n  Projection",
            "updated": "2023-11-21T14:37:30Z",
            "published": "2023-11-16T10:59:44Z",
            "summary": "The Large Vision-Language Model (LVLM) has enhanced the performance of\nvarious downstream tasks in visual-language understanding. Most existing\napproaches encode images and videos into separate feature spaces, which are\nthen fed as inputs to large language models. However, due to the lack of\nunified tokenization for images and videos, namely misalignment before\nprojection, it becomes challenging for a Large Language Model (LLM) to learn\nmulti-modal interactions from several poor projection layers. In this work, we\nunify visual representation into the language feature space to advance the\nfoundational LLM towards a unified LVLM. As a result, we establish a simple but\nrobust LVLM baseline, Video-LLaVA, which learns from a mixed dataset of images\nand videos, mutually enhancing each other. Video-LLaVA achieves superior\nperformances on a broad range of 9 image benchmarks across 5 image\nquestion-answering datasets and 4 image benchmark toolkits. Additionally, our\nVideo-LLaVA also outperforms Video-ChatGPT by 5.8%, 9.9%, 18.6%, and 10.1% on\nMSRVTT, MSVD, TGIF, and ActivityNet, respectively. Notably, extensive\nexperiments demonstrate that Video-LLaVA mutually benefits images and videos\nwithin a unified visual representation, outperforming models designed\nspecifically for images or videos. We aim for this work to provide modest\ninsights into the multi-modal inputs for the LLM.",
            "author": [
                "Bin Lin",
                "Yang Ye",
                "Bin Zhu",
                "Jiaxi Cui",
                "Munan Ning",
                "Peng Jin",
                "Li Yuan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10122v2",
                "http://arxiv.org/pdf/2311.10122v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09775v1",
            "title": "MEGA: A Memory-Efficient GNN Accelerator Exploiting Degree-Aware\n  Mixed-Precision Quantization",
            "updated": "2023-11-16T10:58:34Z",
            "published": "2023-11-16T10:58:34Z",
            "summary": "Graph Neural Networks (GNNs) are becoming a promising technique in various\ndomains due to their excellent capabilities in modeling non-Euclidean data.\nAlthough a spectrum of accelerators has been proposed to accelerate the\ninference of GNNs, our analysis demonstrates that the latency and energy\nconsumption induced by DRAM access still significantly impedes the improvement\nof performance and energy efficiency. To address this issue, we propose a\nMemory-Efficient GNN Accelerator (MEGA) through algorithm and hardware\nco-design in this work. Specifically, at the algorithm level, through an\nin-depth analysis of the node property, we observe that the data-independent\nquantization in previous works is not optimal in terms of accuracy and memory\nefficiency. This motivates us to propose the Degree-Aware mixed-precision\nquantization method, in which a proper bitwidth is learned and allocated to a\nnode according to its in-degree to compress GNNs as much as possible while\nmaintaining accuracy. At the hardware level, we employ a heterogeneous\narchitecture design in which the aggregation and combination phases are\nimplemented separately with different dataflows. In order to boost the\nperformance and energy efficiency, we also present an Adaptive-Package format\nto alleviate the storage overhead caused by the fine-grained bitwidth and\ndiverse sparsity, and a Condense-Edge scheduling method to enhance the data\nlocality and further alleviate the access irregularity induced by the extremely\nsparse adjacency matrix in the graph. We implement our MEGA accelerator in a\n28nm technology node. Extensive experiments demonstrate that MEGA can achieve\nan average speedup of 38.3x, 7.1x, 4.0x, 3.6x and 47.6x, 7.2x, 5.4x, 4.5x\nenergy savings over four state-of-the-art GNN accelerators, HyGCN, GCNAX, GROW,\nand SGCN, respectively, while retaining task accuracy.",
            "author": [
                "Zeyu Zhu",
                "Fanrong Li",
                "Gang Li",
                "Zejian Liu",
                "Zitao Mo",
                "Qinghao Hu",
                "Xiaoyao Liang",
                "Jian Cheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09775v1",
                "http://arxiv.org/pdf/2311.09775v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09774v1",
            "title": "HuatuoGPT-II, One-stage Training for Medical Adaption of LLMs",
            "updated": "2023-11-16T10:56:24Z",
            "published": "2023-11-16T10:56:24Z",
            "summary": "Adapting a language model into a specific domain, a.k.a `domain adaption', is\na common practice when specialized knowledge, e.g. medicine, is not\nencapsulated in a general language model like Llama2. The challenge lies in the\nheterogeneity of data across the two training stages, as it varies in\nlanguages, genres, or formats. To tackle this and simplify the learning\nprotocol, we propose to transform heterogeneous data, from the both\npre-training and supervised stages, into a unified, simple input-output pair\nformat. We validate the new protocol in the domains where proprietary LLMs like\nChatGPT perform relatively poorly, such as Traditional Chinese Medicine. The\ndeveloped model, HuatuoGPT-II, has shown state-of-the-art performance in\nChinese medicine domain on a number of benchmarks, e.g. medical licensing\nexams. It even outperforms proprietary models like ChatGPT and GPT-4 in some\naspects, especially in Traditional Chinese Medicine. Expert manual evaluations\nfurther validate HuatuoGPT-II's advantages over existing LLMs. Notably,\nHuatuoGPT-II was benchmarked in a fresh Chinese National Medical Licensing\nExamination where it achieved the best performance, showcasing not only its\neffectiveness but also its generalization capabilities.",
            "author": [
                "Junying Chen",
                "Xidong Wang",
                "Anningzhe Gao",
                "Feng Jiang",
                "Shunian Chen",
                "Hongbo Zhang",
                "Dingjie Song",
                "Wenya Xie",
                "Chuyi Kong",
                "Jianquan Li",
                "Xiang Wan",
                "Haizhou Li",
                "Benyou Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09774v1",
                "http://arxiv.org/pdf/2311.09774v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09770v2",
            "title": "DINO-VITS: Data-Efficient Noise-Robust Zero-Shot Voice Cloning via\n  Multi-Tasking with Self-Supervised Speaker Verification Loss",
            "updated": "2023-11-17T07:26:35Z",
            "published": "2023-11-16T10:50:22Z",
            "summary": "Recent progress in self-supervised representation learning has opened up new\nopportunities for training from unlabeled data and has been a growing trend in\nvoice conversion. However, unsupervised training of voice cloning seems to\nremain a challenging task. In this paper we propose a semi-supervised zero-shot\nvoice cloning approach that works by adapting a HuBERT-based voice conversion\nsystem to the voice cloning task and shows the robustness of such a system to\nnoises both in training data (we add noises resulting in up to 0db\nsignal-to-noise-ratio to 35% of training data with no significant degradation\nof evaluation metrics) and in the target speaker reference audio at inference.\nMoreover, such a method does not require any type of denoising or\nnoise-labeling of training data. Finally, we introduce a novel multi-tasking\napproach by incorporating self-supervised DINO loss into joint training of a\nCAM++ based speaker verification system and a unit-based VITS cloning system.\nWe show that it significantly improves the quality of generated audio over\nbaselines, especially for noisy target speaker references.",
            "author": [
                "Vikentii Pankov",
                "Valeria Pronina",
                "Alexander Kuzmin",
                "Maksim Borisov",
                "Nikita Usoltsev",
                "Xingshan Zeng",
                "Alexander Golubkov",
                "Nikolai Ermolenko",
                "Aleksandra Shirshova",
                "Yulia Matveeva"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09770v2",
                "http://arxiv.org/pdf/2311.09770v2"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10121v2",
            "title": "Slide-SAM: Medical SAM Meets Sliding Window",
            "updated": "2023-12-05T07:10:25Z",
            "published": "2023-11-16T10:45:46Z",
            "summary": "The Segment Anything Model (SAM) has achieved a notable success in\ntwo-dimensional image segmentation in natural images. However, the substantial\ngap between medical and natural images hinders its direct application to\nmedical image segmentation tasks. Particularly in 3D medical images, SAM\nstruggles to learn contextual relationships between slices, limiting its\npractical applicability. Moreover, applying 2D SAM to 3D images requires\nprompting the entire volume, which is time- and label-consuming. To address\nthese problems, we propose Slide-SAM, which treats a stack of three adjacent\nslices as a prediction window. It firstly takes three slices from a 3D volume\nand point- or bounding box prompts on the central slice as inputs to predict\nsegmentation masks for all three slices. Subsequently, the masks of the top and\nbottom slices are then used to generate new prompts for adjacent slices.\nFinally, step-wise prediction can be achieved by sliding the prediction window\nforward or backward through the entire volume. Our model is trained on multiple\npublic and private medical datasets and demonstrates its effectiveness through\nextensive 3D segmetnation experiments, with the help of minimal prompts. Code\nis available at \\url{https://github.com/Curli-quan/Slide-SAM}.",
            "author": [
                "Quan Quan",
                "Fenghe Tang",
                "Zikang Xu",
                "Heqin Zhu",
                "S. Kevin Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10121v2",
                "http://arxiv.org/pdf/2311.10121v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09767v1",
            "title": "New advancements, challenges and opportunities of nanophotonics for\n  neuromorphic computing: A state-of-the-art review",
            "updated": "2023-11-16T10:44:46Z",
            "published": "2023-11-16T10:44:46Z",
            "summary": "The expansion of optoelectronic devices on photonic integration platforms has\nled to significant growth in the field of photonic computing. Photonic\nintegrated circuits have facilitated the creation of ultrafast artificial\nneural networks, forming the basis for a novel category of information\nprocessing devices. Their application extends to diverse domains such as\nmedical diagnosis, language models, telecommunications, quantum computing, and\nthe metaverse, addressing the escalating demands of machine learning and\nartificial intelligence (AI). In contrast, conventional electronics faces\nchallenges in latency, crosstalk, and energy consumption. Neuromorphic\nphotonics emerges as a compelling solution, featuring sub-nanosecond latencies,\nminimal heat dissipation, and high parallelism, expanding the scope of AI and\nOptical Neural Networks. This review explores recent advances in integrated\nphotonic neuromorphic systems, focusing on materials and device engineering\nbreakthroughs needed to overcome existing challenges. Examining various\ntechnologies in AI accelerators, from traditional optics to PICs, we assess\nenergy efficiency through operations per joule and compute density in\noperations per squared millimeter per second. A comparative analysis highlights\ncrucial technical aspects, emphasizing nanophotonic components like VCSEL\nlasers, optical interconnects, nanocavity resonators, and frequency microcombs.\nThese components showcase recent breakthroughs in photonic engineering and\nmaterials science, enabling the creation of customized neuromorphic systems for\nAI tasks. Despite progress, current technologies face obstacles in achieving\nphotonic AI accelerators with computing speed and energy efficiencies reaching\nthe petaOPS range. The review explores potential future approaches in new\ndevices, fabrication, materials, scalability, and integration to enhance\ncritical performance metrics.",
            "author": [
                "Renjie Li",
                "Yuanhao Gong",
                "Hai Huang",
                "Yuze Zhou",
                "Sixuan Mao",
                "Connie Chang-Hasnain",
                "Zhaoyu Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09767v1",
                "http://arxiv.org/pdf/2311.09767v1"
            ],
            "primary_category": "physics.optics",
            "category": [
                "physics.optics",
                "cs.ET"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09762v1",
            "title": "Graph-Guided Reasoning for Multi-Hop Question Answering in Large\n  Language Models",
            "updated": "2023-11-16T10:36:08Z",
            "published": "2023-11-16T10:36:08Z",
            "summary": "Chain-of-Thought (CoT) prompting has boosted the multi-step reasoning\ncapabilities of Large Language Models (LLMs) by generating a series of\nrationales before the final answer. We analyze the reasoning paths generated by\nCoT and find two issues in multi-step reasoning: (i) Generating rationales\nirrelevant to the question, (ii) Unable to compose subquestions or queries for\ngenerating/retrieving all the relevant information. To address them, we propose\na graph-guided CoT prompting method, which guides the LLMs to reach the correct\nanswer with graph representation/verification steps. Specifically, we first\nleverage LLMs to construct a \"question/rationale graph\" by using knowledge\nextraction prompting given the initial question and the rationales generated in\nthe previous steps. Then, the graph verification step diagnoses the current\nrationale triplet by comparing it with the existing question/rationale graph to\nfilter out irrelevant rationales and generate follow-up questions to obtain\nrelevant information. Additionally, we generate CoT paths that exclude the\nextracted graph information to represent the context information missed from\nthe graph extraction. Our graph-guided reasoning method shows superior\nperformance compared to previous CoT prompting and the variants on multi-hop\nquestion answering benchmark datasets.",
            "author": [
                "Jinyoung Park",
                "Ameen Patel",
                "Omar Zia Khan",
                "Hyunwoo J. Kim",
                "Joo-Kyung Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09762v1",
                "http://arxiv.org/pdf/2311.09762v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09761v1",
            "title": "MAFALDA: A Benchmark and Comprehensive Study of Fallacy Detection and\n  Classification",
            "updated": "2023-11-16T10:35:11Z",
            "published": "2023-11-16T10:35:11Z",
            "summary": "Fallacies can be used to spread disinformation, fake news, and propaganda,\nunderlining the importance of their detection. Automated detection and\nclassification of fallacies, however, remain challenging, mainly because of the\ninnate subjectivity of the task and the need for a comprehensive, unified\napproach in existing research. Addressing these limitations, our study\nintroduces a novel taxonomy of fallacies that aligns and refines previous\nclassifications, a new annotation scheme tailored for subjective NLP tasks, and\na new evaluation method designed to handle subjectivity, adapted to precision,\nrecall, and F1-Score metrics. Using our annotation scheme, the paper introduces\nMAFALDA (Multi-level Annotated FALlacy DAtaset), a gold standard dataset.\nMAFALDA is based on examples from various previously existing fallacy datasets\nunder our unified taxonomy across three levels of granularity. We then evaluate\nseveral language models under a zero-shot learning setting using MAFALDA to\nassess their fallacy detection and classification capability. Our comprehensive\nevaluation not only benchmarks the performance of these models but also\nprovides valuable insights into their strengths and limitations in addressing\nfallacious reasoning.",
            "author": [
                "Chadi Helwe",
                "Tom Calamai",
                "Pierre-Henri Paris",
                "Chlo\u00e9 Clavel",
                "Fabian Suchanek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09761v1",
                "http://arxiv.org/pdf/2311.09761v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09757v1",
            "title": "UFPS: A unified framework for partially-annotated federated segmentation\n  in heterogeneous data distribution",
            "updated": "2023-11-16T10:30:27Z",
            "published": "2023-11-16T10:30:27Z",
            "summary": "Partially supervised segmentation is a label-saving method based on datasets\nwith fractional classes labeled and intersectant. However, it is still far from\nlanding on real-world medical applications due to privacy concerns and data\nheterogeneity. As a remedy without privacy leakage, federated partially\nsupervised segmentation (FPSS) is formulated in this work. The main challenges\nfor FPSS are class heterogeneity and client drift. We propose a Unified\nFederated Partially-labeled Segmentation (UFPS) framework to segment pixels\nwithin all classes for partially-annotated datasets by training a totipotential\nglobal model without class collision. Our framework includes Unified Label\nLearning and sparsed Unified Sharpness Aware Minimization for unification of\nclass and feature space, respectively. We find that vanilla combinations for\ntraditional methods in partially supervised segmentation and federated learning\nare mainly hampered by class collision through empirical study. Our\ncomprehensive experiments on real medical datasets demonstrate better\ndeconflicting and generalization ability of UFPS compared with modified\nmethods.",
            "author": [
                "Le Jiang",
                "Li Yan Ma",
                "Tie Yong Zeng",
                "Shi Hui Ying"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09757v1",
                "http://arxiv.org/pdf/2311.09757v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09756v1",
            "title": "FairytaleCQA: Integrating a Commonsense Knowledge Graph into Children's\n  Storybook Narratives",
            "updated": "2023-11-16T10:30:26Z",
            "published": "2023-11-16T10:30:26Z",
            "summary": "AI models (including LLM) often rely on narrative question-answering (QA)\ndatasets to provide customized QA functionalities to support downstream\nchildren education applications; however, existing datasets only include QA\npairs that are grounded within the given storybook content, but children can\nlearn more when teachers refer the storybook content to real-world knowledge\n(e.g., commonsense knowledge). We introduce the FairytaleCQA dataset, which is\nannotated by children education experts, to supplement 278 storybook narratives\nwith educationally appropriate commonsense knowledge. The dataset has 5,868 QA\npairs that not only originate from the storybook narrative but also contain the\ncommonsense knowledge grounded by an external knowledge graph (i.e.,\nConceptNet). A follow-up experiment shows that a smaller model (T5-large)\nfine-tuned with FairytaleCQA reliably outperforms much larger prompt-engineered\nLLM (e.g., GPT-4) in this new QA-pair generation task (QAG). This result\nsuggests that: 1) our dataset brings novel challenges to existing LLMs, and 2)\nhuman experts' data annotation are still critical as they have much nuanced\nknowledge that LLMs do not know in the children educational domain.",
            "author": [
                "Jiaju Chen",
                "Yuxuan Lu",
                "Shao Zhang",
                "Bingsheng Yao",
                "Yuanzhe Dong",
                "Ying Xu",
                "Yunyao Li",
                "Qianwen Wang",
                "Dakuo Wang",
                "Yuling Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09756v1",
                "http://arxiv.org/pdf/2311.09756v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09750v1",
            "title": "Ensembles of Quantum Classifiers",
            "updated": "2023-11-16T10:27:25Z",
            "published": "2023-11-16T10:27:25Z",
            "summary": "In the current era, known as Noisy Intermediate-Scale Quantum (NISQ),\nencoding large amounts of data in the quantum devices is challenging and the\nimpact of noise significantly affects the quality of the obtained results. A\nviable approach for the execution of quantum classification algorithms is the\nintroduction of a well-known machine learning paradigm, namely, the ensemble\nmethods. Indeed, the ensembles combine multiple internal classifiers, which are\ncharacterized by compact sizes due to the smaller data subsets used for\ntraining, to achieve more accurate and robust prediction performance. In this\nway, it is possible to reduce the qubits requirements with respect to a single\nlarger classifier while achieving comparable or improved performance. In this\nwork, we present an implementation and an extensive empirical evaluation of\nensembles of quantum classifiers for binary classification, with the purpose of\nproviding insights into their effectiveness, limitations, and potential for\nenhancing the performance of basic quantum models. In particular, three\nclassical ensemble methods and three quantum classifiers have been taken into\naccount here. Hence, the scheme that has been implemented (in Python) has a\nhybrid nature. The results (obtained on real-world datasets) have shown an\naccuracy advantage for the ensemble techniques with respect to the single\nquantum classifiers, and also an improvement in robustness. In fact, the\nensembles have turned out to be able to mitigate both unsuitable data\nnormalizations and repeated measurement inaccuracies, making quantum\nclassifiers more stable.",
            "author": [
                "Emiliano Tolotti",
                "Enrico Zardini",
                "Enrico Blanzieri",
                "Davide Pastorello"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09750v1",
                "http://arxiv.org/pdf/2311.09750v1"
            ],
            "primary_category": "cs.ET",
            "category": [
                "cs.ET",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09744v1",
            "title": "Redefining the Laparoscopic Spatial Sense: AI-based Intra- and\n  Postoperative Measurement from Stereoimages",
            "updated": "2023-11-16T10:19:04Z",
            "published": "2023-11-16T10:19:04Z",
            "summary": "A significant challenge in image-guided surgery is the accurate measurement\ntask of relevant structures such as vessel segments, resection margins, or\nbowel lengths. While this task is an essential component of many surgeries, it\ninvolves substantial human effort and is prone to inaccuracies. In this paper,\nwe develop a novel human-AI-based method for laparoscopic measurements\nutilizing stereo vision that has been guided by practicing surgeons. Based on a\nholistic qualitative requirements analysis, this work proposes a comprehensive\nmeasurement method, which comprises state-of-the-art machine learning\narchitectures, such as RAFT-Stereo and YOLOv8. The developed method is assessed\nin various realistic experimental evaluation environments. Our results outline\nthe potential of our method achieving high accuracies in distance measurements\nwith errors below 1 mm. Furthermore, on-surface measurements demonstrate\nrobustness when applied in challenging environments with textureless regions.\nOverall, by addressing the inherent challenges of image-guided surgery, we lay\nthe foundation for a more robust and accurate solution for intra- and\npostoperative measurements, enabling more precise, safe, and efficient surgical\nprocedures.",
            "author": [
                "Leopold M\u00fcller",
                "Patrick Hemmer",
                "Moritz Queisner",
                "Igor Sauer",
                "Simeon Allmendinger",
                "Johannes Jakubik",
                "Michael V\u00f6ssing",
                "Niklas K\u00fchl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09744v1",
                "http://arxiv.org/pdf/2311.09744v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09743v1",
            "title": "Capturing Perspectives of Crowdsourced Annotators in Subjective Learning\n  Tasks",
            "updated": "2023-11-16T10:18:32Z",
            "published": "2023-11-16T10:18:32Z",
            "summary": "In most classification models, it has been assumed to have a single ground\ntruth label for each data point. However, subjective tasks like toxicity\nclassification can lead to genuine disagreement among annotators. In these\ncases aggregating labels will result in biased labeling and, consequently,\nbiased models that can overlook minority opinions. Previous studies have shed\nlight on the pitfalls of label aggregation and have introduced a handful of\npractical approaches to tackle this issue. Recently proposed multi-annotator\nmodels, which predict labels individually per annotator, are vulnerable to\nunder-determination for annotators with small samples. This problem is\nespecially the case in crowd-sourced datasets. In this work, we propose\nAnnotator Aware Representations for Texts (AART) for subjective classification\ntasks. We will show the improvement of our method on metrics that assess the\nperformance on capturing annotators' perspectives. Additionally, our approach\ninvolves learning representations for annotators, allowing for an exploration\nof the captured annotation behaviors.",
            "author": [
                "Negar Mokhberian",
                "Myrl G. Marmarelis",
                "Frederic R. Hopp",
                "Valerio Basile",
                "Fred Morstatter",
                "Kristina Lerman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09743v1",
                "http://arxiv.org/pdf/2311.09743v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09741v1",
            "title": "What Constitutes a Faithful Summary? Preserving Author Perspectives in\n  News Summarization",
            "updated": "2023-11-16T10:14:28Z",
            "published": "2023-11-16T10:14:28Z",
            "summary": "In this work, we take a first step towards designing summarization systems\nthat are faithful to the author's opinions and perspectives. Focusing on a case\nstudy of preserving political perspectives in news summarization, we find that\nexisting approaches alter the political opinions and stances of news articles\nin more than 50% of summaries, misrepresenting the intent and perspectives of\nthe news authors. We thus propose P^3Sum, a diffusion model-based summarization\napproach controlled by political perspective classifiers. In P^3Sum, the\npolitical leaning of a generated summary is iteratively evaluated at each\ndecoding step, and any drift from the article's original stance incurs a loss\nback-propagated to the embedding layers, steering the political stance of the\nsummary at inference time. Extensive experiments on three news summarization\ndatasets demonstrate that P^3Sum outperforms state-of-the-art summarization\nsystems and large language models by up to 11.4% in terms of the success rate\nof stance preservation, with on-par performance on standard summarization\nutility metrics. These findings highlight the lacunae that even for\nstate-of-the-art models it is still challenging to preserve author perspectives\nin news summarization, while P^3Sum presents an important first step towards\nevaluating and developing summarization systems that are faithful to author\nintent and perspectives.",
            "author": [
                "Yuhan Liu",
                "Shangbin Feng",
                "Xiaochuang Han",
                "Vidhisha Balachandran",
                "Chan Young Park",
                "Sachin Kumar",
                "Yulia Tsvetkov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09741v1",
                "http://arxiv.org/pdf/2311.09741v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09740v3",
            "title": "Redefining Super-Resolution: Fine-mesh PDE predictions without classical\n  simulations",
            "updated": "2023-11-27T03:09:21Z",
            "published": "2023-11-16T10:13:09Z",
            "summary": "In Computational Fluid Dynamics (CFD), coarse mesh simulations offer\ncomputational efficiency but often lack precision. Applying conventional\nsuper-resolution to these simulations poses a significant challenge due to the\nfundamental contrast between downsampling high-resolution images and\nauthentically emulating low-resolution physics. The former method conserves\nmore of the underlying physics, surpassing the usual constraints of real-world\nscenarios. We propose a novel definition of super-resolution tailored for\nPDE-based problems. Instead of simply downsampling from a high-resolution\ndataset, we use coarse-grid simulated data as our input and predict fine-grid\nsimulated outcomes. Employing a physics-infused UNet upscaling method, we\ndemonstrate its efficacy across various 2D-CFD problems such as discontinuity\ndetection in Burger's equation, Methane combustion, and fouling in Industrial\nheat exchangers. Our method enables the generation of fine-mesh solutions\nbypassing traditional simulation, ensuring considerable computational saving\nand fidelity to the original ground truth outcomes. Through diverse boundary\nconditions during training, we further establish the robustness of our method,\npaving the way for its broad applications in engineering and scientific CFD\nsolvers.",
            "author": [
                "Rajat Kumar Sarkar",
                "Ritam Majumdar",
                "Vishal Jadhav",
                "Sagar Srinivas Sakhinana",
                "Venkataramana Runkana"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09740v3",
                "http://arxiv.org/pdf/2311.09740v3"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "cs.AI",
                "cs.LG",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09739v1",
            "title": "Machine Learning for Polaritonic Chemistry: Accessing chemical kinetics",
            "updated": "2023-11-16T10:08:44Z",
            "published": "2023-11-16T10:08:44Z",
            "summary": "Altering chemical reactivity and material structure in confined optical\nenvironments is on the rise, and yet, a conclusive understanding of the\nmicroscopic mechanisms remains elusive. This originates mostly from the fact\nthat accurately predicting vibrational and reactive dynamics for soluted\nensembles of realistic molecules is no small endeavor, and adding (collective)\nstrong light-matter interaction does not simplify matters. Here, we establish a\nframework based on a combination of machine learning (ML) models, trained using\ndensity-functional theory calculations, and molecular dynamics to accelerate\nsuch simulations. We then apply this approach to evaluate strong coupling,\nchanges in reaction rate constant, and their influence on enthalpy and entropy\nfor the deprotection reaction of 1-phenyl-2-trimethylsilylacetylene, which has\nbeen studied previously both experimentally and using ab initio simulations.\nWhile we find qualitative agreement with critical experimental observations,\nespecially with regard to the changes in kinetics, we also find differences in\ncomparison with previous theoretical predictions. The features for which the\nML-accelerated and ab initio simulations agree show the experimentally\nestimated kinetic behavior. Conflicting features indicate that a contribution\nof electronic polarization to the reaction process is more relevant then\ncurrently believed. Our work demonstrates the practical use of ML for\npolaritonic chemistry, discusses limitations of common approximations and paves\nthe way for a more holistic description of polaritonic chemistry.",
            "author": [
                "Christian Sch\u00e4fer",
                "Jakub Fojt",
                "Eric Lindgren",
                "Paul Erhart"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09739v1",
                "http://arxiv.org/pdf/2311.09739v1"
            ],
            "primary_category": "physics.chem-ph",
            "category": [
                "physics.chem-ph",
                "physics.comp-ph",
                "physics.optics",
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09737v1",
            "title": "Gradient-Map-Guided Adaptive Domain Generalization for Cross Modality\n  MRI Segmentation",
            "updated": "2023-11-16T10:07:27Z",
            "published": "2023-11-16T10:07:27Z",
            "summary": "Cross-modal MRI segmentation is of great value for computer-aided medical\ndiagnosis, enabling flexible data acquisition and model generalization.\nHowever, most existing methods have difficulty in handling local variations in\ndomain shift and typically require a significant amount of data for training,\nwhich hinders their usage in practice. To address these problems, we propose a\nnovel adaptive domain generalization framework, which integrates a\nlearning-free cross-domain representation based on image gradient maps and a\nclass prior-informed test-time adaptation strategy for mitigating local domain\nshift. We validate our approach on two multi-modal MRI datasets with six\ncross-modal segmentation tasks. Across all the task settings, our method\nconsistently outperforms competing approaches and shows a stable performance\neven with limited training data.",
            "author": [
                "Bingnan Li",
                "Zhitong Gao",
                "Xuming He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09737v1",
                "http://arxiv.org/pdf/2311.09737v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09735v1",
            "title": "GEO: Generative Engine Optimization",
            "updated": "2023-11-16T10:06:09Z",
            "published": "2023-11-16T10:06:09Z",
            "summary": "The advent of large language models (LLMs) has ushered in a new paradigm of\nsearch engines that use generative models to gather and summarize information\nto answer user queries. This emerging technology, which we formalize under the\nunified framework of Generative Engines (GEs), has the potential to generate\naccurate and personalized responses, and is rapidly replacing traditional\nsearch engines like Google and Bing. Generative Engines typically satisfy\nqueries by synthesizing information from multiple sources and summarizing them\nwith the help of LLMs. While this shift significantly improves \\textit{user}\nutility and \\textit{generative search engine} traffic, it results in a huge\nchallenge for the third stakeholder -- website and content creators. Given the\nblack-box and fast-moving nature of Generative Engines, content creators have\nlittle to no control over when and how their content is displayed. With\ngenerative engines here to stay, the right tools should be provided to ensure\nthat creator economy is not severely disadvantaged. To address this, we\nintroduce Generative Engine Optimization (GEO), a novel paradigm to aid content\ncreators in improving the visibility of their content in Generative Engine\nresponses through a black-box optimization framework for optimizing and\ndefining visibility metrics. We facilitate systematic evaluation in this new\nparadigm by introducing GEO-bench, a benchmark of diverse user queries across\nmultiple domains, coupled with sources required to answer these queries.\nThrough rigorous evaluation, we show that GEO can boost visibility by up to\n40\\% in generative engine responses. Moreover, we show the efficacy of these\nstrategies varies across domains, underscoring the need for domain-specific\nmethods. Our work opens a new frontier in the field of information discovery\nsystems, with profound implications for generative engines and content\ncreators.",
            "author": [
                "Pranjal Aggarwal",
                "Vishvak Murahari",
                "Tanmay Rajpurohit",
                "Ashwin Kalyan",
                "Karthik R Narasimhan",
                "Ameet Deshpande"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09735v1",
                "http://arxiv.org/pdf/2311.09735v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09731v1",
            "title": "Prudent Silence or Foolish Babble? Examining Large Language Models'\n  Responses to the Unknown",
            "updated": "2023-11-16T10:02:40Z",
            "published": "2023-11-16T10:02:40Z",
            "summary": "Large Language Models (LLMs) often struggle when faced with situations where\nthey lack the prerequisite knowledge to generate a sensical response. In these\ncases, models tend to fabricate and hallucinate, rather than appropriately\nsignaling uncertainty as humans would. This behavior misaligns with human\nconversational norms and presents challenges surrounding responsible and\nethical AI development. This work aims to systematically investigate LLMs'\nbehaviors in such situations. We curate an adversarial question-answering\nbenchmark containing unanswerable questions targeting information absent from\nthe LLM's training data. Concretely, these unanswerable questions contain\nnon-existent concepts or false premises. When presented with such unanswerable\nquestions, an LLM should appropriately convey uncertainty, and be able to\nchallenge the premise and refuse to generate a response. While facing\nanswerable valid questions, a model should demonstrate a positive correlation\nbetween accuracy and confidence. Using a model-agnostic unified confidence\nelicitation approach, we observe that LLMs that have gone through instruction\nfinetuning and reinforcement learning from human feedback (RLHF) perform\nsignificantly better than their counterparts that do not. Moreover, uncertainty\nexpression 1 through our elicitation method does not always stay consistent\nwith the perceived confidence of the direct response of an LLM. Our findings\ncall for further research into teaching LLMs to proactively and reliably\nexpress uncertainty.",
            "author": [
                "Genglin Liu",
                "Xingyao Wang",
                "Lifan Yuan",
                "Yangyi Chen",
                "Hao Peng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09731v1",
                "http://arxiv.org/pdf/2311.09731v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09730v1",
            "title": "Aligning with Whom? Large Language Models Have Gender and Racial Biases\n  in Subjective NLP Tasks",
            "updated": "2023-11-16T10:02:24Z",
            "published": "2023-11-16T10:02:24Z",
            "summary": "Human perception of language depends on personal backgrounds like gender and\nethnicity. While existing studies have shown that large language models (LLMs)\nhold values that are closer to certain societal groups, it is unclear whether\ntheir prediction behaviors on subjective NLP tasks also exhibit a similar bias.\nIn this study, leveraging the POPQUORN dataset which contains annotations of\ndiverse demographic backgrounds, we conduct a series of experiments on four\npopular LLMs to investigate their capability to understand group differences\nand potential biases in their predictions for politeness and offensiveness. We\nfind that for both tasks, model predictions are closer to the labels from White\nand female participants. We further explore prompting with the target\ndemographic labels and show that including the target demographic in the prompt\nactually worsens the model's performance. More specifically, when being\nprompted to respond from the perspective of \"Black\" and \"Asian\" individuals,\nmodels show lower performance in predicting both overall scores as well as the\nscores from corresponding groups. Our results suggest that LLMs hold gender and\nracial biases for subjective NLP tasks and that demographic-infused prompts\nalone may be insufficient to mitigate such effects. Code and data are available\nat https://github.com/Jiaxin-Pei/LLM-Group-Bias.",
            "author": [
                "Huaman Sun",
                "Jiaxin Pei",
                "Minje Choi",
                "David Jurgens"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09730v1",
                "http://arxiv.org/pdf/2311.09730v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09727v1",
            "title": "Analysis of Comments Given in Documents Inspection in Software\n  Development PBL and Investigation of the Impact on Students",
            "updated": "2023-11-16T09:57:58Z",
            "published": "2023-11-16T09:57:58Z",
            "summary": "This study considers inspection conducted in software development PBL as\nlearning feedback and investigates the impact of each inspection comment on\nstudents. The authors have already collected most inspection comments for not\nonly requirements specification but also UML diagrams on GitHub. The authors\ndevelop a tool that collects comments given in Figma to GitHub. We examine the\nimpact on students of each classification of inspection comments based on the\npost-lesson questionnaire submitted by the students. Finally, we present the\nbenefits that classification of inspection comments can bring to PBL and\ndiscuss automatic comment classification by machine learning enabled by\ntext-based comments and the concept of software development PBL support\napplication enabled by automatic classification of inspection comments.",
            "author": [
                "Oh Sato",
                "Atsuo Hazeyama"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09727v1",
                "http://arxiv.org/pdf/2311.09727v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09726v1",
            "title": "MS-Former: Memory-Supported Transformer for Weakly Supervised Change\n  Detection with Patch-Level Annotations",
            "updated": "2023-11-16T09:57:29Z",
            "published": "2023-11-16T09:57:29Z",
            "summary": "Fully supervised change detection methods have achieved significant\nadvancements in performance, yet they depend severely on acquiring costly\npixel-level labels. Considering that the patch-level annotations also contain\nabundant information corresponding to both changed and unchanged objects in\nbi-temporal images, an intuitive solution is to segment the changes with\npatch-level annotations. How to capture the semantic variations associated with\nthe changed and unchanged regions from the patch-level annotations to obtain\npromising change results is the critical challenge for the weakly supervised\nchange detection task. In this paper, we propose a memory-supported transformer\n(MS-Former), a novel framework consisting of a bi-directional attention block\n(BAB) and a patch-level supervision scheme (PSS) tailored for weakly supervised\nchange detection with patch-level annotations. More specifically, the BAM\ncaptures contexts associated with the changed and unchanged regions from the\ntemporal difference features to construct informative prototypes stored in the\nmemory bank. On the other hand, the BAM extracts useful information from the\nprototypes as supplementary contexts to enhance the temporal difference\nfeatures, thereby better distinguishing changed and unchanged regions. After\nthat, the PSS guides the network learning valuable knowledge from the\npatch-level annotations, thus further elevating the performance. Experimental\nresults on three benchmark datasets demonstrate the effectiveness of our\nproposed method in the change detection task. The demo code for our work will\nbe publicly available at \\url{https://github.com/guanyuezhen/MS-Former}.",
            "author": [
                "Zhenglai Li",
                "Chang Tang",
                "Xinwang Liu",
                "Changdong Li",
                "Xianju Li",
                "Wei Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09726v1",
                "http://arxiv.org/pdf/2311.09726v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09708v1",
            "title": "A Self-enhancement Multitask Framework for Unsupervised Aspect Category\n  Detection",
            "updated": "2023-11-16T09:35:24Z",
            "published": "2023-11-16T09:35:24Z",
            "summary": "Our work addresses the problem of unsupervised Aspect Category Detection\nusing a small set of seed words. Recent works have focused on learning\nembedding spaces for seed words and sentences to establish similarities between\nsentences and aspects. However, aspect representations are limited by the\nquality of initial seed words, and model performances are compromised by noise.\nTo mitigate this limitation, we propose a simple framework that automatically\nenhances the quality of initial seed words and selects high-quality sentences\nfor training instead of using the entire dataset. Our main concepts are to add\na number of seed words to the initial set and to treat the task of noise\nresolution as a task of augmenting data for a low-resource task. In addition,\nwe jointly train Aspect Category Detection with Aspect Term Extraction and\nAspect Term Polarity to further enhance performance. This approach facilitates\nshared representation learning, allowing Aspect Category Detection to benefit\nfrom the additional guidance offered by other tasks. Extensive experiments\ndemonstrate that our framework surpasses strong baselines on standard datasets.",
            "author": [
                "Thi-Nhung Nguyen",
                "Hoang Ngo",
                "Kiem-Hieu Nguyen",
                "Tuan-Dung Cao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09708v1",
                "http://arxiv.org/pdf/2311.09708v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09706v1",
            "title": "Towards Autonomous Hypothesis Verification via Language Models with\n  Minimal Guidance",
            "updated": "2023-11-16T09:34:23Z",
            "published": "2023-11-16T09:34:23Z",
            "summary": "Research automation efforts usually employ AI as a tool to automate specific\ntasks within the research process. To create an AI that truly conduct research\nthemselves, it must independently generate hypotheses, design verification\nplans, and execute verification. Therefore, we investigated if an AI itself\ncould autonomously generate and verify hypothesis for a toy machine learning\nresearch problem. We prompted GPT-4 to generate hypotheses and Python code for\nhypothesis verification with limited methodological guidance. Our findings\nsuggest that, in some instances, GPT-4 can autonomously generate and validate\nhypotheses without detailed guidance. While this is a promising result, we also\nfound that none of the verifications were flawless, and there remain\nsignificant challenges in achieving autonomous, human-level research using only\ngeneric instructions. These findings underscore the need for continued\nexploration to develop a general and autonomous AI researcher.",
            "author": [
                "Shiro Takagi",
                "Ryutaro Yamauchi",
                "Wataru Kumagai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09706v1",
                "http://arxiv.org/pdf/2311.09706v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10119v1",
            "title": "Accommodating Missing Modalities in Time-Continuous Multimodal Emotion\n  Recognition",
            "updated": "2023-11-16T09:22:48Z",
            "published": "2023-11-16T09:22:48Z",
            "summary": "Decades of research indicate that emotion recognition is more effective when\ndrawing information from multiple modalities. But what if some modalities are\nsometimes missing? To address this problem, we propose a novel\nTransformer-based architecture for recognizing valence and arousal in a\ntime-continuous manner even with missing input modalities. We use a coupling of\ncross-attention and self-attention mechanisms to emphasize relationships\nbetween modalities during time and enhance the learning process on weak salient\ninputs. Experimental results on the Ulm-TSST dataset show that our model\nexhibits an improvement of the concordance correlation coefficient evaluation\nof 37% when predicting arousal values and 30% when predicting valence values,\ncompared to a late-fusion baseline approach.",
            "author": [
                "Juan Vazquez-Rodriguez",
                "Gr\u00e9goire Lefebvre",
                "Julien Cumin",
                "James L. Crowley"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10119v1",
                "http://arxiv.org/pdf/2311.10119v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10118v1",
            "title": "Now and Future of Artificial Intelligence-based Signet Ring Cell\n  Diagnosis: A Survey",
            "updated": "2023-11-16T09:20:43Z",
            "published": "2023-11-16T09:20:43Z",
            "summary": "Since signet ring cells (SRCs) are associated with high peripheral metastasis\nrate and dismal survival, they play an important role in determining surgical\napproaches and prognosis, while they are easily missed by even experienced\npathologists. Although automatic diagnosis SRCs based on deep learning has\nreceived increasing attention to assist pathologists in improving the\ndiagnostic efficiency and accuracy, the existing works have not been\nsystematically overviewed, which hindered the evaluation of the gap between\nalgorithms and clinical applications. In this paper, we provide a survey on SRC\nanalysis driven by deep learning from 2008 to August 2023. Specifically, the\nbiological characteristics of SRCs and the challenges of automatic\nidentification are systemically summarized. Then, the representative algorithms\nare analyzed and compared via dividing them into classification, detection, and\nsegmentation. Finally, for comprehensive consideration to the performance of\nexisting methods and the requirements for clinical assistance, we discuss the\nopen issues and future trends of SRC analysis. The retrospect research will\nhelp researchers in the related fields, particularly for who without medical\nscience background not only to clearly find the outline of SRC analysis, but\nalso gain the prospect of intelligent diagnosis, resulting in accelerating the\npractice and application of intelligent algorithms.",
            "author": [
                "Zhu Meng",
                "Junhao Dong",
                "Limei Guo",
                "Fei Su",
                "Guangxi Wang",
                "Zhicheng Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10118v1",
                "http://arxiv.org/pdf/2311.10118v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09692v1",
            "title": "Augmenting Unsupervised Reinforcement Learning with Self-Reference",
            "updated": "2023-11-16T09:07:34Z",
            "published": "2023-11-16T09:07:34Z",
            "summary": "Humans possess the ability to draw on past experiences explicitly when\nlearning new tasks and applying them accordingly. We believe this capacity for\nself-referencing is especially advantageous for reinforcement learning agents\nin the unsupervised pretrain-then-finetune setting. During pretraining, an\nagent's past experiences can be explicitly utilized to mitigate the\nnonstationarity of intrinsic rewards. In the finetuning phase, referencing\nhistorical trajectories prevents the unlearning of valuable exploratory\nbehaviors. Motivated by these benefits, we propose the Self-Reference (SR)\napproach, an add-on module explicitly designed to leverage historical\ninformation and enhance agent performance within the pretrain-finetune\nparadigm. Our approach achieves state-of-the-art results in terms of\nInterquartile Mean (IQM) performance and Optimality Gap reduction on the\nUnsupervised Reinforcement Learning Benchmark for model-free methods, recording\nan 86% IQM and a 16% Optimality Gap. Additionally, it improves current\nalgorithms by up to 17% IQM and reduces the Optimality Gap by 31%. Beyond\nperformance enhancement, the Self-Reference add-on also increases sample\nefficiency, a crucial attribute for real-world applications.",
            "author": [
                "Andrew Zhao",
                "Erle Zhu",
                "Rui Lu",
                "Matthieu Lin",
                "Yong-Jin Liu",
                "Gao Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09692v1",
                "http://arxiv.org/pdf/2311.09692v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09690v2",
            "title": "CDMPP: A Device-Model Agnostic Framework for Latency Prediction of\n  Tensor Programs",
            "updated": "2023-11-17T08:23:11Z",
            "published": "2023-11-16T09:05:52Z",
            "summary": "Deep Neural Networks (DNNs) have shown excellent performance in a wide range\nof machine learning applications. Knowing the latency of running a DNN model or\ntensor program on a specific device is useful in various tasks, such as DNN\ngraph- or tensor-level optimization and device selection. Considering the large\nspace of DNN models and devices that impede direct profiling of all\ncombinations, recent efforts focus on building a predictor to model the\nperformance of DNN models on different devices. However, none of the existing\nattempts have achieved a cost model that can accurately predict the performance\nof various tensor programs while supporting both training and inference\naccelerators. We propose CDMPP, an efficient tensor program latency prediction\nframework for both cross-model and cross-device prediction. We design an\ninformative but efficient representation of tensor programs, called compact\nASTs, and a pre-order-based positional encoding method, to capture the internal\nstructure of tensor programs. We develop a domain-adaption-inspired method to\nlearn domain-invariant representations and devise a KMeans-based sampling\nalgorithm, for the predictor to learn from different domains (i.e., different\nDNN operators and devices). Our extensive experiments on a diverse range of DNN\nmodels and devices demonstrate that CDMPP significantly outperforms\nstate-of-the-art baselines with 14.03% and 10.85% prediction error for\ncross-model and cross-device prediction, respectively, and one order of\nmagnitude higher training efficiency. The implementation and the expanded\ndataset are available at https://github.com/joapolarbear/cdmpp.",
            "author": [
                "Hanpeng Hu",
                "Junwei Su",
                "Juntao Zhao",
                "Yanghua Peng",
                "Yibo Zhu",
                "Haibin Lin",
                "Chuan Wu"
            ],
            "link": [
                "http://dx.doi.org/10.1145/3627703.3629572",
                "http://arxiv.org/abs/2311.09690v2",
                "http://arxiv.org/pdf/2311.09690v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09683v1",
            "title": "Modelling daily mobility using mobile data traffic at fine\n  spatiotemporal scale",
            "updated": "2023-11-16T08:52:31Z",
            "published": "2023-11-16T08:52:31Z",
            "summary": "We applied a data-driven approach that explores the usability of the NetMob\n2023 dataset in modelling mobility patterns within an urban context. We\ncombined the data with a highly suitable external source, the ENACT dataset,\nwhich provides a 1 km x 1km grid with estimates of the day and night population\nacross Europe. We developed three sets of XGBoost models that predict the\npopulation in each 100m x 100m grid cell used in NetMob2023 based on the mobile\ndata traffic of the 68 online services covered in the dataset, using the ENACT\nvalues as ground truth. The results suggest that the NetMob 2023 data can be\nuseful for the estimation of the day and night population and grid cell level\nand can explain part of the dynamics of urban mobility.",
            "author": [
                "Panayotis Christidis",
                "Maria Vega Gonzalo",
                "Miklos Radics"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09683v1",
                "http://arxiv.org/pdf/2311.09683v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14712v1",
            "title": "Multiagent Simulators for Social Networks",
            "updated": "2023-11-16T08:50:12Z",
            "published": "2023-11-16T08:50:12Z",
            "summary": "Multiagent social network simulations are an avenue that can bridge the\ncommunication gap between the public and private platforms in order to develop\nsolutions to a complex array of issues relating to online safety. While there\nare significant challenges relating to the scale of multiagent simulations,\nefficient learning from observational and interventional data to accurately\nmodel micro and macro-level emergent effects, there are equally promising\nopportunities not least with the advent of large language models that provide\nan expressive approximation of user behavior. In this position paper, we review\nprior art relating to social network simulation, highlighting challenges and\nopportunities for future work exploring multiagent security using agent-based\nmodels of social networks",
            "author": [
                "Aditya Surve",
                "Archit Rathod",
                "Mokshit Surana",
                "Gautam Malpani",
                "Aneesh Shamraj",
                "Sainath Reddy Sankepally",
                "Raghav Jain",
                "Swapneel S Mehta"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14712v1",
                "http://arxiv.org/pdf/2311.14712v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09680v4",
            "title": "Trustworthy Large Models in Vision: A Survey",
            "updated": "2023-12-01T15:12:06Z",
            "published": "2023-11-16T08:49:46Z",
            "summary": "The rapid progress of Large Models (LMs) has recently revolutionized various\nfields of deep learning with remarkable grades, ranging from Natural Language\nProcessing (NLP) to Computer Vision (CV). However, LMs are increasingly\nchallenged and criticized by academia and industry due to their powerful\nperformance but untrustworthy behavior, which urgently needs to be alleviated\nby reliable methods. Despite the abundance of literature on trustworthy LMs in\nNLP, a systematic survey specifically delving into the trustworthiness of LMs\nin CV remains absent. In order to mitigate this gap, we summarize four relevant\nconcerns that obstruct the trustworthy usage in vision of LMs in this survey,\nincluding 1) human misuse, 2) vulnerability, 3) inherent issue and 4)\ninterpretability. By highlighting corresponding challenge, countermeasures, and\ndiscussion in each topic, we hope this survey will facilitate readers'\nunderstanding of this field, promote alignment of LMs with human expectations\nand enable trustworthy LMs to serve as welfare rather than disaster for human\nsociety.",
            "author": [
                "Ziyan Guo",
                "Li Xu",
                "Jun Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09680v4",
                "http://arxiv.org/pdf/2311.09680v4"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09677v1",
            "title": "R-Tuning: Teaching Large Language Models to Refuse Unknown Questions",
            "updated": "2023-11-16T08:45:44Z",
            "published": "2023-11-16T08:45:44Z",
            "summary": "Large language models (LLMs) have revolutionized numerous domains with their\nimpressive performance but still face their challenges. A predominant issue is\nthe propensity for these models to generate non-existent facts, a concern\ntermed hallucination. Our research is motivated by the observation that\nprevious instruction tuning methods force the model to complete a sentence no\nmatter whether the model knows the knowledge or not. When the question is out\nof the parametric knowledge, it will try to make up something and fail to\nindicate when it lacks knowledge. In this paper, we present a new approach\ncalled Refusal-Aware Instruction Tuning (R-Tuning). This approach is formalized\nby first identifying the knowledge gap between parametric knowledge and the\ninstruction tuning data. Then, we construct the refusal-aware data based on the\nknowledge intersection, to tune LLMs to refrain from responding to questions\nbeyond its parametric knowledge. Experimental results demonstrate this new\ninstruction tuning approach effectively improves a model's ability to answer\nknown questions and refrain from answering unknown questions. Furthermore, when\ntested on out-of-domain datasets, the refusal ability was found to be a\nmeta-skill that could be generalized to other tasks. Further analysis\nsurprisingly finds that learning the uncertainty during training displays a\nbetter ability to estimate uncertainty than uncertainty-based testing. Our code\nwill be released at https://github.com/shizhediao/R-Tuning.",
            "author": [
                "Hanning Zhang",
                "Shizhe Diao",
                "Yong Lin",
                "Yi R. Fung",
                "Qing Lian",
                "Xingyao Wang",
                "Yangyi Chen",
                "Heng Ji",
                "Tong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09677v1",
                "http://arxiv.org/pdf/2311.09677v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09676v1",
            "title": "Search for Charged Excited States of Dark Matter with KamLAND-Zen",
            "updated": "2023-11-16T08:43:53Z",
            "published": "2023-11-16T08:43:53Z",
            "summary": "Particle dark matter could belong to a multiplet that includes an\nelectrically charged state. WIMP dark matter ($\\chi^{0}$) accompanied by a\nnegatively charged excited state ($\\chi^{-}$) with a small mass difference\n(e.g. $<$ 20 MeV) can form a bound-state with a nucleus such as xenon. This\nbound-state formation is rare and the released energy is $\\mathcal{O}(1-10$)\nMeV depending on the nucleus, making large liquid scintillator detectors\nsuitable for detection. We searched for bound-state formation events with xenon\nin two experimental phases of the KamLAND-Zen experiment, a xenon-doped liquid\nscintillator detector. No statistically significant events were observed. For a\nbenchmark parameter set of WIMP mass $m_{\\chi^{0}} = 1$ TeV and mass difference\n$\\Delta m = 17$ MeV, we set the most stringent upper limits on the\nrecombination cross section times velocity $\\langle\\sigma v\\rangle$ and the\ndecay-width of $\\chi^{-}$ to $9.2 \\times 10^{-30}$ ${\\rm cm^3/s}$ and $8.7\n\\times 10^{-14}$ GeV, respectively at 90% confidence level.",
            "author": [
                "KamLAND-Zen collaboration",
                ":",
                "S. Abe",
                "M. Eizuka",
                "S. Futagi",
                "A. Gando",
                "Y. Gando",
                "S. Goto",
                "T. Hachiya",
                "K. Hata",
                "K. Hosokawa",
                "K. Ichimura",
                "S. Ieki",
                "H. Ikeda",
                "K. Inoue",
                "K. Ishidoshiro",
                "Y. Kamei",
                "N. Kawada",
                "Y. Kishimoto",
                "M. Koga",
                "M. Kurasawa",
                "T. Mitsui",
                "H. Miyake",
                "D. Morita",
                "T. Nakahata",
                "R. Nakajima",
                "K. Nakamura",
                "R. Nakamura",
                "R. Nakamura",
                "J. Nakane",
                "H. Ozaki",
                "T. Sakai",
                "I. Shimizu",
                "J. Shirai",
                "K. Shiraishi",
                "R. Shoji",
                "A. Suzuki",
                "A. Takeuchi",
                "K. Tamae",
                "H. Watanabe",
                "K. Watanabe",
                "S. Obara",
                "S. Yoshida",
                "S. Umehara",
                "K. Fushimi",
                "K. Kotera",
                "Y. Urano",
                "A. K. Ichikawa",
                "B. E. Berger",
                "B. K. Fujikawa",
                "J. G. Learned",
                "J. Maricic",
                "S. N. Axani",
                "Z. Fu",
                "J. Smolsky",
                "L. A. Winslow",
                "Y. Efremenko",
                "H. J. Karwowski",
                "D. M. Markoff",
                "W. Tornow",
                "S. Dell'Oro",
                "T. O'Donnell",
                "J. A. Detwiler",
                "S. Enomoto",
                "M. P. Decowski",
                "K. M. Weerman",
                "C. Grant",
                "A. Li",
                "H. Song"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09676v1",
                "http://arxiv.org/pdf/2311.09676v1"
            ],
            "primary_category": "hep-ex",
            "category": [
                "hep-ex",
                "physics.ins-det"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09671v1",
            "title": "Robust Contrastive Learning With Theory Guarantee",
            "updated": "2023-11-16T08:39:58Z",
            "published": "2023-11-16T08:39:58Z",
            "summary": "Contrastive learning (CL) is a self-supervised training paradigm that allows\nus to extract meaningful features without any label information. A typical CL\nframework is divided into two phases, where it first tries to learn the\nfeatures from unlabelled data, and then uses those features to train a linear\nclassifier with the labeled data. While a fair amount of existing theoretical\nworks have analyzed how the unsupervised loss in the first phase can support\nthe supervised loss in the second phase, none has examined the connection\nbetween the unsupervised loss and the robust supervised loss, which can shed\nlight on how to construct an effective unsupervised loss for the first phase of\nCL. To fill this gap, our work develops rigorous theories to dissect and\nidentify which components in the unsupervised loss can help improve the robust\nsupervised loss and conduct proper experiments to verify our findings.",
            "author": [
                "Ngoc N. Tran",
                "Lam Tran",
                "Hoang Phan",
                "Anh Bui",
                "Tung Pham",
                "Toan Tran",
                "Dinh Phung",
                "Trung Le"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09671v1",
                "http://arxiv.org/pdf/2311.09671v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09668v1",
            "title": "Improving the Generation Quality of Watermarked Large Language Models\n  via Word Importance Scoring",
            "updated": "2023-11-16T08:36:00Z",
            "published": "2023-11-16T08:36:00Z",
            "summary": "The strong general capabilities of Large Language Models (LLMs) bring\npotential ethical risks if they are unrestrictedly accessible to malicious\nusers. Token-level watermarking inserts watermarks in the generated texts by\naltering the token probability distributions with a private random number\ngenerator seeded by its prefix tokens. However, this watermarking algorithm\nalters the logits during generation, which can lead to a downgraded text\nquality if it chooses to promote tokens that are less relevant given the input.\nIn this work, we propose to improve the quality of texts generated by a\nwatermarked language model by Watermarking with Importance Scoring (WIS). At\neach generation step, we estimate the importance of the token to generate, and\nprevent it from being impacted by watermarking if it is important for the\nsemantic correctness of the output. We further propose three methods to predict\nimportance scoring, including a perturbation-based method and two model-based\nmethods. Empirical experiments show that our method can generate texts with\nbetter quality with comparable level of detection rate.",
            "author": [
                "Yuhang Li",
                "Yihan Wang",
                "Zhouxing Shi",
                "Cho-Jui Hsieh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09668v1",
                "http://arxiv.org/pdf/2311.09668v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09663v1",
            "title": "Zenkai -- Framework For Exploring Beyond Backpropagation",
            "updated": "2023-11-16T08:29:26Z",
            "published": "2023-11-16T08:29:26Z",
            "summary": "Zenkai is an open-source framework designed to give researchers more control\nand flexibility over building and training deep learning machines. It does this\nby dividing the deep learning machine into layers of semi-autonomous learning\nmachines with their own target and learning algorithm. This is to allow\nresearchers greater exploration such as the use of non-differentiable layers or\nlearning algorithms beyond those based on error backpropagation.\n  Backpropagation Rumelhart et al. [1986] has powered deep learning to become\none of the most exciting fields of the 21st century. As a result, a large\nnumber of software tools have been developed to support efficient\nimplementation and training of neural networks through the use of backpropa-\ngation. While these have been critical to the success of deep learning,\nbuilding frameworks around backpropagation can make it challenging to implement\nsolutions that do not adhere to it. Zenkai aims to make it easier to get around\nthese limitations and help researchers more easily explore new frontiers in\ndeep learning that do not strictly adhere to the backpropagation framework.",
            "author": [
                "Greg Short"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09663v1",
                "http://arxiv.org/pdf/2311.09663v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09649v1",
            "title": "ICXML: An In-Context Learning Framework for Zero-Shot Extreme\n  Multi-Label Classification",
            "updated": "2023-11-16T08:01:17Z",
            "published": "2023-11-16T08:01:17Z",
            "summary": "This paper focuses on the task of Extreme Multi-Label Classification (XMC)\nwhose goal is to predict multiple labels for each instance from an extremely\nlarge label space. While existing research has primarily focused on fully\nsupervised XMC, real-world scenarios often lack complete supervision signals,\nhighlighting the importance of zero-shot settings. Given the large label space,\nutilizing in-context learning approaches is not trivial. We address this issue\nby introducing In-Context Extreme Multilabel Learning (ICXML), a two-stage\nframework that cuts down the search space by generating a set of candidate\nlabels through incontext learning and then reranks them. Extensive experiments\nsuggest that ICXML advances the state of the art on two diverse public\nbenchmarks.",
            "author": [
                "Yaxin Zhu",
                "Hamed Zamani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09649v1",
                "http://arxiv.org/pdf/2311.09649v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09648v1",
            "title": "Event Causality Is Key to Computational Story Understanding",
            "updated": "2023-11-16T07:59:12Z",
            "published": "2023-11-16T07:59:12Z",
            "summary": "Psychological research suggests the central role of event causality in human\nstory understanding. Further, event causality has been heavily utilized in\nsymbolic story generation. However, few machine learning systems for story\nunderstanding employ event causality, partially due to the lack of reliable\nmethods for identifying open-world causal event relations. Leveraging recent\nprogress in large language models (LLMs), we present the first method for event\ncausality identification that leads to material improvements in computational\nstory understanding. We design specific prompts for extracting event causal\nrelations from GPT. Against human-annotated event causal relations in the\nGLUCOSE dataset, our technique performs on par with supervised models, while\nbeing easily generalizable to stories of different types and lengths. The\nextracted causal relations lead to 5.7\\% improvements on story quality\nevaluation and 8.7\\% on story video-text alignment. Our findings indicate\nenormous untapped potential for event causality in computational story\nunderstanding.",
            "author": [
                "Yidan Sun",
                "Qin Chao",
                "Boyang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09648v1",
                "http://arxiv.org/pdf/2311.09648v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09642v2",
            "title": "Weakly Supervised Anomaly Detection for Chest X-Ray Image",
            "updated": "2023-11-18T16:44:24Z",
            "published": "2023-11-16T07:53:34Z",
            "summary": "Chest X-Ray (CXR) examination is a common method for assessing thoracic\ndiseases in clinical applications. While recent advances in deep learning have\nenhanced the significance of visual analysis for CXR anomaly detection, current\nmethods often miss key cues in anomaly images crucial for identifying disease\nregions, as they predominantly rely on unsupervised training with normal\nimages. This letter focuses on a more practical setup in which few-shot anomaly\nimages with only image-level labels are available during training. For this\npurpose, we propose WSCXR, a weakly supervised anomaly detection framework for\nCXR. WSCXR firstly constructs sets of normal and anomaly image features\nrespectively. It then refines the anomaly image features by eliminating normal\nregion features through anomaly feature mining, thus fully leveraging the\nscarce yet crucial features of diseased areas. Additionally, WSCXR employs a\nlinear mixing strategy to augment the anomaly features, facilitating the\ntraining of anomaly detector with few-shot anomaly images. Experiments on two\nCXR datasets demonstrate the effectiveness of our approach.",
            "author": [
                "Haoqi Ni",
                "Ximiao Zhang",
                "Min Xu",
                "Ning Lang",
                "Xiuzhuang Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09642v2",
                "http://arxiv.org/pdf/2311.09642v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09641v1",
            "title": "On the Exploitability of Reinforcement Learning with Human Feedback for\n  Large Language Models",
            "updated": "2023-11-16T07:48:45Z",
            "published": "2023-11-16T07:48:45Z",
            "summary": "Reinforcement Learning with Human Feedback (RLHF) is a methodology designed\nto align Large Language Models (LLMs) with human preferences, playing an\nimportant role in LLMs alignment. Despite its advantages, RLHF relies on human\nannotators to rank the text, which can introduce potential security\nvulnerabilities if any adversarial annotator (i.e., attackers) manipulates the\nranking score by up-ranking any malicious text to steer the LLM adversarially.\nTo assess the red-teaming of RLHF against human preference data poisoning, we\npropose RankPoison, a poisoning attack method on candidates' selection of\npreference rank flipping to reach certain malicious behaviors (e.g., generating\nlonger sequences, which can increase the computational cost). With poisoned\ndataset generated by RankPoison, we can perform poisoning attacks on LLMs to\ngenerate longer tokens without hurting the original safety alignment\nperformance. Moreover, applying RankPoison, we also successfully implement a\nbackdoor attack where LLMs can generate longer answers under questions with the\ntrigger word. Our findings highlight critical security challenges in RLHF,\nunderscoring the necessity for more robust alignment methods for LLMs.",
            "author": [
                "Jiongxiao Wang",
                "Junlin Wu",
                "Muhao Chen",
                "Yevgeniy Vorobeychik",
                "Chaowei Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09641v1",
                "http://arxiv.org/pdf/2311.09641v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.CR",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09639v1",
            "title": "On the Quantification of Image Reconstruction Uncertainty without\n  Training Data",
            "updated": "2023-11-16T07:46:47Z",
            "published": "2023-11-16T07:46:47Z",
            "summary": "Computational imaging plays a pivotal role in determining hidden information\nfrom sparse measurements. A robust inverse solver is crucial to fully\ncharacterize the uncertainty induced by these measurements, as it allows for\nthe estimation of the complete posterior of unrecoverable targets. This, in\nturn, facilitates a probabilistic interpretation of observational data for\ndecision-making. In this study, we propose a deep variational framework that\nleverages a deep generative model to learn an approximate posterior\ndistribution to effectively quantify image reconstruction uncertainty without\nthe need for training data. We parameterize the target posterior using a\nflow-based model and minimize their Kullback-Leibler (KL) divergence to achieve\naccurate uncertainty estimation. To bolster stability, we introduce a robust\nflow-based model with bi-directional regularization and enhance expressivity\nthrough gradient boosting. Additionally, we incorporate a space-filling design\nto achieve substantial variance reduction on both latent prior space and target\nposterior space. We validate our method on several benchmark tasks and two\nreal-world applications, namely fastMRI and black hole image reconstruction.\nOur results indicate that our method provides reliable and high-quality image\nreconstruction with robust uncertainty estimation.",
            "author": [
                "Sirui Bi",
                "Victor Fung",
                "Jiaxin Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09639v1",
                "http://arxiv.org/pdf/2311.09639v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10117v1",
            "title": "Automatic Engineering of Long Prompts",
            "updated": "2023-11-16T07:42:46Z",
            "published": "2023-11-16T07:42:46Z",
            "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\nsolving complex open-domain tasks, guided by comprehensive instructions and\ndemonstrations provided in the form of prompts. However, these prompts can be\nlengthy, often comprising hundreds of lines and thousands of tokens, and their\ndesign often requires considerable human effort. Recent research has explored\nautomatic prompt engineering for short prompts, typically consisting of one or\na few sentences. However, the automatic design of long prompts remains a\nchallenging problem due to its immense search space. In this paper, we\ninvestigate the performance of greedy algorithms and genetic algorithms for\nautomatic long prompt engineering. We demonstrate that a simple greedy approach\nwith beam search outperforms other methods in terms of search efficiency.\nMoreover, we introduce two novel techniques that utilize search history to\nenhance the effectiveness of LLM-based mutation in our search algorithm. Our\nresults show that the proposed automatic long prompt engineering algorithm\nachieves an average of 9.2% accuracy gain on eight tasks in Big Bench Hard,\nhighlighting the significance of automating prompt designs to fully harness the\ncapabilities of LLMs.",
            "author": [
                "Cho-Jui Hsieh",
                "Si Si",
                "Felix X. Yu",
                "Inderjit S. Dhillon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10117v1",
                "http://arxiv.org/pdf/2311.10117v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09635v1",
            "title": "Evaluating In-Context Learning of Libraries for Code Generation",
            "updated": "2023-11-16T07:37:25Z",
            "published": "2023-11-16T07:37:25Z",
            "summary": "Contemporary Large Language Models (LLMs) exhibit a high degree of code\ngeneration and comprehension capability. A particularly promising area is their\nability to interpret code modules from unfamiliar libraries for solving\nuser-instructed tasks. Recent work has shown that large proprietary LLMs can\nlearn novel library usage in-context from demonstrations. These results raise\nseveral open questions: whether demonstrations of library usage is required,\nwhether smaller (and more open) models also possess such capabilities, etc. In\nthis work, we take a broader approach by systematically evaluating a diverse\narray of LLMs across three scenarios reflecting varying levels of domain\nspecialization to understand their abilities and limitations in generating code\nbased on libraries defined in-context. Our results show that even smaller\nopen-source LLMs like Llama-2 and StarCoder demonstrate an adept understanding\nof novel code libraries based on specification presented in-context. Our\nfindings further reveal that LLMs exhibit a surprisingly high proficiency in\nlearning novel library modules even when provided with just natural language\ndescriptions or raw code implementations of the functions, which are often\ncheaper to obtain than demonstrations. Overall, our results pave the way for\nharnessing LLMs in more adaptable and dynamic coding environments.",
            "author": [
                "Arkil Patel",
                "Siva Reddy",
                "Dzmitry Bahdanau",
                "Pradeep Dasigi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09635v1",
                "http://arxiv.org/pdf/2311.09635v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00029v1",
            "title": "Bergeron: Combating Adversarial Attacks through a Conscience-Based\n  Alignment Framework",
            "updated": "2023-11-16T07:31:18Z",
            "published": "2023-11-16T07:31:18Z",
            "summary": "Modern Large language models (LLMs) can still generate responses that may not\nbe aligned with human expectations or values. While many weight-based alignment\nmethods have been proposed, many of them still leave models vulnerable to\nattacks when used on their own. To help mitigate this issue, we introduce\nBergeron, a framework designed to improve the robustness of LLMs against\nadversarial attacks. Bergeron employs a two-tiered architecture. Here, a\nsecondary LLM serves as a simulated conscience that safeguards a primary LLM.\nWe do this by monitoring for and correcting potentially harmful text within\nboth the prompt inputs and the generated outputs of the primary LLM. Empirical\nevaluation shows that Bergeron can improve the alignment and robustness of\nseveral popular LLMs without costly fine-tuning. It aids both open-source and\nblack-box LLMs by complementing and reinforcing their existing alignment\ntraining.",
            "author": [
                "Matthew Pisano",
                "Peter Ly",
                "Abraham Sanders",
                "Bingsheng Yao",
                "Dakuo Wang",
                "Tomek Strzalkowski",
                "Mei Si"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00029v1",
                "http://arxiv.org/pdf/2312.00029v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09632v1",
            "title": "Online Continual Knowledge Learning for Language Models",
            "updated": "2023-11-16T07:31:03Z",
            "published": "2023-11-16T07:31:03Z",
            "summary": "Large Language Models (LLMs) serve as repositories of extensive world\nknowledge, enabling them to perform tasks such as question-answering and\nfact-checking. However, this knowledge can become obsolete as global contexts\nchange. In this paper, we introduce a novel problem in the realm of continual\nlearning: Online Continual Knowledge Learning (OCKL). This problem formulation\naims to manage the dynamic nature of world knowledge in LMs under real-time\nconstraints. We propose a new benchmark and evaluation metric designed to\nmeasure both the rate of new knowledge acquisition and the retention of\npreviously learned knowledge. Our empirical evaluation, conducted using a\nvariety of state-of-the-art methods, establishes robust base-lines for OCKL.\nOur results reveal that existing continual learning approaches are\nunfortunately insufficient for tackling the unique challenges posed by OCKL. We\nidentify key factors that influence the trade-off between knowledge acquisition\nand retention, thereby advancing our understanding of how to train LMs in a\ncontinually evolving environment.",
            "author": [
                "Yuhao Wu",
                "Tongjun Shi",
                "Karthick Sharma",
                "Chun Wei Seah",
                "Shuhao Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09632v1",
                "http://arxiv.org/pdf/2311.09632v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09631v2",
            "title": "On the Pauli Spectrum of QAC0",
            "updated": "2023-11-17T17:47:21Z",
            "published": "2023-11-16T07:25:06Z",
            "summary": "The circuit class $\\mathsf{QAC}^0$ was introduced by Moore (1999) as a model\nfor constant depth quantum circuits where the gate set includes many-qubit\nToffoli gates. Proving lower bounds against such circuits is a longstanding\nchallenge in quantum circuit complexity; in particular, showing that\npolynomial-size $\\mathsf{QAC}^0$ cannot compute the parity function has\nremained an open question for over 20 years.\n  In this work, we identify a notion of the Pauli spectrum of $\\mathsf{QAC}^0$\ncircuits, which can be viewed as the quantum analogue of the Fourier spectrum\nof classical $\\mathsf{AC}^0$ circuits. We conjecture that the Pauli spectrum of\n$\\mathsf{QAC}^0$ circuits satisfies low-degree concentration, in analogy to the\nfamous Linial, Nisan, Mansour theorem on the low-degree Fourier concentration\nof $\\mathsf{AC}^0$ circuits. If true, this conjecture immediately implies that\npolynomial-size $\\mathsf{QAC}^0$ circuits cannot compute parity.\n  We prove this conjecture for the class of depth-$d$, polynomial-size\n$\\mathsf{QAC}^0$ circuits with at most $n^{O(1/d)}$ auxiliary qubits. We obtain\nnew circuit lower bounds and learning results as applications: this class of\ncircuits cannot correctly compute\n  - the $n$-bit parity function on more than $(\\frac{1}{2} +\n2^{-\\Omega(n^{1/d})})$-fraction of inputs, and\n  - the $n$-bit majority function on more than $(1 -\n1/\\mathrm{poly}(n))$-fraction of inputs.\n  Additionally we show that this class of $\\mathsf{QAC}^0$ circuits with\nlimited auxiliary qubits can be learned with quasipolynomial sample complexity,\ngiving the first learning result for $\\mathsf{QAC}^0$ circuits.\n  More broadly, our results add evidence that \"Pauli-analytic\" techniques can\nbe a powerful tool in studying quantum circuits.",
            "author": [
                "Shivam Nadimpalli",
                "Natalie Parham",
                "Francisca Vasconcelos",
                "Henry Yuen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09631v2",
                "http://arxiv.org/pdf/2311.09631v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.CC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09627v1",
            "title": "CRISPR: Eliminating Bias Neurons from an Instruction-following Language\n  Model",
            "updated": "2023-11-16T07:16:55Z",
            "published": "2023-11-16T07:16:55Z",
            "summary": "Large language models (LLMs) executing tasks through instruction-based\nprompts often face challenges stemming from distribution differences between\nuser instructions and training instructions. This leads to distractions and\nbiases, especially when dealing with inconsistent dynamic labels. In this\npaper, we introduces a novel bias mitigation method, CRISPR, designed to\nalleviate instruction-label biases in LLMs. CRISPR utilizes attribution methods\nto identify bias neurons influencing biased outputs and employs pruning to\neliminate the bias neurons. Experimental results demonstrate the method's\neffectiveness in mitigating biases in instruction-based prompting, enhancing\nlanguage model performance on social bias benchmarks without compromising\npre-existing knowledge. CRISPR proves highly practical, model-agnostic,\noffering flexibility in adapting to evolving social biases.",
            "author": [
                "Nakyeong Yang",
                "Taegwan Kang",
                "Kyomin Jung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09627v1",
                "http://arxiv.org/pdf/2311.09627v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09624v1",
            "title": "AI Recommendation System for Enhanced Customer Experience: A Novel\n  Image-to-Text Method",
            "updated": "2023-11-16T07:15:44Z",
            "published": "2023-11-16T07:15:44Z",
            "summary": "Existing fashion recommendation systems encounter difficulties in using\nvisual data for accurate and personalized recommendations. This research\ndescribes an innovative end-to-end pipeline that uses artificial intelligence\nto provide fine-grained visual interpretation for fashion recommendations. When\ncustomers upload images of desired products or outfits, the system\nautomatically generates meaningful descriptions emphasizing stylistic elements.\nThese captions guide retrieval from a global fashion product catalogue to offer\nsimilar alternatives that fit the visual characteristics of the original image.\nOn a dataset of over 100,000 categorized fashion photos, the pipeline was\ntrained and evaluated. The F1-score for the object detection model was 0.97,\nexhibiting exact fashion object recognition capabilities optimized for\nrecommendation. This visually aware system represents a key advancement in\ncustomer engagement through personalized fashion recommendations",
            "author": [
                "Mohamaed Foued Ayedi",
                "Hiba Ben Salem",
                "Soulaimen Hammami",
                "Ahmed Ben Said",
                "Rateb Jabbar",
                "Achraf CHabbouh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09624v1",
                "http://arxiv.org/pdf/2311.09624v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09620v1",
            "title": "GAIA: Delving into Gradient-based Attribution Abnormality for\n  Out-of-distribution Detection",
            "updated": "2023-11-16T07:05:12Z",
            "published": "2023-11-16T07:05:12Z",
            "summary": "Detecting out-of-distribution (OOD) examples is crucial to guarantee the\nreliability and safety of deep neural networks in real-world settings. In this\npaper, we offer an innovative perspective on quantifying the disparities\nbetween in-distribution (ID) and OOD data -- analyzing the uncertainty that\narises when models attempt to explain their predictive decisions. This\nperspective is motivated by our observation that gradient-based attribution\nmethods encounter challenges in assigning feature importance to OOD data,\nthereby yielding divergent explanation patterns. Consequently, we investigate\nhow attribution gradients lead to uncertain explanation outcomes and introduce\ntwo forms of abnormalities for OOD detection: the zero-deflation abnormality\nand the channel-wise average abnormality. We then propose GAIA, a simple and\neffective approach that incorporates Gradient Abnormality Inspection and\nAggregation. The effectiveness of GAIA is validated on both commonly utilized\n(CIFAR) and large-scale (ImageNet-1k) benchmarks. Specifically, GAIA reduces\nthe average FPR95 by 23.10% on CIFAR10 and by 45.41% on CIFAR100 compared to\nadvanced post-hoc methods.",
            "author": [
                "Jinggang Chen",
                "Junjie Li",
                "Xiaoyang Qu",
                "Jianzong Wang",
                "Jiguang Wan",
                "Jing Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09620v1",
                "http://arxiv.org/pdf/2311.09620v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09619v1",
            "title": "Take One Step at a Time to Know Incremental Utility of Demonstration: An\n  Analysis on Reranking for Few-Shot In-Context Learning",
            "updated": "2023-11-16T07:03:54Z",
            "published": "2023-11-16T07:03:54Z",
            "summary": "In-Context Learning (ICL) is an emergent capability of Large Language Models\n(LLMs). Only a few demonstrations enable LLMs to be used as blackbox for new\ntasks. Previous studies have shown that using LLMs' outputs as labels is\neffective in training models to select demonstrations. Such a label is expected\nto estimate utility of a demonstration in ICL; however, it has not been well\nunderstood how different labeling strategies affect results on target tasks.\nThis paper presents an analysis on different utility functions by focusing on\nLLMs' output probability given ground-truth output, and task-specific reward\ngiven LLMs' prediction. Unlike the previous work, we introduce a novel labeling\nmethod, incremental utility, which estimates how much incremental knowledge is\nbrought into the LLMs by a demonstration. We conduct experiments with\ninstruction-tuned LLMs on binary/multi-class classification, segmentation, and\ntranslation across Arabic, English, Finnish, Japanese, and Spanish. Our results\nshow that (1) the probability is effective when the probability values are\ndistributed across the whole value range (on the classification tasks), and (2)\nthe downstream metric is more robust when nuanced reward values are provided\nwith long outputs (on the segmentation and translation tasks). We then show\nthat the proposed incremental utility further helps ICL by contrasting how the\nLLMs perform with and without the demonstrations.",
            "author": [
                "Kazuma Hashimoto",
                "Karthik Raman",
                "Michael Bendersky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09619v1",
                "http://arxiv.org/pdf/2311.09619v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09614v1",
            "title": "Comprehensive Evaluation and Insights into the Use of Deep Neural\n  Networks to Detect and Quantify Lymphoma Lesions in PET/CT Images",
            "updated": "2023-11-16T06:58:46Z",
            "published": "2023-11-16T06:58:46Z",
            "summary": "This study performs comprehensive evaluation of four neural network\narchitectures (UNet, SegResNet, DynUNet, and SwinUNETR) for lymphoma lesion\nsegmentation from PET/CT images. These networks were trained, validated, and\ntested on a diverse, multi-institutional dataset of 611 cases. Internal testing\n(88 cases; total metabolic tumor volume (TMTV) range [0.52, 2300] ml) showed\nSegResNet as the top performer with a median Dice similarity coefficient (DSC)\nof 0.76 and median false positive volume (FPV) of 4.55 ml; all networks had a\nmedian false negative volume (FNV) of 0 ml. On the unseen external test set\n(145 cases with TMTV range: [0.10, 2480] ml), SegResNet achieved the best\nmedian DSC of 0.68 and FPV of 21.46 ml, while UNet had the best FNV of 0.41 ml.\nWe assessed reproducibility of six lesion measures, calculated their prediction\nerrors, and examined DSC performance in relation to these lesion measures,\noffering insights into segmentation accuracy and clinical relevance.\nAdditionally, we introduced three lesion detection criteria, addressing the\nclinical need for identifying lesions, counting them, and segmenting based on\nmetabolic characteristics. We also performed expert intra-observer variability\nanalysis revealing the challenges in segmenting ``easy'' vs. ``hard'' cases, to\nassist in the development of more resilient segmentation algorithms. Finally,\nwe performed inter-observer agreement assessment underscoring the importance of\na standardized ground truth segmentation protocol involving multiple expert\nannotators. Code is available at:\nhttps://github.com/microsoft/lymphoma-segmentation-dnn",
            "author": [
                "Shadab Ahamed",
                "Yixi Xu",
                "Claire Gowdy",
                "Joo H. O",
                "Ingrid Bloise",
                "Don Wilson",
                "Patrick Martineau",
                "Fran\u00e7ois B\u00e9nard",
                "Fereshteh Yousefirizi",
                "Rahul Dodhia",
                "Juan M. Lavista",
                "William B. Weeks",
                "Carlos F. Uribe",
                "Arman Rahmim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09614v1",
                "http://arxiv.org/pdf/2311.09614v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09612v1",
            "title": "Efficient End-to-End Visual Document Understanding with Rationale\n  Distillation",
            "updated": "2023-11-16T06:50:26Z",
            "published": "2023-11-16T06:50:26Z",
            "summary": "Understanding visually situated language requires recognizing text and visual\nelements, and interpreting complex layouts. State-of-the-art methods commonly\nuse specialized pre-processing tools, such as optical character recognition\n(OCR) systems, that map document image inputs to extracted information in the\nspace of textual tokens, and sometimes also employ large language models (LLMs)\nto reason in text token space. However, the gains from external tools and LLMs\ncome at the cost of increased computational and engineering complexity. In this\npaper, we ask whether small pretrained image-to-text models can learn selective\ntext or layout recognition and reasoning as an intermediate inference step in\nan end-to-end model for pixel-level visual language understanding. We\nincorporate the outputs of such OCR tools, LLMs, and larger multimodal models\nas intermediate ``rationales'' on training data, and train a small student\nmodel to predict both rationales and answers for input questions based on those\ntraining examples. A student model based on Pix2Struct (282M parameters)\nachieves consistent improvements on three visual document understanding\nbenchmarks representing infographics, scanned documents, and figures, with\nimprovements of more than 4\\% absolute over a comparable Pix2Struct model that\npredicts answers directly.",
            "author": [
                "Wang Zhu",
                "Alekh Agarwal",
                "Mandar Joshi",
                "Robin Jia",
                "Jesse Thomason",
                "Kristina Toutanova"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09612v1",
                "http://arxiv.org/pdf/2311.09612v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09608v1",
            "title": "Deep Neural Helmholtz Operators for 3D Elastic Wave Propagation and\n  Inversion",
            "updated": "2023-11-16T06:37:47Z",
            "published": "2023-11-16T06:37:47Z",
            "summary": "Numerical simulations of seismic wave propagation in heterogeneous 3D media\nare central to investigating subsurface structures and understanding earthquake\nprocesses, yet are computationally expensive for large problems. This is\nparticularly problematic for full waveform inversion, which typically involves\nnumerous runs of the forward process. In machine learning there has been\nconsiderable recent work in the area of operator learning, with a new class of\nmodels called neural operators allowing for data-driven solutions to partial\ndifferential equations. Recent works in seismology have shown that when neural\noperators are adequately trained, they can significantly shorten the compute\ntime for wave propagation. However, the memory required for the 3D time domain\nequations may be prohibitive. In this study, we show that these limitations can\nbe overcome by solving the wave equations in the frequency domain, also known\nas the Helmholtz equations, since the solutions for a set of frequencies can be\ndetermined in parallel. The 3D Helmholtz neural operator is 40 times more\nmemory-efficient than an equivalent time-domain version. We employ a U-shaped\nneural operator for 2D and 3D elastic wave modeling, achieving two orders of\nmagnitude acceleration compared to a baseline spectral element method. The\nneural operator accurately generalizes to variable velocity structures and can\nbe evaluated on denser input meshes than used in the training simulations. We\nalso show that when solving for wavefields strictly on the surface, the\naccuracy can be significantly improved via a graph neural operator layer. In\nleveraging automatic differentiation, the proposed method can serve as an\nalternative to the adjoint-state approach for 3D full-waveform inversion,\nreducing the computation time by a factor of 350.",
            "author": [
                "Caifeng Zou",
                "Kamyar Azizzadenesheli",
                "Zachary E. Ross",
                "Robert W. Clayton"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09608v1",
                "http://arxiv.org/pdf/2311.09608v1"
            ],
            "primary_category": "physics.geo-ph",
            "category": [
                "physics.geo-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09607v1",
            "title": "Multi-Task Learning Approach for Unified Biometric Estimation from Fetal\n  Ultrasound Anomaly Scans",
            "updated": "2023-11-16T06:35:02Z",
            "published": "2023-11-16T06:35:02Z",
            "summary": "Precise estimation of fetal biometry parameters from ultrasound images is\nvital for evaluating fetal growth, monitoring health, and identifying potential\ncomplications reliably. However, the automated computerized segmentation of the\nfetal head, abdomen, and femur from ultrasound images, along with the\nsubsequent measurement of fetal biometrics, remains challenging. In this work,\nwe propose a multi-task learning approach to classify the region into head,\nabdomen and femur as well as estimate the associated parameters. We were able\nto achieve a mean absolute error (MAE) of 1.08 mm on head circumference, 1.44\nmm on abdomen circumference and 1.10 mm on femur length with a classification\naccuracy of 99.91\\% on a dataset of fetal Ultrasound images. To achieve this,\nwe leverage a weighted joint classification and segmentation loss function to\ntrain a U-Net architecture with an added classification head. The code can be\naccessed through\n\\href{https://github.com/BioMedIA-MBZUAI/Multi-Task-Learning-Approach-for-Unified-Biometric-Estimation-from-Fetal-Ultrasound-Anomaly-Scans.git}{\\texttt{Github}",
            "author": [
                "Mohammad Areeb Qazi",
                "Mohammed Talha Alam",
                "Ibrahim Almakky",
                "Werner Gerhard Diehl",
                "Leanne Bricker",
                "Mohammad Yaqub"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09607v1",
                "http://arxiv.org/pdf/2311.09607v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10778v1",
            "title": "uHD: Unary Processing for Lightweight and Dynamic Hyperdimensional\n  Computing",
            "updated": "2023-11-16T06:28:19Z",
            "published": "2023-11-16T06:28:19Z",
            "summary": "Hyperdimensional computing (HDC) is a novel computational paradigm that\noperates on long-dimensional vectors known as hypervectors. The hypervectors\nare constructed as long bit-streams and form the basic building blocks of HDC\nsystems. In HDC, hypervectors are generated from scalar values without taking\ntheir bit significance into consideration. HDC has been shown to be efficient\nand robust in various data processing applications, including computer vision\ntasks. To construct HDC models for vision applications, the current\nstate-of-the-art practice utilizes two parameters for data encoding: pixel\nintensity and pixel position. However, the intensity and position information\nembedded in high-dimensional vectors are generally not generated dynamically in\nthe HDC models. Consequently, the optimal design of hypervectors with high\nmodel accuracy requires powerful computing platforms for training. A more\nefficient approach to generating hypervectors is to create them dynamically\nduring the training phase, which results in accurate, low-cost, and highly\nperformable vectors. To this aim, we use low-discrepancy sequences to generate\nintensity hypervectors only, while avoiding position hypervectors. By doing so,\nthe multiplication step in vector encoding is eliminated, resulting in a\npower-efficient HDC system. For the first time in the literature, our proposed\napproach employs lightweight vector generators utilizing unary bit-streams for\nefficient encoding of data instead of using conventional comparator-based\ngenerators.",
            "author": [
                "Sercan Aygun",
                "Mehran Shoushtari Moghadam",
                "M. Hassan Najafi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10778v1",
                "http://arxiv.org/pdf/2311.10778v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09606v1",
            "title": "GistScore: Learning Better Representations for In-Context Example\n  Selection with Gist Bottlenecks",
            "updated": "2023-11-16T06:28:05Z",
            "published": "2023-11-16T06:28:05Z",
            "summary": "Large language models (LLMs) have the ability to perform in-context learning\n(ICL) of new tasks by conditioning on prompts comprising a few task examples.\nThis work studies the problem of selecting the best examples given a candidate\npool to improve ICL performance on given a test input. Existing approaches\neither require training with feedback from a much larger LLM or are\ncomputationally expensive. We propose a novel metric, GistScore, based on\nExample Gisting, a novel approach for training example retrievers for ICL using\nan attention bottleneck via Gisting, a recent technique for compressing task\ninstructions. To tradeoff performance with ease of use, we experiment with both\nfine-tuning gist models on each dataset and multi-task training a single model\non a large collection of datasets. On 21 diverse datasets spanning 9 tasks, we\nshow that our fine-tuned models get state-of-the-art ICL performance with 20%\nabsolute average gain over off-the-shelf retrievers and 7% over the best prior\nmethods. Our multi-task model generalizes well out-of-the-box to new task\ncategories, datasets, and prompt templates with retrieval speeds that are\nconsistently thousands of times faster than the best prior training-free\nmethod.",
            "author": [
                "Shivanshu Gupta",
                "Clemens Rosenbaum",
                "Ethan R. Elenberg"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09606v1",
                "http://arxiv.org/pdf/2311.09606v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09605v1",
            "title": "Measuring and Improving Attentiveness to Partial Inputs with\n  Counterfactuals",
            "updated": "2023-11-16T06:27:35Z",
            "published": "2023-11-16T06:27:35Z",
            "summary": "The inevitable appearance of spurious correlations in training datasets hurts\nthe generalization of NLP models on unseen data. Previous work has found that\ndatasets with paired inputs are prone to correlations between a specific part\nof the input (e.g., the hypothesis in NLI) and the label; consequently, models\ntrained only on those outperform chance. Are these correlations picked up by\nmodels trained on the full input data? To address this question, we propose a\nnew evaluation method, Counterfactual Attentiveness Test (CAT). CAT uses\ncounterfactuals by replacing part of the input with its counterpart from a\ndifferent example (subject to some restrictions), expecting an attentive model\nto change its prediction. Using CAT, we systematically investigate established\nsupervised and in-context learning models on ten datasets spanning four tasks:\nnatural language inference, reading comprehension, paraphrase detection, and\nvisual & language reasoning. CAT reveals that reliance on such correlations is\nmainly data-dependent. Surprisingly, we find that GPT3 becomes less attentive\nwith an increased number of demonstrations, while its accuracy on the test data\nimproves. Our results demonstrate that augmenting training or demonstration\ndata with counterfactuals is effective in improving models' attentiveness. We\nshow that models' attentiveness measured by CAT reveals different conclusions\nfrom solely measuring correlations in data.",
            "author": [
                "Yanai Elazar",
                "Bhargavi Paranjape",
                "Hao Peng",
                "Sarah Wiegreffe",
                "Khyathi Raghavi",
                "Vivek Srikumar",
                "Sameer Singh",
                "Noah A. Smith"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09605v1",
                "http://arxiv.org/pdf/2311.09605v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09601v1",
            "title": "Code Models are Zero-shot Precondition Reasoners",
            "updated": "2023-11-16T06:19:27Z",
            "published": "2023-11-16T06:19:27Z",
            "summary": "One of the fundamental skills required for an agent acting in an environment\nto complete tasks is the ability to understand what actions are plausible at\nany given point. This work explores a novel use of code representations to\nreason about action preconditions for sequential decision making tasks. Code\nrepresentations offer the flexibility to model procedural activities and\nassociated constraints as well as the ability to execute and verify constraint\nsatisfaction. Leveraging code representations, we extract action preconditions\nfrom demonstration trajectories in a zero-shot manner using pre-trained code\nmodels. Given these extracted preconditions, we propose a precondition-aware\naction sampling strategy that ensures actions predicted by a policy are\nconsistent with preconditions. We demonstrate that the proposed approach\nenhances the performance of few-shot policy learning approaches across\ntask-oriented dialog and embodied textworld benchmarks.",
            "author": [
                "Lajanugen Logeswaran",
                "Sungryull Sohn",
                "Yiwei Lyu",
                "Anthony Zhe Liu",
                "Dong-Ki Kim",
                "Dongsub Shim",
                "Moontae Lee",
                "Honglak Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09601v1",
                "http://arxiv.org/pdf/2311.09601v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09596v1",
            "title": "Generating Drug Repurposing Hypotheses through the Combination of\n  Disease-Specific Hypergraphs",
            "updated": "2023-11-16T06:09:14Z",
            "published": "2023-11-16T06:09:14Z",
            "summary": "The drug development pipeline for a new compound can last 10-20 years and\ncost over 10 billion. Drug repurposing offers a more time- and cost-effective\nalternative. Computational approaches based on biomedical knowledge graph\nrepresentations have recently yielded new drug repurposing hypotheses. In this\nstudy, we present a novel, disease-specific hypergraph representation learning\ntechnique to derive contextual embeddings of biological pathways of various\nlengths but that all start at any given drug and all end at the disease of\ninterest. Further, we extend this method to multi-disease hypergraphs. To\ndetermine the repurposing potential of each of the 1,522 drugs, we derive\ndrug-specific distributions of cosine similarity values and ultimately consider\nthe median for ranking. Cosine similarity values are computed between (1) all\nbiological pathways starting at the considered drug and ending at the disease\nof interest and (2) all biological pathways starting at drugs currently\nprescribed against that disease and ending at the disease of interest. We\nillustrate our approach with Alzheimer's disease (AD) and two of its risk\nfactors: hypertension (HTN) and type 2 diabetes (T2D). We compare each drug's\nrank across four hypergraph settings (single- or multi-disease): AD only, AD +\nHTN, AD + T2D, and AD + HTN + T2D. Notably, our framework led to the\nidentification of two promising drugs whose repurposing potential was\nsignificantly higher in hypergraphs combining two diseases: dapagliflozin\n(antidiabetic; moved up, from top 32$\\%$ to top 7$\\%$, across all considered\ndrugs) and debrisoquine (antihypertensive; moved up, from top 76$\\%$ to top\n23$\\%$). Our approach serves as a hypothesis generation tool, to be paired with\na validation pipeline relying on laboratory experiments and semi-automated\nparsing of the biomedical literature.",
            "author": [
                "Ayush Jain",
                "Marie Laure-Charpignon",
                "Irene Y. Chen",
                "Anthony Philippakis",
                "Ahmed Alaa"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09596v1",
                "http://arxiv.org/pdf/2311.09596v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.LG",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09593v1",
            "title": "Multi-Step Dialogue Workflow Action Prediction",
            "updated": "2023-11-16T06:05:47Z",
            "published": "2023-11-16T06:05:47Z",
            "summary": "In task-oriented dialogue, a system often needs to follow a sequence of\nactions, called a workflow, that complies with a set of guidelines in order to\ncomplete a task. In this paper, we propose the novel problem of multi-step\nworkflow action prediction, in which the system predicts multiple future\nworkflow actions. Accurate prediction of multiple steps allows for multi-turn\nautomation, which can free up time to focus on more complex tasks. We propose\nthree modeling approaches that are simple to implement yet lead to more action\nautomation: 1) fine-tuning on a training dataset, 2) few-shot in-context\nlearning leveraging retrieval and large language model prompting, and 3)\nzero-shot graph traversal, which aggregates historical action sequences into a\ngraph for prediction. We show that multi-step action prediction produces\nfeatures that improve accuracy on downstream dialogue tasks like predicting\ntask success, and can increase automation of steps by 20% without requiring as\nmuch feedback from a human overseeing the system.",
            "author": [
                "Ramya Ramakrishnan",
                "Ethan Elenberg",
                "Hashan Narangodage",
                "Ryan McDonald"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09593v1",
                "http://arxiv.org/pdf/2311.09593v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09591v1",
            "title": "Accelerating material discovery with a threshold-driven hybrid\n  acquisition policy-based Bayesian optimization",
            "updated": "2023-11-16T06:02:48Z",
            "published": "2023-11-16T06:02:48Z",
            "summary": "Advancements in materials play a crucial role in technological progress.\nHowever, the process of discovering and developing materials with desired\nproperties is often impeded by substantial experimental costs, extensive\nresource utilization, and lengthy development periods. To address these\nchallenges, modern approaches often employ machine learning (ML) techniques\nsuch as Bayesian Optimization (BO), which streamline the search for optimal\nmaterials by iteratively selecting experiments that are most likely to yield\nbeneficial results. However, traditional BO methods, while beneficial, often\nstruggle with balancing the trade-off between exploration and exploitation,\nleading to sub-optimal performance in material discovery processes. This paper\nintroduces a novel Threshold-Driven UCB-EI Bayesian Optimization (TDUE-BO)\nmethod, which dynamically integrates the strengths of Upper Confidence Bound\n(UCB) and Expected Improvement (EI) acquisition functions to optimize the\nmaterial discovery process. Unlike the classical BO, our method focuses on\nefficiently navigating the high-dimensional material design space (MDS).\nTDUE-BO begins with an exploration-focused UCB approach, ensuring a\ncomprehensive initial sweep of the MDS. As the model gains confidence,\nindicated by reduced uncertainty, it transitions to the more exploitative EI\nmethod, focusing on promising areas identified earlier. The UCB-to-EI switching\npolicy dictated guided through continuous monitoring of the model uncertainty\nduring each step of sequential sampling results in navigating through the MDS\nmore efficiently while ensuring rapid convergence. The effectiveness of TDUE-BO\nis demonstrated through its application on three different material datasets,\nshowing significantly better approximation and optimization performance over\nthe EI and UCB-based BO methods in terms of the RMSE scores and convergence\nefficiency, respectively.",
            "author": [
                "Ahmed Shoyeb Raihan",
                "Hamed Khosravi",
                "Srinjoy Das",
                "Imtiaz Ahmed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09591v1",
                "http://arxiv.org/pdf/2311.09591v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cond-mat.mtrl-sci",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10777v3",
            "title": "A Systematic Review of Aspect-based Sentiment Analysis (ABSA): Domains,\n  Methods, and Trends",
            "updated": "2023-12-03T05:50:36Z",
            "published": "2023-11-16T06:01:47Z",
            "summary": "Aspect-based Sentiment Analysis (ABSA) is a type of fine-grained sentiment\nanalysis (SA) that identifies aspects and the associated opinions from a given\ntext. In the digital era, ABSA gained increasing popularity and applications in\nmining opinionated text data to obtain insights and support decisions. ABSA\nresearch employs linguistic, statistical, and machine-learning approaches and\nutilises resources such as labelled datasets, aspect and sentiment lexicons and\nontology. By its nature, ABSA is domain-dependent and can be sensitive to the\nimpact of misalignment between the resource and application domains. However,\nto our knowledge, this topic has not been explored by the existing ABSA\nliterature reviews. In this paper, we present a Systematic Literature Review\n(SLR) of ABSA studies with a focus on the research application domain, dataset\ndomain, and the research methods to examine their relationships and identify\ntrends over time. Our results suggest a number of potential systemic issues in\nthe ABSA research literature, including the predominance of the\n``product/service review'' dataset domain among the majority of studies that\ndid not have a specific research application domain, coupled with the\nprevalence of dataset-reliant methods such as supervised machine learning. This\nreview makes a number of unique contributions to the ABSA research field: 1) To\nour knowledge, it is the first SLR that links the research domain, dataset\ndomain, and research method through a systematic perspective; 2) it is one of\nthe largest scoped SLR on ABSA, with 519 eligible studies filtered from 4191\nsearch results without time constraint; and 3) our review methodology adopted\nan innovative automatic filtering process based on PDF-mining, which enhanced\nscreening quality and reliability. Suggestions and our review limitations are\nalso discussed.",
            "author": [
                "Yan Cathy Hua",
                "Paul Denny",
                "Katerina Taskova",
                "J\u00f6rg Wicker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10777v3",
                "http://arxiv.org/pdf/2311.10777v3"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09589v1",
            "title": "Mortal Computation: A Foundation for Biomimetic Intelligence",
            "updated": "2023-11-16T06:00:58Z",
            "published": "2023-11-16T06:00:58Z",
            "summary": "This review motivates and synthesizes research efforts in\nneuroscience-inspired artificial intelligence and biomimetic computing in terms\nof mortal computation. Specifically, we characterize the notion of mortality by\nrecasting ideas in biophysics, cybernetics, and cognitive science in terms of a\ntheoretical foundation for sentient behavior. We frame the mortal computation\nthesis through the Markov blanket formalism and the circular causality entailed\nby inference, learning, and selection. The ensuing framework -- underwritten by\nthe free energy principle -- could prove useful for guiding the construction of\nunconventional connectionist computational systems, neuromorphic intelligence,\nand chimeric agents, including sentient organoids, which stand to revolutionize\nthe long-term future of embodied, enactive artificial intelligence and\ncognition research.",
            "author": [
                "Alexander Ororbia",
                "Karl Friston"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09589v1",
                "http://arxiv.org/pdf/2311.09589v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09580v1",
            "title": "MMOE: Mixture of Multimodal Interaction Experts",
            "updated": "2023-11-16T05:31:21Z",
            "published": "2023-11-16T05:31:21Z",
            "summary": "Multimodal machine learning, which studies the information and interactions\nacross various input modalities, has made significant advancements in\nunderstanding the relationship between images and descriptive text. However,\nthis is just a portion of the potential multimodal interactions seen in the\nreal world and does not include new interactions between conflicting utterances\nand gestures in predicting sarcasm, for example. Notably, the current methods\nfor capturing shared information often do not extend well to these more nuanced\ninteractions, sometimes performing as low as 50% in binary classification. In\nthis paper, we address this problem via a new approach called MMOE, which\nstands for a mixture of multimodal interaction experts. Our method\nautomatically classifies data points from unlabeled multimodal datasets by\ntheir interaction type and employs specialized models for each specific\ninteraction. Based on our experiments, this approach improves performance on\nthese challenging interactions by more than 10%, leading to an overall increase\nof 2% for tasks like sarcasm prediction. As a result, interaction\nquantification provides new insights for dataset analysis and yields simple\napproaches that obtain state-of-the-art performance.",
            "author": [
                "Haofei Yu",
                "Paul Pu Liang",
                "Ruslan Salakhutdinov",
                "Louis-Philippe Morency"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09580v1",
                "http://arxiv.org/pdf/2311.09580v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09579v1",
            "title": "Crafting In-context Examples according to LMs' Parametric Knowledge",
            "updated": "2023-11-16T05:30:07Z",
            "published": "2023-11-16T05:30:07Z",
            "summary": "In-context learning has been applied to knowledge-rich tasks such as question\nanswering. In such scenarios, in-context examples are used to trigger a\nbehaviour in the language model: namely, it should surface information stored\nin its parametric knowledge. We study the construction of in-context example\nsets, with a focus on the parametric knowledge of the model regarding\nin-context examples. We identify 'known' examples, where models can correctly\nanswer from its parametric knowledge, and 'unknown' ones. Our experiments show\nthat prompting with 'unknown' examples decreases the performance, potentially\nas it encourages hallucination rather than searching its parametric knowledge.\nConstructing an in-context example set that presents both known and unknown\ninformation performs the best across diverse settings. We perform analysis on\nthree multi-answer question answering datasets, which allows us to further\nstudy answer set ordering strategies based on the LM's knowledge about each\nanswer. Together, our study sheds lights on how to best construct in-context\nexample sets for knowledge-rich tasks.",
            "author": [
                "Yoonsang Lee",
                "Pranav Atreya",
                "Xi Ye",
                "Eunsol Choi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09579v1",
                "http://arxiv.org/pdf/2311.09579v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09578v1",
            "title": "Tied-Lora: Enhacing parameter efficiency of LoRA with weight tying",
            "updated": "2023-11-16T05:29:39Z",
            "published": "2023-11-16T05:29:39Z",
            "summary": "We propose Tied-LoRA, a simple paradigm utilizes weight tying and selective\ntraining to further increase parameter efficiency of the Low-rank adaptation\n(LoRA) method. Our investigations include all feasible combinations parameter\ntraining/freezing in conjunction with weight tying to identify the optimal\nbalance between performance and the number of trainable parameters. Through\nexperiments covering a variety of tasks and two base language models, we\nprovide analysis revealing trade-offs between efficiency and performance. Our\nexperiments uncovered a particular Tied-LoRA configuration that stands out by\ndemonstrating comparable performance across several tasks while employing only\n13~\\% percent of parameters utilized by the standard LoRA method.",
            "author": [
                "Adithya Renduchintala",
                "Tugrul Konuk",
                "Oleksii Kuchaiev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09578v1",
                "http://arxiv.org/pdf/2311.09578v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09577v1",
            "title": "Group-Aware Interest Disentangled Dual-Training for Personalized\n  Recommendation",
            "updated": "2023-11-16T05:23:53Z",
            "published": "2023-11-16T05:23:53Z",
            "summary": "Personalized recommender systems aim to predict users' preferences for items.\nIt has become an indispensable part of online services. Online social platforms\nenable users to form groups based on their common interests. The users' group\nparticipation on social platforms reveals their interests and can be utilized\nas side information to mitigate the data sparsity and cold-start problem in\nrecommender systems. Users join different groups out of different interests. In\nthis paper, we generate group representation from the user's interests and\npropose IGRec (Interest-based Group enhanced Recommendation) to utilize the\ngroup information accurately. It consists of four modules. (1) Interest\ndisentangler via self-gating that disentangles users' interests from their\ninitial embedding representation. (2) Interest aggregator that generates the\ninterest-based group representation by Gumbel-Softmax aggregation on the group\nmembers' interests. (3) Interest-based group aggregation that fuses user's\nrepresentation with the participated group representation. (4) A dual-trained\nrating prediction module to utilize both user-item and group-item interactions.\nWe conduct extensive experiments on three publicly available datasets. Results\nshow IGRec can effectively alleviate the data sparsity problem and enhance the\nrecommender system with interest-based group representation. Experiments on the\ngroup recommendation task further show the informativeness of interest-based\ngroup representation.",
            "author": [
                "Xiaolong Liu",
                "Liangwei Yang",
                "Zhiwei Liu",
                "Xiaohan Li",
                "Mingdai Yang",
                "Chen Wang",
                "Philip S. Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09577v1",
                "http://arxiv.org/pdf/2311.09577v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09574v3",
            "title": "LymphoML: An interpretable artificial intelligence-based method\n  identifies morphologic features that correlate with lymphoma subtype",
            "updated": "2023-11-20T02:01:33Z",
            "published": "2023-11-16T05:17:14Z",
            "summary": "The accurate classification of lymphoma subtypes using hematoxylin and eosin\n(H&E)-stained tissue is complicated by the wide range of morphological features\nthese cancers can exhibit. We present LymphoML - an interpretable machine\nlearning method that identifies morphologic features that correlate with\nlymphoma subtypes. Our method applies steps to process H&E-stained tissue\nmicroarray cores, segment nuclei and cells, compute features encompassing\nmorphology, texture, and architecture, and train gradient-boosted models to\nmake diagnostic predictions. LymphoML's interpretable models, developed on a\nlimited volume of H&E-stained tissue, achieve non-inferior diagnostic accuracy\nto pathologists using whole-slide images and outperform black box deep-learning\non a dataset of 670 cases from Guatemala spanning 8 lymphoma subtypes. Using\nSHapley Additive exPlanation (SHAP) analysis, we assess the impact of each\nfeature on model prediction and find that nuclear shape features are most\ndiscriminative for DLBCL (F1-score: 78.7%) and classical Hodgkin lymphoma\n(F1-score: 74.5%). Finally, we provide the first demonstration that a model\ncombining features from H&E-stained tissue with features from a standardized\npanel of 6 immunostains results in a similar diagnostic accuracy (85.3%) to a\n46-stain panel (86.1%).",
            "author": [
                "Vivek Shankar",
                "Xiaoli Yang",
                "Vrishab Krishna",
                "Brent Tan",
                "Oscar Silva",
                "Rebecca Rojansky",
                "Andrew Ng",
                "Fabiola Valvert",
                "Edward Briercheck",
                "David Weinstock",
                "Yasodha Natkunam",
                "Sebastian Fernandez-Pol",
                "Pranav Rajpurkar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09574v3",
                "http://arxiv.org/pdf/2311.09574v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "I.5.1; I.5.2; I.5.4; J.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09571v1",
            "title": "3D Paintbrush: Local Stylization of 3D Shapes with Cascaded Score\n  Distillation",
            "updated": "2023-11-16T05:13:44Z",
            "published": "2023-11-16T05:13:44Z",
            "summary": "In this work we develop 3D Paintbrush, a technique for automatically\ntexturing local semantic regions on meshes via text descriptions. Our method is\ndesigned to operate directly on meshes, producing texture maps which seamlessly\nintegrate into standard graphics pipelines. We opt to simultaneously produce a\nlocalization map (to specify the edit region) and a texture map which conforms\nto it. This synergistic approach improves the quality of both the localization\nand the stylization. To enhance the details and resolution of the textured\narea, we leverage multiple stages of a cascaded diffusion model to supervise\nour local editing technique with generative priors learned from images at\ndifferent resolutions. Our technique, referred to as Cascaded Score\nDistillation (CSD), simultaneously distills scores at multiple resolutions in a\ncascaded fashion, enabling control over both the granularity and global\nunderstanding of the supervision. We demonstrate the effectiveness of 3D\nPaintbrush to locally texture a variety of shapes within different semantic\nregions. Project page: https://threedle.github.io/3d-paintbrush",
            "author": [
                "Dale Decatur",
                "Itai Lang",
                "Kfir Aberman",
                "Rana Hanocka"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09571v1",
                "http://arxiv.org/pdf/2311.09571v1"
            ],
            "primary_category": "cs.GR",
            "category": [
                "cs.GR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09566v1",
            "title": "A Knowledge Distillation Approach for Sepsis Outcome Prediction from\n  Multivariate Clinical Time Series",
            "updated": "2023-11-16T05:06:51Z",
            "published": "2023-11-16T05:06:51Z",
            "summary": "Sepsis is a life-threatening condition triggered by an extreme infection\nresponse. Our objective is to forecast sepsis patient outcomes using their\nmedical history and treatments, while learning interpretable state\nrepresentations to assess patients' risks in developing various adverse\noutcomes. While neural networks excel in outcome prediction, their limited\ninterpretability remains a key issue. In this work, we use knowledge\ndistillation via constrained variational inference to distill the knowledge of\na powerful \"teacher\" neural network model with high predictive power to train a\n\"student\" latent variable model to learn interpretable hidden state\nrepresentations to achieve high predictive performance for sepsis outcome\nprediction. Using real-world data from the MIMIC-IV database, we trained an\nLSTM as the \"teacher\" model to predict mortality for sepsis patients, given\ninformation about their recent history of vital signs, lab values and\ntreatments. For our student model, we use an autoregressive hidden Markov model\n(AR-HMM) to learn interpretable hidden states from patients' clinical time\nseries, and use the posterior distribution of the learned state representations\nto predict various downstream outcomes, including hospital mortality, pulmonary\nedema, need for diuretics, dialysis, and mechanical ventilation. Our results\nshow that our approach successfully incorporates the constraint to achieve high\npredictive power similar to the teacher model, while maintaining the generative\nperformance.",
            "author": [
                "Anna Wong",
                "Shu Ge",
                "Nassim Oufattole",
                "Adam Dejl",
                "Megan Su",
                "Ardavan Saeedi",
                "Li-wei H. Lehman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09566v1",
                "http://arxiv.org/pdf/2311.09566v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09565v1",
            "title": "The Physical Logic of Protein Machines",
            "updated": "2023-11-16T05:01:15Z",
            "published": "2023-11-16T05:01:15Z",
            "summary": "Proteins are intricate molecular machines whose complexity arises from the\nheterogeneity of the amino acid building blocks and their dynamic network of\nmany-body interactions. These nanomachines gain function when put in the\ncontext of a whole organism through interaction with other inhabitants of the\nbiological realm. And this functionality shapes their evolutionary histories\nthrough intertwined paths of selection and adaptation. Recent advances in\nmachine learning have solved the decades-old problem of how protein sequence\ndetermines their structure. However, the ultimate question regarding the basic\nlogic of protein machines remains open: How does the collective physics of\nproteins lead to their functionality? and how does a sequence encode the full\nrange of dynamics and chemical interactions that facilitate function? Here, we\nexplore these questions within a physical approach that treats proteins as\nmechano-chemical machines, which are adapted to function via concerted\nevolution of structure, motion, and chemical interactions.",
            "author": [
                "John M. McBride",
                "Tsvi Tlusty"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09565v1",
                "http://arxiv.org/pdf/2311.09565v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "physics.bio-ph",
                "q-bio.PE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09559v1",
            "title": "Enchancing Semi-Supervised Learning for Extractive Summarization with an\n  LLM-based pseudolabeler",
            "updated": "2023-11-16T04:29:41Z",
            "published": "2023-11-16T04:29:41Z",
            "summary": "This work tackles the task of extractive text summarization in a limited\nlabeled data scenario using a semi-supervised approach. Specifically, we\npropose a prompt-based pseudolabel selection strategy using GPT-4. We evaluate\nour method on three text summarization datasets: TweetSumm, WikiHow, and\nArXiv/PubMed. Our experiments show that by using an LLM to evaluate and\ngenerate pseudolabels, we can improve the ROUGE-1 by 10-20\\% on the different\ndatasets, which is akin to enhancing pretrained models. We also show that such\na method needs a smaller pool of unlabeled examples to perform better.",
            "author": [
                "Gaurav Sahu",
                "Olga Vechtomova",
                "Issam H. Laradji"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09559v1",
                "http://arxiv.org/pdf/2311.09559v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09558v1",
            "title": "Pachinko: Patching Interpretable QA Models through Natural Language\n  Feedback",
            "updated": "2023-11-16T04:26:32Z",
            "published": "2023-11-16T04:26:32Z",
            "summary": "Eliciting feedback from end users of NLP models can be beneficial for\nimproving models. However, how should we present model responses to users so\nthey are most amenable to be corrected from user feedback? Further, what\nproperties do users value to understand and trust responses? We answer these\nquestions by analyzing the effect of rationales generated by QA models to\nsupport their answers. We specifically consider decomposed question-answering\nmodels that first extract an intermediate rationale based on a context and a\nquestion and then use solely this rationale to answer the question. A rationale\noutlines the approach followed by the model to answer the question. Our work\nconsiders various formats of these rationales that vary according to\nwell-defined properties of interest. We sample these rationales from large\nlanguage models using few-shot prompting for two reading comprehension\ndatasets, and then perform two user studies. In the first one, we present users\nwith incorrect answers and corresponding rationales of various formats and ask\nthem to provide natural language feedback to revise the rationale. We then\nmeasure the effectiveness of this feedback in patching these rationales through\nin-context learning. The second study evaluates how well different rationale\nformats enable users to understand and trust model answers, when they are\ncorrect. We find that rationale formats significantly affect how easy it is (1)\nfor users to give feedback for rationales, and (2) for models to subsequently\nexecute this feedback. In addition to influencing critiquablity, certain\nformats significantly enhance user reported understanding and trust of model\noutputs.",
            "author": [
                "Chaitanya Malaviya",
                "Subin Lee",
                "Dan Roth",
                "Mark Yatskar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09558v1",
                "http://arxiv.org/pdf/2311.09558v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09555v1",
            "title": "Soft and Rigid Object Grasping With Cross-Structure Hand Using Bilateral\n  Control-Based Imitation Learning",
            "updated": "2023-11-16T04:18:14Z",
            "published": "2023-11-16T04:18:14Z",
            "summary": "Object grasping is an important ability required for various robot tasks. In\nparticular, tasks that require precise force adjustments during operation, such\nas grasping an unknown object or using a grasped tool, are difficult for humans\nto program in advance. Recently, AI-based algorithms that can imitate human\nforce skills have been actively explored as a solution. In particular,\nbilateral control-based imitation learning achieves human-level motion speeds\nwith environmental adaptability, only requiring human demonstration and without\nprogramming. However, owing to hardware limitations, its grasping performance\nremains limited, and tasks that involves grasping various objects are yet to be\nachieved. Here, we developed a cross-structure hand to grasp various objects.\nWe experimentally demonstrated that the integration of bilateral control-based\nimitation learning and the cross-structure hand is effective for grasping\nvarious objects and harnessing tools.",
            "author": [
                "Koki Yamane",
                "Sho Sakaino",
                "Toshiaki Tsuji"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09555v1",
                "http://arxiv.org/pdf/2311.09555v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09550v1",
            "title": "A Speed Odyssey for Deployable Quantization of LLMs",
            "updated": "2023-11-16T04:11:19Z",
            "published": "2023-11-16T04:11:19Z",
            "summary": "The large language model era urges faster and less costly inference. Prior\nmodel compression works on LLMs tend to undertake a software-centric approach\nprimarily focused on the simulated quantization performance. By neglecting the\nfeasibility of deployment, these approaches are typically disabled in real\npractice. They used to drastically push down the quantization bit range for a\nreduced computation which might not be supported by the mainstream hardware, or\ninvolve sophisticated algorithms that introduce extra computation or memory\naccess overhead. We argue that pursuing a hardware-centric approach in the\nconstruction of quantization algorithms is crucial. In this regard, we are\ndriven to build our compression method on top of hardware awareness,\neliminating impractical algorithm choices while maximizing the benefit of\nhardware acceleration. Our method, OdysseyLLM, comes with a novel W4A8 kernel\nimplementation called FastGEMM and a combined recipe of quantization\nstrategies. Extensive experiments manifest the superiority of our W4A8 method\nwhich brings the actual speed boosting up to \\textbf{4$\\times$} compared to\nHugging Face FP16 inference and \\textbf{2.23$\\times$} vs. the state-of-the-art\ninference engine TensorRT-LLM in FP16, and \\textbf{1.45$\\times$} vs.\nTensorRT-LLM in INT8, yet without substantially harming the performance.",
            "author": [
                "Qingyuan Li",
                "Ran Meng",
                "Yiduo Li",
                "Bo Zhang",
                "Liang Li",
                "Yifan Lu",
                "Xiangxiang Chu",
                "Yerui Sun",
                "Yuchen Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09550v1",
                "http://arxiv.org/pdf/2311.09550v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09549v1",
            "title": "SparseAuto: An Auto-Scheduler for Sparse Tensor Computations Using\n  Recursive Loop Nest Restructuring",
            "updated": "2023-11-16T04:05:50Z",
            "published": "2023-11-16T04:05:50Z",
            "summary": "Automated code generation and performance optimizations for sparse tensor\nalgebra are cardinal since they have become essential in many real-world\napplications like quantum computing, physics, chemistry, and machine learning.\nGeneral sparse tensor algebra compilers are not always versatile enough to\ngenerate asymptotically optimal code for sparse tensor contractions. This paper\nshows how to optimize and generate asymptotically better schedules for complex\ntensor expressions using kernel fission and fusion. We present a generalized\nloop transformation to achieve loop nesting for minimized memory footprint and\nreduced asymptotic complexity.\n  Furthermore, we present an auto-scheduler that uses a partially ordered\nset-based cost model that uses both time and auxiliary memory complexities in\nits pruning stages. In addition, we highlight the use of SMT solvers in sparse\nauto-schedulers to prune the Pareto frontier of schedules to the smallest\nnumber of possible schedules with user-defined constraints available at compile\ntime. Finally, we show that our auto-scheduler can select asymptotically better\nschedules that use our compiler transformation to generate optimized code. Our\nresults show that the auto-scheduler achieves orders of magnitude speedup\ncompared to the TACO-generated code for several real-world tensor algebra\ncomputations on different real-world inputs.",
            "author": [
                "Adhitha Dias",
                "Logan Anderson",
                "Kirshanthan Sundararajah",
                "Artem Pelenitsyn",
                "Milind Kulkarni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09549v1",
                "http://arxiv.org/pdf/2311.09549v1"
            ],
            "primary_category": "cs.PL",
            "category": [
                "cs.PL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09544v1",
            "title": "Scaling User Modeling: Large-scale Online User Representations for Ads\n  Personalization in Meta",
            "updated": "2023-11-16T03:47:48Z",
            "published": "2023-11-16T03:47:48Z",
            "summary": "Effective user representations are pivotal in personalized advertising.\nHowever, stringent constraints on training throughput, serving latency, and\nmemory, often limit the complexity and input feature set of online ads ranking\nmodels. This challenge is magnified in extensive systems like Meta's, which\nencompass hundreds of models with diverse specifications, rendering the\ntailoring of user representation learning for each model impractical. To\naddress these challenges, we present Scaling User Modeling (SUM), a framework\nwidely deployed in Meta's ads ranking system, designed to facilitate efficient\nand scalable sharing of online user representation across hundreds of ads\nmodels. SUM leverages a few designated upstream user models to synthesize user\nembeddings from massive amounts of user features with advanced modeling\ntechniques. These embeddings then serve as inputs to downstream online ads\nranking models, promoting efficient representation sharing. To adapt to the\ndynamic nature of user features and ensure embedding freshness, we designed SUM\nOnline Asynchronous Platform (SOAP), a latency free online serving system\ncomplemented with model freshness and embedding stabilization, which enables\nfrequent user model updates and online inference of user embeddings upon each\nuser request. We share our hands-on deployment experiences for the SUM\nframework and validate its superiority through comprehensive experiments. To\ndate, SUM has been launched to hundreds of ads ranking models in Meta,\nprocessing hundreds of billions of user requests daily, yielding significant\nonline metric gains and infrastructure cost savings.",
            "author": [
                "Wei Zhang",
                "Dai Li",
                "Chen Liang",
                "Fang Zhou",
                "Zhongke Zhang",
                "Xuewei Wang",
                "Ru Li",
                "Yi Zhou",
                "Yaning Huang",
                "Dong Liang",
                "Kai Wang",
                "Zhangyuan Wang",
                "Zhengxing Chen",
                "Min Li",
                "Fenggang Wu",
                "Minghai Chen",
                "Huayu Li",
                "Yunnan Wu",
                "Zhan Shu",
                "Mindi Yuan",
                "Sri Reddy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09544v1",
                "http://arxiv.org/pdf/2311.09544v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI",
                "cs.LG",
                "68T05, 68T30",
                "I.2.1; H.3.5; H.3.3"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09540v1",
            "title": "FedFusion: Manifold Driven Federated Learning for Multi-satellite and\n  Multi-modality Fusion",
            "updated": "2023-11-16T03:29:19Z",
            "published": "2023-11-16T03:29:19Z",
            "summary": "Multi-satellite, multi-modality in-orbit fusion is a challenging task as it\nexplores the fusion representation of complex high-dimensional data under\nlimited computational resources. Deep neural networks can reveal the underlying\ndistribution of multi-modal remote sensing data, but the in-orbit fusion of\nmultimodal data is more difficult because of the limitations of different\nsensor imaging characteristics, especially when the multimodal data follows\nnon-independent identically distribution (Non-IID) distributions. To address\nthis problem while maintaining classification performance, this paper proposes\na manifold-driven multi-modality fusion framework, FedFusion, which randomly\nsamples local data on each client to jointly estimate the prominent manifold\nstructure of shallow features of each client and explicitly compresses the\nfeature matrices into a low-rank subspace through cascading and additive\napproaches, which is used as the feature input of the subsequent classifier.\nConsidering the physical space limitations of the satellite constellation, we\ndeveloped a multimodal federated learning module designed specifically for\nmanifold data in a deep latent space. This module achieves iterative updating\nof the sub-network parameters of each client through global weighted averaging,\nconstructing a framework that can represent compact representations of each\nclient. The proposed framework surpasses existing methods in terms of\nperformance on three multimodal datasets, achieving a classification average\naccuracy of 94.35$\\%$ while compressing communication costs by a factor of 4.\nFurthermore, extensive numerical evaluations of real-world satellite images\nwere conducted on the orbiting edge computing architecture based on Jetson TX2\nindustrial modules, which demonstrated that FedFusion significantly reduced\ntraining time by 48.4 minutes (15.18%) while optimizing accuracy.}",
            "author": [
                "DaiXun Li",
                "Weiying Xie",
                "Yunsong Li",
                "Leyuan Fang"
            ],
            "link": [
                "http://dx.doi.org/10.1109/TGRS.2023.3339522",
                "http://arxiv.org/abs/2311.09540v1",
                "http://arxiv.org/pdf/2311.09540v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09535v2",
            "title": "FunctionMarker: Watermarking Language Datasets via Knowledge Injection",
            "updated": "2023-11-17T05:00:21Z",
            "published": "2023-11-16T03:22:53Z",
            "summary": "Large Language Models (LLMs) have demonstrated superior performance in\nvarious natural language processing tasks. Meanwhile, they require extensive\ntraining data, raising concerns related to dataset copyright protection.\nBackdoor-based watermarking is a viable approach to protect the copyright of\nclassification datasets. However, these methods may introduce malicious\nmisclassification behaviors into watermarked LLMs by attackers and also affect\nthe semantic information of the watermarked text. To address these issues, we\npropose FunctionMarker, a novel copyright protection method for language\ndatasets via knowledge injection. FunctionMarker enables LLMs to learn specific\nknowledge through fine-tuning on watermarked datasets, and we can extract the\nembedded watermark by obtaining the responses of LLMs to specific\nknowledge-related queries. Considering watermark capacity and stealthness, we\nselect customizable functions as specific knowledge for LLMs to learn and embed\nthe watermark into them. Moreover, FunctionMarker can embed multi-bit\nwatermarks while preserving the original semantic information, thereby\nincreasing the difficulty of adaptive attacks. We take mathematical functions\nas an instance to evaluate the effectiveness of FunctionMarker, and experiments\nshow that only 0.3% of watermarked text achieves a 90% watermark extraction\naccuracy in most cases, validating our method's effectiveness.",
            "author": [
                "Shuai Li",
                "Kejiang Chen",
                "Kunsheng Tang",
                "Wen Huang",
                "Jie Zhang",
                "Weiming Zhang",
                "Nenghai Yu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09535v2",
                "http://arxiv.org/pdf/2311.09535v2"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09533v1",
            "title": "Effective Large Language Model Adaptation for Improved Grounding",
            "updated": "2023-11-16T03:22:25Z",
            "published": "2023-11-16T03:22:25Z",
            "summary": "Large language models (LLMs) have achieved remarkable advancements in natural\nlanguage understanding, generation, and manipulation of text-based data.\nHowever, one major issue towards their widespread deployment in the real world\nis that they can generate \"hallucinated\" answers that are not factual. Towards\nthis end, this paper focuses on improving grounding from a holistic perspective\nwith a novel framework, AGREE, Adaptation of LLMs for GRounding EnhancEment. We\nstart with the design of an iterative test-time adaptation (TTA) capability\nthat takes into account the support information generated in self-grounded\nresponses. To effectively enable this capability, we tune LLMs to ground the\nclaims in their responses to retrieved documents by providing citations. This\ntuning on top of the pre-trained LLMs requires a small amount of data that\nneeds to be constructed in a particular way to learn the grounding information,\nfor which we introduce a data construction method. Our results show that the\ntuning-based AGREE framework generates better grounded responses with more\naccurate citations compared to prompting-based approaches.",
            "author": [
                "Xi Ye",
                "Ruoxi Sun",
                "Sercan \u00d6. Arik",
                "Tomas Pfister"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09533v1",
                "http://arxiv.org/pdf/2311.09533v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09529v1",
            "title": "TransCrimeNet: A Transformer-Based Model for Text-Based Crime Prediction\n  in Criminal Networks",
            "updated": "2023-11-16T03:14:58Z",
            "published": "2023-11-16T03:14:58Z",
            "summary": "This paper presents TransCrimeNet, a novel transformer-based model for\npredicting future crimes in criminal networks from textual data. Criminal\nnetwork analysis has become vital for law enforcement agencies to prevent\ncrimes. However, existing graph-based methods fail to effectively incorporate\ncrucial textual data like social media posts and interrogation transcripts that\nprovide valuable insights into planned criminal activities. To address this\nlimitation, we develop TransCrimeNet which leverages the representation\nlearning capabilities of transformer models like BERT to extract features from\nunstructured text data. These text-derived features are fused with graph\nembeddings of the criminal network for accurate prediction of future crimes.\nExtensive experiments on real-world criminal network datasets demonstrate that\nTransCrimeNet outperforms previous state-of-the-art models by 12.7\\% in F1\nscore for crime prediction. The results showcase the benefits of combining\ntextual and graph-based features for actionable insights to disrupt criminal\nenterprises.",
            "author": [
                "Chen Yang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09529v1",
                "http://arxiv.org/pdf/2311.09529v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09528v1",
            "title": "HelpSteer: Multi-attribute Helpfulness Dataset for SteerLM",
            "updated": "2023-11-16T03:13:29Z",
            "published": "2023-11-16T03:13:29Z",
            "summary": "Existing open-source helpfulness preference datasets do not specify what\nmakes some responses more helpful and others less so. Models trained on these\ndatasets can incidentally learn to model dataset artifacts (e.g. preferring\nlonger but unhelpful responses only due to their length). To alleviate this\nproblem, we collect HelpSteer, a multi-attribute helpfulness dataset annotated\nfor the various aspects that make responses helpful. Specifically, our\n37k-sample dataset has annotations for correctness, coherence, complexity, and\nverbosity in addition to overall helpfulness of responses. Training Llama 2 70B\nusing the HelpSteer dataset with SteerLM technique produces a model that scores\n7.54 on MT Bench, which is currently the highest score for open models that do\nnot require training data from more powerful models (e.g. GPT4). We release\nthis dataset with CC-BY-4.0 license at\nhttps://huggingface.co/datasets/nvidia/HelpSteer",
            "author": [
                "Zhilin Wang",
                "Yi Dong",
                "Jiaqi Zeng",
                "Virginia Adams",
                "Makesh Narsimhan Sreedhar",
                "Daniel Egert",
                "Olivier Delalleau",
                "Jane Polak Scowcroft",
                "Neel Kant",
                "Aidan Swope",
                "Oleksii Kuchaiev"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09528v1",
                "http://arxiv.org/pdf/2311.09528v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09520v1",
            "title": "MDFL: Multi-domain Diffusion-driven Feature Learning",
            "updated": "2023-11-16T02:55:21Z",
            "published": "2023-11-16T02:55:21Z",
            "summary": "High-dimensional images, known for their rich semantic information, are\nwidely applied in remote sensing and other fields. The spatial information in\nthese images reflects the object's texture features, while the spectral\ninformation reveals the potential spectral representations across different\nbands. Currently, the understanding of high-dimensional images remains limited\nto a single-domain perspective with performance degradation. Motivated by the\nmasking texture effect observed in the human visual system, we present a\nmulti-domain diffusion-driven feature learning network (MDFL) , a scheme to\nredefine the effective information domain that the model really focuses on.\nThis method employs diffusion-based posterior sampling to explicitly consider\njoint information interactions between the high-dimensional manifold structures\nin the spectral, spatial, and frequency domains, thereby eliminating the\ninfluence of masking texture effects in visual models. Additionally, we\nintroduce a feature reuse mechanism to gather deep and raw features of\nhigh-dimensional data. We demonstrate that MDFL significantly improves the\nfeature extraction performance of high-dimensional data, thereby providing a\npowerful aid for revealing the intrinsic patterns and structures of such data.\nThe experimental results on three multi-modal remote sensing datasets show that\nMDFL reaches an average overall accuracy of 98.25%, outperforming various\nstate-of-the-art baseline schemes. The code will be released, contributing to\nthe computer vision community.",
            "author": [
                "Daixun Li",
                "Weiying Xie",
                "Jiaqing Zhang",
                "Yunsong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09520v1",
                "http://arxiv.org/pdf/2311.09520v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09519v1",
            "title": "Leveraging Code to Improve In-context Learning for Semantic Parsing",
            "updated": "2023-11-16T02:50:06Z",
            "published": "2023-11-16T02:50:06Z",
            "summary": "In-context learning (ICL) is an appealing approach for semantic parsing due\nto its few-shot nature and improved generalization. However, learning to parse\nto rare domain-specific languages (DSLs) from just a few demonstrations is\nchallenging, limiting the performance of even the most capable LLMs. In this\nwork, we improve the effectiveness of ICL for semantic parsing by (1) using\ngeneral-purpose programming languages such as Python instead of DSLs, and (2)\naugmenting prompts with a structured domain description that includes, e.g.,\nthe available classes and functions. We show that both these changes\nsignificantly improve accuracy across three popular datasets. Combined, they\nlead to dramatic improvements (e.g. 7.9% to 66.5% on SMCalFlow compositional\nsplit), nearly closing the performance gap between easier i.i.d.\\ and harder\ncompositional splits when used with a strong model, and reducing the need for a\nlarge number of demonstrations. We find that the resemblance of the target\nparse language to general-purpose code is a more important factor than the\nlanguage's popularity in pre-training corpora. Our findings provide an improved\nmethodology for building semantic parsers in the modern context of ICL with\nLLMs.",
            "author": [
                "Ben Bogin",
                "Shivanshu Gupta",
                "Peter Clark",
                "Ashish Sabharwal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09519v1",
                "http://arxiv.org/pdf/2311.09519v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09517v1",
            "title": "GEE! Grammar Error Explanation with Large Language Models",
            "updated": "2023-11-16T02:45:47Z",
            "published": "2023-11-16T02:45:47Z",
            "summary": "Grammatical error correction tools are effective at correcting grammatical\nerrors in users' input sentences but do not provide users with \\textit{natural\nlanguage} explanations about their errors. Such explanations are essential for\nhelping users learn the language by gaining a deeper understanding of its\ngrammatical rules (DeKeyser, 2003; Ellis et al., 2006). To address this gap, we\npropose the task of grammar error explanation, where a system needs to provide\none-sentence explanations for each grammatical error in a pair of erroneous and\ncorrected sentences. We analyze the capability of GPT-4 in grammar error\nexplanation, and find that it only produces explanations for 60.2% of the\nerrors using one-shot prompting. To improve upon this performance, we develop a\ntwo-step pipeline that leverages fine-tuned and prompted large language models\nto perform structured atomic token edit extraction, followed by prompting GPT-4\nto generate explanations. We evaluate our pipeline on German and Chinese\ngrammar error correction data sampled from language learners with a wide range\nof proficiency levels. Human evaluation reveals that our pipeline produces\n93.9% and 98.0% correct explanations for German and Chinese data, respectively.\nTo encourage further research in this area, we will open-source our data and\ncode.",
            "author": [
                "Yixiao Song",
                "Kalpesh Krishna",
                "Rajesh Bhatt",
                "Kevin Gimpel",
                "Mohit Iyyer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09517v1",
                "http://arxiv.org/pdf/2311.09517v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09516v1",
            "title": "Real-Time Adaptive Neural Network on FPGA: Enhancing Adaptability\n  through Dynamic Classifier Selection",
            "updated": "2023-11-16T02:44:45Z",
            "published": "2023-11-16T02:44:45Z",
            "summary": "This research studies an adaptive neural network with a Dynamic Classifier\nSelection framework on Field-Programmable Gate Arrays (FPGAs). The evaluations\nare conducted across three different datasets. By adjusting parameters, the\narchitecture surpasses all models in the ensemble set in accuracy and shows an\nimprovement of up to 8% compared to a singular neural network implementation.\nThe research also emphasizes considerable resource savings of up to 109.28%,\nachieved via partial reconfiguration rather than a traditional fixed approach.\nSuch improved efficiency suggests that the architecture is ideal for settings\nlimited by computational capacity, like in edge computing scenarios. The\ncollected data highlights the architecture's two main benefits: high\nperformance and real-world application, signifying a notable input to\nFPGA-based ensemble learning methods.",
            "author": [
                "Achraf El Bouazzaoui",
                "Abdelkader Hadjoudja",
                "Omar Mouhib"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09516v1",
                "http://arxiv.org/pdf/2311.09516v1"
            ],
            "primary_category": "cs.AR",
            "category": [
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09514v1",
            "title": "Know Thy Neighbors: A Graph Based Approach for Effective Sensor-Based\n  Human Activity Recognition in Smart Homes",
            "updated": "2023-11-16T02:43:13Z",
            "published": "2023-11-16T02:43:13Z",
            "summary": "There has been a resurgence of applications focused on Human Activity\nRecognition (HAR) in smart homes, especially in the field of ambient\nintelligence and assisted living technologies. However, such applications\npresent numerous significant challenges to any automated analysis system\noperating in the real world, such as variability, sparsity, and noise in sensor\nmeasurements. Although state-of-the-art HAR systems have made considerable\nstrides in addressing some of these challenges, they especially suffer from a\npractical limitation: they require successful pre-segmentation of continuous\nsensor data streams before automated recognition, i.e., they assume that an\noracle is present during deployment, which is capable of identifying time\nwindows of interest across discrete sensor events. To overcome this limitation,\nwe propose a novel graph-guided neural network approach that performs activity\nrecognition by learning explicit co-firing relationships between sensors. We\naccomplish this by learning a more expressive graph structure representing the\nsensor network in a smart home, in a data-driven manner. Our approach maps\ndiscrete input sensor measurements to a feature space through the application\nof attention mechanisms and hierarchical pooling of node embeddings. We\ndemonstrate the effectiveness of our proposed approach by conducting several\nexperiments on CASAS datasets, showing that the resulting graph-guided neural\nnetwork outperforms the state-of-the-art method for HAR in smart homes across\nmultiple datasets and by large margins. These results are promising because\nthey push HAR for smart homes closer to real-world applications.",
            "author": [
                "Srivatsa P",
                "Thomas Pl\u00f6tz"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09514v1",
                "http://arxiv.org/pdf/2311.09514v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09511v2",
            "title": "Identifying Systems with Symmetries using Equivariant Autoregressive\n  Reservoir Computers",
            "updated": "2023-11-28T22:59:41Z",
            "published": "2023-11-16T02:32:26Z",
            "summary": "The investigation reported in this document focuses on identifying systems\nwith symmetries using equivariant autoregressive reservoir computers. General\nresults in structured matrix approximation theory are presented, exploring a\ntwo-fold approach. Firstly, a comprehensive examination of generic\nsymmetry-preserving nonlinear time delay embedding is conducted. This involves\nanalyzing time series data sampled from an equivariant system under study.\nSecondly, sparse least-squares methods are applied to discern approximate\nrepresentations of the output coupling matrices. These matrices play a pivotal\nrole in determining the nonlinear autoregressive representation of an\nequivariant system. The structural characteristics of these matrices are\ndictated by the set of symmetries inherent in the system. The document outlines\nprototypical algorithms derived from the described techniques, offering insight\ninto their practical applications. Emphasis is placed on their effectiveness in\nthe identification and predictive simulation of equivariant nonlinear systems,\nregardless of whether such systems exhibit chaotic behavior.",
            "author": [
                "Fredy Vides",
                "Idelfonso B. R. Nogueira",
                "Lendy Banegas",
                "Evelyn Flores"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09511v2",
                "http://arxiv.org/pdf/2311.09511v2"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09508v1",
            "title": "Atoms as Words: A Novel Approach to Deciphering Material Properties\n  using NLP-inspired Machine Learning on Crystallographic Information Files\n  (CIFs)",
            "updated": "2023-11-16T02:15:29Z",
            "published": "2023-11-16T02:15:29Z",
            "summary": "In condensed matter physics and materials science, predicting material\nproperties necessitates understanding intricate many-body interactions.\nConventional methods such as density functional theory (DFT) and molecular\ndynamics (MD) often resort to simplifying approximations and are\ncomputationally expensive. Meanwhile, recent machine learning methods use\nhandcrafted descriptors for material representation which sometimes neglect\nvital crystallographic information and are often limited to single property\nprediction or a sub-class of crystal structures. In this study, we pioneer an\nunsupervised strategy, drawing inspiration from Natural Language Processing\n(NLP), to harness the underutilized potential of Crystallographic Information\nFiles (CIFs). We conceptualize atoms and atomic positions within a CIF\nsimilarly to words in textual content. Using a Word2Vec-inspired technique, we\nproduce atomic embeddings that capture intricate atomic relationships. Our\nmodel, CIFSemantics, trained on the extensive Material Project dataset, adeptly\npredicts 15 distinct material properties from the CIFs. Its performance rivals\nspecialized models, marking a significant step forward in material property\npredictions.",
            "author": [
                "Lalit Yadav"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09508v1",
                "http://arxiv.org/pdf/2311.09508v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09506v2",
            "title": "Investigating the Impact of Weight Sharing Decisions on Knowledge\n  Transfer in Continual Learning",
            "updated": "2023-11-28T05:31:06Z",
            "published": "2023-11-16T02:06:23Z",
            "summary": "Continual Learning (CL) has generated attention as a method of avoiding\nCatastrophic Forgetting (CF) in the sequential training of neural networks,\nimproving network efficiency and adaptability to different tasks. Additionally,\nCL serves as an ideal setting for studying network behavior and Forward\nKnowledge Transfer (FKT) between tasks. Pruning methods for CL train\nsubnetworks to handle the sequential tasks which allows us to take a structured\napproach to investigating FKT. Sharing prior subnetworks' weights leverages\npast knowledge for the current task through FKT. Understanding which weights to\nshare is important as sharing all weights can yield sub-optimal accuracy. This\npaper investigates how different sharing decisions affect the FKT between\ntasks. Through this lens we demonstrate how task complexity and similarity\ninfluence the optimal weight sharing decisions, giving insights into the\nrelationships between tasks and helping inform decision making in similar CL\nmethods. We implement three sequential datasets designed to emphasize variation\nin task complexity and similarity, reporting results for both ResNet-18 and\nVGG-16. By sharing in accordance with the decisions supported by our findings,\nwe show that we can improve task accuracy compared to other sharing decisions.",
            "author": [
                "Josh Andle",
                "Ali Payani",
                "Salimeh Yasaei-Sekeh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09506v2",
                "http://arxiv.org/pdf/2311.09506v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09505v1",
            "title": "SegMix: A Simple Structure-Aware Data Augmentation Method",
            "updated": "2023-11-16T02:05:15Z",
            "published": "2023-11-16T02:05:15Z",
            "summary": "Interpolation-based Data Augmentation (DA) methods (Mixup) linearly\ninterpolate the inputs and labels of two or more training examples. Mixup has\nmore recently been adapted to the field of Natural Language Processing (NLP),\nmainly for sequence labeling tasks. However, such a simple adoption yields\nmixed or unstable improvements over the baseline models. We argue that the\ndirect-adoption methods do not account for structures in NLP tasks. To this\nend, we propose SegMix, a collection of interpolation-based DA algorithms that\ncan adapt to task-specific structures. SegMix poses fewer constraints on data\nstructures, is robust to various hyperparameter settings, applies to more task\nsettings, and adds little computational overhead. In the algorithm's core, we\napply interpolation methods on task-specific meaningful segments, in contrast\nto applying them on sequences as in prior work. We find SegMix to be a flexible\nframework that combines rule-based DA methods with interpolation-based methods,\ncreating interesting mixtures of DA techniques. We show that SegMix\nconsistently improves performance over strong baseline models in Named Entity\nRecognition (NER) and Relation Extraction (RE) tasks, especially under\ndata-scarce settings. Furthermore, this method is easy to implement and adds\nnegligible training overhead.",
            "author": [
                "Yuxin Pei",
                "Pushkar Bhuse",
                "Zhengzhong Liu",
                "Eric Xing"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09505v1",
                "http://arxiv.org/pdf/2311.09505v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09502v1",
            "title": "SQATIN: Supervised Instruction Tuning Meets Question Answering for\n  Improved Dialogue NLU",
            "updated": "2023-11-16T01:57:00Z",
            "published": "2023-11-16T01:57:00Z",
            "summary": "Task-oriented dialogue (ToD) systems help users execute well-defined tasks\nacross a variety of domains (e.g., $\\textit{flight booking}$ or $\\textit{food\nordering}$), with their Natural Language Understanding (NLU) components being\ndedicated to the analysis of user utterances, predicting users' intents\n($\\textit{Intent Detection}$, ID) and extracting values for informational slots\n($\\textit{Value Extraction}$, VE). In most domains, labelled NLU data is\nscarce, making sample-efficient learning -- enabled with effective transfer\nparadigms -- paramount. In this work, we introduce SQATIN, a new framework for\ndialog NLU based on (i) instruction tuning and (ii) question-answering-based\nformulation of ID and VE tasks. According to the evaluation on established NLU\nbenchmarks, SQATIN sets the new state of the art in dialogue NLU, substantially\nsurpassing the performance of current models based on standard fine-tuning\nobjectives in both in-domain training and cross-domain transfer. SQATIN yields\nparticularly large performance gains in cross-domain transfer, owing to the\nfact that our QA-based instruction tuning leverages similarities between\nnatural language descriptions of classes (i.e., slots and intents) across\ndomains.",
            "author": [
                "Evgeniia Razumovskaia",
                "Goran Glava\u0161",
                "Anna Korhonen",
                "Ivan Vuli\u0107"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09502v1",
                "http://arxiv.org/pdf/2311.09502v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09500v2",
            "title": "Pseudo-keypoint RKHS Learning for Self-supervised 6DoF Pose Estimation",
            "updated": "2023-11-18T04:09:28Z",
            "published": "2023-11-16T01:52:24Z",
            "summary": "This paper addresses the simulation-to-real domain gap in 6DoF PE, and\nproposes a novel self-supervised keypoint radial voting-based 6DoF PE\nframework, effectively narrowing this gap using a learnable kernel in RKHS. We\nformulate this domain gap as a distance in high-dimensional feature space,\ndistinct from previous iterative matching methods. We propose an adapter\nnetwork, which evolves the network parameters from the source domain, which has\nbeen massively trained on synthetic data with synthetic poses, to the target\ndomain, which is trained on real data. Importantly, the real data training only\nuses pseudo-poses estimated by pseudo-keypoints, and thereby requires no real\ngroundtruth data annotations. RKHSPose achieves state-of-the-art performance on\nthree commonly used 6DoF PE datasets including LINEMOD (+4.2%), Occlusion\nLINEMOD (+2%), and YCB-Video (+3%). It also compares favorably to fully\nsupervised methods on all six applicable BOP core datasets, achieving within\n-10.8% to -0.3% of the top fully supervised results.",
            "author": [
                "Yangzheng Wu",
                "Michael Greenspan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09500v2",
                "http://arxiv.org/pdf/2311.09500v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09498v1",
            "title": "Network Wide Evacuation Traffic Prediction in a Rapidly Intensifying\n  Hurricane from Traffic Detectors and Facebook Movement Data: A Deep Learning\n  Approach",
            "updated": "2023-11-16T01:50:54Z",
            "published": "2023-11-16T01:50:54Z",
            "summary": "Traffic prediction during hurricane evacuation is essential for optimizing\nthe use of transportation infrastructures. It can reduce evacuation time by\nproviding information on future congestion in advance. However, evacuation\ntraffic prediction can be challenging as evacuation traffic patterns is\nsignificantly different than regular period traffic. A data-driven traffic\nprediction model is developed in this study by utilizing traffic detector and\nFacebook movement data during Hurricane Ian, a rapidly intensifying hurricane.\nWe select 766 traffic detectors from Florida's 4 major interstates to collect\ntraffic features. Additionally, we use Facebook movement data collected during\nHurricane Ian's evacuation period. The deep-learning model is first trained on\nregular period (May-August 2022) data to understand regular traffic patterns\nand then Hurricane Ian's evacuation period data is used as test data. The model\nachieves 95% accuracy (RMSE = 356) during regular period, but it underperforms\nwith 55% accuracy (RMSE = 1084) during the evacuation period. Then, a transfer\nlearning approach is adopted where a pretrained model is used with additional\nevacuation related features to predict evacuation period traffic. After\ntransfer learning, the model achieves 89% accuracy (RMSE = 514). Adding\nFacebook movement data further reduces model's RMSE value to 393 and increases\naccuracy to 93%. The proposed model is capable to forecast traffic up to\n6-hours in advance. Evacuation traffic management officials can use the\ndeveloped traffic prediction model to anticipate future traffic congestion in\nadvance and take proactive measures to reduce delays during evacuation.",
            "author": [
                "Md Mobasshir Rashid",
                "Rezaur Rahman",
                "Samiul Hasan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09498v1",
                "http://arxiv.org/pdf/2311.09498v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09497v1",
            "title": "Peer Reviews of Peer Reviews: A Randomized Controlled Trial and Other\n  Experiments",
            "updated": "2023-11-16T01:40:07Z",
            "published": "2023-11-16T01:40:07Z",
            "summary": "Is it possible to reliably evaluate the quality of peer reviews? We study\nthis question driven by two primary motivations -- incentivizing high-quality\nreviewing using assessed quality of reviews and measuring changes to review\nquality in experiments. We conduct a large scale study at the NeurIPS 2022\nconference, a top-tier conference in machine learning, in which we invited\n(meta)-reviewers and authors to evaluate reviews given to submitted papers.\nFirst, we conduct a RCT to examine bias due to the length of reviews. We\ngenerate elongated versions of reviews by adding substantial amounts of\nnon-informative content. Participants in the control group evaluate the\noriginal reviews, whereas participants in the experimental group evaluate the\nartificially lengthened versions. We find that lengthened reviews are scored\n(statistically significantly) higher quality than the original reviews.\nAdditionally, in analysis of observational data we find that authors are\npositively biased towards reviews recommending acceptance of their own papers,\neven after controlling for confounders of review length, quality, and different\nnumbers of papers per author. We also measure disagreement rates between\nmultiple evaluations of the same review of 28%-32%, which is comparable to that\nof paper reviewers at NeurIPS. Further, we assess the amount of miscalibration\nof evaluators of reviews using a linear model of quality scores and find that\nit is similar to estimates of miscalibration of paper reviewers at NeurIPS.\nFinally, we estimate the amount of variability in subjective opinions around\nhow to map individual criteria to overall scores of review quality and find\nthat it is roughly the same as that in the review of papers. Our results\nsuggest that the various problems that exist in reviews of papers --\ninconsistency, bias towards irrelevant factors, miscalibration, subjectivity --\nalso arise in reviewing of reviews.",
            "author": [
                "Alexander Goldberg",
                "Ivan Stelmakh",
                "Kyunghyun Cho",
                "Alice Oh",
                "Alekh Agarwal",
                "Danielle Belgrave",
                "Nihar B. Shah"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09497v1",
                "http://arxiv.org/pdf/2311.09497v1"
            ],
            "primary_category": "cs.DL",
            "category": [
                "cs.DL",
                "cs.GT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09496v2",
            "title": "Posterior-Mean Separable Costs of Information Acquisition",
            "updated": "2023-11-22T17:36:59Z",
            "published": "2023-11-16T01:28:25Z",
            "summary": "We analyze a problem of revealed preference given state-dependent stochastic\nchoice data in which the payoff to a decision maker (DM) only depends on their\nbeliefs about posterior means. Often, the DM must also learn about or pay\nattention to the state; in applied work on this subject, a convenient\nassumption is that the costs of such learning are linearly dependent in the\ndistribution over posterior means. We provide testable conditions to identify\nwhether this assumption holds. This allows for the use of information design\ntechniques to solve the DM's problem.",
            "author": [
                "Jeffrey Mensch",
                "Komal Malik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09496v2",
                "http://arxiv.org/pdf/2311.09496v2"
            ],
            "primary_category": "econ.TH",
            "category": [
                "econ.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09491v1",
            "title": "Spatial Bayesian Neural Networks",
            "updated": "2023-11-16T01:22:22Z",
            "published": "2023-11-16T01:22:22Z",
            "summary": "Statistical models for spatial processes play a central role in statistical\nanalyses of spatial data. Yet, it is the simple, interpretable, and well\nunderstood models that are routinely employed even though, as is revealed\nthrough prior and posterior predictive checks, these can poorly characterise\nthe spatial heterogeneity in the underlying process of interest. Here, we\npropose a new, flexible class of spatial-process models, which we refer to as\nspatial Bayesian neural networks (SBNNs). An SBNN leverages the\nrepresentational capacity of a Bayesian neural network; it is tailored to a\nspatial setting by incorporating a spatial \"embedding layer\" into the network\nand, possibly, spatially-varying network parameters. An SBNN is calibrated by\nmatching its finite-dimensional distribution at locations on a fine gridding of\nspace to that of a target process of interest. That process could be easy to\nsimulate from or we have many realisations from it. We propose several variants\nof SBNNs, most of which are able to match the finite-dimensional distribution\nof the target process at the selected grid better than conventional BNNs of\nsimilar complexity. We also show that a single SBNN can be used to represent a\nvariety of spatial processes often used in practice, such as Gaussian processes\nand lognormal processes. We briefly discuss the tools that could be used to\nmake inference with SBNNs, and we conclude with a discussion of their\nadvantages and limitations.",
            "author": [
                "Andrew Zammit-Mangion",
                "Michael D. Kaminski",
                "Ba-Hien Tran",
                "Maurizio Filippone",
                "Noel Cressie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09491v1",
                "http://arxiv.org/pdf/2311.09491v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10776v2",
            "title": "Towards an Automatic AI Agent for Reaction Condition Recommendation in\n  Chemical Synthesis",
            "updated": "2023-11-28T02:21:40Z",
            "published": "2023-11-16T01:21:33Z",
            "summary": "Artificial intelligence (AI) for reaction condition optimization has become\nan important topic in the pharmaceutical industry, given that a data-driven AI\nmodel can assist drug discovery and accelerate reaction design. However,\nexisting AI models lack the chemical insights and real-time knowledge\nacquisition abilities of experienced human chemists. This paper proposes a\nLarge Language Model (LLM) empowered AI agent to bridge this gap. We put forth\na novel three-phase paradigm and applied advanced intelligence-enhancement\nmethods like in-context learning and multi-LLM debate so that the AI agent can\nborrow human insight and update its knowledge by searching the latest chemical\nliterature. Additionally, we introduce a novel Coarse-label Contrastive\nLearning (CCL) based chemical fingerprint that greatly enhances the agent's\nperformance in optimizing the reaction condition. With the above efforts, the\nproposed AI agent can autonomously generate the optimal reaction condition\nrecommendation without any human interaction. Further, the agent is highly\nprofessional in terms of chemical reactions. It demonstrates close-to-human\nperformance and strong generalization capability in both dry-lab and wet-lab\nexperiments. As the first attempt in the chemical AI agent, this work goes a\nstep further in the field of \"AI for chemistry\" and opens up new possibilities\nfor computer-aided synthesis planning.",
            "author": [
                "Kexin Chen",
                "Junyou Li",
                "Kunyi Wang",
                "Yuyang Du",
                "Jiahui Yu",
                "Jiamin Lu",
                "Lanqing Li",
                "Jiezhong Qiu",
                "Qun Fang",
                "Pheng Ann Heng",
                "Guangyong Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10776v2",
                "http://arxiv.org/pdf/2311.10776v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09483v1",
            "title": "Adaptive Interventions with User-Defined Goals for Health Behavior\n  Change",
            "updated": "2023-11-16T01:00:04Z",
            "published": "2023-11-16T01:00:04Z",
            "summary": "Physical inactivity remains a major public health concern, having\nassociations with adverse health outcomes such as cardiovascular disease and\ntype-2 diabetes. Mobile health applications present a promising avenue for\nlow-cost, scalable physical activity promotion, yet often suffer from small\neffect sizes and low adherence rates, particularly in comparison to human\ncoaching. Goal-setting is a critical component of health coaching that has been\nunderutilized in adaptive algorithms for mobile health interventions. This\npaper introduces a modification to the Thompson sampling algorithm that places\nemphasis on individualized goal-setting by optimizing personalized reward\nfunctions. As a step towards supporting goal-setting, this paper offers a\nbalanced approach that can leverage shared structure while optimizing\nindividual preferences and goals. We prove that our modification incurs only a\nconstant penalty on the cumulative regret while preserving the sample\ncomplexity benefits of data sharing. In a physical activity simulator, we\ndemonstrate that our algorithm achieves substantial improvements in cumulative\nregret compared to baselines that do not share data or do not optimize for\nindividualized rewards.",
            "author": [
                "Aishwarya Mandyam",
                "Matthew Joerke",
                "Barbara E. Engelhardt",
                "Emma Brunskill"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09483v1",
                "http://arxiv.org/pdf/2311.09483v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09480v1",
            "title": "Show Your Work with Confidence: Confidence Bands for Tuning Curves",
            "updated": "2023-11-16T00:50:37Z",
            "published": "2023-11-16T00:50:37Z",
            "summary": "The choice of hyperparameters greatly impacts performance in natural language\nprocessing. Often, it is hard to tell if a method is better than another or\njust better tuned. Tuning curves fix this ambiguity by accounting for tuning\neffort. Specifically, they plot validation performance as a function of the\nnumber of hyperparameter choices tried so far. While several estimators exist\nfor these curves, it is common to use point estimates, which we show fail\nsilently and give contradictory results when given too little data.\n  Beyond point estimates, confidence bands are necessary to rigorously\nestablish the relationship between different approaches. We present the first\nmethod to construct valid confidence bands for tuning curves. The bands are\nexact, simultaneous, and distribution-free, thus they provide a robust basis\nfor comparing methods.\n  Empirical analysis shows that while bootstrap confidence bands, which serve\nas a baseline, fail to approximate their target confidence, ours achieve it\nexactly. We validate our design with ablations, analyze the effect of sample\nsize, and provide guidance on comparing models with our method. To promote\nconfident comparisons in future work, we release a library implementing the\nmethod at https://github.com/nalourie/opda .",
            "author": [
                "Nicholas Lourie",
                "Kyunghyun Cho",
                "He He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09480v1",
                "http://arxiv.org/pdf/2311.09480v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09471v1",
            "title": "Simulation Based Inference of BNS Kilonova Properties: A Case Study with\n  AT2017gfo",
            "updated": "2023-11-16T00:24:28Z",
            "published": "2023-11-16T00:24:28Z",
            "summary": "Kilonovae are a class of astronomical transients observed as counterparts to\nmergers of compact binary systems, such as a binary neutron star (BNS) or black\nhole-neutron star (BHNS) inspirals. They serve as probes for heavy-element\nnucleosynthesis in astrophysical environments, while together with\ngravitational wave emission constraining the distance to the merger itself,\nthey can place constraints on the Hubble constant. Obtaining the physical\nparameters (e.g. ejecta mass, velocity, composition) of a kilonova from\nobservations is a complex inverse problem, usually tackled by sampling-based\ninference methods such as Markov-chain Monte Carlo (MCMC) or nested sampling\ntechniques. These methods often rely on computing approximate likelihoods,\nsince a full simulation of compact object mergers involve expensive\ncomputations such as integrals, the calculation of likelihood of the observed\ndata given parameters can become intractable, rendering the likelihood-based\ninference approaches inapplicable. We propose here to use Simulation-based\nInference (SBI) techniques to infer the physical parameters of BNS kilonovae\nfrom their spectra, using simulations produced with KilonovaNet. Our model uses\nAmortized Neural Posterior Estimation (ANPE) together with an embedding neural\nnetwork to accurately predict posterior distributions from simulated spectra.\nWe further test our model with real observations from AT2017gfo, the only\nkilonova with multi-messenger data, and show that our estimates agree with\nprevious likelihood-based approaches.",
            "author": [
                "Phelipe A. Darc",
                "Clecio R. Bom",
                "Bernardo M. O. Fraga",
                "Charlie D. Kilpatrick"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09471v1",
                "http://arxiv.org/pdf/2311.09471v1"
            ],
            "primary_category": "astro-ph.HE",
            "category": [
                "astro-ph.HE",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09466v1",
            "title": "Soft Matching Distance: A metric on neural representations that captures\n  single-neuron tuning",
            "updated": "2023-11-16T00:13:00Z",
            "published": "2023-11-16T00:13:00Z",
            "summary": "Common measures of neural representational (dis)similarity are designed to be\ninsensitive to rotations and reflections of the neural activation space.\nMotivated by the premise that the tuning of individual units may be important,\nthere has been recent interest in developing stricter notions of\nrepresentational (dis)similarity that require neurons to be individually\nmatched across networks. When two networks have the same size (i.e. same number\nof neurons), a distance metric can be formulated by optimizing over neuron\nindex permutations to maximize tuning curve alignment. However, it is not clear\nhow to generalize this metric to measure distances between networks with\ndifferent sizes. Here, we leverage a connection to optimal transport theory to\nderive a natural generalization based on \"soft\" permutations. The resulting\nmetric is symmetric, satisfies the triangle inequality, and can be interpreted\nas a Wasserstein distance between two empirical distributions. Further, our\nproposed metric avoids counter-intuitive outcomes suffered by alternative\napproaches, and captures complementary geometric insights into neural\nrepresentations that are entirely missed by rotation-invariant metrics.",
            "author": [
                "Meenakshi Khosla",
                "Alex H. Williams"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09466v1",
                "http://arxiv.org/pdf/2311.09466v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.NE",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10775v1",
            "title": "ToolTalk: Evaluating Tool-Usage in a Conversational Setting",
            "updated": "2023-11-15T23:50:31Z",
            "published": "2023-11-15T23:50:31Z",
            "summary": "Large language models (LLMs) have displayed massive improvements in reasoning\nand decision-making skills and can hold natural conversations with users. Many\nrecent works seek to augment LLM-based assistants with external tools so they\ncan access private or up-to-date information and carry out actions on behalf of\nusers. To better measure the performance of these assistants, this paper\nintroduces ToolTalk, a benchmark consisting of complex user intents requiring\nmulti-step tool usage specified through dialogue. ToolTalk contains 28 tools\ngrouped into 7 plugins, and includes a complete simulated implementation of\neach tool, allowing for fully automated evaluation of assistants that rely on\nexecution feedback. ToolTalk also emphasizes tools that externally affect the\nworld rather than only tools for referencing or searching information. We\nevaluate GPT-3.5 and GPT-4 on ToolTalk resulting in success rates of 26% and\n50% respectively. Our analysis of the errors reveals three major categories and\nsuggests some future directions for improvement. We release ToolTalk at\nhttps://github.com/microsoft/ToolTalk.",
            "author": [
                "Nicholas Farn",
                "Richard Shin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10775v1",
                "http://arxiv.org/pdf/2311.10775v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09459v3",
            "title": "On Convex Optimal Value Functions For POSGs",
            "updated": "2023-12-06T09:16:14Z",
            "published": "2023-11-15T23:48:21Z",
            "summary": "Multi-agent planning and reinforcement learning can be challenging when\nagents cannot see the state of the world or communicate with each other due to\ncommunication costs, latency, or noise. Partially Observable Stochastic Games\n(POSGs) provide a mathematical framework for modelling such scenarios. This\npaper aims to improve the efficiency of planning and reinforcement learning\nalgorithms for POSGs by identifying the underlying structure of optimal\nstate-value functions. The approach involves reformulating the original game\nfrom the perspective of a trusted third party who plans on behalf of the agents\nsimultaneously. From this viewpoint, the original POSGs can be viewed as Markov\ngames where states are occupancy states, \\ie posterior probability\ndistributions over the hidden states of the world and the stream of actions and\nobservations that agents have experienced so far. This study mainly proves that\nthe optimal state-value function is a convex function of occupancy states\nexpressed on an appropriate basis in all zero-sum, common-payoff, and\nStackelberg POSGs.",
            "author": [
                "Rafael F. Cunha",
                "Jacopo Castellini",
                "Johan Peralez",
                "Jilles S. Dibangoye"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09459v3",
                "http://arxiv.org/pdf/2311.09459v3"
            ],
            "primary_category": "cs.MA",
            "category": [
                "cs.MA",
                "I.2.6, I.2.8, I.2.11"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09458v1",
            "title": "Lexical Repetitions Lead to Rote Learning: Unveiling the Impact of\n  Lexical Overlap in Train and Test Reference Summaries",
            "updated": "2023-11-15T23:47:53Z",
            "published": "2023-11-15T23:47:53Z",
            "summary": "Ideal summarization models should generalize to novel summary-worthy content\nwithout remembering reference training summaries by rote. However, a single\naverage performance score on the entire test set is inadequate in determining\nsuch model competencies. We propose a fine-grained evaluation protocol by\npartitioning a test set based on the lexical similarity of reference test\nsummaries with training summaries. We observe up to a 5x (1.2x) difference in\nROUGE-2 (entity recall) scores between the subsets with the lowest and highest\nsimilarity. Next, we show that such training repetitions also make a model\nvulnerable to rote learning, reproducing data artifacts such as factual errors,\nespecially when reference test summaries are lexically close to training\nsummaries. Consequently, we propose to limit lexical repetitions in training\nsummaries during both supervised fine-tuning and likelihood calibration stages\nto improve the performance on novel test cases while retaining average\nperformance. Our automatic and human evaluations on novel test subsets and\nrecent news articles show that limiting lexical repetitions in training\nsummaries can prevent rote learning and improve generalization.",
            "author": [
                "Prafulla Kumar Choubey",
                "Alexander R. Fabbri",
                "Caiming Xiong",
                "Chien-Sheng Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09458v1",
                "http://arxiv.org/pdf/2311.09458v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09456v1",
            "title": "DeepMartNet -- A Martingale Based Deep Neural Network Learning Method\n  for Dirichlet BVP and Eigenvalue Problems of Elliptic PDEs",
            "updated": "2023-11-15T23:45:44Z",
            "published": "2023-11-15T23:45:44Z",
            "summary": "In this paper, we propose DeepMartNet - a Martingale based deep neural\nnetwork learning method for solving Dirichlet boundary value problems (BVPs)\nand eigenvalue problems for elliptic partial differential equations (PDEs) in\nhigh dimensions. The method is based on Varadhan's Martingale problem\nformulation for the BVP/eigenvalue problems where a loss function enforcing the\nMartingale property for the PDE solution is used for efficient optimization by\nsampling the stochastic processes associated with elliptic operators. High\ndimensional numerical results for BVPs of the Poisson-Boltzmann equation and\neigenvalue problems of a Fokker-Planck equation demonstrate the capability of\nthe proposed DeepMartNet learning method for solving high dimensional PDE\nproblems.",
            "author": [
                "Wei Cai",
                "Andrew He",
                "Daniel Margolis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09456v1",
                "http://arxiv.org/pdf/2311.09456v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09449v1",
            "title": "HAL 9000: Skynet's Risk Manager",
            "updated": "2023-11-15T23:36:14Z",
            "published": "2023-11-15T23:36:14Z",
            "summary": "Intrusion Tolerant Systems (ITSs) are a necessary component for\ncyber-services/infrastructures. Additionally, as cyberattacks follow a\nmulti-domain attack surface, a similar defensive approach should be applied,\nnamely, the use of an evolving multi-disciplinary solution that combines ITS,\ncybersecurity and Artificial Intelligence (AI). With the increased popularity\nof AI solutions, due to Big Data use-case scenarios and decision support and\nautomation scenarios, new opportunities to apply Machine Learning (ML)\nalgorithms have emerged, namely ITS empowerment. Using ML algorithms, an ITS\ncan augment its intrusion tolerance capability, by learning from previous\nattacks and from known vulnerabilities. As such, this work's contribution is\ntwofold: (1) an ITS architecture (Skynet) based on the state-of-the-art and\nincorporates new components to increase its intrusion tolerance capability and\nits adaptability to new adversaries; (2) an improved Risk Manager design that\nleverages AI to improve ITSs by automatically assessing OS risks to intrusions,\nand advise with safer configurations. One of the reasons that intrusions are\nsuccessful is due to bad configurations or slow adaptability to new threats.\nThis can be caused by the dependency that systems have for human intervention.\nOne of the characteristics in Skynet and HAL 9000 design is the removal of\nhuman intervention. Being fully automatized lowers the chance of successful\nintrusions caused by human error. Our experiments using Skynet, shows that HAL\nis able to choose 15% safer configurations than the state-of-the-art risk\nmanager.",
            "author": [
                "Tadeu Freitas",
                "M\u00e1rio Neto",
                "In\u00eas Dutra",
                "Jo\u00e3o Soares",
                "Manuel Correia",
                "Rolando Martins"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09449v1",
                "http://arxiv.org/pdf/2311.09449v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.OS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09445v1",
            "title": "A Software-Hardware Co-Optimized Toolkit for Deep Reinforcement Learning\n  on Heterogeneous Platforms",
            "updated": "2023-11-15T23:31:18Z",
            "published": "2023-11-15T23:31:18Z",
            "summary": "Deep Reinforcement Learning (DRL) is vital in various AI applications. DRL\nalgorithms comprise diverse compute kernels, which may not be simultaneously\noptimized using a homogeneous architecture. However, even with available\nheterogeneous architectures, optimizing DRL performance remains a challenge due\nto the complexity of hardware and programming models employed in modern data\ncenters. To address this, we introduce PEARL, a toolkit for composing parallel\nDRL systems on heterogeneous platforms consisting of general-purpose processors\n(CPUs) and accelerators (GPUs, FPGAs). Our innovations include: 1. A general\ntraining protocol agnostic of the underlying hardware, enabling portable\nimplementations across various processors and accelerators. 2. Incorporation of\nDRL-specific scheduling optimizations within the protocol, facilitating\nparallelized training and enhancing the overall system performance. 3.\nHigh-level API for productive development using the toolkit. 4. Automatic\noptimization of DRL task-to-device assignments through performance estimation,\nsupporting various optimization metrics including throughput and power\nefficiency.\n  We showcase our toolkit through experimentation with two widely used DRL\nalgorithms, DQN and DDPG, on two diverse heterogeneous platforms. The generated\nimplementations outperform state-of-the-art libraries for CPU-GPU platforms by\nthroughput improvements of up to 2.1$\\times$ and power efficiency improvements\nof up to 3.4$\\times$.",
            "author": [
                "Yuan Meng",
                "Michael Kinsner",
                "Deshanand Singh",
                "Mahesh A Iyer",
                "Viktor Prasanna"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09445v1",
                "http://arxiv.org/pdf/2311.09445v1"
            ],
            "primary_category": "cs.DC",
            "category": [
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09441v1",
            "title": "Exploring the Privacy-Energy Consumption Tradeoff for Split Federated\n  Learning",
            "updated": "2023-11-15T23:23:42Z",
            "published": "2023-11-15T23:23:42Z",
            "summary": "Split Federated Learning (SFL) has recently emerged as a promising\ndistributed learning technology, leveraging the strengths of both federated\nlearning and split learning. It emphasizes the advantages of rapid convergence\nwhile addressing privacy concerns. As a result, this innovation has received\nsignificant attention from both industry and academia. However, since the model\nis split at a specific layer, known as a cut layer, into both client-side and\nserver-side models for the SFL, the choice of the cut layer in SFL can have a\nsubstantial impact on the energy consumption of clients and their privacy, as\nit influences the training burden and the output of the client-side models.\nMoreover, the design challenge of determining the cut layer is highly\nintricate, primarily due to the inherent heterogeneity in the computing and\nnetworking capabilities of clients. In this article, we provide a comprehensive\noverview of the SFL process and conduct a thorough analysis of energy\nconsumption and privacy. This analysis takes into account the influence of\nvarious system parameters on the cut layer selection strategy. Additionally, we\nprovide an illustrative example of the cut layer selection, aiming to minimize\nthe risk of clients from reconstructing the raw data at the server while\nsustaining energy consumption within the required energy budget, which involve\ntrade-offs. Finally, we address open challenges in this field including their\napplications to 6G technology. These directions represent promising avenues for\nfuture research and development.",
            "author": [
                "Joohyung Lee",
                "Mohamed Seif",
                "Jungchan Cho",
                "H. Vincent Poor"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09441v1",
                "http://arxiv.org/pdf/2311.09441v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09439v1",
            "title": "Learning Hyperplanes for Multi-Agent Collision Avoidance in Space",
            "updated": "2023-11-15T23:20:49Z",
            "published": "2023-11-15T23:20:49Z",
            "summary": "A core challenge of multi-robot interactions is collision avoidance among\nrobots with potentially conflicting objectives. We propose a game-theoretic\nmethod for collision avoidance based on rotating hyperplane constraints. These\nconstraints ensure collision avoidance by defining separating hyperplanes that\nrotate around a keep-out zone centered on certain robots. Since it is\nchallenging to select the parameters that define a hyperplane without\nintroducing infeasibilities, we propose to learn them from an expert trajectory\ni.e., one collected by recording human operators. To do so, we solve for the\nparameters whose corresponding equilibrium trajectory best matches the expert\ntrajectory. We validate our method by learning hyperplane parameters from noisy\nexpert trajectories and demonstrate the generalizability of the learned\nparameters to scenarios with more robots and previously unseen initial\nconditions.",
            "author": [
                "Fernando Palafox",
                "Yue Yu",
                "David Fridovich-Keil"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09439v1",
                "http://arxiv.org/pdf/2311.09439v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.MA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09438v1",
            "title": "Labeled Interactive Topic Models",
            "updated": "2023-11-15T23:18:01Z",
            "published": "2023-11-15T23:18:01Z",
            "summary": "Topic models help users understand large document collections; however, topic\nmodels do not always find the ``right'' topics. While classical probabilistic\nand anchor-based topic models have interactive variants to guide models toward\nbetter topics, such interactions are not available for neural topic models such\nas the embedded topic model (\\abr{etm}). We correct this lacuna by adding an\nintuitive interaction to neural topic models: users can label a topic with a\nword, and topics are updated so that the topic words are close to the label.\nThis allows a user to refine topics based on their information need. While,\ninteractivity is intuitive for \\abr{etm}, we extend this framework to work with\nother neural topic models as well. We develop an interactive interface which\nallows users to interact and relabel topic models as they see fit. We evaluate\nour method through a human study, where users can relabel topics to find\nrelevant documents. Using our method, user labeling improves document rank\nscores, helping to find more relevant documents to a given query when compared\nto no user labeling.",
            "author": [
                "Kyle Seelman",
                "Mozhi Zhang",
                "Jordan Boyd-Graber"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09438v1",
                "http://arxiv.org/pdf/2311.09438v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.HC",
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09431v1",
            "title": "Striped Attention: Faster Ring Attention for Causal Transformers",
            "updated": "2023-11-15T23:01:02Z",
            "published": "2023-11-15T23:01:02Z",
            "summary": "To help address the growing demand for ever-longer sequence lengths in\ntransformer models, Liu et al. recently proposed Ring Attention, an exact\nattention algorithm capable of overcoming per-device memory bottle- necks by\ndistributing self-attention across multiple devices. In this paper, we study\nthe performance characteristics of Ring Attention in the important special case\nof causal transformer models, and identify a key workload imbal- ance due to\ntriangular structure of causal attention computations. We propose a simple\nextension to Ring Attention, which we call Striped Attention to fix this\nimbalance. Instead of devices having contiguous subsequences, each device has a\nsubset of tokens distributed uniformly throughout the sequence, which we\ndemonstrate leads to more even workloads. In experiments running Striped\nAttention on A100 GPUs and TPUv4s, we are able to achieve up to 1.45x\nend-to-end throughput improvements over the original Ring Attention algorithm\non causal transformer training at a sequence length of 256k. Furthermore, on 16\nTPUv4 chips, we were able to achieve 1.65x speedups at sequence lengths of\n786k. We release the code for our experiments as open source",
            "author": [
                "William Brandon",
                "Aniruddha Nrusimha",
                "Kevin Qian",
                "Zachary Ankner",
                "Tian Jin",
                "Zhiye Song",
                "Jonathan Ragan-Kelley"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09431v1",
                "http://arxiv.org/pdf/2311.09431v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09428v2",
            "title": "Beyond Detection: Unveiling Fairness Vulnerabilities in Abusive Language\n  Models",
            "updated": "2023-12-05T20:36:23Z",
            "published": "2023-11-15T22:57:13Z",
            "summary": "This work investigates the potential of undermining both fairness and\ndetection performance in abusive language detection. In a dynamic and complex\ndigital world, it is crucial to investigate the vulnerabilities of these\ndetection models to adversarial fairness attacks to improve their fairness\nrobustness. We propose a simple yet effective framework FABLE that leverages\nbackdoor attacks as they allow targeted control over the fairness and detection\nperformance. FABLE explores three types of trigger designs (i.e., rare,\nartificial, and natural triggers) and novel sampling strategies. Specifically,\nthe adversary can inject triggers into samples in the minority group with the\nfavored outcome (i.e., \"non-abusive\") and flip their labels to the unfavored\noutcome, i.e., \"abusive\". Experiments on benchmark datasets demonstrate the\neffectiveness of FABLE attacking fairness and utility in abusive language\ndetection.",
            "author": [
                "Yueqing Liang",
                "Lu Cheng",
                "Ali Payani",
                "Kai Shu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09428v2",
                "http://arxiv.org/pdf/2311.09428v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09413v1",
            "title": "Leveraging machine learning to enhance climate models: a review",
            "updated": "2023-11-15T22:30:32Z",
            "published": "2023-11-15T22:30:32Z",
            "summary": "Recent achievements in machine learning (Ml) have had a significant impact on\nvarious fields, including climate science. Climate modeling is very important\nand plays a crucial role in shaping the decisions of governments and\nindividuals in mitigating the impact of climate change. Climate change poses a\nserious threat to humanity, however, current climate models are limited by\ncomputational costs, uncertainties, and biases, affecting their prediction\naccuracy. The vast amount of climate data generated by satellites, radars, and\nearth system models (ESMS) poses a significant challenge. ML techniques can be\neffectively employed to analyze this data and extract valuable insights that\naid in our understanding of the earth climate. This review paper focuses on how\nml has been utilized in the last 5 years to boost the current state-of-the-art\nclimate models. We invite the ml community to join in the global effort to\naccurately model the earth climate by collaborating with other fields to\nleverage ml as a powerful tool in this endeavor.",
            "author": [
                "Ahmed Elsayed",
                "Shrouk Wally",
                "Islam Alkabbany",
                "Asem Ali",
                "Aly Farag"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09413v1",
                "http://arxiv.org/pdf/2311.09413v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10773v1",
            "title": "User Persona Identification and New Service Adaptation Recommendation",
            "updated": "2023-11-15T22:11:39Z",
            "published": "2023-11-15T22:11:39Z",
            "summary": "Providing a personalized user experience on information dense webpages helps\nusers in reaching their end-goals sooner. We explore an automated approach to\nidentifying user personas by leveraging high dimensional trajectory information\nfrom user sessions on webpages. While neural collaborative filtering (NCF)\napproaches pay little attention to token semantics, our method introduces\nSessionBERT, a Transformer-backed language model trained from scratch on the\nmasked language modeling (mlm) objective for user trajectories (pages,\nmetadata, billing in a session) aiming to capture semantics within them. Our\nresults show that representations learned through SessionBERT are able to\nconsistently outperform a BERT-base model providing a 3% and 1% relative\nimprovement in F1-score for predicting page links and next services. We\nleverage SessionBERT and extend it to provide recommendations (top-5) for the\nnext most-relevant services that a user would be likely to use. We achieve a\nHIT@5 of 58% from our recommendation model.",
            "author": [
                "Narges Tabari",
                "Sandesh Swamy",
                "Rashmi Gangadharaiah"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10773v1",
                "http://arxiv.org/pdf/2311.10773v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09406v1",
            "title": "Alternatives to the Scaled Dot Product for Attention in the Transformer\n  Neural Network Architecture",
            "updated": "2023-11-15T22:10:42Z",
            "published": "2023-11-15T22:10:42Z",
            "summary": "The transformer neural network architecture uses a form of attention in which\nthe dot product of query and key is divided by the square root of the key\ndimension before applying softmax. This scaling of the dot product is designed\nto avoid the absolute value of the dot products becoming so large that applying\nsoftmax leads to vanishing gradients. In this paper, we propose some\nalternative scalings, including dividing the dot product instead by the sum of\nthe key lengths before applying softmax. We use simulated keys and queries to\nshow that in many situations this appears to be more effective at avoiding\nregions where applying softmax leads to vanishing gradients.",
            "author": [
                "James Bernhard"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09406v1",
                "http://arxiv.org/pdf/2311.09406v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.NE",
                "I.2.0; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09402v1",
            "title": "Synthetically Enhanced: Unveiling Synthetic Data's Potential in Medical\n  Imaging Research",
            "updated": "2023-11-15T21:58:01Z",
            "published": "2023-11-15T21:58:01Z",
            "summary": "Chest X-rays (CXR) are the most common medical imaging study and are used to\ndiagnose multiple medical conditions. This study examines the impact of\nsynthetic data supplementation, using diffusion models, on the performance of\ndeep learning (DL) classifiers for CXR analysis. We employed three datasets:\nCheXpert, MIMIC-CXR, and Emory Chest X-ray, training conditional denoising\ndiffusion probabilistic models (DDPMs) to generate synthetic frontal\nradiographs. Our approach ensured that synthetic images mirrored the\ndemographic and pathological traits of the original data. Evaluating the\nclassifiers' performance on internal and external datasets revealed that\nsynthetic data supplementation enhances model accuracy, particularly in\ndetecting less prevalent pathologies. Furthermore, models trained on synthetic\ndata alone approached the performance of those trained on real data. This\nsuggests that synthetic data can potentially compensate for real data shortages\nin training robust DL models. However, despite promising outcomes, the\nsuperiority of real data persists.",
            "author": [
                "Bardia Khosravi",
                "Frank Li",
                "Theo Dapamede",
                "Pouria Rouzrokh",
                "Cooper U. Gamble",
                "Hari M. Trivedi",
                "Cody C. Wyles",
                "Andrew B. Sellergren",
                "Saptarshi Purkayastha",
                "Bradley J. Erickson",
                "Judy W. Gichoya"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09402v1",
                "http://arxiv.org/pdf/2311.09402v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09401v1",
            "title": "MoCo-Transfer: Investigating out-of-distribution contrastive learning\n  for limited-data domains",
            "updated": "2023-11-15T21:56:47Z",
            "published": "2023-11-15T21:56:47Z",
            "summary": "Medical imaging data is often siloed within hospitals, limiting the amount of\ndata available for specialized model development. With limited in-domain data,\none might hope to leverage larger datasets from related domains. In this paper,\nwe analyze the benefit of transferring self-supervised contrastive\nrepresentations from moment contrast (MoCo) pretraining on out-of-distribution\ndata to settings with limited data. We consider two X-ray datasets which image\ndifferent parts of the body, and compare transferring from each other to\ntransferring from ImageNet. We find that depending on quantity of labeled and\nunlabeled data, contrastive pretraining on larger out-of-distribution datasets\ncan perform nearly as well or better than MoCo pretraining in-domain, and\npretraining on related domains leads to higher performance than if one were to\nuse the ImageNet pretrained weights. Finally, we provide a preliminary way of\nquantifying similarity between datasets.",
            "author": [
                "Yuwen Chen",
                "Helen Zhou",
                "Zachary C. Lipton"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09401v1",
                "http://arxiv.org/pdf/2311.09401v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09389v1",
            "title": "Neural machine translation for automated feedback on children's\n  early-stage writing",
            "updated": "2023-11-15T21:32:44Z",
            "published": "2023-11-15T21:32:44Z",
            "summary": "In this work, we address the problem of assessing and constructing feedback\nfor early-stage writing automatically using machine learning. Early-stage\nwriting is typically vastly different from conventional writing due to phonetic\nspelling and lack of proper grammar, punctuation, spacing etc. Consequently,\nearly-stage writing is highly non-trivial to analyze using common linguistic\nmetrics. We propose to use sequence-to-sequence models for \"translating\"\nearly-stage writing by students into \"conventional\" writing, which allows the\ntranslated text to be analyzed using linguistic metrics. Furthermore, we\npropose a novel robust likelihood to mitigate the effect of noise in the\ndataset. We investigate the proposed methods using a set of numerical\nexperiments and demonstrate that the conventional text can be predicted with\nhigh accuracy.",
            "author": [
                "Jonas Vestergaard Jensen",
                "Mikkel Jordahn",
                "Michael Riis Andersen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09389v1",
                "http://arxiv.org/pdf/2311.09389v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09387v2",
            "title": "Banach-Tarski Embeddings and Transformers",
            "updated": "2023-11-21T18:31:57Z",
            "published": "2023-11-15T21:30:26Z",
            "summary": "We introduce a new construction of embeddings of arbitrary recursive data\nstructures into high dimensional vectors. These embeddings provide an\ninterpretable model for the latent state vectors of transformers. We\ndemonstrate that these embeddings can be decoded to the original data structure\nwhen the embedding dimension is sufficiently large. This decoding algorithm has\na natural implementation as a transformer. We also show that these embedding\nvectors can be manipulated directly to perform computations on the underlying\ndata without decoding. As an example we present an algorithm that constructs\nthe embedded parse tree of an embedded token sequence using only vector\noperations in embedding space.",
            "author": [
                "Joshua Maher"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09387v2",
                "http://arxiv.org/pdf/2311.09387v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.DS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09386v1",
            "title": "Beyond PCA: A Probabilistic Gram-Schmidt Approach to Feature Extraction",
            "updated": "2023-11-15T21:29:57Z",
            "published": "2023-11-15T21:29:57Z",
            "summary": "Linear feature extraction at the presence of nonlinear dependencies among the\ndata is a fundamental challenge in unsupervised learning. We propose using a\nProbabilistic Gram-Schmidt (PGS) type orthogonalization process in order to\ndetect and map out redundant dimensions. Specifically, by applying the PGS\nprocess over any family of functions which presumably captures the nonlinear\ndependencies in the data, we construct a series of covariance matrices that can\neither be used to remove those dependencies from the principal components, or\nto identify new large-variance directions. In the former case, we prove that\nunder certain assumptions the resulting algorithms detect and remove nonlinear\ndependencies whenever those dependencies lie in the linear span of the chosen\nfunction family. In the latter, we provide information-theoretic guarantees in\nterms of entropy reduction. Both proposed methods extract linear features from\nthe data while removing nonlinear redundancies. We provide simulation results\non synthetic and real-world datasets which show improved performance over PCA\nand state-of-the-art linear feature extraction algorithms, both in terms of\nvariance maximization of the extracted features, and in terms of improved\nperformance of classification algorithms.",
            "author": [
                "Bahram Yaghooti",
                "Netanel Raviv",
                "Bruno Sinopoli"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09386v1",
                "http://arxiv.org/pdf/2311.09386v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10112v1",
            "title": "Zero-Shot Relational Learning on Temporal Knowledge Graphs with Large\n  Language Models",
            "updated": "2023-11-15T21:25:15Z",
            "published": "2023-11-15T21:25:15Z",
            "summary": "In recent years, modeling evolving knowledge over temporal knowledge graphs\n(TKGs) has become a heated topic. Various methods have been proposed to\nforecast links on TKGs. Most of them are embedding-based, where hidden\nrepresentations are learned to represent knowledge graph (KG) entities and\nrelations based on the observed graph contexts. Although these methods show\nstrong performance on traditional TKG forecasting (TKGF) benchmarks, they\nnaturally face a strong challenge when they are asked to model the unseen\nzero-shot relations that has no prior graph context. In this paper, we try to\nmitigate this problem as follows. We first input the text descriptions of KG\nrelations into large language models (LLMs) for generating relation\nrepresentations, and then introduce them into embedding-based TKGF methods.\nLLM-empowered representations can capture the semantic information in the\nrelation descriptions. This makes the relations, whether seen or unseen, with\nsimilar semantic meanings stay close in the embedding space, enabling TKGF\nmodels to recognize zero-shot relations even without any observed graph\ncontext. Experimental results show that our approach helps TKGF models to\nachieve much better performance in forecasting the facts with previously unseen\nrelations, while still maintaining their ability in link forecasting regarding\nseen relations.",
            "author": [
                "Zifeng Ding",
                "Heling Cai",
                "Jingpei Wu",
                "Yunpu Ma",
                "Ruotong Liao",
                "Bo Xiong",
                "Volker Tresp"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10112v1",
                "http://arxiv.org/pdf/2311.10112v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09383v1",
            "title": "Long-form Question Answering: An Iterative Planning-Retrieval-Generation\n  Approach",
            "updated": "2023-11-15T21:22:27Z",
            "published": "2023-11-15T21:22:27Z",
            "summary": "Long-form question answering (LFQA) poses a challenge as it involves\ngenerating detailed answers in the form of paragraphs, which go beyond simple\nyes/no responses or short factual answers. While existing QA models excel in\nquestions with concise answers, LFQA requires handling multiple topics and\ntheir intricate relationships, demanding comprehensive explanations. Previous\nattempts at LFQA focused on generating long-form answers by utilizing relevant\ncontexts from a corpus, relying solely on the question itself. However, they\noverlooked the possibility that the question alone might not provide sufficient\ninformation to identify the relevant contexts. Additionally, generating\ndetailed long-form answers often entails aggregating knowledge from diverse\nsources. To address these limitations, we propose an LFQA model with iterative\nPlanning, Retrieval, and Generation. This iterative process continues until a\ncomplete answer is generated for the given question. From an extensive\nexperiment on both an open domain and a technical domain QA dataset, we find\nthat our model outperforms the state-of-the-art models on various textual and\nfactual metrics for the LFQA task.",
            "author": [
                "Pritom Saha Akash",
                "Kashob Kumar Roy",
                "Lucian Popa",
                "Kevin Chen-Chuan Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09383v1",
                "http://arxiv.org/pdf/2311.09383v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09375v1",
            "title": "HypOp: Distributed Constrained Combinatorial Optimization leveraging\n  Hypergraph Neural Networks",
            "updated": "2023-11-15T21:06:49Z",
            "published": "2023-11-15T21:06:49Z",
            "summary": "Scalable addressing of high dimensional constrained combinatorial\noptimization problems is a challenge that arises in several science and\nengineering disciplines. Recent work introduced novel application of graph\nneural networks for solving polynomial-cost unconstrained combinatorial\noptimization problems. This paper proposes a new framework, called HypOp, which\ngreatly advances the state of the art for solving combinatorial optimization\nproblems in several aspects: (i) it generalizes the prior results to\nconstrained optimization problems with an arbitrary cost function; (ii) it\nbroadens the application to higher dimensional problems by leveraging a\nhypergraph neural network structure; (iii) it enables scalability to much\nlarger problems by introducing a new distributed and parallel architecture for\nhypergraph neural network training; (iv) it demonstrates generalizability to\nother problem formulations by knowledge transfer from the learned experience of\naddressing one set of cost/constraints to another set for the same hypergraph;\n(v) it significantly boosts the solution accuracy compared with the prior art\nby suggesting a fine-tuning step using simulated annealing; (vi) HypOp shows a\nremarkable progress on benchmark examples, with run times improved by up to\nfivefold using a combination of fine-tuning and distributed training\ntechniques. The framework allows addressing a novel set of scientific problems\nincluding hypergraph MaxCut problem, satisfiability problems (3SAT), and\nresource allocation. We showcase the application of HypOp in scientific\ndiscovery by solving a hypergraph MaxCut problem on the NDC drug-substance\nhypergraph. Through extensive experimentation on a variety of combinatorial\noptimization problems, HypOp demonstrates superiority over existing\nunsupervised learning-based solvers and generic optimization methods.",
            "author": [
                "Nasimeh Heydaribeni",
                "Xinrui Zhan",
                "Ruisi Zhang",
                "Tina Eliassi-Rad",
                "Farinaz Koushanfar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09375v1",
                "http://arxiv.org/pdf/2311.09375v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09369v1",
            "title": "Time-dependent Probabilistic Generative Models for Disease Progression",
            "updated": "2023-11-15T21:00:00Z",
            "published": "2023-11-15T21:00:00Z",
            "summary": "Electronic health records contain valuable information for monitoring\npatients' health trajectories over time. Disease progression models have been\ndeveloped to understand the underlying patterns and dynamics of diseases using\nthese data as sequences. However, analyzing temporal data from EHRs is\nchallenging due to the variability and irregularities present in medical\nrecords. We propose a Markovian generative model of treatments developed to (i)\nmodel the irregular time intervals between medical events; (ii) classify\ntreatments into subtypes based on the patient sequence of medical events and\nthe time intervals between them; and (iii) segment treatments into subsequences\nof disease progression patterns. We assume that sequences have an associated\nstructure of latent variables: a latent class representing the different\nsubtypes of treatments; and a set of latent stages indicating the phase of\nprogression of the treatments. We use the Expectation-Maximization algorithm to\nlearn the model, which is efficiently solved with a dynamic programming-based\nmethod. Various parametric models have been employed to model the time\nintervals between medical events during the learning process, including the\ngeometric, exponential, and Weibull distributions. The results demonstrate the\neffectiveness of our model in recovering the underlying model from data and\naccurately modeling the irregular time intervals between medical actions.",
            "author": [
                "Onintze Zaballa",
                "Aritz P\u00e9rez",
                "Elisa G\u00f3mez-Inhiesto",
                "Teresa Acaiturri-Ayesta",
                "Jose A. Lozano"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09369v1",
                "http://arxiv.org/pdf/2311.09369v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CY",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09366v1",
            "title": "LOKE: Linked Open Knowledge Extraction for Automated Knowledge Graph\n  Construction",
            "updated": "2023-11-15T20:57:44Z",
            "published": "2023-11-15T20:57:44Z",
            "summary": "While the potential of Open Information Extraction (Open IE) for Knowledge\nGraph Construction (KGC) may seem promising, we find that the alignment of Open\nIE extraction results with existing knowledge graphs to be inadequate. The\nadvent of Large Language Models (LLMs), especially the commercially available\nOpenAI models, have reset expectations for what is possible with deep learning\nmodels and have created a new field called prompt engineering. We investigate\nthe use of GPT models and prompt engineering for knowledge graph construction\nwith the Wikidata knowledge graph to address a similar problem to Open IE,\nwhich we call Open Knowledge Extraction (OKE) using an approach we call the\nLinked Open Knowledge Extractor (LOKE, pronounced like \"Loki\"). We consider the\nentity linking task essential to construction of real world knowledge graphs.\nWe merge the CaRB benchmark scoring approach with data from the TekGen dataset\nfor the LOKE task. We then show that a well engineered prompt, paired with a\nnaive entity linking approach (which we call LOKE-GPT), outperforms AllenAI's\nOpenIE 4 implementation on the OKE task, although it over-generates triples\ncompared to the reference set due to overall triple scarcity in the TekGen set.\nThrough an analysis of entity linkability in the CaRB dataset, as well as\noutputs from OpenIE 4 and LOKE-GPT, we see that LOKE-GPT and the \"silver\"\nTekGen triples show that the task is significantly different in content from\nOIE, if not structure. Through this analysis and a qualitative analysis of\nsentence extractions via all methods, we found that LOKE-GPT extractions are of\nhigh utility for the KGC task and suitable for use in semi-automated extraction\nsettings.",
            "author": [
                "Jamie McCusker"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09366v1",
                "http://arxiv.org/pdf/2311.09366v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09355v1",
            "title": "Privacy Threats in Stable Diffusion Models",
            "updated": "2023-11-15T20:31:40Z",
            "published": "2023-11-15T20:31:40Z",
            "summary": "This paper introduces a novel approach to membership inference attacks (MIA)\ntargeting stable diffusion computer vision models, specifically focusing on the\nhighly sophisticated Stable Diffusion V2 by StabilityAI. MIAs aim to extract\nsensitive information about a model's training data, posing significant privacy\nconcerns. Despite its advancements in image synthesis, our research reveals\nprivacy vulnerabilities in the stable diffusion models' outputs. Exploiting\nthis information, we devise a black-box MIA that only needs to query the victim\nmodel repeatedly. Our methodology involves observing the output of a stable\ndiffusion model at different generative epochs and training a classification\nmodel to distinguish when a series of intermediates originated from a training\nsample or not. We propose numerous ways to measure the membership features and\ndiscuss what works best. The attack's efficacy is assessed using the ROC AUC\nmethod, demonstrating a 60\\% success rate in inferring membership information.\nThis paper contributes to the growing body of research on privacy and security\nin machine learning, highlighting the need for robust defenses against MIAs.\nOur findings prompt a reevaluation of the privacy implications of stable\ndiffusion models, urging practitioners and developers to implement enhanced\nsecurity measures to safeguard against such attacks.",
            "author": [
                "Thomas Cilloni",
                "Charles Fleming",
                "Charles Walter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09355v1",
                "http://arxiv.org/pdf/2311.09355v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09354v1",
            "title": "Nondestructive, quantitative viability analysis of 3D tissue cultures\n  using machine learning image segmentation",
            "updated": "2023-11-15T20:28:31Z",
            "published": "2023-11-15T20:28:31Z",
            "summary": "Ascertaining the collective viability of cells in different cell culture\nconditions has typically relied on averaging colorimetric indicators and is\noften reported out in simple binary readouts. Recent research has combined\nviability assessment techniques with image-based deep-learning models to\nautomate the characterization of cellular properties. However, further\ndevelopment of viability measurements to assess the continuity of possible\ncellular states and responses to perturbation across cell culture conditions is\nneeded. In this work, we demonstrate an image processing algorithm for\nquantifying cellular viability in 3D cultures without the need for assay-based\nindicators. We show that our algorithm performs similarly to a pair of human\nexperts in whole-well images over a range of days and culture matrix\ncompositions. To demonstrate potential utility, we perform a longitudinal study\ninvestigating the impact of a known therapeutic on pancreatic cancer spheroids.\nUsing images taken with a high content imaging system, the algorithm\nsuccessfully tracks viability at the individual spheroid and whole-well level.\nThe method we propose reduces analysis time by 97% in comparison to the\nexperts. Because the method is independent of the microscope or imaging system\nused, this approach lays the foundation for accelerating progress in and for\nimproving the robustness and reproducibility of 3D culture analysis across\nbiological and clinical research.",
            "author": [
                "Kylie J. Trettner",
                "Jeremy Hsieh",
                "Weikun Xiao",
                "Jerry S. H. Lee",
                "Andrea M. Armani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09354v1",
                "http://arxiv.org/pdf/2311.09354v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09353v1",
            "title": "Flexible and Adaptive Manufacturing by Complementing Knowledge\n  Representation, Reasoning and Planning with Reinforcement Learning",
            "updated": "2023-11-15T20:28:27Z",
            "published": "2023-11-15T20:28:27Z",
            "summary": "This paper describes a novel approach to adaptive manufacturing in the\ncontext of small batch production and customization. It focuses on integrating\ntask-level planning and reasoning with reinforcement learning (RL) in the\nSkiROS2 skill-based robot control platform. This integration enhances the\nefficiency and adaptability of robotic systems in manufacturing, enabling them\nto adjust to task variations and learn from interaction data. The paper\nhighlights the architecture of SkiROS2, particularly its world model, skill\nlibraries, and task management. It demonstrates how combining RL with robotic\nmanipulators can learn and improve the execution of industrial tasks. It\nadvocates a multi-objective learning model that eases the learning problem\ndesign. The approach can incorporate user priors or previous experiences to\naccelerate learning and increase safety.\n  Spotlight video: https://youtu.be/H5PmZl2rRbs?si=8wmZ-gbwuSJRxe3S&t=1422\n  SkiROS2 code: https://github.com/RVMI/skiros2\n  SkiROS2 talk at ROSCon: https://vimeo.com/879001825/2a0e9d5412\n  SkiREIL code: https://github.com/matthias-mayr/SkiREIL",
            "author": [
                "Matthias Mayr",
                "Faseeh Ahmad",
                "Volker Krueger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09353v1",
                "http://arxiv.org/pdf/2311.09353v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09350v1",
            "title": "Generalizable Imitation Learning Through Pre-Trained Representations",
            "updated": "2023-11-15T20:15:51Z",
            "published": "2023-11-15T20:15:51Z",
            "summary": "In this paper we leverage self-supervised vision transformer models and their\nemergent semantic abilities to improve the generalization abilities of\nimitation learning policies. We introduce BC-ViT, an imitation learning\nalgorithm that leverages rich DINO pre-trained Visual Transformer (ViT)\npatch-level embeddings to obtain better generalization when learning through\ndemonstrations. Our learner sees the world by clustering appearance features\ninto semantic concepts, forming stable keypoints that generalize across a wide\nrange of appearance variations and object types. We show that this\nrepresentation enables generalized behaviour by evaluating imitation learning\nacross a diverse dataset of object manipulation tasks. Our method, data and\nevaluation approach are made available to facilitate further study of\ngeneralization in Imitation Learners.",
            "author": [
                "Wei-Di Chang",
                "Francois Hogan",
                "David Meger",
                "Gregory Dudek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09350v1",
                "http://arxiv.org/pdf/2311.09350v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09349v1",
            "title": "Generative AI-Based Probabilistic Constellation Shaping With Diffusion\n  Models",
            "updated": "2023-11-15T20:14:21Z",
            "published": "2023-11-15T20:14:21Z",
            "summary": "Diffusion models are at the vanguard of generative AI research with renowned\nsolutions such as ImageGen by Google Brain and DALL.E 3 by OpenAI.\nNevertheless, the potential merits of diffusion models for communication\nengineering applications are not fully understood yet. In this paper, we aim to\nunleash the power of generative AI for PHY design of constellation symbols in\ncommunication systems. Although the geometry of constellations is predetermined\naccording to networking standards, e.g., quadrature amplitude modulation (QAM),\nprobabilistic shaping can design the probability of occurrence (generation) of\nconstellation symbols. This can help improve the information rate and decoding\nperformance of communication systems. We exploit the ``denoise-and-generate''\ncharacteristics of denoising diffusion probabilistic models (DDPM) for\nprobabilistic constellation shaping. The key idea is to learn generating\nconstellation symbols out of noise, ``mimicking'' the way the receiver performs\nsymbol reconstruction. This way, we make the constellation symbols sent by the\ntransmitter, and what is inferred (reconstructed) at the receiver become as\nsimilar as possible, resulting in as few mismatches as possible. Our results\nshow that the generative AI-based scheme outperforms deep neural network\n(DNN)-based benchmark and uniform shaping, while providing network resilience\nas well as robust out-of-distribution performance under low-SNR regimes and\nnon-Gaussian assumptions. Numerical evaluations highlight 30% improvement in\nterms of cosine similarity and a threefold improvement in terms of mutual\ninformation compared to DNN-based approach for 64-QAM geometry.",
            "author": [
                "Mehdi Letafati",
                "Samad Ali",
                "Matti Latva-aho"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09349v1",
                "http://arxiv.org/pdf/2311.09349v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.AI",
                "cs.LG",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09348v1",
            "title": "Analysis of Research Trends in Computer Science: A Network Approach",
            "updated": "2023-11-15T20:10:57Z",
            "published": "2023-11-15T20:10:57Z",
            "summary": "Nowadays, computer science (CS) has emerged as a dominant force in numerous\nresearch areas both within and beyond its own discipline. However, despite its\nsignificant impact on scholarly space, only a limited number of studies have\nbeen conducted to analyze the research trends and relationships within computer\nscience. In this study, we collected information on fields and subfields from\nover 2,000 research articles published in the 2022 proceedings of the top\nAssociation for Computing Machinery (ACM) conferences spanning various research\nfields. Through a network approach, we investigated the interconnections\nbetween CS fields and subfields to evaluate their interdisciplinarity and\nmultidisciplinarity. Our findings indicate that computing methodologies and\nprivacy and security stand out as the most interdisciplinary fields, while\nhuman-centered computing exhibits the highest frequency among the papers.\nFurthermore, we discovered that machine learning emerges as the most\ninterdisciplinary and multidisciplinary subfield within computer science. These\nresults offer valuable insights for universities seeking to foster\ninterdisciplinary research opportunities for their students.",
            "author": [
                "Ghazal Kalhor",
                "Behnam Bahrak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09348v1",
                "http://arxiv.org/pdf/2311.09348v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09346v1",
            "title": "Nothing Stands Still: A Spatiotemporal Benchmark on 3D Point Cloud\n  Registration Under Large Geometric and Temporal Change",
            "updated": "2023-11-15T20:09:29Z",
            "published": "2023-11-15T20:09:29Z",
            "summary": "Building 3D geometric maps of man-made spaces is a well-established and\nactive field that is fundamental to computer vision and robotics. However,\nconsidering the evolving nature of built environments, it is essential to\nquestion the capabilities of current mapping efforts in handling temporal\nchanges. In addition, spatiotemporal mapping holds significant potential for\nachieving sustainability and circularity goals. Existing mapping approaches\nfocus on small changes, such as object relocation or self-driving car\noperation; in all cases where the main structure of the scene remains fixed.\nConsequently, these approaches fail to address more radical changes in the\nstructure of the built environment, such as geometry and topology. To this end,\nwe introduce the Nothing Stands Still (NSS) benchmark, which focuses on the\nspatiotemporal registration of 3D scenes undergoing large spatial and temporal\nchange, ultimately creating one coherent spatiotemporal map. Specifically, the\nbenchmark involves registering two or more partial 3D point clouds (fragments)\nfrom the same scene but captured from different spatiotemporal views. In\naddition to the standard pairwise registration, we assess the multi-way\nregistration of multiple fragments that belong to any temporal stage. As part\nof NSS, we introduce a dataset of 3D point clouds recurrently captured in\nlarge-scale building indoor environments that are under construction or\nrenovation. The NSS benchmark presents three scenarios of increasing\ndifficulty, to quantify the generalization ability of point cloud registration\nmethods over space (within one building and across buildings) and time. We\nconduct extensive evaluations of state-of-the-art methods on NSS. The results\ndemonstrate the necessity for novel methods specifically designed to handle\nlarge spatiotemporal changes. The homepage of our benchmark is at\nhttp://nothing-stands-still.com.",
            "author": [
                "Tao Sun",
                "Yan Hao",
                "Shengyu Huang",
                "Silvio Savarese",
                "Konrad Schindler",
                "Marc Pollefeys",
                "Iro Armeni"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09346v1",
                "http://arxiv.org/pdf/2311.09346v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.12129v1",
            "title": "Measure of Dependence for Financial Time-Series",
            "updated": "2023-11-15T20:08:30Z",
            "published": "2023-11-15T20:08:30Z",
            "summary": "Assessing the predictive power of both data and models holds paramount\nsignificance in time-series machine learning applications. Yet, preparing time\nseries data accurately and employing an appropriate measure for predictive\npower seems to be a non-trivial task. This work involves reviewing and\nestablishing the groundwork for a comprehensive analysis of shaping time-series\ndata and evaluating various measures of dependence. Lastly, we present a\nmethod, framework, and a concrete example for selecting and evaluating a\nsuitable measure of dependence.",
            "author": [
                "Martin Winist\u00f6rfer",
                "Ivan Zhdankin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.12129v1",
                "http://arxiv.org/pdf/2311.12129v1"
            ],
            "primary_category": "q-fin.ST",
            "category": [
                "q-fin.ST"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09345v1",
            "title": "A Machine Learning Approach to Understanding the Physical Properties of\n  Magnetic Flux Ropes in the Solar Wind at 1 AU",
            "updated": "2023-11-15T20:07:21Z",
            "published": "2023-11-15T20:07:21Z",
            "summary": "Interplanetary magnetic flux ropes (MFRs) are commonly observed structures in\nthe solar wind, categorized as magnetic clouds (MCs) and small-scale MFRs\n(SMFRs) depending on whether they are associated with coronal mass ejections.\nWe apply machine learning to systematically compare SMFRs, MCs, and ambient\nsolar wind plasma properties. We construct a dataset of 3-minute averaged\nsequential data points of the solar wind's instantaneous bulk fluid plasma\nproperties using about twenty years of measurements from \\emph{Wind}. We label\nsamples by the presence and type of MFRs containing them using a catalog based\non Grad-Shafranov (GS) automated detection for SMFRs and NASA's catalog for MCs\n(with samples in neither labeled non-MFRs). We apply the random forest machine\nlearning algorithm to find which categories can be more easily distinguished\nand by what features. MCs were distinguished from non-MFRs with an AUC of 94%\nand SMFRs with an AUC of 89% and had distinctive plasma properties. In\ncontrast, while SMFRs were distinguished from non-MFRs with an AUC of 86%, this\nappears to rely solely on the $\\langle B \\rangle$ > 5 nT threshold applied by\nthe GS catalog. The results indicate that SMFRs have virtually the same plasma\nproperties as the ambient solar wind, unlike the distinct plasma regimes of\nMCs. We interpret our findings as additional evidence that most SMFRs at 1 au\nare generated within the solar wind, and furthermore, suggesting that they\nshould be considered a salient feature of the solar wind's magnetic structure\nrather than transient events.",
            "author": [
                "Hameedullah Farooki",
                "Yasser Abduallah",
                "Sung Jun Noh",
                "Hyomin Kim",
                "George Bizos",
                "Youra Shin",
                "Jason T. L. Wang",
                "Haimin Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09345v1",
                "http://arxiv.org/pdf/2311.09345v1"
            ],
            "primary_category": "physics.space-ph",
            "category": [
                "physics.space-ph",
                "astro-ph.SR",
                "physics.plasm-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09338v1",
            "title": "Challenges for Predictive Modeling with Neural Network Techniques using\n  Error-Prone Dietary Intake Data",
            "updated": "2023-11-15T19:54:14Z",
            "published": "2023-11-15T19:54:14Z",
            "summary": "Dietary intake data are routinely drawn upon to explore diet-health\nrelationships. However, these data are often subject to measurement error,\ndistorting the true relationships. Beyond measurement error, there are likely\ncomplex synergistic and sometimes antagonistic interactions between different\ndietary components, complicating the relationships between diet and health\noutcomes. Flexible models are required to capture the nuance that these complex\ninteractions introduce. This complexity makes research on diet-health\nrelationships an appealing candidate for the application of machine learning\ntechniques, and in particular, neural networks. Neural networks are\ncomputational models that are able to capture highly complex, nonlinear\nrelationships so long as sufficient data are available. While these models have\nbeen applied in many domains, the impacts of measurement error on the\nperformance of predictive modeling has not been systematically investigated.\nHowever, dietary intake data are typically collected using self-report methods\nand are prone to large amounts of measurement error. In this work, we\ndemonstrate the ways in which measurement error erodes the performance of\nneural networks, and illustrate the care that is required for leveraging these\nmodels in the presence of error. We demonstrate the role that sample size and\nreplicate measurements play on model performance, indicate a motivation for the\ninvestigation of transformations to additivity, and illustrate the caution\nrequired to prevent model overfitting. While the past performance of neural\nnetworks across various domains make them an attractive candidate for examining\ndiet-health relationships, our work demonstrates that substantial care and\nfurther methodological development are both required to observe increased\npredictive performance when applying these techniques, compared to more\ntraditional statistical procedures.",
            "author": [
                "Dylan Spicker",
                "Amir Nazemi",
                "Joy Hutchinson",
                "Paul Fieguth",
                "Sharon I. Kirkpatrick",
                "Michael Wallace",
                "Kevin W. Dodd"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09338v1",
                "http://arxiv.org/pdf/2311.09338v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09336v1",
            "title": "Pinpoint, Not Criticize: Refining Large Language Models via Fine-Grained\n  Actionable Feedback",
            "updated": "2023-11-15T19:52:11Z",
            "published": "2023-11-15T19:52:11Z",
            "summary": "Recent improvements in text generation have leveraged human feedback to\nimprove the quality of the generated output. However, human feedback is not\nalways available, especially during inference. In this work, we propose an\ninference time optimization method FITO to use fine-grained actionable feedback\nin the form of error type, error location and severity level that are predicted\nby a learned error pinpoint model for iterative refinement. FITO starts with an\ninitial output, then iteratively incorporates the feedback via a refinement\nmodel that generates an improved output conditioned on the feedback. Given the\nuncertainty of consistent refined samples at iterative steps, we formulate\niterative refinement into a local search problem and develop a simulated\nannealing based algorithm that balances exploration of the search space and\noptimization for output quality. We conduct experiments on three text\ngeneration tasks, including machine translation, long-form question answering\n(QA) and topical summarization. We observe 0.8 and 0.7 MetricX gain on\nChinese-English and English-German translation, 4.5 and 1.8 ROUGE-L gain at\nlong form QA and topic summarization respectively, with a single iteration of\nrefinement. With our simulated annealing algorithm, we see further quality\nimprovements, including up to 1.7 MetricX improvements over the baseline\napproach.",
            "author": [
                "Wenda Xu",
                "Daniel Deutsch",
                "Mara Finkelstein",
                "Juraj Juraska",
                "Biao Zhang",
                "Zhongtao Liu",
                "William Yang Wang",
                "Lei Li",
                "Markus Freitag"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09336v1",
                "http://arxiv.org/pdf/2311.09336v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10111v1",
            "title": "VideoCon: Robust Video-Language Alignment via Contrast Captions",
            "updated": "2023-11-15T19:51:57Z",
            "published": "2023-11-15T19:51:57Z",
            "summary": "Despite being (pre)trained on a massive amount of data, state-of-the-art\nvideo-language alignment models are not robust to semantically-plausible\ncontrastive changes in the video captions. Our work addresses this by\nidentifying a broad spectrum of contrast misalignments, such as replacing\nentities, actions, and flipping event order, which alignment models should be\nrobust against. To this end, we introduce the VideoCon, a video-language\nalignment dataset constructed by a large language model that generates\nplausible contrast video captions and explanations for differences between\noriginal and contrast video captions. Then, a generative video-language model\nis finetuned with VideoCon to assess video-language entailment and generate\nexplanations. Our VideoCon-based alignment model significantly outperforms\ncurrent models. It exhibits a 12-point increase in AUC for the video-language\nalignment task on human-generated contrast captions. Finally, our model sets\nnew state of the art zero-shot performance in temporally-extensive\nvideo-language tasks such as text-to-video retrieval (SSv2-Temporal) and video\nquestion answering (ATP-Hard). Moreover, our model shows superior performance\non novel videos and human-crafted captions and explanations. Our code and data\nare available at https://github.com/Hritikbansal/videocon.",
            "author": [
                "Hritik Bansal",
                "Yonatan Bitton",
                "Idan Szpektor",
                "Kai-Wei Chang",
                "Aditya Grover"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10111v1",
                "http://arxiv.org/pdf/2311.10111v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09333v1",
            "title": "Strategic Data Augmentation with CTGAN for Smart Manufacturing:\n  Enhancing Machine Learning Predictions of Paper Breaks in Pulp-and-Paper\n  Production",
            "updated": "2023-11-15T19:47:15Z",
            "published": "2023-11-15T19:47:15Z",
            "summary": "A significant challenge for predictive maintenance in the pulp-and-paper\nindustry is the infrequency of paper breaks during the production process. In\nthis article, operational data is analyzed from a paper manufacturing machine\nin which paper breaks are relatively rare but have a high economic impact.\nUtilizing a dataset comprising 18,398 instances derived from a quality\nassurance protocol, we address the scarcity of break events (124 cases) that\npose a challenge for machine learning predictive models. With the help of\nConditional Generative Adversarial Networks (CTGAN) and Synthetic Minority\nOversampling Technique (SMOTE), we implement a novel data augmentation\nframework. This method ensures that the synthetic data mirrors the distribution\nof the real operational data but also seeks to enhance the performance metrics\nof predictive modeling. Before and after the data augmentation, we evaluate\nthree different machine learning algorithms-Decision Trees (DT), Random Forest\n(RF), and Logistic Regression (LR). Utilizing the CTGAN-enhanced dataset, our\nstudy achieved significant improvements in predictive maintenance performance\nmetrics. The efficacy of CTGAN in addressing data scarcity was evident, with\nthe models' detection of machine breaks (Class 1) improving by over 30% for\nDecision Trees, 20% for Random Forest, and nearly 90% for Logistic Regression.\nWith this methodological advancement, this study contributes to industrial\nquality control and maintenance scheduling by addressing rare event prediction\nin manufacturing processes.",
            "author": [
                "Hamed Khosravi",
                "Sarah Farhadpour",
                "Manikanta Grandhi",
                "Ahmed Shoyeb Raihan",
                "Srinjoy Das",
                "Imtiaz Ahmed"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09333v1",
                "http://arxiv.org/pdf/2311.09333v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16168v1",
            "title": "Inexpensive High Fidelity Melt Pool Models in Additive Manufacturing\n  Using Generative Deep Diffusion",
            "updated": "2023-11-15T19:37:20Z",
            "published": "2023-11-15T19:37:20Z",
            "summary": "Defects in laser powder bed fusion (L-PBF) parts often result from the\nmeso-scale dynamics of the molten alloy near the laser, known as the melt pool.\nFor instance, the melt pool can directly contribute to the formation of\nundesirable porosity, residual stress, and surface roughness in the final part.\nExperimental in-situ monitoring of the three-dimensional melt pool physical\nfields is challenging, due to the short length and time scales involved in the\nprocess. Multi-physics simulation methods can describe the three-dimensional\ndynamics of the melt pool, but are computationally expensive at the mesh\nrefinement required for accurate predictions of complex effects, such as the\nformation of keyhole porosity. Therefore, in this work, we develop a generative\ndeep learning model based on the probabilistic diffusion framework to map\nlow-fidelity, coarse-grained simulation information to the high-fidelity\ncounterpart. By doing so, we bypass the computational expense of conducting\nmultiple high-fidelity simulations for analysis by instead upscaling\nlightweight coarse mesh simulations. Specifically, we implement a 2-D diffusion\nmodel to spatially upscale cross-sections of the coarsely simulated melt pool\nto their high-fidelity equivalent. We demonstrate the preservation of key\nmetrics of the melting process between the ground truth simulation data and the\ndiffusion model output, such as the temperature field, the melt pool dimensions\nand the variability of the keyhole vapor cavity. Specifically, we predict the\nmelt pool depth within 3 $\\mu m$ based on low-fidelity input data 4$\\times$\ncoarser than the high-fidelity simulations, reducing analysis time by two\norders of magnitude.",
            "author": [
                "Francis Ogoke",
                "Quanliang Liu",
                "Olabode Ajenifujah",
                "Alexander Myers",
                "Guadalupe Quirarte",
                "Jack Beuth",
                "Jonathan Malen",
                "Amir Barati Farimani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16168v1",
                "http://arxiv.org/pdf/2311.16168v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09329v1",
            "title": "A Comparative Analysis of Machine Learning Models for Early Detection of\n  Hospital-Acquired Infections",
            "updated": "2023-11-15T19:36:12Z",
            "published": "2023-11-15T19:36:12Z",
            "summary": "As more and more infection-specific machine learning models are developed and\nplanned for clinical deployment, simultaneously running predictions from\ndifferent models may provide overlapping or even conflicting information. It is\nimportant to understand the concordance and behavior of parallel models in\ndeployment. In this study, we focus on two models for the early detection of\nhospital-acquired infections (HAIs): 1) the Infection Risk Index (IRI) and 2)\nthe Ventilator-Associated Pneumonia (VAP) prediction model. The IRI model was\nbuilt to predict all HAIs, whereas the VAP model identifies patients at risk of\ndeveloping ventilator-associated pneumonia. These models could make important\nimprovements in patient outcomes and hospital management of infections through\nearly detection of infections and in turn, enable early interventions. The two\nmodels vary in terms of infection label definition, cohort selection, and\nprediction schema. In this work, we present a comparative analysis between the\ntwo models to characterize concordances and confusions in predicting HAIs by\nthese models. The learnings from this study will provide important findings for\nhow to deploy multiple concurrent disease-specific models in the future.",
            "author": [
                "Ethan Harvey",
                "Junzi Dong",
                "Erina Ghosh",
                "Ali Samadani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09329v1",
                "http://arxiv.org/pdf/2311.09329v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09312v2",
            "title": "H-Packer: Holographic Rotationally Equivariant Convolutional Neural\n  Network for Protein Side-Chain Packing",
            "updated": "2023-11-28T18:31:07Z",
            "published": "2023-11-15T19:12:47Z",
            "summary": "Accurately modeling protein 3D structure is essential for the design of\nfunctional proteins. An important sub-task of structure modeling is protein\nside-chain packing: predicting the conformation of side-chains (rotamers) given\nthe protein's backbone structure and amino-acid sequence. Conventional\napproaches for this task rely on expensive sampling procedures over\nhand-crafted energy functions and rotamer libraries. Recently, several deep\nlearning methods have been developed to tackle the problem in a data-driven\nway, albeit with vastly different formulations (from image-to-image translation\nto directly predicting atomic coordinates). Here, we frame the problem as a\njoint regression over the side-chains' true degrees of freedom: the dihedral\n$\\chi$ angles. We carefully study possible objective functions for this task,\nwhile accounting for the underlying symmetries of the task. We propose\nHolographic Packer (H-Packer), a novel two-stage algorithm for side-chain\npacking built on top of two light-weight rotationally equivariant neural\nnetworks. We evaluate our method on CASP13 and CASP14 targets. H-Packer is\ncomputationally efficient and shows favorable performance against conventional\nphysics-based algorithms and is competitive against alternative deep learning\nsolutions.",
            "author": [
                "Gian Marco Visani",
                "William Galvin",
                "Michael Neal Pun",
                "Armita Nourmohammad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09312v2",
                "http://arxiv.org/pdf/2311.09312v2"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM",
                "cs.AI",
                "cs.LG",
                "J.3; I.2.0"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09308v1",
            "title": "Divergences between Language Models and Human Brains",
            "updated": "2023-11-15T19:02:40Z",
            "published": "2023-11-15T19:02:40Z",
            "summary": "Do machines and humans process language in similar ways? A recent line of\nresearch has hinted in the affirmative, demonstrating that human brain signals\ncan be effectively predicted using the internal representations of language\nmodels (LMs). This is thought to reflect shared computational principles\nbetween LMs and human language processing. However, there are also clear\ndifferences in how LMs and humans acquire and use language, even if the final\ntask they are performing is the same. Despite this, there is little work\nexploring systematic differences between human and machine language processing\nusing brain data. To address this question, we examine the differences between\nLM representations and the human brain's responses to language, specifically by\nexamining a dataset of Magnetoencephalography (MEG) responses to a written\nnarrative. In doing so we identify three phenomena that, in prior work, LMs\nhave been found to not capture well: emotional understanding, figurative\nlanguage processing, and physical commonsense. By fine-tuning LMs on datasets\nrelated to these phenomena, we observe that fine-tuned LMs show improved\nalignment with human brain responses across these tasks. Our study implies that\nthe observed divergences between LMs and human brains may stem from LMs'\ninadequate representation of these specific types of knowledge.",
            "author": [
                "Yuchen Zhou",
                "Emmy Liu",
                "Graham Neubig",
                "Leila Wehbe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09308v1",
                "http://arxiv.org/pdf/2311.09308v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09296v1",
            "title": "Towards a data-driven model of hadronization using normalizing flows",
            "updated": "2023-11-15T19:00:04Z",
            "published": "2023-11-15T19:00:04Z",
            "summary": "We introduce a model of hadronization based on invertible neural networks\nthat faithfully reproduces a simplified version of the Lund string model for\nmeson hadronization. Additionally, we introduce a new training method for\nnormalizing flows, termed MAGIC, that improves the agreement between simulated\nand experimental distributions of high-level (macroscopic) observables by\nadjusting single-emission (microscopic) dynamics. Our results constitute an\nimportant step toward realizing a machine-learning based model of hadronization\nthat utilizes experimental data during training. Finally, we demonstrate how a\nBayesian extension to this normalizing-flow architecture can be used to provide\nanalysis of statistical and modeling uncertainties on the generated observable\ndistributions.",
            "author": [
                "Christian Bierlich",
                "Phil Ilten",
                "Tony Menzo",
                "Stephen Mrenna",
                "Manuel Szewc",
                "Michael K. Wilkinson",
                "Ahmed Youssef",
                "Jure Zupan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09296v1",
                "http://arxiv.org/pdf/2311.09296v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph",
                "hep-ex"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09216v1",
            "title": "Assessing Translation capabilities of Large Language Models involving\n  English and Indian Languages",
            "updated": "2023-11-15T18:58:19Z",
            "published": "2023-11-15T18:58:19Z",
            "summary": "Generative Large Language Models (LLMs) have achieved remarkable advancements\nin various NLP tasks. In this work, our aim is to explore the multilingual\ncapabilities of large language models by using machine translation as a task\ninvolving English and 22 Indian languages. We first investigate the translation\ncapabilities of raw large language models, followed by exploring the in-context\nlearning capabilities of the same raw models. We fine-tune these large language\nmodels using parameter efficient fine-tuning methods such as LoRA and\nadditionally with full fine-tuning. Through our study, we have identified the\nbest performing large language model for the translation task involving LLMs,\nwhich is based on LLaMA.\n  Our results demonstrate significant progress, with average BLEU scores of\n13.42, 15.93, 12.13, 12.30, and 12.07, as well as CHRF scores of 43.98, 46.99,\n42.55, 42.42, and 45.39, respectively, using 2-stage fine-tuned LLaMA-13b for\nEnglish to Indian languages on IN22 (conversational), IN22 (general),\nflores200-dev, flores200-devtest, and newstest2019 testsets. Similarly, for\nIndian languages to English, we achieved average BLEU scores of 14.03, 16.65,\n16.17, 15.35 and 12.55 along with chrF scores of 36.71, 40.44, 40.26, 39.51,\nand 36.20, respectively, using fine-tuned LLaMA-13b on IN22 (conversational),\nIN22 (general), flores200-dev, flores200-devtest, and newstest2019 testsets.\nOverall, our findings highlight the potential and strength of large language\nmodels for machine translation capabilities, including for languages that are\ncurrently underrepresented in LLMs.",
            "author": [
                "Vandan Mujadia",
                "Ashok Urlana",
                "Yash Bhaskar",
                "Penumalla Aditya Pavani",
                "Kukkapalli Shravya",
                "Parameswari Krishnamurthy",
                "Dipti Misra Sharma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09216v1",
                "http://arxiv.org/pdf/2311.09216v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09215v1",
            "title": "ConvNet vs Transformer, Supervised vs CLIP: Beyond ImageNet Accuracy",
            "updated": "2023-11-15T18:56:51Z",
            "published": "2023-11-15T18:56:51Z",
            "summary": "Modern computer vision offers a great variety of models to practitioners, and\nselecting a model from multiple options for specific applications can be\nchallenging. Conventionally, competing model architectures and training\nprotocols are compared by their classification accuracy on ImageNet. However,\nthis single metric does not fully capture performance nuances critical for\nspecialized tasks. In this work, we conduct an in-depth comparative analysis of\nmodel behaviors beyond ImageNet accuracy, for both ConvNet and Vision\nTransformer architectures, each across supervised and CLIP training paradigms.\nAlthough our selected models have similar ImageNet accuracies and compute\nrequirements, we find that they differ in many other aspects: types of\nmistakes, output calibration, transferability, and feature invariance, among\nothers. This diversity in model characteristics, not captured by traditional\nmetrics, highlights the need for more nuanced analysis when choosing among\ndifferent models. Our code is available at\nhttps://github.com/kirill-vish/Beyond-INet.",
            "author": [
                "Kirill Vishniakov",
                "Zhiqiang Shen",
                "Zhuang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09215v1",
                "http://arxiv.org/pdf/2311.09215v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09277v1",
            "title": "Contrastive Chain-of-Thought Prompting",
            "updated": "2023-11-15T18:54:01Z",
            "published": "2023-11-15T18:54:01Z",
            "summary": "Despite the success of chain of thought in enhancing language model\nreasoning, the underlying process remains less well understood. Although\nlogically sound reasoning appears inherently crucial for chain of thought,\nprior studies surprisingly reveal minimal impact when using invalid\ndemonstrations instead. Furthermore, the conventional chain of thought does not\ninform language models on what mistakes to avoid, which potentially leads to\nmore errors. Hence, inspired by how humans can learn from both positive and\nnegative examples, we propose contrastive chain of thought to enhance language\nmodel reasoning. Compared to the conventional chain of thought, our approach\nprovides both valid and invalid reasoning demonstrations, to guide the model to\nreason step-by-step while reducing reasoning mistakes. To improve\ngeneralization, we introduce an automatic method to construct contrastive\ndemonstrations. Our experiments on reasoning benchmarks demonstrate that\ncontrastive chain of thought can serve as a general enhancement of\nchain-of-thought prompting.",
            "author": [
                "Yew Ken Chia",
                "Guizhen Chen",
                "Luu Anh Tuan",
                "Soujanya Poria",
                "Lidong Bing"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09277v1",
                "http://arxiv.org/pdf/2311.09277v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09276v1",
            "title": "Leveraging Citizen Science for Flood Extent Detection using Machine\n  Learning Benchmark Dataset",
            "updated": "2023-11-15T18:49:29Z",
            "published": "2023-11-15T18:49:29Z",
            "summary": "Accurate detection of inundated water extents during flooding events is\ncrucial in emergency response decisions and aids in recovery efforts. Satellite\nRemote Sensing data provides a global framework for detecting flooding extents.\nSpecifically, Sentinel-1 C-Band Synthetic Aperture Radar (SAR) imagery has\nproven to be useful in detecting water bodies due to low backscatter of water\nfeatures in both co-polarized and cross-polarized SAR imagery. However,\nincreased backscatter can be observed in certain flooded regions such as\npresence of infrastructure and trees - rendering simple methods such as pixel\nintensity thresholding and time-series differencing inadequate. Machine\nLearning techniques has been leveraged to precisely capture flood extents in\nflooded areas with bumps in backscatter but needs high amounts of labelled data\nto work desirably. Hence, we created a labeled known water body extent and\nflooded area extents during known flooding events covering about 36,000 sq.\nkilometers of regions within mainland U.S and Bangladesh. Further, We also\nleveraged citizen science by open-sourcing the dataset and hosting an open\ncompetition based on the dataset to rapidly prototype flood extent detection\nusing community generated models. In this paper we present the information\nabout the dataset, the data processing pipeline, a baseline model and the\ndetails about the competition, along with discussion on winning approaches. We\nbelieve the dataset adds to already existing datasets based on Sentinel-1C SAR\ndata and leads to more robust modeling of flood extents. We also hope the\nresults from the competition pushes the research in flood extent detection\nfurther.",
            "author": [
                "Muthukumaran Ramasubramanian",
                "Iksha Gurung",
                "Shubhankar Gahlot",
                "Ronny H\u00e4nsch",
                "Andrew L. Molthan",
                "Manil Maskey"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09276v1",
                "http://arxiv.org/pdf/2311.09276v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09200v2",
            "title": "ExpM+NF Tractable Exponential Mechanism via Normalizing Flow, A Path\n  through the Accuracy-Privacy Ceiling Constraining Differentially Private ML",
            "updated": "2023-12-07T03:39:42Z",
            "published": "2023-11-15T18:43:29Z",
            "summary": "The Exponential Mechanism (ExpM), a differentially private optimization\nmethod, promises many advantages over Differentially Private Stochastic\nGradient Descent (DPSGD), the state-of-the-art (SOTA) and de facto method for\ndifferentially private machine learning (ML). Yet, ExpM has been historically\nstymied from differentially private training of modern ML algorithms by two\nobstructions: ExpM requires a sensitivity bound for the given loss function;\nExpM requires sampling from a historically intractable density. We prove a\nsensitivity bound for $\\ell(2)$ loss, and investigate using Normalizing Flows\n(NFs), deep networks furnishing approximate sampling from the otherwise\nintractable ExpM distribution. We prove that as the NF output converges to ExpM\ndistribution, the privacy ($\\varepsilon$) of an NF sample converges to that of\nthe ExpM distribution. Under the assumption that the NF output distribution is\nthe ExpM distribution, we empirically test ExpM+NF against DPSGD using the SOTA\nimplementation (Opacus \\cite{opacus} with PRV accounting) in multiple\nclassification tasks on the Adult Dataset (census data) and MIMIC-III Dataset\n(healthcare records) using Logistic Regression and GRU-D, a deep learning\nrecurrent neural network with \\smallsim 20K-100K parameters. In all experiments\nwe find ExpM+NF achieves greater than 94\\% of the non-private training accuracy\n(AUC) with $\\varepsilon$-DP for $\\varepsilon$ a low as $1\\mathrm{e}{-3}$ --\nthree orders of magnitude stronger privacy with similar accuracy. Further,\nperformance results show ExpM+NF training time is comparable to (slightly less)\nthan DPSGD. Limitations and future directions are provided; notably, research\non NF approximation accuracy and its effect on privacy are a promising avenue\nto substantially advancing the field. Code for these experiments \\hl{will be\nprovided after review}.",
            "author": [
                "Robert A. Bridges",
                "Vandy J. Tombs",
                "Christopher B. Stanley"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09200v2",
                "http://arxiv.org/pdf/2311.09200v2"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.AI",
                "cs.CR",
                "cs.LG",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10770v2",
            "title": "Exponentially Faster Language Modelling",
            "updated": "2023-11-21T06:59:59Z",
            "published": "2023-11-15T18:42:50Z",
            "summary": "Language models only really need to use an exponential fraction of their\nneurons for individual inferences. As proof, we present UltraFastBERT, a BERT\nvariant that uses 0.3% of its neurons during inference while performing on par\nwith similar BERT models. UltraFastBERT selectively engages just 12 out of 4095\nneurons for each layer inference. This is achieved by replacing feedforward\nnetworks with fast feedforward networks (FFFs). While no truly efficient\nimplementation currently exists to unlock the full acceleration potential of\nconditional neural execution, we provide high-level CPU code achieving 78x\nspeedup over the optimized baseline feedforward implementation, and a PyTorch\nimplementation delivering 40x speedup over the equivalent batched feedforward\ninference. We publish our training code, benchmarking setup, and model weights.",
            "author": [
                "Peter Belcak",
                "Roger Wattenhofer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10770v2",
                "http://arxiv.org/pdf/2311.10770v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG",
                "cs.NE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09197v1",
            "title": "A Unified Approach to Learning Ising Models: Beyond Independence and\n  Bounded Width",
            "updated": "2023-11-15T18:41:19Z",
            "published": "2023-11-15T18:41:19Z",
            "summary": "We revisit the problem of efficiently learning the underlying parameters of\nIsing models from data. Current algorithmic approaches achieve essentially\noptimal sample complexity when given i.i.d. samples from the stationary measure\nand the underlying model satisfies \"width\" bounds on the total $\\ell_1$\ninteraction involving each node. We show that a simple existing approach based\non node-wise logistic regression provably succeeds at recovering the underlying\nmodel in several new settings where these assumptions are violated:\n  (1) Given dynamically generated data from a wide variety of local Markov\nchains, like block or round-robin dynamics, logistic regression recovers the\nparameters with optimal sample complexity up to $\\log\\log n$ factors. This\ngeneralizes the specialized algorithm of Bresler, Gamarnik, and Shah [IEEE\nTrans. Inf. Theory'18] for structure recovery in bounded degree graphs from\nGlauber dynamics.\n  (2) For the Sherrington-Kirkpatrick model of spin glasses, given\n$\\mathsf{poly}(n)$ independent samples, logistic regression recovers the\nparameters in most of the known high-temperature regime via a simple reduction\nto weaker structural properties of the measure. This improves on recent work of\nAnari, Jain, Koehler, Pham, and Vuong [ArXiv'23] which gives distribution\nlearning at higher temperature.\n  (3) As a simple byproduct of our techniques, logistic regression achieves an\nexponential improvement in learning from samples in the M-regime of data\nconsidered by Dutt, Lokhov, Vuffray, and Misra [ICML'21] as well as novel\nguarantees for learning from the adversarial Glauber dynamics of Chin, Moitra,\nMossel, and Sandon [ArXiv'23].\n  Our approach thus significantly generalizes the elegant analysis of Wu,\nSanghavi, and Dimakis [Neurips'19] without any algorithmic modification.",
            "author": [
                "Jason Gaitonde",
                "Elchanan Mossel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09197v1",
                "http://arxiv.org/pdf/2311.09197v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DS",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09195v1",
            "title": "Self-Supervised Curriculum Generation for Autonomous Reinforcement\n  Learning without Task-Specific Knowledge",
            "updated": "2023-11-15T18:40:10Z",
            "published": "2023-11-15T18:40:10Z",
            "summary": "A significant bottleneck in applying current reinforcement learning\nalgorithms to real-world scenarios is the need to reset the environment between\nevery episode. This reset process demands substantial human intervention,\nmaking it difficult for the agent to learn continuously and autonomously.\nSeveral recent works have introduced autonomous reinforcement learning (ARL)\nalgorithms that generate curricula for jointly training reset and forward\npolicies. While their curricula can reduce the number of required manual resets\nby taking into account the agent's learning progress, they rely on\ntask-specific knowledge, such as predefined initial states or reset reward\nfunctions. In this paper, we propose a novel ARL algorithm that can generate a\ncurriculum adaptive to the agent's learning progress without task-specific\nknowledge. Our curriculum empowers the agent to autonomously reset to diverse\nand informative initial states. To achieve this, we introduce a success\ndiscriminator that estimates the success probability from each initial state\nwhen the agent follows the forward policy. The success discriminator is trained\nwith relabeled transitions in a self-supervised manner. Our experimental\nresults demonstrate that our ARL algorithm can generate an adaptive curriculum\nand enable the agent to efficiently bootstrap to solve sparse-reward maze\nnavigation tasks, outperforming baselines with significantly fewer manual\nresets.",
            "author": [
                "Sang-Hyun Lee",
                "Seung-Woo Seo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09195v1",
                "http://arxiv.org/pdf/2311.09195v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09191v1",
            "title": "Domain Aligned CLIP for Few-shot Classification",
            "updated": "2023-11-15T18:34:26Z",
            "published": "2023-11-15T18:34:26Z",
            "summary": "Large vision-language representation learning models like CLIP have\ndemonstrated impressive performance for zero-shot transfer to downstream tasks\nwhile largely benefiting from inter-modal (image-text) alignment via\ncontrastive objectives. This downstream performance can further be enhanced by\nfull-scale fine-tuning which is often compute intensive, requires large\nlabelled data, and can reduce out-of-distribution (OOD) robustness.\nFurthermore, sole reliance on inter-modal alignment might overlook the rich\ninformation embedded within each individual modality. In this work, we\nintroduce a sample-efficient domain adaptation strategy for CLIP, termed Domain\nAligned CLIP (DAC), which improves both intra-modal (image-image) and\ninter-modal alignment on target distributions without fine-tuning the main\nmodel. For intra-modal alignment, we introduce a lightweight adapter that is\nspecifically trained with an intra-modal contrastive objective. To improve\ninter-modal alignment, we introduce a simple framework to modulate the\nprecomputed class text embeddings. The proposed few-shot fine-tuning framework\nis computationally efficient, robust to distribution shifts, and does not alter\nCLIP's parameters. We study the effectiveness of DAC by benchmarking on 11\nwidely used image classification tasks with consistent improvements in 16-shot\nclassification upon strong baselines by about 2.3% and demonstrate competitive\nperformance on 4 OOD robustness benchmarks.",
            "author": [
                "Muhammad Waleed Gondal",
                "Jochen Gast",
                "Inigo Alonso Ruiz",
                "Richard Droste",
                "Tommaso Macri",
                "Suren Kumar",
                "Luitpold Staudigl"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09191v1",
                "http://arxiv.org/pdf/2311.09191v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09190v1",
            "title": "On the Computation of the Gaussian Rate-Distortion-Perception Function",
            "updated": "2023-11-15T18:34:03Z",
            "published": "2023-11-15T18:34:03Z",
            "summary": "In this paper, we study the computation of the rate-distortion-perception\nfunction (RDPF) for a multivariate Gaussian source under mean squared error\n(MSE) distortion and, respectively, Kullback-Leibler divergence, geometric\nJensen-Shannon divergence, squared Hellinger distance, and squared\nWasserstein-2 distance perception metrics. To this end, we first characterize\nthe analytical bounds of the scalar Gaussian RDPF for the aforementioned\ndivergence functions, also providing the RDPF-achieving forward \"test-channel\"\nrealization. Focusing on the multivariate case, we establish that, for\ntensorizable distortion and perception metrics, the optimal solution resides on\nthe vector space spanned by the eigenvector of the source covariance matrix.\nConsequently, the multivariate optimization problem can be expressed as a\nfunction of the scalar Gaussian RDPFs of the source marginals, constrained by\nglobal distortion and perception levels. Leveraging this characterization, we\ndesign an alternating minimization scheme based on the block nonlinear\nGauss-Seidel method, which optimally solves the problem while identifying the\nGaussian RDPF-achieving realization. Furthermore, the associated algorithmic\nembodiment is provided, as well as the convergence and the rate of convergence\ncharacterization. Lastly, for the \"perfect realism\" regime, the analytical\nsolution for the multivariate Gaussian RDPF is obtained. We corroborate our\nresults with numerical simulations and draw connections to existing results.",
            "author": [
                "Giuseppe Serra",
                "Photios A. Stavrou",
                "Marios Kountouris"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09190v1",
                "http://arxiv.org/pdf/2311.09190v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.CV",
                "cs.LG",
                "cs.NI",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09188v1",
            "title": "Towards Verifiable Text Generation with Symbolic References",
            "updated": "2023-11-15T18:28:29Z",
            "published": "2023-11-15T18:28:29Z",
            "summary": "Large language models (LLMs) have demonstrated an impressive ability to\nsynthesize plausible and fluent text. However they remain vulnerable to\nhallucinations, and thus their outputs generally require manual human\nverification for high-stakes applications, which can be time-consuming and\ndifficult. This paper proposes symbolically grounded generation (SymGen) as a\nsimple approach for enabling easier validation of an LLM's output. SymGen\nprompts an LLM to interleave its regular output text with explicit symbolic\nreferences to fields present in some conditioning data (e.g., a table in JSON\nformat). The references can be used to display the provenance of different\nspans of text in the generation, reducing the effort required for manual\nverification. Across data-to-text and question answering experiments, we find\nthat LLMs are able to directly output text that makes use of symbolic\nreferences while maintaining fluency and accuracy.",
            "author": [
                "Lucas Torroba Hennigen",
                "Shannon Shen",
                "Aniruddha Nrusimha",
                "Bernhard Gapp",
                "David Sontag",
                "Yoon Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09188v1",
                "http://arxiv.org/pdf/2311.09188v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09184v1",
            "title": "Benchmarking Generation and Evaluation Capabilities of Large Language\n  Models for Instruction Controllable Summarization",
            "updated": "2023-11-15T18:25:26Z",
            "published": "2023-11-15T18:25:26Z",
            "summary": "While large language models (LLMs) already achieve strong performance on\nstandard generic summarization benchmarks, their performance on more complex\nsummarization task settings is less studied. Therefore, we benchmark LLMs on\ninstruction controllable text summarization, where the model input consists of\nboth a source article and a natural language requirement for the desired\nsummary characteristics. To this end, we curate an evaluation-only dataset for\nthis task setting and conduct human evaluation on 5 LLM-based summarization\nsystems. We then benchmark LLM-based automatic evaluation for this task with 4\ndifferent evaluation protocols and 11 LLMs, resulting in 40 evaluation methods\nin total. Our study reveals that instruction controllable text summarization\nremains a challenging task for LLMs, since (1) all LLMs evaluated still make\nfactual and other types of errors in their summaries; (2) all LLM-based\nevaluation methods cannot achieve a strong alignment with human annotators when\njudging the quality of candidate summaries; (3) different LLMs show large\nperformance gaps in summary generation and evaluation. We make our collected\nbenchmark, InstruSum, publicly available to facilitate future research in this\ndirection.",
            "author": [
                "Yixin Liu",
                "Alexander R. Fabbri",
                "Jiawen Chen",
                "Yilun Zhao",
                "Simeng Han",
                "Shafiq Joty",
                "Pengfei Liu",
                "Dragomir Radev",
                "Chien-Sheng Wu",
                "Arman Cohan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09184v1",
                "http://arxiv.org/pdf/2311.09184v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10768v1",
            "title": "Memory Augmented Language Models through Mixture of Word Experts",
            "updated": "2023-11-15T18:19:56Z",
            "published": "2023-11-15T18:19:56Z",
            "summary": "Scaling up the number of parameters of language models has proven to be an\neffective approach to improve performance. For dense models, increasing model\nsize proportionally increases the model's computation footprint. In this work,\nwe seek to aggressively decouple learning capacity and FLOPs through\nMixture-of-Experts (MoE) style models with large knowledge-rich vocabulary\nbased routing functions and experts. Our proposed approach, dubbed Mixture of\nWord Experts (MoWE), can be seen as a memory augmented model, where a large set\nof word-specific experts play the role of a sparse memory. We demonstrate that\nMoWE performs significantly better than the T5 family of models with similar\nnumber of FLOPs in a variety of NLP tasks. Additionally, MoWE outperforms\nregular MoE models on knowledge intensive tasks and has similar performance to\nmore complex memory augmented approaches that often require to invoke custom\nmechanisms to search the sparse memory.",
            "author": [
                "Cicero Nogueira dos Santos",
                "James Lee-Thorp",
                "Isaac Noble",
                "Chung-Ching Chang",
                "David Uthus"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10768v1",
                "http://arxiv.org/pdf/2311.10768v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09172v1",
            "title": "Enhancing AmBC Systems with Deep Learning for Joint Channel Estimation\n  and Signal Detection",
            "updated": "2023-11-15T18:09:52Z",
            "published": "2023-11-15T18:09:52Z",
            "summary": "The era of ubiquitous, affordable wireless connectivity has opened doors to\ncountless practical applications. In this context, ambient backscatter\ncommunication (AmBC) stands out, utilizing passive tags to establish\nconnections with readers by harnessing reflected ambient radio frequency (RF)\nsignals. However, conventional data detectors face limitations due to their\ninadequate knowledge of channel and RF-source parameters. To address this\nchallenge, we propose an innovative approach using a deep neural network (DNN)\nfor channel state estimation (CSI) and signal detection within AmBC systems.\nUnlike traditional methods that separate CSI estimation and data detection, our\napproach leverages a DNN to implicitly estimate CSI and simultaneously detect\ndata. The DNN model, trained offline using simulated data derived from channel\nstatistics, excels in online data recovery, ensuring robust performance in\npractical scenarios. Comprehensive evaluations validate the superiority of our\nproposed DNN method over traditional detectors, particularly in terms of bit\nerror rate (BER). In high signal-to-noise ratio (SNR) conditions, our method\nexhibits an impressive approximately 20% improvement in BER performance\ncompared to the maximum likelihood (ML) approach. These results underscore the\neffectiveness of our developed approach for AmBC channel estimation and signal\ndetection. In summary, our method outperforms traditional detectors, bolstering\nthe reliability and efficiency of AmBC systems, even in challenging channel\nconditions.",
            "author": [
                "S. Zargari",
                "A. Hakimi",
                "C. Tellambura",
                "A. Maaref"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09172v1",
                "http://arxiv.org/pdf/2311.09172v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09165v1",
            "title": "Approaching adverse event detection utilizing transformers on clinical\n  time-series",
            "updated": "2023-11-15T18:05:31Z",
            "published": "2023-11-15T18:05:31Z",
            "summary": "Patients being admitted to a hospital will most often be associated with a\ncertain clinical development during their stay. However, there is always a risk\nof patients being subject to the wrong diagnosis or to a certain treatment not\npertaining to the desired effect, potentially leading to adverse events. Our\nresearch aims to develop an anomaly detection system for identifying deviations\nfrom expected clinical trajectories. To address this goal we analyzed 16 months\nof vital sign recordings obtained from the Nordland Hospital Trust (NHT). We\nemployed an self-supervised framework based on the STraTS transformer\narchitecture to represent the time series data in a latent space. These\nrepresentations were then subjected to various clustering techniques to explore\npotential patient phenotypes based on their clinical progress. While our\npreliminary results from this ongoing research are promising, they underscore\nthe importance of enhancing the dataset with additional demographic information\nfrom patients. This additional data will be crucial for a more comprehensive\nevaluation of the method's performance.",
            "author": [
                "Helge Fredriksen",
                "Per Joel Burman",
                "Ashenafi Woldaregay",
                "Karl \u00d8yvind Mikalsen",
                "St\u00e5le Nymo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09165v1",
                "http://arxiv.org/pdf/2311.09165v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09275v1",
            "title": "Improved Sparse Ising Optimization",
            "updated": "2023-11-15T17:59:06Z",
            "published": "2023-11-15T17:59:06Z",
            "summary": "Sparse Ising problems can be found in application areas such as logistics,\ncondensed matter physics and training of deep Boltzmann networks, but can be\nvery difficult to tackle with high efficiency and accuracy. This report\npresents new data demonstrating significantly higher performance on some\nlongstanding benchmark problems with up to 20,000 variables. The data come from\na new heuristic algorithm tested on the large sparse instances from the Gset\nbenchmark suite. Relative to leading reported combinations of speed and\naccuracy (e.g., from Toshiba's Simulated Bifurcation Machine and Breakout Local\nSearch), a proof-of-concept implementation reached targets 2-4 orders of\nmagnitude faster. For two instances (G72 and G77) the new algorithm discovered\na better solution than all previously reported values. Solution bitstrings\nconfirming these two best solutions are provided. The data suggest exciting\npossibilities for pushing the sparse Ising performance frontier to potentially\nstrengthen algorithm portfolios, AI toolkits and decision-making systems.",
            "author": [
                "Kenneth M. Zick"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09275v1",
                "http://arxiv.org/pdf/2311.09275v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cond-mat.dis-nn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09154v1",
            "title": "CLEAN-EVAL: Clean Evaluation on Contaminated Large Language Models",
            "updated": "2023-11-15T17:50:30Z",
            "published": "2023-11-15T17:50:30Z",
            "summary": "We are currently in an era of fierce competition among various large language\nmodels (LLMs) continuously pushing the boundaries of benchmark performance.\nHowever, genuinely assessing the capabilities of these LLMs has become a\nchallenging and critical issue due to potential data contamination, and it\nwastes dozens of time and effort for researchers and engineers to download and\ntry those contaminated models. To save our precious time, we propose a novel\nand useful method, Clean-Eval, which mitigates the issue of data contamination\nand evaluates the LLMs in a cleaner manner. Clean-Eval employs an LLM to\nparaphrase and back-translate the contaminated data into a candidate set,\ngenerating expressions with the same meaning but in different surface forms. A\nsemantic detector is then used to filter the generated low-quality samples to\nnarrow down this candidate set. The best candidate is finally selected from\nthis set based on the BLEURT score. According to human assessment, this best\ncandidate is semantically similar to the original contamination data but\nexpressed differently. All candidates can form a new benchmark to evaluate the\nmodel. Our experiments illustrate that Clean-Eval substantially restores the\nactual evaluation results on contaminated LLMs under both few-shot learning and\nfine-tuning scenarios.",
            "author": [
                "Wenhong Zhu",
                "Hongkun Hao",
                "Zhiwei He",
                "Yunze Song",
                "Yumeng Zhang",
                "Hanxu Hu",
                "Yiran Wei",
                "Rui Wang",
                "Hongyuan Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09154v1",
                "http://arxiv.org/pdf/2311.09154v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09149v1",
            "title": "Temporal Knowledge Question Answering via Abstract Reasoning Induction",
            "updated": "2023-11-15T17:46:39Z",
            "published": "2023-11-15T17:46:39Z",
            "summary": "In this paper, we tackle the significant challenge of temporal knowledge\nreasoning in Large Language Models (LLMs), an area where such models frequently\nencounter difficulties. These difficulties often result in the generation of\nmisleading or incorrect information, primarily due to their limited capacity to\nprocess evolving factual knowledge and complex temporal logic. In response, we\npropose a novel, constructivism-based approach that advocates for a paradigm\nshift in LLM learning towards an active, ongoing process of knowledge synthesis\nand customization. At the heart of our proposal is the Abstract Reasoning\nInduction ARI framework, which divides temporal reasoning into two distinct\nphases: Knowledge-agnostic and Knowledge-based. This division aims to reduce\ninstances of hallucinations and improve LLMs' capacity for integrating abstract\nmethodologies derived from historical data. Our approach achieves remarkable\nimprovements, with relative gains of 29.7\\% and 9.27\\% on two temporal QA\ndatasets, underscoring its efficacy in advancing temporal reasoning in LLMs.\nThe code will be released at https://github.com/czy1999/ARI.",
            "author": [
                "Ziyang Chen",
                "Dongfang Li",
                "Xiang Zhao",
                "Baotian Hu",
                "Min Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09149v1",
                "http://arxiv.org/pdf/2311.09149v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09148v1",
            "title": "Predicting risk/reward ratio in financial markets for asset management\n  using machine learning",
            "updated": "2023-11-15T17:45:02Z",
            "published": "2023-11-15T17:45:02Z",
            "summary": "Financial market forecasting remains a formidable challenge despite the surge\nin computational capabilities and machine learning advancements. While numerous\nstudies have underscored the precision of computer-generated market\npredictions, many of these forecasts fail to yield profitable trading outcomes.\nThis discrepancy often arises from the unpredictable nature of profit and loss\nratios in the event of successful and unsuccessful predictions. In this study,\nwe introduce a novel algorithm specifically designed for forecasting the profit\nand loss outcomes of trading activities. This is further augmented by an\ninnovative approach for integrating these forecasts with previous predictions\nof market trends. This approach is designed for algorithmic trading, enabling\ntraders to assess the profitability of each trade and calibrate the optimal\ntrade size. Our findings indicate that this method significantly improves the\nperformance of traditional trading strategies as well as algorithmic trading\nsystems, offering a promising avenue for enhancing trading decisions.",
            "author": [
                "Reza Yarbakhsh",
                "Mahdieh Soleymani Baghshah",
                "Hamidreza Karimaghaie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09148v1",
                "http://arxiv.org/pdf/2311.09148v1"
            ],
            "primary_category": "q-fin.CP",
            "category": [
                "q-fin.CP",
                "q-fin.RM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09145v1",
            "title": "Model Agnostic Explainable Selective Regression via Uncertainty\n  Estimation",
            "updated": "2023-11-15T17:40:48Z",
            "published": "2023-11-15T17:40:48Z",
            "summary": "With the wide adoption of machine learning techniques, requirements have\nevolved beyond sheer high performance, often requiring models to be\ntrustworthy. A common approach to increase the trustworthiness of such systems\nis to allow them to refrain from predicting. Such a framework is known as\nselective prediction. While selective prediction for classification tasks has\nbeen widely analyzed, the problem of selective regression is understudied. This\npaper presents a novel approach to selective regression that utilizes\nmodel-agnostic non-parametric uncertainty estimation. Our proposed framework\nshowcases superior performance compared to state-of-the-art selective\nregressors, as demonstrated through comprehensive benchmarking on 69 datasets.\nFinally, we use explainable AI techniques to gain an understanding of the\ndrivers behind selective regression. We implement our selective regression\nmethod in the open-source Python package doubt and release the code used to\nreproduce our experiments.",
            "author": [
                "Andrea Pugnana",
                "Carlos Mougan",
                "Dan Saattrup Nielsen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09145v1",
                "http://arxiv.org/pdf/2311.09145v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09144v1",
            "title": "Grounding or Guesswork? Large Language Models are Presumptive Grounders",
            "updated": "2023-11-15T17:40:27Z",
            "published": "2023-11-15T17:40:27Z",
            "summary": "Effective conversation requires common ground: a shared understanding between\nthe participants. Common ground, however, does not emerge spontaneously in\nconversation. Speakers and listeners work together to both identify and\nconstruct a shared basis while avoiding misunderstanding. To accomplish\ngrounding, humans rely on a range of dialogue acts, like clarification (What do\nyou mean?) and acknowledgment (I understand.). In domains like teaching and\nemotional support, carefully constructing grounding prevents misunderstanding.\nHowever, it is unclear whether large language models (LLMs) leverage these\ndialogue acts in constructing common ground. To this end, we curate a set of\ngrounding acts and propose corresponding metrics that quantify attempted\ngrounding. We study whether LLMs use these grounding acts, simulating them\ntaking turns from several dialogue datasets, and comparing the results to\nhumans. We find that current LLMs are presumptive grounders, biased towards\nassuming common ground without using grounding acts. To understand the roots of\nthis behavior, we examine the role of instruction tuning and reinforcement\nlearning with human feedback (RLHF), finding that RLHF leads to less grounding.\nAltogether, our work highlights the need for more research investigating\ngrounding in human-AI interaction.",
            "author": [
                "Omar Shaikh",
                "Kristina Gligori\u0107",
                "Ashna Khetan",
                "Matthias Gerstgrasser",
                "Diyi Yang",
                "Dan Jurafsky"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09144v1",
                "http://arxiv.org/pdf/2311.09144v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09142v1",
            "title": "Machine-learning parameter tracking with partial state observation",
            "updated": "2023-11-15T17:39:25Z",
            "published": "2023-11-15T17:39:25Z",
            "summary": "Complex and nonlinear dynamical systems often involve parameters that change\nwith time, accurate tracking of which is essential to tasks such as state\nestimation, prediction, and control. Existing machine-learning methods require\nfull state observation of the underlying system and tacitly assume adiabatic\nchanges in the parameter. Formulating an inverse problem and exploiting\nreservoir computing, we develop a model-free and fully data-driven framework to\naccurately track time-varying parameters from partial state observation in real\ntime. In particular, with training data from a subset of the dynamical\nvariables of the system for a small number of known parameter values, the\nframework is able to accurately predict the parameter variations in time. Low-\nand high-dimensional, Markovian and non-Markovian nonlinear dynamical systems\nare used to demonstrate the power of the machine-learning based\nparameter-tracking framework. Pertinent issues affecting the tracking\nperformance are addressed.",
            "author": [
                "Zheng-Meng Zhai",
                "Mohammadamin Moradi",
                "Bryan Glaz",
                "Mulugeta Haile",
                "Ying-Cheng Lai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09142v1",
                "http://arxiv.org/pdf/2311.09142v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.DS",
                "nlin.CD",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09137v1",
            "title": "Causal prediction models for medication safety monitoring: The diagnosis\n  of vancomycin-induced acute kidney injury",
            "updated": "2023-11-15T17:29:24Z",
            "published": "2023-11-15T17:29:24Z",
            "summary": "The current best practice approach for the retrospective diagnosis of adverse\ndrug events (ADEs) in hospitalized patients relies on a full patient chart\nreview and a formal causality assessment by multiple medical experts. This\nevaluation serves to qualitatively estimate the probability of causation (PC);\nthe probability that a drug was a necessary cause of an adverse event. This\npractice is manual, resource intensive and prone to human biases, and may thus\nbenefit from data-driven decision support. Here, we pioneer a causal modeling\napproach using observational data to estimate a lower bound of the PC\n(PC$_{low}$). This method includes two key causal inference components: (1) the\ntarget trial emulation framework and (2) estimation of individualized treatment\neffects using machine learning. We apply our method to the clinically relevant\nuse-case of vancomycin-induced acute kidney injury in intensive care patients,\nand compare our causal model-based PC$_{low}$ estimates to qualitative\nestimates of the PC provided by a medical expert. Important limitations and\npotential improvements are discussed, and we conclude that future improved\ncausal models could provide essential data-driven support for medication safety\nmonitoring in hospitalized patients.",
            "author": [
                "Izak Yasrebi-de Kom",
                "Joanna Klopotowska",
                "Dave Dongelmans",
                "Nicolette De Keizer",
                "Kitty Jager",
                "Ameen Abu-Hanna",
                "Giovanni Cin\u00e0"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09137v1",
                "http://arxiv.org/pdf/2311.09137v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09134v1",
            "title": "Scalable and Effective Generative Information Retrieval",
            "updated": "2023-11-15T17:26:28Z",
            "published": "2023-11-15T17:26:28Z",
            "summary": "Recent research has shown that transformer networks can be used as\ndifferentiable search indexes by representing each document as a sequences of\ndocument ID tokens. These generative retrieval models cast the retrieval\nproblem to a document ID generation problem for each given query. Despite their\nelegant design, existing generative retrieval models only perform well on\nartificially-constructed and small-scale collections. This has led to serious\nskepticism in the research community on their real-world impact. This paper\nrepresents an important milestone in generative retrieval research by showing,\nfor the first time, that generative retrieval models can be trained to perform\neffectively on large-scale standard retrieval benchmarks. For doing so, we\npropose RIPOR- an optimization framework for generative retrieval that can be\nadopted by any encoder-decoder architecture. RIPOR is designed based on two\noften-overlooked fundamental design considerations in generative retrieval.\nFirst, given the sequential decoding nature of document ID generation,\nassigning accurate relevance scores to documents based on the whole document ID\nsequence is not sufficient. To address this issue, RIPOR introduces a novel\nprefix-oriented ranking optimization algorithm. Second, initial document IDs\nshould be constructed based on relevance associations between queries and\ndocuments, instead of the syntactic and semantic information in the documents.\nRIPOR addresses this issue using a relevance-based document ID construction\napproach that quantizes relevance-based representations learned for documents.\nEvaluation on MSMARCO and TREC Deep Learning Track reveals that RIPOR surpasses\nstate-of-the-art generative retrieval models by a large margin (e.g., 30.5% MRR\nimprovements on MS MARCO Dev Set), and perform better on par with popular dense\nretrieval models.",
            "author": [
                "Hansi Zeng",
                "Chen Luo",
                "Bowen Jin",
                "Sheikh Muhammad Sarwar",
                "Tianxin Wei",
                "Hamed Zamani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09134v1",
                "http://arxiv.org/pdf/2311.09134v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09133v1",
            "title": "Explainable Text Classification Techniques in Legal Document Review:\n  Locating Rationales without Using Human Annotated Training Text Snippets",
            "updated": "2023-11-15T17:24:56Z",
            "published": "2023-11-15T17:24:56Z",
            "summary": "US corporations regularly spend millions of dollars reviewing\nelectronically-stored documents in legal matters. Recently, attorneys apply\ntext classification to efficiently cull massive volumes of data to identify\nresponsive documents for use in these matters. While text classification is\nregularly used to reduce the discovery costs of legal matters, it also faces a\nperception challenge: amongst lawyers, this technology is sometimes looked upon\nas a \"black box\". Put simply, no extra information is provided for attorneys to\nunderstand why documents are classified as responsive. In recent years,\nexplainable machine learning has emerged as an active research area. In an\nexplainable machine learning system, predictions or decisions made by a machine\nlearning model are human understandable. In legal 'document review' scenarios,\na document is responsive, because one or more of its small text snippets are\ndeemed responsive. In these scenarios, if these responsive snippets can be\nlocated, then attorneys could easily evaluate the model's document\nclassification decisions - this is especially important in the field of\nresponsible AI. Our prior research identified that predictive models created\nusing annotated training text snippets improved the precision of a model when\ncompared to a model created using all of a set of documents' text as training.\nWhile interesting, manually annotating training text snippets is not generally\npractical during a legal document review. However, small increases in precision\ncan drastically decrease the cost of large document reviews. Automating the\nidentification of training text snippets without human review could then make\nthe application of training text snippet-based models a practical approach.",
            "author": [
                "Christian Mahoney",
                "Peter Gronvall",
                "Nathaniel Huber-Fliflet",
                "Jianping Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09133v1",
                "http://arxiv.org/pdf/2311.09133v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09132v1",
            "title": "Aligning Neural Machine Translation Models: Human Feedback in Training\n  and Inference",
            "updated": "2023-11-15T17:21:58Z",
            "published": "2023-11-15T17:21:58Z",
            "summary": "Reinforcement learning from human feedback (RLHF) is a recent technique to\nimprove the quality of the text generated by a language model, making it closer\nto what humans would generate. A core ingredient in RLHF's success in aligning\nand improving large language models (LLMs) is its reward model, trained using\nhuman feedback on model outputs. In machine translation (MT), where metrics\ntrained from human annotations can readily be used as reward models, recent\nmethods using minimum Bayes risk decoding and reranking have succeeded in\nimproving the final quality of translation. In this study, we comprehensively\nexplore and compare techniques for integrating quality metrics as reward models\ninto the MT pipeline. This includes using the reward model for data filtering,\nduring the training phase through RL, and at inference time by employing\nreranking techniques, and we assess the effects of combining these in a unified\napproach. Our experimental results, conducted across multiple translation\ntasks, underscore the crucial role of effective data filtering, based on\nestimated quality, in harnessing the full potential of RL in enhancing MT\nquality. Furthermore, our findings demonstrate the effectiveness of combining\nRL training with reranking techniques, showcasing substantial improvements in\ntranslation quality.",
            "author": [
                "Miguel Moura Ramos",
                "Patrick Fernandes",
                "Ant\u00f3nio Farinhas",
                "Andr\u00e9 F. T. Martins"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09132v1",
                "http://arxiv.org/pdf/2311.09132v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09131v1",
            "title": "Practical Use of ChatGPT in Psychiatry for Treatment Plan and\n  Psychoeducation",
            "updated": "2023-11-15T17:21:09Z",
            "published": "2023-11-15T17:21:09Z",
            "summary": "Artificial Intelligence (AI) has revolutionized various fields, including\nmedicine and mental health support. One promising application is ChatGPT, an\nadvanced conversational AI model that uses deep learning techniques to provide\nhuman-like responses. This review paper explores the potential impact of\nChatGPT in psychiatry and its various applications, highlighting its role in\ntherapy and counseling techniques, self-help and coping strategies, mindfulness\nand relaxation techniques, screening and monitoring, education and information\ndissemination, specialized support, group and family support, learning and\ntraining, expressive and artistic therapies, telepsychiatry and online support,\nand crisis management and prevention. While ChatGPT offers personalized,\naccessible, and scalable support, it is essential to emphasize that it should\nnot replace the expertise and guidance of qualified mental health\nprofessionals. Ethical considerations, such as user privacy, data security, and\nhuman oversight, are also discussed. By examining the potential and challenges,\nthis paper sheds light on the responsible integration of ChatGPT in psychiatric\nresearch and practice, fostering improved mental health outcomes.",
            "author": [
                "Farzan Vahedifard",
                "Atieh Sadeghniiat Haghighi",
                "Tirth Dave",
                "Mohammad Tolouei",
                "Fateme Hoshyar Zare"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09131v1",
                "http://arxiv.org/pdf/2311.09131v1"
            ],
            "primary_category": "q-bio.NC",
            "category": [
                "q-bio.NC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09128v1",
            "title": "Fast Detection of Phase Transitions with Multi-Task\n  Learning-by-Confusion",
            "updated": "2023-11-15T17:17:49Z",
            "published": "2023-11-15T17:17:49Z",
            "summary": "Machine learning has been successfully used to study phase transitions. One\nof the most popular approaches to identifying critical points from data without\nprior knowledge of the underlying phases is the learning-by-confusion scheme.\nAs input, it requires system samples drawn from a grid of the parameter whose\nchange is associated with potential phase transitions. Up to now, the scheme\nrequired training a distinct binary classifier for each possible splitting of\nthe grid into two sides, resulting in a computational cost that scales linearly\nwith the number of grid points. In this work, we propose and showcase an\nalternative implementation that only requires the training of a single\nmulti-class classifier. Ideally, such multi-task learning eliminates the\nscaling with respect to the number of grid points. In applications to the Ising\nmodel and an image dataset generated with Stable Diffusion, we find significant\nspeedups that closely correspond to the ideal case, with only minor deviations.",
            "author": [
                "Julian Arnold",
                "Frank Sch\u00e4fer",
                "Niels L\u00f6rch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09128v1",
                "http://arxiv.org/pdf/2311.09128v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cond-mat.dis-nn",
                "cond-mat.stat-mech"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09127v1",
            "title": "Jailbreaking GPT-4V via Self-Adversarial Attacks with System Prompts",
            "updated": "2023-11-15T17:17:39Z",
            "published": "2023-11-15T17:17:39Z",
            "summary": "Existing work on jailbreak Multimodal Large Language Models (MLLMs) has\nfocused primarily on adversarial examples in model inputs, with less attention\nto vulnerabilities in model APIs. To fill the research gap, we carry out the\nfollowing work: 1) We discover a system prompt leakage vulnerability in GPT-4V.\nThrough carefully designed dialogue, we successfully steal the internal system\nprompts of GPT-4V. This finding indicates potential exploitable security risks\nin MLLMs; 2)Based on the acquired system prompts, we propose a novel MLLM\njailbreaking attack method termed SASP (Self-Adversarial Attack via System\nPrompt). By employing GPT-4 as a red teaming tool against itself, we aim to\nsearch for potential jailbreak prompts leveraging stolen system prompts.\nFurthermore, in pursuit of better performance, we also add human modification\nbased on GPT-4's analysis, which further improves the attack success rate to\n98.7\\%; 3) We evaluated the effect of modifying system prompts to defend\nagainst jailbreaking attacks. Results show that appropriately designed system\nprompts can significantly reduce jailbreak success rates. Overall, our work\nprovides new insights into enhancing MLLM security, demonstrating the important\nrole of system prompts in jailbreaking, which could be leveraged to greatly\nfacilitate jailbreak success rates while also holding the potential for\ndefending against jailbreaks.",
            "author": [
                "Yuanwei Wu",
                "Xiang Li",
                "Yixin Liu",
                "Pan Zhou",
                "Lichao Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09127v1",
                "http://arxiv.org/pdf/2311.09127v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09122v1",
            "title": "Universal NER: A Gold-Standard Multilingual Named Entity Recognition\n  Benchmark",
            "updated": "2023-11-15T17:09:54Z",
            "published": "2023-11-15T17:09:54Z",
            "summary": "We introduce Universal NER (UNER), an open, community-driven project to\ndevelop gold-standard NER benchmarks in many languages. The overarching goal of\nUNER is to provide high-quality, cross-lingually consistent annotations to\nfacilitate and standardize multilingual NER research. UNER v1 contains 18\ndatasets annotated with named entities in a cross-lingual consistent schema\nacross 12 diverse languages. In this paper, we detail the dataset creation and\ncomposition of UNER; we also provide initial modeling baselines on both\nin-language and cross-lingual learning settings. We release the data, code, and\nfitted models to the public.",
            "author": [
                "Stephen Mayhew",
                "Terra Blevins",
                "Shuheng Liu",
                "Marek \u0160uppa",
                "Hila Gonen",
                "Joseph Marvin Imperial",
                "B\u00f6rje F. Karlsson",
                "Peiqin Lin",
                "Nikola Ljube\u0161i\u0107",
                "LJ Miranda",
                "Barbara Plank",
                "Arij Riabi",
                "Yuval Pinter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09122v1",
                "http://arxiv.org/pdf/2311.09122v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09118v1",
            "title": "WildlifeDatasets: An open-source toolkit for animal re-identification",
            "updated": "2023-11-15T17:08:09Z",
            "published": "2023-11-15T17:08:09Z",
            "summary": "In this paper, we present WildlifeDatasets\n(https://github.com/WildlifeDatasets/wildlife-datasets) - an open-source\ntoolkit intended primarily for ecologists and computer-vision /\nmachine-learning researchers. The WildlifeDatasets is written in Python, allows\nstraightforward access to publicly available wildlife datasets, and provides a\nwide variety of methods for dataset pre-processing, performance analysis, and\nmodel fine-tuning. We showcase the toolkit in various scenarios and baseline\nexperiments, including, to the best of our knowledge, the most comprehensive\nexperimental comparison of datasets and methods for wildlife re-identification,\nincluding both local descriptors and deep learning approaches. Furthermore, we\nprovide the first-ever foundation model for individual re-identification within\na wide range of species - MegaDescriptor - that provides state-of-the-art\nperformance on animal re-identification datasets and outperforms other\npre-trained models such as CLIP and DINOv2 by a significant margin. To make the\nmodel available to the general public and to allow easy integration with any\nexisting wildlife monitoring applications, we provide multiple MegaDescriptor\nflavors (i.e., Small, Medium, and Large) through the HuggingFace hub\n(https://huggingface.co/BVRA).",
            "author": [
                "Vojt\u011bch \u010cerm\u00e1k",
                "Lukas Picek",
                "Luk\u00e1\u0161 Adam",
                "Kostas Papafitsoros"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09118v1",
                "http://arxiv.org/pdf/2311.09118v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09117v1",
            "title": "R-Spin: Efficient Speaker and Noise-invariant Representation Learning\n  with Acoustic Pieces",
            "updated": "2023-11-15T17:07:44Z",
            "published": "2023-11-15T17:07:44Z",
            "summary": "This paper introduces Robust Spin (R-Spin), a data-efficient self-supervised\nfine-tuning framework for speaker and noise-invariant speech representations by\nlearning discrete acoustic units with speaker-invariant clustering (Spin).\nR-Spin resolves Spin's issues and enhances content representations by learning\nto predict acoustic pieces. R-Spin offers a 12X reduction in computational\nresources compared to previous state-of-the-art methods while outperforming\nthem in severely distorted speech scenarios. This paper provides detailed\nanalyses to show how discrete units contribute to speech encoder training and\nimproving robustness in diverse acoustic environments.",
            "author": [
                "Heng-Jui Chang",
                "James Glass"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09117v1",
                "http://arxiv.org/pdf/2311.09117v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09115v2",
            "title": "HEALNet -- Hybrid Multi-Modal Fusion for Heterogeneous Biomedical Data",
            "updated": "2023-11-20T13:55:04Z",
            "published": "2023-11-15T17:06:26Z",
            "summary": "Technological advances in medical data collection such as high-resolution\nhistopathology and high-throughput genomic sequencing have contributed to the\nrising requirement for multi-modal biomedical modelling, specifically for\nimage, tabular, and graph data. Most multi-modal deep learning approaches use\nmodality-specific architectures that are trained separately and cannot capture\nthe crucial cross-modal information that motivates the integration of different\ndata sources. This paper presents the Hybrid Early-fusion Attention Learning\nNetwork (HEALNet): a flexible multi-modal fusion architecture, which a)\npreserves modality-specific structural information, b) captures the cross-modal\ninteractions and structural information in a shared latent space, c) can\neffectively handle missing modalities during training and inference, and d)\nenables intuitive model inspection by learning on the raw data input instead of\nopaque embeddings. We conduct multi-modal survival analysis on Whole Slide\nImages and Multi-omic data on four cancer cohorts of The Cancer Genome Atlas\n(TCGA). HEALNet achieves state-of-the-art performance, substantially improving\nover both uni-modal and recent multi-modal baselines, whilst being robust in\nscenarios with missing modalities.",
            "author": [
                "Konstantin Hemker",
                "Nikola Simidjievski",
                "Mateja Jamnik"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09115v2",
                "http://arxiv.org/pdf/2311.09115v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09114v1",
            "title": "Ever: Mitigating Hallucination in Large Language Models through\n  Real-Time Verification and Rectification",
            "updated": "2023-11-15T17:04:56Z",
            "published": "2023-11-15T17:04:56Z",
            "summary": "Large Language Models (LLMs) have demonstrated remarkable proficiency in\ngenerating fluent text. However, they often encounter the challenge of\ngenerating inaccurate or hallucinated content. This issue is common in both\nnon-retrieval-based generation and retrieval-augmented generation approaches,\nand existing post-hoc rectification methods may not address the accumulated\nhallucination errors that may be caused by the \"snowballing\" issue, especially\nin reasoning tasks. To tackle these challenges, we introduce a novel approach\ncalled Real-time Verification and Rectification (Ever). Instead of waiting\nuntil the end of the generation process to rectify hallucinations, Ever employs\na real-time, step-wise generation and hallucination rectification strategy. The\nprimary objective is to detect and rectify hallucinations as they occur during\nthe text generation process. When compared to both retrieval-based and\nnon-retrieval-based baselines, Ever demonstrates a significant improvement in\ngenerating trustworthy and factually accurate text across a diverse range of\ntasks, including short-form QA, biography generation, and multi-hop reasoning.",
            "author": [
                "Haoqiang Kang",
                "Juntong Ni",
                "Huaxiu Yao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09114v1",
                "http://arxiv.org/pdf/2311.09114v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09109v1",
            "title": "Does Pre-trained Language Model Actually Infer Unseen Links in Knowledge\n  Graph Completion?",
            "updated": "2023-11-15T16:56:49Z",
            "published": "2023-11-15T16:56:49Z",
            "summary": "Knowledge graphs (KGs) consist of links that describe relationships between\nentities. Due to the difficulty of manually enumerating all relationships\nbetween entities, automatically completing them is essential for KGs. Knowledge\nGraph Completion (KGC) is a task that infers unseen relationships between\nentities in a KG. Traditional embedding-based KGC methods, such as RESCAL,\nTransE, DistMult, ComplEx, RotatE, HAKE, HousE, etc., infer missing links using\nonly the knowledge from training data. In contrast, the recent Pre-trained\nLanguage Model (PLM)-based KGC utilizes knowledge obtained during pre-training.\nTherefore, PLM-based KGC can estimate missing links between entities by reusing\nmemorized knowledge from pre-training without inference. This approach is\nproblematic because building KGC models aims to infer unseen links between\nentities. However, conventional evaluations in KGC do not consider inference\nand memorization abilities separately. Thus, a PLM-based KGC method, which\nachieves high performance in current KGC evaluations, may be ineffective in\npractical applications. To address this issue, we analyze whether PLM-based KGC\nmethods make inferences or merely access memorized knowledge. For this purpose,\nwe propose a method for constructing synthetic datasets specified in this\nanalysis and conclude that PLMs acquire the inference abilities required for\nKGC through pre-training, even though the performance improvements mostly come\nfrom textual information of entities and relations.",
            "author": [
                "Yusuke Sakai",
                "Hidetaka Kamigaito",
                "Katsuhiko Hayashi",
                "Taro Watanabe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09109v1",
                "http://arxiv.org/pdf/2311.09109v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09104v1",
            "title": "Cross-view and Cross-pose Completion for 3D Human Understanding",
            "updated": "2023-11-15T16:51:18Z",
            "published": "2023-11-15T16:51:18Z",
            "summary": "Human perception and understanding is a major domain of computer vision\nwhich, like many other vision subdomains recently, stands to gain from the use\nof large models pre-trained on large datasets. We hypothesize that the most\ncommon pre-training strategy of relying on general purpose, object-centric\nimage datasets such as ImageNet, is limited by an important domain shift. On\nthe other hand, collecting domain specific ground truth such as 2D or 3D labels\ndoes not scale well. Therefore, we propose a pre-training approach based on\nself-supervised learning that works on human-centric data using only images.\nOur method uses pairs of images of humans: the first is partially masked and\nthe model is trained to reconstruct the masked parts given the visible ones and\na second image. It relies on both stereoscopic (cross-view) pairs, and temporal\n(cross-pose) pairs taken from videos, in order to learn priors about 3D as well\nas human motion. We pre-train a model for body-centric tasks and one for\nhand-centric tasks. With a generic transformer architecture, these models\noutperform existing self-supervised pre-training methods on a wide set of\nhuman-centric downstream tasks, and obtain state-of-the-art performance for\ninstance when fine-tuning for model-based and model-free human mesh recovery.",
            "author": [
                "Matthieu Armando",
                "Salma Galaaoui",
                "Fabien Baradel",
                "Thomas Lucas",
                "Vincent Leroy",
                "Romain Br\u00e9gier",
                "Philippe Weinzaepfel",
                "Gr\u00e9gory Rogez"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09104v1",
                "http://arxiv.org/pdf/2311.09104v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09101v1",
            "title": "Towards A Unified View of Answer Calibration for Multi-Step Reasoning",
            "updated": "2023-11-15T16:47:57Z",
            "published": "2023-11-15T16:47:57Z",
            "summary": "Large Language Models (LLMs) employing Chain-of-Thought (CoT) prompting have\nbroadened the scope for improving multi-step reasoning capabilities. Usually,\nanswer calibration strategies such as step-level or path-level calibration play\na vital role in multi-step reasoning. While effective, there remains a\nsignificant gap in our understanding of the key factors that drive their\nsuccess. In this paper, we break down the design of recent answer calibration\nstrategies and present a unified view which establishes connections between\nthem. We then conduct a thorough evaluation on these strategies from a unified\nview, systematically scrutinizing step-level and path-level answer calibration\nacross multiple paths. Our study holds the potential to illuminate key insights\nfor optimizing multi-step reasoning with answer calibration.",
            "author": [
                "Shumin Deng",
                "Ningyu Zhang",
                "Nay Oo",
                "Bryan Hooi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09101v1",
                "http://arxiv.org/pdf/2311.09101v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09274v1",
            "title": "Constructing interpretable principal curve using Neural ODEs",
            "updated": "2023-11-15T16:46:53Z",
            "published": "2023-11-15T16:46:53Z",
            "summary": "The study of high dimensional data sets often rely on their low dimensional\nprojections that preserve the local geometry of the original space. While\nnumerous methods have been developed to summarize this space as variations of\ntree-like structures, they are usually non-parametric and \"static\" in nature.\nAs data may come from systems that are dynamical such as a differentiating\ncell, a static, non-parametric characterization of the space may not be the\nmost appropriate. Here, we developed a framework, the principal flow, that is\ncapable of characterizing the space in a dynamical manner. The principal flow,\ndefined using neural ODEs, directs motion of a particle through the space,\nwhere the trajectory of the particle resembles the principal curve of the\ndataset. We illustrate that our framework can be used to characterize shapes of\nvarious complexities, and is flexible to incorporate summaries of relaxation\ndynamics.",
            "author": [
                "Guangzheng Zhang",
                "Bingxian Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09274v1",
                "http://arxiv.org/pdf/2311.09274v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09094v1",
            "title": "Can MusicGen Create Training Data for MIR Tasks?",
            "updated": "2023-11-15T16:41:56Z",
            "published": "2023-11-15T16:41:56Z",
            "summary": "We are investigating the broader concept of using AI-based generative music\nsystems to generate training data for Music Information Retrieval (MIR) tasks.\nTo kick off this line of work, we ran an initial experiment in which we trained\na genre classifier on a fully artificial music dataset created with MusicGen.\nWe constructed over 50 000 genre- conditioned textual descriptions and\ngenerated a collection of music excerpts that covers five musical genres. Our\npreliminary results show that the proposed model can learn genre-specific\ncharacteristics from artificial music tracks that generalise well to real-world\nmusic recordings.",
            "author": [
                "Nadine Kroher",
                "Helena Cuesta",
                "Aggelos Pikrakis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09094v1",
                "http://arxiv.org/pdf/2311.09094v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.AI",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09088v1",
            "title": "Co-ML: Collaborative Machine Learning Model Building for Developing\n  Dataset Design Practices",
            "updated": "2023-11-15T16:32:35Z",
            "published": "2023-11-15T16:32:35Z",
            "summary": "Machine learning (ML) models are fundamentally shaped by data, and building\ninclusive ML systems requires significant considerations around how to design\nrepresentative datasets. Yet, few novice-oriented ML modeling tools are\ndesigned to foster hands-on learning of dataset design practices, including how\nto design for data diversity and inspect for data quality.\n  To this end, we outline a set of four data design practices (DDPs) for\ndesigning inclusive ML models and share how we designed a tablet-based\napplication called Co-ML to foster learning of DDPs through a collaborative ML\nmodel building experience. With Co-ML, beginners can build image classifiers\nthrough a distributed experience where data is synchronized across multiple\ndevices, enabling multiple users to iteratively refine ML datasets in\ndiscussion and coordination with their peers.\n  We deployed Co-ML in a 2-week-long educational AIML Summer Camp, where youth\nages 13-18 worked in groups to build custom ML-powered mobile applications. Our\nanalysis reveals how multi-user model building with Co-ML, in the context of\nstudent-driven projects created during the summer camp, supported development\nof DDPs involving incorporating data diversity, evaluating model performance,\nand inspecting for data quality. Additionally, we found that students' attempts\nto improve model performance often prioritized learnability over class balance.\nThrough this work, we highlight how the combination of collaboration, model\ntesting interfaces, and student-driven projects can empower learners to\nactively engage in exploring the role of data in ML systems.",
            "author": [
                "Tiffany Tseng",
                "Matt J. Davidson",
                "Luis Morales-Navarro",
                "Jennifer King Chen",
                "Victoria Delaney",
                "Mark Leibowitz",
                "Jazbo Beason",
                "R. Benjamin Shapiro"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09088v1",
                "http://arxiv.org/pdf/2311.09088v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09084v1",
            "title": "Contrastive Transformer Learning with Proximity Data Generation for\n  Text-Based Person Search",
            "updated": "2023-11-15T16:26:49Z",
            "published": "2023-11-15T16:26:49Z",
            "summary": "Given a descriptive text query, text-based person search (TBPS) aims to\nretrieve the best-matched target person from an image gallery. Such a\ncross-modal retrieval task is quite challenging due to significant modality\ngap, fine-grained differences and insufficiency of annotated data. To better\nalign the two modalities, most existing works focus on introducing\nsophisticated network structures and auxiliary tasks, which are complex and\nhard to implement. In this paper, we propose a simple yet effective dual\nTransformer model for text-based person search. By exploiting a hardness-aware\ncontrastive learning strategy, our model achieves state-of-the-art performance\nwithout any special design for local feature alignment or side information.\nMoreover, we propose a proximity data generation (PDG) module to automatically\nproduce more diverse data for cross-modal training. The PDG module first\nintroduces an automatic generation algorithm based on a text-to-image diffusion\nmodel, which generates new text-image pair samples in the proximity space of\noriginal ones. Then it combines approximate text generation and feature-level\nmixup during training to further strengthen the data diversity. The PDG module\ncan largely guarantee the reasonability of the generated samples that are\ndirectly used for training without any human inspection for noise rejection. It\nimproves the performance of our model significantly, providing a feasible\nsolution to the data insufficiency problem faced by such fine-grained\nvisual-linguistic tasks. Extensive experiments on two popular datasets of the\nTBPS task (i.e., CUHK-PEDES and ICFG-PEDES) show that the proposed approach\noutperforms state-of-the-art approaches evidently, e.g., improving by 3.88%,\n4.02%, 2.92% in terms of Top1, Top5, Top10 on CUHK-PEDES. The codes will be\navailable at https://github.com/HCPLab-SYSU/PersonSearch-CTLG",
            "author": [
                "Hefeng Wu",
                "Weifeng Chen",
                "Zhibin Liu",
                "Tianshui Chen",
                "Zhiguang Chen",
                "Liang Lin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09084v1",
                "http://arxiv.org/pdf/2311.09084v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09068v1",
            "title": "Learning Fair Division from Bandit Feedback",
            "updated": "2023-11-15T16:10:34Z",
            "published": "2023-11-15T16:10:34Z",
            "summary": "This work addresses learning online fair division under uncertainty, where a\ncentral planner sequentially allocates items without precise knowledge of\nagents' values or utilities. Departing from conventional online algorithm, the\nplanner here relies on noisy, estimated values obtained after allocating items.\nWe introduce wrapper algorithms utilizing \\textit{dual averaging}, enabling\ngradual learning of both the type distribution of arriving items and agents'\nvalues through bandit feedback. This approach enables the algorithms to\nasymptotically achieve optimal Nash social welfare in linear Fisher markets\nwith agents having additive utilities. We establish regret bounds in Nash\nsocial welfare and empirically validate the superior performance of our\nproposed algorithms across synthetic and empirical datasets.",
            "author": [
                "Hakuei Yamada",
                "Junpei Komiyama",
                "Kenshi Abe",
                "Atsushi Iwasaki"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09068v1",
                "http://arxiv.org/pdf/2311.09068v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09065v1",
            "title": "Damped Proximal Augmented Lagrangian Method for weakly-Convex Problems\n  with Convex Constraints",
            "updated": "2023-11-15T16:05:43Z",
            "published": "2023-11-15T16:05:43Z",
            "summary": "We give a damped proximal augmented Lagrangian method (DPALM) for solving\nproblems with a weakly-convex objective and convex linear/nonlinear\nconstraints. Instead of taking a full stepsize, DPALM adopts a damped dual\nstepsize to ensure the boundedness of dual iterates. We show that DPALM can\nproduce a (near) $\\vareps$-KKT point within $O(\\vareps^{-2})$ outer iterations\nif each DPALM subproblem is solved to a proper accuracy. In addition, we\nestablish overall iteration complexity of DPALM when the objective is either a\nregularized smooth function or in a regularized compositional form. For the\nformer case, DPALM achieves the complexity of\n$\\widetilde{\\mathcal{O}}\\left(\\varepsilon^{-2.5} \\right)$ to produce an\n$\\varepsilon$-KKT point by applying an accelerated proximal gradient (APG)\nmethod to each DPALM subproblem. For the latter case, the complexity of DPALM\nis $\\widetilde{\\mathcal{O}}\\left(\\varepsilon^{-3} \\right)$ to produce a near\n$\\varepsilon$-KKT point by using an APG to solve a Moreau-envelope smoothed\nversion of each subproblem. Our outer iteration complexity and the overall\ncomplexity either generalize existing best ones from unconstrained or\nlinear-constrained problems to convex-constrained ones, or improve over the\nbest-known results on solving the same-structured problems. Furthermore,\nnumerical experiments on linearly/quadratically constrained non-convex\nquadratic programs and linear-constrained robust nonlinear least squares are\nconducted to demonstrate the empirical efficiency of the proposed DPALM over\nseveral state-of-the art methods.",
            "author": [
                "Hari Dahal",
                "Wei Liu",
                "Yangyang Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09065v1",
                "http://arxiv.org/pdf/2311.09065v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09064v1",
            "title": "Imagine the Unseen World: A Benchmark for Systematic Generalization in\n  Visual World Models",
            "updated": "2023-11-15T16:02:13Z",
            "published": "2023-11-15T16:02:13Z",
            "summary": "Systematic compositionality, or the ability to adapt to novel situations by\ncreating a mental model of the world using reusable pieces of knowledge,\nremains a significant challenge in machine learning. While there has been\nconsiderable progress in the language domain, efforts towards systematic visual\nimagination, or envisioning the dynamical implications of a visual observation,\nare in their infancy. We introduce the Systematic Visual Imagination Benchmark\n(SVIB), the first benchmark designed to address this problem head-on. SVIB\noffers a novel framework for a minimal world modeling problem, where models are\nevaluated based on their ability to generate one-step image-to-image\ntransformations under a latent world dynamics. The framework provides benefits\nsuch as the possibility to jointly optimize for systematic perception and\nimagination, a range of difficulty levels, and the ability to control the\nfraction of possible factor combinations used during training. We provide a\ncomprehensive evaluation of various baseline models on SVIB, offering insight\ninto the current state-of-the-art in systematic visual imagination. We hope\nthat this benchmark will help advance visual systematic compositionality.",
            "author": [
                "Yeongbin Kim",
                "Gautam Singh",
                "Junyeong Park",
                "Caglar Gulcehre",
                "Sungjin Ahn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09064v1",
                "http://arxiv.org/pdf/2311.09064v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09058v2",
            "title": "Constrained Parameter Regularization",
            "updated": "2023-12-06T14:20:53Z",
            "published": "2023-11-15T15:50:34Z",
            "summary": "Regularization is a critical component in deep learning training, with weight\ndecay being a commonly used approach. It applies a constant penalty coefficient\nuniformly across all parameters. This may be unnecessarily restrictive for some\nparameters, while insufficiently restricting others. To dynamically adjust\npenalty coefficients for different parameter groups, we present constrained\nparameter regularization (CPR) as an alternative to traditional weight decay.\nInstead of applying a single constant penalty to all parameters, we enforce an\nupper bound on a statistical measure (e.g., the L$_2$-norm) of parameter\ngroups. Consequently, learning becomes a constraint optimization problem, which\nwe address by an adaptation of the augmented Lagrangian method. CPR only\nrequires two hyperparameters and incurs no measurable runtime overhead.\nAdditionally, we propose a simple but efficient mechanism to adapt the upper\nbounds during the optimization. We provide empirical evidence of CPR's efficacy\nin experiments on the \"grokking\" phenomenon, computer vision, and language\nmodeling tasks. Our results demonstrate that CPR counteracts the effects of\ngrokking and consistently matches or outperforms traditional weight decay.",
            "author": [
                "J\u00f6rg K. H. Franke",
                "Michael Hefenbrock",
                "Gregor Koehler",
                "Frank Hutter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09058v2",
                "http://arxiv.org/pdf/2311.09058v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09273v1",
            "title": "In-vehicle Sensing and Data Analysis for Older Drivers with Mild\n  Cognitive Impairment",
            "updated": "2023-11-15T15:47:24Z",
            "published": "2023-11-15T15:47:24Z",
            "summary": "Driving is a complex daily activity indicating age and disease related\ncognitive declines. Therefore, deficits in driving performance compared with\nones without mild cognitive impairment (MCI) can reflect changes in cognitive\nfunctioning. There is increasing evidence that unobtrusive monitoring of older\nadults driving performance in a daily-life setting may allow us to detect\nsubtle early changes in cognition. The objectives of this paper include\ndesigning low-cost in-vehicle sensing hardware capable of obtaining\nhigh-precision positioning and telematics data, identifying important\nindicators for early changes in cognition, and detecting early-warning signs of\ncognitive impairment in a truly normal, day-to-day driving condition with\nmachine learning approaches. Our statistical analysis comparing drivers with\nMCI to those without reveals that those with MCI exhibit smoother and safer\ndriving patterns. This suggests that drivers with MCI are cognizant of their\ncondition and tend to avoid erratic driving behaviors. Furthermore, our Random\nForest models identified the number of night trips, number of trips, and\neducation as the most influential factors in our data evaluation.",
            "author": [
                "Sonia Moshfeghi",
                "Muhammad Tanveer Jan",
                "Joshua Conniff",
                "Seyedeh Gol Ara Ghoreishi",
                "Jinwoo Jang",
                "Borko Furht",
                "Kwangsoo Yang",
                "Monica Rosselli",
                "David Newman",
                "Ruth Tappen",
                "Dana Smith"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09273v1",
                "http://arxiv.org/pdf/2311.09273v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09049v2",
            "title": "Adapting Large Language Models by Integrating Collaborative Semantics\n  for Recommendation",
            "updated": "2023-11-28T13:11:41Z",
            "published": "2023-11-15T15:39:33Z",
            "summary": "Recently, large language models (LLMs) have shown great potential in\nrecommender systems, either improving existing recommendation models or serving\nas the backbone. However, there exists a large semantic gap between LLMs and\nrecommender systems, since items to be recommended are often indexed by\ndiscrete identifiers (item ID) out of the LLM's vocabulary. In essence, LLMs\ncapture language semantics while recommender systems imply collaborative\nsemantics, making it difficult to sufficiently leverage the model capacity of\nLLMs for recommendation. To address this challenge, in this paper, we propose a\nnew LLM-based recommendation model called LC-Rec, which can better integrate\nlanguage and collaborative semantics for recommender systems. Our approach can\ndirectly generate items from the entire item set for recommendation, without\nrelying on candidate items. Specifically, we make two major contributions in\nour approach. For item indexing, we design a learning-based vector quantization\nmethod with uniform semantic mapping, which can assign meaningful and\nnon-conflicting IDs (called item indices) for items. For alignment tuning, we\npropose a series of specially designed tuning tasks to enhance the integration\nof collaborative semantics in LLMs. Our fine-tuning tasks enforce LLMs to\ndeeply integrate language and collaborative semantics (characterized by the\nlearned item indices), so as to achieve an effective adaptation to recommender\nsystems. Extensive experiments demonstrate the effectiveness of our method,\nshowing that our approach can outperform a number of competitive baselines\nincluding traditional recommenders and existing LLM-based recommenders. Our\ncode is available at https://github.com/RUCAIBox/LC-Rec/.",
            "author": [
                "Bowen Zheng",
                "Yupeng Hou",
                "Hongyu Lu",
                "Yu Chen",
                "Wayne Xin Zhao",
                "Ming Chen",
                "Ji-Rong Wen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09049v2",
                "http://arxiv.org/pdf/2311.09049v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09035v1",
            "title": "Strengthening our grip on food security by encoding physics into AI",
            "updated": "2023-11-15T15:27:54Z",
            "published": "2023-11-15T15:27:54Z",
            "summary": "Climate change will jeopardize food security. Food security involves the\nrobustness of the global agri-food system. This agri-food system is intricately\nconnected to systems centering around health, economy, social-cultural\ndiversity, and global political stability. A systematic way to determine\nacceptable interventions in the global agri-food systems involves analyses at\ndifferent spatial and temporal scales. Such multi-scale analyses are common\nwithin physics. Unfortunately, physics alone is not sufficient. Machine\nlearning techniques may aid. We focus on neural networks (NN) into which\nphysics-based information is encoded (PeNN) and apply it to a sub-problem\nwithin the agri-food system. We show that the mean squared error of the PeNN is\nalways smaller than that of the NNs, in the order of a factor of thousand.\nFurthermore, the PeNNs capture extra and interpolation very well, contrary to\nthe NNs. It is shown that PeNNs need a much smaller data set size than the NNs\nto achieve a similar mse. Our results suggest that the incorporation of physics\ninto neural networks architectures yields promise for addressing food security.",
            "author": [
                "Marcel B. J. Meinders",
                "Jack Yang",
                "Erik van der Linden"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09035v1",
                "http://arxiv.org/pdf/2311.09035v1"
            ],
            "primary_category": "physics.soc-ph",
            "category": [
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09033v1",
            "title": "MELA: Multilingual Evaluation of Linguistic Acceptability",
            "updated": "2023-11-15T15:25:28Z",
            "published": "2023-11-15T15:25:28Z",
            "summary": "Recent benchmarks for Large Language Models (LLMs) have mostly focused on\napplication-driven tasks such as complex reasoning and code generation, and\nthis has led to a scarcity in purely linguistic evaluation of LLMs. Against\nthis background, we introduce Multilingual Evaluation of Linguistic\nAcceptability -- MELA, the first multilingual benchmark on linguistic\nacceptability with 48K samples covering 10 languages from a diverse set of\nlanguage families. We establish baselines of commonly used LLMs along with\nsupervised models, and conduct cross-lingual transfer and multi-task learning\nexperiments with XLM-R. In pursuit of multilingual interpretability, we analyze\nthe weights of fine-tuned XLM-R to explore the possibility of identifying\ntransfer difficulty between languages. Our results show that ChatGPT benefits\nmuch from in-context examples but still lags behind fine-tuned XLM-R, while the\nperformance of GPT-4 is on par with fine-tuned XLM-R even in zero-shot setting.\nCross-lingual and multi-task learning experiments show that unlike semantic\ntasks, in-language training data is crucial in acceptability judgements.\nResults in layerwise probing indicate that the upper layers of XLM-R become a\ntask-specific but language-agnostic region for multilingual acceptability\njudgment. We also introduce the concept of conflicting weight, which could be a\npotential indicator for the difficulty of cross-lingual transfer between\nlanguages. Our data will be available at https://github.com/sjtu-compling/MELA.",
            "author": [
                "Ziyin Zhang",
                "Yikang Liu",
                "Weifang Huang",
                "Junyu Mao",
                "Rui Wang",
                "Hai Hu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09033v1",
                "http://arxiv.org/pdf/2311.09033v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09030v1",
            "title": "AI-based soundscape analysis: Jointly identifying sound sources and\n  predicting annoyance",
            "updated": "2023-11-15T15:23:33Z",
            "published": "2023-11-15T15:23:33Z",
            "summary": "Soundscape studies typically attempt to capture the perception and\nunderstanding of sonic environments by surveying users. However, for long-term\nmonitoring or assessing interventions, sound-signal-based approaches are\nrequired. To this end, most previous research focused on psycho-acoustic\nquantities or automatic sound recognition. Few attempts were made to include\nappraisal (e.g., in circumplex frameworks). This paper proposes an artificial\nintelligence (AI)-based dual-branch convolutional neural network with\ncross-attention-based fusion (DCNN-CaF) to analyze automatic soundscape\ncharacterization, including sound recognition and appraisal. Using the DeLTA\ndataset containing human-annotated sound source labels and perceived annoyance,\nthe DCNN-CaF is proposed to perform sound source classification (SSC) and\nhuman-perceived annoyance rating prediction (ARP). Experimental findings\nindicate that (1) the proposed DCNN-CaF using loudness and Mel features\noutperforms the DCNN-CaF using only one of them. (2) The proposed DCNN-CaF with\ncross-attention fusion outperforms other typical AI-based models and\nsoundscape-related traditional machine learning methods on the SSC and ARP\ntasks. (3) Correlation analysis reveals that the relationship between sound\nsources and annoyance is similar for humans and the proposed AI-based DCNN-CaF\nmodel. (4) Generalization tests show that the proposed model's ARP in the\npresence of model-unknown sound sources is consistent with expert expectations\nand can explain previous findings from the literature on sound-scape\naugmentation.",
            "author": [
                "Yuanbo Hou",
                "Qiaoqiao Ren",
                "Huizhong Zhang",
                "Andrew Mitchell",
                "Francesco Aletta",
                "Jian Kang",
                "Dick Botteldooren"
            ],
            "link": [
                "http://dx.doi.org/10.1121/10.0022408",
                "http://arxiv.org/abs/2311.09030v1",
                "http://arxiv.org/pdf/2311.09030v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09029v1",
            "title": "Self-Annotated 3D Geometric Learning for Smeared Points Removal",
            "updated": "2023-11-15T15:20:24Z",
            "published": "2023-11-15T15:20:24Z",
            "summary": "There has been significant progress in improving the accuracy and quality of\nconsumer-level dense depth sensors. Nevertheless, there remains a common depth\npixel artifact which we call smeared points. These are points not on any 3D\nsurface and typically occur as interpolations between foreground and background\nobjects. As they cause fictitious surfaces, these points have the potential to\nharm applications dependent on the depth maps. Statistical outlier removal\nmethods fare poorly in removing these points as they tend also to remove actual\nsurface points. Trained network-based point removal faces difficulty in\nobtaining sufficient annotated data. To address this, we propose a fully\nself-annotated method to train a smeared point removal classifier. Our approach\nrelies on gathering 3D geometric evidence from multiple perspectives to\nautomatically detect and annotate smeared points and valid points. To validate\nthe effectiveness of our method, we present a new benchmark dataset: the Real\nAzure-Kinect dataset. Experimental results and ablation studies show that our\nmethod outperforms traditional filters and other self-annotated methods. Our\nwork is publicly available at\nhttps://github.com/wangmiaowei/wacv2024_smearedremover.git.",
            "author": [
                "Miaowei Wang",
                "Daniel Morris"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09029v1",
                "http://arxiv.org/pdf/2311.09029v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09027v1",
            "title": "Assessing the Robustness of Intelligence-Driven Reinforcement Learning",
            "updated": "2023-11-15T15:15:57Z",
            "published": "2023-11-15T15:15:57Z",
            "summary": "Robustness to noise is of utmost importance in reinforcement learning\nsystems, particularly in military contexts where high stakes and uncertain\nenvironments prevail. Noise and uncertainty are inherent features of military\noperations, arising from factors such as incomplete information, adversarial\nactions, or unpredictable battlefield conditions. In RL, noise can critically\nimpact decision-making, mission success, and the safety of personnel. Reward\nmachines offer a powerful tool to express complex reward structures in RL\ntasks, enabling the design of tailored reinforcement signals that align with\nmission objectives. This paper considers the problem of the robustness of\nintelligence-driven reinforcement learning based on reward machines. The\npreliminary results presented suggest the need for further research in\nevidential reasoning and learning to harden current state-of-the-art\nreinforcement learning approaches before being mission-critical-ready.",
            "author": [
                "Lorenzo Nodari",
                "Federico Cerutti"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09027v1",
                "http://arxiv.org/pdf/2311.09027v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09018v2",
            "title": "On the Foundation of Distributionally Robust Reinforcement Learning",
            "updated": "2023-12-04T01:39:22Z",
            "published": "2023-11-15T15:02:23Z",
            "summary": "Motivated by the need for a robust policy in the face of environment shifts\nbetween training and the deployment, we contribute to the theoretical\nfoundation of distributionally robust reinforcement learning (DRRL). This is\naccomplished through a comprehensive modeling framework centered around\ndistributionally robust Markov decision processes (DRMDPs). This framework\nobliges the decision maker to choose an optimal policy under the worst-case\ndistributional shift orchestrated by an adversary. By unifying and extending\nexisting formulations, we rigorously construct DRMDPs that embraces various\nmodeling attributes for both the decision maker and the adversary. These\nattributes include adaptability granularity, exploring history-dependent,\nMarkov, and Markov time-homogeneous decision maker and adversary dynamics.\nAdditionally, we delve into the flexibility of shifts induced by the adversary,\nexamining SA and S-rectangularity. Within this DRMDP framework, we investigate\nconditions for the existence or absence of the dynamic programming principle\n(DPP). From an algorithmic standpoint, the existence of DPP holds significant\nimplications, as the vast majority of existing data and computationally\nefficiency RL algorithms are reliant on the DPP. To study its existence, we\ncomprehensively examine combinations of controller and adversary attributes,\nproviding streamlined proofs grounded in a unified methodology. We also offer\ncounterexamples for settings in which a DPP with full generality is absent.",
            "author": [
                "Shengbo Wang",
                "Nian Si",
                "Jose Blanchet",
                "Zhengyuan Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09018v2",
                "http://arxiv.org/pdf/2311.09018v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.SY",
                "eess.SY",
                "math.OC",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09017v1",
            "title": "Semidefinite programs simulate approximate message passing robustly",
            "updated": "2023-11-15T15:00:48Z",
            "published": "2023-11-15T15:00:48Z",
            "summary": "Approximate message passing (AMP) is a family of iterative algorithms that\ngeneralize matrix power iteration. AMP algorithms are known to optimally solve\nmany average-case optimization problems. In this paper, we show that a large\nclass of AMP algorithms can be simulated in polynomial time by \\emph{local\nstatistics hierarchy} semidefinite programs (SDPs), even when an unknown\nprincipal minor of measure $1/\\mathrm{polylog}(\\mathrm{dimension})$ is\nadversarially corrupted. Ours are the first robust guarantees for many of these\nproblems. Further, our results offer an interesting counterpoint to strong\nlower bounds against less constrained SDP relaxations for average-case\nmax-cut-gain (a.k.a. \"optimizing the Sherrington-Kirkpatrick Hamiltonian\") and\nother problems.",
            "author": [
                "Misha Ivkov",
                "Tselil Schramm"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09017v1",
                "http://arxiv.org/pdf/2311.09017v1"
            ],
            "primary_category": "cs.DS",
            "category": [
                "cs.DS",
                "cs.LG",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09014v1",
            "title": "Adversarial Attacks to Reward Machine-based Reinforcement Learning",
            "updated": "2023-11-15T14:56:49Z",
            "published": "2023-11-15T14:56:49Z",
            "summary": "In recent years, Reward Machines (RMs) have stood out as a simple yet\neffective automata-based formalism for exposing and exploiting task structure\nin reinforcement learning settings. Despite their relevance, little to no\nattention has been directed to the study of their security implications and\nrobustness to adversarial scenarios, likely due to their recent appearance in\nthe literature. With my thesis, I aim to provide the first analysis of the\nsecurity of RM-based reinforcement learning techniques, with the hope of\nmotivating further research in the field, and I propose and evaluate a novel\nclass of attacks on RM-based techniques: blinding attacks.",
            "author": [
                "Lorenzo Nodari"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09014v1",
                "http://arxiv.org/pdf/2311.09014v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09012v1",
            "title": "Estimation of the chances to find new phenomena at the LHC in a\n  model-agnostic combinatorial analysis",
            "updated": "2023-11-15T14:55:41Z",
            "published": "2023-11-15T14:55:41Z",
            "summary": "In this paper, we estimate the number of event topologies that have the\npotential to be produced in $pp$ collisions at the Large Hadron Collider (LHC)\nwithout violating kinematic and other constraints. We use numeric calculations\nand combinatorics, guided by the large-scale Monte Carlo simulations of the\nStandard Model (SM) processes. Then we set the upper limit on the probability\nthat a new physics may escape the detection assuming a model-agnostic approach.\nThe calculated probability is surprisingly large, and the fact that the LHC did\nnot find a new physics up to now is not entirely surprising. We argue that the\nmost optimal direction for maximising the chances of finding new physics is to\nuse unsupervised machine learning for anomaly detection.",
            "author": [
                "S. V. Chekanov"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09012v1",
                "http://arxiv.org/pdf/2311.09012v1"
            ],
            "primary_category": "hep-ph",
            "category": [
                "hep-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09006v1",
            "title": "Data Similarity is Not Enough to Explain Language Model Performance",
            "updated": "2023-11-15T14:48:08Z",
            "published": "2023-11-15T14:48:08Z",
            "summary": "Large language models achieve high performance on many but not all downstream\ntasks. The interaction between pretraining data and task data is commonly\nassumed to determine this variance: a task with data that is more similar to a\nmodel's pretraining data is assumed to be easier for that model. We test\nwhether distributional and example-specific similarity measures (embedding-,\ntoken- and model-based) correlate with language model performance through a\nlarge-scale comparison of the Pile and C4 pretraining datasets with downstream\nbenchmarks. Similarity correlates with performance for multilingual datasets,\nbut in other benchmarks, we surprisingly find that similarity metrics are not\ncorrelated with accuracy or even each other. This suggests that the\nrelationship between pretraining data and downstream tasks is more complex than\noften assumed.",
            "author": [
                "Gregory Yauney",
                "Emily Reif",
                "David Mimno"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09006v1",
                "http://arxiv.org/pdf/2311.09006v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09003v1",
            "title": "Taming under isoperimetry",
            "updated": "2023-11-15T14:44:16Z",
            "published": "2023-11-15T14:44:16Z",
            "summary": "In this article we propose a novel taming Langevin-based scheme called\n$\\mathbf{sTULA}$ to sample from distributions with superlinearly growing\nlog-gradient which also satisfy a Log-Sobolev inequality. We derive\nnon-asymptotic convergence bounds in $KL$ and consequently total variation and\nWasserstein-$2$ distance from the target measure. Non-asymptotic convergence\nguarantees are provided for the performance of the new algorithm as an\noptimizer. Finally, some theoretical results on isoperimertic inequalities for\ndistributions with superlinearly growing gradients are provided. Key findings\nare a Log-Sobolev inequality with constant independent of the dimension, in the\npresence of a higher order regularization and a Poincare inequality with\nconstant independent of temperature and dimension under a novel non-convex\ntheoretical framework.",
            "author": [
                "Iosif Lytras",
                "Sotirios Sabanis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09003v1",
                "http://arxiv.org/pdf/2311.09003v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "cs.NA",
                "math.NA",
                "math.OC",
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08995v1",
            "title": "Simple but Effective Unsupervised Classification for Specified Domain\n  Images: A Case Study on Fungi Images",
            "updated": "2023-11-15T14:33:22Z",
            "published": "2023-11-15T14:33:22Z",
            "summary": "High-quality labeled datasets are essential for deep learning. Traditional\nmanual annotation methods are not only costly and inefficient but also pose\nchallenges in specialized domains where expert knowledge is needed.\nSelf-supervised methods, despite leveraging unlabeled data for feature\nextraction, still require hundreds or thousands of labeled instances to guide\nthe model for effective specialized image classification. Current unsupervised\nlearning methods offer automatic classification without prior annotation but\noften compromise on accuracy. As a result, efficiently procuring high-quality\nlabeled datasets remains a pressing challenge for specialized domain images\ndevoid of annotated data. Addressing this, an unsupervised classification\nmethod with three key ideas is introduced: 1) dual-step feature dimensionality\nreduction using a pre-trained model and manifold learning, 2) a voting\nmechanism from multiple clustering algorithms, and 3) post-hoc instead of prior\nmanual annotation. This approach outperforms supervised methods in\nclassification accuracy, as demonstrated with fungal image data, achieving\n94.1% and 96.7% on public and private datasets respectively. The proposed\nunsupervised classification method reduces dependency on pre-annotated\ndatasets, enabling a closed-loop for data classification. The simplicity and\nease of use of this method will also bring convenience to researchers in\nvarious fields in building datasets, promoting AI applications for images in\nspecialized domains.",
            "author": [
                "Zhaocong liu",
                "Fa Zhang",
                "Lin Cheng",
                "Huanxi Deng",
                "Xiaoyan Yang",
                "Zhenyu Zhang",
                "Chichun Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08995v1",
                "http://arxiv.org/pdf/2311.08995v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08993v1",
            "title": "When does In-context Learning Fall Short and Why? A Study on\n  Specification-Heavy Tasks",
            "updated": "2023-11-15T14:26:30Z",
            "published": "2023-11-15T14:26:30Z",
            "summary": "In-context learning (ICL) has become the default method for using large\nlanguage models (LLMs), making the exploration of its limitations and\nunderstanding the underlying causes crucial. In this paper, we find that ICL\nfalls short of handling specification-heavy tasks, which are tasks with\ncomplicated and extensive task specifications, requiring several hours for\nordinary humans to master, such as traditional information extraction tasks.\nThe performance of ICL on these tasks mostly cannot reach half of the\nstate-of-the-art results. To explore the reasons behind this failure, we\nconduct comprehensive experiments on 18 specification-heavy tasks with various\nLLMs and identify three primary reasons: inability to specifically understand\ncontext, misalignment in task schema comprehension with humans, and inadequate\nlong-text understanding ability. Furthermore, we demonstrate that through\nfine-tuning, LLMs can achieve decent performance on these tasks, indicating\nthat the failure of ICL is not an inherent flaw of LLMs, but rather a drawback\nof existing alignment methods that renders LLMs incapable of handling\ncomplicated specification-heavy tasks via ICL. To substantiate this, we perform\ndedicated instruction tuning on LLMs for these tasks and observe a notable\nimprovement. We hope the analyses in this paper could facilitate advancements\nin alignment methods enabling LLMs to meet more sophisticated human demands.",
            "author": [
                "Hao Peng",
                "Xiaozhi Wang",
                "Jianhui Chen",
                "Weikai Li",
                "Yunjia Qi",
                "Zimu Wang",
                "Zhili Wu",
                "Kaisheng Zeng",
                "Bin Xu",
                "Lei Hou",
                "Juanzi Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08993v1",
                "http://arxiv.org/pdf/2311.08993v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08990v1",
            "title": "sQUlearn $\\unicode{x2013}$ A Python Library for Quantum Machine Learning",
            "updated": "2023-11-15T14:22:53Z",
            "published": "2023-11-15T14:22:53Z",
            "summary": "sQUlearn introduces a user-friendly, NISQ-ready Python library for quantum\nmachine learning (QML), designed for seamless integration with classical\nmachine learning tools like scikit-learn. The library's dual-layer architecture\nserves both QML researchers and practitioners, enabling efficient prototyping,\nexperimentation, and pipelining. sQUlearn provides a comprehensive toolset that\nincludes both quantum kernel methods and quantum neural networks, along with\nfeatures like customizable data encoding strategies, automated execution\nhandling, and specialized kernel regularization techniques. By focusing on\nNISQ-compatibility and end-to-end automation, sQUlearn aims to bridge the gap\nbetween current quantum computing capabilities and practical machine learning\napplications.",
            "author": [
                "David A. Kreplin",
                "Moritz Willmann",
                "Jan Schnabel",
                "Frederic Rapp",
                "Marco Roth"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08990v1",
                "http://arxiv.org/pdf/2311.08990v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08979v1",
            "title": "A Multimodal Dataset of 21,412 Recorded Nights for Sleep and Respiratory\n  Research",
            "updated": "2023-11-15T14:14:26Z",
            "published": "2023-11-15T14:14:26Z",
            "summary": "This study introduces a novel, rich dataset obtained from home sleep apnea\ntests using the FDA-approved WatchPAT-300 device, collected from 7,077\nparticipants over 21,412 nights. The dataset comprises three levels of sleep\ndata: raw multi-channel time-series from sensors, annotated sleep events, and\ncomputed summary statistics, which include 447 features related to sleep\narchitecture, sleep apnea, and heart rate variability (HRV). We present\nreference values for Apnea/Hypopnea Index (AHI), sleep efficiency, Wake After\nSleep Onset (WASO), and HRV sample entropy, stratified by age and sex.\nMoreover, we demonstrate that the dataset improves the predictive capability\nfor various health related traits, including body composition, bone density,\nblood sugar levels and cardiovascular health. These results illustrate the\ndataset's potential to advance sleep research, personalized healthcare, and\nmachine learning applications in biomedicine.",
            "author": [
                "Alon Diament",
                "Maria Gorodetski",
                "Adam Jankelow",
                "Ayya Keshet",
                "Tal Shor",
                "Daphna Weissglas-Volkov",
                "Hagai Rossman",
                "Eran Segal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08979v1",
                "http://arxiv.org/pdf/2311.08979v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09272v1",
            "title": "Linear time Evidence Accumulation Clustering with KMeans",
            "updated": "2023-11-15T14:12:59Z",
            "published": "2023-11-15T14:12:59Z",
            "summary": "Among ensemble clustering methods, Evidence Accumulation Clustering is one of\nthe simplest technics. In this approach, a co-association (CA) matrix\nrepresenting the co-clustering frequency is built and then clustered to extract\nconsensus clusters. Compared to other approaches, this one is simple as there\nis no need to find matches between clusters obtained from two different\npartitionings. Nevertheless, this method suffers from computational issues, as\nit requires to compute and store a matrix of size n x n, where n is the number\nof items. Due to the quadratic cost, this approach is reserved for small\ndatasets. This work describes a trick which mimic the behavior of average\nlinkage clustering. We found a way of computing efficiently the density of a\npartitioning, reducing the cost from a quadratic to linear complexity.\nAdditionally, we proved that the k-means maximizes naturally the density. We\nperformed experiments on several benchmark datasets where we compared the\nk-means and the bisecting version to other state-of-the-art consensus\nalgorithms. The k-means results are comparable to the best state of the art in\nterms of NMI while keeping the computational cost low. Additionally, the\nk-means led to the best results in terms of density. These results provide\nevidence that consensus clustering can be solved with simple algorithms.",
            "author": [
                "Ga\u00eblle Candel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09272v1",
                "http://arxiv.org/pdf/2311.09272v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "68T20",
                "I.2.m"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08978v1",
            "title": "Probability of Collision of satellites and space debris for short-term\n  encounters: Rederivation and fast-to-compute upper and lower bounds",
            "updated": "2023-11-15T14:12:55Z",
            "published": "2023-11-15T14:12:55Z",
            "summary": "The proliferation of space debris in LEO has become a major concern for the\nspace industry. With the growing interest in space exploration, the prediction\nof potential collisions between objects in orbit has become a crucial issue. It\nis estimated that, in orbit, there are millions of fragments a few millimeters\nin size and thousands of inoperative satellites and discarded rocket stages.\nGiven the high speeds that these fragments can reach, even fragments a few\nmillimeters in size can cause fractures in a satellite's hull or put a serious\ncrack in the window of a space shuttle. The conventional method proposed by\nAkella and Alfriend in 2000 remains widely used to estimate the probability of\ncollision in short-term encounters. Given the small period of time, it is\nassumed that, during the encounter: (1) trajectories are represented by\nstraight lines with constant velocity; (2) there is no velocity uncertainty and\nthe position exhibits a stationary distribution throughout the encounter; and\n(3) position uncertainties are independent and represented by Gaussian\ndistributions. This study introduces a novel derivation based on first\nprinciples that naturally allows for tight and fast upper and lower bounds for\nthe probability of collision. We tested implementations of both probability and\nbound computations with the original and our formulation on a real CDM dataset\nused in ESA's Collision Avoidance Challenge. Our approach reduces the\ncalculation of the probability to two one-dimensional integrals and has the\npotential to significantly reduce the processing time compared to the\ntraditional method, from 80% to nearly real-time.",
            "author": [
                "Ricardo Ferreira",
                "Cl\u00e1udia Soares",
                "Marta Guimar\u00e3es"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08978v1",
                "http://arxiv.org/pdf/2311.08978v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08972v2",
            "title": "Unsupervised approaches based on optimal transport and convex analysis\n  for inverse problems in imaging",
            "updated": "2023-11-29T09:57:06Z",
            "published": "2023-11-15T14:04:37Z",
            "summary": "Unsupervised deep learning approaches have recently become one of the crucial\nresearch areas in imaging owing to their ability to learn expressive and\npowerful reconstruction operators even when paired high-quality training data\nis scarcely available. In this chapter, we review theoretically principled\nunsupervised learning schemes for solving imaging inverse problems, with a\nparticular focus on methods rooted in optimal transport and convex analysis. We\nbegin by reviewing the optimal transport-based unsupervised approaches such as\nthe cycle-consistency-based models and learned adversarial regularization\nmethods, which have clear probabilistic interpretations. Subsequently, we give\nan overview of a recent line of works on provably convergent learned\noptimization algorithms applied to accelerate the solution of imaging inverse\nproblems, alongside their dedicated unsupervised training schemes. We also\nsurvey a number of provably convergent plug-and-play algorithms (based on\ngradient-step deep denoisers), which are among the most important and widely\napplied unsupervised approaches for imaging problems. At the end of this\nsurvey, we provide an overview of a few related unsupervised learning\nframeworks that complement our focused schemes. Together with a detailed\nsurvey, we provide an overview of the key mathematical results that underlie\nthe methods reviewed in the chapter to keep our discussion self-contained.",
            "author": [
                "Marcello Carioni",
                "Subhadip Mukherjee",
                "Hong Ye Tan",
                "Junqi Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08972v2",
                "http://arxiv.org/pdf/2311.08972v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08951v1",
            "title": "Corrections to \"Universal Densities Exist for Every Finite Reference\n  Measure\"",
            "updated": "2023-11-15T13:37:59Z",
            "published": "2023-11-15T13:37:59Z",
            "summary": "In the article \"Universal Densities Exist for Every Finite Reference Measure\"\n(IEEE Trans. Inform. Theory, vol. 69, no. 8, pp. 5277--5288, 2023) we neglected\nto mention relevant contributions of Boris Ryabko. We cited a source by him\nthat contains a construction of the universal density that we claimed to be our\nown invention without checking the source after drafting the article. Our\narticle was motivated by a preprint by Feutrill and Roughan, about which we had\nlearned when reviewing the PhD thesis by Andrew Feutrill. Whereas we were not\nallowed to contact Feutrill and Roughan besides the review form, we developed\nsome ideas of theirs further, ignoring that we stepped into the area previously\nresearched by Ryabko. Our published results exceed those by Ryabko but the\narticle should have been refocused to report Ryabko's contributions. In this\nnote, we detail our citation mistakes.",
            "author": [
                "\u0141ukasz D\u0119bowski"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08951v1",
                "http://arxiv.org/pdf/2311.08951v1"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "math.IT",
                "94A29, 62M20"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08949v1",
            "title": "Automated Volume Corrected Mitotic Index Calculation Through\n  Annotation-Free Deep Learning using Immunohistochemistry as Reference\n  Standard",
            "updated": "2023-11-15T13:35:40Z",
            "published": "2023-11-15T13:35:40Z",
            "summary": "The volume-corrected mitotic index (M/V-Index) was shown to provide\nprognostic value in invasive breast carcinomas. However, despite its prognostic\nsignificance, it is not established as the standard method for assessing\naggressive biological behaviour, due to the high additional workload associated\nwith determining the epithelial proportion. In this work, we show that using a\ndeep learning pipeline solely trained with an annotation-free,\nimmunohistochemistry-based approach, provides accurate estimations of\nepithelial segmentation in canine breast carcinomas. We compare our automatic\nframework with the manually annotated M/V-Index in a study with three\nboard-certified pathologists. Our results indicate that the deep learning-based\npipeline shows expert-level performance, while providing time efficiency and\nreproducibility.",
            "author": [
                "Jonas Ammeling",
                "Moritz Hecker",
                "Jonathan Ganz",
                "Taryn A. Donovan",
                "Christof A. Bertram",
                "Katharina Breininger",
                "Marc Aubreville"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08949v1",
                "http://arxiv.org/pdf/2311.08949v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08945v1",
            "title": "A Single-Loop Algorithm for Decentralized Bilevel Optimization",
            "updated": "2023-11-15T13:29:49Z",
            "published": "2023-11-15T13:29:49Z",
            "summary": "Bilevel optimization has received more and more attention recently due to its\nwide applications in machine learning. In this paper, we consider bilevel\noptimization in decentralized networks. In particular, we propose a novel\nsingle-loop algorithm for solving decentralized bilevel optimization with\nstrongly convex lower level problem. Our algorithm is fully single-loop and\ndoes not require heavy matrix-vector multiplications when approximating the\nhypergradient. Moreover, unlike existing methods for decentralized bilevel\noptimization and federated bilevel optimization, our algorithm does not require\nany gradient heterogeneity assumption. Our analysis shows that the proposed\nalgorithm achieves the best known convergence rate for bilevel optimization\nalgorithms.",
            "author": [
                "Youran Dong",
                "Shiqian Ma",
                "Junfeng Yang",
                "Chao Yin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08945v1",
                "http://arxiv.org/pdf/2311.08945v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.DC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08944v1",
            "title": "Stellar Atmospheric Parameters for Cool Dwarfs in Gaia DR3",
            "updated": "2023-11-15T13:29:05Z",
            "published": "2023-11-15T13:29:05Z",
            "summary": "We provide a catalogue of atmospheric parameters for 1,806,921 cool dwarfs\nfrom Gaia DR3 which lie within the range covered by LAMOST cool dwarf\nspectroscopic parameters: 3200 K < T_{eff}< 4300 K, -0.8 < [M/H] < 0.2 dex, and\n4.5 <log{g} < 5.5 dex. Our values are derived based on Machine Learning models\ntrained with multi-band photometry corrected for dust. The photometric data\ncomprises of optical from SDSS r, i, z bands, near-infrared from 2MASS J, H, K\nand mid-infrared from ALLWISE W1, W2. We used both random forest and LightGBM\nmachine learning models and found similar results from both with an error\ndispersion of 68 K, 0.22 dex, and 0.05 dex for T_{eff}, [M/H], and log {g},\nrespectively. Assessment of the relative feature importance of different\nphotometric colors indicated W1 -- W2 as most sensitive to both T_{eff} and\nlog{g}, with J -- H most sensitive to [M/H]. We find that our values show a\ngood agreement with APOGEE, but are significantly different to those provided\nas part of Gaia DR3.",
            "author": [
                "Cai-Xia Qu",
                "A-Li Luo",
                "Rui Wang",
                "Hugh R. A. Jones",
                "Bing Du",
                "Xiang-Lei Chen",
                "You-Fen Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08944v1",
                "http://arxiv.org/pdf/2311.08944v1"
            ],
            "primary_category": "astro-ph.SR",
            "category": [
                "astro-ph.SR",
                "astro-ph.EP",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08936v2",
            "title": "Confident Naturalness Explanation (CNE): A Framework to Explain and\n  Assess Patterns Forming Naturalness",
            "updated": "2023-11-22T14:25:55Z",
            "published": "2023-11-15T13:19:02Z",
            "summary": "Protected natural areas are regions that have been minimally affected by\nhuman activities such as urbanization, agriculture, and other human\ninterventions. To better understand and map the naturalness of these areas,\nmachine learning models can be used to analyze satellite imagery. Specifically,\nexplainable machine learning methods show promise in uncovering patterns that\ncontribute to the concept of naturalness within these protected environments.\nAdditionally, addressing the uncertainty inherent in machine learning models is\ncrucial for a comprehensive understanding of this concept. However, existing\napproaches have limitations. They either fail to provide explanations that are\nboth valid and objective or struggle to offer a quantitative metric that\naccurately measures the contribution of specific patterns to naturalness, along\nwith the associated confidence. In this paper, we propose a novel framework\ncalled the Confident Naturalness Explanation (CNE) framework. This framework\ncombines explainable machine learning and uncertainty quantification to assess\nand explain naturalness. We introduce a new quantitative metric that describes\nthe confident contribution of patterns to the concept of naturalness.\nFurthermore, we generate an uncertainty-aware segmentation mask for each input\nsample, highlighting areas where the model lacks knowledge. To demonstrate the\neffectiveness of our framework, we apply it to a study site in Fennoscandia\nusing two open-source satellite datasets.",
            "author": [
                "Ahmed Emam",
                "Mohamed Farag",
                "Ribana Roscher"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08936v2",
                "http://arxiv.org/pdf/2311.08936v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08935v1",
            "title": "Supported Trust Region Optimization for Offline Reinforcement Learning",
            "updated": "2023-11-15T13:16:16Z",
            "published": "2023-11-15T13:16:16Z",
            "summary": "Offline reinforcement learning suffers from the out-of-distribution issue and\nextrapolation error. Most policy constraint methods regularize the density of\nthe trained policy towards the behavior policy, which is too restrictive in\nmost cases. We propose Supported Trust Region optimization (STR) which performs\ntrust region policy optimization with the policy constrained within the support\nof the behavior policy, enjoying the less restrictive support constraint. We\nshow that, when assuming no approximation and sampling error, STR guarantees\nstrict policy improvement until convergence to the optimal support-constrained\npolicy in the dataset. Further with both errors incorporated, STR still\nguarantees safe policy improvement for each step. Empirical results validate\nthe theory of STR and demonstrate its state-of-the-art performance on MuJoCo\nlocomotion domains and much more challenging AntMaze domains.",
            "author": [
                "Yixiu Mao",
                "Hongchang Zhang",
                "Chen Chen",
                "Yi Xu",
                "Xiangyang Ji"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08935v1",
                "http://arxiv.org/pdf/2311.08935v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08933v1",
            "title": "Design and Implementation of a Hybrid Wireless Power and Communication\n  System for Medical Implants",
            "updated": "2023-11-15T13:15:19Z",
            "published": "2023-11-15T13:15:19Z",
            "summary": "Data collection and analysis from multiple implant nodes in humans can\nprovide targeted medicine and treatment strategies that can prevent many\nchronic diseases. This data can be collected for a long time and processed\nusing artificial intelligence (AI) techniques in a medical network for early\ndetection and prevention of diseases. Additionally, machine learning (ML)\nalgorithms can be applied for the analysis of big data for health monitoring of\nthe population. Wireless powering, sensing, and communication are essential\nparts of future wireless implants that aim to achieve the aforementioned goals.\nIn this paper, we present the technical development of a wireless implant that\nis powered by radio frequency (RF) at 401 MHz, with the sensor data being\ncommunicated to an on-body reader. The implant communication is based on two\nsimultaneous wireless links: RF backscatter for implant-to-on-body\ncommunication and a galvanic link for intra-body implant-to-implant\nconnectivity. It is demonstrated that RF powering, using the proposed compact\nantennas, can provide an efficient and integrable system for powering up to an\n8 cm depth inside body tissues. Furthermore, the same antennas are utilized for\nbackscatter and galvanic communication.",
            "author": [
                "A. Khaleghi",
                "A. Hasanvand",
                "I. Balasingham"
            ],
            "link": [
                "http://dx.doi.org/10.1109/IMBioC56839.2023.10305096",
                "http://arxiv.org/abs/2311.08933v1",
                "http://arxiv.org/pdf/2311.08933v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08931v1",
            "title": "Structural-Based Uncertainty in Deep Learning Across Anatomical Scales:\n  Analysis in White Matter Lesion Segmentation",
            "updated": "2023-11-15T13:04:57Z",
            "published": "2023-11-15T13:04:57Z",
            "summary": "This paper explores uncertainty quantification (UQ) as an indicator of the\ntrustworthiness of automated deep-learning (DL) tools in the context of white\nmatter lesion (WML) segmentation from magnetic resonance imaging (MRI) scans of\nmultiple sclerosis (MS) patients. Our study focuses on two principal aspects of\nuncertainty in structured output segmentation tasks. Firstly, we postulate that\na good uncertainty measure should indicate predictions likely to be incorrect\nwith high uncertainty values. Second, we investigate the merit of quantifying\nuncertainty at different anatomical scales (voxel, lesion, or patient). We\nhypothesize that uncertainty at each scale is related to specific types of\nerrors. Our study aims to confirm this relationship by conducting separate\nanalyses for in-domain and out-of-domain settings. Our primary methodological\ncontributions are (i) the development of novel measures for quantifying\nuncertainty at lesion and patient scales, derived from structural prediction\ndiscrepancies, and (ii) the extension of an error retention curve analysis\nframework to facilitate the evaluation of UQ performance at both lesion and\npatient scales. The results from a multi-centric MRI dataset of 172 patients\ndemonstrate that our proposed measures more effectively capture model errors at\nthe lesion and patient scales compared to measures that average voxel-scale\nuncertainty values. We provide the UQ protocols code at\nhttps://github.com/Medical-Image-Analysis-Laboratory/MS_WML_uncs.",
            "author": [
                "Nataliia Molchanova",
                "Vatsal Raina",
                "Andrey Malinin",
                "Francesco La Rosa",
                "Adrien Depeursinge",
                "Mark Gales",
                "Cristina Granziera",
                "Henning Muller",
                "Mara Graziani",
                "Meritxell Bach Cuadra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08931v1",
                "http://arxiv.org/pdf/2311.08931v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10108v1",
            "title": "Study of topological quantities of lattice QCD by a modified Wasserstein\n  generative adversarial network",
            "updated": "2023-11-15T12:52:42Z",
            "published": "2023-11-15T12:52:42Z",
            "summary": "A modified Wasserstein generative adversarial network (M-WGAN) is proposed to\nstudy the distribution of the topological charge in lattice QCD based on the\nMonte Carlo (MC) simulations. We construct new generator and discriminator in\nM-WGAN to support the generation of high-quality distribution. Our results show\nthat the M-WGAN scheme of the Machine learning should be helpful for us to\ncalculate efficiently the 1D distribution of topological charge compared with\nthe results by the MC simulation alone.",
            "author": [
                "Lin Gao",
                "Zhen Cheng",
                "Heping Ying",
                "Jianbo Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10108v1",
                "http://arxiv.org/pdf/2311.10108v1"
            ],
            "primary_category": "hep-lat",
            "category": [
                "hep-lat"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08921v1",
            "title": "Self-Improving for Zero-Shot Named Entity Recognition with Large\n  Language Models",
            "updated": "2023-11-15T12:47:52Z",
            "published": "2023-11-15T12:47:52Z",
            "summary": "Exploring the application of powerful large language models (LLMs) on the\nfundamental named entity recognition (NER) task has drawn much attention\nrecently. This work aims to investigate the possibilities of pushing the\nboundary of zero-shot NER with LLM via a training-free self-improving strategy.\nWe propose a self-improving framework, which utilize an unlabeled corpus to\nstimulate the self-learning ability of LLMs on NER. First, we use LLM to make\npredictions on the unlabeled corpus and obtain the self-annotated data. Second,\nwe explore various strategies to select reliable samples from the\nself-annotated dataset as demonstrations, considering the similarity, diversity\nand reliability of demonstrations. Finally, we conduct inference for the test\nquery via in-context learning with the selected self-annotated demonstrations.\nThrough comprehensive experimental analysis, our study yielded the following\nfindings: (1) The self-improving framework further pushes the boundary of\nzero-shot NER with LLMs, and achieves an obvious performance improvement; (2)\nIterative self-improving or naively increasing the size of unlabeled corpus\ndoes not guarantee improvements; (3) There might still be space for improvement\nvia more advanced strategy for reliable entity selection.",
            "author": [
                "Tingyu Xie",
                "Qi Li",
                "Yan Zhang",
                "Zuozhu Liu",
                "Hongwei Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08921v1",
                "http://arxiv.org/pdf/2311.08921v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08914v1",
            "title": "Efficiently Escaping Saddle Points for Non-Convex Policy Optimization",
            "updated": "2023-11-15T12:36:45Z",
            "published": "2023-11-15T12:36:45Z",
            "summary": "Policy gradient (PG) is widely used in reinforcement learning due to its\nscalability and good performance. In recent years, several variance-reduced PG\nmethods have been proposed with a theoretical guarantee of converging to an\napproximate first-order stationary point (FOSP) with the sample complexity of\n$O(\\epsilon^{-3})$. However, FOSPs could be bad local optima or saddle points.\nMoreover, these algorithms often use importance sampling (IS) weights which\ncould impair the statistical effectiveness of variance reduction. In this\npaper, we propose a variance-reduced second-order method that uses second-order\ninformation in the form of Hessian vector products (HVP) and converges to an\napproximate second-order stationary point (SOSP) with sample complexity of\n$\\tilde{O}(\\epsilon^{-3})$. This rate improves the best-known sample complexity\nfor achieving approximate SOSPs by a factor of $O(\\epsilon^{-0.5})$. Moreover,\nthe proposed variance reduction technique bypasses IS weights by using HVP\nterms. Our experimental results show that the proposed algorithm outperforms\nthe state of the art and is more robust to changes in random seeds.",
            "author": [
                "Sadegh Khorasani",
                "Saber Salehkaleybar",
                "Negar Kiyavash",
                "Niao He",
                "Matthias Grossglauser"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08914v1",
                "http://arxiv.org/pdf/2311.08914v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC",
                "ACM-class:I.2.6"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08909v1",
            "title": "DLAS: An Exploration and Assessment of the Deep Learning Acceleration\n  Stack",
            "updated": "2023-11-15T12:26:31Z",
            "published": "2023-11-15T12:26:31Z",
            "summary": "Deep Neural Networks (DNNs) are extremely computationally demanding, which\npresents a large barrier to their deployment on resource-constrained devices.\nSince such devices are where many emerging deep learning applications lie\n(e.g., drones, vision-based medical technology), significant bodies of work\nfrom both the machine learning and systems communities have attempted to\nprovide optimizations to accelerate DNNs. To help unify these two perspectives,\nin this paper we combine machine learning and systems techniques within the\nDeep Learning Acceleration Stack (DLAS), and demonstrate how these layers can\nbe tightly dependent on each other with an across-stack perturbation study. We\nevaluate the impact on accuracy and inference time when varying different\nparameters of DLAS across two datasets, seven popular DNN architectures, four\nDNN compression techniques, three algorithmic primitives with sparse and dense\nvariants, untuned and auto-scheduled code generation, and four hardware\nplatforms. Our evaluation highlights how perturbations across DLAS parameters\ncan cause significant variation and across-stack interactions. The highest\nlevel observation from our evaluation is that the model size, accuracy, and\ninference time are not guaranteed to be correlated. Overall we make 13 key\nobservations, including that speedups provided by compression techniques are\nvery hardware dependent, and that compiler auto-tuning can significantly alter\nwhat the best algorithm to use for a given configuration is. With DLAS, we aim\nto provide a reference framework to aid machine learning and systems\npractitioners in reasoning about the context in which their respective DNN\nacceleration solutions exist in. With our evaluation strongly motivating the\nneed for co-design, we believe that DLAS can be a valuable concept for\nexploring the next generation of co-designed accelerated deep learning\nsolutions.",
            "author": [
                "Perry Gibson",
                "Jos\u00e9 Cano",
                "Elliot J. Crowley",
                "Amos Storkey",
                "Michael O'Boyle"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08909v1",
                "http://arxiv.org/pdf/2311.08909v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "cs.PF"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08908v1",
            "title": "Robust Brain MRI Image Classification with SIBOW-SVM",
            "updated": "2023-11-15T12:26:24Z",
            "published": "2023-11-15T12:26:24Z",
            "summary": "The majority of primary Central Nervous System (CNS) tumors in the brain are\namong the most aggressive diseases affecting humans. Early detection of brain\ntumor types, whether benign or malignant, glial or non-glial, is critical for\ncancer prevention and treatment, ultimately improving human life expectancy.\nMagnetic Resonance Imaging (MRI) stands as the most effective technique to\ndetect brain tumors by generating comprehensive brain images through scans.\nHowever, human examination can be error-prone and inefficient due to the\ncomplexity, size, and location variability of brain tumors. Recently, automated\nclassification techniques using machine learning (ML) methods, such as\nConvolutional Neural Network (CNN), have demonstrated significantly higher\naccuracy than manual screening, while maintaining low computational costs.\nNonetheless, deep learning-based image classification methods, including CNN,\nface challenges in estimating class probabilities without proper model\ncalibration. In this paper, we propose a novel brain tumor image classification\nmethod, called SIBOW-SVM, which integrates the Bag-of-Features (BoF) model with\nSIFT feature extraction and weighted Support Vector Machines (wSVMs). This new\napproach effectively captures hidden image features, enabling the\ndifferentiation of various tumor types and accurate label predictions.\nAdditionally, the SIBOW-SVM is able to estimate the probabilities of images\nbelonging to each class, thereby providing high-confidence classification\ndecisions. We have also developed scalable and parallelable algorithms to\nfacilitate the practical implementation of SIBOW-SVM for massive images. As a\nbenchmark, we apply the SIBOW-SVM to a public data set of brain tumor MRI\nimages containing four classes: glioma, meningioma, pituitary, and normal. Our\nresults show that the new method outperforms state-of-the-art methods,\nincluding CNN.",
            "author": [
                "Liyun Zeng",
                "Hao Helen Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08908v1",
                "http://arxiv.org/pdf/2311.08908v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08902v1",
            "title": "On the Importance of Step-wise Embeddings for Heterogeneous Clinical\n  Time-Series",
            "updated": "2023-11-15T12:18:15Z",
            "published": "2023-11-15T12:18:15Z",
            "summary": "Recent advances in deep learning architectures for sequence modeling have not\nfully transferred to tasks handling time-series from electronic health records.\nIn particular, in problems related to the Intensive Care Unit (ICU), the\nstate-of-the-art remains to tackle sequence classification in a tabular manner\nwith tree-based methods. Recent findings in deep learning for tabular data are\nnow surpassing these classical methods by better handling the severe\nheterogeneity of data input features. Given the similar level of feature\nheterogeneity exhibited by ICU time-series and motivated by these findings, we\nexplore these novel methods' impact on clinical sequence modeling tasks. By\njointly using such advances in deep learning for tabular data, our primary\nobjective is to underscore the importance of step-wise embeddings in\ntime-series modeling, which remain unexplored in machine learning methods for\nclinical data. On a variety of clinically relevant tasks from two large-scale\nICU datasets, MIMIC-III and HiRID, our work provides an exhaustive analysis of\nstate-of-the-art methods for tabular time-series as time-step embedding models,\nshowing overall performance improvement. In particular, we evidence the\nimportance of feature grouping in clinical time-series, with significant\nperformance gains when considering features within predefined semantic groups\nin the step-wise embedding module.",
            "author": [
                "Rita Kuznetsova",
                "Aliz\u00e9e Pace",
                "Manuel Burger",
                "Hugo Y\u00e8che",
                "Gunnar R\u00e4tsch"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08902v1",
                "http://arxiv.org/pdf/2311.08902v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09270v1",
            "title": "FedCode: Communication-Efficient Federated Learning via Transferring\n  Codebooks",
            "updated": "2023-11-15T12:06:32Z",
            "published": "2023-11-15T12:06:32Z",
            "summary": "Federated Learning (FL) is a distributed machine learning paradigm that\nenables learning models from decentralized local data. While FL offers\nappealing properties for clients' data privacy, it imposes high communication\nburdens for exchanging model weights between a server and the clients. Existing\napproaches rely on model compression techniques, such as pruning and weight\nclustering to tackle this. However, transmitting the entire set of weight\nupdates at each federated round, even in a compressed format, limits the\npotential for a substantial reduction in communication volume. We propose\nFedCode where clients transmit only codebooks, i.e., the cluster centers of\nupdated model weight values. To ensure a smooth learning curve and proper\ncalibration of clusters between the server and the clients, FedCode\nperiodically transfers model weights after multiple rounds of solely\ncommunicating codebooks. This results in a significant reduction in\ncommunication volume between clients and the server in both directions, without\nimposing significant computational overhead on the clients or leading to major\nperformance degradation of the models. We evaluate the effectiveness of FedCode\nusing various publicly available datasets with ResNet-20 and MobileNet backbone\nmodel architectures. Our evaluations demonstrate a 12.2-fold data transmission\nreduction on average while maintaining a comparable model performance with an\naverage accuracy loss of 1.3% compared to FedAvg. Further validation of FedCode\nperformance under non-IID data distributions showcased an average accuracy loss\nof 2.0% compared to FedAvg while achieving approximately a 12.7-fold data\ntransmission reduction.",
            "author": [
                "Saeed Khalilian",
                "Vasileios Tsouvalas",
                "Tanir Ozcelebi",
                "Nirvana Meratnia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09270v1",
                "http://arxiv.org/pdf/2311.09270v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09269v1",
            "title": "NormNet: Scale Normalization for 6D Pose Estimation in Stacked Scenarios",
            "updated": "2023-11-15T12:02:57Z",
            "published": "2023-11-15T12:02:57Z",
            "summary": "Existing Object Pose Estimation (OPE) methods for stacked scenarios are not\nrobust to changes in object scale. This paper proposes a new 6DoF OPE network\n(NormNet) for different scale objects in stacked scenarios. Specifically, each\nobject's scale is first learned with point-wise regression. Then, all objects\nin the stacked scenario are normalized into the same scale through semantic\nsegmentation and affine transformation. Finally, they are fed into a shared\npose estimator to recover their 6D poses. In addition, we introduce a new\nSim-to-Real transfer pipeline, combining style transfer and domain\nrandomization. This improves the NormNet's performance on real data even if we\nonly train it on synthetic data. Extensive experiments demonstrate that the\nproposed method achieves state-of-the-art performance on public benchmarks and\nthe MultiScale dataset we constructed. The real-world experiments show that our\nmethod can robustly estimate the 6D pose of objects at different scales.",
            "author": [
                "En-Te Lin",
                "Wei-Jie Lv",
                "Ding-Tao Huang",
                "Long Zeng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09269v1",
                "http://arxiv.org/pdf/2311.09269v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08894v1",
            "title": "Combining Transfer Learning with In-context Learning using Blackbox LLMs\n  for Zero-shot Knowledge Base Question Answering",
            "updated": "2023-11-15T11:56:56Z",
            "published": "2023-11-15T11:56:56Z",
            "summary": "We address the zero-shot transfer learning setting for the knowledge base\nquestion answering (KBQA) problem, where a large volume of labeled training\ndata is available for the source domain, but no such labeled examples are\navailable for the target domain. Transfer learning for KBQA makes use of large\nvolumes of unlabeled data in the target in addition to the labeled data in the\nsource. More recently, few-shot in-context learning using Black-box Large\nLanguage Models (BLLMs) has been adapted for KBQA without considering any\nsource domain data. In this work, we show how to meaningfully combine these two\nparadigms for KBQA so that their benefits add up. Specifically, we preserve the\ntwo stage retrieve-then-generate pipeline of supervised KBQA and introduce\ninteraction between in-context learning using BLLMs and transfer learning from\nthe source for both stages. In addition, we propose execution-guided\nself-refinement using BLLMs, decoupled from the transfer setting. With the help\nof experiments using benchmark datasets GrailQA as the source and WebQSP as the\ntarget, we show that the proposed combination brings significant improvements\nto both stages and also outperforms by a large margin state-of-the-art\nsupervised KBQA models trained on the source. We also show that in the\nin-domain setting, the proposed BLLM augmentation significantly outperforms\nstate-of-the-art supervised models, when the volume of labeled data is limited,\nand also outperforms these marginally even when using the entire large training\ndataset.",
            "author": [
                "Mayur Patidar",
                "Avinash Singh",
                "Riya Sawhney",
                "Indrajit Bhattacharya",
                "Mausam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08894v1",
                "http://arxiv.org/pdf/2311.08894v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08886v1",
            "title": "CLIMB: Curriculum Learning for Infant-inspired Model Building",
            "updated": "2023-11-15T11:48:16Z",
            "published": "2023-11-15T11:48:16Z",
            "summary": "We describe our team's contribution to the STRICT-SMALL track of the BabyLM\nChallenge. The challenge requires training a language model from scratch using\nonly a relatively small training dataset of ten million words. We experiment\nwith three variants of cognitively-motivated curriculum learning and analyze\ntheir effect on the performance of the model on linguistic evaluation tasks. In\nthe vocabulary curriculum, we analyze methods for constraining the vocabulary\nin the early stages of training to simulate cognitively more plausible learning\ncurves. In the data curriculum experiments, we vary the order of the training\ninstances based on i) infant-inspired expectations and ii) the learning\nbehavior of the model. In the objective curriculum, we explore different\nvariations of combining the conventional masked language modeling task with a\nmore coarse-grained word class prediction task to reinforce linguistic\ngeneralization capabilities. Our results did not yield consistent improvements\nover our own non-curriculum learning baseline across a range of linguistic\nbenchmarks; however, we do find marginal gains on select tasks. Our analysis\nhighlights key takeaways for specific combinations of tasks and settings which\nbenefit from our proposed curricula. We moreover determine that careful\nselection of model architecture, and training hyper-parameters yield\nsubstantial improvements over the default baselines provided by the BabyLM\nchallenge.",
            "author": [
                "Richard Diehl Martinez",
                "Zebulon Goriely",
                "Hope McGovern",
                "Christopher Davis",
                "Andrew Caines",
                "Paula Buttery",
                "Lisa Beinborn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08886v1",
                "http://arxiv.org/pdf/2311.08886v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08884v1",
            "title": "CREPE Notes: A new method for segmenting pitch contours into discrete\n  notes",
            "updated": "2023-11-15T11:43:48Z",
            "published": "2023-11-15T11:43:48Z",
            "summary": "Tracking the fundamental frequency (f0) of a monophonic instrumental\nperformance is effectively a solved problem with several solutions achieving\n99% accuracy. However, the related task of automatic music transcription\nrequires a further processing step to segment an f0 contour into discrete\nnotes. This sub-task of note segmentation is necessary to enable a range of\napplications including musicological analysis and symbolic music generation.\nBuilding on CREPE, a state-of-the-art monophonic pitch tracking solution based\non a simple neural network, we propose a simple and effective method for\npost-processing CREPE's output to achieve monophonic note segmentation. The\nproposed method demonstrates state-of-the-art results on two challenging\ndatasets of monophonic instrumental music. Our approach also gives a 97%\nreduction in the total number of parameters used when compared with other deep\nlearning based methods.",
            "author": [
                "Xavier Riley",
                "Simon Dixon"
            ],
            "link": [
                "http://dx.doi.org/10.5281/zenodo.8136568",
                "http://arxiv.org/abs/2311.08884v1",
                "http://arxiv.org/pdf/2311.08884v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "cs.MM",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08883v1",
            "title": "Enabling Large Language Models to Learn from Rules",
            "updated": "2023-11-15T11:42:41Z",
            "published": "2023-11-15T11:42:41Z",
            "summary": "Large language models (LLMs) have shown incredible performance in completing\nvarious real-world tasks. The current knowledge learning paradigm of LLMs is\nmainly based on learning from examples, in which LLMs learn the internal rule\nimplicitly from a certain number of supervised examples. However, the learning\nparadigm may not well learn those complicated rules, especially when the\ntraining examples are limited. We are inspired that humans can learn the new\ntasks or knowledge in another way by learning from rules. That is, humans can\ngrasp the new tasks or knowledge quickly and generalize well given only a\ndetailed rule and a few optional examples. Therefore, in this paper, we aim to\nexplore the feasibility of this new learning paradigm, which encodes the\nrule-based knowledge into LLMs. We propose rule distillation, which first uses\nthe strong in-context abilities of LLMs to extract the knowledge from the\ntextual rules and then explicitly encode the knowledge into LLMs' parameters by\nlearning from the above in-context signals produced inside the model. Our\nexperiments show that making LLMs learn from rules by our method is much more\nefficient than example-based learning in both the sample size and\ngeneralization ability.",
            "author": [
                "Wenkai Yang",
                "Yankai Lin",
                "Jie Zhou",
                "Jirong Wen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08883v1",
                "http://arxiv.org/pdf/2311.08883v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08878v1",
            "title": "Multi-objective Non-intrusive Hearing-aid Speech Assessment Model",
            "updated": "2023-11-15T11:32:50Z",
            "published": "2023-11-15T11:32:50Z",
            "summary": "Without the need for a clean reference, non-intrusive speech assessment\nmethods have caught great attention for objective evaluations. While deep\nlearning models have been used to develop non-intrusive speech assessment\nmethods with promising results, there is limited research on hearing-impaired\nsubjects. This study proposes a multi-objective non-intrusive hearing-aid\nspeech assessment model, called HASA-Net Large, which predicts speech quality\nand intelligibility scores based on input speech signals and specified\nhearing-loss patterns. Our experiments showed the utilization of pre-trained\nSSL models leads to a significant boost in speech quality and intelligibility\npredictions compared to using spectrograms as input. Additionally, we examined\nthree distinct fine-tuning approaches that resulted in further performance\nimprovements. Furthermore, we demonstrated that incorporating SSL models\nresulted in greater transferability to OOD dataset. Finally, this study\nintroduces HASA-Net Large, which is a non-invasive approach for evaluating\nspeech quality and intelligibility. HASA-Net Large utilizes raw waveforms and\nhearing-loss patterns to accurately predict speech quality and intelligibility\nlevels for individuals with normal and impaired hearing and demonstrates\nsuperior prediction performance and transferability.",
            "author": [
                "Hsin-Tien Chiang",
                "Szu-Wei Fu",
                "Hsin-Min Wang",
                "Yu Tsao",
                "John H. L. Hansen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08878v1",
                "http://arxiv.org/pdf/2311.08878v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08877v1",
            "title": "Llamas Know What GPTs Don't Show: Surrogate Models for Confidence\n  Estimation",
            "updated": "2023-11-15T11:27:44Z",
            "published": "2023-11-15T11:27:44Z",
            "summary": "To maintain user trust, large language models (LLMs) should signal low\nconfidence on examples where they are incorrect, instead of misleading the\nuser. The standard approach of estimating confidence is to use the softmax\nprobabilities of these models, but as of November 2023, state-of-the-art LLMs\nsuch as GPT-4 and Claude-v1.3 do not provide access to these probabilities. We\nfirst study eliciting confidence linguistically -- asking an LLM for its\nconfidence in its answer -- which performs reasonably (80.5% AUC on GPT-4\naveraged across 12 question-answering datasets -- 7% above a random baseline)\nbut leaves room for improvement. We then explore using a surrogate confidence\nmodel -- using a model where we do have probabilities to evaluate the original\nmodel's confidence in a given question. Surprisingly, even though these\nprobabilities come from a different and often weaker model, this method leads\nto higher AUC than linguistic confidences on 9 out of 12 datasets. Our best\nmethod composing linguistic confidences and surrogate model probabilities gives\nstate-of-the-art confidence estimates on all 12 datasets (84.6% average AUC on\nGPT-4).",
            "author": [
                "Vaishnavi Shrivastava",
                "Percy Liang",
                "Ananya Kumar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08877v1",
                "http://arxiv.org/pdf/2311.08877v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08874v1",
            "title": "Towards Label Embedding -- Measuring classification difficulty",
            "updated": "2023-11-15T11:23:15Z",
            "published": "2023-11-15T11:23:15Z",
            "summary": "Uncertainty quantification in machine learning is a timely and vast field of\nresearch. In supervised learning, uncertainty can already occur in the very\nfirst stage of the training process, the labelling step. In particular, this is\nthe case when not every instance can be unambiguously classified. The problem\noccurs for classifying instances, where classes may overlap or instances can\nnot be clearly categorised. In other words, there is inevitable ambiguity in\nthe annotation step and not necessarily a 'ground truth'. We look exemplary at\nthe classification of satellite images. Each image is annotated independently\nby multiple labellers and classified into local climate zones (LCZs). For each\ninstance we have multiple votes, leading to a distribution of labels rather\nthan a single value. The main idea of this work is that we do not assume a\nground truth label but embed the votes into a K-dimensional space, with K as\nthe number of possible categories. The embedding is derived from the voting\ndistribution in a Bayesian setup, modelled via a Dirichlet-Multinomial model.\nWe estimate the model and posteriors using a stochastic Expectation\nMaximisation algorithm with Markov Chain Monte Carlo steps. While we focus on\nthe particular example of LCZ classification, the methods developed in this\npaper readily extend to other situations where multiple annotators\nindependently label texts or images. We also apply our approach to two other\nbenchmark datasets for image classification to demonstrate this. Besides the\nembeddings themselves, we can investigate the resulting correlation matrices,\nwhich can be seen as generalised confusion matrices and reflect the semantic\nsimilarities of the original classes very well for all three exemplary\ndatasets. The insights gained are valuable and can serve as general label\nembedding if a single ground truth per observation cannot be guaranteed.",
            "author": [
                "Katharina Hechinger",
                "Christoph Koller",
                "Xiao Xiang Zhu",
                "G\u00f6ran Kauermann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08874v1",
                "http://arxiv.org/pdf/2311.08874v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.AP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08870v2",
            "title": "One-Shot Federated Learning with Classifier-Guided Diffusion Models",
            "updated": "2023-11-16T15:43:52Z",
            "published": "2023-11-15T11:11:25Z",
            "summary": "One-shot federated learning (OSFL) has gained attention in recent years due\nto its low communication cost. However, most of the existing methods require\nauxiliary datasets or training generators, which hinders their practicality in\nreal-world scenarios. In this paper, we explore the novel opportunities that\ndiffusion models bring to OSFL and propose FedCADO, utilizing guidance from\nclient classifiers to generate data that complies with clients' distributions\nand subsequently training the aggregated model on the server. Specifically, our\nmethod involves targeted optimizations in two aspects. On one hand, we\nconditionally edit the randomly sampled initial noises, embedding them with\nspecified semantics and distributions, resulting in a significant improvement\nin both the quality and stability of generation. On the other hand, we employ\nthe BN statistics from the classifiers to provide detailed guidance during\ngeneration. These tailored optimizations enable us to limitlessly generate\ndatasets, which closely resemble the distribution and quality of the original\nclient dataset. Our method effectively handles the heterogeneous client models\nand the problems of non-IID features or labels. In terms of privacy protection,\nour method avoids training any generator or transferring any auxiliary\ninformation on clients, eliminating any additional privacy leakage risks.\nLeveraging the extensive knowledge stored in the pre-trained diffusion model,\nthe synthetic datasets can assist us in surpassing the knowledge limitations of\nthe client samples, resulting in aggregation models that even outperform the\nperformance ceiling of centralized training in some cases, which is\nconvincingly demonstrated in the sufficient quantification and visualization\nexperiments conducted on three large-scale multi-domain image datasets.",
            "author": [
                "Mingzhao Yang",
                "Shangchao Su",
                "Bin Li",
                "Xiangyang Xue"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08870v2",
                "http://arxiv.org/pdf/2311.08870v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08863v1",
            "title": "Toulouse Hyperspectral Data Set: a benchmark data set to assess\n  semi-supervised spectral representation learning and pixel-wise\n  classification techniques",
            "updated": "2023-11-15T10:49:15Z",
            "published": "2023-11-15T10:49:15Z",
            "summary": "Airborne hyperspectral images can be used to map the land cover in large\nurban areas, thanks to their very high spatial and spectral resolutions on a\nwide spectral domain. While the spectral dimension of hyperspectral images is\nhighly informative of the chemical composition of the land surface, the use of\nstate-of-the-art machine learning algorithms to map the land cover has been\ndramatically limited by the availability of training data. To cope with the\nscarcity of annotations, semi-supervised and self-supervised techniques have\nlately raised a lot of interest in the community. Yet, the publicly available\nhyperspectral data sets commonly used to benchmark machine learning models are\nnot totally suited to evaluate their generalization performances due to one or\nseveral of the following properties: a limited geographical coverage (which\ndoes not reflect the spectral diversity in metropolitan areas), a small number\nof land cover classes and a lack of appropriate standard train / test splits\nfor semi-supervised and self-supervised learning. Therefore, we release in this\npaper the Toulouse Hyperspectral Data Set that stands out from other data sets\nin the above-mentioned respects in order to meet key issues in spectral\nrepresentation learning and classification over large-scale hyperspectral\nimages with very few labeled pixels. Besides, we discuss and experiment the\nself-supervised task of Masked Autoencoders and establish a baseline for\npixel-wise classification based on a conventional autoencoder combined with a\nRandom Forest classifier achieving 82% overall accuracy and 74% F1 score. The\nToulouse Hyperspectral Data Set and our code are publicly available at\nhttps://www.toulouse-hyperspectral-data-set.com and\nhttps://www.github.com/Romain3Ch216/tlse-experiments, respectively.",
            "author": [
                "Romain Thoreau",
                "Laurent Risser",
                "V\u00e9ronique Achard",
                "B\u00e9atrice Berthelot",
                "Xavier Briottet"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08863v1",
                "http://arxiv.org/pdf/2311.08863v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08851v1",
            "title": "Data Augmentations in Deep Weight Spaces",
            "updated": "2023-11-15T10:43:13Z",
            "published": "2023-11-15T10:43:13Z",
            "summary": "Learning in weight spaces, where neural networks process the weights of other\ndeep neural networks, has emerged as a promising research direction with\napplications in various fields, from analyzing and editing neural fields and\nimplicit neural representations, to network pruning and quantization. Recent\nworks designed architectures for effective learning in that space, which takes\ninto account its unique, permutation-equivariant, structure. Unfortunately, so\nfar these architectures suffer from severe overfitting and were shown to\nbenefit from large datasets. This poses a significant challenge because\ngenerating data for this learning setup is laborious and time-consuming since\neach data sample is a full set of network weights that has to be trained. In\nthis paper, we address this difficulty by investigating data augmentations for\nweight spaces, a set of techniques that enable generating new data examples on\nthe fly without having to train additional input weight space elements. We\nfirst review several recently proposed data augmentation schemes %that were\nproposed recently and divide them into categories. We then introduce a novel\naugmentation scheme based on the Mixup method. We evaluate the performance of\nthese techniques on existing benchmarks as well as new benchmarks we generate,\nwhich can be valuable for future studies.",
            "author": [
                "Aviv Shamsian",
                "David W. Zhang",
                "Aviv Navon",
                "Yan Zhang",
                "Miltiadis Kofinas",
                "Idan Achituve",
                "Riccardo Valperga",
                "Gertjan J. Burghouts",
                "Efstratios Gavves",
                "Cees G. M. Snoek",
                "Ethan Fetaya",
                "Gal Chechik",
                "Haggai Maron"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08851v1",
                "http://arxiv.org/pdf/2311.08851v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08845v1",
            "title": "Statistical learning by sparse deep neural networks",
            "updated": "2023-11-15T10:35:23Z",
            "published": "2023-11-15T10:35:23Z",
            "summary": "We consider a deep neural network estimator based on empirical risk\nminimization with l_1-regularization. We derive a general bound for its excess\nrisk in regression and classification (including multiclass), and prove that it\nis adaptively nearly-minimax (up to log-factors) simultaneously across the\nentire range of various function classes.",
            "author": [
                "Felix Abramovich"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08845v1",
                "http://arxiv.org/pdf/2311.08845v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "cs.LG",
                "stat.ME",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08840v1",
            "title": "An MRL-Based Design Solution for RIS-Assisted MU-MIMO Wireless System\n  under Time-Varying Channels",
            "updated": "2023-11-15T10:29:32Z",
            "published": "2023-11-15T10:29:32Z",
            "summary": "Utilizing Deep Reinforcement Learning (DRL) for Reconfigurable Intelligent\nSurface (RIS) assisted wireless communication has been extensively researched.\nHowever, existing DRL methods either act as a simple optimizer or only solve\nproblems with concurrent Channel State Information (CSI) represented in the\ntraining data set. Consequently, solutions for RIS-assisted wireless\ncommunication systems under time-varying environments are relatively\nunexplored. However, communication problems should be considered with realistic\nassumptions; for instance, in scenarios where the channel is time-varying, the\npolicy obtained by reinforcement learning should be applicable for situations\nwhere CSI is not well represented in the training data set. In this paper, we\napply Meta-Reinforcement Learning (MRL) to the joint optimization problem of\nactive beamforming at the Base Station (BS) and phase shift at the RIS,\nmotivated by MRL's ability to extend the DRL concept of solving one Markov\nDecision Problem (MDP) to multiple MDPs. We provide simulation results to\ncompare the average sum rate of the proposed approach with those of selected\nforerunners in the literature. Our approach improves the sum rate by more than\n60% under time-varying CSI assumption while maintaining the advantages of\ntypical DRL-based solutions. Our study's results emphasize the possibility of\nutilizing MRL-based designs in RIS-assisted wireless communication systems\nwhile considering realistic environment assumptions.",
            "author": [
                "Meng-Qian Alexander Wu",
                "Tzu-Hsien Sang",
                "Luisa Schuhmacher",
                "Ming-Jie Guo",
                "Khodr Hammoud",
                "Sofie Pollin"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08840v1",
                "http://arxiv.org/pdf/2311.08840v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10765v1",
            "title": "Enhancing Machine Translation through Advanced In-Context Learning: A\n  Methodological Strategy for GPT-4 Improvement",
            "updated": "2023-11-15T10:28:28Z",
            "published": "2023-11-15T10:28:28Z",
            "summary": "The challenge of improving translation accuracy in GPT-4 is being addressed\nby harnessing a method known as in-context learning. This paper introduces a\nstrategic approach to utilize in-context learning specifically for machine\ntranslation, aiming to significantly boost accuracy. The crux of this method\nlies in the judicious selection of demonstrations that are most effective for\nin-context learning. By selecting these examples carefully, GPT-4 can utilize\nthem to achieve remarkably accurate machine translations, eliminating the need\nfor task-specific fine-tuning. This technique is anchored in the semantic\nsimilarities between the user's prompt and the chosen dataset. Sentences from\nthis dataset, carefully picked for their relevance and clarity, serve as potent\ndemonstrations for in-context learning. This approach not only enhances\ntranslation accuracy but also enriches the understanding of nuanced linguistic\nstructures. It represents a significant step forward in machine learning,\nleveraging the inherent capabilities of GPT-4 to provide translations that are\nnot only accurate but also contextually rich and linguistically sophisticated.\nThis method demonstrates the potential of in-context learning in overcoming\nlanguage barriers, opening new avenues for cross-cultural communication and\nglobal collaboration.",
            "author": [
                "Yufeng Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10765v1",
                "http://arxiv.org/pdf/2311.10765v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08835v2",
            "title": "Correlation-guided Query-Dependency Calibration in Video Representation\n  Learning for Temporal Grounding",
            "updated": "2023-11-18T15:51:20Z",
            "published": "2023-11-15T10:22:35Z",
            "summary": "Recent endeavors in video temporal grounding enforce strong cross-modal\ninteractions through attention mechanisms to overcome the modality gap between\nvideo and text query. However, previous works treat all video clips equally\nregardless of their semantic relevance with the text query in attention\nmodules. In this paper, our goal is to provide clues for query-associated video\nclips within the crossmodal encoding process. With our Correlation-Guided\nDetection Transformer~(CG-DETR), we explore the appropriate clip-wise degree of\ncross-modal interactions and how to exploit such degrees for prediction. First,\nwe design an adaptive cross-attention layer with dummy tokens. Dummy tokens\nconditioned by text query take a portion of the attention weights, preventing\nirrelevant video clips from being represented by the text query. Yet, not all\nword tokens equally inherit the text query's correlation to video clips. Thus,\nwe further guide the cross-attention map by inferring the fine-grained\ncorrelation between video clips and words. We enable this by learning a joint\nembedding space for high-level concepts, i.e., moment and sentence level, and\ninferring the clip-word correlation. Lastly, we use a moment-adaptive saliency\ndetector to exploit each video clip's degrees of text engagement. We validate\nthe superiority of CG-DETR with the state-of-the-art results on various\nbenchmarks for both moment retrieval and highlight detection. Codes are\navailable at https://github.com/wjun0830/CGDETR.",
            "author": [
                "WonJun Moon",
                "Sangeek Hyun",
                "SuBeen Lee",
                "Jae-Pil Heo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08835v2",
                "http://arxiv.org/pdf/2311.08835v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08829v1",
            "title": "Autoencoder with Group-based Decoder and Multi-task Optimization for\n  Anomalous Sound Detection",
            "updated": "2023-11-15T10:15:37Z",
            "published": "2023-11-15T10:15:37Z",
            "summary": "In industry, machine anomalous sound detection (ASD) is in great demand.\nHowever, collecting enough abnormal samples is difficult due to the high cost,\nwhich boosts the rapid development of unsupervised ASD algorithms. Autoencoder\n(AE) based methods have been widely used for unsupervised ASD, but suffer from\nproblems including 'shortcut', poor anti-noise ability and sub-optimal quality\nof features. To address these challenges, we propose a new AE-based framework\ntermed AEGM. Specifically, we first insert an auxiliary classifier into AE to\nenhance ASD in a multi-task learning manner. Then, we design a group-based\ndecoder structure, accompanied by an adaptive loss function, to endow the model\nwith domain-specific knowledge. Results on the DCASE 2021 Task 2 development\nset show that our methods achieve a relative improvement of 13.11% and 15.20%\nrespectively in average AUC over the official AE and MobileNetV2 across test\nsets of seven machines.",
            "author": [
                "Yifan Zhou",
                "Dongxing Xu",
                "Haoran Wei",
                "Yanhua Long"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08829v1",
                "http://arxiv.org/pdf/2311.08829v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08827v1",
            "title": "A Deep Reinforcement Learning Approach to Efficient Distributed\n  Optimization",
            "updated": "2023-11-15T10:02:42Z",
            "published": "2023-11-15T10:02:42Z",
            "summary": "In distributed optimization, the practical problem-solving performance is\nessentially sensitive to algorithm selection, parameter setting, problem type\nand data pattern. Thus, it is often laborious to acquire a highly efficient\nmethod for a given specific problem. In this paper, we propose a learning-based\nmethod to achieve efficient distributed optimization over networked systems.\nSpecifically, a deep reinforcement learning (DRL) framework is developed for\nadaptive configuration within a parameterized unifying algorithmic form, which\nincorporates an abundance of first-order and second-order optimization\nalgorithms that can be implemented in a decentralized fashion. We exploit the\nlocal consensus and objective information to represent the regularities of\nproblem instances and trace the solving progress, which constitute the states\nobserved by an RL agent. The framework is trained using Proximal Policy\nOptimization (PPO) on a number of practical problem instances of similar\nstructures yet different problem data. Experiments on various smooth and\nnon-smooth classes of objective functions demonstrate that our proposed\nlearning-based method outperforms several state-of-the-art distributed\noptimization algorithms in terms of convergence speed and solution accuracy.",
            "author": [
                "Daokuan Zhu",
                "Jie Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08827v1",
                "http://arxiv.org/pdf/2311.08827v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08820v1",
            "title": "Reinforcement Learning with Model Predictive Control for Highway Ramp\n  Metering",
            "updated": "2023-11-15T09:50:54Z",
            "published": "2023-11-15T09:50:54Z",
            "summary": "In the backdrop of an increasingly pressing need for effective urban and\nhighway transportation systems, this work explores the synergy between\nmodel-based and learning-based strategies to enhance traffic flow management by\nuse of an innovative approach to the problem of highway ramp metering control\nthat embeds Reinforcement Learning techniques within the Model Predictive\nControl framework. The control problem is formulated as an RL task by crafting\na suitable stage cost function that is representative of the traffic\nconditions, variability in the control action, and violations of a\nsafety-critical constraint on the maximum number of vehicles in queue. An\nMPC-based RL approach, which merges the advantages of the two paradigms in\norder to overcome the shortcomings of each framework, is proposed to learn to\nefficiently control an on-ramp and to satisfy its constraints despite\nuncertainties in the system model and variable demands. Finally, simulations\nare performed on a benchmark from the literature consisting of a small-scale\nhighway network. Results show that, starting from an MPC controller that has an\nimprecise model and is poorly tuned, the proposed methodology is able to\neffectively learn to improve the control policy such that congestion in the\nnetwork is reduced and constraints are satisfied, yielding an improved\nperformance compared to the initial controller.",
            "author": [
                "Filippo Airaldi",
                "Bart De Schutter",
                "Azita Dabiri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08820v1",
                "http://arxiv.org/pdf/2311.08820v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.AI",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08819v1",
            "title": "Frequency Domain-based Dataset Distillation",
            "updated": "2023-11-15T09:46:30Z",
            "published": "2023-11-15T09:46:30Z",
            "summary": "This paper presents FreD, a novel parameterization method for dataset\ndistillation, which utilizes the frequency domain to distill a small-sized\nsynthetic dataset from a large-sized original dataset. Unlike conventional\napproaches that focus on the spatial domain, FreD employs frequency-based\ntransforms to optimize the frequency representations of each data instance. By\nleveraging the concentration of spatial domain information on specific\nfrequency components, FreD intelligently selects a subset of frequency\ndimensions for optimization, leading to a significant reduction in the required\nbudget for synthesizing an instance. Through the selection of frequency\ndimensions based on the explained variance, FreD demonstrates both theoretical\nand empirical evidence of its ability to operate efficiently within a limited\nbudget, while better preserving the information of the original dataset\ncompared to conventional parameterization methods. Furthermore, based on the\northogonal compatibility of FreD with existing methods, we confirm that FreD\nconsistently improves the performances of existing distillation methods over\nthe evaluation scenarios with different benchmark datasets. We release the code\nat https://github.com/sdh0818/FreD.",
            "author": [
                "Donghyeok Shin",
                "Seungjae Shin",
                "Il-Chul Moon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08819v1",
                "http://arxiv.org/pdf/2311.08819v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08817v1",
            "title": "MAP's not dead yet: Uncovering true language model modes by conditioning\n  away degeneracy",
            "updated": "2023-11-15T09:38:53Z",
            "published": "2023-11-15T09:38:53Z",
            "summary": "It has been widely observed that exact or approximate MAP (mode-seeking)\ndecoding from natural language generation (NLG) models consistently leads to\ndegenerate outputs (Stahlberg and Byrne, 2019, Holtzman et al., 2019). This has\ngenerally been attributed to either a fundamental inadequacy of modes in models\nor weaknesses in language modeling. Contrastingly in this work, we emphasize\nthat degenerate modes can even occur in the absence of any model error, due to\ncontamination of the training data. Specifically, we show that mixing even a\ntiny amount of low-entropy noise with a population text distribution can cause\nthe data distribution's mode to become degenerate, implying that any models\ntrained on it will be as well. As the unconditional mode of NLG models will\noften be degenerate, we therefore propose to apply MAP decoding to the model's\ndistribution conditional on avoiding specific degeneracies. Using exact-search,\nwe empirically verify that the length-conditional modes of machine translation\nmodels and language models are indeed more fluent and topical than their\nunconditional modes. For the first time, we also share many examples of exact\nmodal sequences from these models, and from several variants of the LLaMA-7B\nmodel. Notably, the modes of the LLaMA models are still degenerate, showing\nthat improvements in modeling have not fixed this issue. Because of the cost of\nexact mode finding algorithms, we develop an approximate mode finding approach,\nACBS, which finds sequences that are both high-likelihood and high-quality. We\napply this approach to LLaMA-7B, a model which was not trained for instruction\nfollowing, and find that we are able to elicit reasonable outputs without any\nfinetuning.",
            "author": [
                "Davis Yoshida",
                "Kartik Goyal",
                "Kevin Gimpel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08817v1",
                "http://arxiv.org/pdf/2311.08817v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08815v1",
            "title": "Self-Supervised Disentanglement by Leveraging Structure in Data\n  Augmentations",
            "updated": "2023-11-15T09:34:08Z",
            "published": "2023-11-15T09:34:08Z",
            "summary": "Self-supervised representation learning often uses data augmentations to\ninduce some invariance to \"style\" attributes of the data. However, with\ndownstream tasks generally unknown at training time, it is difficult to deduce\na priori which attributes of the data are indeed \"style\" and can be safely\ndiscarded. To address this, we introduce a more principled approach that seeks\nto disentangle style features rather than discard them. The key idea is to add\nmultiple style embedding spaces where: (i) each is invariant to all-but-one\naugmentation; and (ii) joint entropy is maximized. We formalize our structured\ndata-augmentation procedure from a causal latent-variable-model perspective,\nand prove identifiability of both content and (multiple blocks of) style\nvariables. We empirically demonstrate the benefits of our approach on synthetic\ndatasets and then present promising but limited results on ImageNet.",
            "author": [
                "Cian Eastwood",
                "Julius von K\u00fcgelgen",
                "Linus Ericsson",
                "Diane Bouchacourt",
                "Pascal Vincent",
                "Bernhard Sch\u00f6lkopf",
                "Mark Ibrahim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08815v1",
                "http://arxiv.org/pdf/2311.08815v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CV",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08811v1",
            "title": "Correlation-aware active learning for surgery video segmentation",
            "updated": "2023-11-15T09:30:52Z",
            "published": "2023-11-15T09:30:52Z",
            "summary": "Semantic segmentation is a complex task that relies heavily on large amounts\nof annotated image data. However, annotating such data can be time-consuming\nand resource-intensive, especially in the medical domain. Active Learning (AL)\nis a popular approach that can help to reduce this burden by iteratively\nselecting images for annotation to improve the model performance. In the case\nof video data, it is important to consider the model uncertainty and the\ntemporal nature of the sequences when selecting images for annotation. This\nwork proposes a novel AL strategy for surgery video segmentation, \\COALSamp{},\nCOrrelation-aWare Active Learning. Our approach involves projecting images into\na latent space that has been fine-tuned using contrastive learning and then\nselecting a fixed number of representative images from local clusters of video\nframes. We demonstrate the effectiveness of this approach on two video datasets\nof surgical instruments and three real-world video datasets. The datasets and\ncode will be made publicly available upon receiving necessary approvals.",
            "author": [
                "Fei Wu",
                "Pablo Marquez-Neila",
                "Mingyi Zheng",
                "Hedyeh Rafii-Tari",
                "Raphael Sznitman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08811v1",
                "http://arxiv.org/pdf/2311.08811v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08808v1",
            "title": "Degradation Estimation Recurrent Neural Network with Local and Non-Local\n  Priors for Compressive Spectral Imaging",
            "updated": "2023-11-15T09:23:42Z",
            "published": "2023-11-15T09:23:42Z",
            "summary": "In coded aperture snapshot spectral imaging (CASSI) systems, a core problem\nis to recover the 3D hyperspectral image (HSI) from the 2D measurement. Current\ndeep unfolding networks (DUNs) for the HSI reconstruction mainly suffered from\nthree issues. Firstly, in previous DUNs, the DNNs across different stages were\nunable to share the feature representations learned from different stages,\nleading to parameter sparsity, which in turn limited their reconstruction\npotential. Secondly, previous DUNs fail to estimate degradation-related\nparameters within a unified framework, including the degradation matrix in the\ndata subproblem and the noise level in the prior subproblem. Consequently,\neither the accuracy of solving the data or the prior subproblem is compromised.\nThirdly, exploiting both local and non-local priors for the HSI reconstruction\nis crucial, and it remains a key issue to be addressed. In this paper, we first\ntransform the DUN into a Recurrent Neural Network (RNN) by sharing parameters\nacross stages, which allows the DNN in each stage could learn feature\nrepresentation from different stages, enhancing the representativeness of the\nDUN. Secondly, we incorporate the Degradation Estimation Network into the RNN\n(DERNN), which simultaneously estimates the degradation matrix and the noise\nlevel by residual learning with reference to the sensing matrix. Thirdly, we\npropose a Local and Non-Local Transformer (LNLT) to effectively exploit both\nlocal and non-local priors in HSIs. By integrating the LNLT into the DERNN for\nsolving the prior subproblem, we propose the DERNN-LNLT, which achieves\nstate-of-the-art performance.",
            "author": [
                "Yubo Dong",
                "Dahua Gao",
                "Yuyan Li",
                "Guangming Shi",
                "Danhua Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08808v1",
                "http://arxiv.org/pdf/2311.08808v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08798v1",
            "title": "X-GRL: An Empirical Assessment of Explainable GNN-DRL in B5G/6G Networks",
            "updated": "2023-11-15T09:11:37Z",
            "published": "2023-11-15T09:11:37Z",
            "summary": "The rapid development of artificial intelligence (AI) techniques has\ntriggered a revolution in beyond fifth-generation (B5G) and upcoming\nsixth-generation (6G) mobile networks. Despite these advances, efficient\nresource allocation in dynamic and complex networks remains a major challenge.\nThis paper presents an experimental implementation of deep reinforcement\nlearning (DRL) enhanced with graph neural networks (GNNs) on a real 5G testbed.\nThe method addresses the explainability of GNNs by evaluating the importance of\neach edge in determining the model's output. The custom sampling functions feed\nthe data into the proposed GNN-driven Monte Carlo policy gradient (REINFORCE)\nagent to optimize the gNodeB (gNB) radio resources according to the specific\ntraffic demands. The demo demonstrates real-time visualization of network\nparameters and superior performance compared to benchmarks.",
            "author": [
                "Farhad Rezazadeh",
                "Sergio Barrachina-MuNoz",
                "Engin Zeydan",
                "Houbing Song",
                "K. P. Subbalakshmi",
                "Josep Mangues-Bafalluy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08798v1",
                "http://arxiv.org/pdf/2311.08798v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08796v1",
            "title": "Interacting Edge-Reinforced Random Walks",
            "updated": "2023-11-15T09:09:16Z",
            "published": "2023-11-15T09:09:16Z",
            "summary": "We consider the edge-reinforced random walk with multiple (but finitely many)\nwalkers which influence the edge weights together. The walker which moves at a\ngiven time step is chosen uniformly at random, or according to a fixed order.\nFirst, we consider 2 walkers with linear reinforcement on a line graph\ncomprising three nodes. We show that the edge weights evolve similarly to the\nsetting with a single walker which corresponds to a P\\'olya urn. In particular,\nthe left edge weight proportion is a martingale at certain stopping times,\nshowing that a (random) limiting proportion exists. We then look at an\narbitrary number of walkers on Z with very general reinforcement. We show that\nin this case, the behaviour is also the same as for a single walker: either all\nwalkers are recurrent or all walkers have finite range. In the particular case\nof reinforcements of \"sequence type\", we give a criterion for recurrence.",
            "author": [
                "Nina Gantert",
                "Fabian Michel",
                "Guilherme Reis"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08796v1",
                "http://arxiv.org/pdf/2311.08796v1"
            ],
            "primary_category": "math.PR",
            "category": [
                "math.PR",
                "60K35, 60K37, 60G42 (Primary) 60F05, 60B10, 60G57 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08793v1",
            "title": "German FinBERT: A German Pre-trained Language Model",
            "updated": "2023-11-15T09:07:29Z",
            "published": "2023-11-15T09:07:29Z",
            "summary": "This study presents German FinBERT, a novel pre-trained German language model\ntailored for financial textual data. The model is trained through a\ncomprehensive pre-training process, leveraging a substantial corpus comprising\nfinancial reports, ad-hoc announcements and news related to German companies.\nThe corpus size is comparable to the data sets commonly used for training\nstandard BERT models. I evaluate the performance of German FinBERT on\ndownstream tasks, specifically sentiment prediction, topic recognition and\nquestion answering against generic German language models. My results\ndemonstrate improved performance on finance-specific data, indicating the\nefficacy of German FinBERT in capturing domain-specific nuances. The presented\nfindings suggest that German FinBERT holds promise as a valuable tool for\nfinancial text analysis, potentially benefiting various applications in the\nfinancial domain.",
            "author": [
                "Moritz Scherrmann"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08793v1",
                "http://arxiv.org/pdf/2311.08793v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14710v1",
            "title": "Neuroscience inspired scientific machine learning (Part-2): Variable\n  spiking wavelet neural operator",
            "updated": "2023-11-15T09:02:01Z",
            "published": "2023-11-15T09:02:01Z",
            "summary": "We propose, in this paper, a Variable Spiking Wavelet Neural Operator\n(VS-WNO), which aims to bridge the gap between theoretical and practical\nimplementation of Artificial Intelligence (AI) algorithms for mechanics\napplications. With recent developments like the introduction of neural\noperators, AI's potential for being used in mechanics applications has\nincreased significantly. However, AI's immense energy and resource requirements\nare a hurdle in its practical field use case. The proposed VS-WNO is based on\nthe principles of spiking neural networks, which have shown promise in reducing\nthe energy requirements of the neural networks. This makes possible the use of\nsuch algorithms in edge computing. The proposed VS-WNO utilizes variable\nspiking neurons, which promote sparse communication, thus conserving energy,\nand its use is further supported by its ability to tackle regression tasks,\noften faced in the field of mechanics. Various examples dealing with partial\ndifferential equations, like Burger's equation, Allen Cahn's equation, and\nDarcy's equation, have been shown. Comparisons have been shown against wavelet\nneural operator utilizing leaky integrate and fire neurons (direct and encoded\ninputs) and vanilla wavelet neural operator utilizing artificial neurons. The\nresults produced illustrate the ability of the proposed VS-WNO to converge to\nground truth while promoting sparse communication.",
            "author": [
                "Shailesh Garg",
                "Souvik Chakraborty"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14710v1",
                "http://arxiv.org/pdf/2311.14710v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08788v1",
            "title": "X-Eval: Generalizable Multi-aspect Text Evaluation via Augmented\n  Instruction Tuning with Auxiliary Evaluation Aspects",
            "updated": "2023-11-15T09:01:55Z",
            "published": "2023-11-15T09:01:55Z",
            "summary": "Natural Language Generation (NLG) typically involves evaluating the generated\ntext in various aspects (e.g., consistency and naturalness) to obtain a\ncomprehensive assessment. However, multi-aspect evaluation remains challenging\nas it may require the evaluator to generalize to any given evaluation aspect\neven if it's absent during training. In this paper, we introduce X-Eval, a\ntwo-stage instruction tuning framework to evaluate the text in both seen and\nunseen aspects customized by end users. X-Eval consists of two learning stages:\nthe vanilla instruction tuning stage that improves the model's ability to\nfollow evaluation instructions, and an enhanced instruction tuning stage that\nexploits the connections between fine-grained evaluation aspects to better\nassess text quality. To support the training of X-Eval, we collect\nAspectInstruct, the first instruction tuning dataset tailored for multi-aspect\nNLG evaluation spanning 27 diverse evaluation aspects with 65 tasks. To enhance\ntask diversity, we devise an augmentation strategy that converts human rating\nannotations into diverse forms of NLG evaluation tasks, including scoring,\ncomparison, ranking, and Boolean question answering. Extensive experiments\nacross three essential categories of NLG tasks: dialogue generation,\nsummarization, and data-to-text coupled with 21 aspects in meta-evaluation,\ndemonstrate that our X-Eval enables even a lightweight language model to\nachieve a comparable if not higher correlation with human judgments compared to\nthe state-of-the-art NLG evaluators, such as GPT-4.",
            "author": [
                "Minqian Liu",
                "Ying Shen",
                "Zhiyang Xu",
                "Yixin Cao",
                "Eunah Cho",
                "Vaibhav Kumar",
                "Reza Ghanadan",
                "Lifu Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08788v1",
                "http://arxiv.org/pdf/2311.08788v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09267v1",
            "title": "Neuroscience inspired scientific machine learning (Part-1): Variable\n  spiking neuron for regression",
            "updated": "2023-11-15T08:59:06Z",
            "published": "2023-11-15T08:59:06Z",
            "summary": "Redundant information transfer in a neural network can increase the\ncomplexity of the deep learning model, thus increasing its power consumption.\nWe introduce in this paper a novel spiking neuron, termed Variable Spiking\nNeuron (VSN), which can reduce the redundant firing using lessons from\nbiological neuron inspired Leaky Integrate and Fire Spiking Neurons (LIF-SN).\nThe proposed VSN blends LIF-SN and artificial neurons. It garners the advantage\nof intermittent firing from the LIF-SN and utilizes the advantage of continuous\nactivation from the artificial neuron. This property of the proposed VSN makes\nit suitable for regression tasks, which is a weak point for the vanilla spiking\nneurons, all while keeping the energy budget low. The proposed VSN is tested\nagainst both classification and regression tasks. The results produced advocate\nfavorably towards the efficacy of the proposed spiking neuron, particularly for\nregression tasks.",
            "author": [
                "Shailesh Garg",
                "Souvik Chakraborty"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09267v1",
                "http://arxiv.org/pdf/2311.09267v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08782v1",
            "title": "Language Semantic Graph Guided Data-Efficient Learning",
            "updated": "2023-11-15T08:54:57Z",
            "published": "2023-11-15T08:54:57Z",
            "summary": "Developing generalizable models that can effectively learn from limited data\nand with minimal reliance on human supervision is a significant objective\nwithin the machine learning community, particularly in the era of deep neural\nnetworks. Therefore, to achieve data-efficient learning, researchers typically\nexplore approaches that can leverage more related or unlabeled data without\nnecessitating additional manual labeling efforts, such as Semi-Supervised\nLearning (SSL), Transfer Learning (TL), and Data Augmentation (DA). SSL\nleverages unlabeled data in the training process, while TL enables the transfer\nof expertise from related data distributions. DA broadens the dataset by\nsynthesizing new data from existing examples. However, the significance of\nadditional knowledge contained within labels has been largely overlooked in\nresearch. In this paper, we propose a novel perspective on data efficiency that\ninvolves exploiting the semantic information contained in the labels of the\navailable data. Specifically, we introduce a Language Semantic Graph (LSG)\nwhich is constructed from labels manifest as natural language descriptions.\nUpon this graph, an auxiliary graph neural network is trained to extract\nhigh-level semantic relations and then used to guide the training of the\nprimary model, enabling more adequate utilization of label knowledge. Across\nimage, video, and audio modalities, we utilize the LSG method in both TL and\nSSL scenarios and illustrate its versatility in significantly enhancing\nperformance compared to other data-efficient learning approaches. Additionally,\nour in-depth analysis shows that the LSG method also expedites the training\nprocess.",
            "author": [
                "Wenxuan Ma",
                "Shuang Li",
                "Lincan Cai",
                "Jingxuan Kang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08782v1",
                "http://arxiv.org/pdf/2311.08782v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08774v2",
            "title": "Two-stage Joint Transductive and Inductive learning for Nuclei\n  Segmentation",
            "updated": "2023-11-17T19:26:53Z",
            "published": "2023-11-15T08:37:11Z",
            "summary": "AI-assisted nuclei segmentation in histopathological images is a crucial task\nin the diagnosis and treatment of cancer diseases. It decreases the time\nrequired to manually screen microscopic tissue images and can resolve the\nconflict between pathologists during diagnosis. Deep Learning has proven useful\nin such a task. However, lack of labeled data is a significant barrier for deep\nlearning-based approaches. In this study, we propose a novel approach to nuclei\nsegmentation that leverages the available labelled and unlabelled data. The\nproposed method combines the strengths of both transductive and inductive\nlearning, which have been previously attempted separately, into a single\nframework. Inductive learning aims at approximating the general function and\ngeneralizing to unseen test data, while transductive learning has the potential\nof leveraging the unlabelled test data to improve the classification. To the\nbest of our knowledge, this is the first study to propose such a hybrid\napproach for medical image segmentation. Moreover, we propose a novel two-stage\ntransductive inference scheme. We evaluate our approach on MoNuSeg benchmark to\ndemonstrate the efficacy and potential of our method.",
            "author": [
                "Hesham Ali",
                "Idriss Tondji",
                "Mennatullah Siam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08774v2",
                "http://arxiv.org/pdf/2311.08774v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09266v1",
            "title": "Adversarially Robust Spiking Neural Networks Through Conversion",
            "updated": "2023-11-15T08:33:46Z",
            "published": "2023-11-15T08:33:46Z",
            "summary": "Spiking neural networks (SNNs) provide an energy-efficient alternative to a\nvariety of artificial neural network (ANN) based AI applications. As the\nprogress in neuromorphic computing with SNNs expands their use in applications,\nthe problem of adversarial robustness of SNNs becomes more pronounced. To the\ncontrary of the widely explored end-to-end adversarial training based\nsolutions, we address the limited progress in scalable robust SNN training\nmethods by proposing an adversarially robust ANN-to-SNN conversion algorithm.\nOur method provides an efficient approach to embrace various computationally\ndemanding robust learning objectives that have been proposed for ANNs. During a\npost-conversion robust finetuning phase, our method adversarially optimizes\nboth layer-wise firing thresholds and synaptic connectivity weights of the SNN\nto maintain transferred robustness gains from the pre-trained ANN. We perform\nexperimental evaluations in numerous adaptive adversarial settings that account\nfor the spike-based operation dynamics of SNNs, and show that our approach\nyields a scalable state-of-the-art solution for adversarially robust deep SNNs\nwith low-latency.",
            "author": [
                "Ozan \u00d6zdenizci",
                "Robert Legenstein"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09266v1",
                "http://arxiv.org/pdf/2311.09266v1"
            ],
            "primary_category": "cs.NE",
            "category": [
                "cs.NE",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14709v1",
            "title": "Towards Long-term Annotators: A Supervised Label Aggregation Baseline",
            "updated": "2023-11-15T08:25:36Z",
            "published": "2023-11-15T08:25:36Z",
            "summary": "Relying on crowdsourced workers, data crowdsourcing platforms are able to\nefficiently provide vast amounts of labeled data. Due to the variability in the\nannotation quality of crowd workers, modern techniques resort to redundant\nannotations and subsequent label aggregation to infer true labels. However,\nthese methods require model updating during the inference, posing challenges in\nreal-world implementation. Meanwhile, in recent years, many data labeling tasks\nhave begun to require skilled and experienced annotators, leading to an\nincreasing demand for long-term annotators. These annotators could leave\nsubstantial historical annotation records on the crowdsourcing platforms, which\ncan benefit label aggregation, but are ignored by previous works. Hereby, in\nthis paper, we propose a novel label aggregation technique, which does not need\nany model updating during inference and can extensively explore the historical\nannotation records. We call it SuperLA, a Supervised Label Aggregation method.\nInside this model, we design three types of input features and a\nstraightforward neural network structure to merge all the information together\nand subsequently produce aggregated labels. Based on comparison experiments\nconducted on 22 public datasets and 11 baseline methods, we find that SuperLA\nnot only outperforms all those baselines in inference performance but also\noffers significant advantages in terms of efficiency.",
            "author": [
                "Haoyu Liu",
                "Fei Wang",
                "Minmin Lin",
                "Runze Wu",
                "Renyu Zhu",
                "Shiwei Zhao",
                "Kai Wang",
                "Tangjie Lv",
                "Changjie Fan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14709v1",
                "http://arxiv.org/pdf/2311.14709v1"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08768v1",
            "title": "Three Conjectures on Unexpectedeness",
            "updated": "2023-11-15T08:24:41Z",
            "published": "2023-11-15T08:24:41Z",
            "summary": "Unexpectedness is a central concept in Simplicity Theory, a theory of\ncognition relating various inferential processes to the computation of\nKolmogorov complexities, rather than probabilities. Its predictive power has\nbeen confirmed by several experiments with human subjects, yet its theoretical\nbasis remains largely unexplored: why does it work? This paper lays the\ngroundwork for three theoretical conjectures. First, unexpectedness can be seen\nas a generalization of Bayes' rule. Second, the frequentist core of\nunexpectedness can be connected to the function of tracking ergodic properties\nof the world. Third, unexpectedness can be seen as constituent of various\nmeasures of divergence between the entropy of the world (environment) and the\nvariety of the observer (system). The resulting framework hints to research\ndirections that go beyond the division between probabilistic and logical\napproaches, potentially bringing new insights into the extraction of causal\nrelations, and into the role of descriptive mechanisms in learning.",
            "author": [
                "Giovanni Sileno",
                "Jean-Louis Dessalles"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08768v1",
                "http://arxiv.org/pdf/2311.08768v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.IT",
                "cs.SY",
                "eess.SY",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08765v1",
            "title": "Machine learning based dimension reduction for a stable modeling of\n  periodic flow phenomena",
            "updated": "2023-11-15T08:16:27Z",
            "published": "2023-11-15T08:16:27Z",
            "summary": "In designing efficient feedback control laws for fluid flow, the modern\ncontrol theory can serve as a powerful tool if the model can be represented by\na linear ordinary differential equation (ODE). However, it is generally\ndifficult to find such a linear model for strongly nonlinear and\nhigh-dimensional fluid flow phenomena. In this study, we propose an autoencoder\nwhich maps the periodic flow phenomena into a latent dynamics governed by a\nlinear ODE, referred to as a pseudo-symplectic Linear system Extracting\nAutoEncoder (LEAE). In addition to the normal functionality of autoencoder,\npseudo-symplectic LEAE emulates a symplectic time integration scheme so that\nthe Hamiltonian (i.e., the pseudo-energy) of the latent variables is conserved.\nWe demonstrate that the stability of the derived ODE is improved by considering\nthe integration stepping forward and backward at the same time. Here, we\nconsider the circular cylinder wake at $Re_D=100$ as a typical periodic flow\nphenomenon.",
            "author": [
                "Hiroshi Omichi",
                "Takeru Ishize",
                "Koji Fukagata"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08765v1",
                "http://arxiv.org/pdf/2311.08765v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08764v1",
            "title": "Combining Past, Present and Future: A Self-Supervised Approach for Class\n  Incremental Learning",
            "updated": "2023-11-15T08:13:52Z",
            "published": "2023-11-15T08:13:52Z",
            "summary": "Class Incremental Learning (CIL) aims to handle the scenario where data of\nnovel classes occur continuously and sequentially. The model should recognize\nthe sequential novel classes while alleviating the catastrophic forgetting. In\nthe self-supervised manner, it becomes more challenging to avoid the conflict\nbetween the feature embedding spaces of novel classes and old ones without any\nclass labels. To address the problem, we propose a self-supervised CIL\nframework CPPF, meaning Combining Past, Present and Future. In detail, CPPF\nconsists of a prototype clustering module (PC), an embedding space reserving\nmodule (ESR) and a multi-teacher distillation module (MTD). 1) The PC and the\nESR modules reserve embedding space for subsequent phases at the prototype\nlevel and the feature level respectively to prepare for knowledge learned in\nthe future. 2) The MTD module maintains the representations of the current\nphase without the interference of past knowledge. One of the teacher networks\nretains the representations of the past phases, and the other teacher network\ndistills relation information of the current phase to the student network.\nExtensive experiments on CIFAR100 and ImageNet100 datasets demonstrate that our\nproposed method boosts the performance of self-supervised class incremental\nlearning. We will release code in the near future.",
            "author": [
                "Xiaoshuang Chen",
                "Zhongyi Sun",
                "Ke Yan",
                "Shouhong Ding",
                "Hongtao Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08764v1",
                "http://arxiv.org/pdf/2311.08764v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08759v1",
            "title": "4K-Resolution Photo Exposure Correction at 125 FPS with ~8K Parameters",
            "updated": "2023-11-15T08:01:12Z",
            "published": "2023-11-15T08:01:12Z",
            "summary": "The illumination of improperly exposed photographs has been widely corrected\nusing deep convolutional neural networks or Transformers. Despite with\npromising performance, these methods usually suffer from large parameter\namounts and heavy computational FLOPs on high-resolution photographs. In this\npaper, we propose extremely light-weight (with only ~8K parameters) Multi-Scale\nLinear Transformation (MSLT) networks under the multi-layer perception\narchitecture, which can process 4K-resolution sRGB images at 125\nFrame-Per-Second (FPS) by a Titan RTX GPU. Specifically, the proposed MSLT\nnetworks first decompose an input image into high and low frequency layers by\nLaplacian pyramid techniques, and then sequentially correct different layers by\npixel-adaptive linear transformation, which is implemented by efficient\nbilateral grid learning or 1x1 convolutions. Experiments on two benchmark\ndatasets demonstrate the efficiency of our MSLTs against the state-of-the-arts\non photo exposure correction. Extensive ablation studies validate the\neffectiveness of our contributions. The code is available at\nhttps://github.com/Zhou-Yijie/MSLTNet.",
            "author": [
                "Yijie Zhou",
                "Chao Li",
                "Jin Liang",
                "Tianyi Xu",
                "Xin Liu",
                "Jun Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08759v1",
                "http://arxiv.org/pdf/2311.08759v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09264v1",
            "title": "Cross-domain feature disentanglement for interpretable modeling of tumor\n  microenvironment impact on drug response",
            "updated": "2023-11-15T07:50:54Z",
            "published": "2023-11-15T07:50:54Z",
            "summary": "High-throughput screening technology has facilitated the generation of\nlarge-scale drug responses across hundreds of cancer cell lines. However, there\nexists significant discrepancy between in vitro cell lines and actual tumors in\nvivo in terms of their response to drug treatments, because of tumors comprise\nof complex cellular compositions and histopathology structure, known as tumor\nmicroenvironment (TME), which greatly influences the drug cytotoxicity against\ntumor cells. To date, no study has focused on modeling the impact of the TME on\nclinical drug response. This paper proposed a domain adaptation network for\nfeature disentanglement to separate representations of cancer cells and TME of\na tumor in patients. Two denoising autoencoders were separately used to extract\nfeatures from cell lines (source domain) and tumors (target domain) for partial\ndomain alignment and feature decoupling. The specific encoder was enforced to\nextract information only about TME. Moreover, to ensure generalizability to\nnovel drugs, we applied a graph attention network to learn the latent\nrepresentation of drugs, allowing us to linearly model the drug perturbation on\ncellular state in latent space. We calibrated our model on a benchmark dataset\nand demonstrated its superior performance in predicting clinical drug response\nand dissecting the influence of the TME on drug efficacy.",
            "author": [
                "Jia Zhai",
                "Hui Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09264v1",
                "http://arxiv.org/pdf/2311.09264v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "q-bio.QM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08755v1",
            "title": "Environment-independent mmWave Fall Detection with Interacting Multiple\n  Model",
            "updated": "2023-11-15T07:49:46Z",
            "published": "2023-11-15T07:49:46Z",
            "summary": "The ageing society brings attention to daily elderly care through sensing\ntechnologies. The future smart home is expected to enable in-home daily\nmonitoring, such as fall detection, for seniors in a non-invasive,\nnon-cooperative, and non-contact manner. The mmWave radar is a promising\ncandidate technology for its privacy-preserving and non-contact manner.\nHowever, existing solutions suffer from low accuracy and robustness due to\nenvironment dependent features. In this paper, we present FADE\n(\\underline{FA}ll \\underline{DE}tection), a practical fall detection radar\nsystem with enhanced accuracy and robustness in real-world scenarios. The key\nenabler underlying FADE is an interacting multiple model (IMM) state estimator\nthat can extract environment-independent features for highly accurate and\ninstantaneous fall detection. Furthermore, we proposed a robust multiple-user\ntracking system to deal with noises from the environment and other human\nbodies. We deployed our algorithm on low computing power and low power\nconsumption system-on-chip (SoC) composed of data front end, DSP, and ARM\nprocessor, and tested its performance in real-world. The experiment shows that\nthe accuracy of fall detection is up to 95\\%.",
            "author": [
                "Xuyao Yu",
                "Jiazhao Wang",
                "Wenchao Jiang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08755v1",
                "http://arxiv.org/pdf/2311.08755v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08754v1",
            "title": "Semi-supervised machine learning model for Lagrangian flow state\n  estimation",
            "updated": "2023-11-15T07:48:27Z",
            "published": "2023-11-15T07:48:27Z",
            "summary": "In recent years, many researchers have demonstrated the strength of\nsupervised machine learning for flow state estimation. Most of the studies\nassume that the sensors are fixed and the high-resolution ground truth can be\nprepared. However, the sensors are not always fixed and may be floating in\npractical situations -- for example, in oceanography and river hydraulics,\nsensors are generally floating. In addition, floating sensors make it more\ndifficult to collect the high-resolution ground truth. We here propose a\nmachine learning model for state estimation from such floating sensors without\nrequiring high-resolution ground-truth data for training. This model estimates\nvelocity fields only from floating sensor measurements and is trained with a\nloss function using only sensor locations. We call this loss function as a\n\"semi-supervised\" loss function, since the sensor measurements are utilized as\nthe ground truth but high-resolution data of the entire velocity fields are not\nrequired. To demonstrate the performance of the proposed model, we consider\nStokes' second problem and two-dimensional decaying homogeneous isotropic\nturbulence. Our results reveal that the proposed semi-supervised model can\nestimate velocity fields with reasonable accuracy when the appropriate number\nof sensors are spatially distributed to some extent in the domain. We also\ndiscuss the dependence of the estimation accuracy on the number and\ndistribution of sensors.",
            "author": [
                "Reno Miura",
                "Koji Fukagata"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08754v1",
                "http://arxiv.org/pdf/2311.08754v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09263v1",
            "title": "Auto-ICL: In-Context Learning without Human Supervision",
            "updated": "2023-11-15T07:37:28Z",
            "published": "2023-11-15T07:37:28Z",
            "summary": "In the era of Large Language Models (LLMs), human-computer interaction has\nevolved towards natural language, offering unprecedented flexibility. Despite\nthis, LLMs are heavily reliant on well-structured prompts to function\nefficiently within the realm of In-Context Learning. Vanilla In-Context\nLearning relies on human-provided contexts, such as labeled examples, explicit\ninstructions, or other guiding mechanisms that shape the model's outputs. To\naddress this challenge, our study presents a universal framework named\nAutomatic In-Context Learning. Upon receiving a user's request, we ask the\nmodel to independently generate examples, including labels, instructions, or\nreasoning pathways. The model then leverages this self-produced context to\ntackle the given problem. Our approach is universally adaptable and can be\nimplemented in any setting where vanilla In-Context Learning is applicable. We\ndemonstrate that our method yields strong performance across a range of tasks,\nstanding up well when compared to existing methods.",
            "author": [
                "Jinghan Yang",
                "Shuming Ma",
                "Furu Wei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09263v1",
                "http://arxiv.org/pdf/2311.09263v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08747v1",
            "title": "Improved Dense Nested Attention Network Based on Transformer for\n  Infrared Small Target Detection",
            "updated": "2023-11-15T07:29:24Z",
            "published": "2023-11-15T07:29:24Z",
            "summary": "Infrared small target detection based on deep learning offers unique\nadvantages in separating small targets from complex and dynamic backgrounds.\nHowever, the features of infrared small targets gradually weaken as the depth\nof convolutional neural network (CNN) increases. To address this issue, we\npropose a novel method for detecting infrared small targets called improved\ndense nested attention network (IDNANet), which is based on the transformer\narchitecture. We preserve the dense nested structure of dense nested attention\nnetwork (DNANet) and introduce the Swin-transformer during feature extraction\nstage to enhance the continuity of features. Furthermore, we integrate the\nACmix attention structure into the dense nested structure to enhance the\nfeatures of intermediate layers. Additionally, we design a weighted dice binary\ncross-entropy (WD-BCE) loss function to mitigate the negative impact of\nforeground-background imbalance in the samples. Moreover, we develop a dataset\nspecifically for infrared small targets, called BIT-SIRST. The dataset\ncomprises a significant amount of real-world targets and manually annotated\nlabels, as well as synthetic data and corresponding labels. We have evaluated\nthe effectiveness of our method through experiments conducted on public\ndatasets. In comparison to other state-of-the-art methods, our approach\noutperforms in terms of probability of detection (P_d), false-alarm rate (F_a),\nand mean intersection of union ($mIoU$). The $mIoU$ reaches 90.89 on the\nNUDT-SIRST dataset and 79.72 on the NUAA-SIRST dataset.",
            "author": [
                "Chun Bao",
                "Jie Cao",
                "Yaqian Ning",
                "Tianhua Zhao",
                "Zhijun Li",
                "Zechen Wang",
                "Li Zhang",
                "Qun Hao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08747v1",
                "http://arxiv.org/pdf/2311.08747v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08745v3",
            "title": "Using Stochastic Gradient Descent to Smooth Nonconvex Functions:\n  Analysis of Implicit Graduated Optimization with Optimal Noise Scheduling",
            "updated": "2023-11-29T03:12:00Z",
            "published": "2023-11-15T07:27:40Z",
            "summary": "The graduated optimization approach is a heuristic method for finding\nglobally optimal solutions for nonconvex functions and has been theoretically\nanalyzed in several studies. This paper defines a new family of nonconvex\nfunctions for graduated optimization, discusses their sufficient conditions,\nand provides a convergence analysis of the graduated optimization algorithm for\nthem. It shows that stochastic gradient descent (SGD) with mini-batch\nstochastic gradients has the effect of smoothing the function, the degree of\nwhich is determined by the learning rate and batch size. This finding provides\ntheoretical insights on why large batch sizes fall into sharp local minima, why\ndecaying learning rates and increasing batch sizes are superior to fixed\nlearning rates and batch sizes, and what the optimal learning rate scheduling\nis. To the best of our knowledge, this is the first paper to provide a\ntheoretical explanation for these aspects. Moreover, a new graduated\noptimization framework that uses a decaying learning rate and increasing batch\nsize is analyzed and experimental results of image classification that support\nour theoretical findings are reported.",
            "author": [
                "Naoki Sato",
                "Hideaki Iiduka"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08745v3",
                "http://arxiv.org/pdf/2311.08745v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08744v1",
            "title": "Towards Graph-Aware Diffusion Modeling for Collaborative Filtering",
            "updated": "2023-11-15T07:25:14Z",
            "published": "2023-11-15T07:25:14Z",
            "summary": "Recovering masked feedback with neural models is a popular paradigm in\nrecommender systems. Seeing the success of diffusion models in solving\nill-posed inverse problems, we introduce a conditional diffusion framework for\ncollaborative filtering that iteratively reconstructs a user's hidden\npreferences guided by its historical interactions. To better align with the\nintrinsic characteristics of implicit feedback data, we implement forward\ndiffusion by applying synthetic smoothing filters to interaction signals on an\nitem-item graph. The resulting reverse diffusion can be interpreted as a\npersonalized process that gradually refines preference scores. Through graph\nFourier transform, we equivalently characterize this model as an anisotropic\nGaussian diffusion in the graph spectral domain, establishing both forward and\nreverse formulations. Our model outperforms state-of-the-art methods by a large\nmargin on one dataset and yields competitive results on the others.",
            "author": [
                "Yunqin Zhu",
                "Chao Wang",
                "Hui Xiong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08744v1",
                "http://arxiv.org/pdf/2311.08744v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08743v1",
            "title": "Kernel-based independence tests for causal structure learning on\n  functional data",
            "updated": "2023-11-15T07:23:28Z",
            "published": "2023-11-15T07:23:28Z",
            "summary": "Measurements of systems taken along a continuous functional dimension, such\nas time or space, are ubiquitous in many fields, from the physical and\nbiological sciences to economics and engineering.Such measurements can be\nviewed as realisations of an underlying smooth process sampled over the\ncontinuum. However, traditional methods for independence testing and causal\nlearning are not directly applicable to such data, as they do not take into\naccount the dependence along the functional dimension. By using specifically\ndesigned kernels, we introduce statistical tests for bivariate, joint, and\nconditional independence for functional variables. Our method not only extends\nthe applicability to functional data of the HSIC and its d-variate version\n(d-HSIC), but also allows us to introduce a test for conditional independence\nby defining a novel statistic for the CPT based on the HSCIC, with optimised\nregularisation strength estimated through an evaluation rejection rate. Our\nempirical results of the size and power of these tests on synthetic functional\ndata show good performance, and we then exemplify their application to several\nconstraint- and regression-based causal structure learning problems, including\nboth synthetic examples and real socio-economic data.",
            "author": [
                "Felix Laumann",
                "Julius von K\u00fcgelgen",
                "Junhyung Park",
                "Bernhard Sch\u00f6lkopf",
                "Mauricio Barahona"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08743v1",
                "http://arxiv.org/pdf/2311.08743v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08740v1",
            "title": "AdVENTR: Autonomous Robot Navigation in Complex Outdoor Environments",
            "updated": "2023-11-15T07:10:13Z",
            "published": "2023-11-15T07:10:13Z",
            "summary": "We present a novel system, AdVENTR for autonomous robot navigation in\nunstructured outdoor environments that consist of uneven and vegetated\nterrains. Our approach is general and can enable both wheeled and legged robots\nto handle outdoor terrain complexity including unevenness, surface properties\nlike poor traction, granularity, obstacle stiffness, etc. We use data from\nsensors including RGB cameras, 3D Lidar, IMU, robot odometry, and pose\ninformation with efficient learning-based perception and planning algorithms\nthat can execute on edge computing hardware. Our system uses a scene-aware\nswitching method to perceive the environment for navigation at any time instant\nand dynamically switches between multiple perception algorithms. We test our\nsystem in a variety of sloped, rocky, muddy, and densely vegetated terrains and\ndemonstrate its performance on Husky and Spot robots.",
            "author": [
                "Kasun Weerakoon",
                "Adarsh Jagan Sathyamoorthy",
                "Mohamed Elnoor",
                "Dinesh Manocha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08740v1",
                "http://arxiv.org/pdf/2311.08740v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08737v1",
            "title": "Probing Iron in Earth's Core With Molecular-Spin Dynamics",
            "updated": "2023-11-15T06:59:54Z",
            "published": "2023-11-15T06:59:54Z",
            "summary": "Dynamic compression of iron to Earth-core conditions is one of the few ways\nto gather important elastic and transport properties needed to uncover key\nmechanisms surrounding the geodynamo effect. Herein a new machine-learned\nab-initio derived molecular-spin dynamics (MSD) methodology with explicit\ntreatment for longitudinal spin-fluctuations is utilized to probe the dynamic\nphase-diagram of iron. This framework uniquely enables an accurate resolution\nof the phase-transition kinetics and Earth-core elastic properties, as\nhighlighted by compressional wave velocity and adiabatic bulk moduli\nmeasurements. In addition, a unique coupling of MSD with time-dependent density\nfunctional theory enables gauging electronic transport properties, critically\nimportant for resolving geodynamo dynamics.",
            "author": [
                "Svetoslav Nikolov",
                "Kushal Ramakrishna",
                "Andrew Rohskopf",
                "Mani Lokamani",
                "Julien Tranchida",
                "John Carpenter",
                "Attila Cangi",
                "Mitchell A. Wood"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08737v1",
                "http://arxiv.org/pdf/2311.08737v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08726v1",
            "title": "Uncertainty Estimation on Sequential Labeling via Uncertainty\n  Transmission",
            "updated": "2023-11-15T06:36:29Z",
            "published": "2023-11-15T06:36:29Z",
            "summary": "Sequential labeling is a task predicting labels for each token in a sequence,\nsuch as Named Entity Recognition (NER). NER tasks aim to extract entities and\npredict their labels given a text, which is important in information\nextraction. Although previous works have shown great progress in improving NER\nperformance, uncertainty estimation on NER (UE-NER) is still underexplored but\nessential. This work focuses on UE-NER, which aims to estimate uncertainty\nscores for the NER predictions. Previous uncertainty estimation models often\noverlook two unique characteristics of NER: the connection between entities\n(i.e., one entity embedding is learned based on the other ones) and wrong span\ncases in the entity extraction subtask. Therefore, we propose a Sequential\nLabeling Posterior Network (SLPN) to estimate uncertainty scores for the\nextracted entities, considering uncertainty transmitted from other tokens.\nMoreover, we have defined an evaluation strategy to address the specificity of\nwrong-span cases. Our SLPN has achieved significant improvements on two\ndatasets, such as a 5.54-point improvement in AUPR on the MIT-Restaurant\ndataset.",
            "author": [
                "Jianfeng He",
                "Linlin Yu",
                "Shuo Lei",
                "Chang-Tien Lu",
                "Feng Chen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08726v1",
                "http://arxiv.org/pdf/2311.08726v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08724v1",
            "title": "Method for Text Entity Linking in Power Distribution Scheduling Oriented\n  to Power Distribution Network Knowledge Graph",
            "updated": "2023-11-15T06:35:01Z",
            "published": "2023-11-15T06:35:01Z",
            "summary": "The proposed method for linking entities in power distribution dispatch texts\nto a power distribution network knowledge graph is based on a deep\nunderstanding of these networks. This method leverages the unique features of\nentities in both the power distribution network's knowledge graph and the\ndispatch texts, focusing on their semantic, phonetic, and syntactic\ncharacteristics. An enhanced model, the Lexical Semantic Feature-based Skip\nConvolutional Neural Network (LSF-SCNN), is utilized for effectively matching\ndispatch text entities with those in the knowledge graph. The efficacy of this\nmodel, compared to a control model, is evaluated through cross-validation\nmethods in real-world power distribution dispatch scenarios. The results\nindicate that the LSF-SCNN model excels in accurately linking a variety of\nentity types, demonstrating high overall accuracy in entity linking when the\nprocess is conducted in English.",
            "author": [
                "Xiang Li",
                "Che Wang",
                "Bing Li",
                "Hao Chen",
                "Sizhe Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08724v1",
                "http://arxiv.org/pdf/2311.08724v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09261v1",
            "title": "Emerging Drug Interaction Prediction Enabled by Flow-based Graph Neural\n  Network with Biomedical Network",
            "updated": "2023-11-15T06:34:00Z",
            "published": "2023-11-15T06:34:00Z",
            "summary": "Accurately predicting drug-drug interactions (DDI) for emerging drugs, which\noffer possibilities for treating and alleviating diseases, with computational\nmethods can improve patient care and contribute to efficient drug development.\nHowever, many existing computational methods require large amounts of known DDI\ninformation, which is scarce for emerging drugs. In this paper, we propose\nEmerGNN, a graph neural network (GNN) that can effectively predict interactions\nfor emerging drugs by leveraging the rich information in biomedical networks.\nEmerGNN learns pairwise representations of drugs by extracting the paths\nbetween drug pairs, propagating information from one drug to the other, and\nincorporating the relevant biomedical concepts on the paths. The different\nedges on the biomedical network are weighted to indicate the relevance for the\ntarget DDI prediction. Overall, EmerGNN has higher accuracy than existing\napproaches in predicting interactions for emerging drugs and can identify the\nmost relevant information on the biomedical network.",
            "author": [
                "Yongqi Zhang",
                "Quanming Yao",
                "Ling Yue",
                "Xian Wu",
                "Ziheng Zhang",
                "Zhenxi Lin",
                "Yefeng Zheng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09261v1",
                "http://arxiv.org/pdf/2311.09261v1"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.AI",
                "cs.CE",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08716v1",
            "title": "Scalable Federated Learning for Clients with Different Input Image Sizes\n  and Numbers of Output Categories",
            "updated": "2023-11-15T05:43:14Z",
            "published": "2023-11-15T05:43:14Z",
            "summary": "Federated learning is a privacy-preserving training method which consists of\ntraining from a plurality of clients but without sharing their confidential\ndata. However, previous work on federated learning do not explore suitable\nneural network architectures for clients with different input images sizes and\ndifferent numbers of output categories. In this paper, we propose an effective\nfederated learning method named ScalableFL, where the depths and widths of the\nlocal models for each client are adjusted according to the clients' input image\nsize and the numbers of output categories. In addition, we provide a new bound\nfor the generalization gap of federated learning. In particular, this bound\nhelps to explain the effectiveness of our scalable neural network approach. We\ndemonstrate the effectiveness of ScalableFL in several heterogeneous client\nsettings for both image classification and object detection tasks.",
            "author": [
                "Shuhei Nitta",
                "Taiji Suzuki",
                "Albert Rodr\u00edguez Mulet",
                "Atsushi Yaguchi",
                "Ryusuke Hirai"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08716v1",
                "http://arxiv.org/pdf/2311.08716v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08708v2",
            "title": "Joint User Pairing and Beamforming Design of Multi-STAR-RISs-Aided NOMA\n  in the Indoor Environment via Multi-Agent Reinforcement Learning",
            "updated": "2023-11-17T03:12:12Z",
            "published": "2023-11-15T05:18:36Z",
            "summary": "The development of 6G/B5G wireless networks, which have requirements that go\nbeyond current 5G networks, is gaining interest from academia and industry.\nHowever, to increase 6G/B5G network quality, conventional cellular networks\nthat rely on terrestrial base stations are constrained geographically and\neconomically. Meanwhile, NOMA allows multiple users to share the same\nresources, which improves the spectral efficiency of the system and has the\nadvantage of supporting a larger number of users. Additionally, by\nintelligently manipulating the phase and amplitude of both the reflected and\ntransmitted signals, STAR-RISs can achieve improved coverage, increased\nspectral efficiency, and enhanced communication reliability. However, STAR-RISs\nmust simultaneously optimize the amplitude and phase shift corresponding to\nreflection and transmission, which makes the existing terrestrial networks more\ncomplicated and is considered a major challenging issue. Motivated by the\nabove, we study the joint user pairing for NOMA and beamforming design of\nMulti-STAR-RISs in an indoor environment. Then, we formulate the optimization\nproblem with the objective of maximizing the total throughput of MUs by jointly\noptimizing the decoding order, user pairing, active beamforming, and passive\nbeamforming. However, the formulated problem is a MINLP. To address this\nchallenge, we first introduce the decoding order for NOMA networks. Next, we\ndecompose the original problem into two subproblems, namely: 1) MU pairing and\n2) Beamforming optimization under the optimal decoding order. For the first\nsubproblem, we employ correlation-based K-means clustering to solve the user\npairing problem. Then, to jointly deal with beamforming vector optimizations,\nwe propose MAPPO, which can make quick decisions in the given environment owing\nto its low complexity.",
            "author": [
                "Yu Min Park",
                "Yan Kyaw Tun",
                "Choong Seon Hong"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08708v2",
                "http://arxiv.org/pdf/2311.08708v2"
            ],
            "primary_category": "cs.IT",
            "category": [
                "cs.IT",
                "cs.AI",
                "cs.NI",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08704v1",
            "title": "Can Large Language Models Follow Concept Annotation Guidelines? A Case\n  Study on Scientific and Financial Domains",
            "updated": "2023-11-15T05:11:26Z",
            "published": "2023-11-15T05:11:26Z",
            "summary": "Although large language models (LLMs) exhibit remarkable capacity to leverage\nin-context demonstrations, it is still unclear to what extent they can learn\nnew concepts or facts from ground-truth labels. To address this question, we\nexamine the capacity of instruction-tuned LLMs to follow in-context concept\nguidelines for sentence labeling tasks. We design guidelines that present\ndifferent types of factual and counterfactual concept definitions, which are\nused as prompts for zero-shot sentence classification tasks. Our results show\nthat although concept definitions consistently help in task performance, only\nthe larger models (with 70B parameters or more) have limited ability to work\nunder counterfactual contexts. Importantly, only proprietary models such as\nGPT-3.5 and GPT-4 can recognize nonsensical guidelines, which we hypothesize is\ndue to more sophisticated alignment methods. Finally, we find that\nFalcon-180B-chat is outperformed by Llama-2-70B-chat is most cases, which\nindicates that careful fine-tuning is more effective than increasing model\nscale. Altogether, our simple evaluation method reveals significant gaps in\nconcept understanding between the most capable open-source language models and\nthe leading proprietary APIs.",
            "author": [
                "Marcio Fonseca",
                "Shay B. Cohen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08704v1",
                "http://arxiv.org/pdf/2311.08704v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08695v1",
            "title": "Attribute Diversity Determines the Systematicity Gap in VQA",
            "updated": "2023-11-15T04:50:30Z",
            "published": "2023-11-15T04:50:30Z",
            "summary": "The degree to which neural networks can generalize to new combinations of\nfamiliar concepts, and the conditions under which they are able to do so, has\nlong been an open question. In this work, we study the systematicity gap in\nvisual question answering: the performance difference between reasoning on\npreviously seen and unseen combinations of object attributes. To test, we\nintroduce a novel diagnostic dataset, CLEVR-HOPE. We find that while increased\nquantity of training data does not reduce the systematicity gap, increased\ntraining data diversity of the attributes in the unseen combination does. In\nall, our experiments suggest that the more distinct attribute type combinations\nare seen during training, the more systematic we can expect the resulting model\nto be.",
            "author": [
                "Ian Berlot-Attwell",
                "A. Michael Carrell",
                "Kumar Krishna Agrawal",
                "Yash Sharma",
                "Naomi Saphra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08695v1",
                "http://arxiv.org/pdf/2311.08695v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CL",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08692v1",
            "title": "Routing to the Expert: Efficient Reward-guided Ensemble of Large\n  Language Models",
            "updated": "2023-11-15T04:40:43Z",
            "published": "2023-11-15T04:40:43Z",
            "summary": "The complementary potential of Large Language Models (LLM) assumes\noff-the-shelf LLMs have heterogeneous expertise in a wide range of domains and\ntasks so that an ensemble of LLMs can achieve consistently better performance.\nExisting ensemble methods for LLMs mainly focus on reward model ranking of\noutputs, leading to significant computation overhead. To combat this issue, we\nrevisit the complementary potential of LLMs and further elaborate it by mining\nlatent expertise with off-the-shelf reward models. We propose Zooter, a\nreward-guided routing method distilling rewards on training queries to train a\nrouting function, which can precisely distribute each query to the LLM with\nexpertise about it. We also integrate a tag-based label enhancement to mitigate\nnoise from uncertainty when using rewards as silver supervision. Zooter shows\ncomputation efficiency in inference as it introduces only a minor computation\noverhead of a routing function compared with reward model ranking methods. We\nevaluate Zooter on a comprehensive benchmark collection with 26 subsets on\ndifferent domains and tasks. Zooter outperforms the best single model on\naverage and ranks first on 44% of tasks, even surpassing multiple reward model\nranking methods.",
            "author": [
                "Keming Lu",
                "Hongyi Yuan",
                "Runji Lin",
                "Junyang Lin",
                "Zheng Yuan",
                "Chang Zhou",
                "Jingren Zhou"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08692v1",
                "http://arxiv.org/pdf/2311.08692v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08690v1",
            "title": "Enabling CMF Estimation in Data-Constrained Scenarios: A\n  Semantic-Encoding Knowledge Mining Model",
            "updated": "2023-11-15T04:37:27Z",
            "published": "2023-11-15T04:37:27Z",
            "summary": "Precise estimation of Crash Modification Factors (CMFs) is central to\nevaluating the effectiveness of various road safety treatments and prioritizing\ninfrastructure investment accordingly. While customized study for each\ncountermeasure scenario is desired, the conventional CMF estimation approaches\nrely heavily on the availability of crash data at given sites. This not only\nmakes the estimation costly, but the results are also less transferable, since\nthe intrinsic similarities between different safety countermeasure scenarios\nare not fully explored. Aiming to fill this gap, this study introduces a novel\nknowledge-mining framework for CMF prediction. This framework delves into the\nconnections of existing countermeasures and reduces the reliance of CMF\nestimation on crash data availability and manual data collection. Specifically,\nit draws inspiration from human comprehension processes and introduces advanced\nNatural Language Processing (NLP) techniques to extract intricate variations\nand patterns from existing CMF knowledge. It effectively encodes unstructured\ncountermeasure scenarios into machine-readable representations and models the\ncomplex relationships between scenarios and CMF values. This new data-driven\nframework provides a cost-effective and adaptable solution that complements the\ncase-specific approaches for CMF estimation, which is particularly beneficial\nwhen availability of crash data or time imposes constraints. Experimental\nvalidation using real-world CMF Clearinghouse data demonstrates the\neffectiveness of this new approach, which shows significant accuracy\nimprovements compared to baseline methods. This approach provides insights into\nnew possibilities of harnessing accumulated transportation knowledge in various\napplications.",
            "author": [
                "Yanlin Qi",
                "Jia Li",
                "Michael Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08690v1",
                "http://arxiv.org/pdf/2311.08690v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CY",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08689v1",
            "title": "Low Complexity High Speed Deep Neural Network Augmented Wireless Channel\n  Estimation",
            "updated": "2023-11-15T04:35:25Z",
            "published": "2023-11-15T04:35:25Z",
            "summary": "The channel estimation (CE) in wireless receivers is one of the most critical\nand computationally complex signal processing operations. Recently, various\nworks have shown that the deep learning (DL) based CE outperforms conventional\nminimum mean square error (MMSE) based CE, and it is hardware-friendly.\nHowever, DL-based CE has higher complexity and latency than popularly used\nleast square (LS) based CE. In this work, we propose a novel low complexity\nhigh-speed Deep Neural Network-Augmented Least Square (LC-LSDNN) algorithm for\nIEEE 802.11p wireless physical layer and efficiently implement it on Zynq\nsystem on chip (ZSoC). The novelty of the LC-LSDNN is to use different DNNs for\nreal and imaginary values of received complex symbols. This helps reduce the\nsize of DL by 59% and optimize the critical path, allowing it to operate at 60%\nhigher clock frequency. We also explore three different architectures for\nMMSE-based CE. We show that LC-LSDNN significantly outperforms MMSE and\nstate-of-the-art DL-based CE for a wide range of signal-to-noise ratios (SNR)\nand different wireless channels. Also, it is computationally efficient, with\naround 50% lower resources than existing DL-based CE.",
            "author": [
                "Syed Asrar ul haq",
                "Varun Singh",
                "Bhanu Teja Tanaji",
                "Sumit Darak"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08689v1",
                "http://arxiv.org/pdf/2311.08689v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.AR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08687v1",
            "title": "An Eye on Clinical BERT: Investigating Language Model Generalization for\n  Diabetic Eye Disease Phenotyping",
            "updated": "2023-11-15T04:30:20Z",
            "published": "2023-11-15T04:30:20Z",
            "summary": "Diabetic eye disease is a major cause of blindness worldwide. The ability to\nmonitor relevant clinical trajectories and detect lapses in care is critical to\nmanaging the disease and preventing blindness. Alas, much of the information\nnecessary to support these goals is found only in the free text of the\nelectronic medical record. To fill this information gap, we introduce a system\nfor extracting evidence from clinical text of 19 clinical concepts related to\ndiabetic eye disease and inferring relevant attributes for each. In developing\nthis ophthalmology phenotyping system, we are also afforded a unique\nopportunity to evaluate the effectiveness of clinical language models at\nadapting to new clinical domains. Across multiple training paradigms, we find\nthat BERT language models pretrained on out-of-distribution clinical data offer\nno significant improvement over BERT language models pretrained on non-clinical\ndata for our domain. Our study tempers recent claims that language models\npretrained on clinical data are necessary for clinical NLP tasks and highlights\nthe importance of not treating clinical language data as a single homogeneous\ndomain.",
            "author": [
                "Keith Harrigian",
                "Tina Tang",
                "Anthony Gonzales",
                "Cindy X. Cai",
                "Mark Dredze"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08687v1",
                "http://arxiv.org/pdf/2311.08687v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09260v1",
            "title": "A Proposed Artificial Neural Network based Approach for Molecules Bitter\n  Prediction",
            "updated": "2023-11-15T04:22:29Z",
            "published": "2023-11-15T04:22:29Z",
            "summary": "In recent years, the development of Artificial Intelligence (AI) has offered\nthe possibility to tackle many interdisciplinary problems, and the field of\nchemistry is not an exception. Drug analysis is crucial in drug discovery,\nplaying an important role in human life. However, this task encounters many\ndifficulties due to the wide range of computational chemistry methods. Drug\nanalysis also involves a massive amount of work, including determining taste.\nThus, applying deep learning to predict a molecule's bitterness is inevitable\nto accelerate innovation in drug analysis by reducing the time spent. This\npaper proposes an artificial neural network (ANN) based approach (EC-ANN) for\nthe molecule's bitter prediction. Our approach took the SMILE (Simplified\nmolecular-input line-entry system) string of a molecule as the input data for\nthe prediction, and the 256-bit ECFP descriptor is the input vector for our\nnetwork. It showed impressive results compared to state-of-the-art, with a\nhigher performance on two out of three test sets according to the experiences\non three popular test sets: Phyto-Dictionary, Unimi, and Bitter-new set [1].\nFor the Phyto-Dictionary test set, our model recorded 0.95 and 0.983 in\nF1-score and AUPR, respectively, depicted as the highest score in F1-score. For\nthe Unimi test set, our model achieved 0.88 in F1-score and 0.88 in AUPR, which\nis roughly 12.3% higher than the peak of previous models [1, 2, 3, 4, 5].",
            "author": [
                "Huynh Quoc Anh Bui",
                "Trong Hop Do",
                "Thanh Binh Nguyen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09260v1",
                "http://arxiv.org/pdf/2311.09260v1"
            ],
            "primary_category": "q-bio.BM",
            "category": [
                "q-bio.BM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08685v1",
            "title": "Safer-Instruct: Aligning Language Models with Automated Preference Data",
            "updated": "2023-11-15T04:22:22Z",
            "published": "2023-11-15T04:22:22Z",
            "summary": "Reinforcement Learning from Human Feedback (RLHF) is a vital strategy for\nenhancing model safety in language models. However, annotating preference data\nfor RLHF is a resource-intensive and creativity-demanding process, while\nautomatic generation methods face limitations in data diversity and quality. In\nresponse, we present Safer-Instruct, a novel pipeline for semi-automatically\nconstructing large-scale preference datasets. Our approach leverages reversed\ninstruction tuning, instruction induction, and expert model evaluation to\nefficiently generate high-quality preference data without human annotators. We\nevaluate Safer-Instruct using LLaMA for instruction induction and GPT-4 as an\nexpert model, generating approximately 10K preference samples. Finetuning an\nAlpaca model on this dataset demonstrates improved harmlessness while\nmaintaining competitive performance on conversation and downstream tasks.\nSafer-Instruct addresses the challenges in preference data acquisition,\nadvancing the development of safer and more responsible AI systems. Our code\nand data are available at https://github.com/uscnlp-lime/safer-instruct",
            "author": [
                "Taiwei Shi",
                "Kai Chen",
                "Jieyu Zhao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08685v1",
                "http://arxiv.org/pdf/2311.08685v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08677v1",
            "title": "Federated Learning for Sparse Principal Component Analysis",
            "updated": "2023-11-15T03:55:28Z",
            "published": "2023-11-15T03:55:28Z",
            "summary": "In the rapidly evolving realm of machine learning, algorithm effectiveness\noften faces limitations due to data quality and availability. Traditional\napproaches grapple with data sharing due to legal and privacy concerns. The\nfederated learning framework addresses this challenge. Federated learning is a\ndecentralized approach where model training occurs on client sides, preserving\nprivacy by keeping data localized. Instead of sending raw data to a central\nserver, only model updates are exchanged, enhancing data security. We apply\nthis framework to Sparse Principal Component Analysis (SPCA) in this work. SPCA\naims to attain sparse component loadings while maximizing data variance for\nimproved interpretability. Beside the L1 norm regularization term in\nconventional SPCA, we add a smoothing function to facilitate gradient-based\noptimization methods. Moreover, in order to improve computational efficiency,\nwe introduce a least squares approximation to original SPCA. This enables\nanalytic solutions on the optimization processes, leading to substantial\ncomputational improvements. Within the federated framework, we formulate SPCA\nas a consensus optimization problem, which can be solved using the Alternating\nDirection Method of Multipliers (ADMM). Our extensive experiments involve both\nIID and non-IID random features across various data owners. Results on\nsynthetic and public datasets affirm the efficacy of our federated SPCA\napproach.",
            "author": [
                "Sin Cheng Ciou",
                "Pin Jui Chen",
                "Elvin Y. Tseng",
                "Yuh-Jye Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08677v1",
                "http://arxiv.org/pdf/2311.08677v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.DC",
                "cs.IT",
                "math.IT",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08675v1",
            "title": "Coreset Selection with Prioritized Multiple Objectives",
            "updated": "2023-11-15T03:43:04Z",
            "published": "2023-11-15T03:43:04Z",
            "summary": "Coreset selection is powerful in reducing computational costs and\naccelerating data processing for deep learning algorithms. It strives to\nidentify a small subset from large-scale data, so that training only on the\nsubset practically performs on par with full data. When coreset selection is\napplied in realistic scenes, under the premise that the identified coreset has\nachieved comparable model performance, practitioners regularly desire the\nidentified coreset can have a size as small as possible for lower costs and\ngreater acceleration. Motivated by this desideratum, for the first time, we\npose the problem of \"coreset selection with prioritized multiple objectives\",\nin which the smallest coreset size under model performance constraints is\nexplored. Moreover, to address this problem, an innovative method is proposed,\nwhich maintains optimization priority order over the model performance and\ncoreset size, and efficiently optimizes them in the coreset selection\nprocedure. Theoretically, we provide the convergence guarantee of the proposed\nmethod. Empirically, extensive experiments confirm its superiority compared\nwith previous strategies, often yielding better model performance with smaller\ncoreset sizes.",
            "author": [
                "Xiaobo Xia",
                "Jiale Liu",
                "Shaokun Zhang",
                "Qingyun Wu",
                "Tongliang Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08675v1",
                "http://arxiv.org/pdf/2311.08675v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08674v1",
            "title": "High-Precision Fruit Localization Using Active Laser-Camera Scanning:\n  Robust Laser Line Extraction for 2D-3D Transformation",
            "updated": "2023-11-15T03:39:27Z",
            "published": "2023-11-15T03:39:27Z",
            "summary": "Recent advancements in deep learning-based approaches have led to remarkable\nprogress in fruit detection, enabling robust fruit identification in complex\nenvironments. However, much less progress has been made on fruit 3D\nlocalization, which is equally crucial for robotic harvesting. Complex fruit\nshape/orientation, fruit clustering, varying lighting conditions, and\nocclusions by leaves and branches have greatly restricted existing sensors from\nachieving accurate fruit localization in the natural orchard environment. In\nthis paper, we report on the design of a novel localization technique, called\nActive Laser-Camera Scanning (ALACS), to achieve accurate and robust fruit 3D\nlocalization. The ALACS hardware setup comprises a red line laser, an RGB color\ncamera, a linear motion slide, and an external RGB-D camera. Leveraging the\nprinciples of dynamic-targeting laser-triangulation, ALACS enables precise\ntransformation of the projected 2D laser line from the surface of apples to the\n3D positions. To facilitate laser pattern acquisitions, a Laser Line Extraction\n(LLE) method is proposed for robust and high-precision feature extraction on\napples. Comprehensive evaluations of LLE demonstrated its ability to extract\nprecise patterns under variable lighting and occlusion conditions. The ALACS\nsystem achieved average apple localization accuracies of 6.9 11.2 mm at\ndistances ranging from 1.0 m to 1.6 m, compared to 21.5 mm by a commercial\nRealSense RGB-D camera, in an indoor experiment. Orchard evaluations\ndemonstrated that ALACS has achieved a 95% fruit detachment rate versus a 71%\nrate by the RealSense camera. By overcoming the challenges of apple 3D\nlocalization, this research contributes to the advancement of robotic fruit\nharvesting technology.",
            "author": [
                "Pengyu Chu",
                "Zhaojian Li",
                "Kaixiang Zhang",
                "Kyle Lammers",
                "Renfu Lu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08674v1",
                "http://arxiv.org/pdf/2311.08674v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08670v1",
            "title": "CLN-VC: Text-Free Voice Conversion Based on Fine-Grained Style Control\n  and Contrastive Learning with Negative Samples Augmentation",
            "updated": "2023-11-15T03:29:31Z",
            "published": "2023-11-15T03:29:31Z",
            "summary": "Better disentanglement of speech representation is essential to improve the\nquality of voice conversion. Recently contrastive learning is applied to voice\nconversion successfully based on speaker labels. However, the performance of\nmodel will reduce in conversion between similar speakers. Hence, we propose an\naugmented negative sample selection to address the issue. Specifically, we\ncreate hard negative samples based on the proposed speaker fusion module to\nimprove learning ability of speaker encoder. Furthermore, considering the\nfine-grain modeling of speaker style, we employ a reference encoder to extract\nfine-grained style and conduct the augmented contrastive learning on global\nstyle. The experimental results show that the proposed method outperforms\nprevious work in voice conversion tasks.",
            "author": [
                "Yimin Deng",
                "Xulong Zhang",
                "Jianzong Wang",
                "Ning Cheng",
                "Jing Xiao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08670v1",
                "http://arxiv.org/pdf/2311.08670v1"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08669v1",
            "title": "Understanding Calibration for Multilingual Question Answering Models",
            "updated": "2023-11-15T03:29:02Z",
            "published": "2023-11-15T03:29:02Z",
            "summary": "Multilingual pre-trained language models are incredibly effective at Question\nAnswering (QA), a core task in Natural Language Understanding, achieving high\naccuracies on several multilingual benchmarks. However, little is known about\nhow well they are calibrated. In this paper, we study the calibration\nproperties of several pre-trained multilingual large language models (LLMs) on\na variety of question-answering tasks. We perform extensive experiments,\nspanning both extractive and generative QA model designs and diverse languages,\nspanning both high-resource and low-resource ones. We study different\ndimensions of calibration in in-distribution, out-of-distribution, and\ncross-lingual transfer settings, and investigate strategies to improve it,\nincluding post-hoc methods and regularized fine-tuning. We demonstrate\nautomatically translated data augmentation as a highly effective technique to\nimprove model calibration. We also conduct a number of ablation experiments to\nstudy the effect of model size on calibration and how multilingual models\ncompare with their monolingual counterparts for diverse tasks and languages.",
            "author": [
                "Yahan Yang",
                "Soham Dan",
                "Dan Roth",
                "Insup Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08669v1",
                "http://arxiv.org/pdf/2311.08669v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08667v2",
            "title": "EDMSound: Spectrogram Based Diffusion Models for Efficient and\n  High-Quality Audio Synthesis",
            "updated": "2023-11-18T15:16:16Z",
            "published": "2023-11-15T03:27:35Z",
            "summary": "Audio diffusion models can synthesize a wide variety of sounds. Existing\nmodels often operate on the latent domain with cascaded phase recovery modules\nto reconstruct waveform. This poses challenges when generating high-fidelity\naudio. In this paper, we propose EDMSound, a diffusion-based generative model\nin spectrogram domain under the framework of elucidated diffusion models (EDM).\nCombining with efficient deterministic sampler, we achieved similar Fr\\'echet\naudio distance (FAD) score as top-ranked baseline with only 10 steps and\nreached state-of-the-art performance with 50 steps on the DCASE2023 foley sound\ngeneration benchmark. We also revealed a potential concern regarding diffusion\nbased audio generation models that they tend to generate samples with high\nperceptual similarity to the data from training data. Project page:\nhttps://agentcooper2002.github.io/EDMSound/",
            "author": [
                "Ge Zhu",
                "Yutong Wen",
                "Marc-Andr\u00e9 Carbonneau",
                "Zhiyao Duan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08667v2",
                "http://arxiv.org/pdf/2311.08667v2"
            ],
            "primary_category": "cs.SD",
            "category": [
                "cs.SD",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08666v1",
            "title": "It Takes Two to Negotiate: Modeling Social Exchange in Online\n  Multiplayer Games",
            "updated": "2023-11-15T03:21:04Z",
            "published": "2023-11-15T03:21:04Z",
            "summary": "Online games are dynamic environments where players interact with each other,\nwhich offers a rich setting for understanding how players negotiate their way\nthrough the game to an ultimate victory. This work studies online player\ninteractions during the turn-based strategy game, Diplomacy. We annotated a\ndataset of over 10,000 chat messages for different negotiation strategies and\nempirically examined their importance in predicting long- and short-term game\noutcomes. Although negotiation strategies can be predicted reasonably\naccurately through the linguistic modeling of the chat messages, more is needed\nfor predicting short-term outcomes such as trustworthiness. On the other hand,\nthey are essential in graph-aware reinforcement learning approaches to predict\nlong-term outcomes, such as a player's success, based on their prior\nnegotiation history. We close with a discussion of the implications and impact\nof our work. The dataset is available at\nhttps://github.com/kj2013/claff-diplomacy.",
            "author": [
                "Kokil Jaidka",
                "Hansin Ahuja",
                "Lynnette Ng"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08666v1",
                "http://arxiv.org/pdf/2311.08666v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.GT",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08661v1",
            "title": "Deep Neural Network Identification of Limnonectes Species and New Class\n  Detection Using Image Data",
            "updated": "2023-11-15T02:57:59Z",
            "published": "2023-11-15T02:57:59Z",
            "summary": "As is true of many complex tasks, the work of discovering, describing, and\nunderstanding the diversity of life on Earth (viz., biological systematics and\ntaxonomy) requires many tools. Some of this work can be accomplished as it has\nbeen done in the past, but some aspects present us with challenges which\ntraditional knowledge and tools cannot adequately resolve. One such challenge\nis presented by species complexes in which the morphological similarities among\nthe group members make it difficult to reliably identify known species and\ndetect new ones. We address this challenge by developing new tools using the\nprinciples of machine learning to resolve two specific questions related to\nspecies complexes. The first question is formulated as a classification problem\nin statistics and machine learning and the second question is an\nout-of-distribution (OOD) detection problem. We apply these tools to a species\ncomplex comprising Southeast Asian stream frogs (Limnonectes kuhlii complex)\nand employ a morphological character (hind limb skin texture) traditionally\ntreated qualitatively in a quantitative and objective manner. We demonstrate\nthat deep neural networks can successfully automate the classification of an\nimage into a known species group for which it has been trained. We further\ndemonstrate that the algorithm can successfully classify an image into a new\nclass if the image does not belong to the existing classes. Additionally, we\nuse the larger MNIST dataset to test the performance of our OOD detection\nalgorithm. We finish our paper with some concluding remarks regarding the\napplication of these methods to species complexes and our efforts to document\ntrue biodiversity. This paper has online supplementary materials.",
            "author": [
                "Li Xu",
                "Yili Hong",
                "Eric P. Smith",
                "David S. McLeod",
                "Xinwei Deng",
                "Laura J. Freeman"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08661v1",
                "http://arxiv.org/pdf/2311.08661v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08658v1",
            "title": "Structured Estimation of Heterogeneous Time Series",
            "updated": "2023-11-15T02:39:13Z",
            "published": "2023-11-15T02:39:13Z",
            "summary": "How best to model structurally heterogeneous processes is a foundational\nquestion in the social, health and behavioral sciences. Recently, Fisher et\nal., (2022) introduced the multi-VAR approach for simultaneously estimating\nmultiple-subject multivariate time series characterized by common and\nindividualizing features using penalized estimation. This approach differs from\nmany popular modeling approaches for multiple-subject time series in that\nqualitative and quantitative differences in a large number of individual\ndynamics are well-accommodated. The current work extends the multi-VAR\nframework to include new adaptive weighting schemes that greatly improve\nestimation performance. In a small set of simulation studies we compare\nadaptive multi-VAR with these new penalty weights to common alternative\nestimators in terms of path recovery and bias. Furthermore, we provide toy\nexamples and code demonstrating the utility of multi-VAR under different\nheterogeneity regimes using the multivar package for R (Fisher, 2022).",
            "author": [
                "Zachary F. Fisher",
                "Younghoon Kim",
                "Vladas Pipiras",
                "Christopher Crawford",
                "Daniel J. Petrie",
                "Michael D. Hunter",
                "Charles F. Geier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08658v1",
                "http://arxiv.org/pdf/2311.08658v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08657v1",
            "title": "ConeQuest: A Benchmark for Cone Segmentation on Mars",
            "updated": "2023-11-15T02:33:08Z",
            "published": "2023-11-15T02:33:08Z",
            "summary": "Over the years, space scientists have collected terabytes of Mars data from\nsatellites and rovers. One important set of features identified in Mars orbital\nimages is pitted cones, which are interpreted to be mud volcanoes believed to\nform in regions that were once saturated in water (i.e., a lake or ocean).\nIdentifying pitted cones globally on Mars would be of great importance, but\nexpert geologists are unable to sort through the massive orbital image archives\nto identify all examples. However, this task is well suited for computer\nvision. Although several computer vision datasets exist for various\nMars-related tasks, there is currently no open-source dataset available for\ncone detection/segmentation. Furthermore, previous studies trained models using\ndata from a single region, which limits their applicability for global\ndetection and mapping. Motivated by this, we introduce ConeQuest, the first\nexpert-annotated public dataset to identify cones on Mars. ConeQuest consists\nof >13k samples from 3 different regions of Mars. We propose two benchmark\ntasks using ConeQuest: (i) Spatial Generalization and (ii) Cone-size\nGeneralization. We finetune and evaluate widely-used segmentation models on\nboth benchmark tasks. Results indicate that cone segmentation is a challenging\nopen problem not solved by existing segmentation models, which achieve an\naverage IoU of 52.52% and 42.55% on in-distribution data for tasks (i) and\n(ii), respectively. We believe this new benchmark dataset will facilitate the\ndevelopment of more accurate and robust models for cone segmentation. Data and\ncode are available at https://github.com/kerner-lab/ConeQuest.",
            "author": [
                "Mirali Purohit",
                "Jacob Adler",
                "Hannah Kerner"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08657v1",
                "http://arxiv.org/pdf/2311.08657v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08655v1",
            "title": "Review of AlexNet for Medical Image Classification",
            "updated": "2023-11-15T02:28:52Z",
            "published": "2023-11-15T02:28:52Z",
            "summary": "In recent years, the rapid development of deep learning has led to a wide\nrange of applications in the field of medical image classification. The\nvariants of neural network models with ever-increasing performance share some\ncommonalities: to try to mitigate overfitting, improve generalization, avoid\ngradient vanishing and exploding, etc. AlexNet first utilizes the dropout\ntechnique to mitigate overfitting and the ReLU activation function to avoid\ngradient vanishing. Therefore, we focus our discussion on AlexNet, which has\ncontributed greatly to the development of CNNs in 2012. After reviewing over 40\npapers, including journal papers and conference papers, we give a narrative on\nthe technical details, advantages, and application areas of AlexNet.",
            "author": [
                "Wenhao Tang",
                "Junding Sun",
                "Shuihua Wang",
                "Yudong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08655v1",
                "http://arxiv.org/pdf/2311.08655v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08652v1",
            "title": "Refining Perception Contracts: Case Studies in Vision-based Safe\n  Auto-landing",
            "updated": "2023-11-15T02:26:41Z",
            "published": "2023-11-15T02:26:41Z",
            "summary": "Perception contracts provide a method for evaluating safety of control\nsystems that use machine learning for perception. A perception contract is a\nspecification for testing the ML components, and it gives a method for proving\nend-to-end system-level safety requirements. The feasibility of contract-based\ntesting and assurance was established earlier in the context of straight lane\nkeeping: a 3-dimensional system with relatively simple dynamics. This paper\npresents the analysis of two 6 and 12-dimensional flight control systems that\nuse multi-stage, heterogeneous, ML-enabled perception. The paper advances\nmethodology by introducing an algorithm for constructing data and requirement\nguided refinement of perception contracts (DaRePC). The resulting analysis\nprovides testable contracts which establish the state and environment\nconditions under which an aircraft can safety touchdown on the runway and a\ndrone can safely pass through a sequence of gates. It can also discover\nconditions (e.g., low-horizon sun) that can possibly violate the safety of the\nvision-based control system.",
            "author": [
                "Yangge Li",
                "Benjamin C Yang",
                "Yixuan Jia",
                "Daniel Zhuang",
                "Sayan Mitra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08652v1",
                "http://arxiv.org/pdf/2311.08652v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08648v1",
            "title": "Explore Spurious Correlations at the Concept Level in Language Models\n  for Text Classification",
            "updated": "2023-11-15T01:58:54Z",
            "published": "2023-11-15T01:58:54Z",
            "summary": "Language models (LMs) have gained great achievement in various NLP tasks for\nboth fine-tuning and in-context learning (ICL) methods. Despite its outstanding\nperformance, evidence shows that spurious correlations caused by imbalanced\nlabel distributions in training data (or exemplars in ICL) lead to robustness\nissues. However, previous studies mostly focus on word- and phrase-level\nfeatures and fail to tackle it from the concept level, partly due to the lack\nof concept labels and subtle and diverse expressions of concepts in text. In\nthis paper, we first use the LLM to label the concept for each text and then\nmeasure the concept bias of models for fine-tuning or ICL on the test data.\nSecond, we propose a data rebalancing method to mitigate the spurious\ncorrelations by adding the LLM-generated counterfactual data to make a balanced\nlabel distribution for each concept. We verify the effectiveness of our\nmitigation method and show its superiority over the token removal method.\nOverall, our results show that there exist label distribution biases in\nconcepts across multiple text classification datasets, and LMs will utilize\nthese shortcuts to make predictions in both fine-tuning and ICL methods.",
            "author": [
                "Yuhang Zhou",
                "Paiheng Xu",
                "Xiaoyu Liu",
                "Bang An",
                "Wei Ai",
                "Furong Huang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08648v1",
                "http://arxiv.org/pdf/2311.08648v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08646v1",
            "title": "Painterly Image Harmonization via Adversarial Residual Learning",
            "updated": "2023-11-15T01:53:46Z",
            "published": "2023-11-15T01:53:46Z",
            "summary": "Image compositing plays a vital role in photo editing. After inserting a\nforeground object into another background image, the composite image may look\nunnatural and inharmonious. When the foreground is photorealistic and the\nbackground is an artistic painting, painterly image harmonization aims to\ntransfer the style of background painting to the foreground object, which is a\nchallenging task due to the large domain gap between foreground and background.\nIn this work, we employ adversarial learning to bridge the domain gap between\nforeground feature map and background feature map. Specifically, we design a\ndual-encoder generator, in which the residual encoder produces the residual\nfeatures added to the foreground feature map from main encoder. Then, a\npixel-wise discriminator plays against the generator, encouraging the refined\nforeground feature map to be indistinguishable from background feature map.\nExtensive experiments demonstrate that our method could achieve more harmonious\nand visually appealing results than previous methods.",
            "author": [
                "Xudong Wang",
                "Li Niu",
                "Junyan Cao",
                "Yan Hong",
                "Liqing Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08646v1",
                "http://arxiv.org/pdf/2311.08646v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08644v1",
            "title": "Interpretable by Design: Wrapper Boxes Combine Neural Performance with\n  Faithful Explanations",
            "updated": "2023-11-15T01:50:53Z",
            "published": "2023-11-15T01:50:53Z",
            "summary": "Can we preserve the accuracy of neural models while also providing faithful\nexplanations? We present wrapper boxes, a general approach to generate\nfaithful, example-based explanations for model predictions while maintaining\npredictive performance. After training a neural model as usual, its learned\nfeature representation is input to a classic, interpretable model to perform\nthe actual prediction. This simple strategy is surprisingly effective, with\nresults largely comparable to those of the original neural model, as shown\nacross three large pre-trained language models, two datasets of varying scale,\nfour classic models, and four evaluation metrics. Moreover, because these\nclassic models are interpretable by design, the subset of training examples\nthat determine classic model predictions can be shown directly to users.",
            "author": [
                "Yiheng Su",
                "Juni Jessy Li",
                "Matthew Lease"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08644v1",
                "http://arxiv.org/pdf/2311.08644v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08640v1",
            "title": "Multistage Collaborative Knowledge Distillation from Large Language\n  Models",
            "updated": "2023-11-15T01:28:28Z",
            "published": "2023-11-15T01:28:28Z",
            "summary": "We study semi-supervised sequence prediction tasks where labeled data are too\nscarce to effectively finetune a model and at the same time few-shot prompting\nof a large language model (LLM) has suboptimal performance. This happens when a\ntask, such as parsing, is expensive to annotate and also unfamiliar to a\npretrained LLM. In this paper, we present a discovery that student models\ndistilled from a prompted LLM can often generalize better than their teacher on\nsuch tasks. Leveraging this finding, we propose a new distillation method,\nmultistage collaborative knowledge distillation from an LLM (MCKD), for such\ntasks. MCKD first prompts an LLM using few-shot in-context learning to produce\npseudolabels for unlabeled data. Then, at each stage of distillation, a pair of\nstudents are trained on disjoint partitions of the pseudolabeled data. Each\nstudent subsequently produces new and improved pseudolabels for the unseen\npartition to supervise the next round of student(s) with. We show the benefit\nof multistage cross-partition labeling on two constituency parsing tasks. On\nCRAFT biomedical parsing, 3-stage MCKD with 50 labeled examples matches the\nperformance of supervised finetuning with 500 examples and outperforms the\nprompted LLM and vanilla KD by 7.5% and 3.7% parsing F1, respectively.",
            "author": [
                "Jiachen Zhao",
                "Wenlong Zhao",
                "Andrew Drozdov",
                "Benjamin Rozonoyer",
                "Md Arafat Sultan",
                "Jay-Yoon Lee",
                "Mohit Iyyer",
                "Andrew McCallum"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08640v1",
                "http://arxiv.org/pdf/2311.08640v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08636v1",
            "title": "Supervised low-rank semi-nonnegative matrix factorization with frequency\n  regularization for forecasting spatio-temporal data",
            "updated": "2023-11-15T01:23:13Z",
            "published": "2023-11-15T01:23:13Z",
            "summary": "We propose a novel methodology for forecasting spatio-temporal data using\nsupervised semi-nonnegative matrix factorization (SSNMF) with frequency\nregularization. Matrix factorization is employed to decompose spatio-temporal\ndata into spatial and temporal components. To improve clarity in the temporal\npatterns, we introduce a nonnegativity constraint on the time domain along with\nregularization in the frequency domain. Specifically, regularization in the\nfrequency domain involves selecting features in the frequency space, making an\ninterpretation in the frequency domain more convenient. We propose two methods\nin the frequency domain: soft and hard regularizations, and provide convergence\nguarantees to first-order stationary points of the corresponding constrained\noptimization problem. While our primary motivation stems from geophysical data\nanalysis based on GRACE (Gravity Recovery and Climate Experiment) data, our\nmethodology has the potential for wider application. Consequently, when\napplying our methodology to GRACE data, we find that the results with the\nproposed methodology are comparable to previous research in the field of\ngeophysical sciences but offer clearer interpretability.",
            "author": [
                "Keunsu Kim",
                "Hanbaek Lyu",
                "Jinsu Kim",
                "Jae-Hun Jung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08636v1",
                "http://arxiv.org/pdf/2311.08636v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "65F22, 65F55 and 86A04"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08635v1",
            "title": "Spatio-Temporal Graph Neural Point Process for Traffic Congestion Event\n  Prediction",
            "updated": "2023-11-15T01:22:47Z",
            "published": "2023-11-15T01:22:47Z",
            "summary": "Traffic congestion event prediction is an important yet challenging task in\nintelligent transportation systems. Many existing works about traffic\nprediction integrate various temporal encoders and graph convolution networks\n(GCNs), called spatio-temporal graph-based neural networks, which focus on\npredicting dense variables such as flow, speed and demand in time snapshots,\nbut they can hardly forecast the traffic congestion events that are sparsely\ndistributed on the continuous time axis. In recent years, neural point process\n(NPP) has emerged as an appropriate framework for event prediction in\ncontinuous time scenarios. However, most conventional works about NPP cannot\nmodel the complex spatio-temporal dependencies and congestion evolution\npatterns. To address these limitations, we propose a spatio-temporal graph\nneural point process framework, named STGNPP for traffic congestion event\nprediction. Specifically, we first design the spatio-temporal graph learning\nmodule to fully capture the long-range spatio-temporal dependencies from the\nhistorical traffic state data along with the road network. The extracted\nspatio-temporal hidden representation and congestion event information are then\nfed into a continuous gated recurrent unit to model the congestion evolution\npatterns. In particular, to fully exploit the periodic information, we also\nimprove the intensity function calculation of the point process with a periodic\ngated mechanism. Finally, our model simultaneously predicts the occurrence time\nand duration of the next congestion. Extensive experiments on two real-world\ndatasets demonstrate that our method achieves superior performance in\ncomparison to existing state-of-the-art approaches.",
            "author": [
                "Guangyin Jin",
                "Lingbo Liu",
                "Fuxian Li",
                "Jincai Huang"
            ],
            "link": [
                "http://dx.doi.org/10.1609/aaai.v37i12.26669",
                "http://arxiv.org/abs/2311.08635v1",
                "http://arxiv.org/pdf/2311.08635v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.SI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08631v2",
            "title": "Influence of Video Dynamics on EEG-based Single-Trial Video Target\n  Surveillance Syste",
            "updated": "2023-11-19T03:00:35Z",
            "published": "2023-11-15T01:10:24Z",
            "summary": "Target detection models are one of the widely used deep learning-based\napplications for reducing human efforts on video surveillance and patrol.\nHowever, the application of conventional computer vision-based target detection\nmodels in military usage can result in limited performance, due to the lack of\nsample data of hostile targets. In this paper, we present the possibility of\nthe electroencephalography-based video target detection model, which could be\napplied as a supportive module of the military video surveillance system. The\nproposed framework and detection model showed prospective performance achieving\na mean macro F-beta of 0.6522 with asynchronous real-time data from five\nsubjects, in a certain video stimulus, but not on some video stimuli. By\nanalyzing the results of experiments using each video stimulus, we present the\nfactors that would affect the performance of electroencephalography-based video\ntarget detection models.",
            "author": [
                "Heon-Gyu Kwak",
                "Sung-Jin Kim",
                "Hyeon-Taek Han",
                "Ji-Hoon Jeong",
                "Seong-Whan Lee"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08631v2",
                "http://arxiv.org/pdf/2311.08631v2"
            ],
            "primary_category": "cs.HC",
            "category": [
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08624v1",
            "title": "Flow control by a hybrid use of machine learning and control theory",
            "updated": "2023-11-15T01:01:57Z",
            "published": "2023-11-15T01:01:57Z",
            "summary": "Flow control has a great potential to contribute to the sustainable society\nthrough mitigation of environmental burden. However, high dimensional and\nnonlinear nature of fluid flows poses challenges in designing efficient control\nlaws. This paper aims to propose a hybrid method (i.e., machine learning and\ncontrol theory) for feedback control of fluid flows. We propose a partially\nnonlinear linear-system extraction autoencoder (pn-LEAE), which consists of\nconvolutional neural networks-based autoencoder (CNN-AE) and a custom layer to\nextract a low-dimensional latent dynamics. This pn-LEAE basically extracts a\nlinear dynamical system so that the modern control theory can easily be\napplied, but at the same time, it is designed to capture a nonlinear\ndevelopment of the latent dynamics. We demonstrate the effectiveness of the\nlinear system extracted by the pn-LEAE, as well as the designed control law's\neffectiveness for a flow around a circular cylinder at the Reynolds number of\n${\\rm Re}_{D}=100$. This is the first attempt utilizing CNN-AE for\nlinearization of fluid flows involving transient development to design a\nfeedback control law.",
            "author": [
                "Takeru Ishize",
                "Hiroshi Omichi",
                "Koji Fukagata"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08624v1",
                "http://arxiv.org/pdf/2311.08624v1"
            ],
            "primary_category": "physics.flu-dyn",
            "category": [
                "physics.flu-dyn",
                "physics.comp-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08623v1",
            "title": "DEED: Dynamic Early Exit on Decoder for Accelerating Encoder-Decoder\n  Transformer Models",
            "updated": "2023-11-15T01:01:02Z",
            "published": "2023-11-15T01:01:02Z",
            "summary": "Encoder-decoder transformer models have achieved great success on various\nvision-language (VL) tasks, but they suffer from high inference latency.\nTypically, the decoder takes up most of the latency because of the\nauto-regressive decoding. To accelerate the inference, we propose an approach\nof performing Dynamic Early Exit on Decoder (DEED). We build a multi-exit\nencoder-decoder transformer model which is trained with deep supervision so\nthat each of its decoder layers is capable of generating plausible predictions.\nIn addition, we leverage simple yet practical techniques, including shared\ngeneration head and adaptation modules, to keep accuracy when exiting at\nshallow decoder layers. Based on the multi-exit model, we perform step-level\ndynamic early exit during inference, where the model may decide to use fewer\ndecoder layers based on its confidence of the current layer at each individual\ndecoding step. Considering different number of decoder layers may be used at\ndifferent decoding steps, we compute deeper-layer decoder features of previous\ndecoding steps just-in-time, which ensures the features from different decoding\nsteps are semantically aligned. We evaluate our approach with two\nstate-of-the-art encoder-decoder transformer models on various VL tasks. We\nshow our approach can reduce overall inference latency by 30%-60% with\ncomparable or even higher accuracy compared to baselines.",
            "author": [
                "Peng Tang",
                "Pengkai Zhu",
                "Tian Li",
                "Srikar Appalaraju",
                "Vijay Mahadevan",
                "R. Manmatha"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08623v1",
                "http://arxiv.org/pdf/2311.08623v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08622v1",
            "title": "Multiple-Question Multiple-Answer Text-VQA",
            "updated": "2023-11-15T01:00:02Z",
            "published": "2023-11-15T01:00:02Z",
            "summary": "We present Multiple-Question Multiple-Answer (MQMA), a novel approach to do\ntext-VQA in encoder-decoder transformer models. The text-VQA task requires a\nmodel to answer a question by understanding multi-modal content: text\n(typically from OCR) and an associated image. To the best of our knowledge,\nalmost all previous approaches for text-VQA process a single question and its\nassociated content to predict a single answer. In order to answer multiple\nquestions from the same image, each question and content are fed into the model\nmultiple times. In contrast, our proposed MQMA approach takes multiple\nquestions and content as input at the encoder and predicts multiple answers at\nthe decoder in an auto-regressive manner at the same time. We make several\nnovel architectural modifications to standard encoder-decoder transformers to\nsupport MQMA. We also propose a novel MQMA denoising pre-training task which is\ndesigned to teach the model to align and delineate multiple questions and\ncontent with associated answers. MQMA pre-trained model achieves\nstate-of-the-art results on multiple text-VQA datasets, each with strong\nbaselines. Specifically, on OCR-VQA (+2.5%), TextVQA (+1.4%), ST-VQA (+0.6%),\nDocVQA (+1.1%) absolute improvements over the previous state-of-the-art\napproaches.",
            "author": [
                "Peng Tang",
                "Srikar Appalaraju",
                "R. Manmatha",
                "Yusheng Xie",
                "Vijay Mahadevan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08622v1",
                "http://arxiv.org/pdf/2311.08622v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08621v1",
            "title": "Cross Device Federated Intrusion Detector for Early Stage Botnet\n  Propagation in IoT",
            "updated": "2023-11-15T00:58:35Z",
            "published": "2023-11-15T00:58:35Z",
            "summary": "A botnet is an army of zombified computers infected with malware and\ncontrolled by malicious actors to carry out tasks such as Distributed Denial of\nService (DDoS) attacks. Billions of Internet of Things (IoT) devices are\nprimarily targeted to be infected as bots since they are configured with weak\ncredentials or contain common vulnerabilities. Detecting botnet propagation by\nmonitoring the network traffic is difficult as they easily blend in with\nregular network traffic. The traditional machine learning (ML) based Intrusion\nDetection System (IDS) requires the raw data to be captured and sent to the ML\nprocessor to detect intrusion. In this research, we examine the viability of a\ncross-device federated intrusion detection mechanism where each device runs the\nML model on its data and updates the model weights to the central coordinator.\nThis mechanism ensures the client's data is not shared with any third party,\nterminating privacy leakage. The model examines each data packet separately and\npredicts anomalies. We evaluate our proposed mechanism on a real botnet\npropagation dataset called MedBIoT. Overall, the proposed method produces an\naverage accuracy of 71%, precision 78%, recall 71%, and f1-score 68%. In\naddition, we also examined whether any device taking part in federated learning\ncan employ a poisoning attack on the overall system.",
            "author": [
                "Angela Grace Famera",
                "Raj Mani Shukla",
                "Suman Bhunia"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08621v1",
                "http://arxiv.org/pdf/2311.08621v1"
            ],
            "primary_category": "cs.NI",
            "category": [
                "cs.NI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08620v1",
            "title": "Toucan: Token-Aware Character Level Language Modeling",
            "updated": "2023-11-15T00:57:51Z",
            "published": "2023-11-15T00:57:51Z",
            "summary": "Character-level language models obviate the need for separately trained\ntokenizers, but efficiency suffers from longer sequence lengths. Learning to\ncombine character representations into tokens has made training these models\nmore efficient, but they still require decoding characters individually. We\npropose Toucan, an augmentation to character-level models to make them\n\"token-aware\". Comparing our method to prior work, we demonstrate significant\nspeed-ups in character generation without a loss in language modeling\nperformance. We then explore differences between our learned dynamic\ntokenization of character sequences with popular fixed vocabulary solutions\nsuch as Byte-Pair Encoding and WordPiece, finding our approach leads to a\ngreater amount of longer sequences tokenized as single items. Our project and\ncode are available at https://nlp.jhu.edu/nuggets/.",
            "author": [
                "William Fleshman",
                "Benjamin Van Durme"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08620v1",
                "http://arxiv.org/pdf/2311.08620v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08615v1",
            "title": "Non-Uniform Smoothness for Gradient Descent",
            "updated": "2023-11-15T00:44:08Z",
            "published": "2023-11-15T00:44:08Z",
            "summary": "The analysis of gradient descent-type methods typically relies on the\nLipschitz continuity of the objective gradient. This generally requires an\nexpensive hyperparameter tuning process to appropriately calibrate a stepsize\nfor a given problem. In this work we introduce a local first-order smoothness\noracle (LFSO) which generalizes the Lipschitz continuous gradients smoothness\ncondition and is applicable to any twice-differentiable function. We show that\nthis oracle can encode all relevant problem information for tuning stepsizes\nfor a suitably modified gradient descent method and give global and local\nconvergence results. We also show that LFSOs in this modified first-order\nmethod can yield global linear convergence rates for non-strongly convex\nproblems with extremely flat minima, and thus improve over the lower bound on\nrates achievable by general (accelerated) first-order methods.",
            "author": [
                "Albert S. Berahas",
                "Lindon Roberts",
                "Fred Roosta"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08615v1",
                "http://arxiv.org/pdf/2311.08615v1"
            ],
            "primary_category": "math.OC",
            "category": [
                "math.OC",
                "cs.LG",
                "65K05, 90C30"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.10763v1",
            "title": "Comparing Generalization in Learning with Limited Numbers of Exemplars:\n  Transformer vs. RNN in Attractor Dynamics",
            "updated": "2023-11-15T00:37:49Z",
            "published": "2023-11-15T00:37:49Z",
            "summary": "ChatGPT, a widely-recognized large language model (LLM), has recently gained\nsubstantial attention for its performance scaling, attributed to the billions\nof web-sourced natural language sentences used for training. Its underlying\narchitecture, Transformer, has found applications across diverse fields,\nincluding video, audio signals, and robotic movement. %The crucial question\nthis raises concerns the Transformer's generalization-in-learning (GIL)\ncapacity. However, this raises a crucial question about Transformer's\ngeneralization in learning (GIL) capacity. Is ChatGPT's success chiefly due to\nthe vast dataset used for training, or is there more to the story? To\ninvestigate this, we compared Transformer's GIL capabilities with those of a\ntraditional Recurrent Neural Network (RNN) in tasks involving attractor\ndynamics learning. For performance evaluation, the Dynamic Time Warping (DTW)\nmethod has been employed. Our simulation results suggest that under conditions\nof limited data availability, Transformer's GIL abilities are markedly inferior\nto those of RNN.",
            "author": [
                "Rui Fukushima",
                "Jun Tani"
            ],
            "link": [
                "http://arxiv.org/abs/2311.10763v1",
                "http://arxiv.org/pdf/2311.10763v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08614v1",
            "title": "XplainLLM: A QA Explanation Dataset for Understanding LLM\n  Decision-Making",
            "updated": "2023-11-15T00:34:28Z",
            "published": "2023-11-15T00:34:28Z",
            "summary": "Large Language Models (LLMs) have recently made impressive strides in natural\nlanguage understanding tasks. Despite their remarkable performance,\nunderstanding their decision-making process remains a big challenge. In this\npaper, we look into bringing some transparency to this process by introducing a\nnew explanation dataset for question answering (QA) tasks that integrates\nknowledge graphs (KGs) in a novel way. Our dataset includes 12,102\nquestion-answer-explanation (QAE) triples. Each explanation in the dataset\nlinks the LLM's reasoning to entities and relations in the KGs. The explanation\ncomponent includes a why-choose explanation, a why-not-choose explanation, and\na set of reason-elements that underlie the LLM's decision. We leverage KGs and\ngraph attention networks (GAT) to find the reason-elements and transform them\ninto why-choose and why-not-choose explanations that are comprehensible to\nhumans. Through quantitative and qualitative evaluations, we demonstrate the\npotential of our dataset to improve the in-context learning of LLMs, and\nenhance their interpretability and explainability. Our work contributes to the\nfield of explainable AI by enabling a deeper understanding of the LLMs\ndecision-making process to make them more transparent and thereby, potentially\nmore reliable, to researchers and practitioners alike. Our dataset is available\nat: https://github.com/chen-zichen/XplainLLM_dataset.git",
            "author": [
                "Zichen Chen",
                "Jianda Chen",
                "Mitali Gaidhani",
                "Ambuj Singh",
                "Misha Sra"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08614v1",
                "http://arxiv.org/pdf/2311.08614v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08610v1",
            "title": "Converting Transformers to Polynomial Form for Secure Inference Over\n  Homomorphic Encryption",
            "updated": "2023-11-15T00:23:58Z",
            "published": "2023-11-15T00:23:58Z",
            "summary": "Designing privacy-preserving deep learning models is a major challenge within\nthe deep learning community. Homomorphic Encryption (HE) has emerged as one of\nthe most promising approaches in this realm, enabling the decoupling of\nknowledge between the model owner and the data owner. Despite extensive\nresearch and application of this technology, primarily in convolutional neural\nnetworks, incorporating HE into transformer models has been challenging because\nof the difficulties in converting these models into a polynomial form. We break\nnew ground by introducing the first polynomial transformer, providing the first\ndemonstration of secure inference over HE with transformers. This includes a\ntransformer architecture tailored for HE, alongside a novel method for\nconverting operators to their polynomial equivalent. This innovation enables us\nto perform secure inference on LMs with WikiText-103. It also allows us to\nperform image classification with CIFAR-100 and Tiny-ImageNet. Our models yield\nresults comparable to traditional methods, bridging the performance gap with\ntransformers of similar scale and underscoring the viability of HE for\nstate-of-the-art applications. Finally, we assess the stability of our models\nand conduct a series of ablations to quantify the contribution of each model\ncomponent.",
            "author": [
                "Itamar Zimerman",
                "Moran Baruch",
                "Nir Drucker",
                "Gilad Ezov",
                "Omri Soceanu",
                "Lior Wolf"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08610v1",
                "http://arxiv.org/pdf/2311.08610v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR",
                "F.2.2; I.2.7"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08607v1",
            "title": "Towards Generalizable SER: Soft Labeling and Data Augmentation for\n  Modeling Temporal Emotion Shifts in Large-Scale Multilingual Speech",
            "updated": "2023-11-15T00:09:21Z",
            "published": "2023-11-15T00:09:21Z",
            "summary": "Recognizing emotions in spoken communication is crucial for advanced\nhuman-machine interaction. Current emotion detection methodologies often\ndisplay biases when applied cross-corpus. To address this, our study\namalgamates 16 diverse datasets, resulting in 375 hours of data across\nlanguages like English, Chinese, and Japanese. We propose a soft labeling\nsystem to capture gradational emotional intensities. Using the Whisper encoder\nand data augmentation methods inspired by contrastive learning, our method\nemphasizes the temporal dynamics of emotions. Our validation on four\nmultilingual datasets demonstrates notable zero-shot generalization. We publish\nour open source model weights and initial promising results after fine-tuning\non Hume-Prosody.",
            "author": [
                "Mohamed Osman",
                "Tamer Nadeem",
                "Ghada Khoriba"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08607v1",
                "http://arxiv.org/pdf/2311.08607v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "eess.AS"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08606v1",
            "title": "Protective Effects of Halite to Vacuum and Vacuum-Ultraviolet Radiation:\n  A Potential Scenario During a Young Sun Superflare",
            "updated": "2023-11-15T00:04:00Z",
            "published": "2023-11-15T00:04:00Z",
            "summary": "Halite (NaCl mineral) has exhibited the potential to preserve microorganisms\nfor millions of years on Earth. This mineral was also identified on Mars and in\nmeteorites. In this study, we investigated the potential of halite crystals to\nprotect microbial life forms on the surface of an airless body (e.g.,\nmeteorite), for instance, during a lithopanspermia process (interplanetary\ntravel step) in the early Solar System. To investigate the effect of the\nradiation of the young Sun on microorganisms, we performed extensive simulation\nexperiments by employing a synchrotron facility. We focused on two exposure\nconditions: vacuum (low Earth orbit, 10^{-4}Pa) and vacuum-ultraviolet (VUV)\nradiation (range 57.6 - 124 nm, flux 7.14 W m^{-2}), with the latter\nrepresenting an extreme scenario with high VUV fluxes comparable to the amount\nof radiation of a stellar superflare from the young Sun. The stellar VUV\nparameters were estimated by using the very well-studied solar analog of the\nyoung Sun, k^{1}Cet. To evaluate the protective effects of halite, we entrapped\na halophilic archaeon (Haloferax volcanii) and a non-halophilic bacterium\n(Deinococcus radiodurans) in laboratory-grown halite. Control groups were cells\nentrapped in salt crystals (mixtures of different salts and NaCl) and\nnon-trapped (naked) cells, respectively. All groups were exposed either to\nvacuum alone or to vacuum plus VUV. Our results demonstrate that halite can\nserve as protection against vacuum and VUV radiation, regardless of the type of\nmicroorganism. In addition, we found that the protection is higher than\nprovided by crystals obtained from mixtures of salts. This extends the\nprotective effects of halite documented in previous studies and reinforces the\npossibility to consider the crystals of this mineral as potential preservation\nstructures in airless bodies or as vehicles for the interplanetary transfer of\nmicroorganisms.",
            "author": [
                "Ximena C. Abrevaya",
                "Douglas Galante",
                "Paula M. Tribelli",
                "Oscar J. Oppezzo",
                "Felipe Nobrega",
                "Gabriel G. Araujo",
                "Fabio Rodrigues",
                "Petra Odert",
                "Martin Leitzinger",
                "Martiniano M. Ricardi",
                "Maria Eugenia Varela",
                "Tamires Gallo",
                "Jorge Sanz-Forcada",
                "Ignasi Ribas",
                "Gustavo F. Porto de Mello",
                "Florian Rodler",
                "1 Maria Fernanda Cerini",
                "Arnold Hanslmeier",
                "Jorge E. Horvath"
            ],
            "link": [
                "http://dx.doi.org/10.1089/ast.2022.0016",
                "http://arxiv.org/abs/2311.08606v1",
                "http://arxiv.org/pdf/2311.08606v1"
            ],
            "primary_category": "astro-ph.EP",
            "category": [
                "astro-ph.EP",
                "astro-ph.IM",
                "astro-ph.SR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08599v1",
            "title": "High-speed surface-property recognition by 140-GHz frequency",
            "updated": "2023-11-14T23:45:00Z",
            "published": "2023-11-14T23:45:00Z",
            "summary": "In the field of integrated sensing and communication, there's a growing need\nfor advanced environmental perception. The terahertz (THz) frequency band,\nsignificant for ultra-high-speed data connections, shows promise in\nenvironmental sensing, particularly in detecting surface textures crucial for\nautonomous system's decision-making. However, traditional numerical methods for\nparameter estimation in these environments struggle with accuracy, speed, and\nstability, especially in high-speed scenarios like vehicle-to-everything\ncommunications. This study introduces a deep learning approach for identifying\nsurface roughness using a 140-GHz setup tailored for high-speed conditions. A\nhigh-speed data acquisition system was developed to mimic real-world scenarios,\nand a diverse set of rough surface samples was collected for realistic\nhigh-speed datasets to train the models. The model was trained and validated in\nthree challenging scenarios: random occlusions, sparse data, and narrow-angle\nobservations. The results demonstrate the method's effectiveness in high-speed\nconditions, suggesting terahertz frequencies' potential in future sensing and\ncommunication applications.",
            "author": [
                "Jiacheng Liu",
                "Da Li",
                "Guohao Liu",
                "Yige Qiao",
                "Menghan Wei",
                "Chengyu Zhang",
                "Houjun Sun",
                "Jianjun Ma"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08599v1",
                "http://arxiv.org/pdf/2311.08599v1"
            ],
            "primary_category": "physics.app-ph",
            "category": [
                "physics.app-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08594v1",
            "title": "Variational Temporal IRT: Fast, Accurate, and Explainable Inference of\n  Dynamic Learner Proficiency",
            "updated": "2023-11-14T23:36:39Z",
            "published": "2023-11-14T23:36:39Z",
            "summary": "Dynamic Item Response Models extend the standard Item Response Theory (IRT)\nto capture temporal dynamics in learner ability. While these models have the\npotential to allow instructional systems to actively monitor the evolution of\nlearner proficiency in real time, existing dynamic item response models rely on\nexpensive inference algorithms that scale poorly to massive datasets. In this\nwork, we propose Variational Temporal IRT (VTIRT) for fast and accurate\ninference of dynamic learner proficiency. VTIRT offers orders of magnitude\nspeedup in inference runtime while still providing accurate inference.\nMoreover, the proposed algorithm is intrinsically interpretable by virtue of\nits modular design. When applied to 9 real student datasets, VTIRT consistently\nyields improvements in predicting future learner performance over other learner\nproficiency models.",
            "author": [
                "Yunsung Kim",
                "Sreechan Sankaranarayanan",
                "Chris Piech",
                "Candace Thille"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08594v1",
                "http://arxiv.org/pdf/2311.08594v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08585v1",
            "title": "Unsupervised segmentation of irradiation$\\unicode{x2010}$induced\n  order$\\unicode{x2010}$disorder phase transitions in electron microscopy",
            "updated": "2023-11-14T23:13:59Z",
            "published": "2023-11-14T23:13:59Z",
            "summary": "We present a method for the unsupervised segmentation of electron microscopy\nimages, which are powerful descriptors of materials and chemical systems.\nImages are oversegmented into overlapping chips, and similarity graphs are\ngenerated from embeddings extracted from a domain$\\unicode{x2010}$pretrained\nconvolutional neural network (CNN). The Louvain method for community detection\nis then applied to perform segmentation. The graph representation provides an\nintuitive way of presenting the relationship between chips and communities. We\ndemonstrate our method to track irradiation$\\unicode{x2010}$induced amorphous\nfronts in thin films used for catalysis and electronics. This method has\npotential for \"on$\\unicode{x2010}$the$\\unicode{x2010}$fly\" segmentation to\nguide emerging automated electron microscopes.",
            "author": [
                "Arman H Ter-Petrosyan",
                "Jenna A Bilbrey",
                "Christina M Doty",
                "Bethany E Matthews",
                "Le Wang",
                "Yingge Du",
                "Eric Lang",
                "Khalid Hattar",
                "Steven R Spurgeon"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08585v1",
                "http://arxiv.org/pdf/2311.08585v1"
            ],
            "primary_category": "cond-mat.mtrl-sci",
            "category": [
                "cond-mat.mtrl-sci",
                "cs.CV",
                "cs.LG",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08579v1",
            "title": "Graph-Induced Syntactic-Semantic Spaces in Transformer-Based Variational\n  AutoEncoders",
            "updated": "2023-11-14T22:47:23Z",
            "published": "2023-11-14T22:47:23Z",
            "summary": "The injection of syntactic information in Variational AutoEncoders (VAEs) has\nbeen shown to result in an overall improvement of performances and\ngeneralisation. An effective strategy to achieve such a goal is to separate the\nencoding of distributional semantic features and syntactic structures into\nheterogeneous latent spaces via multi-task learning or dual encoder\narchitectures. However, existing works employing such techniques are limited to\nLSTM-based VAEs. In this paper, we investigate latent space separation methods\nfor structural syntactic injection in Transformer-based VAE architectures\n(i.e., Optimus). Specifically, we explore how syntactic structures can be\nleveraged in the encoding stage through the integration of graph-based and\nsequential models, and how multiple, specialised latent representations can be\ninjected into the decoder's attention mechanism via low-rank operators. Our\nempirical evaluation, carried out on natural language sentences and\nmathematical expressions, reveals that the proposed end-to-end VAE architecture\ncan result in a better overall organisation of the latent space, alleviating\nthe information loss occurring in standard VAE setups, resulting in enhanced\nperformances on language modelling and downstream generation tasks.",
            "author": [
                "Yingji Zhang",
                "Marco Valentino",
                "Danilo S. Carvalho",
                "Ian Pratt-Hartmann",
                "Andr\u00e9 Freitas"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08579v1",
                "http://arxiv.org/pdf/2311.08579v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08576v1",
            "title": "Towards Evaluating AI Systems for Moral Status Using Self-Reports",
            "updated": "2023-11-14T22:45:44Z",
            "published": "2023-11-14T22:45:44Z",
            "summary": "As AI systems become more advanced and widely deployed, there will likely be\nincreasing debate over whether AI systems could have conscious experiences,\ndesires, or other states of potential moral significance. It is important to\ninform these discussions with empirical evidence to the extent possible. We\nargue that under the right circumstances, self-reports, or an AI system's\nstatements about its own internal states, could provide an avenue for\ninvestigating whether AI systems have states of moral significance.\nSelf-reports are the main way such states are assessed in humans (\"Are you in\npain?\"), but self-reports from current systems like large language models are\nspurious for many reasons (e.g. often just reflecting what humans would say).\nTo make self-reports more appropriate for this purpose, we propose to train\nmodels to answer many kinds of questions about themselves with known answers,\nwhile avoiding or limiting training incentives that bias self-reports. The hope\nof this approach is that models will develop introspection-like capabilities,\nand that these capabilities will generalize to questions about states of moral\nsignificance. We then propose methods for assessing the extent to which these\ntechniques have succeeded: evaluating self-report consistency across contexts\nand between similar models, measuring the confidence and resilience of models'\nself-reports, and using interpretability to corroborate self-reports. We also\ndiscuss challenges for our approach, from philosophical difficulties in\ninterpreting self-reports to technical reasons why our proposal might fail. We\nhope our discussion inspires philosophers and AI researchers to criticize and\nimprove our proposed methodology, as well as to run experiments to test whether\nself-reports can be made reliable enough to provide information about states of\nmoral significance.",
            "author": [
                "Ethan Perez",
                "Robert Long"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08576v1",
                "http://arxiv.org/pdf/2311.08576v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08575v1",
            "title": "Gaussian Approximation of Convex Sets by Intersections of Halfspaces",
            "updated": "2023-11-14T22:42:47Z",
            "published": "2023-11-14T22:42:47Z",
            "summary": "We study the approximability of general convex sets in $\\mathbb{R}^n$ by\nintersections of halfspaces, where the approximation quality is measured with\nrespect to the standard Gaussian distribution $N(0,I_n)$ and the complexity of\nan approximation is the number of halfspaces used. While a large body of\nresearch has considered the approximation of convex sets by intersections of\nhalfspaces under distance metrics such as the Lebesgue measure and Hausdorff\ndistance, prior to our work there has not been a systematic study of convex\napproximation under the Gaussian distribution.\n  We establish a range of upper and lower bounds, both for general convex sets\nand for specific natural convex sets that are of particular interest. Our\nresults demonstrate that the landscape of approximation is intriguingly\ndifferent under the Gaussian distribution versus previously studied distance\nmeasures. For example, we show that $2^{\\Theta(\\sqrt{n})}$ halfspaces are both\nnecessary and sufficient to approximate the origin-centered $\\ell_2$ ball of\nGaussian volume 1/2 to any constant accuracy, and that for $1 \\leq p < 2$, the\norigin-centered $\\ell_p$ ball of Gaussian volume 1/2 can be approximated to any\nconstant accuracy as an intersection of $2^{\\widetilde{O}(n^{3/4})}$ many\nhalfspaces. These bounds are quite different from known approximation results\nunder more commonly studied distance measures.\n  Our results are proved using techniques from many different areas. These\ninclude classical results on convex polyhedral approximation, Cram\\'er-type\nbounds on large deviations from probability theory, and -- perhaps surprisingly\n-- a range of topics from computational complexity, including computational\nlearning theory, unconditional pseudorandomness, and the study of influences\nand noise sensitivity in the analysis of Boolean functions.",
            "author": [
                "Anindya De",
                "Shivam Nadimpalli",
                "Rocco A. Servedio"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08575v1",
                "http://arxiv.org/pdf/2311.08575v1"
            ],
            "primary_category": "cs.CC",
            "category": [
                "cs.CC",
                "cs.DS",
                "math.MG",
                "math.PR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08572v1",
            "title": "Parameter-Efficient Multilingual Summarisation: An Empirical Study",
            "updated": "2023-11-14T22:32:39Z",
            "published": "2023-11-14T22:32:39Z",
            "summary": "With the increasing prevalence of Large Language Models, traditional full\nfine-tuning approaches face growing challenges, especially in memory-intensive\ntasks. This paper investigates the potential of Parameter-Efficient\nFine-Tuning, focusing on Low-Rank Adaptation (LoRA), for complex and\nunder-explored multilingual summarisation tasks. We conduct an extensive study\nacross different data availability scenarios, including full-data, low-data,\nand cross-lingual transfer, leveraging models of different sizes. Our findings\nreveal that LoRA lags behind full fine-tuning when trained with full data,\nhowever, it excels in low-data scenarios and cross-lingual transfer.\nInterestingly, as models scale up, the performance gap between LoRA and full\nfine-tuning diminishes. Additionally, we investigate effective strategies for\nfew-shot cross-lingual transfer, finding that continued LoRA tuning achieves\nthe best performance compared to both full fine-tuning and dynamic composition\nof language-specific LoRA modules.",
            "author": [
                "Chenxi Whitehouse",
                "Fantine Huot",
                "Jasmijn Bastings",
                "Mostafa Dehghani",
                "Chu-Cheng Lin",
                "Mirella Lapata"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08572v1",
                "http://arxiv.org/pdf/2311.08572v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08569v2",
            "title": "Uncertainty Quantification in Neural-Network Based Pain Intensity\n  Estimation",
            "updated": "2023-11-29T13:20:53Z",
            "published": "2023-11-14T22:14:07Z",
            "summary": "Improper pain management can lead to severe physical or mental consequences,\nincluding suffering, and an increased risk of opioid dependency. Assessing the\npresence and severity of pain is imperative to prevent such outcomes and\ndetermine the appropriate intervention. However, the evaluation of pain\nintensity is challenging because different individuals experience pain\ndifferently. To overcome this, researchers have employed machine learning\nmodels to evaluate pain intensity objectively. However, these efforts have\nprimarily focused on point estimation of pain, disregarding the inherent\nuncertainty and variability present in the data and model. Consequently, the\npoint estimates provide only partial information for clinical decision-making.\nThis study presents a neural network-based method for objective pain interval\nestimation, incorporating uncertainty quantification. This work explores three\nalgorithms: the bootstrap method, lower and upper bound estimation (LossL)\noptimized by genetic algorithm, and modified lower and upper bound estimation\n(LossS) optimized by gradient descent algorithm. Our empirical results reveal\nthat LossS outperforms the other two by providing a narrower prediction\ninterval. As LossS outperforms, we assessed its performance in three different\nscenarios for pain assessment: (1) a generalized approach (single model for the\nentire population), (2) a personalized approach (separate model for each\nindividual), and (3) a hybrid approach (separate model for each cluster of\nindividuals). Our findings demonstrate the hybrid approach's superior\nperformance, with notable practicality in clinical contexts. It has the\npotential to be a valuable tool for clinicians, enabling objective pain\nintensity assessment while taking uncertainty into account. This capability is\ncrucial in facilitating effective pain management and reducing the risks\nassociated with improper treatment.",
            "author": [
                "Burcu Ozek",
                "Zhenyuan Lu",
                "Srinivasan Radhakrishnan",
                "Sagar Kamarthi"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08569v2",
                "http://arxiv.org/pdf/2311.08569v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08568v1",
            "title": "Adversarial Imitation Learning On Aggregated Data",
            "updated": "2023-11-14T22:13:38Z",
            "published": "2023-11-14T22:13:38Z",
            "summary": "Inverse Reinforcement Learning (IRL) learns an optimal policy, given some\nexpert demonstrations, thus avoiding the need for the tedious process of\nspecifying a suitable reward function. However, current methods are constrained\nby at least one of the following requirements. The first one is the need to\nfully solve a forward Reinforcement Learning (RL) problem in the inner loop of\nthe algorithm, which might be prohibitively expensive in many complex\nenvironments. The second one is the need for full trajectories from the\nexperts, which might not be easily available. The third one is the assumption\nthat the expert data is homogeneous rather than a collection from various\nexperts or possibly alternative solutions to the same task. Such constraints\nmake IRL approaches either not scalable or not usable on certain existing\nsystems. In this work we propose an approach which removes these requirements\nthrough a dynamic, adaptive method called Adversarial Imitation Learning on\nAggregated Data (AILAD). It learns conjointly both a non linear reward function\nand the associated optimal policy using an adversarial framework. The reward\nlearner only uses aggregated data. Moreover, it generates diverse behaviors\nproducing a distribution over the aggregated data matching that of the experts.",
            "author": [
                "Pierre Le Pelletier de Woillemont",
                "R\u00e9mi Labory",
                "Vincent Corruble"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08568v1",
                "http://arxiv.org/pdf/2311.08568v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08561v1",
            "title": "Measuring association with recursive rank binning",
            "updated": "2023-11-14T21:43:56Z",
            "published": "2023-11-14T21:43:56Z",
            "summary": "Pairwise measures of dependence are a common tool to map data in the early\nstages of analysis with several modern examples based on maximized partitions\nof the pairwise sample space. Following a short survey of modern measures of\ndependence, we introduce a new measure which recursively splits the ranks of a\npair of variables to partition the sample space and computes the $\\chi^2$\nstatistic on the resulting bins. Splitting logic is detailed for splits\nmaximizing a score function and randomly selected splits. Simulations indicate\nthat random splitting produces a statistic conservatively approximated by the\n$\\chi^2$ distribution without a loss of power to detect numerous different data\npatterns compared to maximized binning. Though it seems to add no power to\ndetect dependence, maximized recursive binning is shown to produce a natural\nvisualization of the data and the measure. Applying maximized recursive rank\nbinning to S&P 500 constituent data suggests the automatic detection of tail\ndependence.",
            "author": [
                "Chris Salahub",
                "Wayne Oldford"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08561v1",
                "http://arxiv.org/pdf/2311.08561v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.CO",
                "stat.ML",
                "62G10",
                "G.3; J.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08557v1",
            "title": "Low-light Pedestrian Detection in Visible and Infrared Image Feeds:\n  Issues and Challenges",
            "updated": "2023-11-14T21:39:15Z",
            "published": "2023-11-14T21:39:15Z",
            "summary": "Pedestrian detection has become a cornerstone for several high-level tasks,\nincluding autonomous driving, intelligent transportation, and traffic\nsurveillance. There are several works focussed on pedestrian detection using\nvisible images, mainly in the daytime. However, this task is very intriguing\nwhen the environmental conditions change to poor lighting or nighttime.\nRecently, new ideas have been spurred to use alternative sources, such as Far\nInfraRed (FIR) temperature sensor feeds for detecting pedestrians in low-light\nconditions. This study comprehensively reviews recent developments in low-light\npedestrian detection approaches. It systematically categorizes and analyses\nvarious algorithms from region-based to non-region-based and graph-based\nlearning methodologies by highlighting their methodologies, implementation\nissues, and challenges. It also outlines the key benchmark datasets that can be\nused for research and development of advanced pedestrian detection algorithms,\nparticularly in low-light situations",
            "author": [
                "Hrishikesh Vachhani",
                "Thangarajah Akilan",
                "Yash Devmurari",
                "Nisharaff Shaik",
                "Dhruvisha Patel"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08557v1",
                "http://arxiv.org/pdf/2311.08557v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08549v1",
            "title": "Manifold learning in Wasserstein space",
            "updated": "2023-11-14T21:21:35Z",
            "published": "2023-11-14T21:21:35Z",
            "summary": "This paper aims at building the theoretical foundations for manifold learning\nalgorithms in the space of absolutely continuous probability measures on a\ncompact and convex subset of $\\mathbb{R}^d$, metrized with the Wasserstein-2\ndistance $W$. We begin by introducing a natural construction of submanifolds\n$\\Lambda$ of probability measures equipped with metric $W_\\Lambda$, the\ngeodesic restriction of $W$ to $\\Lambda$. In contrast to other constructions,\nthese submanifolds are not necessarily flat, but still allow for local\nlinearizations in a similar fashion to Riemannian submanifolds of\n$\\mathbb{R}^d$. We then show how the latent manifold structure of\n$(\\Lambda,W_{\\Lambda})$ can be learned from samples $\\{\\lambda_i\\}_{i=1}^N$ of\n$\\Lambda$ and pairwise extrinsic Wasserstein distances $W$ only. In particular,\nwe show that the metric space $(\\Lambda,W_{\\Lambda})$ can be asymptotically\nrecovered in the sense of Gromov--Wasserstein from a graph with nodes\n$\\{\\lambda_i\\}_{i=1}^N$ and edge weights $W(\\lambda_i,\\lambda_j)$. In addition,\nwe demonstrate how the tangent space at a sample $\\lambda$ can be\nasymptotically recovered via spectral analysis of a suitable \"covariance\noperator\" using optimal transport maps from $\\lambda$ to sufficiently close and\ndiverse samples $\\{\\lambda_i\\}_{i=1}^N$. The paper closes with some explicit\nconstructions of submanifolds $\\Lambda$ and numerical examples on the recovery\nof tangent spaces through spectral analysis.",
            "author": [
                "Keaton Hamm",
                "Caroline Moosm\u00fcller",
                "Bernhard Schmitzer",
                "Matthew Thorpe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08549v1",
                "http://arxiv.org/pdf/2311.08549v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG",
                "math.DG",
                "49Q22, 41A65, 58B20, 53Z50"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08547v1",
            "title": "DeepThought: An Architecture for Autonomous Self-motivated Systems",
            "updated": "2023-11-14T21:20:23Z",
            "published": "2023-11-14T21:20:23Z",
            "summary": "The ability of large language models (LLMs) to engage in credible dialogues\nwith humans, taking into account the training data and the context of the\nconversation, has raised discussions about their ability to exhibit intrinsic\nmotivations, agency, or even some degree of consciousness. We argue that the\ninternal architecture of LLMs and their finite and volatile state cannot\nsupport any of these properties. By combining insights from complementary\nlearning systems, global neuronal workspace, and attention schema theories, we\npropose to integrate LLMs and other deep learning systems into an architecture\nfor cognitive language agents able to exhibit properties akin to agency,\nself-motivation, even some features of meta-cognition.",
            "author": [
                "Arlindo L. Oliveira",
                "Tiago Domingos",
                "M\u00e1rio Figueiredo",
                "Pedro U. Lima"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08547v1",
                "http://arxiv.org/pdf/2311.08547v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "I.2"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08543v1",
            "title": "2D-RC: Two-Dimensional Neural Network Approach for OTFS Symbol Detection",
            "updated": "2023-11-14T21:16:40Z",
            "published": "2023-11-14T21:16:40Z",
            "summary": "Orthogonal time frequency space (OTFS) is a promising modulation scheme for\nwireless communication in high-mobility scenarios. Recently, a reservoir\ncomputing (RC) based approach has been introduced for online subframe-based\nsymbol detection in the OTFS system, where only a limited number of\nover-the-air (OTA) pilot symbols are utilized for training. However, this\napproach does not leverage the domain knowledge specific to the OTFS system.\nThis paper introduces a novel two-dimensional RC (2D-RC) method that\nincorporates the structural knowledge of the OTFS system into the design for\nonline symbol detection on a subframe basis. Specifically, as the channel\nresponse acts as a two-dimensional (2D) operation over the transmitted\ninformation symbols in the delay-Doppler (DD) domain, the 2D-RC is designed to\nhave a 2D structure to equalize the channel. With the introduced architecture,\nthe 2D-RC can benefit from the predictable channel representation in the DD\ndomain. Moreover, unlike the previous work that requires multiple RCs to learn\nthe channel feature, the 2D-RC only requires a single neural network for\ndetection. Experimental results demonstrate the effectiveness of the 2D-RC\napproach across different OTFS system variants and modulation orders.",
            "author": [
                "Jiarui Xu",
                "Karim Said",
                "Lizhong Zheng",
                "Lingjia Liu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08543v1",
                "http://arxiv.org/pdf/2311.08543v1"
            ],
            "primary_category": "eess.SP",
            "category": [
                "eess.SP",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08539v1",
            "title": "Physical Adversarial Examples for Multi-Camera Systems",
            "updated": "2023-11-14T21:04:49Z",
            "published": "2023-11-14T21:04:49Z",
            "summary": "Neural networks build the foundation of several intelligent systems, which,\nhowever, are known to be easily fooled by adversarial examples. Recent advances\nmade these attacks possible even in air-gapped scenarios, where the autonomous\nsystem observes its surroundings by, e.g., a camera. We extend these ideas in\nour research and evaluate the robustness of multi-camera setups against such\nphysical adversarial examples. This scenario becomes ever more important with\nthe rise in popularity of autonomous vehicles, which fuse the information of\nseveral cameras for their driving decision. While we find that multi-camera\nsetups provide some robustness towards past attack methods, we see that this\nadvantage reduces when optimizing on multiple perspectives at once. We propose\na novel attack method that we call Transcender-MC, where we incorporate online\n3D renderings and perspective projections in the training process. Moreover, we\nmotivate that certain data augmentation techniques can facilitate the\ngeneration of successful adversarial examples even further. Transcender-MC is\n11% more effective in successfully attacking multi-camera setups than\nstate-of-the-art methods. Our findings offer valuable insights regarding the\nresilience of object detection in a setup with multiple cameras and motivate\nthe need of developing adequate defense mechanisms against them.",
            "author": [
                "Ana R\u0103du\u0163oiu",
                "Jan-Philipp Schulze",
                "Philip Sperl",
                "Konstantin B\u00f6ttinger"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08539v1",
                "http://arxiv.org/pdf/2311.08539v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08538v1",
            "title": "Extending Multilingual Machine Translation through Imitation Learning",
            "updated": "2023-11-14T21:04:03Z",
            "published": "2023-11-14T21:04:03Z",
            "summary": "Despite the growing variety of languages supported by existing multilingual\nneural machine translation (MNMT) models, most of the world's languages are\nstill being left behind. We aim to extend large-scale MNMT models to a new\nlanguage, allowing for translation between the newly added and all of the\nalready supported languages in a challenging scenario: using only a parallel\ncorpus between the new language and English. Previous approaches, such as\ncontinued training on parallel data including the new language, suffer from\ncatastrophic forgetting (i.e., performance on other languages is reduced). Our\nnovel approach Imit-MNMT treats the task as an imitation learning process,\nwhich mimicks the behavior of an expert, a technique widely used in the\ncomputer vision area, but not well explored in NLP. More specifically, we\nconstruct a pseudo multi-parallel corpus of the new and the original languages\nby pivoting through English, and imitate the output distribution of the\noriginal MNMT model. Extensive experiments show that our approach significantly\nimproves the translation performance between the new and the original\nlanguages, without severe catastrophic forgetting. We also demonstrate that our\napproach is capable of solving copy and off-target problems, which are two\ncommon issues existence in current large-scale MNMT models.",
            "author": [
                "Wen Lai",
                "Viktor Hangya",
                "Alexander Fraser"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08538v1",
                "http://arxiv.org/pdf/2311.08538v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08536v1",
            "title": "Low-Frequency Load Identification using CNN-BiLSTM Attention Mechanism",
            "updated": "2023-11-14T21:02:27Z",
            "published": "2023-11-14T21:02:27Z",
            "summary": "Non-intrusive Load Monitoring (NILM) is an established technique for\neffective and cost-efficient electricity consumption management. The method is\nused to estimate appliance-level power consumption from aggregated power\nmeasurements. This paper presents a hybrid learning approach, consisting of a\nconvolutional neural network (CNN) and a bidirectional long short-term memory\n(BILSTM), featuring an integrated attention mechanism, all within the context\nof disaggregating low-frequency power data. While prior research has been\nmainly focused on high-frequency data disaggregation, our study takes a\ndistinct direction by concentrating on low-frequency data. The proposed hybrid\nCNN-BILSTM model is adept at extracting both temporal (time-related) and\nspatial (location-related) features, allowing it to precisely identify energy\nconsumption patterns at the appliance level. This accuracy is further enhanced\nby the attention mechanism, which aids the model in pinpointing crucial parts\nof the data for more precise event detection and load disaggregation. We\nconduct simulations using the existing low-frequency REDD dataset to assess our\nmodel performance. The results demonstrate that our proposed approach\noutperforms existing methods in terms of accuracy and computation time.",
            "author": [
                "Amanie Azzam",
                "Saba Sanami",
                "Amir G. Aghdam"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08536v1",
                "http://arxiv.org/pdf/2311.08536v1"
            ],
            "primary_category": "eess.SY",
            "category": [
                "eess.SY",
                "cs.LG",
                "cs.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08533v1",
            "title": "Natural Language Processing for Financial Regulation",
            "updated": "2023-11-14T20:58:21Z",
            "published": "2023-11-14T20:58:21Z",
            "summary": "This article provides an understanding of Natural Language Processing\ntechniques in the framework of financial regulation, more specifically in order\nto perform semantic matching search between rules and policy when no dataset is\navailable for supervised learning. We outline how to outperform simple\npre-trained sentences-transformer models using freely available resources and\nexplain the mathematical concepts behind the key building blocks of Natural\nLanguage Processing.",
            "author": [
                "Ixandra Achitouv",
                "Dragos Gorduza",
                "Antoine Jacquier"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08533v1",
                "http://arxiv.org/pdf/2311.08533v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.LG",
                "q-fin.CP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08530v1",
            "title": "SceneScore: Learning a Cost Function for Object Arrangement",
            "updated": "2023-11-14T20:55:40Z",
            "published": "2023-11-14T20:55:40Z",
            "summary": "Arranging objects correctly is a key capability for robots which unlocks a\nwide range of useful tasks. A prerequisite for creating successful arrangements\nis the ability to evaluate the desirability of a given arrangement. Our method\n\"SceneScore\" learns a cost function for arrangements, such that desirable,\nhuman-like arrangements have a low cost. We learn the distribution of training\narrangements offline using an energy-based model, solely from example images\nwithout requiring environment interaction or human supervision. Our model is\nrepresented by a graph neural network which learns object-object relations,\nusing graphs constructed from images. Experiments demonstrate that the learned\ncost function can be used to predict poses for missing objects, generalise to\nnovel objects using semantic features, and can be composed with other cost\nfunctions to satisfy constraints at inference time.",
            "author": [
                "Ivan Kapelyukh",
                "Edward Johns"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08530v1",
                "http://arxiv.org/pdf/2311.08530v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08527v1",
            "title": "Inferring the Long-Term Causal Effects of Long-Term Treatments from\n  Short-Term Experiments",
            "updated": "2023-11-14T20:42:52Z",
            "published": "2023-11-14T20:42:52Z",
            "summary": "We study inference on the long-term causal effect of a continual exposure to\na novel intervention, which we term a long-term treatment, based on an\nexperiment involving only short-term observations. Key examples include the\nlong-term health effects of regularly-taken medicine or of environmental\nhazards and the long-term effects on users of changes to an online platform.\nThis stands in contrast to short-term treatments or \"shocks,\" whose long-term\neffect can reasonably be mediated by short-term observations, enabling the use\nof surrogate methods. Long-term treatments by definition have direct effects on\nlong-term outcomes via continual exposure so surrogacy cannot reasonably hold.\n  Our approach instead learns long-term temporal dynamics directly from\nshort-term experimental data, assuming that the initial dynamics observed\npersist but avoiding the need for both surrogacy assumptions and auxiliary data\nwith long-term observations. We connect the problem with offline reinforcement\nlearning, leveraging doubly-robust estimators to estimate long-term causal\neffects for long-term treatments and construct confidence intervals. Finally,\nwe demonstrate the method in simulated experiments.",
            "author": [
                "Allen Tran",
                "Aur\u00e9lien Bibaut",
                "Nathan Kallus"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08527v1",
                "http://arxiv.org/pdf/2311.08527v1"
            ],
            "primary_category": "stat.AP",
            "category": [
                "stat.AP",
                "stat.ME"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08526v1",
            "title": "GLiNER: Generalist Model for Named Entity Recognition using\n  Bidirectional Transformer",
            "updated": "2023-11-14T20:39:12Z",
            "published": "2023-11-14T20:39:12Z",
            "summary": "Named Entity Recognition (NER) is essential in various Natural Language\nProcessing (NLP) applications. Traditional NER models are effective but limited\nto a set of predefined entity types. In contrast, Large Language Models (LLMs)\ncan extract arbitrary entities through natural language instructions, offering\ngreater flexibility. However, their size and cost, particularly for those\naccessed via APIs like ChatGPT, make them impractical in resource-limited\nscenarios. In this paper, we introduce a compact NER model trained to identify\nany type of entity. Leveraging a bidirectional transformer encoder, our model,\nGLiNER, facilitates parallel entity extraction, an advantage over the slow\nsequential token generation of LLMs. Through comprehensive testing, GLiNER\ndemonstrate strong performance, outperforming both ChatGPT and fine-tuned LLMs\nin zero-shot evaluations on various NER benchmarks.",
            "author": [
                "Urchade Zaratiana",
                "Nadi Tomeh",
                "Pierre Holat",
                "Thierry Charnois"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08526v1",
                "http://arxiv.org/pdf/2311.08526v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08525v1",
            "title": "Efficient Rotation Invariance in Deep Neural Networks through Artificial\n  Mental Rotation",
            "updated": "2023-11-14T20:37:54Z",
            "published": "2023-11-14T20:37:54Z",
            "summary": "Humans and animals recognize objects irrespective of the beholder's point of\nview, which may drastically change their appearances. Artificial pattern\nrecognizers also strive to achieve this, e.g., through translational invariance\nin convolutional neural networks (CNNs). However, both CNNs and vision\ntransformers (ViTs) perform very poorly on rotated inputs. Here we present\nartificial mental rotation (AMR), a novel deep learning paradigm for dealing\nwith in-plane rotations inspired by the neuro-psychological concept of mental\nrotation. Our simple AMR implementation works with all common CNN and ViT\narchitectures. We test it on ImageNet, Stanford Cars, and Oxford Pet. With a\ntop-1 error (averaged across datasets and architectures) of $0.743$, AMR\noutperforms the current state of the art (rotational data augmentation, average\ntop-1 error of $0.626$) by $19\\%$. We also easily transfer a trained AMR module\nto a downstream task to improve the performance of a pre-trained semantic\nsegmentation model on rotated CoCo from $32.7$ to $55.2$ IoU.",
            "author": [
                "Lukas Tuggener",
                "Thilo Stadelmann",
                "J\u00fcrgen Schmidhuber"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08525v1",
                "http://arxiv.org/pdf/2311.08525v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08524v1",
            "title": "Cross-dataset domain adaptation for the classification COVID-19 using\n  chest computed tomography images",
            "updated": "2023-11-14T20:36:34Z",
            "published": "2023-11-14T20:36:34Z",
            "summary": "Detecting COVID-19 patients using Computed Tomography (CT) images of the\nlungs is an active area of research. Datasets of CT images from COVID-19\npatients are becoming available. Deep learning (DL) solutions and in particular\nConvolutional Neural Networks (CNN) have achieved impressive results for the\nclassification of COVID-19 CT images, but only when the training and testing\ntake place within the same dataset. Work on the cross-dataset problem is still\nlimited and the achieved results are low. Our work tackles the cross-dataset\nproblem through a Domain Adaptation (DA) technique with deep learning. Our\nproposed solution, COVID19-DANet, is based on pre-trained CNN backbone for\nfeature extraction. For this task, we select the pre-trained Efficientnet-B3\nCNN because it has achieved impressive classification accuracy in previous\nwork. The backbone CNN is followed by a prototypical layer which is a concept\nborrowed from prototypical networks in few-shot learning (FSL). It computes a\ncosine distance between given samples and the class prototypes and then\nconverts them to class probabilities using the Softmax function. To train the\nCOVID19-DANet model, we propose a combined loss function that is composed of\nthe standard cross-entropy loss for class discrimination and another entropy\nloss computed over the unlabelled target set only. This so-called unlabelled\ntarget entropy loss is minimized and maximized in an alternative fashion, to\nreach the two objectives of class discrimination and domain invariance.\nCOVID19-DANet is tested under four cross-dataset scenarios using the\nSARS-CoV-2-CT and COVID19-CT datasets and has achieved encouraging results\ncompared to recent work in the literature.",
            "author": [
                "Ridha Ouni",
                "Haikel Alhichri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08524v1",
                "http://arxiv.org/pdf/2311.08524v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08516v1",
            "title": "LLMs cannot find reasoning errors, but can correct them!",
            "updated": "2023-11-14T20:12:38Z",
            "published": "2023-11-14T20:12:38Z",
            "summary": "While self-correction has shown promise in improving LLM outputs in terms of\nstyle and quality (e.g. Chen et al., 2023; Madaan et al., 2023), recent\nattempts to self-correct logical or reasoning errors often cause correct\nanswers to become incorrect, resulting in worse performances overall (Huang et\nal., 2023). In this paper, we break down the self-correction process into two\ncore components: mistake finding and output correction. For mistake finding, we\nrelease BIG-Bench Mistake, a dataset of logical mistakes in Chain-of-Thought\nreasoning traces. We provide benchmark numbers for several state-of-the-art\nLLMs, and demonstrate that LLMs generally struggle with finding logical\nmistakes. For output correction, we propose a backtracking method which\nprovides large improvements when given information on mistake location. We\nconstrue backtracking as a lightweight alternative to reinforcement learning\nmethods, and show that it remains effective with a reward model at 60-70%\naccuracy.",
            "author": [
                "Gladys Tyen",
                "Hassan Mansoor",
                "Peter Chen",
                "Tony Mak",
                "Victor C\u0103rbune"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08516v1",
                "http://arxiv.org/pdf/2311.08516v1"
            ],
            "primary_category": "cs.AI",
            "category": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00026v1",
            "title": "A Quality-of-Service Compliance System using Federated Learning and\n  Optimistic Rollups",
            "updated": "2023-11-14T20:02:37Z",
            "published": "2023-11-14T20:02:37Z",
            "summary": "Edge computing brings a new paradigm in which the sharing of computing,\nstorage, and bandwidth resources as close as possible to the mobile devices or\nsensors generating a large amount of data. A parallel trend is the rise of\nphones and tablets as primary computing devices for many people. The powerful\nsensors present on these devices combined with the fact that they are mobile,\nmean they have access to data of an unprecedentedly diverse and private nature.\nModels learned on such data hold the promise of greatly improving usability by\npowering more intelligent applications, but the sensitive nature of the data\nmeans there are risks and responsibilities to storing it in a centralized\nlocation. To address the data privacy required for some data in these devices\nwe propose the use of Federated Learning (FL) so that specific data about\nservices performed by clients do not leave the source machines. Instead of\nsharing data, users collaboratively train a model by only sending weight\nupdates to a server. However, the naive use of FL in those scenarios exposes it\nto a risk of corruption, whether intentional or not, during the training phase.\nTo improve the security of the FL structure, we propose a decentralized\nBlockchain-based FL in an edge computing scenario. We also apply blockchain to\ncreate a reward mechanism in FL to enable incentive strategy for trainers.",
            "author": [
                "Joao Paulo de Brito Goncalves",
                "Guilherme Emerick Sathler",
                "Rodolfo da Silva Villaca"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00026v1",
                "http://arxiv.org/pdf/2312.00026v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08504v1",
            "title": "On semi-supervised estimation using exponential tilt mixture models",
            "updated": "2023-11-14T19:53:26Z",
            "published": "2023-11-14T19:53:26Z",
            "summary": "Consider a semi-supervised setting with a labeled dataset of binary responses\nand predictors and an unlabeled dataset with only the predictors. Logistic\nregression is equivalent to an exponential tilt model in the labeled\npopulation. For semi-supervised estimation, we develop further analysis and\nunderstanding of a statistical approach using exponential tilt mixture (ETM)\nmodels and maximum nonparametric likelihood estimation, while allowing that the\nclass proportions may differ between the unlabeled and labeled data. We derive\nasymptotic properties of ETM-based estimation and demonstrate improved\nefficiency over supervised logistic regression in a random sampling setup and\nan outcome-stratified sampling setup previously used. Moreover, we reconcile\nsuch efficiency improvement with the existing semiparametric efficiency theory\nwhen the class proportions in the unlabeled and labeled data are restricted to\nbe the same. We also provide a simulation study to numerically illustrate our\ntheoretical findings.",
            "author": [
                "Ye Tian",
                "Xinwei Zhang",
                "Zhiqiang Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08504v1",
                "http://arxiv.org/pdf/2311.08504v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08503v1",
            "title": "MADG: Margin-based Adversarial Learning for Domain Generalization",
            "updated": "2023-11-14T19:53:09Z",
            "published": "2023-11-14T19:53:09Z",
            "summary": "Domain Generalization (DG) techniques have emerged as a popular approach to\naddress the challenges of domain shift in Deep Learning (DL), with the goal of\ngeneralizing well to the target domain unseen during the training. In recent\nyears, numerous methods have been proposed to address the DG setting, among\nwhich one popular approach is the adversarial learning-based methodology. The\nmain idea behind adversarial DG methods is to learn domain-invariant features\nby minimizing a discrepancy metric. However, most adversarial DG methods use\n0-1 loss based $\\mathcal{H}\\Delta\\mathcal{H}$ divergence metric. In contrast,\nthe margin loss-based discrepancy metric has the following advantages: more\ninformative, tighter, practical, and efficiently optimizable. To mitigate this\ngap, this work proposes a novel adversarial learning DG algorithm, MADG,\nmotivated by a margin loss-based discrepancy metric. The proposed MADG model\nlearns domain-invariant features across all source domains and uses adversarial\ntraining to generalize well to the unseen target domain. We also provide a\ntheoretical analysis of the proposed MADG model based on the unseen target\nerror bound. Specifically, we construct the link between the source and unseen\ndomains in the real-valued hypothesis space and derive the generalization bound\nusing margin loss and Rademacher complexity. We extensively experiment with the\nMADG model on popular real-world DG datasets, VLCS, PACS, OfficeHome,\nDomainNet, and TerraIncognita. We evaluate the proposed algorithm on\nDomainBed's benchmark and observe consistent performance across all the\ndatasets.",
            "author": [
                "Aveen Dayal",
                "Vimal K. B.",
                "Linga Reddy Cenkeramaddi",
                "C. Krishna Mohan",
                "Abhinav Kumar",
                "Vineeth N Balasubramanian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08503v1",
                "http://arxiv.org/pdf/2311.08503v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08502v2",
            "title": "Variational Quantum Eigensolver with Constraints (VQEC): Solving\n  Constrained Optimization Problems via VQE",
            "updated": "2023-11-17T16:08:52Z",
            "published": "2023-11-14T19:49:09Z",
            "summary": "Variational quantum approaches have shown great promise in finding\nnear-optimal solutions to computationally challenging tasks. Nonetheless,\nenforcing constraints in a disciplined fashion has been largely unexplored. To\naddress this gap, this work proposes a hybrid quantum-classical algorithmic\nparadigm termed VQEC that extends the celebrated VQE to handle optimization\nwith constraints. As with the standard VQE, the vector of optimization\nvariables is captured by the state of a variational quantum circuit (VQC). To\ndeal with constraints, VQEC optimizes a Lagrangian function classically over\nboth the VQC parameters as well as the dual variables associated with\nconstraints. To comply with the quantum setup, variables are updated via a\nperturbed primal-dual method leveraging the parameter shift rule. Among a wide\ngamut of potential applications, we showcase how VQEC can approximately solve\nquadratically-constrained binary optimization (QCBO) problems, find stochastic\nbinary policies satisfying quadratic constraints on the average and in\nprobability, and solve large-scale linear programs (LP) over the probability\nsimplex. Under an assumption on the error for the VQC to approximate an\narbitrary probability mass function (PMF), we provide bounds on the optimality\ngap attained by a VQC. Numerical tests on a quantum simulator investigate the\neffect of various parameters and corroborate that VQEC can generate\nhigh-quality solutions.",
            "author": [
                "Thinh Viet Le",
                "Vassilis Kekatos"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08502v2",
                "http://arxiv.org/pdf/2311.08502v2"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph",
                "cs.LG",
                "math.OC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.16167v1",
            "title": "MMPDE-Net and Moving Sampling Physics-informed Neural Networks Based On\n  Moving Mesh Method",
            "updated": "2023-11-14T19:43:56Z",
            "published": "2023-11-14T19:43:56Z",
            "summary": "In this work, we propose an end-to-end adaptive sampling neural network\n(MMPDE-Net) based on the moving mesh PDE method, which can adaptively generate\nnew coordinates of sampling points by solving the moving mesh PDE. This model\nfocuses on improving the efficiency of individual sampling points. Moreover, we\nhave developed an iterative algorithm based on MMPDE-Net, which makes the\nsampling points more precise and controllable. Since MMPDE-Net is a framework\nindependent of the deep learning solver, we combine it with PINN to propose\nMS-PINN and demonstrate its effectiveness by performing error analysis under\nthe assumptions given in this paper. Meanwhile, we demonstrate the performance\nimprovement of MS-PINN compared to PINN through numerical experiments on four\ntypical examples to verify the effectiveness of our method.",
            "author": [
                "Yu Yang",
                "Qihong Yang",
                "Yangtao Deng",
                "Qiaolin He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.16167v1",
                "http://arxiv.org/pdf/2311.16167v1"
            ],
            "primary_category": "math.NA",
            "category": [
                "math.NA",
                "cs.AI",
                "cs.LG",
                "cs.NA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08496v1",
            "title": "Robust Differentiable Predictive Control with Safety Guarantees: A\n  Predictive Safety Filter Approach",
            "updated": "2023-11-14T19:42:00Z",
            "published": "2023-11-14T19:42:00Z",
            "summary": "In this paper, we propose a novel predictive safety filter that is robust to\nbounded perturbations and is combined with a learning-based control called\ndifferentiable predictive control (DPC). The proposed method provides rigorous\nguarantees of safety in the presence of bounded perturbations and implements\nDPC so long as the DPC control satisfies the system constraints. The approach\nalso incorporates two forms of event-triggering to reduce online computation.\nThe approach is comprised of a robust predictive safety filter that extends\nupon existing work to reject disturbances for discrete-time, time-varying\nnonlinear systems with time-varying constraints. The safety filter is based on\nnovel concepts of robust, discrete-time barrier functions and can be used to\nfilter any control law. Here we use the safety filter in conjunction with DPC\nas a promising policy optimization method. The approach is demonstrated on a\nsingle-integrator, two-tank system, and building example.",
            "author": [
                "Wenceslao Shaw Cortez",
                "Jan Drgona",
                "Draguna Vrabie",
                "Mahantesh Halappanavar"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08496v1",
                "http://arxiv.org/pdf/2311.08496v1"
            ],
            "primary_category": "cs.SY",
            "category": [
                "cs.SY",
                "eess.SY"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08493v1",
            "title": "Performance of Machine Learning Classification in Mammography Images\n  using BI-RADS",
            "updated": "2023-11-14T19:41:19Z",
            "published": "2023-11-14T19:41:19Z",
            "summary": "This research aims to investigate the classification accuracy of various\nstate-of-the-art image classification models across different categories of\nbreast ultrasound images, as defined by the Breast Imaging Reporting and Data\nSystem (BI-RADS). To achieve this, we have utilized a comprehensively assembled\ndataset of 2,945 mammographic images sourced from 1,540 patients. In order to\nconduct a thorough analysis, we employed six advanced classification\narchitectures, including VGG19 \\cite{simonyan2014very}, ResNet50\n\\cite{he2016deep}, GoogleNet \\cite{szegedy2015going}, ConvNext\n\\cite{liu2022convnet}, EfficientNet \\cite{tan2019efficientnet}, and Vision\nTransformers (ViT) \\cite{dosovitskiy2020image}, instead of traditional machine\nlearning models. We evaluate models in three different settings: full\nfine-tuning, linear evaluation and training from scratch. Our findings\ndemonstrate the effectiveness and capability of our Computer-Aided Diagnosis\n(CAD) system, with a remarkable accuracy of 76.39\\% and an F1 score of 67.94\\%\nin the full fine-tuning setting. Our findings indicate the potential for\nenhanced diagnostic accuracy in the field of breast imaging, providing a solid\nfoundation for future endeavors aiming to improve the precision and reliability\nof CAD systems in medical imaging.",
            "author": [
                "Malitha Gunawardhana",
                "Norbert Zolek"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08493v1",
                "http://arxiv.org/pdf/2311.08493v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08485v1",
            "title": "Automated Identification of Sexual Orientation and Gender Identity\n  Discriminatory Texts from Issue Comments",
            "updated": "2023-11-14T19:24:31Z",
            "published": "2023-11-14T19:24:31Z",
            "summary": "In an industry dominated by straight men, many developers representing other\ngender identities and sexual orientations often encounter hateful or\ndiscriminatory messages. Such communications pose barriers to participation for\nwomen and LGBTQ+ persons. Due to sheer volume, manual inspection of all\ncommunications for discriminatory communication is infeasible for a large-scale\nFree Open-Source Software (FLOSS) community. To address this challenge, this\nstudy aims to develop an automated mechanism to identify Sexual orientation and\nGender identity Discriminatory (SGID) texts from software developers'\ncommunications. On this goal, we trained and evaluated SGID4SE ( Sexual\norientation and Gender Identity Discriminatory text identification for (4)\nSoftware Engineering texts) as a supervised learning-based SGID detection tool.\nSGID4SE incorporates six preprocessing steps and ten state-of-the-art\nalgorithms. SGID4SE implements six different strategies to improve the\nperformance of the minority class. We empirically evaluated each strategy and\nidentified an optimum configuration for each algorithm. In our ten-fold\ncross-validation-based evaluations, a BERT-based model boosts the best\nperformance with 85.9% precision, 80.0% recall, and 82.9% F1-Score for the SGID\nclass. This model achieves 95.7% accuracy and 80.4% Matthews Correlation\nCoefficient. Our dataset and tool establish a foundation for further research\nin this direction.",
            "author": [
                "Sayma Sultana",
                "Jaydeb Sarker",
                "Farzana Israt",
                "Rajshakhar Paul",
                "Amiangshu Bosu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08485v1",
                "http://arxiv.org/pdf/2311.08485v1"
            ],
            "primary_category": "cs.SE",
            "category": [
                "cs.SE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08481v1",
            "title": "Functionality learning through specification instructions",
            "updated": "2023-11-14T19:15:55Z",
            "published": "2023-11-14T19:15:55Z",
            "summary": "Test suites assess natural language processing models' performance on\nspecific functionalities: cases of interest involving model robustness,\nfairness, or particular linguistic capabilities. They enable fine-grained\nevaluations of model aspects that would otherwise go unnoticed in standard\nevaluation datasets, but they do not address the problem of how to fix the\nfailure cases. Previous work has explored functionality learning by fine-tuning\nmodels on suite data. While this improves performance on seen functionalities,\nit often does not generalize to unseen ones and can harm general performance.\n  This paper analyses a fine-tuning-free approach to functionality learning.\nFor each functionality in a suite, we generate a specification instruction that\nencodes it. We combine the obtained specification instructions to create\nspecification-augmented prompts, which we feed to language models pre-trained\non natural instruction data to generate suite predictions. A core aspect of our\nanalysis is to measure the effect that including a set of specifications has on\na held-out set of unseen, qualitatively different specifications. Our\nexperiments across four tasks and models ranging from 80M to 175B parameters\nshow that smaller models struggle to follow specification instructions.\nHowever, larger models (> 3B params.) can benefit from specifications and even\ngeneralize desirable behaviors across functionalities.",
            "author": [
                "Pedro Henrique Luz de Araujo",
                "Benjamin Roth"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08481v1",
                "http://arxiv.org/pdf/2311.08481v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08479v1",
            "title": "Leveraging Foundation Models to Improve Lightweight Clients in Federated\n  Learning",
            "updated": "2023-11-14T19:10:56Z",
            "published": "2023-11-14T19:10:56Z",
            "summary": "Federated Learning (FL) is a distributed training paradigm that enables\nclients scattered across the world to cooperatively learn a global model\nwithout divulging confidential data. However, FL faces a significant challenge\nin the form of heterogeneous data distributions among clients, which leads to a\nreduction in performance and robustness. A recent approach to mitigating the\nimpact of heterogeneous data distributions is through the use of foundation\nmodels, which offer better performance at the cost of larger computational\noverheads and slower inference speeds. We introduce foundation model\ndistillation to assist in the federated training of lightweight client models\nand increase their performance under heterogeneous data settings while keeping\ninference costs low. Our results show improvement in the global model\nperformance on a balanced testing set, which contains rarely observed samples,\neven under extreme non-IID client data distributions. We conduct a thorough\nevaluation of our framework with different foundation model backbones on\nCIFAR10, with varying degrees of heterogeneous data distributions ranging from\nclass-specific data partitions across clients to dirichlet data sampling,\nparameterized by values between 0.01 and 1.0.",
            "author": [
                "Xidong Wu",
                "Wan-Yi Lin",
                "Devin Willmott",
                "Filipe Condessa",
                "Yufei Huang",
                "Zhenzhen Li",
                "Madan Ravi Ganesh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08479v1",
                "http://arxiv.org/pdf/2311.08479v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CV",
                "cs.DC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08473v1",
            "title": "Real-time topology optimization via learnable mappings",
            "updated": "2023-11-14T19:04:16Z",
            "published": "2023-11-14T19:04:16Z",
            "summary": "In traditional topology optimization, the computing time required to\niteratively update the material distribution within a design domain strongly\ndepends on the complexity or size of the problem, limiting its application in\nreal engineering contexts. This work proposes a multi-stage machine learning\nstrategy that aims to predict an optimal topology and the related stress fields\nof interest, either in 2D or 3D, without resorting to any iterative analysis\nand design process. The overall topology optimization is treated as regression\ntask in a low-dimensional latent space, that encodes the variability of the\ntarget designs. First, a fully-connected model is employed to surrogate the\nfunctional link between the parametric input space characterizing the design\nproblem and the latent space representation of the corresponding optimal\ntopology. The decoder branch of an autoencoder is then exploited to reconstruct\nthe desired optimal topology from its latent representation. The deep learning\nmodels are trained on a dataset generated through a standard method of topology\noptimization implementing the solid isotropic material with penalization, for\nvarying boundary and loading conditions. The underlying hypothesis behind the\nproposed strategy is that optimal topologies share enough common patterns to be\ncompressed into small latent space representations without significant\ninformation loss. Results relevant to a 2D Messerschmitt-B\\\"olkow-Blohm beam\nand a 3D bridge case demonstrate the capabilities of the proposed framework to\nprovide accurate optimal topology predictions in a fraction of a second.",
            "author": [
                "Gabriel Garayalde",
                "Matteo Torzoni",
                "Matteo Bruggi",
                "Alberto Corigliano"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08473v1",
                "http://arxiv.org/pdf/2311.08473v1"
            ],
            "primary_category": "cs.CE",
            "category": [
                "cs.CE"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08472v1",
            "title": "Selecting Shots for Demographic Fairness in Few-Shot Learning with Large\n  Language Models",
            "updated": "2023-11-14T19:02:03Z",
            "published": "2023-11-14T19:02:03Z",
            "summary": "Recently, work in NLP has shifted to few-shot (in-context) learning, with\nlarge language models (LLMs) performing well across a range of tasks. However,\nwhile fairness evaluations have become a standard for supervised methods,\nlittle is known about the fairness of LLMs as prediction systems. Further,\ncommon standard methods for fairness involve access to models weights or are\napplied during finetuning, which are not applicable in few-shot learning. Do\nLLMs exhibit prediction biases when used for standard NLP tasks? In this work,\nwe explore the effect of shots, which directly affect the performance of\nmodels, on the fairness of LLMs as NLP classification systems. We consider how\ndifferent shot selection strategies, both existing and new demographically\nsensitive methods, affect model fairness across three standard fairness\ndatasets. We discuss how future work can include LLM fairness evaluations.",
            "author": [
                "Carlos Aguirre",
                "Kuleen Sasse",
                "Isabel Cachola",
                "Mark Dredze"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08472v1",
                "http://arxiv.org/pdf/2311.08472v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08469v1",
            "title": "UNcommonsense Reasoning: Abductive Reasoning about Uncommon Situations",
            "updated": "2023-11-14T19:00:55Z",
            "published": "2023-11-14T19:00:55Z",
            "summary": "Language technologies that accurately model the dynamics of events must\nperform commonsense reasoning. Existing work evaluating commonsense reasoning\nfocuses on making inferences about common, everyday situations. To instead\ninvestigate the ability to model unusual, unexpected, and unlikely situations,\nwe explore the task of uncommonsense abductive reasoning. Given a piece of\ncontext with an unexpected outcome, this task requires reasoning abductively to\ngenerate a natural language explanation that makes the unexpected outcome more\nlikely in the context. To this end, we curate and release a new English\nlanguage corpus called UNcommonsense. We characterize the differences between\nthe performance of human explainers and the best performing large language\nmodels, finding that model-enhanced human-written explanations achieve the\nhighest quality by trading off between specificity and diversity. Finally, we\nexperiment with several online imitation learning algorithms to train open and\naccessible language models on this task. When compared with the vanilla\nsupervised fine-tuning approach, these methods consistently reduce lose rates\non both common and uncommonsense abductive reasoning judged by human\nevaluators.",
            "author": [
                "Wenting Zhao",
                "Justin T Chiu",
                "Jena D. Hwang",
                "Faeze Brahman",
                "Jack Hessel",
                "Sanjiban Choudhury",
                "Yejin Choi",
                "Xiang Lorraine Li",
                "Alane Suhr"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08469v1",
                "http://arxiv.org/pdf/2311.08469v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08460v1",
            "title": "Surrogate Modeling for Computationally Expensive Simulations of\n  Supernovae in High-Resolution Galaxy Simulations",
            "updated": "2023-11-14T19:00:03Z",
            "published": "2023-11-14T19:00:03Z",
            "summary": "Some stars are known to explode at the end of their lives, called supernovae\n(SNe). The substantial amount of matter and energy that SNe release provides\nsignificant feedback to star formation and gas dynamics in a galaxy. SNe\nrelease a substantial amount of matter and energy to the interstellar medium,\nresulting in significant feedback to star formation and gas dynamics in a\ngalaxy. While such feedback has a crucial role in galaxy formation and\nevolution, in simulations of galaxy formation, it has only been implemented\nusing simple {\\it sub-grid models} instead of numerically solving the evolution\nof gas elements around SNe in detail due to a lack of resolution. We develop a\nmethod combining machine learning and Gibbs sampling to predict how a supernova\n(SN) affects the surrounding gas. The fidelity of our model in the thermal\nenergy and momentum distribution outperforms the low-resolution SN simulations.\nOur method can replace the SN sub-grid models and help properly simulate\nun-resolved SN feedback in galaxy formation simulations. We find that employing\nour new approach reduces the necessary computational cost to $\\sim$ 1 percent\ncompared to directly resolving SN feedback.",
            "author": [
                "Keiya Hirashima",
                "Kana Moriwaki",
                "Michiko S. Fujii",
                "Yutaka Hirai",
                "Takayuki R. Saitoh",
                "Junichiro Makino",
                "Shirley Ho"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08460v1",
                "http://arxiv.org/pdf/2311.08460v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08403v1",
            "title": "Instant3D: Instant Text-to-3D Generation",
            "updated": "2023-11-14T18:59:59Z",
            "published": "2023-11-14T18:59:59Z",
            "summary": "Text-to-3D generation, which aims to synthesize vivid 3D objects from text\nprompts, has attracted much attention from the computer vision community. While\nseveral existing works have achieved impressive results for this task, they\nmainly rely on a time-consuming optimization paradigm. Specifically, these\nmethods optimize a neural field from scratch for each text prompt, taking\napproximately one hour or more to generate one object. This heavy and\nrepetitive training cost impedes their practical deployment. In this paper, we\npropose a novel framework for fast text-to-3D generation, dubbed Instant3D.\nOnce trained, Instant3D is able to create a 3D object for an unseen text prompt\nin less than one second with a single run of a feedforward network. We achieve\nthis remarkable speed by devising a new network that directly constructs a 3D\ntriplane from a text prompt. The core innovation of our Instant3D lies in our\nexploration of strategies to effectively inject text conditions into the\nnetwork. Furthermore, we propose a simple yet effective activation function,\nthe scaled-sigmoid, to replace the original sigmoid function, which speeds up\nthe training convergence by more than ten times. Finally, to address the Janus\n(multi-head) problem in 3D generation, we propose an adaptive Perp-Neg\nalgorithm that can dynamically adjust its concept negation scales according to\nthe severity of the Janus problem during training, effectively reducing the\nmulti-head effect. Extensive experiments on a wide variety of benchmark\ndatasets demonstrate that the proposed algorithm performs favorably against the\nstate-of-the-art methods both qualitatively and quantitatively, while achieving\nsignificantly better efficiency. The project page is at\nhttps://ming1993li.github.io/Instant3DProj.",
            "author": [
                "Ming Li",
                "Pan Zhou",
                "Jia-Wei Liu",
                "Jussi Keppo",
                "Min Lin",
                "Shuicheng Yan",
                "Xiangyu Xu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08403v1",
                "http://arxiv.org/pdf/2311.08403v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.GR",
                "cs.LG",
                "cs.MM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08401v1",
            "title": "Fine-tuning Language Models for Factuality",
            "updated": "2023-11-14T18:59:15Z",
            "published": "2023-11-14T18:59:15Z",
            "summary": "The fluency and creativity of large pre-trained language models (LLMs) have\nled to their widespread use, sometimes even as a replacement for traditional\nsearch engines. Yet language models are prone to making convincing but\nfactually inaccurate claims, often referred to as 'hallucinations.' These\nerrors can inadvertently spread misinformation or harmfully perpetuate\nmisconceptions. Further, manual fact-checking of model responses is a\ntime-consuming process, making human factuality labels expensive to acquire. In\nthis work, we fine-tune language models to be more factual, without human\nlabeling and targeting more open-ended generation settings than past work. We\nleverage two key recent innovations in NLP to do so. First, several recent\nworks have proposed methods for judging the factuality of open-ended text by\nmeasuring consistency with an external knowledge base or simply a large model's\nconfidence scores. Second, the direct preference optimization algorithm enables\nstraightforward fine-tuning of language models on objectives other than\nsupervised imitation, using a preference ranking over possible model responses.\nWe show that learning from automatically generated factuality preference\nrankings, generated either through existing retrieval systems or our novel\nretrieval-free approach, significantly improves the factuality (percent of\ngenerated claims that are correct) of Llama-2 on held-out topics compared with\nRLHF or decoding strategies targeted at factuality. At 7B scale, compared to\nLlama-2-chat, we observe 58% and 40% reduction in factual error rate when\ngenerating biographies and answering medical questions, respectively.",
            "author": [
                "Katherine Tian",
                "Eric Mitchell",
                "Huaxiu Yao",
                "Christopher D. Manning",
                "Chelsea Finn"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08401v1",
                "http://arxiv.org/pdf/2311.08401v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08398v2",
            "title": "Are Large Language Models Temporally Grounded?",
            "updated": "2023-11-16T09:41:28Z",
            "published": "2023-11-14T18:57:15Z",
            "summary": "Are Large language models (LLMs) temporally grounded? Since LLMs cannot\nperceive and interact with the environment, it is impossible to answer this\nquestion directly. Instead, we provide LLMs with textual narratives and probe\nthem with respect to their common-sense knowledge of the structure and duration\nof events, their ability to order events along a timeline, and self-consistency\nwithin their temporal model (e.g., temporal relations such as after and before\nare mutually exclusive for any pair of events). We evaluate state-of-the-art\nLLMs (such as LLaMA 2 and GPT-4) on three tasks reflecting these abilities.\nGenerally, we find that LLMs lag significantly behind both human performance as\nwell as small-scale, specialised LMs. In-context learning, instruction tuning,\nand chain-of-thought prompting reduce this gap only to a limited degree.\nCrucially, LLMs struggle the most with self-consistency, displaying incoherent\nbehaviour in at least 27.23% of their predictions. Contrary to expectations, we\nalso find that scaling the model size does not guarantee positive gains in\nperformance. To explain these results, we study the sources from which LLMs may\ngather temporal information: we find that sentence ordering in unlabelled\ntexts, available during pre-training, is only weakly correlated with event\nordering. Moreover, public instruction tuning mixtures contain few temporal\ntasks. Hence, we conclude that current LLMs lack a consistent temporal model of\ntextual narratives. Code, datasets, and LLM outputs are available at\nhttps://github.com/yfqiu-nlp/temporal-llms.",
            "author": [
                "Yifu Qiu",
                "Zheng Zhao",
                "Yftah Ziser",
                "Anna Korhonen",
                "Edoardo M. Ponti",
                "Shay B. Cohen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08398v2",
                "http://arxiv.org/pdf/2311.08398v2"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08396v1",
            "title": "Zero-shot audio captioning with audio-language model guidance and audio\n  context keywords",
            "updated": "2023-11-14T18:55:48Z",
            "published": "2023-11-14T18:55:48Z",
            "summary": "Zero-shot audio captioning aims at automatically generating descriptive\ntextual captions for audio content without prior training for this task.\nDifferent from speech recognition which translates audio content that contains\nspoken language into text, audio captioning is commonly concerned with ambient\nsounds, or sounds produced by a human performing an action. Inspired by\nzero-shot image captioning methods, we propose ZerAuCap, a novel framework for\nsummarising such general audio signals in a text caption without requiring\ntask-specific training. In particular, our framework exploits a pre-trained\nlarge language model (LLM) for generating the text which is guided by a\npre-trained audio-language model to produce captions that describe the audio\ncontent. Additionally, we use audio context keywords that prompt the language\nmodel to generate text that is broadly relevant to sounds. Our proposed\nframework achieves state-of-the-art results in zero-shot audio captioning on\nthe AudioCaps and Clotho datasets. Our code is available at\nhttps://github.com/ExplainableML/ZerAuCap.",
            "author": [
                "Leonard Salewski",
                "Stefan Fauth",
                "A. Sophia Koepke",
                "Zeynep Akata"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08396v1",
                "http://arxiv.org/pdf/2311.08396v1"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.AI",
                "cs.CL",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08393v2",
            "title": "MVSA-Net: Multi-View State-Action Recognition for Robust and Deployable\n  Trajectory Generation",
            "updated": "2023-11-18T21:51:33Z",
            "published": "2023-11-14T18:53:28Z",
            "summary": "The learn-from-observation (LfO) paradigm is a human-inspired mode for a\nrobot to learn to perform a task simply by watching it being performed. LfO can\nfacilitate robot integration on factory floors by minimizing disruption and\nreducing tedious programming. A key component of the LfO pipeline is a\ntransformation of the depth camera frames to the corresponding task state and\naction pairs, which are then relayed to learning techniques such as imitation\nor inverse reinforcement learning for understanding the task parameters. While\nseveral existing computer vision models analyze videos for activity\nrecognition, SA-Net specifically targets robotic LfO from RGB-D data. However,\nSA-Net and many other models analyze frame data captured from a single\nviewpoint. Their analysis is therefore highly sensitive to occlusions of the\nobserved task, which are frequent in deployments. An obvious way of reducing\nocclusions is to simultaneously observe the task from multiple viewpoints and\nsynchronously fuse the multiple streams in the model. Toward this, we present\nmulti-view SA-Net, which generalizes the SA-Net model to allow the perception\nof multiple viewpoints of the task activity, integrate them, and better\nrecognize the state and action in each frame. Performance evaluations on two\ndistinct domains establish that MVSA-Net recognizes the state-action pairs\nunder occlusion more accurately compared to single-view MVSA-Net and other\nbaselines. Our ablation studies further evaluate its performance under\ndifferent ambient conditions and establish the contribution of the architecture\ncomponents. As such, MVSA-Net offers a significantly more robust and deployable\nstate-action trajectory generation compared to previous methods.",
            "author": [
                "Ehsan Asali",
                "Prashant Doshi",
                "Jin Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08393v2",
                "http://arxiv.org/pdf/2311.08393v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08384v1",
            "title": "Offline Data Enhanced On-Policy Policy Gradient with Provable Guarantees",
            "updated": "2023-11-14T18:45:56Z",
            "published": "2023-11-14T18:45:56Z",
            "summary": "Hybrid RL is the setting where an RL agent has access to both offline data\nand online data by interacting with the real-world environment. In this work,\nwe propose a new hybrid RL algorithm that combines an on-policy actor-critic\nmethod with offline data. On-policy methods such as policy gradient and natural\npolicy gradient (NPG) have shown to be more robust to model misspecification,\nthough sometimes it may not be as sample efficient as methods that rely on\noff-policy learning. On the other hand, offline methods that depend on\noff-policy training often require strong assumptions in theory and are less\nstable to train in practice. Our new approach integrates a procedure of\noff-policy training on the offline data into an on-policy NPG framework. We\nshow that our approach, in theory, can obtain a best-of-both-worlds type of\nresult -- it achieves the state-of-art theoretical guarantees of offline RL\nwhen offline RL-specific assumptions hold, while at the same time maintaining\nthe theoretical guarantees of on-policy NPG regardless of the offline RL\nassumptions' validity. Experimentally, in challenging rich-observation\nenvironments, we show that our approach outperforms a state-of-the-art hybrid\nRL baseline which only relies on off-policy policy optimization, demonstrating\nthe empirical benefit of combining on-policy and off-policy learning. Our code\nis publicly available at https://github.com/YifeiZhou02/HNPG.",
            "author": [
                "Yifei Zhou",
                "Ayush Sekhari",
                "Yuda Song",
                "Wen Sun"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08384v1",
                "http://arxiv.org/pdf/2311.08384v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08380v1",
            "title": "Direct Preference Optimization for Neural Machine Translation with\n  Minimum Bayes Risk Decoding",
            "updated": "2023-11-14T18:43:51Z",
            "published": "2023-11-14T18:43:51Z",
            "summary": "Minimum Bayes Risk (MBR) decoding can significantly improve translation\nperformance of Multilingual Large Language Models (MLLMs). However, MBR\ndecoding is computationally expensive and in this paper, we show how recently\ndeveloped Reinforcement Learning (RL) technique, Direct Preference Optimization\n(DPO) can be used to fine-tune MLLMs so that we get the gains from MBR without\nthe additional computation in inference. Our fine-tuned models have\nsignificantly improved performance on multiple NMT test sets compared to base\nMLLMs without preference optimization. Our method boosts the translation\nperformance of MLLMs using relatively small monolingual fine-tuning sets.",
            "author": [
                "Guangyu Yang",
                "Jinghong Chen",
                "Weizhe Lin",
                "Bill Byrne"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08380v1",
                "http://arxiv.org/pdf/2311.08380v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08445v1",
            "title": "Lecture notes on quantum computing",
            "updated": "2023-11-14T18:42:55Z",
            "published": "2023-11-14T18:42:55Z",
            "summary": "These are the lecture notes of the master's course \"Quantum Computing\",\ntaught at Chalmers University of Technology every fall since 2020, with\nparticipation of students from RWTH Aachen and Delft University of Technology.\nThe aim of this course is to provide a theoretical overview of quantum\ncomputing, excluding specific hardware implementations. Topics covered in these\nnotes include quantum algorithms (such as Grover's algorithm, the quantum\nFourier transform, phase estimation, and Shor's algorithm), variational quantum\nalgorithms that utilise an interplay between classical and quantum computers\n[such as the variational quantum eigensolver (VQE) and the quantum approximate\noptimisation algorithm (QAOA), among others], quantum error correction, various\nversions of quantum computing (such as measurement-based quantum computation,\nadiabatic quantum computation, and the continuous-variable approach to quantum\ninformation), the intersection of quantum computing and machine learning, and\nquantum complexity theory. Lectures on these topics are compiled into 12\nchapters, most of which contain a few suggested exercises at the end, and\ninterspersed with four tutorials, which provide practical exercises as well as\nfurther details. At Chalmers, the course is taught in seven weeks, with three\ntwo-hour lectures or tutorials per week. It is recommended that the students\ntaking the course have some previous experience with quantum physics, but not\nstrictly necessary.",
            "author": [
                "Anton Frisk Kockum",
                "Ariadna Soro",
                "Laura Garc\u00eda-\u00c1lvarez",
                "Pontus Vikst\u00e5l",
                "Tom Douce",
                "G\u00f6ran Johansson",
                "Giulia Ferrini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08445v1",
                "http://arxiv.org/pdf/2311.08445v1"
            ],
            "primary_category": "quant-ph",
            "category": [
                "quant-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08379v3",
            "title": "Scheming AIs: Will AIs fake alignment during training in order to get\n  power?",
            "updated": "2023-11-27T19:30:35Z",
            "published": "2023-11-14T18:42:40Z",
            "summary": "This report examines whether advanced AIs that perform well in training will\nbe doing so in order to gain power later -- a behavior I call \"scheming\" (also\nsometimes called \"deceptive alignment\"). I conclude that scheming is a\ndisturbingly plausible outcome of using baseline machine learning methods to\ntrain goal-directed AIs sophisticated enough to scheme (my subjective\nprobability on such an outcome, given these conditions, is roughly 25%). In\nparticular: if performing well in training is a good strategy for gaining power\n(as I think it might well be), then a very wide variety of goals would motivate\nscheming -- and hence, good training performance. This makes it plausible that\ntraining might either land on such a goal naturally and then reinforce it, or\nactively push a model's motivations towards such a goal as an easy way of\nimproving performance. What's more, because schemers pretend to be aligned on\ntests designed to reveal their motivations, it may be quite difficult to tell\nwhether this has occurred. However, I also think there are reasons for comfort.\nIn particular: scheming may not actually be such a good strategy for gaining\npower; various selection pressures in training might work against schemer-like\ngoals (for example, relative to non-schemers, schemers need to engage in extra\ninstrumental reasoning, which might harm their training performance); and we\nmay be able to increase such pressures intentionally. The report discusses\nthese and a wide variety of other considerations in detail, and it suggests an\narray of empirical research directions for probing the topic further.",
            "author": [
                "Joe Carlsmith"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08379v3",
                "http://arxiv.org/pdf/2311.08379v3"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08377v1",
            "title": "Learning to Filter Context for Retrieval-Augmented Generation",
            "updated": "2023-11-14T18:41:54Z",
            "published": "2023-11-14T18:41:54Z",
            "summary": "On-the-fly retrieval of relevant knowledge has proven an essential element of\nreliable systems for tasks such as open-domain question answering and fact\nverification. However, because retrieval systems are not perfect, generation\nmodels are required to generate outputs given partially or entirely irrelevant\npassages. This can cause over- or under-reliance on context, and result in\nproblems in the generated output such as hallucinations. To alleviate these\nproblems, we propose FILCO, a method that improves the quality of the context\nprovided to the generator by (1) identifying useful context based on lexical\nand information-theoretic approaches, and (2) training context filtering models\nthat can filter retrieved contexts at test time. We experiment on six\nknowledge-intensive tasks with FLAN-T5 and LLaMa2, and demonstrate that our\nmethod outperforms existing approaches on extractive question answering (QA),\ncomplex multi-hop and long-form QA, fact verification, and dialog generation\ntasks. FILCO effectively improves the quality of context, whether or not it\nsupports the canonical output.",
            "author": [
                "Zhiruo Wang",
                "Jun Araki",
                "Zhengbao Jiang",
                "Md Rizwan Parvez",
                "Graham Neubig"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08377v1",
                "http://arxiv.org/pdf/2311.08377v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08376v1",
            "title": "Ensemble sampling for linear bandits: small ensembles suffice",
            "updated": "2023-11-14T18:41:28Z",
            "published": "2023-11-14T18:41:28Z",
            "summary": "We provide the first useful, rigorous analysis of ensemble sampling for the\nstochastic linear bandit setting. In particular, we show that, under standard\nassumptions, for a $d$-dimensional stochastic linear bandit with an interaction\nhorizon $T$, ensemble sampling with an ensemble of size $m$ on the order of $d\n\\log T$ incurs regret bounded by order $(d \\log T)^{5/2} \\sqrt{T}$. Ours is the\nfirst result in any structured setting not to require the size of the ensemble\nto scale linearly with $T$ -- which defeats the purpose of ensemble sampling --\nwhile obtaining near $\\sqrt{T}$ order regret. Ours is also the first result\nthat allows infinite action sets.",
            "author": [
                "David Janz",
                "Alexander E. Litvak",
                "Csaba Szepesv\u00e1ri"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08376v1",
                "http://arxiv.org/pdf/2311.08376v1"
            ],
            "primary_category": "stat.ML",
            "category": [
                "stat.ML",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08371v1",
            "title": "USLR: an open-source tool for unbiased and smooth longitudinal\n  registration of brain MR",
            "updated": "2023-11-14T18:34:18Z",
            "published": "2023-11-14T18:34:18Z",
            "summary": "We present USLR, a computational framework for longitudinal registration of\nbrain MRI scans to estimate nonlinear image trajectories that are smooth across\ntime, unbiased to any timepoint, and robust to imaging artefacts. It operates\non the Lie algebra parameterisation of spatial transforms (which is compatible\nwith rigid transforms and stationary velocity fields for nonlinear deformation)\nand takes advantage of log-domain properties to solve the problem using\nBayesian inference. USRL estimates rigid and nonlinear registrations that: (i)\nbring all timepoints to an unbiased subject-specific space; and (i) compute a\nsmooth trajectory across the imaging time-series. We capitalise on\nlearning-based registration algorithms and closed-form expressions for fast\ninference. A use-case Alzheimer's disease study is used to showcase the\nbenefits of the pipeline in multiple fronts, such as time-consistent image\nsegmentation to reduce intra-subject variability, subject-specific prediction\nor population analysis using tensor-based morphometry. We demonstrate that such\napproach improves upon cross-sectional methods in identifying group\ndifferences, which can be helpful in detecting more subtle atrophy levels or in\nreducing sample sizes in clinical trials. The code is publicly available in\nhttps://github.com/acasamitjana/uslr",
            "author": [
                "Adri\u00e0 Casamitjana",
                "Roser Sala-Llonch",
                "Karim Lekadir",
                "Juan Eugenio Iglesias"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08371v1",
                "http://arxiv.org/pdf/2311.08371v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09253v1",
            "title": "The Perception-Robustness Tradeoff in Deterministic Image Restoration",
            "updated": "2023-11-14T18:30:34Z",
            "published": "2023-11-14T18:30:34Z",
            "summary": "We study the behavior of deterministic methods for solving inverse problems\nin imaging. These methods are commonly designed to achieve two goals: (1)\nattaining high perceptual quality, and (2) generating reconstructions that are\nconsistent with the measurements. We provide a rigorous proof that the better a\npredictor satisfies these two requirements, the larger its Lipschitz constant\nmust be, regardless of the nature of the degradation involved. In particular,\nto approach perfect perceptual quality and perfect consistency, the Lipschitz\nconstant of the model must grow to infinity. This implies that such methods are\nnecessarily more susceptible to adversarial attacks. We demonstrate our theory\non single image super-resolution algorithms, addressing both noisy and\nnoiseless settings. We also show how this undesired behavior can be leveraged\nto explore the posterior distribution, thereby allowing the deterministic model\nto imitate stochastic methods.",
            "author": [
                "Guy Ohayon",
                "Tomer Michaeli",
                "Michael Elad"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09253v1",
                "http://arxiv.org/pdf/2311.09253v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "eess.SP"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08364v1",
            "title": "Plum: Prompt Learning using Metaheuristic",
            "updated": "2023-11-14T18:14:56Z",
            "published": "2023-11-14T18:14:56Z",
            "summary": "Since the emergence of large language models, prompt learning has become a\npopular method for optimizing and customizing these models. Special prompts,\nsuch as Chain-of-Thought, have even revealed previously unknown reasoning\ncapabilities within these models. However, the progress of discovering\neffective prompts has been slow, driving a desire for general prompt\noptimization methods. Unfortunately, few existing prompt learning methods\nsatisfy the criteria of being truly \"general\", i.e., automatic, discrete,\nblack-box, gradient-free, and interpretable all at once. In this paper, we\nintroduce metaheuristics, a branch of discrete non-convex optimization methods\nwith over 100 options, as a promising approach to prompt learning. Within our\nparadigm, we test six typical methods: hill climbing, simulated annealing,\ngenetic algorithms with/without crossover, tabu search, and harmony search,\ndemonstrating their effectiveness in black-box prompt learning and\nChain-of-Thought prompt tuning. Furthermore, we show that these methods can be\nused to discover more human-understandable prompts that were previously\nunknown, opening the door to a cornucopia of possibilities in prompt\noptimization. We release all the codes in\n\\url{https://github.com/research4pan/Plum}.",
            "author": [
                "Rui Pan",
                "Shuo Xing",
                "Shizhe Diao",
                "Xiang Liu",
                "Kashun Shum",
                "Jipeng Zhang",
                "Tong Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08364v1",
                "http://arxiv.org/pdf/2311.08364v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.DM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08362v1",
            "title": "Transformers can optimally learn regression mixture models",
            "updated": "2023-11-14T18:09:15Z",
            "published": "2023-11-14T18:09:15Z",
            "summary": "Mixture models arise in many regression problems, but most methods have seen\nlimited adoption partly due to these algorithms' highly-tailored and\nmodel-specific nature. On the other hand, transformers are flexible, neural\nsequence models that present the intriguing possibility of providing\ngeneral-purpose prediction methods, even in this mixture setting. In this work,\nwe investigate the hypothesis that transformers can learn an optimal predictor\nfor mixtures of regressions. We construct a generative process for a mixture of\nlinear regressions for which the decision-theoretic optimal procedure is given\nby data-driven exponential weights on a finite set of parameters. We observe\nthat transformers achieve low mean-squared error on data generated via this\nprocess. By probing the transformer's output at inference time, we also show\nthat transformers typically make predictions that are close to the optimal\npredictor. Our experiments also demonstrate that transformers can learn\nmixtures of regressions in a sample-efficient fashion and are somewhat robust\nto distribution shifts. We complement our experimental observations by proving\nconstructively that the decision-theoretic optimal procedure is indeed\nimplementable by a transformer.",
            "author": [
                "Reese Pathak",
                "Rajat Sen",
                "Weihao Kong",
                "Abhimanyu Das"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08362v1",
                "http://arxiv.org/pdf/2311.08362v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08360v2",
            "title": "The Transient Nature of Emergent In-Context Learning in Transformers",
            "updated": "2023-11-15T04:02:44Z",
            "published": "2023-11-14T18:03:20Z",
            "summary": "Transformer neural networks can exhibit a surprising capacity for in-context\nlearning (ICL) despite not being explicitly trained for it. Prior work has\nprovided a deeper understanding of how ICL emerges in transformers, e.g.\nthrough the lens of mechanistic interpretability, Bayesian inference, or by\nexamining the distributional properties of training data. However, in each of\nthese cases, ICL is treated largely as a persistent phenomenon; namely, once\nICL emerges, it is assumed to persist asymptotically. Here, we show that the\nemergence of ICL during transformer training is, in fact, often transient. We\ntrain transformers on synthetic data designed so that both ICL and in-weights\nlearning (IWL) strategies can lead to correct predictions. We find that ICL\nfirst emerges, then disappears and gives way to IWL, all while the training\nloss decreases, indicating an asymptotic preference for IWL. The transient\nnature of ICL is observed in transformers across a range of model sizes and\ndatasets, raising the question of how much to \"overtrain\" transformers when\nseeking compact, cheaper-to-run models. We find that L2 regularization may\noffer a path to more persistent ICL that removes the need for early stopping\nbased on ICL-style validation tasks. Finally, we present initial evidence that\nICL transience may be caused by competition between ICL and IWL circuits.",
            "author": [
                "Aaditya K. Singh",
                "Stephanie C. Y. Chan",
                "Ted Moskovitz",
                "Erin Grant",
                "Andrew M. Saxe",
                "Felix Hill"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08360v2",
                "http://arxiv.org/pdf/2311.08360v2"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08359v1",
            "title": "Rotation-Agnostic Image Representation Learning for Digital Pathology",
            "updated": "2023-11-14T18:01:15Z",
            "published": "2023-11-14T18:01:15Z",
            "summary": "This paper addresses complex challenges in histopathological image analysis\nthrough three key contributions. Firstly, it introduces a fast patch selection\nmethod, FPS, for whole-slide image (WSI) analysis, significantly reducing\ncomputational cost while maintaining accuracy. Secondly, it presents PathDino,\na lightweight histopathology feature extractor with a minimal configuration of\nfive Transformer blocks and only 9 million parameters, markedly fewer than\nalternatives. Thirdly, it introduces a rotation-agnostic representation\nlearning paradigm using self-supervised learning, effectively mitigating\noverfitting. We also show that our compact model outperforms existing\nstate-of-the-art histopathology-specific vision transformers on 12 diverse\ndatasets, including both internal datasets spanning four sites (breast, liver,\nskin, and colorectal) and seven public datasets (PANDA, CAMELYON16, BRACS,\nDigestPath, Kather, PanNuke, and WSSS4LUAD). Notably, even with a training\ndataset of 6 million histopathology patches from The Cancer Genome Atlas\n(TCGA), our approach demonstrates an average 8.5% improvement in patch-level\nmajority vote performance. These contributions provide a robust framework for\nenhancing image analysis in digital pathology, rigorously validated through\nextensive evaluation. Project Page: https://rhazeslab.github.io/PathDino-Page/",
            "author": [
                "Saghir Alfasly",
                "Abubakr Shafique",
                "Peyman Nejat",
                "Jibran Khan",
                "Areej Alsaafin",
                "Ghazal Alabtah",
                "H. R. Tizhoosh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08359v1",
                "http://arxiv.org/pdf/2311.08359v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08357v1",
            "title": "Sparsity-Preserving Differentially Private Training of Large Embedding\n  Models",
            "updated": "2023-11-14T17:59:51Z",
            "published": "2023-11-14T17:59:51Z",
            "summary": "As the use of large embedding models in recommendation systems and language\napplications increases, concerns over user data privacy have also risen.\nDP-SGD, a training algorithm that combines differential privacy with stochastic\ngradient descent, has been the workhorse in protecting user privacy without\ncompromising model accuracy by much. However, applying DP-SGD naively to\nembedding models can destroy gradient sparsity, leading to reduced training\nefficiency. To address this issue, we present two new algorithms, DP-FEST and\nDP-AdaFEST, that preserve gradient sparsity during private training of large\nembedding models. Our algorithms achieve substantial reductions ($10^6 \\times$)\nin gradient size, while maintaining comparable levels of accuracy, on benchmark\nreal-world datasets.",
            "author": [
                "Badih Ghazi",
                "Yangsibo Huang",
                "Pritish Kamath",
                "Ravi Kumar",
                "Pasin Manurangsi",
                "Amer Sinha",
                "Chiyuan Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08357v1",
                "http://arxiv.org/pdf/2311.08357v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.CR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08345v1",
            "title": "Speeding Up Optimization-based Motion Planning through Deep Learning",
            "updated": "2023-11-14T17:42:01Z",
            "published": "2023-11-14T17:42:01Z",
            "summary": "Planning collision-free motions for robots with many degrees of freedom is\nchallenging in environments with complex obstacle geometries. Recent work\nintroduced the idea of speeding up the planning by encoding prior experience of\nsuccessful motion plans in a neural network. However, this \"neural motion\nplanning\" did not scale to complex robots in unseen 3D environments as needed\nfor real-world applications. Here, we introduce \"basis point set\", well-known\nin computer vision, to neural motion planning as a modern compact environment\nencoding enabling efficient supervised training networks that generalize well\nover diverse 3D worlds. Combined with a new elaborate training scheme, we reach\na planning success rate of 100%. We use the network to predict an educated\ninitial guess for an optimization-based planner (OMP), which quickly converges\nto a feasible solution, massively outperforming random multi-starts when tested\non previously unseen environments. For the DLR humanoid Agile Justin with 19DoF\nand in challenging obstacle environments, optimal paths can be generated in\n200ms using only a single CPU core. We also show a first successful real-world\nexperiment based on a high-resolution world model from an integrated 3D sensor.",
            "author": [
                "Johannes Tenhumberg",
                "Darius Burschka",
                "Berthold B\u00e4uml"
            ],
            "link": [
                "http://dx.doi.org/10.1109/IROS47612.2022.9981717",
                "http://arxiv.org/abs/2311.08345v1",
                "http://arxiv.org/pdf/2311.08345v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08442v1",
            "title": "Mean-field variational inference with the TAP free energy: Geometric and\n  statistical properties in linear models",
            "updated": "2023-11-14T17:35:01Z",
            "published": "2023-11-14T17:35:01Z",
            "summary": "We study mean-field variational inference in a Bayesian linear model when the\nsample size n is comparable to the dimension p. In high dimensions, the common\napproach of minimizing a Kullback-Leibler divergence from the posterior\ndistribution, or maximizing an evidence lower bound, may deviate from the true\nposterior mean and underestimate posterior uncertainty. We study instead\nminimization of the TAP free energy, showing in a high-dimensional asymptotic\nframework that it has a local minimizer which provides a consistent estimate of\nthe posterior marginals and may be used for correctly calibrated posterior\ninference. Geometrically, we show that the landscape of the TAP free energy is\nstrongly convex in an extensive neighborhood of this local minimizer, which\nunder certain general conditions can be found by an Approximate Message Passing\n(AMP) algorithm. We then exhibit an efficient algorithm that linearly converges\nto the minimizer within this local neighborhood. In settings where it is\nconjectured that no efficient algorithm can find this local neighborhood, we\nprove analogous geometric properties for a local minimizer of the TAP free\nenergy reachable by AMP, and show that posterior inference based on this\nminimizer remains correctly calibrated.",
            "author": [
                "Michael Celentano",
                "Zhou Fan",
                "Licong Lin",
                "Song Mei"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08442v1",
                "http://arxiv.org/pdf/2311.08442v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "cs.LG",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08340v1",
            "title": "Causal Message Passing: A Method for Experiments with Unknown and\n  General Network Interference",
            "updated": "2023-11-14T17:31:50Z",
            "published": "2023-11-14T17:31:50Z",
            "summary": "Randomized experiments are a powerful methodology for data-driven evaluation\nof decisions or interventions. Yet, their validity may be undermined by network\ninterference. This occurs when the treatment of one unit impacts not only its\noutcome but also that of connected units, biasing traditional treatment effect\nestimations. Our study introduces a new framework to accommodate complex and\nunknown network interference, moving beyond specialized models in the existing\nliterature. Our framework, which we term causal message-passing, is grounded in\na high-dimensional approximate message passing methodology and is specifically\ntailored to experimental design settings with prevalent network interference.\nUtilizing causal message-passing, we present a practical algorithm for\nestimating the total treatment effect and demonstrate its efficacy in four\nnumerical scenarios, each with its unique interference structure.",
            "author": [
                "Sadegh Shirani",
                "Mohsen Bayati"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08340v1",
                "http://arxiv.org/pdf/2311.08340v1"
            ],
            "primary_category": "stat.ME",
            "category": [
                "stat.ME",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08331v1",
            "title": "Radio Galaxy Zoo: Leveraging latent space representations from\n  variational autoencoder",
            "updated": "2023-11-14T17:21:16Z",
            "published": "2023-11-14T17:21:16Z",
            "summary": "We propose to learn latent space representations of radio galaxies, and train\na very deep variational autoencoder (\\protect\\Verb+VDVAE+) on RGZ DR1, an\nunlabeled dataset, to this end. We show that the encoded features can be\nleveraged for downstream tasks such as classifying galaxies in labeled\ndatasets, and similarity search. Results show that the model is able to\nreconstruct its given inputs, capturing the salient features of the latter. We\nuse the latent codes of galaxy images, from MiraBest Confident and FR-DEEP NVSS\ndatasets, to train various non-neural network classifiers. It is found that the\nlatter can differentiate FRI from FRII galaxies achieving \\textit{accuracy}\n$\\ge 76\\%$, \\textit{roc-auc} $\\ge 0.86$, \\textit{specificity} $\\ge 0.73$ and\n\\textit{recall} $\\ge 0.78$ on MiraBest Confident dataset, comparable to results\nobtained in previous studies. The performance of simple classifiers trained on\nFR-DEEP NVSS data representations is on par with that of a deep learning\nclassifier (CNN based) trained on images in previous work, highlighting how\npowerful the compressed information is. We successfully exploit the learned\nrepresentations to search for galaxies in a dataset that are semantically\nsimilar to a query image belonging to a different dataset. Although generating\nnew galaxy images (e.g. for data augmentation) is not our primary objective, we\nfind that the \\protect\\Verb+VDVAE+ model is a relatively good emulator.\nFinally, as a step toward detecting anomaly/novelty, a density estimator --\nMasked Autoregressive Flow (\\protect\\Verb+MAF+) -- is trained on the latent\ncodes, such that the log-likelihood of data can be estimated. The downstream\ntasks conducted in this work demonstrate the meaningfulness of the latent\ncodes.",
            "author": [
                "Sambatra Andrianomena",
                "Hongming Tang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08331v1",
                "http://arxiv.org/pdf/2311.08331v1"
            ],
            "primary_category": "astro-ph.GA",
            "category": [
                "astro-ph.GA",
                "astro-ph.IM"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08330v2",
            "title": "Generative De-Quantization for Neural Speech Codec via Latent Diffusion",
            "updated": "2023-11-15T15:23:03Z",
            "published": "2023-11-14T17:19:40Z",
            "summary": "In low-bitrate speech coding, end-to-end speech coding networks aim to learn\ncompact yet expressive features and a powerful decoder in a single network. A\nchallenging problem as such results in unwelcome complexity increase and\ninferior speech quality. In this paper, we propose to separate the\nrepresentation learning and information reconstruction tasks. We leverage an\nend-to-end codec for learning low-dimensional discrete tokens and employ a\nlatent diffusion model to de-quantize coded features into a high-dimensional\ncontinuous space, relieving the decoder's burden of de-quantizing and\nupsampling. To mitigate the issue of over-smooth generation, we introduce\nmidway-infilling with less noise reduction and stronger conditioning. In\nablation studies, we investigate the hyperparameters for midway-infilling and\nlatent diffusion space with different dimensions. Subjective listening tests\nshow that our model outperforms the state-of-the-art at two low bitrates, 1.5\nand 3 kbps. Codes and samples of this work are available on our webpage.",
            "author": [
                "Haici Yang",
                "Inseon Jang",
                "Minje Kim"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08330v2",
                "http://arxiv.org/pdf/2311.08330v2"
            ],
            "primary_category": "eess.AS",
            "category": [
                "eess.AS",
                "cs.SD"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08324v1",
            "title": "Anti-LM Decoding for Zero-shot In-context Machine Translation",
            "updated": "2023-11-14T17:09:43Z",
            "published": "2023-11-14T17:09:43Z",
            "summary": "Zero-shot In-context learning is the phenomenon where models can perform the\ntask simply given the instructions. However, pre-trained large language models\nare known to be poorly calibrated for this task. One of the most effective\napproaches to handling this bias is to adopt a contrastive decoding objective,\nwhich accounts for the prior probability of generating the next token by\nconditioning on some context. This work introduces an Anti-Language Model\nobjective with a decay factor designed to address the weaknesses of In-context\nMachine Translation. We conduct our experiments across 3 model types and sizes,\n3 language directions, and for both greedy decoding and beam search ($B=5$).\nThe proposed method outperforms other state-of-art decoding objectives, with up\nto $20$ BLEU point improvement from the default objective observed in some\nsettings.",
            "author": [
                "Suzanna Sia",
                "Alexandra DeLucia",
                "Kevin Duh"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08324v1",
                "http://arxiv.org/pdf/2311.08324v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08315v1",
            "title": "Total Empiricism: Learning from Data",
            "updated": "2023-11-14T16:59:37Z",
            "published": "2023-11-14T16:59:37Z",
            "summary": "Statistical analysis is an important tool to distinguish systematic from\nchance findings. Current statistical analyses rely on distributional\nassumptions reflecting the structure of some underlying model, which if not met\nlead to problems in the analysis and interpretation of the results. Instead of\ntrying to fix the model or \"correct\" the data, we here describe a totally\nempirical statistical approach that does not rely on ad hoc distributional\nassumptions in order to overcome many problems in contemporary statistics.\nStarting from elementary combinatorics, we motivate an information-guided\nformalism to quantify knowledge extracted from the given data. Subsequently, we\nderive model-agnostic methods to identify patterns that are solely evidenced by\nthe data based on our prior knowledge. The data-centric character of empiricism\nallows for its universal applicability, particularly as sample size grows\nlarger. In this comprehensive framework, we re-interpret and extend model\ndistributions, scores and statistical tests used in different schools of\nstatistics.",
            "author": [
                "Orestis Loukas",
                "Ho Ryun Chung"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08315v1",
                "http://arxiv.org/pdf/2311.08315v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "physics.data-an",
                "stat.ME",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08314v1",
            "title": "Convolutional Neural Networks Exploiting Attributes of Biological\n  Neurons",
            "updated": "2023-11-14T16:58:18Z",
            "published": "2023-11-14T16:58:18Z",
            "summary": "In this era of artificial intelligence, deep neural networks like\nConvolutional Neural Networks (CNNs) have emerged as front-runners, often\nsurpassing human capabilities. These deep networks are often perceived as the\npanacea for all challenges. Unfortunately, a common downside of these networks\nis their ''black-box'' character, which does not necessarily mirror the\noperation of biological neural systems. Some even have millions/billions of\nlearnable (tunable) parameters, and their training demands extensive data and\ntime.\n  Here, we integrate the principles of biological neurons in certain layer(s)\nof CNNs. Specifically, we explore the use of neuro-science-inspired\ncomputational models of the Lateral Geniculate Nucleus (LGN) and simple cells\nof the primary visual cortex. By leveraging such models, we aim to extract\nimage features to use as input to CNNs, hoping to enhance training efficiency\nand achieve better accuracy. We aspire to enable shallow networks with a\nPush-Pull Combination of Receptive Fields (PP-CORF) model of simple cells as\nthe foundation layer of CNNs to enhance their learning process and performance.\nTo achieve this, we propose a two-tower CNN, one shallow tower and the other as\nResNet 18. Rather than extracting the features blindly, it seeks to mimic how\nthe brain perceives and extracts features. The proposed system exhibits a\nnoticeable improvement in the performance (on an average of $5\\%-10\\%$) on\nCIFAR-10, CIFAR-100, and ImageNet-100 datasets compared to ResNet-18. We also\ncheck the efficiency of only the Push-Pull tower of the network.",
            "author": [
                "Neeraj Kumar Singh",
                "Nikhil R. Pal"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08314v1",
                "http://arxiv.org/pdf/2311.08314v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08309v1",
            "title": "Introducing an Improved Information-Theoretic Measure of Predictive\n  Uncertainty",
            "updated": "2023-11-14T16:55:12Z",
            "published": "2023-11-14T16:55:12Z",
            "summary": "Applying a machine learning model for decision-making in the real world\nrequires to distinguish what the model knows from what it does not. A critical\nfactor in assessing the knowledge of a model is to quantify its predictive\nuncertainty. Predictive uncertainty is commonly measured by the entropy of the\nBayesian model average (BMA) predictive distribution. Yet, the properness of\nthis current measure of predictive uncertainty was recently questioned. We\nprovide new insights regarding those limitations. Our analyses show that the\ncurrent measure erroneously assumes that the BMA predictive distribution is\nequivalent to the predictive distribution of the true model that generated the\ndataset. Consequently, we introduce a theoretically grounded measure to\novercome these limitations. We experimentally verify the benefits of our\nintroduced measure of predictive uncertainty. We find that our introduced\nmeasure behaves more reasonably in controlled synthetic tasks. Moreover, our\nevaluations on ImageNet demonstrate that our introduced measure is advantageous\nin real-world applications utilizing predictive uncertainty.",
            "author": [
                "Kajetan Schweighofer",
                "Lukas Aichberger",
                "Mykyta Ielanskyi",
                "Sepp Hochreiter"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08309v1",
                "http://arxiv.org/pdf/2311.08309v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "stat.ML"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08306v1",
            "title": "On-the-Fly Fusion of Large Language Models and Machine Translation",
            "updated": "2023-11-14T16:49:33Z",
            "published": "2023-11-14T16:49:33Z",
            "summary": "We propose the on-the-fly ensembling of a machine translation model with an\nLLM, prompted on the same task and input. We perform experiments on 4 language\npairs (both directions) with varying data amounts. We find that a slightly\nweaker-at-translation LLM can improve translations of a NMT model, and\nensembling with an LLM can produce better translations than ensembling two\nstronger MT models. We combine our method with various techniques from LLM\nprompting, such as in context learning and translation context.",
            "author": [
                "Hieu Hoang",
                "Huda Khayrallah",
                "Marcin Junczys-Dowmunt"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08306v1",
                "http://arxiv.org/pdf/2311.08306v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08302v2",
            "title": "Inverse Learning with Extremely Sparse Feedback for Recommendation",
            "updated": "2023-11-20T23:52:58Z",
            "published": "2023-11-14T16:46:10Z",
            "summary": "Modern personalized recommendation services often rely on user feedback,\neither explicit or implicit, to improve the quality of services. Explicit\nfeedback refers to behaviors like ratings, while implicit feedback refers to\nbehaviors like user clicks. However, in the scenario of full-screen video\nviewing experiences like Tiktok and Reels, the click action is absent,\nresulting in unclear feedback from users, hence introducing noises in modeling\ntraining. Existing approaches on de-noising recommendation mainly focus on\npositive instances while ignoring the noise in a large amount of sampled\nnegative feedback. In this paper, we propose a meta-learning method to annotate\nthe unlabeled data from loss and gradient perspectives, which considers the\nnoises in both positive and negative instances. Specifically, we first propose\nan Inverse Dual Loss (IDL) to boost the true label learning and prevent the\nfalse label learning. Then we further propose an Inverse Gradient (IG) method\nto explore the correct updating gradient and adjust the updating based on\nmeta-learning. Finally, we conduct extensive experiments on both benchmark and\nindustrial datasets where our proposed method can significantly improve AUC by\n9.25% against state-of-the-art methods. Further analysis verifies the proposed\ninverse learning framework is model-agnostic and can improve a variety of\nrecommendation backbones. The source code, along with the best hyper-parameter\nsettings, is available at this link:\nhttps://github.com/Guanyu-Lin/InverseLearning.",
            "author": [
                "Guanyu Lin",
                "Chen Gao",
                "Yu Zheng",
                "Yinfeng Li",
                "Jianxin Chang",
                "Yanan Niu",
                "Yang Song",
                "Kun Gai",
                "Zhiheng Li",
                "Depeng Jin",
                "Yong Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08302v2",
                "http://arxiv.org/pdf/2311.08302v2"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08300v1",
            "title": "Workflow-Guided Response Generation for Task-Oriented Dialogue",
            "updated": "2023-11-14T16:44:33Z",
            "published": "2023-11-14T16:44:33Z",
            "summary": "Task-oriented dialogue (TOD) systems aim to achieve specific goals through\ninteractive dialogue. Such tasks usually involve following specific workflows,\ni.e. executing a sequence of actions in a particular order. While prior work\nhas focused on supervised learning methods to condition on past actions, they\ndo not explicitly optimize for compliance to a desired workflow. In this paper,\nwe propose a novel framework based on reinforcement learning (RL) to generate\ndialogue responses that are aligned with a given workflow. Our framework\nconsists of ComplianceScorer, a metric designed to evaluate how well a\ngenerated response executes the specified action, combined with an RL\nopimization process that utilizes an interactive sampling technique. We\nevaluate our approach on two TOD datasets, Action-Based Conversations Dataset\n(ABCD) (Chen et al., 2021a) and MultiWOZ 2.2 (Zang et al., 2020) on a range of\nautomated and human evaluation metrics. Our findings indicate that our RL-based\nframework outperforms baselines and is effective at enerating responses that\nboth comply with the intended workflows while being expressed in a natural and\nfluent manner.",
            "author": [
                "Do June Min",
                "Paloma Sodhi",
                "Ramya Ramakrishnan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08300v1",
                "http://arxiv.org/pdf/2311.08300v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08299v1",
            "title": "VERVE: Template-based ReflectiVE Rewriting for MotiVational IntErviewing",
            "updated": "2023-11-14T16:44:16Z",
            "published": "2023-11-14T16:44:16Z",
            "summary": "Reflective listening is a fundamental skill that counselors must acquire to\nachieve proficiency in motivational interviewing (MI). It involves responding\nin a manner that acknowledges and explores the meaning of what the client has\nexpressed in the conversation. In this work, we introduce the task of\ncounseling response rewriting, which transforms non-reflective statements into\nreflective responses. We introduce VERVE, a template-based rewriting system\nwith paraphrase-augmented training and adaptive template updating. VERVE first\ncreates a template by identifying and filtering out tokens that are not\nrelevant to reflections and constructs a reflective response using the\ntemplate. Paraphrase-augmented training allows the model to learn less-strict\nfillings of masked spans, and adaptive template updating helps discover\neffective templates for rewriting without significantly removing the original\ncontent. Using both automatic and human evaluations, we compare our method\nagainst text rewriting baselines and show that our framework is effective in\nturning non-reflective statements into more reflective responses while\nachieving a good content preservation-reflection style trade-off.",
            "author": [
                "Do June Min",
                "Ver\u00f3nica P\u00e9rez-Rosas",
                "Kenneth Resnicow",
                "Rada Mihalcea"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08299v1",
                "http://arxiv.org/pdf/2311.08299v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08290v1",
            "title": "On-Policy Policy Gradient Reinforcement Learning Without On-Policy\n  Sampling",
            "updated": "2023-11-14T16:37:28Z",
            "published": "2023-11-14T16:37:28Z",
            "summary": "On-policy reinforcement learning (RL) algorithms perform policy updates using\ni.i.d. trajectories collected by the current policy. However, after observing\nonly a finite number of trajectories, on-policy sampling may produce data that\nfails to match the expected on-policy data distribution. This sampling error\nleads to noisy updates and data inefficient on-policy learning. Recent work in\nthe policy evaluation setting has shown that non-i.i.d., off-policy sampling\ncan produce data with lower sampling error than on-policy sampling can produce.\nMotivated by this observation, we introduce an adaptive, off-policy sampling\nmethod to improve the data efficiency of on-policy policy gradient algorithms.\nOur method, Proximal Robust On-Policy Sampling (PROPS), reduces sampling error\nby collecting data with a behavior policy that increases the probability of\nsampling actions that are under-sampled with respect to the current policy.\nRather than discarding data from old policies -- as is commonly done in\non-policy algorithms -- PROPS uses data collection to adjust the distribution\nof previously collected data to be approximately on-policy. We empirically\nevaluate PROPS on both continuous-action MuJoCo benchmark tasks as well as\ndiscrete-action tasks and demonstrate that (1) PROPS decreases sampling error\nthroughout training and (2) improves the data efficiency of on-policy policy\ngradient algorithms. Our work improves the RL community's understanding of a\nnuance in the on-policy vs off-policy dichotomy: on-policy learning requires\non-policy data, not on-policy sampling.",
            "author": [
                "Nicholas E. Corrado",
                "Josiah P. Hanna"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08290v1",
                "http://arxiv.org/pdf/2311.08290v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08287v1",
            "title": "How Well Do Large Language Models Understand Syntax? An Evaluation by\n  Asking Natural Language Questions",
            "updated": "2023-11-14T16:30:36Z",
            "published": "2023-11-14T16:30:36Z",
            "summary": "While recent advancements in large language models (LLMs) bring us closer to\nachieving artificial general intelligence, the question persists: Do LLMs truly\nunderstand language, or do they merely mimic comprehension through pattern\nrecognition? This study seeks to explore this question through the lens of\nsyntax, a crucial component of sentence comprehension. Adopting a natural\nlanguage question-answering (Q&A) scheme, we craft questions targeting nine\nsyntactic knowledge points that are most closely related to sentence\ncomprehension. Experiments conducted on 24 LLMs suggest that most have a\nlimited grasp of syntactic knowledge, exhibiting notable discrepancies across\ndifferent syntactic knowledge points. In particular, questions involving\nprepositional phrase attachment pose the greatest challenge, whereas those\nconcerning adjectival modifier and indirect object are relatively easier for\nLLMs to handle. Furthermore, a case study on the training dynamics of the LLMs\nreveals that the majority of syntactic knowledge is learned during the initial\nstages of training, hinting that simply increasing the number of training\ntokens may not be the `silver bullet' for improving the comprehension ability\nof LLMs.",
            "author": [
                "Houquan Zhou",
                "Yang Hou",
                "Zhenghua Li",
                "Xuebin Wang",
                "Zhefeng Wang",
                "Xinyu Duan",
                "Min Zhang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08287v1",
                "http://arxiv.org/pdf/2311.08287v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08284v1",
            "title": "Level Set KSVD",
            "updated": "2023-11-14T16:27:33Z",
            "published": "2023-11-14T16:27:33Z",
            "summary": "We present a new algorithm for image segmentation - Level-set KSVD. Level-set\nKSVD merges the methods of sparse dictionary learning for feature extraction\nand variational level-set method for image segmentation. Specifically, we use a\ngeneralization of the Chan-Vese functional with features learned by KSVD. The\nmotivation for this model is agriculture based. Aerial images are taken in\norder to detect the spread of fungi in various crops. Our model is tested on\nsuch images of cotton fields. The results are compared to other methods.",
            "author": [
                "Omer Sapir",
                "Iftach Klapp",
                "Nir Sochen"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08284v1",
                "http://arxiv.org/pdf/2311.08284v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "eess.IV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08272v1",
            "title": "Mixed Attention Network for Cross-domain Sequential Recommendation",
            "updated": "2023-11-14T16:07:16Z",
            "published": "2023-11-14T16:07:16Z",
            "summary": "In modern recommender systems, sequential recommendation leverages\nchronological user behaviors to make effective next-item suggestions, which\nsuffers from data sparsity issues, especially for new users. One promising line\nof work is the cross-domain recommendation, which trains models with data\nacross multiple domains to improve the performance in data-scarce domains.\nRecent proposed cross-domain sequential recommendation models such as PiNet and\nDASL have a common drawback relying heavily on overlapped users in different\ndomains, which limits their usage in practical recommender systems. In this\npaper, we propose a Mixed Attention Network (MAN) with local and global\nattention modules to extract the domain-specific and cross-domain information.\nFirstly, we propose a local/global encoding layer to capture the\ndomain-specific/cross-domain sequential pattern. Then we propose a mixed\nattention layer with item similarity attention, sequence-fusion attention, and\ngroup-prototype attention to capture the local/global item similarity, fuse the\nlocal/global item sequence, and extract the user groups across different\ndomains, respectively. Finally, we propose a local/global prediction layer to\nfurther evolve and combine the domain-specific and cross-domain interests.\nExperimental results on two real-world datasets (each with two domains)\ndemonstrate the superiority of our proposed model. Further study also\nillustrates that our proposed method and components are model-agnostic and\neffective, respectively. The code and data are available at\nhttps://github.com/Guanyu-Lin/MAN.",
            "author": [
                "Guanyu Lin",
                "Chen Gao",
                "Yu Zheng",
                "Jianxin Chang",
                "Yanan Niu",
                "Yang Song",
                "Kun Gai",
                "Zhiheng Li",
                "Depeng Jin",
                "Yong Li",
                "Meng Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08272v1",
                "http://arxiv.org/pdf/2311.08272v1"
            ],
            "primary_category": "cs.IR",
            "category": [
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08271v1",
            "title": "Mobility-Induced Graph Learning for WiFi Positioning",
            "updated": "2023-11-14T16:06:11Z",
            "published": "2023-11-14T16:06:11Z",
            "summary": "A smartphone-based user mobility tracking could be effective in finding\nhis/her location, while the unpredictable error therein due to low\nspecification of built-in inertial measurement units (IMUs) rejects its\nstandalone usage but demands the integration to another positioning technique\nlike WiFi positioning. This paper aims to propose a novel integration technique\nusing a graph neural network called Mobility-INduced Graph LEarning (MINGLE),\nwhich is designed based on two types of graphs made by capturing different user\nmobility features. Specifically, considering sequential measurement points\n(MPs) as nodes, a user's regular mobility pattern allows us to connect neighbor\nMPs as edges, called time-driven mobility graph (TMG). Second, a user's\nrelatively straight transition at a constant pace when moving from one position\nto another can be captured by connecting the nodes on each path, called a\ndirection-driven mobility graph (DMG). Then, we can design graph convolution\nnetwork (GCN)-based cross-graph learning, where two different GCN models for\nTMG and DMG are jointly trained by feeding different input features created by\nWiFi RTTs yet sharing their weights. Besides, the loss function includes a\nmobility regularization term such that the differences between adjacent\nlocation estimates should be less variant due to the user's stable moving pace.\nNoting that the regularization term does not require ground-truth location,\nMINGLE can be designed under semi- and self-supervised learning frameworks. The\nproposed MINGLE's effectiveness is extensively verified through field\nexperiments, showing a better positioning accuracy than benchmarks, say root\nmean square errors (RMSEs) being 1.398 (m) and 1.073 (m) for self- and\nsemi-supervised learning cases, respectively.",
            "author": [
                "Kyuwon Han",
                "Seung Min Yu",
                "Seong-Lyun Kim",
                "Seung-Woo Ko"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08271v1",
                "http://arxiv.org/pdf/2311.08271v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG",
                "cs.IT",
                "cs.NI",
                "eess.SP",
                "math.IT"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08269v2",
            "title": "Defining the boundaries: challenges and advances in identifying cells in\n  microscopy images",
            "updated": "2023-11-28T17:18:44Z",
            "published": "2023-11-14T16:02:18Z",
            "summary": "Segmentation, or the outlining of objects within images, is a critical step\nin the measurement and analysis of cells within microscopy images. While\nimprovements continue to be made in tools that rely on classical methods for\nsegmentation, deep learning-based tools increasingly dominate advances in the\ntechnology. Specialist models such as Cellpose continue to improve in accuracy\nand user-friendliness, and segmentation challenges such as the Multi-Modality\nCell Segmentation Challenge continue to push innovation in accuracy across\nwidely-varying test data as well as efficiency and usability. Increased\nattention on documentation, sharing, and evaluation standards are leading to\nincreased user-friendliness and acceleration towards the goal of a truly\nuniversal method.",
            "author": [
                "Nodar Gogoberidze",
                "Beth A. Cimini"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08269v2",
                "http://arxiv.org/pdf/2311.08269v2"
            ],
            "primary_category": "q-bio.QM",
            "category": [
                "q-bio.QM",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08265v1",
            "title": "On The Relationship Between Universal Adversarial Attacks And Sparse\n  Representations",
            "updated": "2023-11-14T16:00:29Z",
            "published": "2023-11-14T16:00:29Z",
            "summary": "The prominent success of neural networks, mainly in computer vision tasks, is\nincreasingly shadowed by their sensitivity to small, barely perceivable\nadversarial perturbations in image input.\n  In this work, we aim at explaining this vulnerability through the framework\nof sparsity.\n  We show the connection between adversarial attacks and sparse\nrepresentations, with a focus on explaining the universality and\ntransferability of adversarial examples in neural networks.\n  To this end, we show that sparse coding algorithms, and the neural\nnetwork-based learned iterative shrinkage thresholding algorithm (LISTA) among\nthem, suffer from this sensitivity, and that common attacks on neural networks\ncan be expressed as attacks on the sparse representation of the input image.\nThe phenomenon that we observe holds true also when the network is agnostic to\nthe sparse representation and dictionary, and thus can provide a possible\nexplanation for the universality and transferability of adversarial attacks.\n  The code is available at\nhttps://github.com/danawr/adversarial_attacks_and_sparse_representations.",
            "author": [
                "Dana Weitzner",
                "Raja Giryes"
            ],
            "link": [
                "http://dx.doi.org/10.1109/OJSP.2023.3244486",
                "http://arxiv.org/abs/2311.08265v1",
                "http://arxiv.org/pdf/2311.08265v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.AI"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08258v2",
            "title": "Unprecedented reach and rich online journeys drive hate and extremism\n  globally",
            "updated": "2023-11-16T13:11:26Z",
            "published": "2023-11-14T15:54:19Z",
            "summary": "Hate and extremism cannot be controlled globally without understanding how\nthey operate at scale. Both have escalated dramatically during the Israel-Hamas\nand Ukraine-Russia wars. Here we show how the online hate-extremism system is\nnow operating at unprecedented scale across 26 social media platforms of all\nsizes, audience demographics, and geographic locations; and we analyze\nindividuals' journeys through it. This new picture contradicts notions of\nrabbit-hole activity at the fringe of the Internet. Instead, it shows that\nhate-extremism support now enjoys a direct link to more than a billion of the\ngeneral global population, and that newcomers now enjoy a rich variety of\nonline journey experiences during which they get to mingle with experienced\nviolent actors, discuss topics from diverse news sources, and learn to\ncollectively adapt in order to bypass platform shutdowns. Our results mean that\nlaw enforcement must expect future mass shooters to have increasingly\nhard-to-understand online journeys; that new E.U. laws will fall short because\nthe combined impact of many smaller, lesser-known platforms outstrips larger\nones like Twitter; and that the current global hate-extremism infrastructure\nwill become increasingly robust in 2024 and beyond. Fortunately, it also\nreveals a new opportunity for system-wide control akin to adaptive vs.\nextinction treatments for cancer.",
            "author": [
                "Richard Sear",
                "Neil F. Johnson"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08258v2",
                "http://arxiv.org/pdf/2311.08258v2"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.HC",
                "nlin.AO",
                "physics.soc-ph"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08256v1",
            "title": "Consensus and Disagreement: Information Aggregation under (not so) Naive\n  Learning",
            "updated": "2023-11-14T15:52:23Z",
            "published": "2023-11-14T15:52:23Z",
            "summary": "We explore a model of non-Bayesian information aggregation in networks.\nAgents non-cooperatively choose among Friedkin-Johnsen type aggregation rules\nto maximize payoffs. The DeGroot rule is chosen in equilibrium if and only if\nthere is noiseless information transmission, leading to consensus. With noisy\ntransmission, while some disagreement is inevitable, the optimal choice of rule\namplifies the disagreement: even with little noise, individuals place\nsubstantial weight on their own initial opinion in every period, exacerbating\nthe disagreement. We use this framework to think about equilibrium versus\nsocially efficient choice of rules and its connection to polarization of\nopinions across groups.",
            "author": [
                "Abhijit Banerjee",
                "Olivier Compte"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08256v1",
                "http://arxiv.org/pdf/2311.08256v1"
            ],
            "primary_category": "econ.GN",
            "category": [
                "econ.GN",
                "q-fin.EC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.14708v1",
            "title": "Large Language Model-Driven Classroom Flipping: Empowering\n  Student-Centric Peer Questioning with Flipped Interaction",
            "updated": "2023-11-14T15:48:19Z",
            "published": "2023-11-14T15:48:19Z",
            "summary": "Reciprocal questioning is essential for effective teaching and learning,\nfostering active engagement and deeper understanding through collaborative\ninteractions, especially in large classrooms. Can large language model (LLM),\nsuch as OpenAI's GPT (Generative Pre-trained Transformer) series, assist in\nthis? This paper investigates a pedagogical approach of classroom flipping\nbased on flipped interaction in LLMs. Flipped interaction involves using\nlanguage models to prioritize generating questions instead of answers to\nprompts. We demonstrate how traditional classroom flipping techniques,\nincluding Peer Instruction and Just-in-Time Teaching (JiTT), can be enhanced\nthrough flipped interaction techniques, creating student-centric questions for\nhybrid teaching. In particular, we propose a workflow to integrate prompt\nengineering with clicker and JiTT quizzes by a poll-prompt-quiz routine and a\nquiz-prompt-discuss routine to empower students to self-regulate their learning\ncapacity and enable teachers to swiftly personalize training pathways. We\ndevelop an LLM-driven chatbot software that digitizes various elements of\nclassroom flipping and facilitates the assessment of students using these\nroutines to deliver peer-generated questions. We have applied our LLM-driven\nchatbot software for teaching both undergraduate and graduate students from\n2020 to 2022, effectively useful for bridging the gap between teachers and\nstudents in remote teaching during the COVID-19 pandemic years. In particular,\nLLM-driven classroom flipping can be particularly beneficial in large class\nsettings to optimize teaching pace and enable engaging classroom experiences.",
            "author": [
                "Chee Wei Tan"
            ],
            "link": [
                "http://arxiv.org/abs/2311.14708v1",
                "http://arxiv.org/pdf/2311.14708v1"
            ],
            "primary_category": "cs.CY",
            "category": [
                "cs.CY",
                "cs.AI",
                "cs.CL",
                "cs.HC"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08252v1",
            "title": "REST: Retrieval-Based Speculative Decoding",
            "updated": "2023-11-14T15:43:47Z",
            "published": "2023-11-14T15:43:47Z",
            "summary": "We introduce Retrieval-Based Speculative Decoding (REST), a novel algorithm\ndesigned to speed up language model generation. The key insight driving the\ndevelopment of REST is the observation that the process of text generation\noften includes certain common phases and patterns. Unlike previous methods that\nrely on a draft language model for speculative decoding, REST harnesses the\npower of retrieval to generate draft tokens. This method draws from the\nreservoir of existing knowledge, retrieving and employing relevant tokens based\non the current context. Its plug-and-play nature allows for seamless\nintegration and acceleration of any language models, all without necessitating\nadditional training. When benchmarked on 7B and 13B language models in a\nsingle-batch setting, REST achieves a significant speedup of 1.62X to 2.36X on\ncode or text generation. The code of REST is available at\nhttps://github.com/FasterDecoding/REST.",
            "author": [
                "Zhenyu He",
                "Zexuan Zhong",
                "Tianle Cai",
                "Jason D Lee",
                "Di He"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08252v1",
                "http://arxiv.org/pdf/2311.08252v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.09251v1",
            "title": "A Simple and Powerful Framework for Stable Dynamic Network Embedding",
            "updated": "2023-11-14T15:38:17Z",
            "published": "2023-11-14T15:38:17Z",
            "summary": "In this paper, we address the problem of dynamic network embedding, that is,\nrepresenting the nodes of a dynamic network as evolving vectors within a\nlow-dimensional space. While the field of static network embedding is wide and\nestablished, the field of dynamic network embedding is comparatively in its\ninfancy. We propose that a wide class of established static network embedding\nmethods can be used to produce interpretable and powerful dynamic network\nembeddings when they are applied to the dilated unfolded adjacency matrix. We\nprovide a theoretical guarantee that, regardless of embedding dimension, these\nunfolded methods will produce stable embeddings, meaning that nodes with\nidentical latent behaviour will be exchangeable, regardless of their position\nin time or space. We additionally define a hypothesis testing framework which\ncan be used to evaluate the quality of a dynamic network embedding by testing\nfor planted structure in simulated networks. Using this, we demonstrate that,\neven in trivial cases, unstable methods are often either conservative or encode\nincorrect structure. In contrast, we demonstrate that our suite of stable\nunfolded methods are not only more interpretable but also more powerful in\ncomparison to their unstable counterparts.",
            "author": [
                "Ed Davis",
                "Ian Gallagher",
                "Daniel John Lawson",
                "Patrick Rubin-Delanchy"
            ],
            "link": [
                "http://arxiv.org/abs/2311.09251v1",
                "http://arxiv.org/pdf/2311.09251v1"
            ],
            "primary_category": "cs.SI",
            "category": [
                "cs.SI",
                "cs.LG",
                "stat.ML",
                "62H15 (Primary) 62H30, 62M10, 62G99 (Secondary)"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08249v1",
            "title": "On Using Distribution-Based Compositionality Assessment to Evaluate\n  Compositional Generalisation in Machine Translation",
            "updated": "2023-11-14T15:37:19Z",
            "published": "2023-11-14T15:37:19Z",
            "summary": "Compositional generalisation (CG), in NLP and in machine learning more\ngenerally, has been assessed mostly using artificial datasets. It is important\nto develop benchmarks to assess CG also in real-world natural language tasks in\norder to understand the abilities and limitations of systems deployed in the\nwild. To this end, our GenBench Collaborative Benchmarking Task submission\nutilises the distribution-based compositionality assessment (DBCA) framework to\nsplit the Europarl translation corpus into a training and a test set in such a\nway that the test set requires compositional generalisation capacity.\nSpecifically, the training and test sets have divergent distributions of\ndependency relations, testing NMT systems' capability of translating\ndependencies that they have not been trained on. This is a fully-automated\nprocedure to create natural language compositionality benchmarks, making it\nsimple and inexpensive to apply it further to other datasets and languages. The\ncode and data for the experiments is available at\nhttps://github.com/aalto-speech/dbca.",
            "author": [
                "Anssi Moisio",
                "Mathias Creutz",
                "Mikko Kurimo"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08249v1",
                "http://arxiv.org/pdf/2311.08249v1"
            ],
            "primary_category": "cs.CL",
            "category": [
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08245v1",
            "title": "TENT: Connect Language Models with IoT Sensors for Zero-Shot Activity\n  Recognition",
            "updated": "2023-11-14T15:30:17Z",
            "published": "2023-11-14T15:30:17Z",
            "summary": "Recent achievements in language models have showcased their extraordinary\ncapabilities in bridging visual information with semantic language\nunderstanding. This leads us to a novel question: can language models connect\ntextual semantics with IoT sensory signals to perform recognition tasks, e.g.,\nHuman Activity Recognition (HAR)? If so, an intelligent HAR system with\nhuman-like cognition can be built, capable of adapting to new environments and\nunseen categories. This paper explores its feasibility with an innovative\napproach, IoT-sEnsors-language alignmEnt pre-Training (TENT), which jointly\naligns textual embeddings with IoT sensor signals, including camera video,\nLiDAR, and mmWave. Through the IoT-language contrastive learning, we derive a\nunified semantic feature space that aligns multi-modal features with language\nembeddings, so that the IoT data corresponds to specific words that describe\nthe IoT data. To enhance the connection between textual categories and their\nIoT data, we propose supplementary descriptions and learnable prompts that\nbring more semantic information into the joint feature space. TENT can not only\nrecognize actions that have been seen but also ``guess'' the unseen action by\nthe closest textual words from the feature space. We demonstrate TENT achieves\nstate-of-the-art performance on zero-shot HAR tasks using different modalities,\nimproving the best vision-language models by over 12%.",
            "author": [
                "Yunjiao Zhou",
                "Jianfei Yang",
                "Han Zou",
                "Lihua Xie"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08245v1",
                "http://arxiv.org/pdf/2311.08245v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08244v1",
            "title": "Language and Sketching: An LLM-driven Interactive Multimodal Multitask\n  Robot Navigation Framework",
            "updated": "2023-11-14T15:29:52Z",
            "published": "2023-11-14T15:29:52Z",
            "summary": "The socially-aware navigation system has evolved to adeptly avoid various\nobstacles while performing multiple tasks, such as point-to-point navigation,\nhuman-following, and -guiding. However, a prominent gap persists: in\nHuman-Robot Interaction (HRI), the procedure of communicating commands to\nrobots demands intricate mathematical formulations. Furthermore, the transition\nbetween tasks does not quite possess the intuitive control and user-centric\ninteractivity that one would desire. In this work, we propose an LLM-driven\ninteractive multimodal multitask robot navigation framework, termed LIM2N, to\nsolve the above new challenge in the navigation field. We achieve this by first\nintroducing a multimodal interaction framework where language and hand-drawn\ninputs can serve as navigation constraints and control objectives. Next, a\nreinforcement learning agent is built to handle multiple tasks with the\nreceived information. Crucially, LIM2N creates smooth cooperation among the\nreasoning of multimodal input, multitask planning, and adaptation and\nprocessing of the intelligent sensing modules in the complicated system.\nExtensive experiments are conducted in both simulation and the real world\ndemonstrating that LIM2N has superior user needs understanding, alongside an\nenhanced interactive experience.",
            "author": [
                "Weiqin Zu",
                "Wenbin Song",
                "Ruiqing Chen",
                "Ze Guo",
                "Fanglei Sun",
                "Zheng Tian",
                "Wei Pan",
                "Jun Wang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08244v1",
                "http://arxiv.org/pdf/2311.08244v1"
            ],
            "primary_category": "cs.RO",
            "category": [
                "cs.RO"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08243v1",
            "title": "MCMC to address model misspecification in Deep Learning classification\n  of Radio Galaxies",
            "updated": "2023-11-14T15:25:44Z",
            "published": "2023-11-14T15:25:44Z",
            "summary": "The radio astronomy community is adopting deep learning techniques to deal\nwith the huge data volumes expected from the next-generation of radio\nobservatories. Bayesian neural networks (BNNs) provide a principled way to\nmodel uncertainty in the predictions made by deep learning models and will play\nan important role in extracting well-calibrated uncertainty estimates from the\noutputs of these models. However, most commonly used approximate Bayesian\ninference techniques such as variational inference and MCMC-based algorithms\nexperience a \"cold posterior effect (CPE)\", according to which the posterior\nmust be down-weighted in order to get good predictive performance. The CPE has\nbeen linked to several factors such as data augmentation or dataset curation\nleading to a misspecified likelihood and prior misspecification. In this work\nwe use MCMC sampling to show that a Gaussian parametric family is a poor\nvariational approximation to the true posterior and gives rise to the CPE\npreviously observed in morphological classification of radio galaxies using\nvariational inference based BNNs.",
            "author": [
                "Devina Mohan",
                "Anna Scaife"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08243v1",
                "http://arxiv.org/pdf/2311.08243v1"
            ],
            "primary_category": "astro-ph.IM",
            "category": [
                "astro-ph.IM",
                "astro-ph.GA"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08239v2",
            "title": "Learning Physics-Inspired Regularization for Medical Image Registration\n  with Hypernetworks",
            "updated": "2023-12-04T08:25:58Z",
            "published": "2023-11-14T15:20:42Z",
            "summary": "Medical image registration aims at identifying the spatial deformation\nbetween images of the same anatomical region and is fundamental to image-based\ndiagnostics and therapy. To date, the majority of the deep learning-based\nregistration methods employ regularizers that enforce global spatial\nsmoothness, e.g., the diffusion regularizer. However, such regularizers are not\ntailored to the data and might not be capable of reflecting the complex\nunderlying deformation. In contrast, physics-inspired regularizers promote\nphysically plausible deformations. One such regularizer is the linear elastic\nregularizer which models the deformation of elastic material. These\nregularizers are driven by parameters that define the material's physical\nproperties. For biological tissue, a wide range of estimations of such\nparameters can be found in the literature and it remains an open challenge to\nidentify suitable parameter values for successful registration. To overcome\nthis problem and to incorporate physical properties into learning-based\nregistration, we propose to use a hypernetwork that learns the effect of the\nphysical parameters of a physics-inspired regularizer on the resulting spatial\ndeformation field. In particular, we adapt the HyperMorph framework to learn\nthe effect of the two elasticity parameters of the linear elastic regularizer.\nOur approach enables the efficient discovery of suitable, data-specific\nphysical parameters at test time.",
            "author": [
                "Anna Reithmeir",
                "Julia A. Schnabel",
                "Veronika A. Zimmer"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08239v2",
                "http://arxiv.org/pdf/2311.08239v2"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.AI",
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08439v1",
            "title": "A Unified Approach for Comprehensive Analysis of Various Spectral and\n  Tissue Doppler Echocardiography",
            "updated": "2023-11-14T15:10:05Z",
            "published": "2023-11-14T15:10:05Z",
            "summary": "Doppler echocardiography offers critical insights into cardiac function and\nphases by quantifying blood flow velocities and evaluating myocardial motion.\nHowever, previous methods for automating Doppler analysis, ranging from initial\nsignal processing techniques to advanced deep learning approaches, have been\nconstrained by their reliance on electrocardiogram (ECG) data and their\ninability to process Doppler views collectively. We introduce a novel unified\nframework using a convolutional neural network for comprehensive analysis of\nspectral and tissue Doppler echocardiography images that combines automatic\nmeasurements and end-diastole (ED) detection into a singular method. The\nnetwork automatically recognizes key features across various Doppler views,\nwith novel Doppler shape embedding and anti-aliasing modules enhancing\ninterpretation and ensuring consistent analysis. Empirical results indicate a\nconsistent outperformance in performance metrics, including dice similarity\ncoefficients (DSC) and intersection over union (IoU). The proposed framework\ndemonstrates strong agreement with clinicians in Doppler automatic measurements\nand competitive performance in ED detection.",
            "author": [
                "Jaeik Jeon",
                "Jiyeon Kim",
                "Yeonggul Jang",
                "Yeonyee E. Yoon",
                "Dawun Jeong",
                "Youngtaek Hong",
                "Seung-Ah Lee",
                "Hyuk-Jae Chang"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08439v1",
                "http://arxiv.org/pdf/2311.08439v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08228v3",
            "title": "Counterfactual Explanation for Regression via Disentanglement in Latent\n  Space",
            "updated": "2023-11-23T10:11:06Z",
            "published": "2023-11-14T15:08:14Z",
            "summary": "Counterfactual Explanations (CEs) help address the question: How can the\nfactors that influence the prediction of a predictive model be changed to\nachieve a more favorable outcome from a user's perspective? Thus, they bear the\npotential to guide the user's interaction with AI systems since they represent\neasy-to-understand explanations. To be applicable, CEs need to be realistic and\nactionable. In the literature, various methods have been proposed to generate\nCEs. However, the majority of research on CEs focuses on classification\nproblems where questions like \"What should I do to get my rejected loan\napproved?\" are raised. In practice, answering questions like \"What should I do\nto increase my salary?\" are of a more regressive nature. In this paper, we\nintroduce a novel method to generate CEs for a pre-trained regressor by first\ndisentangling the label-relevant from the label-irrelevant dimensions in the\nlatent space. CEs are then generated by combining the label-irrelevant\ndimensions and the predefined output. The intuition behind this approach is\nthat the ideal counterfactual search should focus on the label-irrelevant\ncharacteristics of the input and suggest changes toward target-relevant\ncharacteristics. Searching in the latent space could help achieve this goal. We\nshow that our method maintains the characteristics of the query sample during\nthe counterfactual search. In various experiments, we demonstrate that the\nproposed method is competitive based on different quality measures on image and\ntabular datasets in regression problem settings. It efficiently returns results\ncloser to the original data manifold compared to three state-of-the-art\nmethods, which is essential for realistic high-dimensional machine learning\napplications. Our code will be made available as an open-source package upon\nthe publication of this work.",
            "author": [
                "Xuan Zhao",
                "Klaus Broelemann",
                "Gjergji Kasneci"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08228v3",
                "http://arxiv.org/pdf/2311.08228v3"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08223v2",
            "title": "Improving Image Captioning via Predicting Structured Concepts",
            "updated": "2023-11-28T04:05:03Z",
            "published": "2023-11-14T15:01:58Z",
            "summary": "Having the difficulty of solving the semantic gap between images and texts\nfor the image captioning task, conventional studies in this area paid some\nattention to treating semantic concepts as a bridge between the two modalities\nand improved captioning performance accordingly. Although promising results on\nconcept prediction were obtained, the aforementioned studies normally ignore\nthe relationship among concepts, which relies on not only objects in the image,\nbut also word dependencies in the text, so that offers a considerable potential\nfor improving the process of generating good descriptions. In this paper, we\npropose a structured concept predictor (SCP) to predict concepts and their\nstructures, then we integrate them into captioning, so as to enhance the\ncontribution of visual signals in this task via concepts and further use their\nrelations to distinguish cross-modal semantics for better description\ngeneration. Particularly, we design weighted graph convolutional networks\n(W-GCN) to depict concept relations driven by word dependencies, and then\nlearns differentiated contributions from these concepts for following decoding\nprocess. Therefore, our approach captures potential relations among concepts\nand discriminatively learns different concepts, so that effectively facilitates\nimage captioning with inherited information across modalities. Extensive\nexperiments and their results demonstrate the effectiveness of our approach as\nwell as each proposed module in this work.",
            "author": [
                "Ting Wang",
                "Weidong Chen",
                "Yuanhe Tian",
                "Yan Song",
                "Zhendong Mao"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08223v2",
                "http://arxiv.org/pdf/2311.08223v2"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08217v1",
            "title": "Peer is Your Pillar: A Data-unbalanced Conditional GANs for Few-shot\n  Image Generation",
            "updated": "2023-11-14T14:55:42Z",
            "published": "2023-11-14T14:55:42Z",
            "summary": "Few-shot image generation aims to train generative models using a small\nnumber of training images. When there are few images available for training\n(e.g. 10 images), Learning From Scratch (LFS) methods often generate images\nthat closely resemble the training data while Transfer Learning (TL) methods\ntry to improve performance by leveraging prior knowledge from GANs pre-trained\non large-scale datasets. However, current TL methods may not allow for\nsufficient control over the degree of knowledge preservation from the source\nmodel, making them unsuitable for setups where the source and target domains\nare not closely related. To address this, we propose a novel pipeline called\nPeer is your Pillar (PIP), which combines a target few-shot dataset with a peer\ndataset to create a data-unbalanced conditional generation. Our approach\nincludes a class embedding method that separates the class space from the\nlatent space, and we use a direction loss based on pre-trained CLIP to improve\nimage diversity. Experiments on various few-shot datasets demonstrate the\nadvancement of the proposed PIP, especially reduces the training requirements\nof few-shot image generation.",
            "author": [
                "Ziqiang Li",
                "Chaoyue Wang",
                "Xue Rui",
                "Chao Xue",
                "Jiaxu Leng",
                "Bin Li"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08217v1",
                "http://arxiv.org/pdf/2311.08217v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08214v1",
            "title": "Frequentist Guarantees of Distributed (Non)-Bayesian Inference",
            "updated": "2023-11-14T14:50:46Z",
            "published": "2023-11-14T14:50:46Z",
            "summary": "Motivated by the need to analyze large, decentralized datasets, distributed\nBayesian inference has become a critical research area across multiple fields,\nincluding statistics, electrical engineering, and economics. This paper\nestablishes Frequentist properties, such as posterior consistency, asymptotic\nnormality, and posterior contraction rates, for the distributed (non-)Bayes\nInference problem among agents connected via a communication network. Our\nresults show that, under appropriate assumptions on the communication graph,\ndistributed Bayesian inference retains parametric efficiency while enhancing\nrobustness in uncertainty quantification. We also explore the trade-off between\nstatistical efficiency and communication efficiency by examining how the design\nand size of the communication graph impact the posterior contraction rate.\nFurthermore, We extend our analysis to time-varying graphs and apply our\nresults to exponential family models, distributed logistic regression, and\ndecentralized detection models.",
            "author": [
                "Bohan Wu",
                "C\u00e9sar A. Uribe"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08214v1",
                "http://arxiv.org/pdf/2311.08214v1"
            ],
            "primary_category": "math.ST",
            "category": [
                "math.ST",
                "stat.ML",
                "stat.TH"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08213v1",
            "title": "Unlock the Power: Competitive Distillation for Multi-Modal Large\n  Language Models",
            "updated": "2023-11-14T14:49:46Z",
            "published": "2023-11-14T14:49:46Z",
            "summary": "Recently, multi-modal content generation has attracted lots of attention from\nresearchers by investigating the utilization of visual instruction tuning based\non large language models (LLMs). To enhance the performance and generalization\nability of such LLMs, the practice of distilling knowledge from pretrained\nmulti-modal models (a.k.a. teachers) to more compact multi-modal LLMs\n(students) has gained considerable interest. However, the prevailing paradigm\nof instructiontuning in multi-modal LLMs knowledge distillation is\nresource-intensive and unidirectional, neglecting the potential for mutual\nfeedback between the student and teacher models. Thus, we propose an innovative\nCompetitive Multi-modal Distillation framework (CoMD), which captures\nbidirectional feedback between teacher and student models and continually\nupdates the multi-modal capabilities that the student model has learned. It\ncomprises two stages: multi-modal pre-training and multi-modal competitive\ndistillation. The first stage pre-trains the student model on a large number of\nfiltered multi-modal datasets. The second stage facilitates a bidirectional\nknowledge transfer between the student and teacher models. Our experimental\nanalysis of diverse datasets shows that our knowledge transfer method\nconsistently improves the capabilities of the student model. Finally, the\n7B-sized student model after four distillations surpassed the current\nstate-of-the-art model LLaVA-13B on the ScienceQA and LLaVA Test dataset, also\noutperforms other strong baselines in the zero-shot setting.",
            "author": [
                "Xinwei Li",
                "Li Lin",
                "Shuai Wang",
                "Chen Qian"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08213v1",
                "http://arxiv.org/pdf/2311.08213v1"
            ],
            "primary_category": "cs.CV",
            "category": [
                "cs.CV",
                "cs.CL"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08202v1",
            "title": "Federated Skewed Label Learning with Logits Fusion",
            "updated": "2023-11-14T14:37:33Z",
            "published": "2023-11-14T14:37:33Z",
            "summary": "Federated learning (FL) aims to collaboratively train a shared model across\nmultiple clients without transmitting their local data. Data heterogeneity is a\ncritical challenge in realistic FL settings, as it causes significant\nperformance deterioration due to discrepancies in optimization among local\nmodels. In this work, we focus on label distribution skew, a common scenario in\ndata heterogeneity, where the data label categories are imbalanced on each\nclient. To address this issue, we propose FedBalance, which corrects the\noptimization bias among local models by calibrating their logits. Specifically,\nwe introduce an extra private weak learner on the client side, which forms an\nensemble model with the local model. By fusing the logits of the two models,\nthe private weak learner can capture the variance of different data, regardless\nof their category. Therefore, the optimization direction of local models can be\nimproved by increasing the penalty for misclassifying minority classes and\nreducing the attention to majority classes, resulting in a better global model.\nExtensive experiments show that our method can gain 13\\% higher average\naccuracy compared with state-of-the-art methods.",
            "author": [
                "Yuwei Wang",
                "Runhan Li",
                "Hao Tan",
                "Xuefeng Jiang",
                "Sheng Sun",
                "Min Liu",
                "Bo Gao",
                "Zhiyuan Wu"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08202v1",
                "http://arxiv.org/pdf/2311.08202v1"
            ],
            "primary_category": "cs.LG",
            "category": [
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2312.00025v1",
            "title": "Secure Transformer Inference",
            "updated": "2023-11-14T14:37:23Z",
            "published": "2023-11-14T14:37:23Z",
            "summary": "We present a three-party protocol that can protect both Transformer\nparameters and user data during the inference phase. For each feedforward\ninference process, our protocol only introduces permutation computation of\ninput and output data on the user side. Our protocol, Secure Transformer\nInference Protocol (STIP), can be applied to real-world services like ChatGPT.",
            "author": [
                "Mu Yuan",
                "Lan Zhang",
                "Xiang-Yang Li"
            ],
            "link": [
                "http://arxiv.org/abs/2312.00025v1",
                "http://arxiv.org/pdf/2312.00025v1"
            ],
            "primary_category": "cs.CR",
            "category": [
                "cs.CR",
                "cs.LG"
            ]
        }
    },
    {
        "public": {
            "@context": "https://schema.org",
            "@type": "ArxivArticle",
            "@id": "urn:research:http://arxiv.org/abs/2311.08199v1",
            "title": "Diffusion-based generation of Histopathological Whole Slide Images at a\n  Gigapixel scale",
            "updated": "2023-11-14T14:33:39Z",
            "published": "2023-11-14T14:33:39Z",
            "summary": "We present a novel diffusion-based approach to generate synthetic\nhistopathological Whole Slide Images (WSIs) at an unprecedented gigapixel\nscale. Synthetic WSIs have many potential applications: They can augment\ntraining datasets to enhance the performance of many computational pathology\napplications. They allow the creation of synthesized copies of datasets that\ncan be shared without violating privacy regulations. Or they can facilitate\nlearning representations of WSIs without requiring data annotations. Despite\nthis variety of applications, no existing deep-learning-based method generates\nWSIs at their typically high resolutions. Mainly due to the high computational\ncomplexity. Therefore, we propose a novel coarse-to-fine sampling scheme to\ntackle image generation of high-resolution WSIs. In this scheme, we increase\nthe resolution of an initial low-resolution image to a high-resolution WSI.\nParticularly, a diffusion model sequentially adds fine details to images and\nincreases their resolution. In our experiments, we train our method with WSIs\nfrom the TCGA-BRCA dataset. Additionally to quantitative evaluations, we also\nperformed a user study with pathologists. The study results suggest that our\ngenerated WSIs resemble the structure of real WSIs.",
            "author": [
                "Robert Harb",
                "Thomas Pock",
                "Heimo M\u00fcller"
            ],
            "link": [
                "http://arxiv.org/abs/2311.08199v1",
                "http://arxiv.org/pdf/2311.08199v1"
            ],
            "primary_category": "eess.IV",
            "category": [
                "eess.IV",
                "cs.CV",
                "cs.LG",
                "I.4.9; I.5.4; I.2.10"
            ]
        }
    }
]